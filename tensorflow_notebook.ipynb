{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from functools import reduce\n",
    "import operator as op\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "dataset_folder = os.path.abspath(\"./individual_npzs/{0}/*.npz\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0003\n",
    "batch_size = 64\n",
    "dropout = 0.5\n",
    "max_pool = 2\n",
    "strides = 1\n",
    "input_size = 60000\n",
    "output_size = 4\n",
    "epochs = 30\n",
    "timesteps = 38\n",
    "seed_num = 72\n",
    "hidden_layer = 64\n",
    "\n",
    "validation_session = 4\n",
    "test_session = 5\n",
    "\n",
    "label_dictionary = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}\n",
    "\n",
    "tf.set_random_seed(seed_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, labels):\n",
    "    steps = math.ceil(data.shape[0] / batch_size)\n",
    "    for batch_step in range(0, steps):\n",
    "        start = batch_size * batch_step\n",
    "        end = batch_size * (batch_step + 1)\n",
    "        yield data[start:end], labels[start:end]\n",
    "        \n",
    "def build_encoded_array(emotion_label):\n",
    "    initialized_array = [0. for key in label_dictionary]\n",
    "    initialized_array[label_dictionary[emotion_label]] = 1.\n",
    "    return initialized_array\n",
    "        \n",
    "def onehot_encode(label_minibatch):\n",
    "    return [build_encoded_array(emotion_label) for emotion_label in label_minibatch]\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    class_weights = np.ndarray.tolist(class_weight.compute_class_weight('balanced', np.unique(labels), labels))\n",
    "    #class_weights_dict = {index: value for (index, value) in enumerate(class_weights)}\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset: 3 sessions for training, 1 for validation, 1 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "validation_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "train_labels = []\n",
    "validation_labels = []\n",
    "test_labels = []\n",
    "\n",
    "session_string = 'session{0}'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    formatted = session_string.format(i)\n",
    "    for spectrogram in glob.glob(dataset_folder.format(formatted)):\n",
    "        loaded_spec = np.load(spectrogram)\n",
    "        for x in loaded_spec['spectrograms']:\n",
    "            if i != validation_session and i != test_session:\n",
    "                train_dataset.append(x) \n",
    "            elif i == validation_session:\n",
    "                validation_dataset.append(x)\n",
    "            elif i == test_session:\n",
    "                test_dataset.append(x)\n",
    "        for x in loaded_spec['labels']:\n",
    "            if i != validation_session and i != test_session:\n",
    "                train_labels.append(x) \n",
    "            elif i == validation_session:\n",
    "                validation_labels.append(x)\n",
    "            elif i == test_session:\n",
    "                test_labels.append(x)\n",
    "        \n",
    "train_dataset = np.asarray(train_dataset)\n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "validation_dataset = np.asarray(validation_dataset)\n",
    "validation_labels = np.asarray(validation_labels)\n",
    "\n",
    "test_dataset = np.asarray(test_dataset)\n",
    "test_labels = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros([len(train_dataset), train_dataset[0].shape[0], train_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(train_dataset)):\n",
    "    train_data[data,:,:] = train_dataset[data]\n",
    "    \n",
    "validation_data = np.zeros([len(validation_dataset), validation_dataset[0].shape[0], validation_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(validation_dataset)):\n",
    "    validation_data[data,:,:] = validation_dataset[data]\n",
    "    \n",
    "test_data = np.zeros([len(test_dataset), test_dataset[0].shape[0], test_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(test_dataset)):\n",
    "    test_data[data,:,:] = test_dataset[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = validation_data.reshape((validation_data.shape[0], input_size))\n",
    "validation_labels = onehot_encode(validation_labels)\n",
    "\n",
    "test_data = test_data.reshape((test_data.shape[0], input_size))\n",
    "class_weights = compute_class_weights(test_labels)\n",
    "test_labels = onehot_encode(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(to_process, weights, biases, strides=1):\n",
    "    conv_out = tf.nn.conv2d(to_process, weights, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    bias_out = tf.nn.bias_add(conv_out, biases)\n",
    "    relu_out = tf.nn.relu(bias_out)\n",
    "    return relu_out\n",
    "\n",
    "def maxpool2d(to_pool, pool_size=2):\n",
    "    maxpool_out = tf.nn.max_pool(to_pool, ksize=[1, pool_size, pool_size, 1], strides=[1, pool_size, pool_size, 1], padding='SAME')\n",
    "    return maxpool_out\n",
    "\n",
    "def nn_pipeline(spectrogram, weights, biases):\n",
    "    \n",
    "    reshaped_input = tf.reshape(spectrogram, shape=[-1, 200, 300, 1])\n",
    "    \n",
    "    first_layer_out = conv2d(reshaped_input, weights['first_layer_weights'], biases['first_layer_biases'])\n",
    "    first_maxpool_out = maxpool2d(first_layer_out, pool_size=2)\n",
    "    \n",
    "    second_layer_out = conv2d(first_maxpool_out, weights['second_layer_weights'], biases['second_layer_biases'])\n",
    "    second_maxpool_out = maxpool2d(second_layer_out, pool_size=2)\n",
    "    \n",
    "    third_layer_out = conv2d(second_maxpool_out, weights['third_layer_weights'], biases['third_layer_biases'])\n",
    "    third_maxpool_out = maxpool2d(third_layer_out, pool_size=2)\n",
    "    \n",
    "    reshape_for_fc = tf.reshape(third_maxpool_out, [-1, weights['fully_connected_weights'].get_shape().as_list()[0]])\n",
    "    fully_connected_out = tf.add(tf.matmul(reshape_for_fc, weights['fully_connected_weights']), biases['fully_connected_biases'])\n",
    "    fully_connected_activation = tf.nn.relu(fully_connected_out)\n",
    "    fully_connected_dropout = tf.nn.dropout(fully_connected_activation, dropout)\n",
    "    \n",
    "    fully_connected_out_2 = tf.add(tf.matmul(fully_connected_dropout, weights['fully_connected_weights_2']), biases['fully_connected_biases_2'])\n",
    "    fully_connected_activation_2 = tf.nn.relu(fully_connected_out_2)\n",
    "    fully_connected_dropout_2 = tf.nn.dropout(fully_connected_activation_2, dropout)\n",
    "    \n",
    "    prediction = tf.add(tf.matmul(fully_connected_dropout_2, weights['output']), biases['output'])\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_pipeline_rnn(spectrogram, weights, biases):\n",
    "    reshaped_input = tf.reshape(spectrogram, shape=[-1, 200, 300, 1])\n",
    "\n",
    "    first_layer_out = conv2d(reshaped_input, weights['first_layer_weights'], biases['first_layer_biases'])\n",
    "    first_maxpool_out = maxpool2d(first_layer_out, pool_size=2)\n",
    "    first_batch_norm = tf.layers.batch_normalization(first_maxpool_out)\n",
    "\n",
    "    second_layer_out = conv2d(first_batch_norm, weights['second_layer_weights'], biases['second_layer_biases'])\n",
    "    second_maxpool_out = maxpool2d(second_layer_out, pool_size=2)\n",
    "    second_batch_norm = tf.layers.batch_normalization(second_maxpool_out)\n",
    "\n",
    "    third_layer_out = conv2d(second_batch_norm, weights['third_layer_weights'], biases['third_layer_biases'])\n",
    "    third_maxpool_out = maxpool2d(third_layer_out, pool_size=2)\n",
    "    third_batch_norm = tf.layers.batch_normalization(third_maxpool_out)\n",
    "\n",
    "    interim_shape = third_batch_norm.get_shape().as_list()\n",
    "    transposed = tf.transpose(third_batch_norm, perm=[0, 2, 1, 3])\n",
    "    reshape_for_rnn = tf.reshape(transposed, [-1, interim_shape[2], interim_shape[1]*interim_shape[3]])\n",
    "    reshape_for_rnn.set_shape([None, interim_shape[2], interim_shape[1]*interim_shape[3]])\n",
    "\n",
    "    hidden_list = [hidden_layer, hidden_layer]\n",
    "\n",
    "    gru_fw_cell = [tf.contrib.rnn.GRUCell(hidden) for hidden in hidden_list]\n",
    "    gru_bw_cell = [tf.contrib.rnn.GRUCell(hidden) for hidden in hidden_list]\n",
    "\n",
    "    gru_output, _, _, = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(gru_fw_cell, gru_bw_cell, reshape_for_rnn, dtype=tf.float32)\n",
    "    interim_shape_gru = tf.shape(gru_output)\n",
    "    gru_flatten = tf.reshape(gru_output, [-1, interim_shape_gru[1]*interim_shape_gru[2]])\n",
    "    \n",
    "    fully_connected_out = tf.add(tf.matmul(gru_flatten, weights['gru_weights']), biases['gru_biases'])\n",
    "    fully_connected_activation = tf.nn.relu(fully_connected_out)\n",
    "    fully_connected_dropout = tf.nn.dropout(fully_connected_activation, dropout)\n",
    "    \n",
    "    prediction = tf.add(tf.matmul(fully_connected_dropout, weights['output']), biases['output'])\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'first_layer_weights': tf.Variable(tf.random_normal([10, 15, 1, 16])),\n",
    "    'second_layer_weights': tf.Variable(tf.random_normal([8, 10, 16, 24])),\n",
    "    'third_layer_weights': tf.Variable(tf.random_normal([5, 8, 24, 32])),\n",
    "    'fully_connected_weights': tf.Variable(tf.random_normal([25*38*32, 2048])),\n",
    "    'fully_connected_weights_2': tf.Variable(tf.random_normal([2048, 2048])),\n",
    "    'output': tf.Variable(tf.random_normal([2048, output_size]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'first_layer_biases': tf.Variable(tf.random_normal([16])),\n",
    "    'second_layer_biases': tf.Variable(tf.random_normal([24])),\n",
    "    'third_layer_biases': tf.Variable(tf.random_normal([32])),\n",
    "    'fully_connected_biases': tf.Variable(tf.random_normal([2048])),\n",
    "    'fully_connected_biases_2': tf.Variable(tf.random_normal([2048])),\n",
    "    'output': tf.Variable(tf.random_normal([output_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_rnn = {\n",
    "    'first_layer_weights': tf.Variable(tf.truncated_normal([10, 15, 1, 16], seed=seed_num)),\n",
    "    'second_layer_weights': tf.Variable(tf.truncated_normal([8, 10, 16, 24], seed=seed_num)),\n",
    "    'third_layer_weights': tf.Variable(tf.truncated_normal([5, 8, 24, 32], seed=seed_num)),\n",
    "    'gru_weights': tf.Variable(tf.truncated_normal([2*hidden_layer*timesteps, hidden_layer], seed=seed_num)),\n",
    "    'output': tf.Variable(tf.truncated_normal([hidden_layer, output_size], seed=seed_num))\n",
    "}\n",
    "\n",
    "biases_rnn = {\n",
    "    'first_layer_biases': tf.Variable(tf.truncated_normal([16], seed=seed_num)),\n",
    "    'second_layer_biases': tf.Variable(tf.truncated_normal([24], seed=seed_num)),\n",
    "    'third_layer_biases': tf.Variable(tf.truncated_normal([32], seed=seed_num)),\n",
    "    'gru_biases': tf.Variable(tf.truncated_normal([hidden_layer], seed=seed_num)),\n",
    "    'output': tf.Variable(tf.truncated_normal([output_size], seed=seed_num))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "Y = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = nn_pipeline_rnn(X, weights_rnn, biases_rnn)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "weights = tf.reduce_sum(class_weights * Y, axis=1)\n",
    "weight_regularizer = tf.add_n([tf.nn.l2_loss(weights_rnn[weights]) for weights in weights_rnn]) * 0.01\n",
    "bias_regularizer = tf.add_n([tf.nn.l2_loss(biases_rnn[biases]) for biases in biases_rnn]) * 0.01\n",
    "\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=Y)*weights) + weight_regularizer + bias_regularizer\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "train_trigger = optimizer.minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session initialized.\n",
      "Training accuracy of batch: Loss=412.7390, Accuracy=0.2841.\n",
      "Training accuracy of batch: Loss=280.0649, Accuracy=0.3034.\n",
      "Training accuracy of batch: Loss=235.0946, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=231.0252, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=231.4066, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=232.2294, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=225.5135, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=224.9844, Accuracy=0.3339.\n",
      "Training accuracy of batch: Loss=218.2465, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=213.1193, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=217.9947, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=221.3722, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=217.3204, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=220.8102, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=219.7844, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=220.7055, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=213.8305, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=212.6872, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=214.6202, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=205.4291, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=212.0692, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=205.6742, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=209.1775, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=206.8511, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=199.7057, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=201.8839, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=199.1691, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=200.7227, Accuracy=0.3515.\n",
      "Training accuracy of batch: Loss=199.2845, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=197.3073, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=200.7153, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=199.6339, Accuracy=0.3387.\n",
      "Training accuracy of batch: Loss=206.7027, Accuracy=0.3579.\n",
      "Validation after epoch #1, Validation Loss= 203.3466, Validation Accuracy= 0.364\n",
      "Training accuracy of batch: Loss=202.0051, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=201.2325, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=194.1159, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=201.2647, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=193.4867, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=190.7477, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=199.1638, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=197.7617, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=193.9508, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=190.6496, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=192.3104, Accuracy=0.3291.\n",
      "Training accuracy of batch: Loss=191.1203, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=192.6674, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=195.6905, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=198.2840, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=193.9899, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=194.0286, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=194.1033, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=191.7949, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=191.9113, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=193.1743, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=188.9920, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=191.0977, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=190.6779, Accuracy=0.3451.\n",
      "Training accuracy of batch: Loss=185.6505, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=187.6998, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=188.9380, Accuracy=0.3130.\n",
      "Training accuracy of batch: Loss=188.2151, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=185.7630, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=187.0323, Accuracy=0.3274.\n",
      "Training accuracy of batch: Loss=186.8909, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=187.6758, Accuracy=0.3419.\n",
      "Training accuracy of batch: Loss=187.3028, Accuracy=0.3708.\n",
      "Validation after epoch #2, Validation Loss= 185.0394, Validation Accuracy= 0.384\n",
      "Training accuracy of batch: Loss=185.8500, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=184.2344, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=184.8889, Accuracy=0.3515.\n",
      "Training accuracy of batch: Loss=184.4321, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=186.6987, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=185.6890, Accuracy=0.3515.\n",
      "Training accuracy of batch: Loss=184.1400, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=183.9518, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=183.9084, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=181.3098, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=182.7376, Accuracy=0.3323.\n",
      "Training accuracy of batch: Loss=179.1538, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=181.8732, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=184.8773, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=182.3613, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=183.3812, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=179.9615, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=184.4541, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=181.7542, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=181.5862, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=182.0665, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=181.2825, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=179.7170, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=178.6311, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=180.9742, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=178.4405, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=180.0981, Accuracy=0.3274.\n",
      "Training accuracy of batch: Loss=175.1076, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=174.2674, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=176.5554, Accuracy=0.3274.\n",
      "Training accuracy of batch: Loss=178.5906, Accuracy=0.3291.\n",
      "Training accuracy of batch: Loss=179.7859, Accuracy=0.3323.\n",
      "Training accuracy of batch: Loss=177.5178, Accuracy=0.3499.\n",
      "Validation after epoch #3, Validation Loss= 179.8109, Validation Accuracy= 0.380\n",
      "Training accuracy of batch: Loss=177.0385, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=176.3472, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=175.5172, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=176.2264, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=176.1743, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=175.8050, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=175.5110, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=177.0377, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=174.4316, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=172.9075, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=173.5762, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=175.4430, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=176.5601, Accuracy=0.3419.\n",
      "Training accuracy of batch: Loss=177.3340, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=175.8600, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=177.6902, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=175.4064, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=174.5293, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=174.3765, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=175.0166, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=174.2898, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=173.9451, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=172.7240, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=172.7065, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=174.7080, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=168.4188, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=170.9270, Accuracy=0.3515.\n",
      "Training accuracy of batch: Loss=172.8381, Accuracy=0.3339.\n",
      "Training accuracy of batch: Loss=170.2417, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=172.7889, Accuracy=0.3291.\n",
      "Training accuracy of batch: Loss=173.3319, Accuracy=0.3114.\n",
      "Training accuracy of batch: Loss=170.5961, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=169.9737, Accuracy=0.3692.\n",
      "Validation after epoch #4, Validation Loss= 170.7534, Validation Accuracy= 0.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=170.2940, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=170.7321, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=171.5083, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=169.8801, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=170.1165, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=169.7102, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=170.7073, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=169.3211, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=169.1282, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=168.7306, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=170.1703, Accuracy=0.3451.\n",
      "Training accuracy of batch: Loss=169.4748, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=169.9965, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=171.3423, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=172.6695, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=171.0466, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=170.1549, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=170.7489, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=169.5745, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=167.6230, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=169.3583, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=168.2227, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=168.0673, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=167.3618, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=166.6881, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=166.0477, Accuracy=0.3419.\n",
      "Training accuracy of batch: Loss=168.4617, Accuracy=0.3130.\n",
      "Training accuracy of batch: Loss=164.5936, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=165.4674, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=166.4660, Accuracy=0.3339.\n",
      "Training accuracy of batch: Loss=166.8240, Accuracy=0.3082.\n",
      "Training accuracy of batch: Loss=164.8865, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=166.5479, Accuracy=0.3692.\n",
      "Validation after epoch #5, Validation Loss= 166.4831, Validation Accuracy= 0.377\n",
      "Training accuracy of batch: Loss=166.0790, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=166.1024, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=164.9826, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=164.4128, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=166.4438, Accuracy=0.3483.\n",
      "Training accuracy of batch: Loss=164.2837, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=165.3556, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=165.6990, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=164.5655, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=162.6787, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=165.0814, Accuracy=0.3194.\n",
      "Training accuracy of batch: Loss=163.8951, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=164.8239, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=166.3745, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=167.7312, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=165.0390, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=165.2879, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=165.1256, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=165.2454, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=163.2040, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=164.8049, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=163.6151, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=165.2537, Accuracy=0.3435.\n",
      "Training accuracy of batch: Loss=163.2667, Accuracy=0.3210.\n",
      "Training accuracy of batch: Loss=162.6332, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=161.8703, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=163.2760, Accuracy=0.3130.\n",
      "Training accuracy of batch: Loss=162.9143, Accuracy=0.3178.\n",
      "Training accuracy of batch: Loss=163.1859, Accuracy=0.3387.\n",
      "Training accuracy of batch: Loss=161.5531, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=161.1961, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=163.1869, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=162.3136, Accuracy=0.3900.\n",
      "Validation after epoch #6, Validation Loss= 163.8686, Validation Accuracy= 0.376\n",
      "Training accuracy of batch: Loss=161.8346, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=161.7029, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=160.6636, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=161.9058, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=161.0157, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=160.2817, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=161.5341, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=160.1226, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=160.0977, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=159.6092, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=160.2678, Accuracy=0.3435.\n",
      "Training accuracy of batch: Loss=160.1705, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=160.7358, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=161.3168, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=162.4196, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=160.0906, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=160.9437, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=159.7260, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=160.7597, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=159.4721, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=160.2742, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=159.8394, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=159.5963, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=159.6330, Accuracy=0.3435.\n",
      "Training accuracy of batch: Loss=160.5415, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=159.0354, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=159.7601, Accuracy=0.3034.\n",
      "Training accuracy of batch: Loss=157.8999, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=158.2586, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=157.8151, Accuracy=0.3499.\n",
      "Training accuracy of batch: Loss=158.1313, Accuracy=0.3130.\n",
      "Training accuracy of batch: Loss=158.6092, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=158.8261, Accuracy=0.3692.\n",
      "Validation after epoch #7, Validation Loss= 159.2374, Validation Accuracy= 0.369\n",
      "Training accuracy of batch: Loss=157.7294, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=157.5116, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=158.0463, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=157.1646, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=157.7612, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=156.7532, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=159.0044, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=158.2794, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=157.4094, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=157.5127, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=157.2865, Accuracy=0.3178.\n",
      "Training accuracy of batch: Loss=157.9791, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=158.1341, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=158.8149, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=158.3108, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=157.7128, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=157.9341, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=157.6412, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=156.4953, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=156.3146, Accuracy=0.3387.\n",
      "Training accuracy of batch: Loss=157.0257, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=156.2942, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=155.8476, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=156.0937, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=157.2184, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=156.1852, Accuracy=0.3451.\n",
      "Training accuracy of batch: Loss=155.9539, Accuracy=0.2953.\n",
      "Training accuracy of batch: Loss=156.0086, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=155.1722, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=154.7688, Accuracy=0.3419.\n",
      "Training accuracy of batch: Loss=154.5719, Accuracy=0.3451.\n",
      "Training accuracy of batch: Loss=155.9405, Accuracy=0.3435.\n",
      "Training accuracy of batch: Loss=155.7711, Accuracy=0.3820.\n",
      "Validation after epoch #8, Validation Loss= 155.9012, Validation Accuracy= 0.369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=154.8683, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=154.9871, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=154.8611, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=154.6666, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=153.9290, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=154.3587, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=155.1525, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=154.3750, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=154.3249, Accuracy=0.3596.\n",
      "Training accuracy of batch: Loss=154.0244, Accuracy=0.3323.\n",
      "Training accuracy of batch: Loss=154.4106, Accuracy=0.3291.\n",
      "Training accuracy of batch: Loss=154.9559, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=154.9299, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=154.9258, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=155.6367, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=154.9003, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=154.4594, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=154.1839, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=154.4853, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=153.4896, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=154.5981, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=154.0730, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=153.0901, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=153.2683, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=153.3514, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=153.2531, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=153.9394, Accuracy=0.3162.\n",
      "Training accuracy of batch: Loss=152.2600, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=152.6440, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=152.6658, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=152.3402, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=153.1849, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=153.6581, Accuracy=0.3917.\n",
      "Validation after epoch #9, Validation Loss= 153.2046, Validation Accuracy= 0.400\n",
      "Training accuracy of batch: Loss=152.5634, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=152.5751, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=152.2883, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=152.9458, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=152.0654, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=152.1455, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=152.5052, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=152.4584, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=151.8855, Accuracy=0.3612.\n",
      "Training accuracy of batch: Loss=152.0378, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=152.0582, Accuracy=0.3082.\n",
      "Training accuracy of batch: Loss=153.1575, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=153.4060, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=153.6913, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=153.9448, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=152.9146, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=152.2824, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=151.8878, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=151.7259, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=151.4346, Accuracy=0.3419.\n",
      "Training accuracy of batch: Loss=152.5712, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=152.0772, Accuracy=0.3435.\n",
      "Training accuracy of batch: Loss=151.2730, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=151.8310, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=151.7469, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=151.1014, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=151.6824, Accuracy=0.3018.\n",
      "Training accuracy of batch: Loss=150.8600, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=151.4185, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=150.7697, Accuracy=0.3451.\n",
      "Training accuracy of batch: Loss=150.9990, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=151.3888, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=152.0715, Accuracy=0.3997.\n",
      "Validation after epoch #10, Validation Loss= 152.1163, Validation Accuracy= 0.392\n",
      "Training accuracy of batch: Loss=151.4839, Accuracy=0.3515.\n",
      "Training accuracy of batch: Loss=151.7218, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=151.1575, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=151.1604, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=150.8866, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=150.8487, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=151.2275, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=150.6003, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=150.5403, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=150.7071, Accuracy=0.3274.\n",
      "Training accuracy of batch: Loss=150.9095, Accuracy=0.3515.\n",
      "Training accuracy of batch: Loss=150.4899, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=150.5423, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=151.1802, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=151.1498, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=150.4303, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=150.8080, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=150.7798, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=150.5119, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=150.4493, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=150.6161, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=150.9276, Accuracy=0.3242.\n",
      "Training accuracy of batch: Loss=150.2397, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=150.3122, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=150.3355, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=150.1186, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=150.1877, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=150.0869, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=149.6890, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=149.7111, Accuracy=0.3563.\n",
      "Training accuracy of batch: Loss=150.0156, Accuracy=0.3644.\n",
      "Training accuracy of batch: Loss=149.7300, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=149.7326, Accuracy=0.3949.\n",
      "Validation after epoch #11, Validation Loss= 149.9522, Validation Accuracy= 0.396\n",
      "Training accuracy of batch: Loss=149.5244, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=149.8959, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=149.5244, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=149.7732, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=149.4218, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=149.5961, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=149.6380, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=149.3686, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=149.3093, Accuracy=0.3756.\n",
      "Training accuracy of batch: Loss=149.4303, Accuracy=0.3676.\n",
      "Training accuracy of batch: Loss=149.6203, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=149.2884, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=149.4206, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=149.5147, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=149.7427, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=149.6390, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=148.9658, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=149.2918, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=149.2402, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=149.4120, Accuracy=0.3435.\n",
      "Training accuracy of batch: Loss=149.3718, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=149.4142, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=149.1558, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=149.0065, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=149.3779, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=149.0732, Accuracy=0.3724.\n",
      "Training accuracy of batch: Loss=149.5864, Accuracy=0.3242.\n",
      "Training accuracy of batch: Loss=148.9554, Accuracy=0.3660.\n",
      "Training accuracy of batch: Loss=149.0641, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=148.8484, Accuracy=0.3371.\n",
      "Training accuracy of batch: Loss=149.1109, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=148.8453, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=148.9331, Accuracy=0.3917.\n",
      "Validation after epoch #12, Validation Loss= 149.0125, Validation Accuracy= 0.385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=148.7001, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=148.9270, Accuracy=0.3708.\n",
      "Training accuracy of batch: Loss=148.6372, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=148.8761, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=148.8384, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=148.7176, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=148.7822, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=148.6248, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=148.5679, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=148.7650, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=148.6633, Accuracy=0.3387.\n",
      "Training accuracy of batch: Loss=148.5452, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=148.5417, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=148.7396, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=148.6677, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=148.7007, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=148.5453, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=148.6204, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=148.2708, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=148.6052, Accuracy=0.3579.\n",
      "Training accuracy of batch: Loss=148.4049, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=148.3970, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=148.3225, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=148.3219, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=148.4003, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=148.1198, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=148.2642, Accuracy=0.3628.\n",
      "Training accuracy of batch: Loss=148.3242, Accuracy=0.3692.\n",
      "Training accuracy of batch: Loss=147.9413, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=148.1069, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=147.9568, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=147.9921, Accuracy=0.3740.\n",
      "Training accuracy of batch: Loss=148.0058, Accuracy=0.3836.\n",
      "Validation after epoch #13, Validation Loss= 147.9418, Validation Accuracy= 0.385\n",
      "Training accuracy of batch: Loss=148.0802, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=147.9796, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.9248, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=148.0183, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.8546, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=147.8699, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.8871, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=147.8529, Accuracy=0.3820.\n",
      "Training accuracy of batch: Loss=147.8052, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.7656, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=147.9238, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=147.8612, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=147.8493, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.8106, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=147.9384, Accuracy=0.4061.\n",
      "Training accuracy of batch: Loss=147.8997, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.9344, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.8036, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.6429, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=147.8611, Accuracy=0.3804.\n",
      "Training accuracy of batch: Loss=147.8533, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=147.8247, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.5597, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.6035, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=147.6049, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.4389, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=147.5194, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.5686, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=147.3654, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.3348, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.3316, Accuracy=0.3788.\n",
      "Training accuracy of batch: Loss=147.2515, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.3630, Accuracy=0.3965.\n",
      "Validation after epoch #14, Validation Loss= 147.3818, Validation Accuracy= 0.395\n",
      "Training accuracy of batch: Loss=147.2568, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=147.2856, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.4036, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=147.3275, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.2610, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=147.1365, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.2883, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.1147, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=147.1446, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.0899, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.1313, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=147.1493, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.1849, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=147.2995, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=147.1728, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=147.1964, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=147.0836, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=147.0689, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=147.1018, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=147.0795, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.1828, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=147.2286, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=147.0245, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.9751, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.9921, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.9203, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.9383, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.9078, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.8233, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.8227, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.7411, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.7370, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.8445, Accuracy=0.3933.\n",
      "Validation after epoch #15, Validation Loss= 146.7540, Validation Accuracy= 0.388\n",
      "Training accuracy of batch: Loss=146.7674, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.6996, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.7374, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.7109, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.7445, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.6399, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.6339, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.6003, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.6415, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.4846, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.5113, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.5304, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.6320, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.6248, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.7109, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.6170, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.5184, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.6106, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.6054, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.5797, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.6532, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.5978, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.5365, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.5645, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.5478, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.5240, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.4548, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.4319, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.4411, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3726, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3374, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.4113, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3890, Accuracy=0.3965.\n",
      "Validation after epoch #16, Validation Loss= 146.5034, Validation Accuracy= 0.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=146.4550, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.4662, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3649, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3974, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3887, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3337, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.4179, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3280, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3091, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2997, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3362, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3916, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3956, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.4192, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.4753, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.4203, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.4698, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.4477, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3832, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.4143, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.4454, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3964, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3456, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.4003, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3661, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3305, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2917, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2954, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3089, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2936, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2849, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3342, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3557, Accuracy=0.3981.\n",
      "Validation after epoch #17, Validation Loss= 146.3426, Validation Accuracy= 0.401\n",
      "Training accuracy of batch: Loss=146.3150, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3334, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2413, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3150, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2974, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3468, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3835, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2992, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3079, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2849, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3660, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3241, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3315, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.4435, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3950, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.4053, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3691, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.4008, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=146.3754, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3605, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.4203, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.4037, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3136, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3549, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3241, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2701, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3366, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2953, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2918, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2582, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2832, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3330, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3395, Accuracy=0.3933.\n",
      "Validation after epoch #18, Validation Loss= 146.3637, Validation Accuracy= 0.401\n",
      "Training accuracy of batch: Loss=146.3134, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3483, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3257, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3558, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2923, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3317, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3554, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3178, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3130, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2927, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2722, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3285, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3715, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.4393, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3889, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3954, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.4166, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3948, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3565, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3893, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=146.3292, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3386, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3932, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3417, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3358, Accuracy=0.4061.\n",
      "Training accuracy of batch: Loss=146.2961, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2993, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2884, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2652, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2702, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2753, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2610, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3518, Accuracy=0.3917.\n",
      "Validation after epoch #19, Validation Loss= 146.3438, Validation Accuracy= 0.387\n",
      "Training accuracy of batch: Loss=146.2954, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2806, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2619, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3152, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.2890, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3104, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3570, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3354, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3282, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2589, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2387, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3026, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3925, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3827, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.4130, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3703, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3790, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3913, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3676, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3043, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3829, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3640, Accuracy=0.4061.\n",
      "Training accuracy of batch: Loss=146.3345, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3487, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3706, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2722, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2718, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2796, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2664, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2619, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2216, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2612, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2727, Accuracy=0.4029.\n",
      "Validation after epoch #20, Validation Loss= 146.3528, Validation Accuracy= 0.390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=146.3457, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3232, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3187, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3426, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3551, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3035, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3022, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3304, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3155, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2733, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2809, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3395, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3846, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3763, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3844, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3466, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3384, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3672, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3180, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3664, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3632, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3200, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3494, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.3194, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3016, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2943, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2735, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2411, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3000, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2345, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2438, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2390, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3029, Accuracy=0.4013.\n",
      "Validation after epoch #21, Validation Loss= 146.2958, Validation Accuracy= 0.403\n",
      "Training accuracy of batch: Loss=146.3113, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3450, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2802, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2948, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3003, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2762, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3708, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2969, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2856, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2275, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2578, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3192, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3794, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3591, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.4299, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3430, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3509, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3328, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3806, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3612, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.4077, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3509, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3306, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3101, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2954, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2738, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2575, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2038, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2681, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2777, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.2979, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2455, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3408, Accuracy=0.3917.\n",
      "Validation after epoch #22, Validation Loss= 146.2670, Validation Accuracy= 0.393\n",
      "Training accuracy of batch: Loss=146.2964, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3453, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3100, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=146.3017, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3203, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2941, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3470, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2809, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2063, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2517, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2561, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2704, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3164, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3799, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.4315, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3357, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.4226, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3784, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3586, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3391, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3415, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.4042, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3242, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2918, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3518, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2655, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2966, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2657, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2479, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2266, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2300, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2123, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3323, Accuracy=0.3900.\n",
      "Validation after epoch #23, Validation Loss= 146.3942, Validation Accuracy= 0.380\n",
      "Training accuracy of batch: Loss=146.2672, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3013, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2300, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3367, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3463, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2876, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3120, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2842, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2349, Accuracy=0.4061.\n",
      "Training accuracy of batch: Loss=146.2636, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2637, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2565, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3003, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3577, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3989, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3569, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3740, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3443, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3825, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.3483, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3675, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3200, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3327, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3250, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2979, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2848, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2487, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2337, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.2550, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2603, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2372, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2423, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3482, Accuracy=0.3772.\n",
      "Validation after epoch #24, Validation Loss= 146.2875, Validation Accuracy= 0.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=146.3361, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2655, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3014, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2831, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.2813, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2653, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2501, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2718, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2657, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2228, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2669, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2989, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3112, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3476, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.4040, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3992, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3218, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3661, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3490, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3560, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2964, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3174, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3733, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2630, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3144, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2780, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2788, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2243, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2667, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.1911, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2421, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2540, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3015, Accuracy=0.3949.\n",
      "Validation after epoch #25, Validation Loss= 146.3614, Validation Accuracy= 0.388\n",
      "Training accuracy of batch: Loss=146.2722, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2813, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2566, Accuracy=0.4061.\n",
      "Training accuracy of batch: Loss=146.2858, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3311, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3050, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2773, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2745, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2578, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2170, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2909, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3403, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3495, Accuracy=0.3772.\n",
      "Training accuracy of batch: Loss=146.3283, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.4299, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3147, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3242, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.3171, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3060, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2669, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3242, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3162, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.2729, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=146.2638, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3290, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2536, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2313, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2612, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2137, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2338, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2467, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2245, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2641, Accuracy=0.3965.\n",
      "Validation after epoch #26, Validation Loss= 146.3020, Validation Accuracy= 0.393\n",
      "Training accuracy of batch: Loss=146.2369, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2914, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2222, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2739, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2734, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2143, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2738, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2324, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2872, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2370, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2471, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2307, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3195, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3086, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3689, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3167, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3192, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3561, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2786, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2316, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3580, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3262, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3718, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3147, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3237, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2494, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2231, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2475, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2488, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.1948, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2222, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.1949, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2840, Accuracy=0.3949.\n",
      "Validation after epoch #27, Validation Loss= 146.3177, Validation Accuracy= 0.393\n",
      "Training accuracy of batch: Loss=146.2646, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2532, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3332, Accuracy=0.3836.\n",
      "Training accuracy of batch: Loss=146.2836, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2034, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2177, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2472, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3034, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2320, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2378, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2372, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2265, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2941, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3734, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.3774, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3173, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3475, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3299, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3392, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3053, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.3487, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.2524, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2486, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2779, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3405, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.2443, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2642, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2234, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2964, Accuracy=0.3868.\n",
      "Training accuracy of batch: Loss=146.2285, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.1893, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2714, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2556, Accuracy=0.3997.\n",
      "Validation after epoch #28, Validation Loss= 146.2681, Validation Accuracy= 0.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=146.2427, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2707, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2045, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3179, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3064, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2929, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2658, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3166, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2635, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2218, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2931, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.3067, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2773, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.3498, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.4197, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3167, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3503, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.3665, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3086, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2919, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3637, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3773, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.3039, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2582, Accuracy=0.3884.\n",
      "Training accuracy of batch: Loss=146.2910, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2585, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2336, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2019, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2446, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.1877, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.1789, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2338, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.3392, Accuracy=0.3884.\n",
      "Validation after epoch #29, Validation Loss= 146.2627, Validation Accuracy= 0.401\n",
      "Training accuracy of batch: Loss=146.2506, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2697, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.2390, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2771, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.2694, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2192, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2427, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2422, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2645, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2052, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2218, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2673, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2986, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.3253, Accuracy=0.3933.\n",
      "Training accuracy of batch: Loss=146.3499, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.3629, Accuracy=0.3852.\n",
      "Training accuracy of batch: Loss=146.3383, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2987, Accuracy=0.4013.\n",
      "Training accuracy of batch: Loss=146.3413, Accuracy=0.3900.\n",
      "Training accuracy of batch: Loss=146.2762, Accuracy=0.4029.\n",
      "Training accuracy of batch: Loss=146.2955, Accuracy=0.4141.\n",
      "Training accuracy of batch: Loss=146.3326, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2841, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2691, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2775, Accuracy=0.4045.\n",
      "Training accuracy of batch: Loss=146.2702, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.1993, Accuracy=0.3949.\n",
      "Training accuracy of batch: Loss=146.2110, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2236, Accuracy=0.3965.\n",
      "Training accuracy of batch: Loss=146.2348, Accuracy=0.3997.\n",
      "Training accuracy of batch: Loss=146.2094, Accuracy=0.3917.\n",
      "Training accuracy of batch: Loss=146.2525, Accuracy=0.3981.\n",
      "Training accuracy of batch: Loss=146.2011, Accuracy=0.3965.\n",
      "Validation after epoch #30, Validation Loss= 146.2279, Validation Accuracy= 0.392\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:1'):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        print('Session initialized.')\n",
    "\n",
    "        for epoch_step in range(1, epochs+1):\n",
    "            batch_gen = batch_generator(train_data, train_labels)\n",
    "            for data_minibatch, label_minibatch in batch_gen:\n",
    "                data_reshaped = data_minibatch.reshape((data_minibatch.shape[0], input_size))\n",
    "                labels_encoded = onehot_encode(label_minibatch)\n",
    "                sess.run(train_trigger, feed_dict={X: data_reshaped, Y: labels_encoded, keep_prob: dropout})\n",
    "                train_loss, train_acc = sess.run([loss_function, accuracy], feed_dict={X: validation_data, Y: validation_labels, keep_prob: 1.0})\n",
    "                print(\"Training accuracy of batch: Loss={:.4f}\".format(train_loss) +\", Accuracy={:.4f}.\".format(train_acc))\n",
    "            loss, acc = sess.run([loss_function, accuracy], feed_dict={X: validation_data, Y: validation_labels, keep_prob: 1.0})\n",
    "            print(\"Validation after epoch #\" + str(epoch_step) + \", Validation Loss= \"+ \"{:.4f}\".format(loss) + \", Validation Accuracy= \" + \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "            sess.run(accuracy, feed_dict={X: test_data,\n",
    "                                          Y: test_labels,\n",
    "                                          keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = tf.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
