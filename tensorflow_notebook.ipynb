{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from functools import reduce\n",
    "import operator as op\n",
    "\n",
    "dataset_folder = os.path.abspath(\"./individual_npzs/{0}/*.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "dropout = 0.75\n",
    "max_pool = 2\n",
    "strides = 1\n",
    "input_size = 60000\n",
    "output_size = 4\n",
    "epochs = 30\n",
    "timesteps = 38\n",
    "hidden_layer = 64\n",
    "\n",
    "validation_session = 4\n",
    "test_session = 5\n",
    "\n",
    "label_dictionary = {'neu': 0, 'hap': 1, 'sad': 2, 'ang': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, labels):\n",
    "    steps = math.ceil(data.shape[0] / batch_size)\n",
    "    for batch_step in range(0, steps):\n",
    "        start = batch_size * batch_step\n",
    "        end = batch_size * (batch_step + 1)\n",
    "        yield data[start:end], labels[start:end]\n",
    "        \n",
    "def build_encoded_array(emotion_label):\n",
    "    initialized_array = [0. for key in label_dictionary]\n",
    "    initialized_array[label_dictionary[emotion_label]] = 1.\n",
    "    return initialized_array\n",
    "        \n",
    "def onehot_encode(label_minibatch):\n",
    "    return [build_encoded_array(emotion_label) for emotion_label in label_minibatch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset: 3 sessions for training, 1 for validation, 1 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "validation_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "train_labels = []\n",
    "validation_labels = []\n",
    "test_labels = []\n",
    "\n",
    "session_string = 'session{0}'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    formatted = session_string.format(i)\n",
    "    for spectrogram in glob.glob(dataset_folder.format(formatted)):\n",
    "        loaded_spec = np.load(spectrogram)\n",
    "        for x in loaded_spec['spectrograms']:\n",
    "            if i != validation_session and i != test_session:\n",
    "                train_dataset.append(x) \n",
    "            elif i == validation_session:\n",
    "                validation_dataset.append(x)\n",
    "            elif i == test_session:\n",
    "                test_dataset.append(x)\n",
    "        for x in loaded_spec['labels']:\n",
    "            if i != validation_session and i != test_session:\n",
    "                train_labels.append(x) \n",
    "            elif i == validation_session:\n",
    "                validation_labels.append(x)\n",
    "            elif i == test_session:\n",
    "                test_labels.append(x)\n",
    "        \n",
    "train_dataset = np.asarray(train_dataset)\n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "validation_dataset = np.asarray(validation_dataset)\n",
    "validation_labels = np.asarray(validation_labels)\n",
    "\n",
    "test_dataset = np.asarray(test_dataset)\n",
    "test_labels = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros([len(train_dataset), train_dataset[0].shape[0], train_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(train_dataset)):\n",
    "    train_data[data,:,:] = train_dataset[data]\n",
    "    \n",
    "validation_data = np.zeros([len(validation_dataset), validation_dataset[0].shape[0], validation_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(validation_dataset)):\n",
    "    validation_data[data,:,:] = validation_dataset[data]\n",
    "    \n",
    "test_data = np.zeros([len(test_dataset), test_dataset[0].shape[0], test_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(test_dataset)):\n",
    "    test_data[data,:,:] = test_dataset[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = validation_data.reshape((validation_data.shape[0], input_size))\n",
    "validation_labels = onehot_encode(validation_labels)\n",
    "\n",
    "test_data = test_data.reshape((test_data.shape[0], input_size))\n",
    "test_labels = onehot_encode(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(to_process, weights, biases, strides=1):\n",
    "    conv_out = tf.nn.conv2d(to_process, weights, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    bias_out = tf.nn.bias_add(conv_out, biases)\n",
    "    relu_out = tf.nn.relu(bias_out)\n",
    "    return relu_out\n",
    "\n",
    "def maxpool2d(to_pool, pool_size=2):\n",
    "    maxpool_out = tf.nn.max_pool(to_pool, ksize=[1, pool_size, pool_size, 1], strides=[1, pool_size, pool_size, 1], padding='SAME')\n",
    "    return maxpool_out\n",
    "\n",
    "def nn_pipeline(spectrogram, weights, biases):\n",
    "    \n",
    "    reshaped_input = tf.reshape(spectrogram, shape=[-1, 200, 300, 1])\n",
    "    \n",
    "    first_layer_out = conv2d(reshaped_input, weights['first_layer_weights'], biases['first_layer_biases'])\n",
    "    first_maxpool_out = maxpool2d(first_layer_out, pool_size=2)\n",
    "    \n",
    "    second_layer_out = conv2d(first_maxpool_out, weights['second_layer_weights'], biases['second_layer_biases'])\n",
    "    second_maxpool_out = maxpool2d(second_layer_out, pool_size=2)\n",
    "    \n",
    "    third_layer_out = conv2d(second_maxpool_out, weights['third_layer_weights'], biases['third_layer_biases'])\n",
    "    third_maxpool_out = maxpool2d(third_layer_out, pool_size=2)\n",
    "    \n",
    "    reshape_for_fc = tf.reshape(third_maxpool_out, [-1, weights['fully_connected_weights'].get_shape().as_list()[0]])\n",
    "    fully_connected_out = tf.add(tf.matmul(reshape_for_fc, weights['fully_connected_weights']), biases['fully_connected_biases'])\n",
    "    fully_connected_activation = tf.nn.relu(fully_connected_out)\n",
    "    fully_connected_dropout = tf.nn.dropout(fully_connected_activation, dropout)\n",
    "    \n",
    "    fully_connected_out_2 = tf.add(tf.matmul(fully_connected_dropout, weights['fully_connected_weights_2']), biases['fully_connected_biases_2'])\n",
    "    fully_connected_activation_2 = tf.nn.relu(fully_connected_out_2)\n",
    "    fully_connected_dropout_2 = tf.nn.dropout(fully_connected_activation_2, dropout)\n",
    "    \n",
    "    prediction = tf.add(tf.matmul(fully_connected_dropout_2, weights['output']), biases['output'])\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_pipeline_rnn(spectrogram, weights, biases):\n",
    "    reshaped_input = tf.reshape(spectrogram, shape=[-1, 200, 300, 1])\n",
    "\n",
    "    first_layer_out = conv2d(reshaped_input, weights['first_layer_weights'], biases['first_layer_biases'])\n",
    "    first_maxpool_out = maxpool2d(first_layer_out, pool_size=2)\n",
    "\n",
    "    second_layer_out = conv2d(first_maxpool_out, weights['second_layer_weights'], biases['second_layer_biases'])\n",
    "    second_maxpool_out = maxpool2d(second_layer_out, pool_size=2)\n",
    "\n",
    "    third_layer_out = conv2d(second_maxpool_out, weights['third_layer_weights'], biases['third_layer_biases'])\n",
    "    third_maxpool_out = maxpool2d(third_layer_out, pool_size=2)\n",
    "\n",
    "    interim_shape = third_maxpool_out.get_shape().as_list()\n",
    "    transposed = tf.transpose(third_maxpool_out, perm=[0, 2, 1, 3])\n",
    "    reshape_for_rnn = tf.reshape(transposed, [-1, interim_shape[2], interim_shape[1]*interim_shape[3]])\n",
    "    reshape_for_rnn.set_shape([None, interim_shape[2], interim_shape[1]*interim_shape[3]])\n",
    "\n",
    "    hidden_list = [hidden_layer, hidden_layer]\n",
    "\n",
    "    gru_fw_cell = [tf.contrib.rnn.GRUCell(hidden) for hidden in hidden_list]\n",
    "    gru_bw_cell = [tf.contrib.rnn.GRUCell(hidden) for hidden in hidden_list]\n",
    "\n",
    "    gru_output, _, _, = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(gru_fw_cell, gru_bw_cell, reshape_for_rnn, dtype=tf.float32)\n",
    "    interim_shape_gru = tf.shape(gru_output)\n",
    "    gru_flatten = tf.reshape(gru_output, [-1, interim_shape_gru[1]*interim_shape_gru[2]])\n",
    "    \n",
    "    fully_connected_out = tf.add(tf.matmul(gru_flatten, weights['gru_weights']), biases['gru_biases'])\n",
    "    fully_connected_activation = tf.nn.relu(fully_connected_out)\n",
    "    fully_connected_dropout = tf.nn.dropout(fully_connected_activation, dropout)\n",
    "    \n",
    "    prediction = tf.add(tf.matmul(fully_connected_dropout, weights['output']), biases['output'])\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'first_layer_weights': tf.Variable(tf.random_normal([10, 15, 1, 16])),\n",
    "    'second_layer_weights': tf.Variable(tf.random_normal([8, 10, 16, 24])),\n",
    "    'third_layer_weights': tf.Variable(tf.random_normal([5, 8, 24, 32])),\n",
    "    'fully_connected_weights': tf.Variable(tf.random_normal([25*38*32, 2048])),\n",
    "    'fully_connected_weights_2': tf.Variable(tf.random_normal([2048, 2048])),\n",
    "    'output': tf.Variable(tf.random_normal([2048, output_size]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'first_layer_biases': tf.Variable(tf.random_normal([16])),\n",
    "    'second_layer_biases': tf.Variable(tf.random_normal([24])),\n",
    "    'third_layer_biases': tf.Variable(tf.random_normal([32])),\n",
    "    'fully_connected_biases': tf.Variable(tf.random_normal([2048])),\n",
    "    'fully_connected_biases_2': tf.Variable(tf.random_normal([2048])),\n",
    "    'output': tf.Variable(tf.random_normal([output_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_rnn = {\n",
    "    'first_layer_weights': tf.Variable(tf.random_normal([10, 15, 1, 16])),\n",
    "    'second_layer_weights': tf.Variable(tf.random_normal([8, 10, 16, 24])),\n",
    "    'third_layer_weights': tf.Variable(tf.random_normal([5, 8, 24, 32])),\n",
    "    'gru_weights': tf.Variable(tf.random_normal([2*hidden_layer*timesteps, hidden_layer])),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_layer, output_size]))\n",
    "}\n",
    "\n",
    "biases_rnn = {\n",
    "    'first_layer_biases': tf.Variable(tf.random_normal([16])),\n",
    "    'second_layer_biases': tf.Variable(tf.random_normal([24])),\n",
    "    'third_layer_biases': tf.Variable(tf.random_normal([32])),\n",
    "    'gru_biases': tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'output': tf.Variable(tf.random_normal([output_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "Y = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = nn_pipeline_rnn(X, weights_rnn, biases_rnn)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdaGradOptimizer  (learning_rate=learning_rate)\n",
    "train_trigger = optimizer.minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session initialized.\n",
      "Training accuracy of batch: Loss=332.3513, Accuracy=0.2215.\n",
      "Training accuracy of batch: Loss=248.9896, Accuracy=0.3403.\n",
      "Training accuracy of batch: Loss=220.2322, Accuracy=0.3018.\n",
      "Training accuracy of batch: Loss=224.0689, Accuracy=0.3451.\n",
      "Training accuracy of batch: Loss=181.1047, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=192.1497, Accuracy=0.3034.\n",
      "Training accuracy of batch: Loss=189.5631, Accuracy=0.3467.\n",
      "Training accuracy of batch: Loss=152.6131, Accuracy=0.3547.\n",
      "Training accuracy of batch: Loss=166.7588, Accuracy=0.3419.\n",
      "Training accuracy of batch: Loss=143.9497, Accuracy=0.2729.\n",
      "Training accuracy of batch: Loss=135.6255, Accuracy=0.2713.\n",
      "Training accuracy of batch: Loss=140.8757, Accuracy=0.3018.\n",
      "Training accuracy of batch: Loss=116.5505, Accuracy=0.2889.\n",
      "Training accuracy of batch: Loss=109.7144, Accuracy=0.2953.\n",
      "Training accuracy of batch: Loss=98.1888, Accuracy=0.2809.\n",
      "Training accuracy of batch: Loss=91.5290, Accuracy=0.2905.\n",
      "Training accuracy of batch: Loss=118.9431, Accuracy=0.3242.\n",
      "Validation after epoch #1, Validation Loss= 114.6389, Validation Accuracy= 0.303\n",
      "Training accuracy of batch: Loss=98.1925, Accuracy=0.2889.\n",
      "Training accuracy of batch: Loss=81.5592, Accuracy=0.3098.\n",
      "Training accuracy of batch: Loss=79.0909, Accuracy=0.2937.\n",
      "Training accuracy of batch: Loss=78.0646, Accuracy=0.3066.\n",
      "Training accuracy of batch: Loss=75.8351, Accuracy=0.3018.\n",
      "Training accuracy of batch: Loss=76.5311, Accuracy=0.2697.\n",
      "Training accuracy of batch: Loss=75.7372, Accuracy=0.3291.\n",
      "Training accuracy of batch: Loss=73.0456, Accuracy=0.3002.\n",
      "Training accuracy of batch: Loss=61.6048, Accuracy=0.2937.\n",
      "Training accuracy of batch: Loss=57.7496, Accuracy=0.3114.\n",
      "Training accuracy of batch: Loss=58.8261, Accuracy=0.2986.\n",
      "Training accuracy of batch: Loss=61.7797, Accuracy=0.2793.\n",
      "Training accuracy of batch: Loss=48.8741, Accuracy=0.2857.\n",
      "Training accuracy of batch: Loss=43.4645, Accuracy=0.2970.\n",
      "Training accuracy of batch: Loss=50.3733, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=41.1590, Accuracy=0.3531.\n",
      "Training accuracy of batch: Loss=60.4250, Accuracy=0.2825.\n",
      "Validation after epoch #2, Validation Loss= 53.7437, Validation Accuracy= 0.355\n",
      "Training accuracy of batch: Loss=41.5536, Accuracy=0.2857.\n",
      "Training accuracy of batch: Loss=42.4155, Accuracy=0.3242.\n",
      "Training accuracy of batch: Loss=41.7608, Accuracy=0.2905.\n",
      "Training accuracy of batch: Loss=49.1788, Accuracy=0.3258.\n",
      "Training accuracy of batch: Loss=43.4197, Accuracy=0.2600.\n",
      "Training accuracy of batch: Loss=40.3305, Accuracy=0.2825.\n",
      "Training accuracy of batch: Loss=46.7217, Accuracy=0.3082.\n",
      "Training accuracy of batch: Loss=34.4397, Accuracy=0.3098.\n",
      "Training accuracy of batch: Loss=38.3554, Accuracy=0.2953.\n",
      "Training accuracy of batch: Loss=30.6482, Accuracy=0.2777.\n",
      "Training accuracy of batch: Loss=32.4640, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=30.5108, Accuracy=0.3146.\n",
      "Training accuracy of batch: Loss=27.2545, Accuracy=0.2729.\n",
      "Training accuracy of batch: Loss=26.1021, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=22.2307, Accuracy=0.2568.\n",
      "Training accuracy of batch: Loss=23.6774, Accuracy=0.3066.\n",
      "Training accuracy of batch: Loss=32.0918, Accuracy=0.3162.\n",
      "Validation after epoch #3, Validation Loss= 36.1590, Validation Accuracy= 0.303\n",
      "Training accuracy of batch: Loss=27.5210, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=22.9855, Accuracy=0.2921.\n",
      "Training accuracy of batch: Loss=24.9055, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=20.9649, Accuracy=0.2777.\n",
      "Training accuracy of batch: Loss=26.1626, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=34.8671, Accuracy=0.2825.\n",
      "Training accuracy of batch: Loss=31.4376, Accuracy=0.3355.\n",
      "Training accuracy of batch: Loss=19.4068, Accuracy=0.3098.\n",
      "Training accuracy of batch: Loss=17.2984, Accuracy=0.2953.\n",
      "Training accuracy of batch: Loss=19.5103, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=18.4970, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=16.3003, Accuracy=0.2697.\n",
      "Training accuracy of batch: Loss=16.9196, Accuracy=0.2632.\n",
      "Training accuracy of batch: Loss=20.1019, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=13.3847, Accuracy=0.2568.\n",
      "Training accuracy of batch: Loss=13.4185, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=42.5487, Accuracy=0.3130.\n",
      "Validation after epoch #4, Validation Loss= 40.5101, Validation Accuracy= 0.335\n",
      "Training accuracy of batch: Loss=16.1045, Accuracy=0.2103.\n",
      "Training accuracy of batch: Loss=14.6903, Accuracy=0.2616.\n",
      "Training accuracy of batch: Loss=12.1147, Accuracy=0.2632.\n",
      "Training accuracy of batch: Loss=14.6382, Accuracy=0.2937.\n",
      "Training accuracy of batch: Loss=11.0263, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=10.4384, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=11.0549, Accuracy=0.2729.\n",
      "Training accuracy of batch: Loss=10.3012, Accuracy=0.2520.\n",
      "Training accuracy of batch: Loss=12.6681, Accuracy=0.2616.\n",
      "Training accuracy of batch: Loss=10.7303, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=10.8592, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=9.8120, Accuracy=0.2648.\n",
      "Training accuracy of batch: Loss=10.9344, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=10.4384, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=8.1273, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=9.3045, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=26.0934, Accuracy=0.2889.\n",
      "Validation after epoch #5, Validation Loss= 25.1244, Validation Accuracy= 0.289\n",
      "Training accuracy of batch: Loss=14.9840, Accuracy=0.2713.\n",
      "Training accuracy of batch: Loss=10.8514, Accuracy=0.3002.\n",
      "Training accuracy of batch: Loss=10.4013, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=9.8364, Accuracy=0.2568.\n",
      "Training accuracy of batch: Loss=8.3034, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=9.2782, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=9.3727, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=7.3990, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=5.7236, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=5.7657, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=5.4828, Accuracy=0.1461.\n",
      "Training accuracy of batch: Loss=5.7989, Accuracy=0.1541.\n",
      "Training accuracy of batch: Loss=4.9632, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=5.1153, Accuracy=0.2215.\n",
      "Training accuracy of batch: Loss=5.9036, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=5.5487, Accuracy=0.1653.\n",
      "Training accuracy of batch: Loss=7.6784, Accuracy=0.2360.\n",
      "Validation after epoch #6, Validation Loss= 7.6019, Validation Accuracy= 0.215\n",
      "Training accuracy of batch: Loss=5.8069, Accuracy=0.2006.\n",
      "Training accuracy of batch: Loss=6.1079, Accuracy=0.1846.\n",
      "Training accuracy of batch: Loss=6.3530, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=6.5268, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=5.4428, Accuracy=0.1846.\n",
      "Training accuracy of batch: Loss=5.2523, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=6.0022, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=4.2799, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=3.8662, Accuracy=0.2103.\n",
      "Training accuracy of batch: Loss=4.8594, Accuracy=0.1429.\n",
      "Training accuracy of batch: Loss=3.9613, Accuracy=0.1509.\n",
      "Training accuracy of batch: Loss=4.2823, Accuracy=0.1589.\n",
      "Training accuracy of batch: Loss=4.9185, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=4.3154, Accuracy=0.1766.\n",
      "Training accuracy of batch: Loss=3.9027, Accuracy=0.1862.\n",
      "Training accuracy of batch: Loss=4.9092, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=8.4807, Accuracy=0.2424.\n",
      "Validation after epoch #7, Validation Loss= 7.3937, Validation Accuracy= 0.254\n",
      "Training accuracy of batch: Loss=4.4127, Accuracy=0.1798.\n",
      "Training accuracy of batch: Loss=3.6432, Accuracy=0.1750.\n",
      "Training accuracy of batch: Loss=3.9218, Accuracy=0.1445.\n",
      "Training accuracy of batch: Loss=3.7801, Accuracy=0.1862.\n",
      "Training accuracy of batch: Loss=4.4959, Accuracy=0.1541.\n",
      "Training accuracy of batch: Loss=4.6657, Accuracy=0.2215.\n",
      "Training accuracy of batch: Loss=7.8672, Accuracy=0.2825.\n",
      "Training accuracy of batch: Loss=4.7779, Accuracy=0.1637.\n",
      "Training accuracy of batch: Loss=3.9903, Accuracy=0.2729.\n",
      "Training accuracy of batch: Loss=4.2969, Accuracy=0.1461.\n",
      "Training accuracy of batch: Loss=3.8827, Accuracy=0.1766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=4.4726, Accuracy=0.1621.\n",
      "Training accuracy of batch: Loss=3.8780, Accuracy=0.1750.\n",
      "Training accuracy of batch: Loss=3.5909, Accuracy=0.1589.\n",
      "Training accuracy of batch: Loss=3.2941, Accuracy=0.1750.\n",
      "Training accuracy of batch: Loss=3.5691, Accuracy=0.1750.\n",
      "Training accuracy of batch: Loss=4.4866, Accuracy=0.2536.\n",
      "Validation after epoch #8, Validation Loss= 4.6958, Validation Accuracy= 0.257\n",
      "Training accuracy of batch: Loss=5.0069, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=4.1091, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=3.9979, Accuracy=0.1717.\n",
      "Training accuracy of batch: Loss=3.4052, Accuracy=0.2343.\n",
      "Training accuracy of batch: Loss=3.2786, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=3.3082, Accuracy=0.1653.\n",
      "Training accuracy of batch: Loss=3.2689, Accuracy=0.1605.\n",
      "Training accuracy of batch: Loss=3.3150, Accuracy=0.1814.\n",
      "Training accuracy of batch: Loss=3.4136, Accuracy=0.1830.\n",
      "Training accuracy of batch: Loss=2.8816, Accuracy=0.1429.\n",
      "Training accuracy of batch: Loss=2.9928, Accuracy=0.1477.\n",
      "Training accuracy of batch: Loss=3.0149, Accuracy=0.1573.\n",
      "Training accuracy of batch: Loss=4.3093, Accuracy=0.1750.\n",
      "Training accuracy of batch: Loss=3.8145, Accuracy=0.1621.\n",
      "Training accuracy of batch: Loss=4.4582, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=3.8741, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=3.6161, Accuracy=0.2199.\n",
      "Validation after epoch #9, Validation Loss= 4.1586, Validation Accuracy= 0.197\n",
      "Training accuracy of batch: Loss=4.0143, Accuracy=0.1685.\n",
      "Training accuracy of batch: Loss=3.5464, Accuracy=0.1910.\n",
      "Training accuracy of batch: Loss=3.3065, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=3.1768, Accuracy=0.2039.\n",
      "Training accuracy of batch: Loss=2.8495, Accuracy=0.1685.\n",
      "Training accuracy of batch: Loss=2.8877, Accuracy=0.1798.\n",
      "Training accuracy of batch: Loss=3.2794, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=4.1233, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=3.9907, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=3.6282, Accuracy=0.1236.\n",
      "Training accuracy of batch: Loss=3.3086, Accuracy=0.1477.\n",
      "Training accuracy of batch: Loss=3.1201, Accuracy=0.1782.\n",
      "Training accuracy of batch: Loss=2.7529, Accuracy=0.1685.\n",
      "Training accuracy of batch: Loss=2.9924, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=2.8064, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=3.0830, Accuracy=0.2119.\n",
      "Training accuracy of batch: Loss=7.3323, Accuracy=0.2777.\n",
      "Validation after epoch #10, Validation Loss= 8.3564, Validation Accuracy= 0.260\n",
      "Training accuracy of batch: Loss=3.3457, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=3.2145, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.8313, Accuracy=0.1814.\n",
      "Training accuracy of batch: Loss=3.8701, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=3.5320, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=2.7605, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=2.6917, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=2.4029, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=2.6477, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=2.5726, Accuracy=0.1814.\n",
      "Training accuracy of batch: Loss=2.6143, Accuracy=0.1589.\n",
      "Training accuracy of batch: Loss=2.5128, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=2.6702, Accuracy=0.1669.\n",
      "Training accuracy of batch: Loss=2.4763, Accuracy=0.1220.\n",
      "Training accuracy of batch: Loss=2.3922, Accuracy=0.1717.\n",
      "Training accuracy of batch: Loss=2.4672, Accuracy=0.1910.\n",
      "Training accuracy of batch: Loss=4.5101, Accuracy=0.2665.\n",
      "Validation after epoch #11, Validation Loss= 3.6106, Validation Accuracy= 0.252\n",
      "Training accuracy of batch: Loss=2.5667, Accuracy=0.1910.\n",
      "Training accuracy of batch: Loss=2.4456, Accuracy=0.1798.\n",
      "Training accuracy of batch: Loss=2.3317, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=2.7513, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=2.5199, Accuracy=0.1701.\n",
      "Training accuracy of batch: Loss=2.5951, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=2.5741, Accuracy=0.2648.\n",
      "Training accuracy of batch: Loss=2.7740, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=2.6043, Accuracy=0.2055.\n",
      "Training accuracy of batch: Loss=3.1151, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=3.5250, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=3.0614, Accuracy=0.1894.\n",
      "Training accuracy of batch: Loss=2.4758, Accuracy=0.2215.\n",
      "Training accuracy of batch: Loss=2.6057, Accuracy=0.1621.\n",
      "Training accuracy of batch: Loss=2.8309, Accuracy=0.1669.\n",
      "Training accuracy of batch: Loss=2.7856, Accuracy=0.2327.\n",
      "Training accuracy of batch: Loss=3.1815, Accuracy=0.2327.\n",
      "Validation after epoch #12, Validation Loss= 3.3768, Validation Accuracy= 0.218\n",
      "Training accuracy of batch: Loss=3.7932, Accuracy=0.1910.\n",
      "Training accuracy of batch: Loss=4.3927, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=2.7924, Accuracy=0.1717.\n",
      "Training accuracy of batch: Loss=2.5439, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.3444, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=2.3605, Accuracy=0.2039.\n",
      "Training accuracy of batch: Loss=2.3939, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=2.9822, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.4388, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.1506, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=2.4395, Accuracy=0.2135.\n",
      "Training accuracy of batch: Loss=2.2513, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=2.6766, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=2.7706, Accuracy=0.1766.\n",
      "Training accuracy of batch: Loss=2.5717, Accuracy=0.1814.\n",
      "Training accuracy of batch: Loss=2.3529, Accuracy=0.2103.\n",
      "Training accuracy of batch: Loss=2.6099, Accuracy=0.2055.\n",
      "Validation after epoch #13, Validation Loss= 2.4528, Validation Accuracy= 0.215\n",
      "Training accuracy of batch: Loss=2.8723, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.9911, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=2.4927, Accuracy=0.2006.\n",
      "Training accuracy of batch: Loss=2.5566, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.4778, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=2.2997, Accuracy=0.1814.\n",
      "Training accuracy of batch: Loss=2.9732, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=2.3136, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=2.5632, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.2992, Accuracy=0.1701.\n",
      "Training accuracy of batch: Loss=2.5385, Accuracy=0.1589.\n",
      "Training accuracy of batch: Loss=2.1554, Accuracy=0.1766.\n",
      "Training accuracy of batch: Loss=2.2359, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=2.3262, Accuracy=0.1557.\n",
      "Training accuracy of batch: Loss=2.3416, Accuracy=0.1766.\n",
      "Training accuracy of batch: Loss=2.3365, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=3.1691, Accuracy=0.2616.\n",
      "Validation after epoch #14, Validation Loss= 2.7651, Validation Accuracy= 0.242\n",
      "Training accuracy of batch: Loss=2.4992, Accuracy=0.2600.\n",
      "Training accuracy of batch: Loss=2.3218, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=2.2699, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=2.2388, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=2.5017, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=2.5639, Accuracy=0.1846.\n",
      "Training accuracy of batch: Loss=2.7317, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=2.6901, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=2.3104, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=2.1327, Accuracy=0.1685.\n",
      "Training accuracy of batch: Loss=2.4068, Accuracy=0.1782.\n",
      "Training accuracy of batch: Loss=2.1223, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=2.1707, Accuracy=0.1862.\n",
      "Training accuracy of batch: Loss=2.3862, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=2.2712, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=2.3317, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=2.7194, Accuracy=0.2488.\n",
      "Validation after epoch #15, Validation Loss= 2.7952, Validation Accuracy= 0.271\n",
      "Training accuracy of batch: Loss=2.2864, Accuracy=0.2456.\n",
      "Training accuracy of batch: Loss=2.2549, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=2.1305, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=2.3050, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=2.0072, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=2.5444, Accuracy=0.2183.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=2.0740, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=2.0730, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=2.1598, Accuracy=0.1958.\n",
      "Training accuracy of batch: Loss=2.2467, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=2.2887, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=2.2336, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=2.0845, Accuracy=0.2006.\n",
      "Training accuracy of batch: Loss=2.4145, Accuracy=0.1461.\n",
      "Training accuracy of batch: Loss=2.0508, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=2.0728, Accuracy=0.1958.\n",
      "Training accuracy of batch: Loss=2.2714, Accuracy=0.2472.\n",
      "Validation after epoch #16, Validation Loss= 2.4877, Validation Accuracy= 0.225\n",
      "Training accuracy of batch: Loss=2.2212, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=2.5658, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=2.4670, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=2.2218, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=2.1670, Accuracy=0.2039.\n",
      "Training accuracy of batch: Loss=2.0483, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=2.3582, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=2.4377, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.4841, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=2.4094, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=2.2039, Accuracy=0.2039.\n",
      "Training accuracy of batch: Loss=2.3244, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=2.2051, Accuracy=0.1701.\n",
      "Training accuracy of batch: Loss=1.9632, Accuracy=0.1846.\n",
      "Training accuracy of batch: Loss=1.9301, Accuracy=0.2215.\n",
      "Training accuracy of batch: Loss=1.9512, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=2.3838, Accuracy=0.2295.\n",
      "Validation after epoch #17, Validation Loss= 2.0699, Validation Accuracy= 0.226\n",
      "Training accuracy of batch: Loss=2.2585, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=2.9098, Accuracy=0.2681.\n",
      "Training accuracy of batch: Loss=2.1531, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=2.0959, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=2.0538, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=1.9670, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=1.8925, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=2.0507, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=2.2137, Accuracy=0.2456.\n",
      "Training accuracy of batch: Loss=2.3506, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=2.3270, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=2.1187, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=2.3551, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=2.1576, Accuracy=0.2087.\n",
      "Training accuracy of batch: Loss=2.1343, Accuracy=0.1894.\n",
      "Training accuracy of batch: Loss=2.3255, Accuracy=0.2135.\n",
      "Training accuracy of batch: Loss=2.3664, Accuracy=0.2488.\n",
      "Validation after epoch #18, Validation Loss= 2.3182, Validation Accuracy= 0.257\n",
      "Training accuracy of batch: Loss=1.9023, Accuracy=0.2600.\n",
      "Training accuracy of batch: Loss=2.2713, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=2.0168, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=2.0028, Accuracy=0.2360.\n",
      "Training accuracy of batch: Loss=2.0132, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=2.1199, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=2.0525, Accuracy=0.2343.\n",
      "Training accuracy of batch: Loss=2.1889, Accuracy=0.2520.\n",
      "Training accuracy of batch: Loss=2.2686, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.2605, Accuracy=0.2135.\n",
      "Training accuracy of batch: Loss=2.2859, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=1.8927, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=2.0457, Accuracy=0.2135.\n",
      "Training accuracy of batch: Loss=1.9343, Accuracy=0.1750.\n",
      "Training accuracy of batch: Loss=2.2111, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=2.1334, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=2.2593, Accuracy=0.2632.\n",
      "Validation after epoch #19, Validation Loss= 2.0479, Validation Accuracy= 0.239\n",
      "Training accuracy of batch: Loss=2.0799, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=2.4000, Accuracy=0.2215.\n",
      "Training accuracy of batch: Loss=1.7762, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=1.9602, Accuracy=0.2632.\n",
      "Training accuracy of batch: Loss=2.0155, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=1.9232, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.0183, Accuracy=0.2327.\n",
      "Training accuracy of batch: Loss=1.9208, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=2.1864, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=1.8684, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=1.8804, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=2.1954, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=1.8933, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=1.8759, Accuracy=0.1846.\n",
      "Training accuracy of batch: Loss=2.1043, Accuracy=0.1958.\n",
      "Training accuracy of batch: Loss=2.0140, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=3.9453, Accuracy=0.2520.\n",
      "Validation after epoch #20, Validation Loss= 4.5015, Validation Accuracy= 0.281\n",
      "Training accuracy of batch: Loss=2.3063, Accuracy=0.2616.\n",
      "Training accuracy of batch: Loss=2.1662, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=2.2012, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=1.9959, Accuracy=0.2552.\n",
      "Training accuracy of batch: Loss=1.9270, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=1.9733, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=1.9652, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=2.1131, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=1.9121, Accuracy=0.2488.\n",
      "Training accuracy of batch: Loss=2.0627, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=1.8768, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=1.8482, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=2.0698, Accuracy=0.1798.\n",
      "Training accuracy of batch: Loss=1.9149, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=2.0208, Accuracy=0.1862.\n",
      "Training accuracy of batch: Loss=1.9329, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.1166, Accuracy=0.2376.\n",
      "Validation after epoch #21, Validation Loss= 1.9424, Validation Accuracy= 0.249\n",
      "Training accuracy of batch: Loss=1.9991, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=1.8069, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=1.8524, Accuracy=0.2648.\n",
      "Training accuracy of batch: Loss=1.9692, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=1.8743, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=2.0228, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=2.0333, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=2.0796, Accuracy=0.2552.\n",
      "Training accuracy of batch: Loss=2.1906, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=1.8482, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=1.9686, Accuracy=0.2103.\n",
      "Training accuracy of batch: Loss=1.8552, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=2.0691, Accuracy=0.1894.\n",
      "Training accuracy of batch: Loss=1.8005, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=2.2031, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=1.9569, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=1.9752, Accuracy=0.2520.\n",
      "Validation after epoch #22, Validation Loss= 1.9843, Validation Accuracy= 0.226\n",
      "Training accuracy of batch: Loss=1.8476, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=1.8824, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.9336, Accuracy=0.1958.\n",
      "Training accuracy of batch: Loss=2.2559, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.0043, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=1.8705, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.9376, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=1.9995, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=1.8970, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=2.2006, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=1.9168, Accuracy=0.2055.\n",
      "Training accuracy of batch: Loss=1.8864, Accuracy=0.1814.\n",
      "Training accuracy of batch: Loss=1.8876, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=2.0217, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=2.0054, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=2.0744, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.1447, Accuracy=0.2648.\n",
      "Validation after epoch #23, Validation Loss= 1.7954, Validation Accuracy= 0.266\n",
      "Training accuracy of batch: Loss=1.9791, Accuracy=0.2343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of batch: Loss=1.8725, Accuracy=0.2616.\n",
      "Training accuracy of batch: Loss=2.1298, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=2.1334, Accuracy=0.2343.\n",
      "Training accuracy of batch: Loss=1.8636, Accuracy=0.1974.\n",
      "Training accuracy of batch: Loss=1.9983, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=2.0375, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=2.3641, Accuracy=0.2456.\n",
      "Training accuracy of batch: Loss=1.8891, Accuracy=0.2167.\n",
      "Training accuracy of batch: Loss=1.8024, Accuracy=0.2327.\n",
      "Training accuracy of batch: Loss=1.9197, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.9342, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=1.9088, Accuracy=0.1717.\n",
      "Training accuracy of batch: Loss=1.8869, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.9088, Accuracy=0.2119.\n",
      "Training accuracy of batch: Loss=1.8180, Accuracy=0.2006.\n",
      "Training accuracy of batch: Loss=2.1248, Accuracy=0.2279.\n",
      "Validation after epoch #24, Validation Loss= 1.9016, Validation Accuracy= 0.247\n",
      "Training accuracy of batch: Loss=2.0783, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=2.2122, Accuracy=0.2119.\n",
      "Training accuracy of batch: Loss=2.1544, Accuracy=0.2360.\n",
      "Training accuracy of batch: Loss=2.0181, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=1.9326, Accuracy=0.1942.\n",
      "Training accuracy of batch: Loss=2.1181, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=2.0371, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.8689, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.8733, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=1.9545, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=2.3307, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=2.0479, Accuracy=0.2006.\n",
      "Training accuracy of batch: Loss=1.8644, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=2.0079, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.1694, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=2.1094, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=2.0507, Accuracy=0.2504.\n",
      "Validation after epoch #25, Validation Loss= 1.9411, Validation Accuracy= 0.241\n",
      "Training accuracy of batch: Loss=1.9257, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=2.0455, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=2.3740, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=2.4178, Accuracy=0.2568.\n",
      "Training accuracy of batch: Loss=1.9056, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=2.1379, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=1.9383, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=1.8071, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=1.8837, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=1.9712, Accuracy=0.2135.\n",
      "Training accuracy of batch: Loss=1.9336, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=1.8737, Accuracy=0.1653.\n",
      "Training accuracy of batch: Loss=1.8106, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=1.8629, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=1.7401, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=1.8976, Accuracy=0.2231.\n",
      "Training accuracy of batch: Loss=1.8214, Accuracy=0.2681.\n",
      "Validation after epoch #26, Validation Loss= 1.8760, Validation Accuracy= 0.249\n",
      "Training accuracy of batch: Loss=1.9877, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=1.9086, Accuracy=0.2600.\n",
      "Training accuracy of batch: Loss=1.7625, Accuracy=0.2360.\n",
      "Training accuracy of batch: Loss=1.9914, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=1.8637, Accuracy=0.2199.\n",
      "Training accuracy of batch: Loss=1.8576, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=1.9886, Accuracy=0.2632.\n",
      "Training accuracy of batch: Loss=1.9087, Accuracy=0.2456.\n",
      "Training accuracy of batch: Loss=1.8556, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=1.8319, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=2.1049, Accuracy=0.2392.\n",
      "Training accuracy of batch: Loss=1.8252, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=1.9001, Accuracy=0.1894.\n",
      "Training accuracy of batch: Loss=1.9138, Accuracy=0.2103.\n",
      "Training accuracy of batch: Loss=1.8342, Accuracy=0.1862.\n",
      "Training accuracy of batch: Loss=1.8774, Accuracy=0.2360.\n",
      "Training accuracy of batch: Loss=1.9697, Accuracy=0.2263.\n",
      "Validation after epoch #27, Validation Loss= 2.0930, Validation Accuracy= 0.226\n",
      "Training accuracy of batch: Loss=2.0099, Accuracy=0.2327.\n",
      "Training accuracy of batch: Loss=1.9916, Accuracy=0.2360.\n",
      "Training accuracy of batch: Loss=2.1264, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=2.5636, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=1.7445, Accuracy=0.2247.\n",
      "Training accuracy of batch: Loss=1.7947, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=2.0017, Accuracy=0.2343.\n",
      "Training accuracy of batch: Loss=1.8796, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=1.8375, Accuracy=0.2424.\n",
      "Training accuracy of batch: Loss=1.7518, Accuracy=0.2311.\n",
      "Training accuracy of batch: Loss=1.9887, Accuracy=0.1894.\n",
      "Training accuracy of batch: Loss=1.7778, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=1.7835, Accuracy=0.2135.\n",
      "Training accuracy of batch: Loss=1.8822, Accuracy=0.1958.\n",
      "Training accuracy of batch: Loss=1.8883, Accuracy=0.2071.\n",
      "Training accuracy of batch: Loss=1.7119, Accuracy=0.2408.\n",
      "Training accuracy of batch: Loss=1.9612, Accuracy=0.2071.\n",
      "Validation after epoch #28, Validation Loss= 1.9154, Validation Accuracy= 0.246\n",
      "Training accuracy of batch: Loss=1.7642, Accuracy=0.2520.\n",
      "Training accuracy of batch: Loss=1.7165, Accuracy=0.2761.\n",
      "Training accuracy of batch: Loss=2.1472, Accuracy=0.2376.\n",
      "Training accuracy of batch: Loss=1.8249, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=1.8433, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=1.8551, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=1.9202, Accuracy=0.2504.\n",
      "Training accuracy of batch: Loss=1.8784, Accuracy=0.2327.\n",
      "Training accuracy of batch: Loss=1.8564, Accuracy=0.2520.\n",
      "Training accuracy of batch: Loss=2.1200, Accuracy=0.1926.\n",
      "Training accuracy of batch: Loss=1.9901, Accuracy=0.2022.\n",
      "Training accuracy of batch: Loss=1.8346, Accuracy=0.1990.\n",
      "Training accuracy of batch: Loss=1.8760, Accuracy=0.2119.\n",
      "Training accuracy of batch: Loss=1.6847, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=1.7303, Accuracy=0.2151.\n",
      "Training accuracy of batch: Loss=1.8214, Accuracy=0.2343.\n",
      "Training accuracy of batch: Loss=1.7470, Accuracy=0.2681.\n",
      "Validation after epoch #29, Validation Loss= 1.8350, Validation Accuracy= 0.249\n",
      "Training accuracy of batch: Loss=1.8748, Accuracy=0.2472.\n",
      "Training accuracy of batch: Loss=1.8745, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=1.7383, Accuracy=0.2183.\n",
      "Training accuracy of batch: Loss=1.8188, Accuracy=0.2552.\n",
      "Training accuracy of batch: Loss=2.0035, Accuracy=0.2279.\n",
      "Training accuracy of batch: Loss=2.4293, Accuracy=0.2440.\n",
      "Training accuracy of batch: Loss=1.8413, Accuracy=0.2584.\n",
      "Training accuracy of batch: Loss=1.9346, Accuracy=0.2103.\n",
      "Training accuracy of batch: Loss=2.1681, Accuracy=0.2520.\n",
      "Training accuracy of batch: Loss=1.9088, Accuracy=0.2263.\n",
      "Training accuracy of batch: Loss=2.0473, Accuracy=0.2039.\n",
      "Training accuracy of batch: Loss=1.8036, Accuracy=0.1846.\n",
      "Training accuracy of batch: Loss=1.8924, Accuracy=0.1878.\n",
      "Training accuracy of batch: Loss=1.8566, Accuracy=0.2295.\n",
      "Training accuracy of batch: Loss=1.7877, Accuracy=0.1830.\n",
      "Training accuracy of batch: Loss=1.9220, Accuracy=0.2327.\n",
      "Training accuracy of batch: Loss=1.7950, Accuracy=0.2408.\n",
      "Validation after epoch #30, Validation Loss= 1.8257, Validation Accuracy= 0.255\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.3394919\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('Session initialized.')\n",
    "    \n",
    "    for epoch_step in range(1, epochs+1):\n",
    "        batch_gen = batch_generator(train_data, train_labels)\n",
    "        for data_minibatch, label_minibatch in batch_gen:\n",
    "            data_reshaped = data_minibatch.reshape((data_minibatch.shape[0], input_size))\n",
    "            labels_encoded = onehot_encode(label_minibatch)\n",
    "            sess.run(train_trigger, feed_dict={X: data_reshaped, Y: labels_encoded, keep_prob: dropout})\n",
    "            train_loss, train_acc = sess.run([loss_function, accuracy], feed_dict={X: validation_data, Y: validation_labels, keep_prob: 1.0})\n",
    "            print(\"Training accuracy of batch: Loss={:.4f}\".format(train_loss) +\", Accuracy={:.4f}.\".format(train_acc))\n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={X: validation_data, Y: validation_labels, keep_prob: 1.0})\n",
    "        print(\"Validation after epoch #\" + str(epoch_step) + \", Validation Loss= \"+ \"{:.4f}\".format(loss) + \", Validation Accuracy= \" + \"{:.3f}\".format(acc))\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data,\n",
    "                                      Y: test_labels,\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
