{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "seed_num = 72\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_num)\n",
    "import random\n",
    "random.seed(seed_num)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_num)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "from functools import reduce\n",
    "import operator as op\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "dataset_folder = os.path.abspath(\"./individual_npzs_overlap/{0}/*.npz\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "dropout = 0.75\n",
    "max_pool = 2\n",
    "strides = 1\n",
    "input_size = 60000\n",
    "output_size = 4\n",
    "epochs = 10000\n",
    "timesteps = 38\n",
    "\n",
    "hidden_layer = 128\n",
    "l2_beta = 0.0001\n",
    "tolerance = 200\n",
    "\n",
    "validation_session = 0\n",
    "test_session = 1\n",
    "\n",
    "label_dictionary = {'ang': 0, 'hap': 1, 'neu': 2, 'sad': 3}\n",
    "onehot_dictionary = {0: 'ang', 1: 'hap', 2:'neu', 3:'sad'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_batch_generator(data, labels):\n",
    "    steps = math.ceil(data.shape[0] / batch_size)\n",
    "    counts = [math.floor(class_count / steps) for class_count in np.unique(train_labels, return_counts=True)[1].tolist()]\n",
    "    for batch_step in range(0, steps):\n",
    "        minibatch = []\n",
    "        if (batch_step != steps-1):\n",
    "            for count in counts:\n",
    "                while (count != 0): \n",
    "                    minibatch.append()\n",
    "    \n",
    "    \n",
    "def batch_generator(data, labels):\n",
    "    steps = math.ceil(data.shape[0] / batch_size)\n",
    "    for batch_step in range(0, steps):\n",
    "        start = batch_size * batch_step\n",
    "        end = batch_size * (batch_step + 1)\n",
    "        yield data[start:end], labels[start:end], batch_step\n",
    "        \n",
    "def build_encoded_array(emotion_label):\n",
    "    initialized_array = [0. for key in label_dictionary]\n",
    "    initialized_array[label_dictionary[emotion_label]] = 1.\n",
    "    return initialized_array\n",
    "        \n",
    "def onehot_encode(label_minibatch):\n",
    "    return [build_encoded_array(emotion_label) for emotion_label in label_minibatch]\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    return np.ndarray.tolist(class_weight.compute_class_weight('balanced', np.unique(labels), labels))\n",
    "\n",
    "def sparse_encode(label_minibatch):\n",
    "    return [label_dictionary[emotion_label] for emotion_label in label_minibatch]\n",
    "\n",
    "def onehot_decode(onehot_labels):\n",
    "    return [onehot_dictionary[label.index(1.0)] for label in onehot_labels]\n",
    "\n",
    "def weighted_accuracy(y_pred, y_true):\n",
    "    #Suma vsetkych spravne urcenych viet predelena vsetkymi vetami\n",
    "\n",
    "    correct = 0\n",
    "    all = 0\n",
    "    for key in y_true:\n",
    "        correct += y_pred[key]\n",
    "        all += y_true[key]\n",
    "\n",
    "    return correct/all\n",
    "\n",
    "\n",
    "def unweighted_accuracy(y_pred, y_true):\n",
    "\n",
    "    #Suma poctu spravnych viet lomeno vsetky vety pre kazdu emociu (triedu) predelena poctom tried\n",
    "\n",
    "    correct = 0\n",
    "    emotions = len(y_true)\n",
    "    for key in y_true:\n",
    "        correct += y_pred[key]/y_true[key]\n",
    "\n",
    "    return correct/emotions\n",
    "\n",
    "def validation_results(current_sess, data, labels):\n",
    "    predictions = current_sess.run(correct_prediction, feed_dict={X:data, Y:labels, keep_prob:1.0, normalization_switch: False})\n",
    "    coupled_validation = list(zip(predictions, onehot_decode(labels)))\n",
    "    final_dict = {'ang':0, 'hap':0, 'neu':0, 'sad':0}\n",
    "    overall_dict = {'ang':0, 'hap':0, 'neu':0, 'sad':0}\n",
    "\n",
    "    for couple in coupled_validation:\n",
    "        if (couple[0]):\n",
    "            final_dict[couple[1]] += 1\n",
    "        overall_dict[couple[1]] += 1\n",
    "    unweighted_acc = unweighted_accuracy(final_dict, overall_dict)\n",
    "    return unweighted_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset: 3 sessions for training, 1 for validation, 1 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "#validation_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "train_labels = []\n",
    "#validation_labels = []\n",
    "test_labels = []\n",
    "\n",
    "all_sessions = {1: [], 2:[], 3:[], 4:[], 5:[]}\n",
    "\n",
    "session_string = 'session{0}'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    formatted = session_string.format(i)\n",
    "    for spectrogram in glob.glob(dataset_folder.format(formatted)):\n",
    "        loaded_spec = np.load(spectrogram)\n",
    "        for x in loaded_spec['spectrograms']:\n",
    "            if i != validation_session and i != test_session:\n",
    "                train_dataset.append(x) \n",
    "         #   elif i == validation_session:\n",
    "         #       validation_dataset.append(x)\n",
    "            elif i == test_session:\n",
    "                test_dataset.append(x)\n",
    "        for x in loaded_spec['labels']:\n",
    "            all_sessions[i].append(x)\n",
    "            if i != validation_session and i != test_session:\n",
    "                train_labels.append(x) \n",
    "          #  elif i == validation_session:\n",
    "          #      validation_labels.append(x)\n",
    "            elif i == test_session:\n",
    "                test_labels.append(x)\n",
    "        \n",
    "train_dataset = np.asarray(train_dataset)\n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "#validation_dataset = np.asarray(validation_dataset)\n",
    "#validation_labels = np.asarray(validation_labels)\n",
    "\n",
    "test_dataset = np.asarray(test_dataset)\n",
    "test_labels = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros([len(train_dataset), train_dataset[0].shape[0], train_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(train_dataset)):\n",
    "    train_data[data,:,:] = train_dataset[data]\n",
    "    \n",
    "#validation_data = np.zeros([len(validation_dataset), validation_dataset[0].shape[0], validation_dataset[0].shape[1]], dtype=np.uint8)\n",
    "#for data in range(len(validation_dataset)):\n",
    "#    validation_data[data,:,:] = validation_dataset[data]\n",
    "    \n",
    "test_data = np.zeros([len(test_dataset), test_dataset[0].shape[0], test_dataset[0].shape[1]], dtype=np.uint8)\n",
    "for data in range(len(test_dataset)):\n",
    "    test_data[data,:,:] = test_dataset[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = np.unique(train_labels, return_counts=True)[1]\n",
    "sum_counts = sum(counts)\n",
    "class_weights = [(0.25/(count/sum_counts)) for count in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.655743740795287, 2.0935754189944134, 0.602491961414791, 0.7945229681978798]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(validation_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ang', 'hap', 'neu', 'sad'], dtype='<U3'),\n",
       " array([ 71, 125, 670, 317], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ang', 'hap', 'neu', 'sad'], dtype='<U3'),\n",
       " array([ 679,  537, 1866, 1415], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_data = validation_data.reshape((validation_data.shape[0], input_size))\n",
    "#validation_labels = onehot_encode(validation_labels)\n",
    "\n",
    "test_data = test_data.reshape((test_data.shape[0], input_size))\n",
    "test_labels = onehot_encode(test_labels)\n",
    "\n",
    "train_data = train_data.reshape((train_data.shape[0], input_size))\n",
    "train_labels = onehot_encode(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=seed_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(to_process, weights, biases, strides=1):\n",
    "    conv_out = tf.nn.conv2d(to_process, weights, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    bias_out = tf.nn.bias_add(conv_out, biases)\n",
    "    relu_out = tf.nn.relu(bias_out)\n",
    "    return relu_out\n",
    "\n",
    "def maxpool2d(to_pool, pool_size=2):\n",
    "    maxpool_out = tf.nn.max_pool(to_pool, ksize=[1, pool_size, pool_size, 1], strides=[1, pool_size, pool_size, 1], padding='SAME')\n",
    "    return maxpool_out\n",
    "\n",
    "def nn_pipeline_rnn(spectrogram, weights, biases, dropout_num, normalization_switch):\n",
    "    reshaped_input = tf.reshape(spectrogram, shape=[-1, 200, 300, 1])\n",
    "\n",
    "    first_layer_out = conv2d(reshaped_input, weights['first_layer_weights'], biases['first_layer_biases'])\n",
    "    first_maxpool_out = maxpool2d(first_layer_out, pool_size=2)\n",
    "    first_batch_norm = tf.layers.batch_normalization(first_maxpool_out, training=normalization_switch)\n",
    "\n",
    "    second_layer_out = conv2d(first_batch_norm, weights['second_layer_weights'], biases['second_layer_biases'])\n",
    "    second_maxpool_out = maxpool2d(second_layer_out, pool_size=2)\n",
    "    second_batch_norm = tf.layers.batch_normalization(second_maxpool_out, training=normalization_switch)\n",
    "\n",
    "    third_layer_out = conv2d(second_batch_norm, weights['third_layer_weights'], biases['third_layer_biases'])\n",
    "    third_maxpool_out = maxpool2d(third_layer_out, pool_size=2)\n",
    "    third_batch_norm = tf.layers.batch_normalization(third_maxpool_out, training=normalization_switch)\n",
    "\n",
    "    interim_shape = third_batch_norm.get_shape().as_list()\n",
    "    transposed = tf.transpose(third_batch_norm, perm=[0, 2, 1, 3])\n",
    "    reshape_for_rnn = tf.reshape(transposed, [-1, interim_shape[2], interim_shape[1]*interim_shape[3]])\n",
    "    reshape_for_rnn.set_shape([None, interim_shape[2], interim_shape[1]*interim_shape[3]])\n",
    "    \n",
    "    fw_cell = tf.contrib.rnn.GRUCell(hidden_layer)\n",
    "    bw_cell = tf.contrib.rnn.GRUCell(hidden_layer)\n",
    "    gru_fw_cell = tf.contrib.rnn.DropoutWrapper(cell=fw_cell, output_keep_prob=dropout_num, seed=seed_num)\n",
    "    gru_bw_cell = tf.contrib.rnn.DropoutWrapper(cell=bw_cell, output_keep_prob=dropout_num, seed=seed_num)\n",
    "    \n",
    "    gru_output, _ = tf.nn.bidirectional_dynamic_rnn(gru_fw_cell, gru_bw_cell, reshape_for_rnn, dtype=tf.float32)\n",
    "    gru_output_concatted = tf.concat(gru_output, axis=2)\n",
    "    interim_shape_gru = tf.shape(gru_output_concatted)\n",
    "    gru_flatten = tf.reshape(gru_output_concatted, [-1, interim_shape_gru[1]*interim_shape_gru[2]])\n",
    "    \n",
    "    fully_connected_out = tf.add(tf.matmul(gru_flatten, weights['gru_weights']), biases['gru_biases'])\n",
    "    fully_connected_activation = tf.nn.relu(fully_connected_out)\n",
    "    fully_connected_dropout = tf.nn.dropout(fully_connected_activation, dropout_num, seed=seed_num)\n",
    "    \n",
    "    prediction = tf.add(tf.matmul(fully_connected_dropout, weights['output']), biases['output'])\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_rnn = {\n",
    "    'first_layer_weights': tf.Variable(tf.truncated_normal([10, 15, 1, 16], seed=seed_num)),\n",
    "    'second_layer_weights': tf.Variable(tf.truncated_normal([8, 10, 16, 24], seed=seed_num)),\n",
    "    'third_layer_weights': tf.Variable(tf.truncated_normal([5, 8, 24, 32], seed=seed_num)),\n",
    "    'gru_weights': tf.Variable(tf.truncated_normal([2*hidden_layer*timesteps, hidden_layer], seed=seed_num)),\n",
    "    'output': tf.Variable(tf.truncated_normal([hidden_layer, output_size], seed=seed_num))\n",
    "}\n",
    "\n",
    "biases_rnn = {\n",
    "    'first_layer_biases': tf.Variable(tf.truncated_normal([16], seed=seed_num)),\n",
    "    'second_layer_biases': tf.Variable(tf.truncated_normal([24], seed=seed_num)),\n",
    "    'third_layer_biases': tf.Variable(tf.truncated_normal([32], seed=seed_num)),\n",
    "    'gru_biases': tf.Variable(tf.truncated_normal([hidden_layer], seed=seed_num)),\n",
    "    'output': tf.Variable(tf.truncated_normal([output_size], seed=seed_num))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(logits, labels):\n",
    "    flat_logits = tf.reshape(logits, [-1, output_size])\n",
    "    flat_labels = tf.reshape(labels, [-1, output_size])\n",
    "    \n",
    "    eps = tf.constant(value=1e-10)\n",
    "    flat_logits = flat_logits + eps\n",
    "    \n",
    "    softmax = tf.nn.softmax(flat_logits)\n",
    "    \n",
    "    coeffs = tf.constant(class_weights)\n",
    "    \n",
    "    cross_entropy = -tf.reduce_sum(tf.multiply(flat_labels * tf.log(softmax + eps), coeffs), reduction_indices=[1])\n",
    "    \n",
    "    l2_loss = tf.add_n([tf.nn.l2_loss(weights_rnn[weights]) for weights in weights_rnn]) * l2_beta\n",
    "    \n",
    "    return tf.reduce_mean(tf.add(cross_entropy, l2_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_size])\n",
    "Y = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "normalization_switch = tf.placeholder(tf.bool)\n",
    "\n",
    "logits = nn_pipeline_rnn(X, weights_rnn, biases_rnn, keep_prob, normalization_switch)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "#weighted_logits = tf.multiply(class_weights, logits)\n",
    "#weight_regularizer = tf.add_n([tf.nn.l2_loss(weights_rnn[weights]) for weights in weights_rnn]) * 0.01\n",
    "#loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "loss_function = loss_function(logits, Y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_trigger = optimizer.minimize(loss_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(session):\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_loss = sys.maxsize\n",
    "    best_train_acc = 0\n",
    "    current_tolerance = 0\n",
    "    \n",
    "    for epoch_step in range(1, epochs+1):\n",
    "        batch_gen = batch_generator(train_data, train_labels)\n",
    "        train_acc_all = []\n",
    "        train_loss_all = []\n",
    "        for data_minibatch, label_minibatch, current_index in batch_gen:\n",
    "            sess.run(train_trigger, feed_dict={X: data_minibatch, Y: label_minibatch, keep_prob: dropout, normalization_switch: True})\n",
    "            train_loss, train_acc = sess.run([loss_function, accuracy], feed_dict={X: data_minibatch, Y: label_minibatch, keep_prob: 1.0, normalization_switch: False})\n",
    "            print(\"Train loss and acc of batch {0}: {1}, {2}\".format(current_index, train_loss, train_acc))\n",
    "            train_acc_all.append(train_acc)\n",
    "            train_loss_all.append(train_loss)\n",
    "        train_acc_whole = sum(train_acc_all)/len(train_acc_all)\n",
    "        train_loss_whole = sum(train_loss_all)/len(train_loss_all)\n",
    "        print(\"Training accuracy and loss of epoch #\" + str(epoch_step) + \": {:.4f}\".format(train_acc_whole) + \", {:.4f}\".format(train_loss_whole))\n",
    "        #loss, acc = sess.run([loss_function, accuracy], feed_dict={X: validation_data, Y: validation_labels, keep_prob: 1.0, normalization_switch: False})\n",
    "        #unweighted_acc = validation_results(sess, validation_data, validation_labels)\n",
    "        #print(\"Validation after epoch #\" + str(epoch_step) + \", Validation Loss= \"+ \"{:.4f}\".format(loss) + \", Validation Accuracy= \" + \"{:.3f}\".format(acc) + \", Unweighted Accuracy= \" + \"{:.3f}\".format(unweighted_acc))\n",
    "        #saved_by = []\n",
    "\n",
    "        if train_acc_whole > best_train_acc:\n",
    "            best_train_acc = train_acc_whole\n",
    "            saver.save(sess, \"./saved_models_overlap_fasterer/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\")\n",
    "            print(\"Saved model by train acc {0}\".format(train_acc_whole))\n",
    "        \n",
    "        if train_loss_whole < best_loss:\n",
    "            best_loss = train_loss_whole\n",
    "            saver.save(sess, \"./saved_models_overlap_fasterer_loss/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\")\n",
    "            print(\"Saved model by train loss {0}\".format(train_loss_whole))\n",
    "      \n",
    "        if train_acc_whole == 1.0:\n",
    "            break\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('Session initialized.')\n",
    "    train_network(sess)\n",
    "\n",
    "    #print(\"Testing Accuracy:\", \\\n",
    "    #    sess.run(accuracy, feed_dict={X: test_data,\n",
    "    #                                  Y: test_labels,\n",
    "    #                                  keep_prob: 1.0, normalization_switch: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models_overlap_fasterer_loss/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\n",
      "Train loss and acc of batch 0: 48.05868148803711, 1.0\n",
      "Train loss and acc of batch 1: 48.05867385864258, 1.0\n",
      "Train loss and acc of batch 2: 48.344520568847656, 0.984375\n",
      "Train loss and acc of batch 3: 48.275421142578125, 0.984375\n",
      "Train loss and acc of batch 4: 48.05864715576172, 1.0\n",
      "Train loss and acc of batch 5: 49.407562255859375, 0.96875\n",
      "Train loss and acc of batch 6: 48.56124496459961, 0.96875\n",
      "Train loss and acc of batch 7: 48.05862045288086, 1.0\n",
      "Train loss and acc of batch 8: 48.654319763183594, 0.984375\n",
      "Train loss and acc of batch 9: 48.344451904296875, 0.984375\n",
      "Train loss and acc of batch 10: 48.05859375, 1.0\n",
      "Train loss and acc of batch 11: 48.0585823059082, 1.0\n",
      "Train loss and acc of batch 12: 48.811798095703125, 0.984375\n",
      "Train loss and acc of batch 13: 48.27532958984375, 0.984375\n",
      "Train loss and acc of batch 14: 48.27532196044922, 0.984375\n",
      "Train loss and acc of batch 15: 48.65425109863281, 0.984375\n",
      "Train loss and acc of batch 16: 48.65424346923828, 0.984375\n",
      "Train loss and acc of batch 17: 48.81175994873047, 0.984375\n",
      "Train loss and acc of batch 18: 48.9400749206543, 0.96875\n",
      "Train loss and acc of batch 19: 48.05851364135742, 1.0\n",
      "Train loss and acc of batch 20: 48.058502197265625, 1.0\n",
      "Train loss and acc of batch 21: 48.654197692871094, 0.984375\n",
      "Train loss and acc of batch 22: 48.65419006347656, 0.984375\n",
      "Train loss and acc of batch 23: 48.275238037109375, 0.984375\n",
      "Train loss and acc of batch 24: 48.6541748046875, 0.984375\n",
      "Train loss and acc of batch 25: 48.05846405029297, 1.0\n",
      "Train loss and acc of batch 26: 48.058448791503906, 1.0\n",
      "Train loss and acc of batch 27: 48.058441162109375, 1.0\n",
      "Train loss and acc of batch 28: 48.058433532714844, 1.0\n",
      "Train loss and acc of batch 29: 48.65412139892578, 0.984375\n",
      "Train loss and acc of batch 30: 48.05841827392578, 1.0\n",
      "Train loss and acc of batch 31: 48.275169372558594, 0.984375\n",
      "Train loss and acc of batch 32: 48.05839538574219, 1.0\n",
      "Train loss and acc of batch 33: 48.058387756347656, 1.0\n",
      "Train loss and acc of batch 34: 48.654075622558594, 0.984375\n",
      "Train loss and acc of batch 35: 48.49190139770508, 0.96875\n",
      "Train loss and acc of batch 36: 48.05836868286133, 1.0\n",
      "Train loss and acc of batch 37: 48.81157302856445, 0.984375\n",
      "Train loss and acc of batch 38: 49.407264709472656, 0.96875\n",
      "Train loss and acc of batch 39: 48.27510070800781, 0.984375\n",
      "Train loss and acc of batch 40: 48.058326721191406, 1.0\n",
      "Train loss and acc of batch 41: 49.40724563598633, 0.96875\n",
      "Train loss and acc of batch 42: 48.05830383300781, 1.0\n",
      "Train loss and acc of batch 43: 48.65399932861328, 0.984375\n",
      "Train loss and acc of batch 44: 48.058292388916016, 1.0\n",
      "Train loss and acc of batch 45: 48.65398406982422, 0.984375\n",
      "Train loss and acc of batch 46: 48.34412384033203, 0.984375\n",
      "Train loss and acc of batch 47: 48.058265686035156, 1.0\n",
      "Train loss and acc of batch 48: 48.058250427246094, 1.0\n",
      "Train loss and acc of batch 49: 48.058250427246094, 1.0\n",
      "Train loss and acc of batch 50: 48.65394592285156, 0.984375\n",
      "Train loss and acc of batch 51: 49.40715026855469, 0.96875\n",
      "Train loss and acc of batch 52: 49.314056396484375, 0.953125\n",
      "Train loss and acc of batch 53: 48.05820846557617, 1.0\n",
      "Train loss and acc of batch 54: 48.27496337890625, 0.984375\n",
      "Train loss and acc of batch 55: 48.05819320678711, 1.0\n",
      "Train loss and acc of batch 56: 48.05818176269531, 1.0\n",
      "Train loss and acc of batch 57: 48.65387725830078, 0.984375\n",
      "Train loss and acc of batch 58: 48.05816650390625, 1.0\n",
      "Train loss and acc of batch 59: 48.05815505981445, 1.0\n",
      "Train loss and acc of batch 60: 48.05814743041992, 1.0\n",
      "Train loss and acc of batch 61: 48.05813980102539, 1.0\n",
      "Train loss and acc of batch 62: 48.27488708496094, 0.984375\n",
      "Train loss and acc of batch 63: 49.2495231628418, 0.96875\n",
      "Train loss and acc of batch 64: 48.274879455566406, 0.984375\n",
      "Train loss and acc of batch 65: 48.05809783935547, 1.0\n",
      "Train loss and acc of batch 66: 48.0580940246582, 1.0\n",
      "Train loss and acc of batch 67: 48.87055206298828, 0.96875\n",
      "Train loss and acc of batch 68: 48.653778076171875, 0.984375\n",
      "Train loss and acc of batch 69: 48.27483367919922, 0.984375\n",
      "Train loss and acc of batch 70: 48.05805206298828, 1.0\n",
      "Training accuracy and loss of epoch #1: 0.9890, 48.3894\n",
      "Saved model by train acc 0.9889964788732394\n",
      "Saved model by train loss 48.3893859755825\n",
      "Train loss and acc of batch 0: 48.058048248291016, 1.0\n",
      "Train loss and acc of batch 1: 48.05804443359375, 1.0\n",
      "Train loss and acc of batch 2: 48.34387969970703, 0.984375\n",
      "Train loss and acc of batch 3: 48.27478790283203, 0.984375\n",
      "Train loss and acc of batch 4: 48.058013916015625, 1.0\n",
      "Train loss and acc of batch 5: 49.40692901611328, 0.96875\n",
      "Train loss and acc of batch 6: 48.56060791015625, 0.96875\n",
      "Train loss and acc of batch 7: 48.0579833984375, 1.0\n",
      "Train loss and acc of batch 8: 48.65367126464844, 0.984375\n",
      "Train loss and acc of batch 9: 48.34382629394531, 0.984375\n",
      "Train loss and acc of batch 10: 48.05795669555664, 1.0\n",
      "Train loss and acc of batch 11: 48.057952880859375, 1.0\n",
      "Train loss and acc of batch 12: 48.8111686706543, 0.984375\n",
      "Train loss and acc of batch 13: 48.274688720703125, 0.984375\n",
      "Train loss and acc of batch 14: 48.274688720703125, 0.984375\n",
      "Train loss and acc of batch 15: 48.65361785888672, 0.984375\n",
      "Train loss and acc of batch 16: 48.653602600097656, 0.984375\n",
      "Train loss and acc of batch 17: 48.81111526489258, 0.984375\n",
      "Train loss and acc of batch 18: 48.93944549560547, 0.96875\n",
      "Train loss and acc of batch 19: 48.05787658691406, 1.0\n",
      "Train loss and acc of batch 20: 48.05786895751953, 1.0\n",
      "Train loss and acc of batch 21: 48.65355682373047, 0.984375\n",
      "Train loss and acc of batch 22: 48.65354919433594, 0.984375\n",
      "Train loss and acc of batch 23: 48.27460479736328, 0.984375\n",
      "Train loss and acc of batch 24: 48.653533935546875, 0.984375\n",
      "Train loss and acc of batch 25: 48.05782699584961, 1.0\n",
      "Train loss and acc of batch 26: 48.05781936645508, 1.0\n",
      "Train loss and acc of batch 27: 48.05780029296875, 1.0\n",
      "Train loss and acc of batch 28: 48.05780029296875, 1.0\n",
      "Train loss and acc of batch 29: 48.65349578857422, 0.984375\n",
      "Train loss and acc of batch 30: 48.05778121948242, 1.0\n",
      "Train loss and acc of batch 31: 48.2745361328125, 0.984375\n",
      "Train loss and acc of batch 32: 48.05776596069336, 1.0\n",
      "Train loss and acc of batch 33: 48.0577507019043, 1.0\n",
      "Train loss and acc of batch 34: 48.6534423828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.49126052856445, 0.96875\n",
      "Train loss and acc of batch 36: 48.05772399902344, 1.0\n",
      "Train loss and acc of batch 37: 48.810943603515625, 0.984375\n",
      "Train loss and acc of batch 38: 49.40663146972656, 0.96875\n",
      "Train loss and acc of batch 39: 48.27446746826172, 0.984375\n",
      "Train loss and acc of batch 40: 48.05769348144531, 1.0\n",
      "Train loss and acc of batch 41: 49.4066047668457, 0.96875\n",
      "Train loss and acc of batch 42: 48.05767059326172, 1.0\n",
      "Train loss and acc of batch 43: 48.65336608886719, 0.984375\n",
      "Train loss and acc of batch 44: 48.057655334472656, 1.0\n",
      "Train loss and acc of batch 45: 48.653350830078125, 0.984375\n",
      "Train loss and acc of batch 46: 48.343482971191406, 0.984375\n",
      "Train loss and acc of batch 47: 48.0576286315918, 1.0\n",
      "Train loss and acc of batch 48: 48.05762481689453, 1.0\n",
      "Train loss and acc of batch 49: 48.05760955810547, 1.0\n",
      "Train loss and acc of batch 50: 48.653297424316406, 0.984375\n",
      "Train loss and acc of batch 51: 49.406517028808594, 0.96875\n",
      "Train loss and acc of batch 52: 49.313419342041016, 0.953125\n",
      "Train loss and acc of batch 53: 48.05757522583008, 1.0\n",
      "Train loss and acc of batch 54: 48.274330139160156, 0.984375\n",
      "Train loss and acc of batch 55: 48.05755615234375, 1.0\n",
      "Train loss and acc of batch 56: 48.057552337646484, 1.0\n",
      "Train loss and acc of batch 57: 48.65324401855469, 0.984375\n",
      "Train loss and acc of batch 58: 48.05752944946289, 1.0\n",
      "Train loss and acc of batch 59: 48.057518005371094, 1.0\n",
      "Train loss and acc of batch 60: 48.0575065612793, 1.0\n",
      "Train loss and acc of batch 61: 48.0575065612793, 1.0\n",
      "Train loss and acc of batch 62: 48.274261474609375, 0.984375\n",
      "Train loss and acc of batch 63: 49.2488899230957, 0.96875\n",
      "Train loss and acc of batch 64: 48.27423858642578, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 48.05746841430664, 1.0\n",
      "Train loss and acc of batch 66: 48.05745315551758, 1.0\n",
      "Train loss and acc of batch 67: 48.86991882324219, 0.96875\n",
      "Train loss and acc of batch 68: 48.65314483642578, 0.984375\n",
      "Train loss and acc of batch 69: 48.274192810058594, 0.984375\n",
      "Train loss and acc of batch 70: 48.05742263793945, 1.0\n",
      "Training accuracy and loss of epoch #2: 0.9890, 48.3888\n",
      "Saved model by train loss 48.38875064043931\n",
      "Train loss and acc of batch 0: 48.05741500854492, 1.0\n",
      "Train loss and acc of batch 1: 48.057403564453125, 1.0\n",
      "Train loss and acc of batch 2: 48.34324645996094, 0.984375\n",
      "Train loss and acc of batch 3: 48.274147033691406, 0.984375\n",
      "Train loss and acc of batch 4: 48.05738067626953, 1.0\n",
      "Train loss and acc of batch 5: 49.40629577636719, 0.96875\n",
      "Train loss and acc of batch 6: 48.559974670410156, 0.96875\n",
      "Train loss and acc of batch 7: 48.057350158691406, 1.0\n",
      "Train loss and acc of batch 8: 48.653045654296875, 0.984375\n",
      "Train loss and acc of batch 9: 48.34318542480469, 0.984375\n",
      "Train loss and acc of batch 10: 48.05731964111328, 1.0\n",
      "Train loss and acc of batch 11: 48.057315826416016, 1.0\n",
      "Train loss and acc of batch 12: 48.81052780151367, 0.984375\n",
      "Train loss and acc of batch 13: 48.27406311035156, 0.984375\n",
      "Train loss and acc of batch 14: 48.27405548095703, 0.984375\n",
      "Train loss and acc of batch 15: 48.652984619140625, 0.984375\n",
      "Train loss and acc of batch 16: 48.65296936035156, 0.984375\n",
      "Train loss and acc of batch 17: 48.810482025146484, 0.984375\n",
      "Train loss and acc of batch 18: 48.938804626464844, 0.96875\n",
      "Train loss and acc of batch 19: 48.057247161865234, 1.0\n",
      "Train loss and acc of batch 20: 48.05723190307617, 1.0\n",
      "Train loss and acc of batch 21: 48.652931213378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.652915954589844, 0.984375\n",
      "Train loss and acc of batch 23: 48.27397155761719, 0.984375\n",
      "Train loss and acc of batch 24: 48.65290069580078, 0.984375\n",
      "Train loss and acc of batch 25: 48.057193756103516, 1.0\n",
      "Train loss and acc of batch 26: 48.05717849731445, 1.0\n",
      "Train loss and acc of batch 27: 48.05717468261719, 1.0\n",
      "Train loss and acc of batch 28: 48.057159423828125, 1.0\n",
      "Train loss and acc of batch 29: 48.652854919433594, 0.984375\n",
      "Train loss and acc of batch 30: 48.05714416503906, 1.0\n",
      "Train loss and acc of batch 31: 48.273895263671875, 0.984375\n",
      "Train loss and acc of batch 32: 48.057125091552734, 1.0\n",
      "Train loss and acc of batch 33: 48.0571174621582, 1.0\n",
      "Train loss and acc of batch 34: 48.652809143066406, 0.984375\n",
      "Train loss and acc of batch 35: 48.49062728881836, 0.96875\n",
      "Train loss and acc of batch 36: 48.057090759277344, 1.0\n",
      "Train loss and acc of batch 37: 48.810298919677734, 0.984375\n",
      "Train loss and acc of batch 38: 49.40599060058594, 0.96875\n",
      "Train loss and acc of batch 39: 48.273826599121094, 0.984375\n",
      "Train loss and acc of batch 40: 48.05705261230469, 1.0\n",
      "Train loss and acc of batch 41: 49.405975341796875, 0.96875\n",
      "Train loss and acc of batch 42: 48.05703353881836, 1.0\n",
      "Train loss and acc of batch 43: 48.65272521972656, 0.984375\n",
      "Train loss and acc of batch 44: 48.057010650634766, 1.0\n",
      "Train loss and acc of batch 45: 48.6527099609375, 0.984375\n",
      "Train loss and acc of batch 46: 48.34284973144531, 0.984375\n",
      "Train loss and acc of batch 47: 48.05698776245117, 1.0\n",
      "Train loss and acc of batch 48: 48.056976318359375, 1.0\n",
      "Train loss and acc of batch 49: 48.05697250366211, 1.0\n",
      "Train loss and acc of batch 50: 48.65266418457031, 0.984375\n",
      "Train loss and acc of batch 51: 49.40587615966797, 0.96875\n",
      "Train loss and acc of batch 52: 49.31278991699219, 0.953125\n",
      "Train loss and acc of batch 53: 48.05693817138672, 1.0\n",
      "Train loss and acc of batch 54: 48.27368927001953, 0.984375\n",
      "Train loss and acc of batch 55: 48.056922912597656, 1.0\n",
      "Train loss and acc of batch 56: 48.05690383911133, 1.0\n",
      "Train loss and acc of batch 57: 48.65260314941406, 0.984375\n",
      "Train loss and acc of batch 58: 48.05689239501953, 1.0\n",
      "Train loss and acc of batch 59: 48.056880950927734, 1.0\n",
      "Train loss and acc of batch 60: 48.05686950683594, 1.0\n",
      "Train loss and acc of batch 61: 48.056861877441406, 1.0\n",
      "Train loss and acc of batch 62: 48.27362060546875, 0.984375\n",
      "Train loss and acc of batch 63: 49.248252868652344, 0.96875\n",
      "Train loss and acc of batch 64: 48.27360534667969, 0.984375\n",
      "Train loss and acc of batch 65: 48.056827545166016, 1.0\n",
      "Train loss and acc of batch 66: 48.056819915771484, 1.0\n",
      "Train loss and acc of batch 67: 48.86927795410156, 0.96875\n",
      "Train loss and acc of batch 68: 48.652503967285156, 0.984375\n",
      "Train loss and acc of batch 69: 48.2735595703125, 0.984375\n",
      "Train loss and acc of batch 70: 48.05678176879883, 1.0\n",
      "Training accuracy and loss of epoch #3: 0.9890, 48.3881\n",
      "Saved model by train loss 48.38811390836474\n",
      "Train loss and acc of batch 0: 48.0567741394043, 1.0\n",
      "Train loss and acc of batch 1: 48.056766510009766, 1.0\n",
      "Train loss and acc of batch 2: 48.34260559082031, 0.984375\n",
      "Train loss and acc of batch 3: 48.27351379394531, 0.984375\n",
      "Train loss and acc of batch 4: 48.056739807128906, 1.0\n",
      "Train loss and acc of batch 5: 49.40565490722656, 0.96875\n",
      "Train loss and acc of batch 6: 48.55934143066406, 0.96875\n",
      "Train loss and acc of batch 7: 48.05671310424805, 1.0\n",
      "Train loss and acc of batch 8: 48.65240478515625, 0.984375\n",
      "Train loss and acc of batch 9: 48.34254455566406, 0.984375\n",
      "Train loss and acc of batch 10: 48.05668258666992, 1.0\n",
      "Train loss and acc of batch 11: 48.056678771972656, 1.0\n",
      "Train loss and acc of batch 12: 48.80989074707031, 0.984375\n",
      "Train loss and acc of batch 13: 48.27342224121094, 0.984375\n",
      "Train loss and acc of batch 14: 48.273414611816406, 0.984375\n",
      "Train loss and acc of batch 15: 48.65234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.65232849121094, 0.984375\n",
      "Train loss and acc of batch 17: 48.809844970703125, 0.984375\n",
      "Train loss and acc of batch 18: 48.93816375732422, 0.96875\n",
      "Train loss and acc of batch 19: 48.056602478027344, 1.0\n",
      "Train loss and acc of batch 20: 48.05659866333008, 1.0\n",
      "Train loss and acc of batch 21: 48.65229034423828, 0.984375\n",
      "Train loss and acc of batch 22: 48.65227508544922, 0.984375\n",
      "Train loss and acc of batch 23: 48.273338317871094, 0.984375\n",
      "Train loss and acc of batch 24: 48.652259826660156, 0.984375\n",
      "Train loss and acc of batch 25: 48.056549072265625, 1.0\n",
      "Train loss and acc of batch 26: 48.056541442871094, 1.0\n",
      "Train loss and acc of batch 27: 48.0565299987793, 1.0\n",
      "Train loss and acc of batch 28: 48.056522369384766, 1.0\n",
      "Train loss and acc of batch 29: 48.65221405029297, 0.984375\n",
      "Train loss and acc of batch 30: 48.05650329589844, 1.0\n",
      "Train loss and acc of batch 31: 48.27326202392578, 0.984375\n",
      "Train loss and acc of batch 32: 48.056488037109375, 1.0\n",
      "Train loss and acc of batch 33: 48.05647659301758, 1.0\n",
      "Train loss and acc of batch 34: 48.65217590332031, 0.984375\n",
      "Train loss and acc of batch 35: 48.489990234375, 0.96875\n",
      "Train loss and acc of batch 36: 48.056453704833984, 1.0\n",
      "Train loss and acc of batch 37: 48.80967330932617, 0.984375\n",
      "Train loss and acc of batch 38: 49.405357360839844, 0.96875\n",
      "Train loss and acc of batch 39: 48.273193359375, 0.984375\n",
      "Train loss and acc of batch 40: 48.056419372558594, 1.0\n",
      "Train loss and acc of batch 41: 49.405330657958984, 0.96875\n",
      "Train loss and acc of batch 42: 48.056400299072266, 1.0\n",
      "Train loss and acc of batch 43: 48.65209197998047, 0.984375\n",
      "Train loss and acc of batch 44: 48.05638122558594, 1.0\n",
      "Train loss and acc of batch 45: 48.652069091796875, 0.984375\n",
      "Train loss and acc of batch 46: 48.34221649169922, 0.984375\n",
      "Train loss and acc of batch 47: 48.05635070800781, 1.0\n",
      "Train loss and acc of batch 48: 48.05634689331055, 1.0\n",
      "Train loss and acc of batch 49: 48.05633544921875, 1.0\n",
      "Train loss and acc of batch 50: 48.65203094482422, 0.984375\n",
      "Train loss and acc of batch 51: 49.405250549316406, 0.96875\n",
      "Train loss and acc of batch 52: 49.31214904785156, 0.953125\n",
      "Train loss and acc of batch 53: 48.056297302246094, 1.0\n",
      "Train loss and acc of batch 54: 48.27306365966797, 0.984375\n",
      "Train loss and acc of batch 55: 48.056278228759766, 1.0\n",
      "Train loss and acc of batch 56: 48.0562744140625, 1.0\n",
      "Train loss and acc of batch 57: 48.65196228027344, 0.984375\n",
      "Train loss and acc of batch 58: 48.05625534057617, 1.0\n",
      "Train loss and acc of batch 59: 48.05624771118164, 1.0\n",
      "Train loss and acc of batch 60: 48.05623245239258, 1.0\n",
      "Train loss and acc of batch 61: 48.05622863769531, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 62: 48.272987365722656, 0.984375\n",
      "Train loss and acc of batch 63: 49.24761199951172, 0.96875\n",
      "Train loss and acc of batch 64: 48.27296447753906, 0.984375\n",
      "Train loss and acc of batch 65: 48.05619812011719, 1.0\n",
      "Train loss and acc of batch 66: 48.05617904663086, 1.0\n",
      "Train loss and acc of batch 67: 48.8686408996582, 0.96875\n",
      "Train loss and acc of batch 68: 48.65186309814453, 0.984375\n",
      "Train loss and acc of batch 69: 48.272918701171875, 0.984375\n",
      "Train loss and acc of batch 70: 48.056148529052734, 1.0\n",
      "Training accuracy and loss of epoch #4: 0.9890, 48.3875\n",
      "Saved model by train loss 48.38747674646512\n",
      "Train loss and acc of batch 0: 48.0561408996582, 1.0\n",
      "Train loss and acc of batch 1: 48.056129455566406, 1.0\n",
      "Train loss and acc of batch 2: 48.34197998046875, 0.984375\n",
      "Train loss and acc of batch 3: 48.27287292480469, 0.984375\n",
      "Train loss and acc of batch 4: 48.05610275268555, 1.0\n",
      "Train loss and acc of batch 5: 49.40502166748047, 0.96875\n",
      "Train loss and acc of batch 6: 48.55870056152344, 0.96875\n",
      "Train loss and acc of batch 7: 48.05607604980469, 1.0\n",
      "Train loss and acc of batch 8: 48.651763916015625, 0.984375\n",
      "Train loss and acc of batch 9: 48.34191131591797, 0.984375\n",
      "Train loss and acc of batch 10: 48.05604934692383, 1.0\n",
      "Train loss and acc of batch 11: 48.0560417175293, 1.0\n",
      "Train loss and acc of batch 12: 48.80924987792969, 0.984375\n",
      "Train loss and acc of batch 13: 48.272789001464844, 0.984375\n",
      "Train loss and acc of batch 14: 48.27278137207031, 0.984375\n",
      "Train loss and acc of batch 15: 48.651710510253906, 0.984375\n",
      "Train loss and acc of batch 16: 48.651702880859375, 0.984375\n",
      "Train loss and acc of batch 17: 48.809207916259766, 0.984375\n",
      "Train loss and acc of batch 18: 48.937530517578125, 0.96875\n",
      "Train loss and acc of batch 19: 48.05596923828125, 1.0\n",
      "Train loss and acc of batch 20: 48.05596160888672, 1.0\n",
      "Train loss and acc of batch 21: 48.651649475097656, 0.984375\n",
      "Train loss and acc of batch 22: 48.651649475097656, 0.984375\n",
      "Train loss and acc of batch 23: 48.27269744873047, 0.984375\n",
      "Train loss and acc of batch 24: 48.65162658691406, 0.984375\n",
      "Train loss and acc of batch 25: 48.055912017822266, 1.0\n",
      "Train loss and acc of batch 26: 48.055904388427734, 1.0\n",
      "Train loss and acc of batch 27: 48.05590057373047, 1.0\n",
      "Train loss and acc of batch 28: 48.055885314941406, 1.0\n",
      "Train loss and acc of batch 29: 48.651580810546875, 0.984375\n",
      "Train loss and acc of batch 30: 48.05587387084961, 1.0\n",
      "Train loss and acc of batch 31: 48.27262878417969, 0.984375\n",
      "Train loss and acc of batch 32: 48.055850982666016, 1.0\n",
      "Train loss and acc of batch 33: 48.05584716796875, 1.0\n",
      "Train loss and acc of batch 34: 48.65153503417969, 0.984375\n",
      "Train loss and acc of batch 35: 48.489356994628906, 0.96875\n",
      "Train loss and acc of batch 36: 48.05582046508789, 1.0\n",
      "Train loss and acc of batch 37: 48.80903244018555, 0.984375\n",
      "Train loss and acc of batch 38: 49.40472412109375, 0.96875\n",
      "Train loss and acc of batch 39: 48.272552490234375, 0.984375\n",
      "Train loss and acc of batch 40: 48.05577850341797, 1.0\n",
      "Train loss and acc of batch 41: 49.404701232910156, 0.96875\n",
      "Train loss and acc of batch 42: 48.055763244628906, 1.0\n",
      "Train loss and acc of batch 43: 48.651458740234375, 0.984375\n",
      "Train loss and acc of batch 44: 48.055747985839844, 1.0\n",
      "Train loss and acc of batch 45: 48.65143585205078, 0.984375\n",
      "Train loss and acc of batch 46: 48.341575622558594, 0.984375\n",
      "Train loss and acc of batch 47: 48.055721282958984, 1.0\n",
      "Train loss and acc of batch 48: 48.05570983886719, 1.0\n",
      "Train loss and acc of batch 49: 48.05569839477539, 1.0\n",
      "Train loss and acc of batch 50: 48.651390075683594, 0.984375\n",
      "Train loss and acc of batch 51: 49.40460968017578, 0.96875\n",
      "Train loss and acc of batch 52: 49.31151580810547, 0.953125\n",
      "Train loss and acc of batch 53: 48.055660247802734, 1.0\n",
      "Train loss and acc of batch 54: 48.272422790527344, 0.984375\n",
      "Train loss and acc of batch 55: 48.05564880371094, 1.0\n",
      "Train loss and acc of batch 56: 48.055641174316406, 1.0\n",
      "Train loss and acc of batch 57: 48.651329040527344, 0.984375\n",
      "Train loss and acc of batch 58: 48.05562210083008, 1.0\n",
      "Train loss and acc of batch 59: 48.05561065673828, 1.0\n",
      "Train loss and acc of batch 60: 48.055606842041016, 1.0\n",
      "Train loss and acc of batch 61: 48.05559158325195, 1.0\n",
      "Train loss and acc of batch 62: 48.27234649658203, 0.984375\n",
      "Train loss and acc of batch 63: 49.24697494506836, 0.96875\n",
      "Train loss and acc of batch 64: 48.27233123779297, 0.984375\n",
      "Train loss and acc of batch 65: 48.05555725097656, 1.0\n",
      "Train loss and acc of batch 66: 48.0555534362793, 1.0\n",
      "Train loss and acc of batch 67: 48.868003845214844, 0.96875\n",
      "Train loss and acc of batch 68: 48.65122985839844, 0.984375\n",
      "Train loss and acc of batch 69: 48.27228546142578, 0.984375\n",
      "Train loss and acc of batch 70: 48.055511474609375, 1.0\n",
      "Training accuracy and loss of epoch #5: 0.9890, 48.3868\n",
      "Saved model by train loss 48.38684162623446\n",
      "Train loss and acc of batch 0: 48.055503845214844, 1.0\n",
      "Train loss and acc of batch 1: 48.05550003051758, 1.0\n",
      "Train loss and acc of batch 2: 48.341339111328125, 0.984375\n",
      "Train loss and acc of batch 3: 48.272247314453125, 0.984375\n",
      "Train loss and acc of batch 4: 48.05546951293945, 1.0\n",
      "Train loss and acc of batch 5: 49.404380798339844, 0.96875\n",
      "Train loss and acc of batch 6: 48.558067321777344, 0.96875\n",
      "Train loss and acc of batch 7: 48.05543899536133, 1.0\n",
      "Train loss and acc of batch 8: 48.65113067626953, 0.984375\n",
      "Train loss and acc of batch 9: 48.341278076171875, 0.984375\n",
      "Train loss and acc of batch 10: 48.055416107177734, 1.0\n",
      "Train loss and acc of batch 11: 48.05540084838867, 1.0\n",
      "Train loss and acc of batch 12: 48.80862045288086, 0.984375\n",
      "Train loss and acc of batch 13: 48.27214813232422, 0.984375\n",
      "Train loss and acc of batch 14: 48.27214050292969, 0.984375\n",
      "Train loss and acc of batch 15: 48.65106964111328, 0.984375\n",
      "Train loss and acc of batch 16: 48.65106201171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.8085823059082, 0.984375\n",
      "Train loss and acc of batch 18: 48.936893463134766, 0.96875\n",
      "Train loss and acc of batch 19: 48.05533218383789, 1.0\n",
      "Train loss and acc of batch 20: 48.055328369140625, 1.0\n",
      "Train loss and acc of batch 21: 48.65101623535156, 0.984375\n",
      "Train loss and acc of batch 22: 48.65100860595703, 0.984375\n",
      "Train loss and acc of batch 23: 48.272056579589844, 0.984375\n",
      "Train loss and acc of batch 24: 48.65099334716797, 0.984375\n",
      "Train loss and acc of batch 25: 48.05528259277344, 1.0\n",
      "Train loss and acc of batch 26: 48.055274963378906, 1.0\n",
      "Train loss and acc of batch 27: 48.055259704589844, 1.0\n",
      "Train loss and acc of batch 28: 48.05525588989258, 1.0\n",
      "Train loss and acc of batch 29: 48.65093994140625, 0.984375\n",
      "Train loss and acc of batch 30: 48.05523681640625, 1.0\n",
      "Train loss and acc of batch 31: 48.271995544433594, 0.984375\n",
      "Train loss and acc of batch 32: 48.055213928222656, 1.0\n",
      "Train loss and acc of batch 33: 48.055206298828125, 1.0\n",
      "Train loss and acc of batch 34: 48.650901794433594, 0.984375\n",
      "Train loss and acc of batch 35: 48.48871994018555, 0.96875\n",
      "Train loss and acc of batch 36: 48.05518341064453, 1.0\n",
      "Train loss and acc of batch 37: 48.80839538574219, 0.984375\n",
      "Train loss and acc of batch 38: 49.404090881347656, 0.96875\n",
      "Train loss and acc of batch 39: 48.27191925048828, 0.984375\n",
      "Train loss and acc of batch 40: 48.05514907836914, 1.0\n",
      "Train loss and acc of batch 41: 49.40406036376953, 0.96875\n",
      "Train loss and acc of batch 42: 48.05512619018555, 1.0\n",
      "Train loss and acc of batch 43: 48.65082550048828, 0.984375\n",
      "Train loss and acc of batch 44: 48.05510711669922, 1.0\n",
      "Train loss and acc of batch 45: 48.65081024169922, 0.984375\n",
      "Train loss and acc of batch 46: 48.3409423828125, 0.984375\n",
      "Train loss and acc of batch 47: 48.05508804321289, 1.0\n",
      "Train loss and acc of batch 48: 48.05507278442383, 1.0\n",
      "Train loss and acc of batch 49: 48.0550651550293, 1.0\n",
      "Train loss and acc of batch 50: 48.6507568359375, 0.984375\n",
      "Train loss and acc of batch 51: 49.403968811035156, 0.96875\n",
      "Train loss and acc of batch 52: 49.31087875366211, 0.953125\n",
      "Train loss and acc of batch 53: 48.055030822753906, 1.0\n",
      "Train loss and acc of batch 54: 48.27178192138672, 0.984375\n",
      "Train loss and acc of batch 55: 48.05500793457031, 1.0\n",
      "Train loss and acc of batch 56: 48.05500411987305, 1.0\n",
      "Train loss and acc of batch 57: 48.65069580078125, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 58: 48.05498504638672, 1.0\n",
      "Train loss and acc of batch 59: 48.05498123168945, 1.0\n",
      "Train loss and acc of batch 60: 48.05496597290039, 1.0\n",
      "Train loss and acc of batch 61: 48.05495834350586, 1.0\n",
      "Train loss and acc of batch 62: 48.27171325683594, 0.984375\n",
      "Train loss and acc of batch 63: 49.246341705322266, 0.96875\n",
      "Train loss and acc of batch 64: 48.271697998046875, 0.984375\n",
      "Train loss and acc of batch 65: 48.0549201965332, 1.0\n",
      "Train loss and acc of batch 66: 48.05491256713867, 1.0\n",
      "Train loss and acc of batch 67: 48.867374420166016, 0.96875\n",
      "Train loss and acc of batch 68: 48.650596618652344, 0.984375\n",
      "Train loss and acc of batch 69: 48.27165222167969, 0.984375\n",
      "Train loss and acc of batch 70: 48.05487823486328, 1.0\n",
      "Training accuracy and loss of epoch #6: 0.9890, 48.3862\n",
      "Saved model by train loss 48.386206344819406\n",
      "Train loss and acc of batch 0: 48.05486297607422, 1.0\n",
      "Train loss and acc of batch 1: 48.05485916137695, 1.0\n",
      "Train loss and acc of batch 2: 48.3406982421875, 0.984375\n",
      "Train loss and acc of batch 3: 48.2716064453125, 0.984375\n",
      "Train loss and acc of batch 4: 48.05483627319336, 1.0\n",
      "Train loss and acc of batch 5: 49.40374755859375, 0.96875\n",
      "Train loss and acc of batch 6: 48.557430267333984, 0.96875\n",
      "Train loss and acc of batch 7: 48.054805755615234, 1.0\n",
      "Train loss and acc of batch 8: 48.65049743652344, 0.984375\n",
      "Train loss and acc of batch 9: 48.34064483642578, 0.984375\n",
      "Train loss and acc of batch 10: 48.054779052734375, 1.0\n",
      "Train loss and acc of batch 11: 48.054771423339844, 1.0\n",
      "Train loss and acc of batch 12: 48.8079833984375, 0.984375\n",
      "Train loss and acc of batch 13: 48.271514892578125, 0.984375\n",
      "Train loss and acc of batch 14: 48.271507263183594, 0.984375\n",
      "Train loss and acc of batch 15: 48.65043640136719, 0.984375\n",
      "Train loss and acc of batch 16: 48.650428771972656, 0.984375\n",
      "Train loss and acc of batch 17: 48.80793762207031, 0.984375\n",
      "Train loss and acc of batch 18: 48.93626022338867, 0.96875\n",
      "Train loss and acc of batch 19: 48.0546989440918, 1.0\n",
      "Train loss and acc of batch 20: 48.054691314697266, 1.0\n",
      "Train loss and acc of batch 21: 48.65038299560547, 0.984375\n",
      "Train loss and acc of batch 22: 48.65037536621094, 0.984375\n",
      "Train loss and acc of batch 23: 48.27143096923828, 0.984375\n",
      "Train loss and acc of batch 24: 48.650360107421875, 0.984375\n",
      "Train loss and acc of batch 25: 48.05464553833008, 1.0\n",
      "Train loss and acc of batch 26: 48.05463790893555, 1.0\n",
      "Train loss and acc of batch 27: 48.054630279541016, 1.0\n",
      "Train loss and acc of batch 28: 48.05461883544922, 1.0\n",
      "Train loss and acc of batch 29: 48.650306701660156, 0.984375\n",
      "Train loss and acc of batch 30: 48.05459976196289, 1.0\n",
      "Train loss and acc of batch 31: 48.27135467529297, 0.984375\n",
      "Train loss and acc of batch 32: 48.05458450317383, 1.0\n",
      "Train loss and acc of batch 33: 48.05457305908203, 1.0\n",
      "Train loss and acc of batch 34: 48.6502685546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.48808670043945, 0.96875\n",
      "Train loss and acc of batch 36: 48.05454635620117, 1.0\n",
      "Train loss and acc of batch 37: 48.80775833129883, 0.984375\n",
      "Train loss and acc of batch 38: 49.40345764160156, 0.96875\n",
      "Train loss and acc of batch 39: 48.27128601074219, 0.984375\n",
      "Train loss and acc of batch 40: 48.05451202392578, 1.0\n",
      "Train loss and acc of batch 41: 49.4034309387207, 0.96875\n",
      "Train loss and acc of batch 42: 48.05449295043945, 1.0\n",
      "Train loss and acc of batch 43: 48.650184631347656, 0.984375\n",
      "Train loss and acc of batch 44: 48.054473876953125, 1.0\n",
      "Train loss and acc of batch 45: 48.650169372558594, 0.984375\n",
      "Train loss and acc of batch 46: 48.340309143066406, 0.984375\n",
      "Train loss and acc of batch 47: 48.054447174072266, 1.0\n",
      "Train loss and acc of batch 48: 48.054443359375, 1.0\n",
      "Train loss and acc of batch 49: 48.05442810058594, 1.0\n",
      "Train loss and acc of batch 50: 48.650115966796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.40333557128906, 0.96875\n",
      "Train loss and acc of batch 52: 49.310245513916016, 0.953125\n",
      "Train loss and acc of batch 53: 48.05439376831055, 1.0\n",
      "Train loss and acc of batch 54: 48.271148681640625, 0.984375\n",
      "Train loss and acc of batch 55: 48.05437469482422, 1.0\n",
      "Train loss and acc of batch 56: 48.05436706542969, 1.0\n",
      "Train loss and acc of batch 57: 48.650062561035156, 0.984375\n",
      "Train loss and acc of batch 58: 48.05434799194336, 1.0\n",
      "Train loss and acc of batch 59: 48.05434036254883, 1.0\n",
      "Train loss and acc of batch 60: 48.05432891845703, 1.0\n",
      "Train loss and acc of batch 61: 48.054325103759766, 1.0\n",
      "Train loss and acc of batch 62: 48.271080017089844, 0.984375\n",
      "Train loss and acc of batch 63: 49.245704650878906, 0.96875\n",
      "Train loss and acc of batch 64: 48.27105712890625, 0.984375\n",
      "Train loss and acc of batch 65: 48.05428695678711, 1.0\n",
      "Train loss and acc of batch 66: 48.05427932739258, 1.0\n",
      "Train loss and acc of batch 67: 48.866737365722656, 0.96875\n",
      "Train loss and acc of batch 68: 48.64995574951172, 0.984375\n",
      "Train loss and acc of batch 69: 48.27101135253906, 0.984375\n",
      "Train loss and acc of batch 70: 48.05424118041992, 1.0\n",
      "Training accuracy and loss of epoch #7: 0.9890, 48.3856\n",
      "Saved model by train loss 48.38557090221996\n",
      "Train loss and acc of batch 0: 48.054237365722656, 1.0\n",
      "Train loss and acc of batch 1: 48.054222106933594, 1.0\n",
      "Train loss and acc of batch 2: 48.340065002441406, 0.984375\n",
      "Train loss and acc of batch 3: 48.270973205566406, 0.984375\n",
      "Train loss and acc of batch 4: 48.054195404052734, 1.0\n",
      "Train loss and acc of batch 5: 49.403114318847656, 0.96875\n",
      "Train loss and acc of batch 6: 48.55679702758789, 0.96875\n",
      "Train loss and acc of batch 7: 48.054168701171875, 1.0\n",
      "Train loss and acc of batch 8: 48.649864196777344, 0.984375\n",
      "Train loss and acc of batch 9: 48.340003967285156, 0.984375\n",
      "Train loss and acc of batch 10: 48.05414581298828, 1.0\n",
      "Train loss and acc of batch 11: 48.05413818359375, 1.0\n",
      "Train loss and acc of batch 12: 48.80734634399414, 0.984375\n",
      "Train loss and acc of batch 13: 48.27088165283203, 0.984375\n",
      "Train loss and acc of batch 14: 48.2708740234375, 0.984375\n",
      "Train loss and acc of batch 15: 48.649803161621094, 0.984375\n",
      "Train loss and acc of batch 16: 48.64978790283203, 0.984375\n",
      "Train loss and acc of batch 17: 48.80730438232422, 0.984375\n",
      "Train loss and acc of batch 18: 48.93562316894531, 0.96875\n",
      "Train loss and acc of batch 19: 48.0540657043457, 1.0\n",
      "Train loss and acc of batch 20: 48.054054260253906, 1.0\n",
      "Train loss and acc of batch 21: 48.649742126464844, 0.984375\n",
      "Train loss and acc of batch 22: 48.64973449707031, 0.984375\n",
      "Train loss and acc of batch 23: 48.270790100097656, 0.984375\n",
      "Train loss and acc of batch 24: 48.64971923828125, 0.984375\n",
      "Train loss and acc of batch 25: 48.05400848388672, 1.0\n",
      "Train loss and acc of batch 26: 48.05399703979492, 1.0\n",
      "Train loss and acc of batch 27: 48.053993225097656, 1.0\n",
      "Train loss and acc of batch 28: 48.053985595703125, 1.0\n",
      "Train loss and acc of batch 29: 48.64967346191406, 0.984375\n",
      "Train loss and acc of batch 30: 48.05396270751953, 1.0\n",
      "Train loss and acc of batch 31: 48.270721435546875, 0.984375\n",
      "Train loss and acc of batch 32: 48.05394744873047, 1.0\n",
      "Train loss and acc of batch 33: 48.0539436340332, 1.0\n",
      "Train loss and acc of batch 34: 48.649627685546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.48744583129883, 0.96875\n",
      "Train loss and acc of batch 36: 48.05391311645508, 1.0\n",
      "Train loss and acc of batch 37: 48.80712127685547, 0.984375\n",
      "Train loss and acc of batch 38: 49.40281677246094, 0.96875\n",
      "Train loss and acc of batch 39: 48.270652770996094, 0.984375\n",
      "Train loss and acc of batch 40: 48.05387496948242, 1.0\n",
      "Train loss and acc of batch 41: 49.402793884277344, 0.96875\n",
      "Train loss and acc of batch 42: 48.05385971069336, 1.0\n",
      "Train loss and acc of batch 43: 48.64955139160156, 0.984375\n",
      "Train loss and acc of batch 44: 48.05384063720703, 1.0\n",
      "Train loss and acc of batch 45: 48.64952850341797, 0.984375\n",
      "Train loss and acc of batch 46: 48.33967590332031, 0.984375\n",
      "Train loss and acc of batch 47: 48.053810119628906, 1.0\n",
      "Train loss and acc of batch 48: 48.053802490234375, 1.0\n",
      "Train loss and acc of batch 49: 48.053794860839844, 1.0\n",
      "Train loss and acc of batch 50: 48.64949035644531, 0.984375\n",
      "Train loss and acc of batch 51: 49.40269470214844, 0.96875\n",
      "Train loss and acc of batch 52: 49.30960464477539, 0.953125\n",
      "Train loss and acc of batch 53: 48.05375671386719, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 54: 48.27051544189453, 0.984375\n",
      "Train loss and acc of batch 55: 48.053741455078125, 1.0\n",
      "Train loss and acc of batch 56: 48.053733825683594, 1.0\n",
      "Train loss and acc of batch 57: 48.64942169189453, 0.984375\n",
      "Train loss and acc of batch 58: 48.053714752197266, 1.0\n",
      "Train loss and acc of batch 59: 48.05370330810547, 1.0\n",
      "Train loss and acc of batch 60: 48.05369567871094, 1.0\n",
      "Train loss and acc of batch 61: 48.053688049316406, 1.0\n",
      "Train loss and acc of batch 62: 48.27043914794922, 0.984375\n",
      "Train loss and acc of batch 63: 49.24507141113281, 0.96875\n",
      "Train loss and acc of batch 64: 48.270423889160156, 0.984375\n",
      "Train loss and acc of batch 65: 48.05364990234375, 1.0\n",
      "Train loss and acc of batch 66: 48.05363845825195, 1.0\n",
      "Train loss and acc of batch 67: 48.8661003112793, 0.96875\n",
      "Train loss and acc of batch 68: 48.649322509765625, 0.984375\n",
      "Train loss and acc of batch 69: 48.2703857421875, 0.984375\n",
      "Train loss and acc of batch 70: 48.05360794067383, 1.0\n",
      "Training accuracy and loss of epoch #8: 0.9890, 48.3849\n",
      "Saved model by train loss 48.38493513725173\n",
      "Train loss and acc of batch 0: 48.053592681884766, 1.0\n",
      "Train loss and acc of batch 1: 48.0535888671875, 1.0\n",
      "Train loss and acc of batch 2: 48.33943176269531, 0.984375\n",
      "Train loss and acc of batch 3: 48.27033233642578, 0.984375\n",
      "Train loss and acc of batch 4: 48.05356216430664, 1.0\n",
      "Train loss and acc of batch 5: 49.40248107910156, 0.96875\n",
      "Train loss and acc of batch 6: 48.5561637878418, 0.96875\n",
      "Train loss and acc of batch 7: 48.05353927612305, 1.0\n",
      "Train loss and acc of batch 8: 48.64922332763672, 0.984375\n",
      "Train loss and acc of batch 9: 48.33937072753906, 0.984375\n",
      "Train loss and acc of batch 10: 48.05350875854492, 1.0\n",
      "Train loss and acc of batch 11: 48.053497314453125, 1.0\n",
      "Train loss and acc of batch 12: 48.80671691894531, 0.984375\n",
      "Train loss and acc of batch 13: 48.27024841308594, 0.984375\n",
      "Train loss and acc of batch 14: 48.270240783691406, 0.984375\n",
      "Train loss and acc of batch 15: 48.64916229248047, 0.984375\n",
      "Train loss and acc of batch 16: 48.64915466308594, 0.984375\n",
      "Train loss and acc of batch 17: 48.80666732788086, 0.984375\n",
      "Train loss and acc of batch 18: 48.93498992919922, 0.96875\n",
      "Train loss and acc of batch 19: 48.053428649902344, 1.0\n",
      "Train loss and acc of batch 20: 48.05342102050781, 1.0\n",
      "Train loss and acc of batch 21: 48.64910888671875, 0.984375\n",
      "Train loss and acc of batch 22: 48.64910125732422, 0.984375\n",
      "Train loss and acc of batch 23: 48.27015686035156, 0.984375\n",
      "Train loss and acc of batch 24: 48.649078369140625, 0.984375\n",
      "Train loss and acc of batch 25: 48.053375244140625, 1.0\n",
      "Train loss and acc of batch 26: 48.053367614746094, 1.0\n",
      "Train loss and acc of batch 27: 48.05335998535156, 1.0\n",
      "Train loss and acc of batch 28: 48.053348541259766, 1.0\n",
      "Train loss and acc of batch 29: 48.64904022216797, 0.984375\n",
      "Train loss and acc of batch 30: 48.05332946777344, 1.0\n",
      "Train loss and acc of batch 31: 48.27008819580078, 0.984375\n",
      "Train loss and acc of batch 32: 48.05331039428711, 1.0\n",
      "Train loss and acc of batch 33: 48.05329895019531, 1.0\n",
      "Train loss and acc of batch 34: 48.64899444580078, 0.984375\n",
      "Train loss and acc of batch 35: 48.48681640625, 0.96875\n",
      "Train loss and acc of batch 36: 48.05327224731445, 1.0\n",
      "Train loss and acc of batch 37: 48.806488037109375, 0.984375\n",
      "Train loss and acc of batch 38: 49.40217590332031, 0.96875\n",
      "Train loss and acc of batch 39: 48.27001190185547, 0.984375\n",
      "Train loss and acc of batch 40: 48.05324172973633, 1.0\n",
      "Train loss and acc of batch 41: 49.40216064453125, 0.96875\n",
      "Train loss and acc of batch 42: 48.05322265625, 1.0\n",
      "Train loss and acc of batch 43: 48.64891052246094, 0.984375\n",
      "Train loss and acc of batch 44: 48.05320358276367, 1.0\n",
      "Train loss and acc of batch 45: 48.648895263671875, 0.984375\n",
      "Train loss and acc of batch 46: 48.33903503417969, 0.984375\n",
      "Train loss and acc of batch 47: 48.05317687988281, 1.0\n",
      "Train loss and acc of batch 48: 48.05316925048828, 1.0\n",
      "Train loss and acc of batch 49: 48.053157806396484, 1.0\n",
      "Train loss and acc of batch 50: 48.64884948730469, 0.984375\n",
      "Train loss and acc of batch 51: 49.402069091796875, 0.96875\n",
      "Train loss and acc of batch 52: 49.3089714050293, 0.953125\n",
      "Train loss and acc of batch 53: 48.053123474121094, 1.0\n",
      "Train loss and acc of batch 54: 48.26988220214844, 0.984375\n",
      "Train loss and acc of batch 55: 48.0531005859375, 1.0\n",
      "Train loss and acc of batch 56: 48.053096771240234, 1.0\n",
      "Train loss and acc of batch 57: 48.64878845214844, 0.984375\n",
      "Train loss and acc of batch 58: 48.05308151245117, 1.0\n",
      "Train loss and acc of batch 59: 48.053070068359375, 1.0\n",
      "Train loss and acc of batch 60: 48.053062438964844, 1.0\n",
      "Train loss and acc of batch 61: 48.05304718017578, 1.0\n",
      "Train loss and acc of batch 62: 48.269813537597656, 0.984375\n",
      "Train loss and acc of batch 63: 49.24443435668945, 0.96875\n",
      "Train loss and acc of batch 64: 48.26979064941406, 0.984375\n",
      "Train loss and acc of batch 65: 48.053016662597656, 1.0\n",
      "Train loss and acc of batch 66: 48.05300521850586, 1.0\n",
      "Train loss and acc of batch 67: 48.86545944213867, 0.96875\n",
      "Train loss and acc of batch 68: 48.64868927001953, 0.984375\n",
      "Train loss and acc of batch 69: 48.269744873046875, 0.984375\n",
      "Train loss and acc of batch 70: 48.052974700927734, 1.0\n",
      "Training accuracy and loss of epoch #9: 0.9890, 48.3843\n",
      "Saved model by train loss 48.38429985583668\n",
      "Train loss and acc of batch 0: 48.05295944213867, 1.0\n",
      "Train loss and acc of batch 1: 48.052955627441406, 1.0\n",
      "Train loss and acc of batch 2: 48.33879852294922, 0.984375\n",
      "Train loss and acc of batch 3: 48.269691467285156, 0.984375\n",
      "Train loss and acc of batch 4: 48.05292510986328, 1.0\n",
      "Train loss and acc of batch 5: 49.40184020996094, 0.96875\n",
      "Train loss and acc of batch 6: 48.55552673339844, 0.96875\n",
      "Train loss and acc of batch 7: 48.05289840698242, 1.0\n",
      "Train loss and acc of batch 8: 48.648590087890625, 0.984375\n",
      "Train loss and acc of batch 9: 48.33872985839844, 0.984375\n",
      "Train loss and acc of batch 10: 48.05287551879883, 1.0\n",
      "Train loss and acc of batch 11: 48.0528678894043, 1.0\n",
      "Train loss and acc of batch 12: 48.80607604980469, 0.984375\n",
      "Train loss and acc of batch 13: 48.26960754394531, 0.984375\n",
      "Train loss and acc of batch 14: 48.26960754394531, 0.984375\n",
      "Train loss and acc of batch 15: 48.648529052734375, 0.984375\n",
      "Train loss and acc of batch 16: 48.648521423339844, 0.984375\n",
      "Train loss and acc of batch 17: 48.8060302734375, 0.984375\n",
      "Train loss and acc of batch 18: 48.93435287475586, 0.96875\n",
      "Train loss and acc of batch 19: 48.052791595458984, 1.0\n",
      "Train loss and acc of batch 20: 48.05278396606445, 1.0\n",
      "Train loss and acc of batch 21: 48.648475646972656, 0.984375\n",
      "Train loss and acc of batch 22: 48.648468017578125, 0.984375\n",
      "Train loss and acc of batch 23: 48.26951599121094, 0.984375\n",
      "Train loss and acc of batch 24: 48.64845275878906, 0.984375\n",
      "Train loss and acc of batch 25: 48.052738189697266, 1.0\n",
      "Train loss and acc of batch 26: 48.05272674560547, 1.0\n",
      "Train loss and acc of batch 27: 48.05271911621094, 1.0\n",
      "Train loss and acc of batch 28: 48.05270767211914, 1.0\n",
      "Train loss and acc of batch 29: 48.648406982421875, 0.984375\n",
      "Train loss and acc of batch 30: 48.05269241333008, 1.0\n",
      "Train loss and acc of batch 31: 48.269447326660156, 0.984375\n",
      "Train loss and acc of batch 32: 48.05267333984375, 1.0\n",
      "Train loss and acc of batch 33: 48.05266571044922, 1.0\n",
      "Train loss and acc of batch 34: 48.64836120605469, 0.984375\n",
      "Train loss and acc of batch 35: 48.48617935180664, 0.96875\n",
      "Train loss and acc of batch 36: 48.05263900756836, 1.0\n",
      "Train loss and acc of batch 37: 48.80585479736328, 0.984375\n",
      "Train loss and acc of batch 38: 49.40155029296875, 0.96875\n",
      "Train loss and acc of batch 39: 48.269378662109375, 0.984375\n",
      "Train loss and acc of batch 40: 48.0526008605957, 1.0\n",
      "Train loss and acc of batch 41: 49.40152359008789, 0.96875\n",
      "Train loss and acc of batch 42: 48.052581787109375, 1.0\n",
      "Train loss and acc of batch 43: 48.648284912109375, 0.984375\n",
      "Train loss and acc of batch 44: 48.05257034301758, 1.0\n",
      "Train loss and acc of batch 45: 48.64825439453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.338401794433594, 0.984375\n",
      "Train loss and acc of batch 47: 48.05253982543945, 1.0\n",
      "Train loss and acc of batch 48: 48.05253219604492, 1.0\n",
      "Train loss and acc of batch 49: 48.05252456665039, 1.0\n",
      "Train loss and acc of batch 50: 48.648216247558594, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 51: 49.40142822265625, 0.96875\n",
      "Train loss and acc of batch 52: 49.3083381652832, 0.953125\n",
      "Train loss and acc of batch 53: 48.052490234375, 1.0\n",
      "Train loss and acc of batch 54: 48.26924133300781, 0.984375\n",
      "Train loss and acc of batch 55: 48.05247116088867, 1.0\n",
      "Train loss and acc of batch 56: 48.052459716796875, 1.0\n",
      "Train loss and acc of batch 57: 48.648155212402344, 0.984375\n",
      "Train loss and acc of batch 58: 48.05244445800781, 1.0\n",
      "Train loss and acc of batch 59: 48.05242919921875, 1.0\n",
      "Train loss and acc of batch 60: 48.052425384521484, 1.0\n",
      "Train loss and acc of batch 61: 48.05241775512695, 1.0\n",
      "Train loss and acc of batch 62: 48.26917266845703, 0.984375\n",
      "Train loss and acc of batch 63: 49.243797302246094, 0.96875\n",
      "Train loss and acc of batch 64: 48.26915740966797, 0.984375\n",
      "Train loss and acc of batch 65: 48.0523796081543, 1.0\n",
      "Train loss and acc of batch 66: 48.052371978759766, 1.0\n",
      "Train loss and acc of batch 67: 48.864830017089844, 0.96875\n",
      "Train loss and acc of batch 68: 48.64805603027344, 0.984375\n",
      "Train loss and acc of batch 69: 48.26911163330078, 0.984375\n",
      "Train loss and acc of batch 70: 48.05233383178711, 1.0\n",
      "Training accuracy and loss of epoch #10: 0.9890, 48.3837\n",
      "Saved model by train loss 48.38366414459659\n",
      "Train loss and acc of batch 0: 48.052330017089844, 1.0\n",
      "Train loss and acc of batch 1: 48.05231857299805, 1.0\n",
      "Train loss and acc of batch 2: 48.338157653808594, 0.984375\n",
      "Train loss and acc of batch 3: 48.269065856933594, 0.984375\n",
      "Train loss and acc of batch 4: 48.05229187011719, 1.0\n",
      "Train loss and acc of batch 5: 49.401206970214844, 0.96875\n",
      "Train loss and acc of batch 6: 48.55488967895508, 0.96875\n",
      "Train loss and acc of batch 7: 48.052268981933594, 1.0\n",
      "Train loss and acc of batch 8: 48.64795684814453, 0.984375\n",
      "Train loss and acc of batch 9: 48.338104248046875, 0.984375\n",
      "Train loss and acc of batch 10: 48.0522346496582, 1.0\n",
      "Train loss and acc of batch 11: 48.05222702026367, 1.0\n",
      "Train loss and acc of batch 12: 48.805442810058594, 0.984375\n",
      "Train loss and acc of batch 13: 48.26897430419922, 0.984375\n",
      "Train loss and acc of batch 14: 48.26896667480469, 0.984375\n",
      "Train loss and acc of batch 15: 48.64788818359375, 0.984375\n",
      "Train loss and acc of batch 16: 48.64788818359375, 0.984375\n",
      "Train loss and acc of batch 17: 48.805397033691406, 0.984375\n",
      "Train loss and acc of batch 18: 48.933719635009766, 0.96875\n",
      "Train loss and acc of batch 19: 48.052154541015625, 1.0\n",
      "Train loss and acc of batch 20: 48.052146911621094, 1.0\n",
      "Train loss and acc of batch 21: 48.64784240722656, 0.984375\n",
      "Train loss and acc of batch 22: 48.64783477783203, 0.984375\n",
      "Train loss and acc of batch 23: 48.268890380859375, 0.984375\n",
      "Train loss and acc of batch 24: 48.64781951904297, 0.984375\n",
      "Train loss and acc of batch 25: 48.052101135253906, 1.0\n",
      "Train loss and acc of batch 26: 48.052093505859375, 1.0\n",
      "Train loss and acc of batch 27: 48.05208206176758, 1.0\n",
      "Train loss and acc of batch 28: 48.05207824707031, 1.0\n",
      "Train loss and acc of batch 29: 48.64777374267578, 0.984375\n",
      "Train loss and acc of batch 30: 48.052059173583984, 1.0\n",
      "Train loss and acc of batch 31: 48.26881408691406, 0.984375\n",
      "Train loss and acc of batch 32: 48.052040100097656, 1.0\n",
      "Train loss and acc of batch 33: 48.05202865600586, 1.0\n",
      "Train loss and acc of batch 34: 48.647727966308594, 0.984375\n",
      "Train loss and acc of batch 35: 48.48554229736328, 0.96875\n",
      "Train loss and acc of batch 36: 48.052005767822266, 1.0\n",
      "Train loss and acc of batch 37: 48.80522155761719, 0.984375\n",
      "Train loss and acc of batch 38: 49.400909423828125, 0.96875\n",
      "Train loss and acc of batch 39: 48.26873779296875, 0.984375\n",
      "Train loss and acc of batch 40: 48.05196762084961, 1.0\n",
      "Train loss and acc of batch 41: 49.40088653564453, 0.96875\n",
      "Train loss and acc of batch 42: 48.05195236206055, 1.0\n",
      "Train loss and acc of batch 43: 48.64764404296875, 0.984375\n",
      "Train loss and acc of batch 44: 48.05193328857422, 1.0\n",
      "Train loss and acc of batch 45: 48.64762878417969, 0.984375\n",
      "Train loss and acc of batch 46: 48.3377685546875, 0.984375\n",
      "Train loss and acc of batch 47: 48.05190658569336, 1.0\n",
      "Train loss and acc of batch 48: 48.05189514160156, 1.0\n",
      "Train loss and acc of batch 49: 48.05188751220703, 1.0\n",
      "Train loss and acc of batch 50: 48.6475830078125, 0.984375\n",
      "Train loss and acc of batch 51: 49.400794982910156, 0.96875\n",
      "Train loss and acc of batch 52: 49.307708740234375, 0.953125\n",
      "Train loss and acc of batch 53: 48.05185317993164, 1.0\n",
      "Train loss and acc of batch 54: 48.26860809326172, 0.984375\n",
      "Train loss and acc of batch 55: 48.05183410644531, 1.0\n",
      "Train loss and acc of batch 56: 48.05182647705078, 1.0\n",
      "Train loss and acc of batch 57: 48.64752197265625, 0.984375\n",
      "Train loss and acc of batch 58: 48.05180358886719, 1.0\n",
      "Train loss and acc of batch 59: 48.05179977416992, 1.0\n",
      "Train loss and acc of batch 60: 48.05179214477539, 1.0\n",
      "Train loss and acc of batch 61: 48.051780700683594, 1.0\n",
      "Train loss and acc of batch 62: 48.26853942871094, 0.984375\n",
      "Train loss and acc of batch 63: 49.243167877197266, 0.96875\n",
      "Train loss and acc of batch 64: 48.268516540527344, 0.984375\n",
      "Train loss and acc of batch 65: 48.05175018310547, 1.0\n",
      "Train loss and acc of batch 66: 48.051734924316406, 1.0\n",
      "Train loss and acc of batch 67: 48.864192962646484, 0.96875\n",
      "Train loss and acc of batch 68: 48.64741516113281, 0.984375\n",
      "Train loss and acc of batch 69: 48.268470764160156, 0.984375\n",
      "Train loss and acc of batch 70: 48.051700592041016, 1.0\n",
      "Training accuracy and loss of epoch #11: 0.9890, 48.3830\n",
      "Saved model by train loss 48.38302956164723\n",
      "Train loss and acc of batch 0: 48.05168914794922, 1.0\n",
      "Train loss and acc of batch 1: 48.05168151855469, 1.0\n",
      "Train loss and acc of batch 2: 48.33753204345703, 0.984375\n",
      "Train loss and acc of batch 3: 48.2684326171875, 0.984375\n",
      "Train loss and acc of batch 4: 48.05165481567383, 1.0\n",
      "Train loss and acc of batch 5: 49.40057373046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.55424880981445, 0.96875\n",
      "Train loss and acc of batch 7: 48.051631927490234, 1.0\n",
      "Train loss and acc of batch 8: 48.64733123779297, 0.984375\n",
      "Train loss and acc of batch 9: 48.33746337890625, 0.984375\n",
      "Train loss and acc of batch 10: 48.05160140991211, 1.0\n",
      "Train loss and acc of batch 11: 48.05159378051758, 1.0\n",
      "Train loss and acc of batch 12: 48.804805755615234, 0.984375\n",
      "Train loss and acc of batch 13: 48.268341064453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.26832580566406, 0.984375\n",
      "Train loss and acc of batch 15: 48.647254943847656, 0.984375\n",
      "Train loss and acc of batch 16: 48.647247314453125, 0.984375\n",
      "Train loss and acc of batch 17: 48.80476760864258, 0.984375\n",
      "Train loss and acc of batch 18: 48.933082580566406, 0.96875\n",
      "Train loss and acc of batch 19: 48.0515251159668, 1.0\n",
      "Train loss and acc of batch 20: 48.051513671875, 1.0\n",
      "Train loss and acc of batch 21: 48.64720916748047, 0.984375\n",
      "Train loss and acc of batch 22: 48.64720153808594, 0.984375\n",
      "Train loss and acc of batch 23: 48.26824951171875, 0.984375\n",
      "Train loss and acc of batch 24: 48.647178649902344, 0.984375\n",
      "Train loss and acc of batch 25: 48.05146789550781, 1.0\n",
      "Train loss and acc of batch 26: 48.051456451416016, 1.0\n",
      "Train loss and acc of batch 27: 48.05145263671875, 1.0\n",
      "Train loss and acc of batch 28: 48.05144119262695, 1.0\n",
      "Train loss and acc of batch 29: 48.647132873535156, 0.984375\n",
      "Train loss and acc of batch 30: 48.05142593383789, 1.0\n",
      "Train loss and acc of batch 31: 48.26818084716797, 0.984375\n",
      "Train loss and acc of batch 32: 48.05140686035156, 1.0\n",
      "Train loss and acc of batch 33: 48.05139923095703, 1.0\n",
      "Train loss and acc of batch 34: 48.64708709716797, 0.984375\n",
      "Train loss and acc of batch 35: 48.48490905761719, 0.96875\n",
      "Train loss and acc of batch 36: 48.05137252807617, 1.0\n",
      "Train loss and acc of batch 37: 48.80458450317383, 0.984375\n",
      "Train loss and acc of batch 38: 49.40027618408203, 0.96875\n",
      "Train loss and acc of batch 39: 48.268104553222656, 0.984375\n",
      "Train loss and acc of batch 40: 48.051334381103516, 1.0\n",
      "Train loss and acc of batch 41: 49.40025329589844, 0.96875\n",
      "Train loss and acc of batch 42: 48.05131530761719, 1.0\n",
      "Train loss and acc of batch 43: 48.647010803222656, 0.984375\n",
      "Train loss and acc of batch 44: 48.051300048828125, 1.0\n",
      "Train loss and acc of batch 45: 48.646995544433594, 0.984375\n",
      "Train loss and acc of batch 46: 48.337135314941406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 48.051273345947266, 1.0\n",
      "Train loss and acc of batch 48: 48.0512580871582, 1.0\n",
      "Train loss and acc of batch 49: 48.05125427246094, 1.0\n",
      "Train loss and acc of batch 50: 48.646949768066406, 0.984375\n",
      "Train loss and acc of batch 51: 49.40015411376953, 0.96875\n",
      "Train loss and acc of batch 52: 49.307071685791016, 0.953125\n",
      "Train loss and acc of batch 53: 48.05121612548828, 1.0\n",
      "Train loss and acc of batch 54: 48.267974853515625, 0.984375\n",
      "Train loss and acc of batch 55: 48.05119705200195, 1.0\n",
      "Train loss and acc of batch 56: 48.05118942260742, 1.0\n",
      "Train loss and acc of batch 57: 48.646881103515625, 0.984375\n",
      "Train loss and acc of batch 58: 48.051177978515625, 1.0\n",
      "Train loss and acc of batch 59: 48.05116271972656, 1.0\n",
      "Train loss and acc of batch 60: 48.0511589050293, 1.0\n",
      "Train loss and acc of batch 61: 48.0511474609375, 1.0\n",
      "Train loss and acc of batch 62: 48.26789855957031, 0.984375\n",
      "Train loss and acc of batch 63: 49.242530822753906, 0.96875\n",
      "Train loss and acc of batch 64: 48.26788330078125, 0.984375\n",
      "Train loss and acc of batch 65: 48.051109313964844, 1.0\n",
      "Train loss and acc of batch 66: 48.05110549926758, 1.0\n",
      "Train loss and acc of batch 67: 48.86355972290039, 0.96875\n",
      "Train loss and acc of batch 68: 48.64678955078125, 0.984375\n",
      "Train loss and acc of batch 69: 48.267845153808594, 0.984375\n",
      "Train loss and acc of batch 70: 48.051063537597656, 1.0\n",
      "Training accuracy and loss of epoch #12: 0.9890, 48.3824\n",
      "Saved model by train loss 48.38239481751348\n",
      "Train loss and acc of batch 0: 48.051055908203125, 1.0\n",
      "Train loss and acc of batch 1: 48.051048278808594, 1.0\n",
      "Train loss and acc of batch 2: 48.336891174316406, 0.984375\n",
      "Train loss and acc of batch 3: 48.267799377441406, 0.984375\n",
      "Train loss and acc of batch 4: 48.051025390625, 1.0\n",
      "Train loss and acc of batch 5: 49.399932861328125, 0.96875\n",
      "Train loss and acc of batch 6: 48.55362319946289, 0.96875\n",
      "Train loss and acc of batch 7: 48.05099105834961, 1.0\n",
      "Train loss and acc of batch 8: 48.64668273925781, 0.984375\n",
      "Train loss and acc of batch 9: 48.336830139160156, 0.984375\n",
      "Train loss and acc of batch 10: 48.050968170166016, 1.0\n",
      "Train loss and acc of batch 11: 48.050960540771484, 1.0\n",
      "Train loss and acc of batch 12: 48.804168701171875, 0.984375\n",
      "Train loss and acc of batch 13: 48.2677001953125, 0.984375\n",
      "Train loss and acc of batch 14: 48.26769256591797, 0.984375\n",
      "Train loss and acc of batch 15: 48.646629333496094, 0.984375\n",
      "Train loss and acc of batch 16: 48.64661407470703, 0.984375\n",
      "Train loss and acc of batch 17: 48.80413055419922, 0.984375\n",
      "Train loss and acc of batch 18: 48.93245315551758, 0.96875\n",
      "Train loss and acc of batch 19: 48.05088806152344, 1.0\n",
      "Train loss and acc of batch 20: 48.050880432128906, 1.0\n",
      "Train loss and acc of batch 21: 48.646568298339844, 0.984375\n",
      "Train loss and acc of batch 22: 48.64656066894531, 0.984375\n",
      "Train loss and acc of batch 23: 48.267616271972656, 0.984375\n",
      "Train loss and acc of batch 24: 48.64654541015625, 0.984375\n",
      "Train loss and acc of batch 25: 48.05083465576172, 1.0\n",
      "Train loss and acc of batch 26: 48.05083084106445, 1.0\n",
      "Train loss and acc of batch 27: 48.05081558227539, 1.0\n",
      "Train loss and acc of batch 28: 48.050804138183594, 1.0\n",
      "Train loss and acc of batch 29: 48.64649963378906, 0.984375\n",
      "Train loss and acc of batch 30: 48.05078887939453, 1.0\n",
      "Train loss and acc of batch 31: 48.267547607421875, 0.984375\n",
      "Train loss and acc of batch 32: 48.0507698059082, 1.0\n",
      "Train loss and acc of batch 33: 48.05076217651367, 1.0\n",
      "Train loss and acc of batch 34: 48.646453857421875, 0.984375\n",
      "Train loss and acc of batch 35: 48.48427200317383, 0.96875\n",
      "Train loss and acc of batch 36: 48.05073165893555, 1.0\n",
      "Train loss and acc of batch 37: 48.803951263427734, 0.984375\n",
      "Train loss and acc of batch 38: 49.39964294433594, 0.96875\n",
      "Train loss and acc of batch 39: 48.267478942871094, 0.984375\n",
      "Train loss and acc of batch 40: 48.050697326660156, 1.0\n",
      "Train loss and acc of batch 41: 49.399620056152344, 0.96875\n",
      "Train loss and acc of batch 42: 48.05067825317383, 1.0\n",
      "Train loss and acc of batch 43: 48.64636993408203, 0.984375\n",
      "Train loss and acc of batch 44: 48.050662994384766, 1.0\n",
      "Train loss and acc of batch 45: 48.64635467529297, 0.984375\n",
      "Train loss and acc of batch 46: 48.33650207519531, 0.984375\n",
      "Train loss and acc of batch 47: 48.050636291503906, 1.0\n",
      "Train loss and acc of batch 48: 48.050628662109375, 1.0\n",
      "Train loss and acc of batch 49: 48.05061721801758, 1.0\n",
      "Train loss and acc of batch 50: 48.64630889892578, 0.984375\n",
      "Train loss and acc of batch 51: 49.39952850341797, 0.96875\n",
      "Train loss and acc of batch 52: 49.306434631347656, 0.953125\n",
      "Train loss and acc of batch 53: 48.05058288574219, 1.0\n",
      "Train loss and acc of batch 54: 48.26734161376953, 0.984375\n",
      "Train loss and acc of batch 55: 48.050567626953125, 1.0\n",
      "Train loss and acc of batch 56: 48.05055618286133, 1.0\n",
      "Train loss and acc of batch 57: 48.64624786376953, 0.984375\n",
      "Train loss and acc of batch 58: 48.050540924072266, 1.0\n",
      "Train loss and acc of batch 59: 48.05052947998047, 1.0\n",
      "Train loss and acc of batch 60: 48.05052185058594, 1.0\n",
      "Train loss and acc of batch 61: 48.05051040649414, 1.0\n",
      "Train loss and acc of batch 62: 48.26726531982422, 0.984375\n",
      "Train loss and acc of batch 63: 49.24189376831055, 0.96875\n",
      "Train loss and acc of batch 64: 48.267250061035156, 0.984375\n",
      "Train loss and acc of batch 65: 48.05047607421875, 1.0\n",
      "Train loss and acc of batch 66: 48.05046844482422, 1.0\n",
      "Train loss and acc of batch 67: 48.86292266845703, 0.96875\n",
      "Train loss and acc of batch 68: 48.646148681640625, 0.984375\n",
      "Train loss and acc of batch 69: 48.26720428466797, 0.984375\n",
      "Train loss and acc of batch 70: 48.05043029785156, 1.0\n",
      "Training accuracy and loss of epoch #13: 0.9890, 48.3818\n",
      "Saved model by train loss 48.38175969728282\n",
      "Train loss and acc of batch 0: 48.050418853759766, 1.0\n",
      "Train loss and acc of batch 1: 48.050411224365234, 1.0\n",
      "Train loss and acc of batch 2: 48.33625793457031, 0.984375\n",
      "Train loss and acc of batch 3: 48.26715850830078, 0.984375\n",
      "Train loss and acc of batch 4: 48.050384521484375, 1.0\n",
      "Train loss and acc of batch 5: 49.39930725097656, 0.96875\n",
      "Train loss and acc of batch 6: 48.55298614501953, 0.96875\n",
      "Train loss and acc of batch 7: 48.05035400390625, 1.0\n",
      "Train loss and acc of batch 8: 48.64604949951172, 0.984375\n",
      "Train loss and acc of batch 9: 48.33618927001953, 0.984375\n",
      "Train loss and acc of batch 10: 48.05033493041992, 1.0\n",
      "Train loss and acc of batch 11: 48.05032730102539, 1.0\n",
      "Train loss and acc of batch 12: 48.80353927612305, 0.984375\n",
      "Train loss and acc of batch 13: 48.267066955566406, 0.984375\n",
      "Train loss and acc of batch 14: 48.267059326171875, 0.984375\n",
      "Train loss and acc of batch 15: 48.64598846435547, 0.984375\n",
      "Train loss and acc of batch 16: 48.64598083496094, 0.984375\n",
      "Train loss and acc of batch 17: 48.803489685058594, 0.984375\n",
      "Train loss and acc of batch 18: 48.93181610107422, 0.96875\n",
      "Train loss and acc of batch 19: 48.05025100708008, 1.0\n",
      "Train loss and acc of batch 20: 48.05024337768555, 1.0\n",
      "Train loss and acc of batch 21: 48.64593505859375, 0.984375\n",
      "Train loss and acc of batch 22: 48.64592742919922, 0.984375\n",
      "Train loss and acc of batch 23: 48.26697540283203, 0.984375\n",
      "Train loss and acc of batch 24: 48.645904541015625, 0.984375\n",
      "Train loss and acc of batch 25: 48.050193786621094, 1.0\n",
      "Train loss and acc of batch 26: 48.05018997192383, 1.0\n",
      "Train loss and acc of batch 27: 48.05017852783203, 1.0\n",
      "Train loss and acc of batch 28: 48.050174713134766, 1.0\n",
      "Train loss and acc of batch 29: 48.64585876464844, 0.984375\n",
      "Train loss and acc of batch 30: 48.05015563964844, 1.0\n",
      "Train loss and acc of batch 31: 48.26690673828125, 0.984375\n",
      "Train loss and acc of batch 32: 48.05013656616211, 1.0\n",
      "Train loss and acc of batch 33: 48.05012893676758, 1.0\n",
      "Train loss and acc of batch 34: 48.64581298828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.48363494873047, 0.96875\n",
      "Train loss and acc of batch 36: 48.05009841918945, 1.0\n",
      "Train loss and acc of batch 37: 48.803314208984375, 0.984375\n",
      "Train loss and acc of batch 38: 49.39900207519531, 0.96875\n",
      "Train loss and acc of batch 39: 48.26683807373047, 0.984375\n",
      "Train loss and acc of batch 40: 48.0500602722168, 1.0\n",
      "Train loss and acc of batch 41: 49.398983001708984, 0.96875\n",
      "Train loss and acc of batch 42: 48.05004119873047, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 43: 48.64573669433594, 0.984375\n",
      "Train loss and acc of batch 44: 48.050025939941406, 1.0\n",
      "Train loss and acc of batch 45: 48.645721435546875, 0.984375\n",
      "Train loss and acc of batch 46: 48.33586120605469, 0.984375\n",
      "Train loss and acc of batch 47: 48.05000686645508, 1.0\n",
      "Train loss and acc of batch 48: 48.04998779296875, 1.0\n",
      "Train loss and acc of batch 49: 48.04998016357422, 1.0\n",
      "Train loss and acc of batch 50: 48.64567565917969, 0.984375\n",
      "Train loss and acc of batch 51: 49.398887634277344, 0.96875\n",
      "Train loss and acc of batch 52: 49.30579376220703, 0.953125\n",
      "Train loss and acc of batch 53: 48.04994201660156, 1.0\n",
      "Train loss and acc of batch 54: 48.266700744628906, 0.984375\n",
      "Train loss and acc of batch 55: 48.049930572509766, 1.0\n",
      "Train loss and acc of batch 56: 48.04991912841797, 1.0\n",
      "Train loss and acc of batch 57: 48.645606994628906, 0.984375\n",
      "Train loss and acc of batch 58: 48.049903869628906, 1.0\n",
      "Train loss and acc of batch 59: 48.04989242553711, 1.0\n",
      "Train loss and acc of batch 60: 48.04988479614258, 1.0\n",
      "Train loss and acc of batch 61: 48.04987716674805, 1.0\n",
      "Train loss and acc of batch 62: 48.266632080078125, 0.984375\n",
      "Train loss and acc of batch 63: 49.24125671386719, 0.96875\n",
      "Train loss and acc of batch 64: 48.26660919189453, 0.984375\n",
      "Train loss and acc of batch 65: 48.04983901977539, 1.0\n",
      "Train loss and acc of batch 66: 48.04983139038086, 1.0\n",
      "Train loss and acc of batch 67: 48.862281799316406, 0.96875\n",
      "Train loss and acc of batch 68: 48.64551544189453, 0.984375\n",
      "Train loss and acc of batch 69: 48.266571044921875, 0.984375\n",
      "Train loss and acc of batch 70: 48.0497932434082, 1.0\n",
      "Training accuracy and loss of epoch #14: 0.9890, 48.3811\n",
      "Saved model by train loss 48.38112296520824\n",
      "Train loss and acc of batch 0: 48.049781799316406, 1.0\n",
      "Train loss and acc of batch 1: 48.04977798461914, 1.0\n",
      "Train loss and acc of batch 2: 48.33561706542969, 0.984375\n",
      "Train loss and acc of batch 3: 48.26652526855469, 0.984375\n",
      "Train loss and acc of batch 4: 48.04975128173828, 1.0\n",
      "Train loss and acc of batch 5: 49.39866638183594, 0.96875\n",
      "Train loss and acc of batch 6: 48.55234909057617, 0.96875\n",
      "Train loss and acc of batch 7: 48.04972457885742, 1.0\n",
      "Train loss and acc of batch 8: 48.645416259765625, 0.984375\n",
      "Train loss and acc of batch 9: 48.33555603027344, 0.984375\n",
      "Train loss and acc of batch 10: 48.0496940612793, 1.0\n",
      "Train loss and acc of batch 11: 48.049686431884766, 1.0\n",
      "Train loss and acc of batch 12: 48.80290222167969, 0.984375\n",
      "Train loss and acc of batch 13: 48.26643371582031, 0.984375\n",
      "Train loss and acc of batch 14: 48.26642608642578, 0.984375\n",
      "Train loss and acc of batch 15: 48.645355224609375, 0.984375\n",
      "Train loss and acc of batch 16: 48.64533996582031, 0.984375\n",
      "Train loss and acc of batch 17: 48.802860260009766, 0.984375\n",
      "Train loss and acc of batch 18: 48.93117904663086, 0.96875\n",
      "Train loss and acc of batch 19: 48.04961395263672, 1.0\n",
      "Train loss and acc of batch 20: 48.04960632324219, 1.0\n",
      "Train loss and acc of batch 21: 48.645294189453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.645286560058594, 0.984375\n",
      "Train loss and acc of batch 23: 48.26634216308594, 0.984375\n",
      "Train loss and acc of batch 24: 48.64527130126953, 0.984375\n",
      "Train loss and acc of batch 25: 48.049560546875, 1.0\n",
      "Train loss and acc of batch 26: 48.049556732177734, 1.0\n",
      "Train loss and acc of batch 27: 48.04954147338867, 1.0\n",
      "Train loss and acc of batch 28: 48.049537658691406, 1.0\n",
      "Train loss and acc of batch 29: 48.645225524902344, 0.984375\n",
      "Train loss and acc of batch 30: 48.04951477050781, 1.0\n",
      "Train loss and acc of batch 31: 48.266273498535156, 0.984375\n",
      "Train loss and acc of batch 32: 48.049503326416016, 1.0\n",
      "Train loss and acc of batch 33: 48.04948806762695, 1.0\n",
      "Train loss and acc of batch 34: 48.645179748535156, 0.984375\n",
      "Train loss and acc of batch 35: 48.48300552368164, 0.96875\n",
      "Train loss and acc of batch 36: 48.04946517944336, 1.0\n",
      "Train loss and acc of batch 37: 48.802677154541016, 0.984375\n",
      "Train loss and acc of batch 38: 49.39836883544922, 0.96875\n",
      "Train loss and acc of batch 39: 48.266197204589844, 0.984375\n",
      "Train loss and acc of batch 40: 48.04943084716797, 1.0\n",
      "Train loss and acc of batch 41: 49.398345947265625, 0.96875\n",
      "Train loss and acc of batch 42: 48.04941177368164, 1.0\n",
      "Train loss and acc of batch 43: 48.645103454589844, 0.984375\n",
      "Train loss and acc of batch 44: 48.04938507080078, 1.0\n",
      "Train loss and acc of batch 45: 48.64508056640625, 0.984375\n",
      "Train loss and acc of batch 46: 48.335227966308594, 0.984375\n",
      "Train loss and acc of batch 47: 48.04936218261719, 1.0\n",
      "Train loss and acc of batch 48: 48.049354553222656, 1.0\n",
      "Train loss and acc of batch 49: 48.04934310913086, 1.0\n",
      "Train loss and acc of batch 50: 48.64503479003906, 0.984375\n",
      "Train loss and acc of batch 51: 49.39825439453125, 0.96875\n",
      "Train loss and acc of batch 52: 49.305152893066406, 0.953125\n",
      "Train loss and acc of batch 53: 48.04930877685547, 1.0\n",
      "Train loss and acc of batch 54: 48.26606750488281, 0.984375\n",
      "Train loss and acc of batch 55: 48.04928970336914, 1.0\n",
      "Train loss and acc of batch 56: 48.04928207397461, 1.0\n",
      "Train loss and acc of batch 57: 48.64497375488281, 0.984375\n",
      "Train loss and acc of batch 58: 48.04926300048828, 1.0\n",
      "Train loss and acc of batch 59: 48.04925537109375, 1.0\n",
      "Train loss and acc of batch 60: 48.04924392700195, 1.0\n",
      "Train loss and acc of batch 61: 48.04923629760742, 1.0\n",
      "Train loss and acc of batch 62: 48.2659912109375, 0.984375\n",
      "Train loss and acc of batch 63: 49.240623474121094, 0.96875\n",
      "Train loss and acc of batch 64: 48.26597595214844, 0.984375\n",
      "Train loss and acc of batch 65: 48.04920196533203, 1.0\n",
      "Train loss and acc of batch 66: 48.049190521240234, 1.0\n",
      "Train loss and acc of batch 67: 48.86164855957031, 0.96875\n",
      "Train loss and acc of batch 68: 48.644874572753906, 0.984375\n",
      "Train loss and acc of batch 69: 48.26593017578125, 0.984375\n",
      "Train loss and acc of batch 70: 48.049156188964844, 1.0\n",
      "Training accuracy and loss of epoch #15: 0.9890, 48.3805\n",
      "Saved model by train loss 48.38048666295871\n",
      "Train loss and acc of batch 0: 48.04914474487305, 1.0\n",
      "Train loss and acc of batch 1: 48.049137115478516, 1.0\n",
      "Train loss and acc of batch 2: 48.334983825683594, 0.984375\n",
      "Train loss and acc of batch 3: 48.26588439941406, 0.984375\n",
      "Train loss and acc of batch 4: 48.049110412597656, 1.0\n",
      "Train loss and acc of batch 5: 49.398033142089844, 0.96875\n",
      "Train loss and acc of batch 6: 48.55170822143555, 0.96875\n",
      "Train loss and acc of batch 7: 48.04908752441406, 1.0\n",
      "Train loss and acc of batch 8: 48.644775390625, 0.984375\n",
      "Train loss and acc of batch 9: 48.33491516113281, 0.984375\n",
      "Train loss and acc of batch 10: 48.04905700683594, 1.0\n",
      "Train loss and acc of batch 11: 48.04905319213867, 1.0\n",
      "Train loss and acc of batch 12: 48.80226135253906, 0.984375\n",
      "Train loss and acc of batch 13: 48.26579284667969, 0.984375\n",
      "Train loss and acc of batch 14: 48.265785217285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.64471435546875, 0.984375\n",
      "Train loss and acc of batch 16: 48.64470672607422, 0.984375\n",
      "Train loss and acc of batch 17: 48.802215576171875, 0.984375\n",
      "Train loss and acc of batch 18: 48.930538177490234, 0.96875\n",
      "Train loss and acc of batch 19: 48.04897689819336, 1.0\n",
      "Train loss and acc of batch 20: 48.04896926879883, 1.0\n",
      "Train loss and acc of batch 21: 48.64466094970703, 0.984375\n",
      "Train loss and acc of batch 22: 48.6446533203125, 0.984375\n",
      "Train loss and acc of batch 23: 48.26570129394531, 0.984375\n",
      "Train loss and acc of batch 24: 48.64463806152344, 0.984375\n",
      "Train loss and acc of batch 25: 48.048927307128906, 1.0\n",
      "Train loss and acc of batch 26: 48.04891586303711, 1.0\n",
      "Train loss and acc of batch 27: 48.04890441894531, 1.0\n",
      "Train loss and acc of batch 28: 48.04890060424805, 1.0\n",
      "Train loss and acc of batch 29: 48.64459228515625, 0.984375\n",
      "Train loss and acc of batch 30: 48.04887771606445, 1.0\n",
      "Train loss and acc of batch 31: 48.26563262939453, 0.984375\n",
      "Train loss and acc of batch 32: 48.048858642578125, 1.0\n",
      "Train loss and acc of batch 33: 48.04885482788086, 1.0\n",
      "Train loss and acc of batch 34: 48.64454650878906, 0.984375\n",
      "Train loss and acc of batch 35: 48.482364654541016, 0.96875\n",
      "Train loss and acc of batch 36: 48.048828125, 1.0\n",
      "Train loss and acc of batch 37: 48.80203628540039, 0.984375\n",
      "Train loss and acc of batch 38: 49.397735595703125, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 39: 48.26555633544922, 0.984375\n",
      "Train loss and acc of batch 40: 48.04878616333008, 1.0\n",
      "Train loss and acc of batch 41: 49.397708892822266, 0.96875\n",
      "Train loss and acc of batch 42: 48.04877471923828, 1.0\n",
      "Train loss and acc of batch 43: 48.64446258544922, 0.984375\n",
      "Train loss and acc of batch 44: 48.04875564575195, 1.0\n",
      "Train loss and acc of batch 45: 48.644439697265625, 0.984375\n",
      "Train loss and acc of batch 46: 48.33458709716797, 0.984375\n",
      "Train loss and acc of batch 47: 48.04872512817383, 1.0\n",
      "Train loss and acc of batch 48: 48.0487174987793, 1.0\n",
      "Train loss and acc of batch 49: 48.048709869384766, 1.0\n",
      "Train loss and acc of batch 50: 48.64440155029297, 0.984375\n",
      "Train loss and acc of batch 51: 49.397613525390625, 0.96875\n",
      "Train loss and acc of batch 52: 49.30452346801758, 0.953125\n",
      "Train loss and acc of batch 53: 48.04867172241211, 1.0\n",
      "Train loss and acc of batch 54: 48.26542663574219, 0.984375\n",
      "Train loss and acc of batch 55: 48.04865646362305, 1.0\n",
      "Train loss and acc of batch 56: 48.04864501953125, 1.0\n",
      "Train loss and acc of batch 57: 48.64434051513672, 0.984375\n",
      "Train loss and acc of batch 58: 48.04862594604492, 1.0\n",
      "Train loss and acc of batch 59: 48.048614501953125, 1.0\n",
      "Train loss and acc of batch 60: 48.04861068725586, 1.0\n",
      "Train loss and acc of batch 61: 48.04860305786133, 1.0\n",
      "Train loss and acc of batch 62: 48.265357971191406, 0.984375\n",
      "Train loss and acc of batch 63: 49.239986419677734, 0.96875\n",
      "Train loss and acc of batch 64: 48.26533508300781, 0.984375\n",
      "Train loss and acc of batch 65: 48.04856872558594, 1.0\n",
      "Train loss and acc of batch 66: 48.048553466796875, 1.0\n",
      "Train loss and acc of batch 67: 48.86101150512695, 0.96875\n",
      "Train loss and acc of batch 68: 48.64424133300781, 0.984375\n",
      "Train loss and acc of batch 69: 48.265289306640625, 0.984375\n",
      "Train loss and acc of batch 70: 48.04852294921875, 1.0\n",
      "Training accuracy and loss of epoch #16: 0.9890, 48.3798\n",
      "Saved model by train loss 48.379849339874696\n",
      "Train loss and acc of batch 0: 48.04851531982422, 1.0\n",
      "Train loss and acc of batch 1: 48.048500061035156, 1.0\n",
      "Train loss and acc of batch 2: 48.33434295654297, 0.984375\n",
      "Train loss and acc of batch 3: 48.26525115966797, 0.984375\n",
      "Train loss and acc of batch 4: 48.04847717285156, 1.0\n",
      "Train loss and acc of batch 5: 49.39739227294922, 0.96875\n",
      "Train loss and acc of batch 6: 48.55107116699219, 0.96875\n",
      "Train loss and acc of batch 7: 48.0484504699707, 1.0\n",
      "Train loss and acc of batch 8: 48.644142150878906, 0.984375\n",
      "Train loss and acc of batch 9: 48.33428192138672, 0.984375\n",
      "Train loss and acc of batch 10: 48.04841995239258, 1.0\n",
      "Train loss and acc of batch 11: 48.04841232299805, 1.0\n",
      "Train loss and acc of batch 12: 48.8016242980957, 0.984375\n",
      "Train loss and acc of batch 13: 48.265159606933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.26515197753906, 0.984375\n",
      "Train loss and acc of batch 15: 48.644081115722656, 0.984375\n",
      "Train loss and acc of batch 16: 48.644065856933594, 0.984375\n",
      "Train loss and acc of batch 17: 48.80158233642578, 0.984375\n",
      "Train loss and acc of batch 18: 48.92990493774414, 0.96875\n",
      "Train loss and acc of batch 19: 48.048343658447266, 1.0\n",
      "Train loss and acc of batch 20: 48.048336029052734, 1.0\n",
      "Train loss and acc of batch 21: 48.64402770996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.644012451171875, 0.984375\n",
      "Train loss and acc of batch 23: 48.26507568359375, 0.984375\n",
      "Train loss and acc of batch 24: 48.64398956298828, 0.984375\n",
      "Train loss and acc of batch 25: 48.04828643798828, 1.0\n",
      "Train loss and acc of batch 26: 48.04827880859375, 1.0\n",
      "Train loss and acc of batch 27: 48.04826736450195, 1.0\n",
      "Train loss and acc of batch 28: 48.04826354980469, 1.0\n",
      "Train loss and acc of batch 29: 48.643951416015625, 0.984375\n",
      "Train loss and acc of batch 30: 48.048240661621094, 1.0\n",
      "Train loss and acc of batch 31: 48.26499938964844, 0.984375\n",
      "Train loss and acc of batch 32: 48.04822540283203, 1.0\n",
      "Train loss and acc of batch 33: 48.0482177734375, 1.0\n",
      "Train loss and acc of batch 34: 48.64390563964844, 0.984375\n",
      "Train loss and acc of batch 35: 48.48173141479492, 0.96875\n",
      "Train loss and acc of batch 36: 48.04819107055664, 1.0\n",
      "Train loss and acc of batch 37: 48.8014030456543, 0.984375\n",
      "Train loss and acc of batch 38: 49.3970947265625, 0.96875\n",
      "Train loss and acc of batch 39: 48.264923095703125, 0.984375\n",
      "Train loss and acc of batch 40: 48.048152923583984, 1.0\n",
      "Train loss and acc of batch 41: 49.39706802368164, 0.96875\n",
      "Train loss and acc of batch 42: 48.04813766479492, 1.0\n",
      "Train loss and acc of batch 43: 48.643829345703125, 0.984375\n",
      "Train loss and acc of batch 44: 48.048118591308594, 1.0\n",
      "Train loss and acc of batch 45: 48.64380645751953, 0.984375\n",
      "Train loss and acc of batch 46: 48.333953857421875, 0.984375\n",
      "Train loss and acc of batch 47: 48.048091888427734, 1.0\n",
      "Train loss and acc of batch 48: 48.0480842590332, 1.0\n",
      "Train loss and acc of batch 49: 48.048072814941406, 1.0\n",
      "Train loss and acc of batch 50: 48.643768310546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.39698028564453, 0.96875\n",
      "Train loss and acc of batch 52: 49.30387878417969, 0.953125\n",
      "Train loss and acc of batch 53: 48.04803466796875, 1.0\n",
      "Train loss and acc of batch 54: 48.264793395996094, 0.984375\n",
      "Train loss and acc of batch 55: 48.04801940917969, 1.0\n",
      "Train loss and acc of batch 56: 48.04800796508789, 1.0\n",
      "Train loss and acc of batch 57: 48.643699645996094, 0.984375\n",
      "Train loss and acc of batch 58: 48.04799270629883, 1.0\n",
      "Train loss and acc of batch 59: 48.04798126220703, 1.0\n",
      "Train loss and acc of batch 60: 48.047977447509766, 1.0\n",
      "Train loss and acc of batch 61: 48.04796600341797, 1.0\n",
      "Train loss and acc of batch 62: 48.26471710205078, 0.984375\n",
      "Train loss and acc of batch 63: 49.23934555053711, 0.96875\n",
      "Train loss and acc of batch 64: 48.26470184326172, 0.984375\n",
      "Train loss and acc of batch 65: 48.04793167114258, 1.0\n",
      "Train loss and acc of batch 66: 48.04792022705078, 1.0\n",
      "Train loss and acc of batch 67: 48.86037826538086, 0.96875\n",
      "Train loss and acc of batch 68: 48.64360046386719, 0.984375\n",
      "Train loss and acc of batch 69: 48.26465606689453, 0.984375\n",
      "Train loss and acc of batch 70: 48.04788589477539, 1.0\n",
      "Training accuracy and loss of epoch #17: 0.9890, 48.3792\n",
      "Saved model by train loss 48.37921330626582\n",
      "Train loss and acc of batch 0: 48.04787826538086, 1.0\n",
      "Train loss and acc of batch 1: 48.04786682128906, 1.0\n",
      "Train loss and acc of batch 2: 48.333709716796875, 0.984375\n",
      "Train loss and acc of batch 3: 48.264617919921875, 0.984375\n",
      "Train loss and acc of batch 4: 48.04784393310547, 1.0\n",
      "Train loss and acc of batch 5: 49.396751403808594, 0.96875\n",
      "Train loss and acc of batch 6: 48.55044174194336, 0.96875\n",
      "Train loss and acc of batch 7: 48.047813415527344, 1.0\n",
      "Train loss and acc of batch 8: 48.64350891113281, 0.984375\n",
      "Train loss and acc of batch 9: 48.333648681640625, 0.984375\n",
      "Train loss and acc of batch 10: 48.04778289794922, 1.0\n",
      "Train loss and acc of batch 11: 48.04777526855469, 1.0\n",
      "Train loss and acc of batch 12: 48.80099105834961, 0.984375\n",
      "Train loss and acc of batch 13: 48.2645263671875, 0.984375\n",
      "Train loss and acc of batch 14: 48.26451873779297, 0.984375\n",
      "Train loss and acc of batch 15: 48.64344024658203, 0.984375\n",
      "Train loss and acc of batch 16: 48.64344024658203, 0.984375\n",
      "Train loss and acc of batch 17: 48.80094909667969, 0.984375\n",
      "Train loss and acc of batch 18: 48.92927169799805, 0.96875\n",
      "Train loss and acc of batch 19: 48.047706604003906, 1.0\n",
      "Train loss and acc of batch 20: 48.047698974609375, 1.0\n",
      "Train loss and acc of batch 21: 48.643394470214844, 0.984375\n",
      "Train loss and acc of batch 22: 48.64337921142578, 0.984375\n",
      "Train loss and acc of batch 23: 48.264434814453125, 0.984375\n",
      "Train loss and acc of batch 24: 48.64335632324219, 0.984375\n",
      "Train loss and acc of batch 25: 48.04765701293945, 1.0\n",
      "Train loss and acc of batch 26: 48.047645568847656, 1.0\n",
      "Train loss and acc of batch 27: 48.04763412475586, 1.0\n",
      "Train loss and acc of batch 28: 48.04762268066406, 1.0\n",
      "Train loss and acc of batch 29: 48.64331817626953, 0.984375\n",
      "Train loss and acc of batch 30: 48.047607421875, 1.0\n",
      "Train loss and acc of batch 31: 48.264366149902344, 0.984375\n",
      "Train loss and acc of batch 32: 48.0475959777832, 1.0\n",
      "Train loss and acc of batch 33: 48.047584533691406, 1.0\n",
      "Train loss and acc of batch 34: 48.643272399902344, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 35: 48.48109436035156, 0.96875\n",
      "Train loss and acc of batch 36: 48.04755401611328, 1.0\n",
      "Train loss and acc of batch 37: 48.8007698059082, 0.984375\n",
      "Train loss and acc of batch 38: 49.396461486816406, 0.96875\n",
      "Train loss and acc of batch 39: 48.26429748535156, 0.984375\n",
      "Train loss and acc of batch 40: 48.04751968383789, 1.0\n",
      "Train loss and acc of batch 41: 49.39643478393555, 0.96875\n",
      "Train loss and acc of batch 42: 48.04750061035156, 1.0\n",
      "Train loss and acc of batch 43: 48.64319610595703, 0.984375\n",
      "Train loss and acc of batch 44: 48.047481536865234, 1.0\n",
      "Train loss and acc of batch 45: 48.64317321777344, 0.984375\n",
      "Train loss and acc of batch 46: 48.33332061767578, 0.984375\n",
      "Train loss and acc of batch 47: 48.04745864868164, 1.0\n",
      "Train loss and acc of batch 48: 48.047447204589844, 1.0\n",
      "Train loss and acc of batch 49: 48.04744338989258, 1.0\n",
      "Train loss and acc of batch 50: 48.64312744140625, 0.984375\n",
      "Train loss and acc of batch 51: 49.39634704589844, 0.96875\n",
      "Train loss and acc of batch 52: 49.30324935913086, 0.953125\n",
      "Train loss and acc of batch 53: 48.047401428222656, 1.0\n",
      "Train loss and acc of batch 54: 48.26416015625, 0.984375\n",
      "Train loss and acc of batch 55: 48.04738235473633, 1.0\n",
      "Train loss and acc of batch 56: 48.04737091064453, 1.0\n",
      "Train loss and acc of batch 57: 48.64306640625, 0.984375\n",
      "Train loss and acc of batch 58: 48.047359466552734, 1.0\n",
      "Train loss and acc of batch 59: 48.04734802246094, 1.0\n",
      "Train loss and acc of batch 60: 48.04734420776367, 1.0\n",
      "Train loss and acc of batch 61: 48.047332763671875, 1.0\n",
      "Train loss and acc of batch 62: 48.26408386230469, 0.984375\n",
      "Train loss and acc of batch 63: 49.23871612548828, 0.96875\n",
      "Train loss and acc of batch 64: 48.264060974121094, 0.984375\n",
      "Train loss and acc of batch 65: 48.04729461669922, 1.0\n",
      "Train loss and acc of batch 66: 48.04728698730469, 1.0\n",
      "Train loss and acc of batch 67: 48.8597412109375, 0.96875\n",
      "Train loss and acc of batch 68: 48.642974853515625, 0.984375\n",
      "Train loss and acc of batch 69: 48.26402282714844, 0.984375\n",
      "Train loss and acc of batch 70: 48.04724884033203, 1.0\n",
      "Training accuracy and loss of epoch #18: 0.9890, 48.3786\n",
      "Saved model by train loss 48.37857920686964\n",
      "Train loss and acc of batch 0: 48.0472412109375, 1.0\n",
      "Train loss and acc of batch 1: 48.04723358154297, 1.0\n",
      "Train loss and acc of batch 2: 48.33307647705078, 0.984375\n",
      "Train loss and acc of batch 3: 48.26397705078125, 0.984375\n",
      "Train loss and acc of batch 4: 48.04720687866211, 1.0\n",
      "Train loss and acc of batch 5: 49.39612579345703, 0.96875\n",
      "Train loss and acc of batch 6: 48.5498046875, 0.96875\n",
      "Train loss and acc of batch 7: 48.04717254638672, 1.0\n",
      "Train loss and acc of batch 8: 48.64287567138672, 0.984375\n",
      "Train loss and acc of batch 9: 48.33301544189453, 0.984375\n",
      "Train loss and acc of batch 10: 48.04715347290039, 1.0\n",
      "Train loss and acc of batch 11: 48.04714584350586, 1.0\n",
      "Train loss and acc of batch 12: 48.800357818603516, 0.984375\n",
      "Train loss and acc of batch 13: 48.263885498046875, 0.984375\n",
      "Train loss and acc of batch 14: 48.263877868652344, 0.984375\n",
      "Train loss and acc of batch 15: 48.64280700683594, 0.984375\n",
      "Train loss and acc of batch 16: 48.642799377441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.80030822753906, 0.984375\n",
      "Train loss and acc of batch 18: 48.92863845825195, 0.96875\n",
      "Train loss and acc of batch 19: 48.04707336425781, 1.0\n",
      "Train loss and acc of batch 20: 48.04706573486328, 1.0\n",
      "Train loss and acc of batch 21: 48.64275360107422, 0.984375\n",
      "Train loss and acc of batch 22: 48.64274597167969, 0.984375\n",
      "Train loss and acc of batch 23: 48.26380157470703, 0.984375\n",
      "Train loss and acc of batch 24: 48.642730712890625, 0.984375\n",
      "Train loss and acc of batch 25: 48.047019958496094, 1.0\n",
      "Train loss and acc of batch 26: 48.04701232910156, 1.0\n",
      "Train loss and acc of batch 27: 48.047000885009766, 1.0\n",
      "Train loss and acc of batch 28: 48.046993255615234, 1.0\n",
      "Train loss and acc of batch 29: 48.64268493652344, 0.984375\n",
      "Train loss and acc of batch 30: 48.046974182128906, 1.0\n",
      "Train loss and acc of batch 31: 48.26372528076172, 0.984375\n",
      "Train loss and acc of batch 32: 48.046958923339844, 1.0\n",
      "Train loss and acc of batch 33: 48.04694747924805, 1.0\n",
      "Train loss and acc of batch 34: 48.64263916015625, 0.984375\n",
      "Train loss and acc of batch 35: 48.48045349121094, 0.96875\n",
      "Train loss and acc of batch 36: 48.04691696166992, 1.0\n",
      "Train loss and acc of batch 37: 48.800132751464844, 0.984375\n",
      "Train loss and acc of batch 38: 49.39582824707031, 0.96875\n",
      "Train loss and acc of batch 39: 48.26365661621094, 0.984375\n",
      "Train loss and acc of batch 40: 48.04688262939453, 1.0\n",
      "Train loss and acc of batch 41: 49.39580154418945, 0.96875\n",
      "Train loss and acc of batch 42: 48.0468635559082, 1.0\n",
      "Train loss and acc of batch 43: 48.64256286621094, 0.984375\n",
      "Train loss and acc of batch 44: 48.04684829711914, 1.0\n",
      "Train loss and acc of batch 45: 48.642539978027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.332679748535156, 0.984375\n",
      "Train loss and acc of batch 47: 48.04682540893555, 1.0\n",
      "Train loss and acc of batch 48: 48.04681396484375, 1.0\n",
      "Train loss and acc of batch 49: 48.04680252075195, 1.0\n",
      "Train loss and acc of batch 50: 48.642494201660156, 0.984375\n",
      "Train loss and acc of batch 51: 49.39570617675781, 0.96875\n",
      "Train loss and acc of batch 52: 49.3026123046875, 0.953125\n",
      "Train loss and acc of batch 53: 48.04676818847656, 1.0\n",
      "Train loss and acc of batch 54: 48.263519287109375, 0.984375\n",
      "Train loss and acc of batch 55: 48.0467529296875, 1.0\n",
      "Train loss and acc of batch 56: 48.04674530029297, 1.0\n",
      "Train loss and acc of batch 57: 48.642433166503906, 0.984375\n",
      "Train loss and acc of batch 58: 48.046722412109375, 1.0\n",
      "Train loss and acc of batch 59: 48.04671096801758, 1.0\n",
      "Train loss and acc of batch 60: 48.04670333862305, 1.0\n",
      "Train loss and acc of batch 61: 48.04669952392578, 1.0\n",
      "Train loss and acc of batch 62: 48.263450622558594, 0.984375\n",
      "Train loss and acc of batch 63: 49.23808670043945, 0.96875\n",
      "Train loss and acc of batch 64: 48.263427734375, 0.984375\n",
      "Train loss and acc of batch 65: 48.04665756225586, 1.0\n",
      "Train loss and acc of batch 66: 48.046653747558594, 1.0\n",
      "Train loss and acc of batch 67: 48.85911178588867, 0.96875\n",
      "Train loss and acc of batch 68: 48.642333984375, 0.984375\n",
      "Train loss and acc of batch 69: 48.263389587402344, 0.984375\n",
      "Train loss and acc of batch 70: 48.04661560058594, 1.0\n",
      "Training accuracy and loss of epoch #19: 0.9890, 48.3779\n",
      "Saved model by train loss 48.377944140367106\n",
      "Train loss and acc of batch 0: 48.046607971191406, 1.0\n",
      "Train loss and acc of batch 1: 48.04659652709961, 1.0\n",
      "Train loss and acc of batch 2: 48.332435607910156, 0.984375\n",
      "Train loss and acc of batch 3: 48.263343811035156, 0.984375\n",
      "Train loss and acc of batch 4: 48.046573638916016, 1.0\n",
      "Train loss and acc of batch 5: 49.395484924316406, 0.96875\n",
      "Train loss and acc of batch 6: 48.54916763305664, 0.96875\n",
      "Train loss and acc of batch 7: 48.046546936035156, 1.0\n",
      "Train loss and acc of batch 8: 48.642234802246094, 0.984375\n",
      "Train loss and acc of batch 9: 48.332374572753906, 0.984375\n",
      "Train loss and acc of batch 10: 48.04651641845703, 1.0\n",
      "Train loss and acc of batch 11: 48.0465087890625, 1.0\n",
      "Train loss and acc of batch 12: 48.799720764160156, 0.984375\n",
      "Train loss and acc of batch 13: 48.26325988769531, 0.984375\n",
      "Train loss and acc of batch 14: 48.26324462890625, 0.984375\n",
      "Train loss and acc of batch 15: 48.642173767089844, 0.984375\n",
      "Train loss and acc of batch 16: 48.64216613769531, 0.984375\n",
      "Train loss and acc of batch 17: 48.79967498779297, 0.984375\n",
      "Train loss and acc of batch 18: 48.92799758911133, 0.96875\n",
      "Train loss and acc of batch 19: 48.04643630981445, 1.0\n",
      "Train loss and acc of batch 20: 48.046424865722656, 1.0\n",
      "Train loss and acc of batch 21: 48.642112731933594, 0.984375\n",
      "Train loss and acc of batch 22: 48.642112731933594, 0.984375\n",
      "Train loss and acc of batch 23: 48.263160705566406, 0.984375\n",
      "Train loss and acc of batch 24: 48.64209747314453, 0.984375\n",
      "Train loss and acc of batch 25: 48.046382904052734, 1.0\n",
      "Train loss and acc of batch 26: 48.0463752746582, 1.0\n",
      "Train loss and acc of batch 27: 48.04636764526367, 1.0\n",
      "Train loss and acc of batch 28: 48.04636001586914, 1.0\n",
      "Train loss and acc of batch 29: 48.64204406738281, 0.984375\n",
      "Train loss and acc of batch 30: 48.04634094238281, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 31: 48.263092041015625, 0.984375\n",
      "Train loss and acc of batch 32: 48.04632568359375, 1.0\n",
      "Train loss and acc of batch 33: 48.04631423950195, 1.0\n",
      "Train loss and acc of batch 34: 48.642005920410156, 0.984375\n",
      "Train loss and acc of batch 35: 48.47982406616211, 0.96875\n",
      "Train loss and acc of batch 36: 48.04628372192383, 1.0\n",
      "Train loss and acc of batch 37: 48.799495697021484, 0.984375\n",
      "Train loss and acc of batch 38: 49.39519500732422, 0.96875\n",
      "Train loss and acc of batch 39: 48.26301574707031, 0.984375\n",
      "Train loss and acc of batch 40: 48.04624938964844, 1.0\n",
      "Train loss and acc of batch 41: 49.39516830444336, 0.96875\n",
      "Train loss and acc of batch 42: 48.046234130859375, 1.0\n",
      "Train loss and acc of batch 43: 48.64192199707031, 0.984375\n",
      "Train loss and acc of batch 44: 48.04621124267578, 1.0\n",
      "Train loss and acc of batch 45: 48.64190673828125, 0.984375\n",
      "Train loss and acc of batch 46: 48.33204650878906, 0.984375\n",
      "Train loss and acc of batch 47: 48.04618835449219, 1.0\n",
      "Train loss and acc of batch 48: 48.046173095703125, 1.0\n",
      "Train loss and acc of batch 49: 48.04616928100586, 1.0\n",
      "Train loss and acc of batch 50: 48.64186096191406, 0.984375\n",
      "Train loss and acc of batch 51: 49.39507293701172, 0.96875\n",
      "Train loss and acc of batch 52: 49.30198287963867, 0.953125\n",
      "Train loss and acc of batch 53: 48.0461311340332, 1.0\n",
      "Train loss and acc of batch 54: 48.26288604736328, 0.984375\n",
      "Train loss and acc of batch 55: 48.04611587524414, 1.0\n",
      "Train loss and acc of batch 56: 48.04610824584961, 1.0\n",
      "Train loss and acc of batch 57: 48.64179992675781, 0.984375\n",
      "Train loss and acc of batch 58: 48.046085357666016, 1.0\n",
      "Train loss and acc of batch 59: 48.04607391357422, 1.0\n",
      "Train loss and acc of batch 60: 48.04606628417969, 1.0\n",
      "Train loss and acc of batch 61: 48.046058654785156, 1.0\n",
      "Train loss and acc of batch 62: 48.2628173828125, 0.984375\n",
      "Train loss and acc of batch 63: 49.23744583129883, 0.96875\n",
      "Train loss and acc of batch 64: 48.262794494628906, 0.984375\n",
      "Train loss and acc of batch 65: 48.046024322509766, 1.0\n",
      "Train loss and acc of batch 66: 48.046016693115234, 1.0\n",
      "Train loss and acc of batch 67: 48.85847091674805, 0.96875\n",
      "Train loss and acc of batch 68: 48.641700744628906, 0.984375\n",
      "Train loss and acc of batch 69: 48.26275634765625, 0.984375\n",
      "Train loss and acc of batch 70: 48.04597854614258, 1.0\n",
      "Training accuracy and loss of epoch #20: 0.9890, 48.3773\n",
      "Saved model by train loss 48.37730864403953\n",
      "Train loss and acc of batch 0: 48.04597473144531, 1.0\n",
      "Train loss and acc of batch 1: 48.04595947265625, 1.0\n",
      "Train loss and acc of batch 2: 48.33180236816406, 0.984375\n",
      "Train loss and acc of batch 3: 48.26271057128906, 0.984375\n",
      "Train loss and acc of batch 4: 48.04593276977539, 1.0\n",
      "Train loss and acc of batch 5: 49.39485168457031, 0.96875\n",
      "Train loss and acc of batch 6: 48.54853439331055, 0.96875\n",
      "Train loss and acc of batch 7: 48.0459098815918, 1.0\n",
      "Train loss and acc of batch 8: 48.6416015625, 0.984375\n",
      "Train loss and acc of batch 9: 48.33174133300781, 0.984375\n",
      "Train loss and acc of batch 10: 48.04587936401367, 1.0\n",
      "Train loss and acc of batch 11: 48.045875549316406, 1.0\n",
      "Train loss and acc of batch 12: 48.79908752441406, 0.984375\n",
      "Train loss and acc of batch 13: 48.26261901855469, 0.984375\n",
      "Train loss and acc of batch 14: 48.262611389160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.64153289794922, 0.984375\n",
      "Train loss and acc of batch 16: 48.64153289794922, 0.984375\n",
      "Train loss and acc of batch 17: 48.799041748046875, 0.984375\n",
      "Train loss and acc of batch 18: 48.92736053466797, 0.96875\n",
      "Train loss and acc of batch 19: 48.04580307006836, 1.0\n",
      "Train loss and acc of batch 20: 48.04579162597656, 1.0\n",
      "Train loss and acc of batch 21: 48.64148712158203, 0.984375\n",
      "Train loss and acc of batch 22: 48.6414794921875, 0.984375\n",
      "Train loss and acc of batch 23: 48.26252746582031, 0.984375\n",
      "Train loss and acc of batch 24: 48.641456604003906, 0.984375\n",
      "Train loss and acc of batch 25: 48.045745849609375, 1.0\n",
      "Train loss and acc of batch 26: 48.045738220214844, 1.0\n",
      "Train loss and acc of batch 27: 48.04573059082031, 1.0\n",
      "Train loss and acc of batch 28: 48.04572296142578, 1.0\n",
      "Train loss and acc of batch 29: 48.64141082763672, 0.984375\n",
      "Train loss and acc of batch 30: 48.04570007324219, 1.0\n",
      "Train loss and acc of batch 31: 48.26245880126953, 0.984375\n",
      "Train loss and acc of batch 32: 48.045684814453125, 1.0\n",
      "Train loss and acc of batch 33: 48.04567337036133, 1.0\n",
      "Train loss and acc of batch 34: 48.64136505126953, 0.984375\n",
      "Train loss and acc of batch 35: 48.47918701171875, 0.96875\n",
      "Train loss and acc of batch 36: 48.045650482177734, 1.0\n",
      "Train loss and acc of batch 37: 48.79886245727539, 0.984375\n",
      "Train loss and acc of batch 38: 49.394554138183594, 0.96875\n",
      "Train loss and acc of batch 39: 48.26239013671875, 0.984375\n",
      "Train loss and acc of batch 40: 48.045616149902344, 1.0\n",
      "Train loss and acc of batch 41: 49.39453125, 0.96875\n",
      "Train loss and acc of batch 42: 48.045597076416016, 1.0\n",
      "Train loss and acc of batch 43: 48.64128875732422, 0.984375\n",
      "Train loss and acc of batch 44: 48.04558181762695, 1.0\n",
      "Train loss and acc of batch 45: 48.641265869140625, 0.984375\n",
      "Train loss and acc of batch 46: 48.33141326904297, 0.984375\n",
      "Train loss and acc of batch 47: 48.04554748535156, 1.0\n",
      "Train loss and acc of batch 48: 48.0455436706543, 1.0\n",
      "Train loss and acc of batch 49: 48.0455322265625, 1.0\n",
      "Train loss and acc of batch 50: 48.64122772216797, 0.984375\n",
      "Train loss and acc of batch 51: 49.394439697265625, 0.96875\n",
      "Train loss and acc of batch 52: 49.30134582519531, 0.953125\n",
      "Train loss and acc of batch 53: 48.045494079589844, 1.0\n",
      "Train loss and acc of batch 54: 48.26226043701172, 0.984375\n",
      "Train loss and acc of batch 55: 48.04547882080078, 1.0\n",
      "Train loss and acc of batch 56: 48.04547119140625, 1.0\n",
      "Train loss and acc of batch 57: 48.64115905761719, 0.984375\n",
      "Train loss and acc of batch 58: 48.04545211791992, 1.0\n",
      "Train loss and acc of batch 59: 48.045440673828125, 1.0\n",
      "Train loss and acc of batch 60: 48.045433044433594, 1.0\n",
      "Train loss and acc of batch 61: 48.04542541503906, 1.0\n",
      "Train loss and acc of batch 62: 48.262184143066406, 0.984375\n",
      "Train loss and acc of batch 63: 49.23680877685547, 0.96875\n",
      "Train loss and acc of batch 64: 48.26216125488281, 0.984375\n",
      "Train loss and acc of batch 65: 48.04539108276367, 1.0\n",
      "Train loss and acc of batch 66: 48.045379638671875, 1.0\n",
      "Train loss and acc of batch 67: 48.85783767700195, 0.96875\n",
      "Train loss and acc of batch 68: 48.64105987548828, 0.984375\n",
      "Train loss and acc of batch 69: 48.262115478515625, 0.984375\n",
      "Train loss and acc of batch 70: 48.04534149169922, 1.0\n",
      "Training accuracy and loss of epoch #21: 0.9890, 48.3767\n",
      "Saved model by train loss 48.37667330889634\n",
      "Train loss and acc of batch 0: 48.04533767700195, 1.0\n",
      "Train loss and acc of batch 1: 48.045326232910156, 1.0\n",
      "Train loss and acc of batch 2: 48.33116912841797, 0.984375\n",
      "Train loss and acc of batch 3: 48.26206970214844, 0.984375\n",
      "Train loss and acc of batch 4: 48.04530334472656, 1.0\n",
      "Train loss and acc of batch 5: 49.39421844482422, 0.96875\n",
      "Train loss and acc of batch 6: 48.54790115356445, 0.96875\n",
      "Train loss and acc of batch 7: 48.04526901245117, 1.0\n",
      "Train loss and acc of batch 8: 48.640960693359375, 0.984375\n",
      "Train loss and acc of batch 9: 48.33110809326172, 0.984375\n",
      "Train loss and acc of batch 10: 48.04524612426758, 1.0\n",
      "Train loss and acc of batch 11: 48.04523468017578, 1.0\n",
      "Train loss and acc of batch 12: 48.7984504699707, 0.984375\n",
      "Train loss and acc of batch 13: 48.261985778808594, 0.984375\n",
      "Train loss and acc of batch 14: 48.26197814941406, 0.984375\n",
      "Train loss and acc of batch 15: 48.640907287597656, 0.984375\n",
      "Train loss and acc of batch 16: 48.640892028808594, 0.984375\n",
      "Train loss and acc of batch 17: 48.798404693603516, 0.984375\n",
      "Train loss and acc of batch 18: 48.926727294921875, 0.96875\n",
      "Train loss and acc of batch 19: 48.045166015625, 1.0\n",
      "Train loss and acc of batch 20: 48.04515838623047, 1.0\n",
      "Train loss and acc of batch 21: 48.64085388183594, 0.984375\n",
      "Train loss and acc of batch 22: 48.640838623046875, 0.984375\n",
      "Train loss and acc of batch 23: 48.26189422607422, 0.984375\n",
      "Train loss and acc of batch 24: 48.64081573486328, 0.984375\n",
      "Train loss and acc of batch 25: 48.04511260986328, 1.0\n",
      "Train loss and acc of batch 26: 48.04510498046875, 1.0\n",
      "Train loss and acc of batch 27: 48.04509353637695, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 28: 48.04508590698242, 1.0\n",
      "Train loss and acc of batch 29: 48.640777587890625, 0.984375\n",
      "Train loss and acc of batch 30: 48.04506301879883, 1.0\n",
      "Train loss and acc of batch 31: 48.26182556152344, 0.984375\n",
      "Train loss and acc of batch 32: 48.04505157470703, 1.0\n",
      "Train loss and acc of batch 33: 48.0450439453125, 1.0\n",
      "Train loss and acc of batch 34: 48.64073181152344, 0.984375\n",
      "Train loss and acc of batch 35: 48.478553771972656, 0.96875\n",
      "Train loss and acc of batch 36: 48.04500961303711, 1.0\n",
      "Train loss and acc of batch 37: 48.79823303222656, 0.984375\n",
      "Train loss and acc of batch 38: 49.3939208984375, 0.96875\n",
      "Train loss and acc of batch 39: 48.261749267578125, 0.984375\n",
      "Train loss and acc of batch 40: 48.04497528076172, 1.0\n",
      "Train loss and acc of batch 41: 49.39389419555664, 0.96875\n",
      "Train loss and acc of batch 42: 48.044960021972656, 1.0\n",
      "Train loss and acc of batch 43: 48.640655517578125, 0.984375\n",
      "Train loss and acc of batch 44: 48.04494094848633, 1.0\n",
      "Train loss and acc of batch 45: 48.64063262939453, 0.984375\n",
      "Train loss and acc of batch 46: 48.330780029296875, 0.984375\n",
      "Train loss and acc of batch 47: 48.044918060302734, 1.0\n",
      "Train loss and acc of batch 48: 48.04490661621094, 1.0\n",
      "Train loss and acc of batch 49: 48.04490280151367, 1.0\n",
      "Train loss and acc of batch 50: 48.640586853027344, 0.984375\n",
      "Train loss and acc of batch 51: 49.39380645751953, 0.96875\n",
      "Train loss and acc of batch 52: 49.30071258544922, 0.953125\n",
      "Train loss and acc of batch 53: 48.04486083984375, 1.0\n",
      "Train loss and acc of batch 54: 48.261619567871094, 0.984375\n",
      "Train loss and acc of batch 55: 48.04484176635742, 1.0\n",
      "Train loss and acc of batch 56: 48.04483413696289, 1.0\n",
      "Train loss and acc of batch 57: 48.640533447265625, 0.984375\n",
      "Train loss and acc of batch 58: 48.04481887817383, 1.0\n",
      "Train loss and acc of batch 59: 48.0448112487793, 1.0\n",
      "Train loss and acc of batch 60: 48.044795989990234, 1.0\n",
      "Train loss and acc of batch 61: 48.04478454589844, 1.0\n",
      "Train loss and acc of batch 62: 48.26155090332031, 0.984375\n",
      "Train loss and acc of batch 63: 49.236175537109375, 0.96875\n",
      "Train loss and acc of batch 64: 48.26152801513672, 0.984375\n",
      "Train loss and acc of batch 65: 48.04475402832031, 1.0\n",
      "Train loss and acc of batch 66: 48.04474639892578, 1.0\n",
      "Train loss and acc of batch 67: 48.857200622558594, 0.96875\n",
      "Train loss and acc of batch 68: 48.64042663574219, 0.984375\n",
      "Train loss and acc of batch 69: 48.26148223876953, 0.984375\n",
      "Train loss and acc of batch 70: 48.04471206665039, 1.0\n",
      "Training accuracy and loss of epoch #22: 0.9890, 48.3760\n",
      "Saved model by train loss 48.37603834985008\n",
      "Train loss and acc of batch 0: 48.04470443725586, 1.0\n",
      "Train loss and acc of batch 1: 48.04469299316406, 1.0\n",
      "Train loss and acc of batch 2: 48.330535888671875, 0.984375\n",
      "Train loss and acc of batch 3: 48.261444091796875, 0.984375\n",
      "Train loss and acc of batch 4: 48.04466247558594, 1.0\n",
      "Train loss and acc of batch 5: 49.393585205078125, 0.96875\n",
      "Train loss and acc of batch 6: 48.547264099121094, 0.96875\n",
      "Train loss and acc of batch 7: 48.04463577270508, 1.0\n",
      "Train loss and acc of batch 8: 48.64032745361328, 0.984375\n",
      "Train loss and acc of batch 9: 48.330474853515625, 0.984375\n",
      "Train loss and acc of batch 10: 48.044612884521484, 1.0\n",
      "Train loss and acc of batch 11: 48.04460144042969, 1.0\n",
      "Train loss and acc of batch 12: 48.79781723022461, 0.984375\n",
      "Train loss and acc of batch 13: 48.26134490966797, 0.984375\n",
      "Train loss and acc of batch 14: 48.26134490966797, 0.984375\n",
      "Train loss and acc of batch 15: 48.64026641845703, 0.984375\n",
      "Train loss and acc of batch 16: 48.6402587890625, 0.984375\n",
      "Train loss and acc of batch 17: 48.79777526855469, 0.984375\n",
      "Train loss and acc of batch 18: 48.926090240478516, 0.96875\n",
      "Train loss and acc of batch 19: 48.044532775878906, 1.0\n",
      "Train loss and acc of batch 20: 48.044525146484375, 1.0\n",
      "Train loss and acc of batch 21: 48.64021301269531, 0.984375\n",
      "Train loss and acc of batch 22: 48.64020538330078, 0.984375\n",
      "Train loss and acc of batch 23: 48.261260986328125, 0.984375\n",
      "Train loss and acc of batch 24: 48.64018249511719, 0.984375\n",
      "Train loss and acc of batch 25: 48.04447555541992, 1.0\n",
      "Train loss and acc of batch 26: 48.04446792602539, 1.0\n",
      "Train loss and acc of batch 27: 48.04446029663086, 1.0\n",
      "Train loss and acc of batch 28: 48.044456481933594, 1.0\n",
      "Train loss and acc of batch 29: 48.64014434814453, 0.984375\n",
      "Train loss and acc of batch 30: 48.04443359375, 1.0\n",
      "Train loss and acc of batch 31: 48.261192321777344, 0.984375\n",
      "Train loss and acc of batch 32: 48.044410705566406, 1.0\n",
      "Train loss and acc of batch 33: 48.04440689086914, 1.0\n",
      "Train loss and acc of batch 34: 48.64009094238281, 0.984375\n",
      "Train loss and acc of batch 35: 48.4779167175293, 0.96875\n",
      "Train loss and acc of batch 36: 48.04438400268555, 1.0\n",
      "Train loss and acc of batch 37: 48.7975959777832, 0.984375\n",
      "Train loss and acc of batch 38: 49.393287658691406, 0.96875\n",
      "Train loss and acc of batch 39: 48.26111602783203, 0.984375\n",
      "Train loss and acc of batch 40: 48.044342041015625, 1.0\n",
      "Train loss and acc of batch 41: 49.39326095581055, 0.96875\n",
      "Train loss and acc of batch 42: 48.04432678222656, 1.0\n",
      "Train loss and acc of batch 43: 48.64002227783203, 0.984375\n",
      "Train loss and acc of batch 44: 48.044307708740234, 1.0\n",
      "Train loss and acc of batch 45: 48.63999938964844, 0.984375\n",
      "Train loss and acc of batch 46: 48.33013916015625, 0.984375\n",
      "Train loss and acc of batch 47: 48.04428482055664, 1.0\n",
      "Train loss and acc of batch 48: 48.04426956176758, 1.0\n",
      "Train loss and acc of batch 49: 48.04426193237305, 1.0\n",
      "Train loss and acc of batch 50: 48.63995361328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.39317321777344, 0.96875\n",
      "Train loss and acc of batch 52: 49.30007553100586, 0.953125\n",
      "Train loss and acc of batch 53: 48.044227600097656, 1.0\n",
      "Train loss and acc of batch 54: 48.26097869873047, 0.984375\n",
      "Train loss and acc of batch 55: 48.04420852661133, 1.0\n",
      "Train loss and acc of batch 56: 48.04420471191406, 1.0\n",
      "Train loss and acc of batch 57: 48.63988494873047, 0.984375\n",
      "Train loss and acc of batch 58: 48.04418182373047, 1.0\n",
      "Train loss and acc of batch 59: 48.04417419433594, 1.0\n",
      "Train loss and acc of batch 60: 48.04416275024414, 1.0\n",
      "Train loss and acc of batch 61: 48.044151306152344, 1.0\n",
      "Train loss and acc of batch 62: 48.26091003417969, 0.984375\n",
      "Train loss and acc of batch 63: 49.23553466796875, 0.96875\n",
      "Train loss and acc of batch 64: 48.260894775390625, 0.984375\n",
      "Train loss and acc of batch 65: 48.04412078857422, 1.0\n",
      "Train loss and acc of batch 66: 48.04411315917969, 1.0\n",
      "Train loss and acc of batch 67: 48.856571197509766, 0.96875\n",
      "Train loss and acc of batch 68: 48.639793395996094, 0.984375\n",
      "Train loss and acc of batch 69: 48.26084899902344, 0.984375\n",
      "Train loss and acc of batch 70: 48.04407501220703, 1.0\n",
      "Training accuracy and loss of epoch #23: 0.9890, 48.3754\n",
      "Saved model by train loss 48.3754035519882\n",
      "Train loss and acc of batch 0: 48.04405975341797, 1.0\n",
      "Train loss and acc of batch 1: 48.04405975341797, 1.0\n",
      "Train loss and acc of batch 2: 48.32990264892578, 0.984375\n",
      "Train loss and acc of batch 3: 48.26080322265625, 0.984375\n",
      "Train loss and acc of batch 4: 48.04403305053711, 1.0\n",
      "Train loss and acc of batch 5: 49.3929443359375, 0.96875\n",
      "Train loss and acc of batch 6: 48.546627044677734, 0.96875\n",
      "Train loss and acc of batch 7: 48.04400634765625, 1.0\n",
      "Train loss and acc of batch 8: 48.63969421386719, 0.984375\n",
      "Train loss and acc of batch 9: 48.32984161376953, 0.984375\n",
      "Train loss and acc of batch 10: 48.043975830078125, 1.0\n",
      "Train loss and acc of batch 11: 48.04397201538086, 1.0\n",
      "Train loss and acc of batch 12: 48.79718017578125, 0.984375\n",
      "Train loss and acc of batch 13: 48.260711669921875, 0.984375\n",
      "Train loss and acc of batch 14: 48.260704040527344, 0.984375\n",
      "Train loss and acc of batch 15: 48.63963317871094, 0.984375\n",
      "Train loss and acc of batch 16: 48.639625549316406, 0.984375\n",
      "Train loss and acc of batch 17: 48.79713821411133, 0.984375\n",
      "Train loss and acc of batch 18: 48.92545700073242, 0.96875\n",
      "Train loss and acc of batch 19: 48.04389572143555, 1.0\n",
      "Train loss and acc of batch 20: 48.043888092041016, 1.0\n",
      "Train loss and acc of batch 21: 48.63957977294922, 0.984375\n",
      "Train loss and acc of batch 22: 48.63957214355469, 0.984375\n",
      "Train loss and acc of batch 23: 48.26062774658203, 0.984375\n",
      "Train loss and acc of batch 24: 48.639556884765625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 25: 48.04384231567383, 1.0\n",
      "Train loss and acc of batch 26: 48.0438346862793, 1.0\n",
      "Train loss and acc of batch 27: 48.0438232421875, 1.0\n",
      "Train loss and acc of batch 28: 48.0438117980957, 1.0\n",
      "Train loss and acc of batch 29: 48.639503479003906, 0.984375\n",
      "Train loss and acc of batch 30: 48.04379653930664, 1.0\n",
      "Train loss and acc of batch 31: 48.26055145263672, 0.984375\n",
      "Train loss and acc of batch 32: 48.04377746582031, 1.0\n",
      "Train loss and acc of batch 33: 48.04376983642578, 1.0\n",
      "Train loss and acc of batch 34: 48.63946533203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.47727966308594, 0.96875\n",
      "Train loss and acc of batch 36: 48.043739318847656, 1.0\n",
      "Train loss and acc of batch 37: 48.79695510864258, 0.984375\n",
      "Train loss and acc of batch 38: 49.39264678955078, 0.96875\n",
      "Train loss and acc of batch 39: 48.26048278808594, 0.984375\n",
      "Train loss and acc of batch 40: 48.04370880126953, 1.0\n",
      "Train loss and acc of batch 41: 49.39262008666992, 0.96875\n",
      "Train loss and acc of batch 42: 48.0436897277832, 1.0\n",
      "Train loss and acc of batch 43: 48.639381408691406, 0.984375\n",
      "Train loss and acc of batch 44: 48.043670654296875, 1.0\n",
      "Train loss and acc of batch 45: 48.639366149902344, 0.984375\n",
      "Train loss and acc of batch 46: 48.329505920410156, 0.984375\n",
      "Train loss and acc of batch 47: 48.043643951416016, 1.0\n",
      "Train loss and acc of batch 48: 48.043636322021484, 1.0\n",
      "Train loss and acc of batch 49: 48.04362869262695, 1.0\n",
      "Train loss and acc of batch 50: 48.639320373535156, 0.984375\n",
      "Train loss and acc of batch 51: 49.39253234863281, 0.96875\n",
      "Train loss and acc of batch 52: 49.2994384765625, 0.953125\n",
      "Train loss and acc of batch 53: 48.04359436035156, 1.0\n",
      "Train loss and acc of batch 54: 48.260345458984375, 0.984375\n",
      "Train loss and acc of batch 55: 48.04357147216797, 1.0\n",
      "Train loss and acc of batch 56: 48.04356384277344, 1.0\n",
      "Train loss and acc of batch 57: 48.639259338378906, 0.984375\n",
      "Train loss and acc of batch 58: 48.04354476928711, 1.0\n",
      "Train loss and acc of batch 59: 48.04353713989258, 1.0\n",
      "Train loss and acc of batch 60: 48.04352569580078, 1.0\n",
      "Train loss and acc of batch 61: 48.043521881103516, 1.0\n",
      "Train loss and acc of batch 62: 48.260276794433594, 0.984375\n",
      "Train loss and acc of batch 63: 49.23490524291992, 0.96875\n",
      "Train loss and acc of batch 64: 48.26026153564453, 0.984375\n",
      "Train loss and acc of batch 65: 48.04348373413086, 1.0\n",
      "Train loss and acc of batch 66: 48.04347229003906, 1.0\n",
      "Train loss and acc of batch 67: 48.85593032836914, 0.96875\n",
      "Train loss and acc of batch 68: 48.63916015625, 0.984375\n",
      "Train loss and acc of batch 69: 48.26020812988281, 0.984375\n",
      "Train loss and acc of batch 70: 48.04343795776367, 1.0\n",
      "Training accuracy and loss of epoch #24: 0.9890, 48.3748\n",
      "Saved model by train loss 48.37476778701997\n",
      "Train loss and acc of batch 0: 48.043434143066406, 1.0\n",
      "Train loss and acc of batch 1: 48.043418884277344, 1.0\n",
      "Train loss and acc of batch 2: 48.329261779785156, 0.984375\n",
      "Train loss and acc of batch 3: 48.260169982910156, 0.984375\n",
      "Train loss and acc of batch 4: 48.04339599609375, 1.0\n",
      "Train loss and acc of batch 5: 49.392311096191406, 0.96875\n",
      "Train loss and acc of batch 6: 48.54599380493164, 0.96875\n",
      "Train loss and acc of batch 7: 48.04336929321289, 1.0\n",
      "Train loss and acc of batch 8: 48.63905334472656, 0.984375\n",
      "Train loss and acc of batch 9: 48.329200744628906, 0.984375\n",
      "Train loss and acc of batch 10: 48.04334259033203, 1.0\n",
      "Train loss and acc of batch 11: 48.0433349609375, 1.0\n",
      "Train loss and acc of batch 12: 48.79654312133789, 0.984375\n",
      "Train loss and acc of batch 13: 48.26007843017578, 0.984375\n",
      "Train loss and acc of batch 14: 48.26006317138672, 0.984375\n",
      "Train loss and acc of batch 15: 48.638999938964844, 0.984375\n",
      "Train loss and acc of batch 16: 48.63898468017578, 0.984375\n",
      "Train loss and acc of batch 17: 48.79650115966797, 0.984375\n",
      "Train loss and acc of batch 18: 48.92482376098633, 0.96875\n",
      "Train loss and acc of batch 19: 48.04326629638672, 1.0\n",
      "Train loss and acc of batch 20: 48.043251037597656, 1.0\n",
      "Train loss and acc of batch 21: 48.638938903808594, 0.984375\n",
      "Train loss and acc of batch 22: 48.63893127441406, 0.984375\n",
      "Train loss and acc of batch 23: 48.25999450683594, 0.984375\n",
      "Train loss and acc of batch 24: 48.638916015625, 0.984375\n",
      "Train loss and acc of batch 25: 48.043209075927734, 1.0\n",
      "Train loss and acc of batch 26: 48.04319381713867, 1.0\n",
      "Train loss and acc of batch 27: 48.043190002441406, 1.0\n",
      "Train loss and acc of batch 28: 48.04317855834961, 1.0\n",
      "Train loss and acc of batch 29: 48.63887023925781, 0.984375\n",
      "Train loss and acc of batch 30: 48.04315948486328, 1.0\n",
      "Train loss and acc of batch 31: 48.259918212890625, 0.984375\n",
      "Train loss and acc of batch 32: 48.04314422607422, 1.0\n",
      "Train loss and acc of batch 33: 48.04313659667969, 1.0\n",
      "Train loss and acc of batch 34: 48.638824462890625, 0.984375\n",
      "Train loss and acc of batch 35: 48.47664260864258, 0.96875\n",
      "Train loss and acc of batch 36: 48.04310607910156, 1.0\n",
      "Train loss and acc of batch 37: 48.79632568359375, 0.984375\n",
      "Train loss and acc of batch 38: 49.39201354980469, 0.96875\n",
      "Train loss and acc of batch 39: 48.259849548339844, 0.984375\n",
      "Train loss and acc of batch 40: 48.04307174682617, 1.0\n",
      "Train loss and acc of batch 41: 49.391990661621094, 0.96875\n",
      "Train loss and acc of batch 42: 48.043052673339844, 1.0\n",
      "Train loss and acc of batch 43: 48.63874053955078, 0.984375\n",
      "Train loss and acc of batch 44: 48.04303741455078, 1.0\n",
      "Train loss and acc of batch 45: 48.63872528076172, 0.984375\n",
      "Train loss and acc of batch 46: 48.32887268066406, 0.984375\n",
      "Train loss and acc of batch 47: 48.04301452636719, 1.0\n",
      "Train loss and acc of batch 48: 48.043006896972656, 1.0\n",
      "Train loss and acc of batch 49: 48.04298782348633, 1.0\n",
      "Train loss and acc of batch 50: 48.63867950439453, 0.984375\n",
      "Train loss and acc of batch 51: 49.39189910888672, 0.96875\n",
      "Train loss and acc of batch 52: 49.298805236816406, 0.953125\n",
      "Train loss and acc of batch 53: 48.0429573059082, 1.0\n",
      "Train loss and acc of batch 54: 48.25971221923828, 0.984375\n",
      "Train loss and acc of batch 55: 48.04293441772461, 1.0\n",
      "Train loss and acc of batch 56: 48.04292678833008, 1.0\n",
      "Train loss and acc of batch 57: 48.63861846923828, 0.984375\n",
      "Train loss and acc of batch 58: 48.042911529541016, 1.0\n",
      "Train loss and acc of batch 59: 48.04290008544922, 1.0\n",
      "Train loss and acc of batch 60: 48.04289245605469, 1.0\n",
      "Train loss and acc of batch 61: 48.042884826660156, 1.0\n",
      "Train loss and acc of batch 62: 48.2596435546875, 0.984375\n",
      "Train loss and acc of batch 63: 49.23427200317383, 0.96875\n",
      "Train loss and acc of batch 64: 48.259620666503906, 0.984375\n",
      "Train loss and acc of batch 65: 48.0428466796875, 1.0\n",
      "Train loss and acc of batch 66: 48.04283905029297, 1.0\n",
      "Train loss and acc of batch 67: 48.85529708862305, 0.96875\n",
      "Train loss and acc of batch 68: 48.638519287109375, 0.984375\n",
      "Train loss and acc of batch 69: 48.25958251953125, 0.984375\n",
      "Train loss and acc of batch 70: 48.04280471801758, 1.0\n",
      "Training accuracy and loss of epoch #25: 0.9890, 48.3741\n",
      "Saved model by train loss 48.374132236964265\n",
      "Train loss and acc of batch 0: 48.04279327392578, 1.0\n",
      "Train loss and acc of batch 1: 48.04278564453125, 1.0\n",
      "Train loss and acc of batch 2: 48.32862854003906, 0.984375\n",
      "Train loss and acc of batch 3: 48.25953674316406, 0.984375\n",
      "Train loss and acc of batch 4: 48.042762756347656, 1.0\n",
      "Train loss and acc of batch 5: 49.39167785644531, 0.96875\n",
      "Train loss and acc of batch 6: 48.54536056518555, 0.96875\n",
      "Train loss and acc of batch 7: 48.04273223876953, 1.0\n",
      "Train loss and acc of batch 8: 48.638427734375, 0.984375\n",
      "Train loss and acc of batch 9: 48.32856750488281, 0.984375\n",
      "Train loss and acc of batch 10: 48.04270935058594, 1.0\n",
      "Train loss and acc of batch 11: 48.042694091796875, 1.0\n",
      "Train loss and acc of batch 12: 48.7959098815918, 0.984375\n",
      "Train loss and acc of batch 13: 48.25944519042969, 0.984375\n",
      "Train loss and acc of batch 14: 48.259437561035156, 0.984375\n",
      "Train loss and acc of batch 15: 48.63835906982422, 0.984375\n",
      "Train loss and acc of batch 16: 48.63835144042969, 0.984375\n",
      "Train loss and acc of batch 17: 48.79586410522461, 0.984375\n",
      "Train loss and acc of batch 18: 48.92418670654297, 0.96875\n",
      "Train loss and acc of batch 19: 48.04262924194336, 1.0\n",
      "Train loss and acc of batch 20: 48.04261779785156, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 21: 48.6383056640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.63829803466797, 0.984375\n",
      "Train loss and acc of batch 23: 48.25935363769531, 0.984375\n",
      "Train loss and acc of batch 24: 48.638282775878906, 0.984375\n",
      "Train loss and acc of batch 25: 48.042572021484375, 1.0\n",
      "Train loss and acc of batch 26: 48.04256057739258, 1.0\n",
      "Train loss and acc of batch 27: 48.04255676269531, 1.0\n",
      "Train loss and acc of batch 28: 48.042545318603516, 1.0\n",
      "Train loss and acc of batch 29: 48.63823699951172, 0.984375\n",
      "Train loss and acc of batch 30: 48.04252624511719, 1.0\n",
      "Train loss and acc of batch 31: 48.25928497314453, 0.984375\n",
      "Train loss and acc of batch 32: 48.042510986328125, 1.0\n",
      "Train loss and acc of batch 33: 48.04249954223633, 1.0\n",
      "Train loss and acc of batch 34: 48.63819122314453, 0.984375\n",
      "Train loss and acc of batch 35: 48.47601318359375, 0.96875\n",
      "Train loss and acc of batch 36: 48.0424690246582, 1.0\n",
      "Train loss and acc of batch 37: 48.79568862915039, 0.984375\n",
      "Train loss and acc of batch 38: 49.391380310058594, 0.96875\n",
      "Train loss and acc of batch 39: 48.25920867919922, 0.984375\n",
      "Train loss and acc of batch 40: 48.04243469238281, 1.0\n",
      "Train loss and acc of batch 41: 49.391357421875, 0.96875\n",
      "Train loss and acc of batch 42: 48.042423248291016, 1.0\n",
      "Train loss and acc of batch 43: 48.63810729980469, 0.984375\n",
      "Train loss and acc of batch 44: 48.04240036010742, 1.0\n",
      "Train loss and acc of batch 45: 48.638092041015625, 0.984375\n",
      "Train loss and acc of batch 46: 48.32823181152344, 0.984375\n",
      "Train loss and acc of batch 47: 48.04237365722656, 1.0\n",
      "Train loss and acc of batch 48: 48.0423698425293, 1.0\n",
      "Train loss and acc of batch 49: 48.0423583984375, 1.0\n",
      "Train loss and acc of batch 50: 48.63804626464844, 0.984375\n",
      "Train loss and acc of batch 51: 49.391258239746094, 0.96875\n",
      "Train loss and acc of batch 52: 49.29816818237305, 0.953125\n",
      "Train loss and acc of batch 53: 48.042320251464844, 1.0\n",
      "Train loss and acc of batch 54: 48.25907897949219, 0.984375\n",
      "Train loss and acc of batch 55: 48.04230499267578, 1.0\n",
      "Train loss and acc of batch 56: 48.04229736328125, 1.0\n",
      "Train loss and acc of batch 57: 48.63798522949219, 0.984375\n",
      "Train loss and acc of batch 58: 48.04227828979492, 1.0\n",
      "Train loss and acc of batch 59: 48.04227066040039, 1.0\n",
      "Train loss and acc of batch 60: 48.042259216308594, 1.0\n",
      "Train loss and acc of batch 61: 48.0422477722168, 1.0\n",
      "Train loss and acc of batch 62: 48.259010314941406, 0.984375\n",
      "Train loss and acc of batch 63: 49.23363494873047, 0.96875\n",
      "Train loss and acc of batch 64: 48.25898742675781, 0.984375\n",
      "Train loss and acc of batch 65: 48.042213439941406, 1.0\n",
      "Train loss and acc of batch 66: 48.042205810546875, 1.0\n",
      "Train loss and acc of batch 67: 48.85466003417969, 0.96875\n",
      "Train loss and acc of batch 68: 48.63788604736328, 0.984375\n",
      "Train loss and acc of batch 69: 48.258941650390625, 0.984375\n",
      "Train loss and acc of batch 70: 48.042171478271484, 1.0\n",
      "Training accuracy and loss of epoch #26: 0.9890, 48.3735\n",
      "Saved model by train loss 48.37349770774304\n",
      "Train loss and acc of batch 0: 48.04216003417969, 1.0\n",
      "Train loss and acc of batch 1: 48.04214859008789, 1.0\n",
      "Train loss and acc of batch 2: 48.32799530029297, 0.984375\n",
      "Train loss and acc of batch 3: 48.25889587402344, 0.984375\n",
      "Train loss and acc of batch 4: 48.04212188720703, 1.0\n",
      "Train loss and acc of batch 5: 49.39103698730469, 0.96875\n",
      "Train loss and acc of batch 6: 48.54472351074219, 0.96875\n",
      "Train loss and acc of batch 7: 48.04209899902344, 1.0\n",
      "Train loss and acc of batch 8: 48.637786865234375, 0.984375\n",
      "Train loss and acc of batch 9: 48.32793426513672, 0.984375\n",
      "Train loss and acc of batch 10: 48.04207229614258, 1.0\n",
      "Train loss and acc of batch 11: 48.04206085205078, 1.0\n",
      "Train loss and acc of batch 12: 48.7952766418457, 0.984375\n",
      "Train loss and acc of batch 13: 48.258811950683594, 0.984375\n",
      "Train loss and acc of batch 14: 48.25880432128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.637725830078125, 0.984375\n",
      "Train loss and acc of batch 16: 48.637718200683594, 0.984375\n",
      "Train loss and acc of batch 17: 48.795230865478516, 0.984375\n",
      "Train loss and acc of batch 18: 48.923553466796875, 0.96875\n",
      "Train loss and acc of batch 19: 48.04198455810547, 1.0\n",
      "Train loss and acc of batch 20: 48.04198455810547, 1.0\n",
      "Train loss and acc of batch 21: 48.637672424316406, 0.984375\n",
      "Train loss and acc of batch 22: 48.637664794921875, 0.984375\n",
      "Train loss and acc of batch 23: 48.25871276855469, 0.984375\n",
      "Train loss and acc of batch 24: 48.63764190673828, 0.984375\n",
      "Train loss and acc of batch 25: 48.041934967041016, 1.0\n",
      "Train loss and acc of batch 26: 48.04193115234375, 1.0\n",
      "Train loss and acc of batch 27: 48.04191970825195, 1.0\n",
      "Train loss and acc of batch 28: 48.04191207885742, 1.0\n",
      "Train loss and acc of batch 29: 48.637603759765625, 0.984375\n",
      "Train loss and acc of batch 30: 48.041893005371094, 1.0\n",
      "Train loss and acc of batch 31: 48.258644104003906, 0.984375\n",
      "Train loss and acc of batch 32: 48.041873931884766, 1.0\n",
      "Train loss and acc of batch 33: 48.041866302490234, 1.0\n",
      "Train loss and acc of batch 34: 48.63755798339844, 0.984375\n",
      "Train loss and acc of batch 35: 48.47537612915039, 0.96875\n",
      "Train loss and acc of batch 36: 48.04183578491211, 1.0\n",
      "Train loss and acc of batch 37: 48.79505157470703, 0.984375\n",
      "Train loss and acc of batch 38: 49.3907470703125, 0.96875\n",
      "Train loss and acc of batch 39: 48.258575439453125, 0.984375\n",
      "Train loss and acc of batch 40: 48.04179763793945, 1.0\n",
      "Train loss and acc of batch 41: 49.39072036743164, 0.96875\n",
      "Train loss and acc of batch 42: 48.041778564453125, 1.0\n",
      "Train loss and acc of batch 43: 48.637474060058594, 0.984375\n",
      "Train loss and acc of batch 44: 48.0417594909668, 1.0\n",
      "Train loss and acc of batch 45: 48.637451171875, 0.984375\n",
      "Train loss and acc of batch 46: 48.327598571777344, 0.984375\n",
      "Train loss and acc of batch 47: 48.04173278808594, 1.0\n",
      "Train loss and acc of batch 48: 48.041725158691406, 1.0\n",
      "Train loss and acc of batch 49: 48.04172134399414, 1.0\n",
      "Train loss and acc of batch 50: 48.637413024902344, 0.984375\n",
      "Train loss and acc of batch 51: 49.390625, 0.96875\n",
      "Train loss and acc of batch 52: 49.29753112792969, 0.953125\n",
      "Train loss and acc of batch 53: 48.041683197021484, 1.0\n",
      "Train loss and acc of batch 54: 48.25843811035156, 0.984375\n",
      "Train loss and acc of batch 55: 48.04166793823242, 1.0\n",
      "Train loss and acc of batch 56: 48.041656494140625, 1.0\n",
      "Train loss and acc of batch 57: 48.637351989746094, 0.984375\n",
      "Train loss and acc of batch 58: 48.0416374206543, 1.0\n",
      "Train loss and acc of batch 59: 48.041629791259766, 1.0\n",
      "Train loss and acc of batch 60: 48.04161834716797, 1.0\n",
      "Train loss and acc of batch 61: 48.04160690307617, 1.0\n",
      "Train loss and acc of batch 62: 48.25836944580078, 0.984375\n",
      "Train loss and acc of batch 63: 49.232994079589844, 0.96875\n",
      "Train loss and acc of batch 64: 48.25834655761719, 0.984375\n",
      "Train loss and acc of batch 65: 48.04157257080078, 1.0\n",
      "Train loss and acc of batch 66: 48.041568756103516, 1.0\n",
      "Train loss and acc of batch 67: 48.85402297973633, 0.96875\n",
      "Train loss and acc of batch 68: 48.63725280761719, 0.984375\n",
      "Train loss and acc of batch 69: 48.25830078125, 0.984375\n",
      "Train loss and acc of batch 70: 48.04153060913086, 1.0\n",
      "Training accuracy and loss of epoch #27: 0.9890, 48.3729\n",
      "Saved model by train loss 48.37286081448407\n",
      "Train loss and acc of batch 0: 48.04152297973633, 1.0\n",
      "Train loss and acc of batch 1: 48.0415153503418, 1.0\n",
      "Train loss and acc of batch 2: 48.327354431152344, 0.984375\n",
      "Train loss and acc of batch 3: 48.258262634277344, 0.984375\n",
      "Train loss and acc of batch 4: 48.04148483276367, 1.0\n",
      "Train loss and acc of batch 5: 49.390403747558594, 0.96875\n",
      "Train loss and acc of batch 6: 48.54408645629883, 0.96875\n",
      "Train loss and acc of batch 7: 48.04145812988281, 1.0\n",
      "Train loss and acc of batch 8: 48.63715362548828, 0.984375\n",
      "Train loss and acc of batch 9: 48.327293395996094, 0.984375\n",
      "Train loss and acc of batch 10: 48.04143142700195, 1.0\n",
      "Train loss and acc of batch 11: 48.04142379760742, 1.0\n",
      "Train loss and acc of batch 12: 48.794639587402344, 0.984375\n",
      "Train loss and acc of batch 13: 48.25817108154297, 0.984375\n",
      "Train loss and acc of batch 14: 48.25816345214844, 0.984375\n",
      "Train loss and acc of batch 15: 48.63709259033203, 0.984375\n",
      "Train loss and acc of batch 16: 48.6370849609375, 0.984375\n",
      "Train loss and acc of batch 17: 48.79458999633789, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 18: 48.92291259765625, 0.96875\n",
      "Train loss and acc of batch 19: 48.041351318359375, 1.0\n",
      "Train loss and acc of batch 20: 48.041343688964844, 1.0\n",
      "Train loss and acc of batch 21: 48.63703155517578, 0.984375\n",
      "Train loss and acc of batch 22: 48.63702392578125, 0.984375\n",
      "Train loss and acc of batch 23: 48.258079528808594, 0.984375\n",
      "Train loss and acc of batch 24: 48.63700866699219, 0.984375\n",
      "Train loss and acc of batch 25: 48.041297912597656, 1.0\n",
      "Train loss and acc of batch 26: 48.04128646850586, 1.0\n",
      "Train loss and acc of batch 27: 48.04127883911133, 1.0\n",
      "Train loss and acc of batch 28: 48.0412712097168, 1.0\n",
      "Train loss and acc of batch 29: 48.636962890625, 0.984375\n",
      "Train loss and acc of batch 30: 48.041255950927734, 1.0\n",
      "Train loss and acc of batch 31: 48.25800323486328, 0.984375\n",
      "Train loss and acc of batch 32: 48.04123306274414, 1.0\n",
      "Train loss and acc of batch 33: 48.04122543334961, 1.0\n",
      "Train loss and acc of batch 34: 48.636924743652344, 0.984375\n",
      "Train loss and acc of batch 35: 48.474735260009766, 0.96875\n",
      "Train loss and acc of batch 36: 48.04119873046875, 1.0\n",
      "Train loss and acc of batch 37: 48.79441452026367, 0.984375\n",
      "Train loss and acc of batch 38: 49.390106201171875, 0.96875\n",
      "Train loss and acc of batch 39: 48.2579345703125, 0.984375\n",
      "Train loss and acc of batch 40: 48.041160583496094, 1.0\n",
      "Train loss and acc of batch 41: 49.39008331298828, 0.96875\n",
      "Train loss and acc of batch 42: 48.041141510009766, 1.0\n",
      "Train loss and acc of batch 43: 48.6368408203125, 0.984375\n",
      "Train loss and acc of batch 44: 48.04113006591797, 1.0\n",
      "Train loss and acc of batch 45: 48.636817932128906, 0.984375\n",
      "Train loss and acc of batch 46: 48.32695770263672, 0.984375\n",
      "Train loss and acc of batch 47: 48.041099548339844, 1.0\n",
      "Train loss and acc of batch 48: 48.04109191894531, 1.0\n",
      "Train loss and acc of batch 49: 48.04108428955078, 1.0\n",
      "Train loss and acc of batch 50: 48.63677215576172, 0.984375\n",
      "Train loss and acc of batch 51: 49.389991760253906, 0.96875\n",
      "Train loss and acc of batch 52: 49.29690170288086, 0.953125\n",
      "Train loss and acc of batch 53: 48.04104995727539, 1.0\n",
      "Train loss and acc of batch 54: 48.25779724121094, 0.984375\n",
      "Train loss and acc of batch 55: 48.0410270690918, 1.0\n",
      "Train loss and acc of batch 56: 48.04102325439453, 1.0\n",
      "Train loss and acc of batch 57: 48.63671112060547, 0.984375\n",
      "Train loss and acc of batch 58: 48.0410041809082, 1.0\n",
      "Train loss and acc of batch 59: 48.040992736816406, 1.0\n",
      "Train loss and acc of batch 60: 48.04098129272461, 1.0\n",
      "Train loss and acc of batch 61: 48.04097366333008, 1.0\n",
      "Train loss and acc of batch 62: 48.25773620605469, 0.984375\n",
      "Train loss and acc of batch 63: 49.23236083984375, 0.96875\n",
      "Train loss and acc of batch 64: 48.257713317871094, 0.984375\n",
      "Train loss and acc of batch 65: 48.04093933105469, 1.0\n",
      "Train loss and acc of batch 66: 48.040931701660156, 1.0\n",
      "Train loss and acc of batch 67: 48.853389739990234, 0.96875\n",
      "Train loss and acc of batch 68: 48.63661193847656, 0.984375\n",
      "Train loss and acc of batch 69: 48.257667541503906, 0.984375\n",
      "Train loss and acc of batch 70: 48.040897369384766, 1.0\n",
      "Training accuracy and loss of epoch #28: 0.9890, 48.3722\n",
      "Saved model by train loss 48.37222386749698\n",
      "Train loss and acc of batch 0: 48.040889739990234, 1.0\n",
      "Train loss and acc of batch 1: 48.04087829589844, 1.0\n",
      "Train loss and acc of batch 2: 48.32672119140625, 0.984375\n",
      "Train loss and acc of batch 3: 48.25762939453125, 0.984375\n",
      "Train loss and acc of batch 4: 48.04084777832031, 1.0\n",
      "Train loss and acc of batch 5: 49.3897705078125, 0.96875\n",
      "Train loss and acc of batch 6: 48.54344940185547, 0.96875\n",
      "Train loss and acc of batch 7: 48.04082489013672, 1.0\n",
      "Train loss and acc of batch 8: 48.63652038574219, 0.984375\n",
      "Train loss and acc of batch 9: 48.32666015625, 0.984375\n",
      "Train loss and acc of batch 10: 48.04079818725586, 1.0\n",
      "Train loss and acc of batch 11: 48.04078674316406, 1.0\n",
      "Train loss and acc of batch 12: 48.79399871826172, 0.984375\n",
      "Train loss and acc of batch 13: 48.257537841796875, 0.984375\n",
      "Train loss and acc of batch 14: 48.25752258300781, 0.984375\n",
      "Train loss and acc of batch 15: 48.63645935058594, 0.984375\n",
      "Train loss and acc of batch 16: 48.636444091796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.79396057128906, 0.984375\n",
      "Train loss and acc of batch 18: 48.922279357910156, 0.96875\n",
      "Train loss and acc of batch 19: 48.04071807861328, 1.0\n",
      "Train loss and acc of batch 20: 48.040706634521484, 1.0\n",
      "Train loss and acc of batch 21: 48.63639831542969, 0.984375\n",
      "Train loss and acc of batch 22: 48.636390686035156, 0.984375\n",
      "Train loss and acc of batch 23: 48.2574462890625, 0.984375\n",
      "Train loss and acc of batch 24: 48.636375427246094, 0.984375\n",
      "Train loss and acc of batch 25: 48.0406608581543, 1.0\n",
      "Train loss and acc of batch 26: 48.040653228759766, 1.0\n",
      "Train loss and acc of batch 27: 48.0406494140625, 1.0\n",
      "Train loss and acc of batch 28: 48.0406379699707, 1.0\n",
      "Train loss and acc of batch 29: 48.636329650878906, 0.984375\n",
      "Train loss and acc of batch 30: 48.040618896484375, 1.0\n",
      "Train loss and acc of batch 31: 48.25737762451172, 0.984375\n",
      "Train loss and acc of batch 32: 48.04059982299805, 1.0\n",
      "Train loss and acc of batch 33: 48.04058837890625, 1.0\n",
      "Train loss and acc of batch 34: 48.63628387451172, 0.984375\n",
      "Train loss and acc of batch 35: 48.47410202026367, 0.96875\n",
      "Train loss and acc of batch 36: 48.040565490722656, 1.0\n",
      "Train loss and acc of batch 37: 48.79377746582031, 0.984375\n",
      "Train loss and acc of batch 38: 49.38947296142578, 0.96875\n",
      "Train loss and acc of batch 39: 48.257301330566406, 0.984375\n",
      "Train loss and acc of batch 40: 48.04052734375, 1.0\n",
      "Train loss and acc of batch 41: 49.38944625854492, 0.96875\n",
      "Train loss and acc of batch 42: 48.04051208496094, 1.0\n",
      "Train loss and acc of batch 43: 48.636199951171875, 0.984375\n",
      "Train loss and acc of batch 44: 48.04049301147461, 1.0\n",
      "Train loss and acc of batch 45: 48.63618469238281, 0.984375\n",
      "Train loss and acc of batch 46: 48.326324462890625, 0.984375\n",
      "Train loss and acc of batch 47: 48.04046630859375, 1.0\n",
      "Train loss and acc of batch 48: 48.04045104980469, 1.0\n",
      "Train loss and acc of batch 49: 48.04044723510742, 1.0\n",
      "Train loss and acc of batch 50: 48.636138916015625, 0.984375\n",
      "Train loss and acc of batch 51: 49.38935089111328, 0.96875\n",
      "Train loss and acc of batch 52: 49.2962646484375, 0.953125\n",
      "Train loss and acc of batch 53: 48.04041290283203, 1.0\n",
      "Train loss and acc of batch 54: 48.257164001464844, 0.984375\n",
      "Train loss and acc of batch 55: 48.0403938293457, 1.0\n",
      "Train loss and acc of batch 56: 48.04038619995117, 1.0\n",
      "Train loss and acc of batch 57: 48.636077880859375, 0.984375\n",
      "Train loss and acc of batch 58: 48.040367126464844, 1.0\n",
      "Train loss and acc of batch 59: 48.04035949707031, 1.0\n",
      "Train loss and acc of batch 60: 48.040348052978516, 1.0\n",
      "Train loss and acc of batch 61: 48.040340423583984, 1.0\n",
      "Train loss and acc of batch 62: 48.25709533691406, 0.984375\n",
      "Train loss and acc of batch 63: 49.231727600097656, 0.96875\n",
      "Train loss and acc of batch 64: 48.257080078125, 0.984375\n",
      "Train loss and acc of batch 65: 48.04030990600586, 1.0\n",
      "Train loss and acc of batch 66: 48.04029846191406, 1.0\n",
      "Train loss and acc of batch 67: 48.852752685546875, 0.96875\n",
      "Train loss and acc of batch 68: 48.63597869873047, 0.984375\n",
      "Train loss and acc of batch 69: 48.25703430175781, 0.984375\n",
      "Train loss and acc of batch 70: 48.040260314941406, 1.0\n",
      "Training accuracy and loss of epoch #29: 0.9890, 48.3716\n",
      "Saved model by train loss 48.37158912336323\n",
      "Train loss and acc of batch 0: 48.04024887084961, 1.0\n",
      "Train loss and acc of batch 1: 48.04024124145508, 1.0\n",
      "Train loss and acc of batch 2: 48.326087951660156, 0.984375\n",
      "Train loss and acc of batch 3: 48.256988525390625, 0.984375\n",
      "Train loss and acc of batch 4: 48.04021453857422, 1.0\n",
      "Train loss and acc of batch 5: 49.389129638671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.542816162109375, 0.96875\n",
      "Train loss and acc of batch 7: 48.04018783569336, 1.0\n",
      "Train loss and acc of batch 8: 48.63587951660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.326019287109375, 0.984375\n",
      "Train loss and acc of batch 10: 48.040164947509766, 1.0\n",
      "Train loss and acc of batch 11: 48.04015350341797, 1.0\n",
      "Train loss and acc of batch 12: 48.793365478515625, 0.984375\n",
      "Train loss and acc of batch 13: 48.25689697265625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 14: 48.25688934326172, 0.984375\n",
      "Train loss and acc of batch 15: 48.63581848144531, 0.984375\n",
      "Train loss and acc of batch 16: 48.63581085205078, 0.984375\n",
      "Train loss and acc of batch 17: 48.7933235168457, 0.984375\n",
      "Train loss and acc of batch 18: 48.92164611816406, 0.96875\n",
      "Train loss and acc of batch 19: 48.04008483886719, 1.0\n",
      "Train loss and acc of batch 20: 48.040069580078125, 1.0\n",
      "Train loss and acc of batch 21: 48.635765075683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.63574981689453, 0.984375\n",
      "Train loss and acc of batch 23: 48.256813049316406, 0.984375\n",
      "Train loss and acc of batch 24: 48.63573455810547, 0.984375\n",
      "Train loss and acc of batch 25: 48.04003143310547, 1.0\n",
      "Train loss and acc of batch 26: 48.040016174316406, 1.0\n",
      "Train loss and acc of batch 27: 48.04001235961914, 1.0\n",
      "Train loss and acc of batch 28: 48.03999710083008, 1.0\n",
      "Train loss and acc of batch 29: 48.63569641113281, 0.984375\n",
      "Train loss and acc of batch 30: 48.03998565673828, 1.0\n",
      "Train loss and acc of batch 31: 48.256736755371094, 0.984375\n",
      "Train loss and acc of batch 32: 48.03996658325195, 1.0\n",
      "Train loss and acc of batch 33: 48.039955139160156, 1.0\n",
      "Train loss and acc of batch 34: 48.635650634765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.47346878051758, 0.96875\n",
      "Train loss and acc of batch 36: 48.0399284362793, 1.0\n",
      "Train loss and acc of batch 37: 48.79314422607422, 0.984375\n",
      "Train loss and acc of batch 38: 49.38883972167969, 0.96875\n",
      "Train loss and acc of batch 39: 48.25666809082031, 0.984375\n",
      "Train loss and acc of batch 40: 48.03989791870117, 1.0\n",
      "Train loss and acc of batch 41: 49.38881301879883, 0.96875\n",
      "Train loss and acc of batch 42: 48.03987503051758, 1.0\n",
      "Train loss and acc of batch 43: 48.63556671142578, 0.984375\n",
      "Train loss and acc of batch 44: 48.039859771728516, 1.0\n",
      "Train loss and acc of batch 45: 48.63555145263672, 0.984375\n",
      "Train loss and acc of batch 46: 48.32569122314453, 0.984375\n",
      "Train loss and acc of batch 47: 48.03982925415039, 1.0\n",
      "Train loss and acc of batch 48: 48.03982162475586, 1.0\n",
      "Train loss and acc of batch 49: 48.03981399536133, 1.0\n",
      "Train loss and acc of batch 50: 48.63550567626953, 0.984375\n",
      "Train loss and acc of batch 51: 49.38871765136719, 0.96875\n",
      "Train loss and acc of batch 52: 49.295631408691406, 0.953125\n",
      "Train loss and acc of batch 53: 48.03977966308594, 1.0\n",
      "Train loss and acc of batch 54: 48.25653839111328, 0.984375\n",
      "Train loss and acc of batch 55: 48.03976058959961, 1.0\n",
      "Train loss and acc of batch 56: 48.03974914550781, 1.0\n",
      "Train loss and acc of batch 57: 48.63544464111328, 0.984375\n",
      "Train loss and acc of batch 58: 48.039737701416016, 1.0\n",
      "Train loss and acc of batch 59: 48.03972244262695, 1.0\n",
      "Train loss and acc of batch 60: 48.03971481323242, 1.0\n",
      "Train loss and acc of batch 61: 48.03970718383789, 1.0\n",
      "Train loss and acc of batch 62: 48.25646209716797, 0.984375\n",
      "Train loss and acc of batch 63: 49.2310905456543, 0.96875\n",
      "Train loss and acc of batch 64: 48.256439208984375, 0.984375\n",
      "Train loss and acc of batch 65: 48.039669036865234, 1.0\n",
      "Train loss and acc of batch 66: 48.0396614074707, 1.0\n",
      "Train loss and acc of batch 67: 48.85211944580078, 0.96875\n",
      "Train loss and acc of batch 68: 48.635345458984375, 0.984375\n",
      "Train loss and acc of batch 69: 48.25640106201172, 0.984375\n",
      "Train loss and acc of batch 70: 48.03961944580078, 1.0\n",
      "Training accuracy and loss of epoch #30: 0.9890, 48.3710\n",
      "Saved model by train loss 48.37095400313257\n",
      "Train loss and acc of batch 0: 48.039615631103516, 1.0\n",
      "Train loss and acc of batch 1: 48.03961181640625, 1.0\n",
      "Train loss and acc of batch 2: 48.32545471191406, 0.984375\n",
      "Train loss and acc of batch 3: 48.25635528564453, 0.984375\n",
      "Train loss and acc of batch 4: 48.039581298828125, 1.0\n",
      "Train loss and acc of batch 5: 49.38849639892578, 0.96875\n",
      "Train loss and acc of batch 6: 48.54218292236328, 0.96875\n",
      "Train loss and acc of batch 7: 48.03955078125, 1.0\n",
      "Train loss and acc of batch 8: 48.63524627685547, 0.984375\n",
      "Train loss and acc of batch 9: 48.32538604736328, 0.984375\n",
      "Train loss and acc of batch 10: 48.03953170776367, 1.0\n",
      "Train loss and acc of batch 11: 48.039520263671875, 1.0\n",
      "Train loss and acc of batch 12: 48.7927360534668, 0.984375\n",
      "Train loss and acc of batch 13: 48.256263732910156, 0.984375\n",
      "Train loss and acc of batch 14: 48.256256103515625, 0.984375\n",
      "Train loss and acc of batch 15: 48.63518524169922, 0.984375\n",
      "Train loss and acc of batch 16: 48.63517761230469, 0.984375\n",
      "Train loss and acc of batch 17: 48.79269027709961, 0.984375\n",
      "Train loss and acc of batch 18: 48.9210090637207, 0.96875\n",
      "Train loss and acc of batch 19: 48.03944778442383, 1.0\n",
      "Train loss and acc of batch 20: 48.03943634033203, 1.0\n",
      "Train loss and acc of batch 21: 48.6351318359375, 0.984375\n",
      "Train loss and acc of batch 22: 48.63511657714844, 0.984375\n",
      "Train loss and acc of batch 23: 48.25617218017578, 0.984375\n",
      "Train loss and acc of batch 24: 48.635101318359375, 0.984375\n",
      "Train loss and acc of batch 25: 48.03939437866211, 1.0\n",
      "Train loss and acc of batch 26: 48.03938674926758, 1.0\n",
      "Train loss and acc of batch 27: 48.039371490478516, 1.0\n",
      "Train loss and acc of batch 28: 48.03936767578125, 1.0\n",
      "Train loss and acc of batch 29: 48.63506317138672, 0.984375\n",
      "Train loss and acc of batch 30: 48.03934860229492, 1.0\n",
      "Train loss and acc of batch 31: 48.256103515625, 0.984375\n",
      "Train loss and acc of batch 32: 48.039329528808594, 1.0\n",
      "Train loss and acc of batch 33: 48.03932189941406, 1.0\n",
      "Train loss and acc of batch 34: 48.635009765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.47282791137695, 0.96875\n",
      "Train loss and acc of batch 36: 48.03929138183594, 1.0\n",
      "Train loss and acc of batch 37: 48.792510986328125, 0.984375\n",
      "Train loss and acc of batch 38: 49.388206481933594, 0.96875\n",
      "Train loss and acc of batch 39: 48.25603485107422, 0.984375\n",
      "Train loss and acc of batch 40: 48.03926086425781, 1.0\n",
      "Train loss and acc of batch 41: 49.38817596435547, 0.96875\n",
      "Train loss and acc of batch 42: 48.03923797607422, 1.0\n",
      "Train loss and acc of batch 43: 48.63494110107422, 0.984375\n",
      "Train loss and acc of batch 44: 48.039222717285156, 1.0\n",
      "Train loss and acc of batch 45: 48.634918212890625, 0.984375\n",
      "Train loss and acc of batch 46: 48.32505798339844, 0.984375\n",
      "Train loss and acc of batch 47: 48.0391960144043, 1.0\n",
      "Train loss and acc of batch 48: 48.0391845703125, 1.0\n",
      "Train loss and acc of batch 49: 48.03917694091797, 1.0\n",
      "Train loss and acc of batch 50: 48.63487243652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.388084411621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.29499053955078, 0.953125\n",
      "Train loss and acc of batch 53: 48.03913879394531, 1.0\n",
      "Train loss and acc of batch 54: 48.255897521972656, 0.984375\n",
      "Train loss and acc of batch 55: 48.03912353515625, 1.0\n",
      "Train loss and acc of batch 56: 48.03911590576172, 1.0\n",
      "Train loss and acc of batch 57: 48.63481140136719, 0.984375\n",
      "Train loss and acc of batch 58: 48.039100646972656, 1.0\n",
      "Train loss and acc of batch 59: 48.03908920288086, 1.0\n",
      "Train loss and acc of batch 60: 48.03908157348633, 1.0\n",
      "Train loss and acc of batch 61: 48.03907012939453, 1.0\n",
      "Train loss and acc of batch 62: 48.255828857421875, 0.984375\n",
      "Train loss and acc of batch 63: 49.23045349121094, 0.96875\n",
      "Train loss and acc of batch 64: 48.25580596923828, 0.984375\n",
      "Train loss and acc of batch 65: 48.03903579711914, 1.0\n",
      "Train loss and acc of batch 66: 48.039024353027344, 1.0\n",
      "Train loss and acc of batch 67: 48.85148620605469, 0.96875\n",
      "Train loss and acc of batch 68: 48.63471221923828, 0.984375\n",
      "Train loss and acc of batch 69: 48.255760192871094, 0.984375\n",
      "Train loss and acc of batch 70: 48.03899383544922, 1.0\n",
      "Training accuracy and loss of epoch #31: 0.9890, 48.3703\n",
      "Saved model by train loss 48.37031936645508\n",
      "Train loss and acc of batch 0: 48.038978576660156, 1.0\n",
      "Train loss and acc of batch 1: 48.03897476196289, 1.0\n",
      "Train loss and acc of batch 2: 48.32481384277344, 0.984375\n",
      "Train loss and acc of batch 3: 48.255714416503906, 0.984375\n",
      "Train loss and acc of batch 4: 48.038944244384766, 1.0\n",
      "Train loss and acc of batch 5: 49.38786315917969, 0.96875\n",
      "Train loss and acc of batch 6: 48.541542053222656, 0.96875\n",
      "Train loss and acc of batch 7: 48.038917541503906, 1.0\n",
      "Train loss and acc of batch 8: 48.634613037109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.32475280761719, 0.984375\n",
      "Train loss and acc of batch 10: 48.03889465332031, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 11: 48.038883209228516, 1.0\n",
      "Train loss and acc of batch 12: 48.79209899902344, 0.984375\n",
      "Train loss and acc of batch 13: 48.25563049316406, 0.984375\n",
      "Train loss and acc of batch 14: 48.25562286376953, 0.984375\n",
      "Train loss and acc of batch 15: 48.634544372558594, 0.984375\n",
      "Train loss and acc of batch 16: 48.634544372558594, 0.984375\n",
      "Train loss and acc of batch 17: 48.79205322265625, 0.984375\n",
      "Train loss and acc of batch 18: 48.92037582397461, 0.96875\n",
      "Train loss and acc of batch 19: 48.03881072998047, 1.0\n",
      "Train loss and acc of batch 20: 48.03880310058594, 1.0\n",
      "Train loss and acc of batch 21: 48.634490966796875, 0.984375\n",
      "Train loss and acc of batch 22: 48.634490966796875, 0.984375\n",
      "Train loss and acc of batch 23: 48.25553894042969, 0.984375\n",
      "Train loss and acc of batch 24: 48.63446807861328, 0.984375\n",
      "Train loss and acc of batch 25: 48.03875732421875, 1.0\n",
      "Train loss and acc of batch 26: 48.03874969482422, 1.0\n",
      "Train loss and acc of batch 27: 48.03874206542969, 1.0\n",
      "Train loss and acc of batch 28: 48.03873062133789, 1.0\n",
      "Train loss and acc of batch 29: 48.634422302246094, 0.984375\n",
      "Train loss and acc of batch 30: 48.03871536254883, 1.0\n",
      "Train loss and acc of batch 31: 48.255462646484375, 0.984375\n",
      "Train loss and acc of batch 32: 48.0386962890625, 1.0\n",
      "Train loss and acc of batch 33: 48.0386848449707, 1.0\n",
      "Train loss and acc of batch 34: 48.634376525878906, 0.984375\n",
      "Train loss and acc of batch 35: 48.47219467163086, 0.96875\n",
      "Train loss and acc of batch 36: 48.038658142089844, 1.0\n",
      "Train loss and acc of batch 37: 48.791873931884766, 0.984375\n",
      "Train loss and acc of batch 38: 49.38756561279297, 0.96875\n",
      "Train loss and acc of batch 39: 48.255393981933594, 0.984375\n",
      "Train loss and acc of batch 40: 48.03862380981445, 1.0\n",
      "Train loss and acc of batch 41: 49.38754653930664, 0.96875\n",
      "Train loss and acc of batch 42: 48.038604736328125, 1.0\n",
      "Train loss and acc of batch 43: 48.634300231933594, 0.984375\n",
      "Train loss and acc of batch 44: 48.0385856628418, 1.0\n",
      "Train loss and acc of batch 45: 48.63428497314453, 0.984375\n",
      "Train loss and acc of batch 46: 48.324424743652344, 0.984375\n",
      "Train loss and acc of batch 47: 48.0385627746582, 1.0\n",
      "Train loss and acc of batch 48: 48.03854751586914, 1.0\n",
      "Train loss and acc of batch 49: 48.038543701171875, 1.0\n",
      "Train loss and acc of batch 50: 48.63423156738281, 0.984375\n",
      "Train loss and acc of batch 51: 49.387451171875, 0.96875\n",
      "Train loss and acc of batch 52: 49.29435729980469, 0.953125\n",
      "Train loss and acc of batch 53: 48.03850555419922, 1.0\n",
      "Train loss and acc of batch 54: 48.25526428222656, 0.984375\n",
      "Train loss and acc of batch 55: 48.038490295410156, 1.0\n",
      "Train loss and acc of batch 56: 48.038482666015625, 1.0\n",
      "Train loss and acc of batch 57: 48.63417053222656, 0.984375\n",
      "Train loss and acc of batch 58: 48.03845977783203, 1.0\n",
      "Train loss and acc of batch 59: 48.0384521484375, 1.0\n",
      "Train loss and acc of batch 60: 48.03844451904297, 1.0\n",
      "Train loss and acc of batch 61: 48.03843688964844, 1.0\n",
      "Train loss and acc of batch 62: 48.25518798828125, 0.984375\n",
      "Train loss and acc of batch 63: 49.229820251464844, 0.96875\n",
      "Train loss and acc of batch 64: 48.25517272949219, 0.984375\n",
      "Train loss and acc of batch 65: 48.03839874267578, 1.0\n",
      "Train loss and acc of batch 66: 48.03839111328125, 1.0\n",
      "Train loss and acc of batch 67: 48.85084533691406, 0.96875\n",
      "Train loss and acc of batch 68: 48.634071350097656, 0.984375\n",
      "Train loss and acc of batch 69: 48.255126953125, 0.984375\n",
      "Train loss and acc of batch 70: 48.038352966308594, 1.0\n",
      "Training accuracy and loss of epoch #32: 0.9890, 48.3697\n",
      "Saved model by train loss 48.36968349403059\n",
      "Train loss and acc of batch 0: 48.03834915161133, 1.0\n",
      "Train loss and acc of batch 1: 48.03833770751953, 1.0\n",
      "Train loss and acc of batch 2: 48.324180603027344, 0.984375\n",
      "Train loss and acc of batch 3: 48.255088806152344, 0.984375\n",
      "Train loss and acc of batch 4: 48.03831100463867, 1.0\n",
      "Train loss and acc of batch 5: 49.38722229003906, 0.96875\n",
      "Train loss and acc of batch 6: 48.54090881347656, 0.96875\n",
      "Train loss and acc of batch 7: 48.03828811645508, 1.0\n",
      "Train loss and acc of batch 8: 48.63397216796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.324119567871094, 0.984375\n",
      "Train loss and acc of batch 10: 48.03825759887695, 1.0\n",
      "Train loss and acc of batch 11: 48.03824996948242, 1.0\n",
      "Train loss and acc of batch 12: 48.79146194458008, 0.984375\n",
      "Train loss and acc of batch 13: 48.25499725341797, 0.984375\n",
      "Train loss and acc of batch 14: 48.25498962402344, 0.984375\n",
      "Train loss and acc of batch 15: 48.6339111328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.63390350341797, 0.984375\n",
      "Train loss and acc of batch 17: 48.791419982910156, 0.984375\n",
      "Train loss and acc of batch 18: 48.91973876953125, 0.96875\n",
      "Train loss and acc of batch 19: 48.038177490234375, 1.0\n",
      "Train loss and acc of batch 20: 48.038169860839844, 1.0\n",
      "Train loss and acc of batch 21: 48.63386535644531, 0.984375\n",
      "Train loss and acc of batch 22: 48.63385009765625, 0.984375\n",
      "Train loss and acc of batch 23: 48.25489807128906, 0.984375\n",
      "Train loss and acc of batch 24: 48.63383483886719, 0.984375\n",
      "Train loss and acc of batch 25: 48.038124084472656, 1.0\n",
      "Train loss and acc of batch 26: 48.03812026977539, 1.0\n",
      "Train loss and acc of batch 27: 48.03810119628906, 1.0\n",
      "Train loss and acc of batch 28: 48.0380973815918, 1.0\n",
      "Train loss and acc of batch 29: 48.6337890625, 0.984375\n",
      "Train loss and acc of batch 30: 48.03807830810547, 1.0\n",
      "Train loss and acc of batch 31: 48.25483703613281, 0.984375\n",
      "Train loss and acc of batch 32: 48.038063049316406, 1.0\n",
      "Train loss and acc of batch 33: 48.038047790527344, 1.0\n",
      "Train loss and acc of batch 34: 48.63374328613281, 0.984375\n",
      "Train loss and acc of batch 35: 48.471561431884766, 0.96875\n",
      "Train loss and acc of batch 36: 48.038021087646484, 1.0\n",
      "Train loss and acc of batch 37: 48.79124069213867, 0.984375\n",
      "Train loss and acc of batch 38: 49.386924743652344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2547607421875, 0.984375\n",
      "Train loss and acc of batch 40: 48.03799057006836, 1.0\n",
      "Train loss and acc of batch 41: 49.38690185546875, 0.96875\n",
      "Train loss and acc of batch 42: 48.0379753112793, 1.0\n",
      "Train loss and acc of batch 43: 48.63365936279297, 0.984375\n",
      "Train loss and acc of batch 44: 48.0379524230957, 1.0\n",
      "Train loss and acc of batch 45: 48.633644104003906, 0.984375\n",
      "Train loss and acc of batch 46: 48.32378387451172, 0.984375\n",
      "Train loss and acc of batch 47: 48.037925720214844, 1.0\n",
      "Train loss and acc of batch 48: 48.03792190551758, 1.0\n",
      "Train loss and acc of batch 49: 48.03791046142578, 1.0\n",
      "Train loss and acc of batch 50: 48.63359832763672, 0.984375\n",
      "Train loss and acc of batch 51: 49.386810302734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.29372024536133, 0.953125\n",
      "Train loss and acc of batch 53: 48.037872314453125, 1.0\n",
      "Train loss and acc of batch 54: 48.25463104248047, 0.984375\n",
      "Train loss and acc of batch 55: 48.0378532409668, 1.0\n",
      "Train loss and acc of batch 56: 48.037845611572266, 1.0\n",
      "Train loss and acc of batch 57: 48.63353729248047, 0.984375\n",
      "Train loss and acc of batch 58: 48.03782653808594, 1.0\n",
      "Train loss and acc of batch 59: 48.037818908691406, 1.0\n",
      "Train loss and acc of batch 60: 48.03780746459961, 1.0\n",
      "Train loss and acc of batch 61: 48.03779983520508, 1.0\n",
      "Train loss and acc of batch 62: 48.254554748535156, 0.984375\n",
      "Train loss and acc of batch 63: 49.22918701171875, 0.96875\n",
      "Train loss and acc of batch 64: 48.254539489746094, 0.984375\n",
      "Train loss and acc of batch 65: 48.03776931762695, 1.0\n",
      "Train loss and acc of batch 66: 48.03775405883789, 1.0\n",
      "Train loss and acc of batch 67: 48.850215911865234, 0.96875\n",
      "Train loss and acc of batch 68: 48.63343811035156, 0.984375\n",
      "Train loss and acc of batch 69: 48.254493713378906, 0.984375\n",
      "Train loss and acc of batch 70: 48.037723541259766, 1.0\n",
      "Training accuracy and loss of epoch #33: 0.9890, 48.3690\n",
      "Saved model by train loss 48.369048964809366\n",
      "Train loss and acc of batch 0: 48.03771209716797, 1.0\n",
      "Train loss and acc of batch 1: 48.03770065307617, 1.0\n",
      "Train loss and acc of batch 2: 48.32354736328125, 0.984375\n",
      "Train loss and acc of batch 3: 48.25444793701172, 0.984375\n",
      "Train loss and acc of batch 4: 48.03767395019531, 1.0\n",
      "Train loss and acc of batch 5: 49.3865966796875, 0.96875\n",
      "Train loss and acc of batch 6: 48.540279388427734, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 7: 48.03764724731445, 1.0\n",
      "Train loss and acc of batch 8: 48.633338928222656, 0.984375\n",
      "Train loss and acc of batch 9: 48.32347869873047, 0.984375\n",
      "Train loss and acc of batch 10: 48.03762435913086, 1.0\n",
      "Train loss and acc of batch 11: 48.03761291503906, 1.0\n",
      "Train loss and acc of batch 12: 48.79082489013672, 0.984375\n",
      "Train loss and acc of batch 13: 48.254364013671875, 0.984375\n",
      "Train loss and acc of batch 14: 48.25434875488281, 0.984375\n",
      "Train loss and acc of batch 15: 48.633277893066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.633270263671875, 0.984375\n",
      "Train loss and acc of batch 17: 48.7907829284668, 0.984375\n",
      "Train loss and acc of batch 18: 48.91910171508789, 0.96875\n",
      "Train loss and acc of batch 19: 48.037540435791016, 1.0\n",
      "Train loss and acc of batch 20: 48.037532806396484, 1.0\n",
      "Train loss and acc of batch 21: 48.63322448730469, 0.984375\n",
      "Train loss and acc of batch 22: 48.63322448730469, 0.984375\n",
      "Train loss and acc of batch 23: 48.2542724609375, 0.984375\n",
      "Train loss and acc of batch 24: 48.633201599121094, 0.984375\n",
      "Train loss and acc of batch 25: 48.03749084472656, 1.0\n",
      "Train loss and acc of batch 26: 48.0374755859375, 1.0\n",
      "Train loss and acc of batch 27: 48.037471771240234, 1.0\n",
      "Train loss and acc of batch 28: 48.03746032714844, 1.0\n",
      "Train loss and acc of batch 29: 48.633155822753906, 0.984375\n",
      "Train loss and acc of batch 30: 48.03744125366211, 1.0\n",
      "Train loss and acc of batch 31: 48.25419616699219, 0.984375\n",
      "Train loss and acc of batch 32: 48.03742599487305, 1.0\n",
      "Train loss and acc of batch 33: 48.03742218017578, 1.0\n",
      "Train loss and acc of batch 34: 48.63311004638672, 0.984375\n",
      "Train loss and acc of batch 35: 48.47092819213867, 0.96875\n",
      "Train loss and acc of batch 36: 48.03738784790039, 1.0\n",
      "Train loss and acc of batch 37: 48.79060745239258, 0.984375\n",
      "Train loss and acc of batch 38: 49.38629913330078, 0.96875\n",
      "Train loss and acc of batch 39: 48.254119873046875, 0.984375\n",
      "Train loss and acc of batch 40: 48.037353515625, 1.0\n",
      "Train loss and acc of batch 41: 49.38627243041992, 0.96875\n",
      "Train loss and acc of batch 42: 48.03733444213867, 1.0\n",
      "Train loss and acc of batch 43: 48.633033752441406, 0.984375\n",
      "Train loss and acc of batch 44: 48.03731918334961, 1.0\n",
      "Train loss and acc of batch 45: 48.63300323486328, 0.984375\n",
      "Train loss and acc of batch 46: 48.323150634765625, 0.984375\n",
      "Train loss and acc of batch 47: 48.037288665771484, 1.0\n",
      "Train loss and acc of batch 48: 48.03728103637695, 1.0\n",
      "Train loss and acc of batch 49: 48.03727340698242, 1.0\n",
      "Train loss and acc of batch 50: 48.632965087890625, 0.984375\n",
      "Train loss and acc of batch 51: 49.38618469238281, 0.96875\n",
      "Train loss and acc of batch 52: 49.2930908203125, 0.953125\n",
      "Train loss and acc of batch 53: 48.03723907470703, 1.0\n",
      "Train loss and acc of batch 54: 48.253990173339844, 0.984375\n",
      "Train loss and acc of batch 55: 48.0372200012207, 1.0\n",
      "Train loss and acc of batch 56: 48.037208557128906, 1.0\n",
      "Train loss and acc of batch 57: 48.632904052734375, 0.984375\n",
      "Train loss and acc of batch 58: 48.03719711303711, 1.0\n",
      "Train loss and acc of batch 59: 48.03718185424805, 1.0\n",
      "Train loss and acc of batch 60: 48.037174224853516, 1.0\n",
      "Train loss and acc of batch 61: 48.037166595458984, 1.0\n",
      "Train loss and acc of batch 62: 48.25392150878906, 0.984375\n",
      "Train loss and acc of batch 63: 49.22854995727539, 0.96875\n",
      "Train loss and acc of batch 64: 48.25390625, 0.984375\n",
      "Train loss and acc of batch 65: 48.03712844848633, 1.0\n",
      "Train loss and acc of batch 66: 48.03712463378906, 1.0\n",
      "Train loss and acc of batch 67: 48.84957504272461, 0.96875\n",
      "Train loss and acc of batch 68: 48.63279724121094, 0.984375\n",
      "Train loss and acc of batch 69: 48.25386047363281, 0.984375\n",
      "Train loss and acc of batch 70: 48.037086486816406, 1.0\n",
      "Training accuracy and loss of epoch #34: 0.9890, 48.3684\n",
      "Saved model by train loss 48.36841411321935\n",
      "Train loss and acc of batch 0: 48.03707504272461, 1.0\n",
      "Train loss and acc of batch 1: 48.037071228027344, 1.0\n",
      "Train loss and acc of batch 2: 48.322914123535156, 0.984375\n",
      "Train loss and acc of batch 3: 48.253814697265625, 0.984375\n",
      "Train loss and acc of batch 4: 48.03704071044922, 1.0\n",
      "Train loss and acc of batch 5: 49.385955810546875, 0.96875\n",
      "Train loss and acc of batch 6: 48.539642333984375, 0.96875\n",
      "Train loss and acc of batch 7: 48.037010192871094, 1.0\n",
      "Train loss and acc of batch 8: 48.63270568847656, 0.984375\n",
      "Train loss and acc of batch 9: 48.322853088378906, 0.984375\n",
      "Train loss and acc of batch 10: 48.036983489990234, 1.0\n",
      "Train loss and acc of batch 11: 48.0369758605957, 1.0\n",
      "Train loss and acc of batch 12: 48.79019546508789, 0.984375\n",
      "Train loss and acc of batch 13: 48.25372314453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.25371551513672, 0.984375\n",
      "Train loss and acc of batch 15: 48.63264465332031, 0.984375\n",
      "Train loss and acc of batch 16: 48.63263702392578, 0.984375\n",
      "Train loss and acc of batch 17: 48.79014587402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.91847229003906, 0.96875\n",
      "Train loss and acc of batch 19: 48.036903381347656, 1.0\n",
      "Train loss and acc of batch 20: 48.03689956665039, 1.0\n",
      "Train loss and acc of batch 21: 48.632591247558594, 0.984375\n",
      "Train loss and acc of batch 22: 48.63258361816406, 0.984375\n",
      "Train loss and acc of batch 23: 48.253639221191406, 0.984375\n",
      "Train loss and acc of batch 24: 48.63255310058594, 0.984375\n",
      "Train loss and acc of batch 25: 48.0368537902832, 1.0\n",
      "Train loss and acc of batch 26: 48.03684616088867, 1.0\n",
      "Train loss and acc of batch 27: 48.036834716796875, 1.0\n",
      "Train loss and acc of batch 28: 48.036827087402344, 1.0\n",
      "Train loss and acc of batch 29: 48.63251495361328, 0.984375\n",
      "Train loss and acc of batch 30: 48.036808013916016, 1.0\n",
      "Train loss and acc of batch 31: 48.253562927246094, 0.984375\n",
      "Train loss and acc of batch 32: 48.03678894042969, 1.0\n",
      "Train loss and acc of batch 33: 48.036781311035156, 1.0\n",
      "Train loss and acc of batch 34: 48.632469177246094, 0.984375\n",
      "Train loss and acc of batch 35: 48.47029113769531, 0.96875\n",
      "Train loss and acc of batch 36: 48.03675842285156, 1.0\n",
      "Train loss and acc of batch 37: 48.78997039794922, 0.984375\n",
      "Train loss and acc of batch 38: 49.385658264160156, 0.96875\n",
      "Train loss and acc of batch 39: 48.25349426269531, 0.984375\n",
      "Train loss and acc of batch 40: 48.03671646118164, 1.0\n",
      "Train loss and acc of batch 41: 49.38563537597656, 0.96875\n",
      "Train loss and acc of batch 42: 48.03670120239258, 1.0\n",
      "Train loss and acc of batch 43: 48.63239288330078, 0.984375\n",
      "Train loss and acc of batch 44: 48.03668212890625, 1.0\n",
      "Train loss and acc of batch 45: 48.63237762451172, 0.984375\n",
      "Train loss and acc of batch 46: 48.32251739501953, 0.984375\n",
      "Train loss and acc of batch 47: 48.03665542602539, 1.0\n",
      "Train loss and acc of batch 48: 48.036643981933594, 1.0\n",
      "Train loss and acc of batch 49: 48.03664016723633, 1.0\n",
      "Train loss and acc of batch 50: 48.63233184814453, 0.984375\n",
      "Train loss and acc of batch 51: 49.38555145263672, 0.96875\n",
      "Train loss and acc of batch 52: 49.292449951171875, 0.953125\n",
      "Train loss and acc of batch 53: 48.03660583496094, 1.0\n",
      "Train loss and acc of batch 54: 48.25335693359375, 0.984375\n",
      "Train loss and acc of batch 55: 48.036582946777344, 1.0\n",
      "Train loss and acc of batch 56: 48.03657531738281, 1.0\n",
      "Train loss and acc of batch 57: 48.63227081298828, 0.984375\n",
      "Train loss and acc of batch 58: 48.03656005859375, 1.0\n",
      "Train loss and acc of batch 59: 48.03655242919922, 1.0\n",
      "Train loss and acc of batch 60: 48.03654098510742, 1.0\n",
      "Train loss and acc of batch 61: 48.036529541015625, 1.0\n",
      "Train loss and acc of batch 62: 48.25328826904297, 0.984375\n",
      "Train loss and acc of batch 63: 49.227909088134766, 0.96875\n",
      "Train loss and acc of batch 64: 48.253273010253906, 0.984375\n",
      "Train loss and acc of batch 65: 48.0364990234375, 1.0\n",
      "Train loss and acc of batch 66: 48.03648376464844, 1.0\n",
      "Train loss and acc of batch 67: 48.84894561767578, 0.96875\n",
      "Train loss and acc of batch 68: 48.632171630859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.25321960449219, 0.984375\n",
      "Train loss and acc of batch 70: 48.03645324707031, 1.0\n",
      "Training accuracy and loss of epoch #35: 0.9890, 48.3678\n",
      "Saved model by train loss 48.367779154173085\n",
      "Train loss and acc of batch 0: 48.03643798828125, 1.0\n",
      "Train loss and acc of batch 1: 48.036434173583984, 1.0\n",
      "Train loss and acc of batch 2: 48.32227325439453, 0.984375\n",
      "Train loss and acc of batch 3: 48.25318145751953, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 4: 48.03640365600586, 1.0\n",
      "Train loss and acc of batch 5: 49.38532257080078, 0.96875\n",
      "Train loss and acc of batch 6: 48.53900146484375, 0.96875\n",
      "Train loss and acc of batch 7: 48.036380767822266, 1.0\n",
      "Train loss and acc of batch 8: 48.63207244873047, 0.984375\n",
      "Train loss and acc of batch 9: 48.32221221923828, 0.984375\n",
      "Train loss and acc of batch 10: 48.036354064941406, 1.0\n",
      "Train loss and acc of batch 11: 48.036338806152344, 1.0\n",
      "Train loss and acc of batch 12: 48.78955841064453, 0.984375\n",
      "Train loss and acc of batch 13: 48.253089904785156, 0.984375\n",
      "Train loss and acc of batch 14: 48.253082275390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.63201141357422, 0.984375\n",
      "Train loss and acc of batch 16: 48.63200378417969, 0.984375\n",
      "Train loss and acc of batch 17: 48.789512634277344, 0.984375\n",
      "Train loss and acc of batch 18: 48.9178352355957, 0.96875\n",
      "Train loss and acc of batch 19: 48.03627014160156, 1.0\n",
      "Train loss and acc of batch 20: 48.036258697509766, 1.0\n",
      "Train loss and acc of batch 21: 48.6319580078125, 0.984375\n",
      "Train loss and acc of batch 22: 48.63194274902344, 0.984375\n",
      "Train loss and acc of batch 23: 48.25299835205078, 0.984375\n",
      "Train loss and acc of batch 24: 48.631927490234375, 0.984375\n",
      "Train loss and acc of batch 25: 48.036216735839844, 1.0\n",
      "Train loss and acc of batch 26: 48.03620910644531, 1.0\n",
      "Train loss and acc of batch 27: 48.03619384765625, 1.0\n",
      "Train loss and acc of batch 28: 48.036190032958984, 1.0\n",
      "Train loss and acc of batch 29: 48.63188171386719, 0.984375\n",
      "Train loss and acc of batch 30: 48.03617477416992, 1.0\n",
      "Train loss and acc of batch 31: 48.2529296875, 0.984375\n",
      "Train loss and acc of batch 32: 48.036155700683594, 1.0\n",
      "Train loss and acc of batch 33: 48.0361442565918, 1.0\n",
      "Train loss and acc of batch 34: 48.6318359375, 0.984375\n",
      "Train loss and acc of batch 35: 48.46965789794922, 0.96875\n",
      "Train loss and acc of batch 36: 48.03611755371094, 1.0\n",
      "Train loss and acc of batch 37: 48.78933334350586, 0.984375\n",
      "Train loss and acc of batch 38: 49.385032653808594, 0.96875\n",
      "Train loss and acc of batch 39: 48.25285339355469, 0.984375\n",
      "Train loss and acc of batch 40: 48.03608322143555, 1.0\n",
      "Train loss and acc of batch 41: 49.3849983215332, 0.96875\n",
      "Train loss and acc of batch 42: 48.03606414794922, 1.0\n",
      "Train loss and acc of batch 43: 48.63175964355469, 0.984375\n",
      "Train loss and acc of batch 44: 48.036048889160156, 1.0\n",
      "Train loss and acc of batch 45: 48.631744384765625, 0.984375\n",
      "Train loss and acc of batch 46: 48.32188415527344, 0.984375\n",
      "Train loss and acc of batch 47: 48.0360221862793, 1.0\n",
      "Train loss and acc of batch 48: 48.0360107421875, 1.0\n",
      "Train loss and acc of batch 49: 48.036006927490234, 1.0\n",
      "Train loss and acc of batch 50: 48.63169860839844, 0.984375\n",
      "Train loss and acc of batch 51: 49.384910583496094, 0.96875\n",
      "Train loss and acc of batch 52: 49.29182052612305, 0.953125\n",
      "Train loss and acc of batch 53: 48.03596878051758, 1.0\n",
      "Train loss and acc of batch 54: 48.252723693847656, 0.984375\n",
      "Train loss and acc of batch 55: 48.035953521728516, 1.0\n",
      "Train loss and acc of batch 56: 48.03593444824219, 1.0\n",
      "Train loss and acc of batch 57: 48.631629943847656, 0.984375\n",
      "Train loss and acc of batch 58: 48.03592300415039, 1.0\n",
      "Train loss and acc of batch 59: 48.03591537475586, 1.0\n",
      "Train loss and acc of batch 60: 48.03590774536133, 1.0\n",
      "Train loss and acc of batch 61: 48.0359001159668, 1.0\n",
      "Train loss and acc of batch 62: 48.252647399902344, 0.984375\n",
      "Train loss and acc of batch 63: 49.22728729248047, 0.96875\n",
      "Train loss and acc of batch 64: 48.25263214111328, 0.984375\n",
      "Train loss and acc of batch 65: 48.03586196899414, 1.0\n",
      "Train loss and acc of batch 66: 48.035850524902344, 1.0\n",
      "Train loss and acc of batch 67: 48.84830856323242, 0.96875\n",
      "Train loss and acc of batch 68: 48.63153076171875, 0.984375\n",
      "Train loss and acc of batch 69: 48.252586364746094, 0.984375\n",
      "Train loss and acc of batch 70: 48.03581619262695, 1.0\n",
      "Training accuracy and loss of epoch #36: 0.9890, 48.3671\n",
      "Saved model by train loss 48.367143926486165\n",
      "Train loss and acc of batch 0: 48.035804748535156, 1.0\n",
      "Train loss and acc of batch 1: 48.035797119140625, 1.0\n",
      "Train loss and acc of batch 2: 48.32164001464844, 0.984375\n",
      "Train loss and acc of batch 3: 48.25254821777344, 0.984375\n",
      "Train loss and acc of batch 4: 48.035770416259766, 1.0\n",
      "Train loss and acc of batch 5: 49.38468933105469, 0.96875\n",
      "Train loss and acc of batch 6: 48.53837203979492, 0.96875\n",
      "Train loss and acc of batch 7: 48.035743713378906, 1.0\n",
      "Train loss and acc of batch 8: 48.631439208984375, 0.984375\n",
      "Train loss and acc of batch 9: 48.32157897949219, 0.984375\n",
      "Train loss and acc of batch 10: 48.03571319580078, 1.0\n",
      "Train loss and acc of batch 11: 48.035709381103516, 1.0\n",
      "Train loss and acc of batch 12: 48.7889289855957, 0.984375\n",
      "Train loss and acc of batch 13: 48.25245666503906, 0.984375\n",
      "Train loss and acc of batch 14: 48.25244140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.631378173828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.63136291503906, 0.984375\n",
      "Train loss and acc of batch 17: 48.788883209228516, 0.984375\n",
      "Train loss and acc of batch 18: 48.917198181152344, 0.96875\n",
      "Train loss and acc of batch 19: 48.03563690185547, 1.0\n",
      "Train loss and acc of batch 20: 48.03562927246094, 1.0\n",
      "Train loss and acc of batch 21: 48.631324768066406, 0.984375\n",
      "Train loss and acc of batch 22: 48.631309509277344, 0.984375\n",
      "Train loss and acc of batch 23: 48.25236511230469, 0.984375\n",
      "Train loss and acc of batch 24: 48.63129425048828, 0.984375\n",
      "Train loss and acc of batch 25: 48.03558349609375, 1.0\n",
      "Train loss and acc of batch 26: 48.03557205200195, 1.0\n",
      "Train loss and acc of batch 27: 48.03556442260742, 1.0\n",
      "Train loss and acc of batch 28: 48.03555679321289, 1.0\n",
      "Train loss and acc of batch 29: 48.631248474121094, 0.984375\n",
      "Train loss and acc of batch 30: 48.03553771972656, 1.0\n",
      "Train loss and acc of batch 31: 48.252296447753906, 0.984375\n",
      "Train loss and acc of batch 32: 48.0355224609375, 1.0\n",
      "Train loss and acc of batch 33: 48.0355110168457, 1.0\n",
      "Train loss and acc of batch 34: 48.631202697753906, 0.984375\n",
      "Train loss and acc of batch 35: 48.469024658203125, 0.96875\n",
      "Train loss and acc of batch 36: 48.03548049926758, 1.0\n",
      "Train loss and acc of batch 37: 48.7886962890625, 0.984375\n",
      "Train loss and acc of batch 38: 49.38439178466797, 0.96875\n",
      "Train loss and acc of batch 39: 48.252220153808594, 0.984375\n",
      "Train loss and acc of batch 40: 48.03544998168945, 1.0\n",
      "Train loss and acc of batch 41: 49.384368896484375, 0.96875\n",
      "Train loss and acc of batch 42: 48.03543472290039, 1.0\n",
      "Train loss and acc of batch 43: 48.631126403808594, 0.984375\n",
      "Train loss and acc of batch 44: 48.0354118347168, 1.0\n",
      "Train loss and acc of batch 45: 48.631103515625, 0.984375\n",
      "Train loss and acc of batch 46: 48.32124328613281, 0.984375\n",
      "Train loss and acc of batch 47: 48.03538513183594, 1.0\n",
      "Train loss and acc of batch 48: 48.035377502441406, 1.0\n",
      "Train loss and acc of batch 49: 48.03536605834961, 1.0\n",
      "Train loss and acc of batch 50: 48.631065368652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.38427734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.29117965698242, 0.953125\n",
      "Train loss and acc of batch 53: 48.03533172607422, 1.0\n",
      "Train loss and acc of batch 54: 48.25209045410156, 0.984375\n",
      "Train loss and acc of batch 55: 48.03531265258789, 1.0\n",
      "Train loss and acc of batch 56: 48.035308837890625, 1.0\n",
      "Train loss and acc of batch 57: 48.63099670410156, 0.984375\n",
      "Train loss and acc of batch 58: 48.03528594970703, 1.0\n",
      "Train loss and acc of batch 59: 48.0352783203125, 1.0\n",
      "Train loss and acc of batch 60: 48.03526306152344, 1.0\n",
      "Train loss and acc of batch 61: 48.03526306152344, 1.0\n",
      "Train loss and acc of batch 62: 48.25202178955078, 0.984375\n",
      "Train loss and acc of batch 63: 49.226646423339844, 0.96875\n",
      "Train loss and acc of batch 64: 48.25199890136719, 0.984375\n",
      "Train loss and acc of batch 65: 48.03522491455078, 1.0\n",
      "Train loss and acc of batch 66: 48.035213470458984, 1.0\n",
      "Train loss and acc of batch 67: 48.84767532348633, 0.96875\n",
      "Train loss and acc of batch 68: 48.630897521972656, 0.984375\n",
      "Train loss and acc of batch 69: 48.251953125, 0.984375\n",
      "Train loss and acc of batch 70: 48.03518295288086, 1.0\n",
      "Training accuracy and loss of epoch #37: 0.9890, 48.3665\n",
      "Saved model by train loss 48.366509289808675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 48.03517532348633, 1.0\n",
      "Train loss and acc of batch 1: 48.035160064697266, 1.0\n",
      "Train loss and acc of batch 2: 48.321006774902344, 0.984375\n",
      "Train loss and acc of batch 3: 48.25190734863281, 0.984375\n",
      "Train loss and acc of batch 4: 48.03513717651367, 1.0\n",
      "Train loss and acc of batch 5: 49.38404846191406, 0.96875\n",
      "Train loss and acc of batch 6: 48.53773498535156, 0.96875\n",
      "Train loss and acc of batch 7: 48.03510665893555, 1.0\n",
      "Train loss and acc of batch 8: 48.63079833984375, 0.984375\n",
      "Train loss and acc of batch 9: 48.32093811035156, 0.984375\n",
      "Train loss and acc of batch 10: 48.03508377075195, 1.0\n",
      "Train loss and acc of batch 11: 48.035072326660156, 1.0\n",
      "Train loss and acc of batch 12: 48.78828811645508, 0.984375\n",
      "Train loss and acc of batch 13: 48.25182342529297, 0.984375\n",
      "Train loss and acc of batch 14: 48.251808166503906, 0.984375\n",
      "Train loss and acc of batch 15: 48.6307373046875, 0.984375\n",
      "Train loss and acc of batch 16: 48.63072967529297, 0.984375\n",
      "Train loss and acc of batch 17: 48.788238525390625, 0.984375\n",
      "Train loss and acc of batch 18: 48.91656494140625, 0.96875\n",
      "Train loss and acc of batch 19: 48.035003662109375, 1.0\n",
      "Train loss and acc of batch 20: 48.03498840332031, 1.0\n",
      "Train loss and acc of batch 21: 48.63068389892578, 0.984375\n",
      "Train loss and acc of batch 22: 48.63067626953125, 0.984375\n",
      "Train loss and acc of batch 23: 48.251731872558594, 0.984375\n",
      "Train loss and acc of batch 24: 48.63066101074219, 0.984375\n",
      "Train loss and acc of batch 25: 48.034950256347656, 1.0\n",
      "Train loss and acc of batch 26: 48.03493881225586, 1.0\n",
      "Train loss and acc of batch 27: 48.034934997558594, 1.0\n",
      "Train loss and acc of batch 28: 48.0349235534668, 1.0\n",
      "Train loss and acc of batch 29: 48.630615234375, 0.984375\n",
      "Train loss and acc of batch 30: 48.0349006652832, 1.0\n",
      "Train loss and acc of batch 31: 48.25165557861328, 0.984375\n",
      "Train loss and acc of batch 32: 48.03488540649414, 1.0\n",
      "Train loss and acc of batch 33: 48.03487777709961, 1.0\n",
      "Train loss and acc of batch 34: 48.63056182861328, 0.984375\n",
      "Train loss and acc of batch 35: 48.468387603759766, 0.96875\n",
      "Train loss and acc of batch 36: 48.03485107421875, 1.0\n",
      "Train loss and acc of batch 37: 48.78806686401367, 0.984375\n",
      "Train loss and acc of batch 38: 49.383750915527344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2515869140625, 0.984375\n",
      "Train loss and acc of batch 40: 48.034812927246094, 1.0\n",
      "Train loss and acc of batch 41: 49.38373565673828, 0.96875\n",
      "Train loss and acc of batch 42: 48.034793853759766, 1.0\n",
      "Train loss and acc of batch 43: 48.63048553466797, 0.984375\n",
      "Train loss and acc of batch 44: 48.03477478027344, 1.0\n",
      "Train loss and acc of batch 45: 48.630470275878906, 0.984375\n",
      "Train loss and acc of batch 46: 48.32061004638672, 0.984375\n",
      "Train loss and acc of batch 47: 48.034751892089844, 1.0\n",
      "Train loss and acc of batch 48: 48.03474044799805, 1.0\n",
      "Train loss and acc of batch 49: 48.034732818603516, 1.0\n",
      "Train loss and acc of batch 50: 48.63042449951172, 0.984375\n",
      "Train loss and acc of batch 51: 49.383644104003906, 0.96875\n",
      "Train loss and acc of batch 52: 49.290550231933594, 0.953125\n",
      "Train loss and acc of batch 53: 48.034698486328125, 1.0\n",
      "Train loss and acc of batch 54: 48.25145721435547, 0.984375\n",
      "Train loss and acc of batch 55: 48.03468322753906, 1.0\n",
      "Train loss and acc of batch 56: 48.03467559814453, 1.0\n",
      "Train loss and acc of batch 57: 48.63036346435547, 0.984375\n",
      "Train loss and acc of batch 58: 48.03465270996094, 1.0\n",
      "Train loss and acc of batch 59: 48.03464126586914, 1.0\n",
      "Train loss and acc of batch 60: 48.034637451171875, 1.0\n",
      "Train loss and acc of batch 61: 48.03462600708008, 1.0\n",
      "Train loss and acc of batch 62: 48.251380920410156, 0.984375\n",
      "Train loss and acc of batch 63: 49.226009368896484, 0.96875\n",
      "Train loss and acc of batch 64: 48.251365661621094, 0.984375\n",
      "Train loss and acc of batch 65: 48.03459167480469, 1.0\n",
      "Train loss and acc of batch 66: 48.03458023071289, 1.0\n",
      "Train loss and acc of batch 67: 48.8470344543457, 0.96875\n",
      "Train loss and acc of batch 68: 48.63026428222656, 0.984375\n",
      "Train loss and acc of batch 69: 48.251319885253906, 0.984375\n",
      "Train loss and acc of batch 70: 48.0345458984375, 1.0\n",
      "Training accuracy and loss of epoch #38: 0.9890, 48.3659\n",
      "Saved model by train loss 48.36587390093736\n",
      "Train loss and acc of batch 0: 48.0345344543457, 1.0\n",
      "Train loss and acc of batch 1: 48.03452682495117, 1.0\n",
      "Train loss and acc of batch 2: 48.32037353515625, 0.984375\n",
      "Train loss and acc of batch 3: 48.25127410888672, 0.984375\n",
      "Train loss and acc of batch 4: 48.03450012207031, 1.0\n",
      "Train loss and acc of batch 5: 49.38341522216797, 0.96875\n",
      "Train loss and acc of batch 6: 48.53710174560547, 0.96875\n",
      "Train loss and acc of batch 7: 48.03447341918945, 1.0\n",
      "Train loss and acc of batch 8: 48.630165100097656, 0.984375\n",
      "Train loss and acc of batch 9: 48.32030487060547, 0.984375\n",
      "Train loss and acc of batch 10: 48.03444290161133, 1.0\n",
      "Train loss and acc of batch 11: 48.03443908691406, 1.0\n",
      "Train loss and acc of batch 12: 48.787654876708984, 0.984375\n",
      "Train loss and acc of batch 13: 48.251182556152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.25117492675781, 0.984375\n",
      "Train loss and acc of batch 15: 48.630104064941406, 0.984375\n",
      "Train loss and acc of batch 16: 48.630096435546875, 0.984375\n",
      "Train loss and acc of batch 17: 48.7876091003418, 0.984375\n",
      "Train loss and acc of batch 18: 48.915931701660156, 0.96875\n",
      "Train loss and acc of batch 19: 48.03436279296875, 1.0\n",
      "Train loss and acc of batch 20: 48.034358978271484, 1.0\n",
      "Train loss and acc of batch 21: 48.63005065917969, 0.984375\n",
      "Train loss and acc of batch 22: 48.630043029785156, 0.984375\n",
      "Train loss and acc of batch 23: 48.2510986328125, 0.984375\n",
      "Train loss and acc of batch 24: 48.63002014160156, 0.984375\n",
      "Train loss and acc of batch 25: 48.03430938720703, 1.0\n",
      "Train loss and acc of batch 26: 48.03430938720703, 1.0\n",
      "Train loss and acc of batch 27: 48.03429412841797, 1.0\n",
      "Train loss and acc of batch 28: 48.03428649902344, 1.0\n",
      "Train loss and acc of batch 29: 48.629974365234375, 0.984375\n",
      "Train loss and acc of batch 30: 48.03426742553711, 1.0\n",
      "Train loss and acc of batch 31: 48.25102233886719, 0.984375\n",
      "Train loss and acc of batch 32: 48.03425216674805, 1.0\n",
      "Train loss and acc of batch 33: 48.03424072265625, 1.0\n",
      "Train loss and acc of batch 34: 48.62993621826172, 0.984375\n",
      "Train loss and acc of batch 35: 48.46775436401367, 0.96875\n",
      "Train loss and acc of batch 36: 48.034217834472656, 1.0\n",
      "Train loss and acc of batch 37: 48.78742980957031, 0.984375\n",
      "Train loss and acc of batch 38: 49.38311767578125, 0.96875\n",
      "Train loss and acc of batch 39: 48.250953674316406, 0.984375\n",
      "Train loss and acc of batch 40: 48.034175872802734, 1.0\n",
      "Train loss and acc of batch 41: 49.38309860229492, 0.96875\n",
      "Train loss and acc of batch 42: 48.03416061401367, 1.0\n",
      "Train loss and acc of batch 43: 48.629852294921875, 0.984375\n",
      "Train loss and acc of batch 44: 48.034141540527344, 1.0\n",
      "Train loss and acc of batch 45: 48.62983703613281, 0.984375\n",
      "Train loss and acc of batch 46: 48.319976806640625, 0.984375\n",
      "Train loss and acc of batch 47: 48.034114837646484, 1.0\n",
      "Train loss and acc of batch 48: 48.03410720825195, 1.0\n",
      "Train loss and acc of batch 49: 48.03410339355469, 1.0\n",
      "Train loss and acc of batch 50: 48.629791259765625, 0.984375\n",
      "Train loss and acc of batch 51: 49.38301086425781, 0.96875\n",
      "Train loss and acc of batch 52: 49.28990936279297, 0.953125\n",
      "Train loss and acc of batch 53: 48.034061431884766, 1.0\n",
      "Train loss and acc of batch 54: 48.250823974609375, 0.984375\n",
      "Train loss and acc of batch 55: 48.03403854370117, 1.0\n",
      "Train loss and acc of batch 56: 48.034034729003906, 1.0\n",
      "Train loss and acc of batch 57: 48.629722595214844, 0.984375\n",
      "Train loss and acc of batch 58: 48.03401565551758, 1.0\n",
      "Train loss and acc of batch 59: 48.03400802612305, 1.0\n",
      "Train loss and acc of batch 60: 48.034000396728516, 1.0\n",
      "Train loss and acc of batch 61: 48.03398513793945, 1.0\n",
      "Train loss and acc of batch 62: 48.25074768066406, 0.984375\n",
      "Train loss and acc of batch 63: 49.225372314453125, 0.96875\n",
      "Train loss and acc of batch 64: 48.25072479248047, 0.984375\n",
      "Train loss and acc of batch 65: 48.03395462036133, 1.0\n",
      "Train loss and acc of batch 66: 48.03394317626953, 1.0\n",
      "Train loss and acc of batch 67: 48.846397399902344, 0.96875\n",
      "Train loss and acc of batch 68: 48.62963104248047, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 48.25067901611328, 0.984375\n",
      "Train loss and acc of batch 70: 48.03390884399414, 1.0\n",
      "Training accuracy and loss of epoch #39: 0.9890, 48.3652\n",
      "Saved model by train loss 48.36523851206605\n",
      "Train loss and acc of batch 0: 48.033897399902344, 1.0\n",
      "Train loss and acc of batch 1: 48.03388977050781, 1.0\n",
      "Train loss and acc of batch 2: 48.319740295410156, 0.984375\n",
      "Train loss and acc of batch 3: 48.250633239746094, 0.984375\n",
      "Train loss and acc of batch 4: 48.03386306762695, 1.0\n",
      "Train loss and acc of batch 5: 49.382781982421875, 0.96875\n",
      "Train loss and acc of batch 6: 48.53646469116211, 0.96875\n",
      "Train loss and acc of batch 7: 48.033836364746094, 1.0\n",
      "Train loss and acc of batch 8: 48.62953186035156, 0.984375\n",
      "Train loss and acc of batch 9: 48.319671630859375, 0.984375\n",
      "Train loss and acc of batch 10: 48.033809661865234, 1.0\n",
      "Train loss and acc of batch 11: 48.03379821777344, 1.0\n",
      "Train loss and acc of batch 12: 48.78701400756836, 0.984375\n",
      "Train loss and acc of batch 13: 48.25054931640625, 0.984375\n",
      "Train loss and acc of batch 14: 48.25053405761719, 0.984375\n",
      "Train loss and acc of batch 15: 48.62946319580078, 0.984375\n",
      "Train loss and acc of batch 16: 48.62945556640625, 0.984375\n",
      "Train loss and acc of batch 17: 48.78697204589844, 0.984375\n",
      "Train loss and acc of batch 18: 48.91529083251953, 0.96875\n",
      "Train loss and acc of batch 19: 48.033729553222656, 1.0\n",
      "Train loss and acc of batch 20: 48.03371810913086, 1.0\n",
      "Train loss and acc of batch 21: 48.62940979003906, 0.984375\n",
      "Train loss and acc of batch 22: 48.62940216064453, 0.984375\n",
      "Train loss and acc of batch 23: 48.250457763671875, 0.984375\n",
      "Train loss and acc of batch 24: 48.62938690185547, 0.984375\n",
      "Train loss and acc of batch 25: 48.03367614746094, 1.0\n",
      "Train loss and acc of batch 26: 48.03366470336914, 1.0\n",
      "Train loss and acc of batch 27: 48.03365707397461, 1.0\n",
      "Train loss and acc of batch 28: 48.03364944458008, 1.0\n",
      "Train loss and acc of batch 29: 48.62934112548828, 0.984375\n",
      "Train loss and acc of batch 30: 48.033634185791016, 1.0\n",
      "Train loss and acc of batch 31: 48.25038146972656, 0.984375\n",
      "Train loss and acc of batch 32: 48.03361511230469, 1.0\n",
      "Train loss and acc of batch 33: 48.03360366821289, 1.0\n",
      "Train loss and acc of batch 34: 48.629295349121094, 0.984375\n",
      "Train loss and acc of batch 35: 48.46711730957031, 0.96875\n",
      "Train loss and acc of batch 36: 48.03357696533203, 1.0\n",
      "Train loss and acc of batch 37: 48.78679275512695, 0.984375\n",
      "Train loss and acc of batch 38: 49.382484436035156, 0.96875\n",
      "Train loss and acc of batch 39: 48.25031280517578, 0.984375\n",
      "Train loss and acc of batch 40: 48.033538818359375, 1.0\n",
      "Train loss and acc of batch 41: 49.3824577331543, 0.96875\n",
      "Train loss and acc of batch 42: 48.03351974487305, 1.0\n",
      "Train loss and acc of batch 43: 48.62921905517578, 0.984375\n",
      "Train loss and acc of batch 44: 48.03350830078125, 1.0\n",
      "Train loss and acc of batch 45: 48.62919616699219, 0.984375\n",
      "Train loss and acc of batch 46: 48.31934356689453, 0.984375\n",
      "Train loss and acc of batch 47: 48.03348159790039, 1.0\n",
      "Train loss and acc of batch 48: 48.03346633911133, 1.0\n",
      "Train loss and acc of batch 49: 48.03346252441406, 1.0\n",
      "Train loss and acc of batch 50: 48.629150390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.38236999511719, 0.96875\n",
      "Train loss and acc of batch 52: 49.289276123046875, 0.953125\n",
      "Train loss and acc of batch 53: 48.033424377441406, 1.0\n",
      "Train loss and acc of batch 54: 48.25017547607422, 0.984375\n",
      "Train loss and acc of batch 55: 48.033409118652344, 1.0\n",
      "Train loss and acc of batch 56: 48.03339385986328, 1.0\n",
      "Train loss and acc of batch 57: 48.62908935546875, 0.984375\n",
      "Train loss and acc of batch 58: 48.033382415771484, 1.0\n",
      "Train loss and acc of batch 59: 48.03336715698242, 1.0\n",
      "Train loss and acc of batch 60: 48.03335952758789, 1.0\n",
      "Train loss and acc of batch 61: 48.03335189819336, 1.0\n",
      "Train loss and acc of batch 62: 48.25010681152344, 0.984375\n",
      "Train loss and acc of batch 63: 49.22473907470703, 0.96875\n",
      "Train loss and acc of batch 64: 48.250091552734375, 0.984375\n",
      "Train loss and acc of batch 65: 48.03331756591797, 1.0\n",
      "Train loss and acc of batch 66: 48.03330993652344, 1.0\n",
      "Train loss and acc of batch 67: 48.845767974853516, 0.96875\n",
      "Train loss and acc of batch 68: 48.628990173339844, 0.984375\n",
      "Train loss and acc of batch 69: 48.25004577636719, 0.984375\n",
      "Train loss and acc of batch 70: 48.03327178955078, 1.0\n",
      "Training accuracy and loss of epoch #40: 0.9890, 48.3646\n",
      "Saved model by train loss 48.364601242710165\n",
      "Train loss and acc of batch 0: 48.03326416015625, 1.0\n",
      "Train loss and acc of batch 1: 48.03325653076172, 1.0\n",
      "Train loss and acc of batch 2: 48.31909942626953, 0.984375\n",
      "Train loss and acc of batch 3: 48.25000762939453, 0.984375\n",
      "Train loss and acc of batch 4: 48.033226013183594, 1.0\n",
      "Train loss and acc of batch 5: 49.38214111328125, 0.96875\n",
      "Train loss and acc of batch 6: 48.53582763671875, 0.96875\n",
      "Train loss and acc of batch 7: 48.033199310302734, 1.0\n",
      "Train loss and acc of batch 8: 48.62889099121094, 0.984375\n",
      "Train loss and acc of batch 9: 48.31903839111328, 0.984375\n",
      "Train loss and acc of batch 10: 48.033172607421875, 1.0\n",
      "Train loss and acc of batch 11: 48.03316879272461, 1.0\n",
      "Train loss and acc of batch 12: 48.786380767822266, 0.984375\n",
      "Train loss and acc of batch 13: 48.249916076660156, 0.984375\n",
      "Train loss and acc of batch 14: 48.249900817871094, 0.984375\n",
      "Train loss and acc of batch 15: 48.62883758544922, 0.984375\n",
      "Train loss and acc of batch 16: 48.628822326660156, 0.984375\n",
      "Train loss and acc of batch 17: 48.78633499145508, 0.984375\n",
      "Train loss and acc of batch 18: 48.91465377807617, 0.96875\n",
      "Train loss and acc of batch 19: 48.0330924987793, 1.0\n",
      "Train loss and acc of batch 20: 48.033084869384766, 1.0\n",
      "Train loss and acc of batch 21: 48.62877655029297, 0.984375\n",
      "Train loss and acc of batch 22: 48.62876892089844, 0.984375\n",
      "Train loss and acc of batch 23: 48.24982452392578, 0.984375\n",
      "Train loss and acc of batch 24: 48.628753662109375, 0.984375\n",
      "Train loss and acc of batch 25: 48.033042907714844, 1.0\n",
      "Train loss and acc of batch 26: 48.03303527832031, 1.0\n",
      "Train loss and acc of batch 27: 48.03302001953125, 1.0\n",
      "Train loss and acc of batch 28: 48.03301239013672, 1.0\n",
      "Train loss and acc of batch 29: 48.628700256347656, 0.984375\n",
      "Train loss and acc of batch 30: 48.032997131347656, 1.0\n",
      "Train loss and acc of batch 31: 48.24974822998047, 0.984375\n",
      "Train loss and acc of batch 32: 48.03297805786133, 1.0\n",
      "Train loss and acc of batch 33: 48.03296661376953, 1.0\n",
      "Train loss and acc of batch 34: 48.628662109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.46647644042969, 0.96875\n",
      "Train loss and acc of batch 36: 48.03293991088867, 1.0\n",
      "Train loss and acc of batch 37: 48.786155700683594, 0.984375\n",
      "Train loss and acc of batch 38: 49.38185119628906, 0.96875\n",
      "Train loss and acc of batch 39: 48.24967956542969, 0.984375\n",
      "Train loss and acc of batch 40: 48.03290939331055, 1.0\n",
      "Train loss and acc of batch 41: 49.38182830810547, 0.96875\n",
      "Train loss and acc of batch 42: 48.03289031982422, 1.0\n",
      "Train loss and acc of batch 43: 48.628578186035156, 0.984375\n",
      "Train loss and acc of batch 44: 48.03287124633789, 1.0\n",
      "Train loss and acc of batch 45: 48.628562927246094, 0.984375\n",
      "Train loss and acc of batch 46: 48.318702697753906, 0.984375\n",
      "Train loss and acc of batch 47: 48.032840728759766, 1.0\n",
      "Train loss and acc of batch 48: 48.032833099365234, 1.0\n",
      "Train loss and acc of batch 49: 48.0328254699707, 1.0\n",
      "Train loss and acc of batch 50: 48.628517150878906, 0.984375\n",
      "Train loss and acc of batch 51: 49.38172912597656, 0.96875\n",
      "Train loss and acc of batch 52: 49.28864288330078, 0.953125\n",
      "Train loss and acc of batch 53: 48.03279113769531, 1.0\n",
      "Train loss and acc of batch 54: 48.249549865722656, 0.984375\n",
      "Train loss and acc of batch 55: 48.032772064208984, 1.0\n",
      "Train loss and acc of batch 56: 48.03276443481445, 1.0\n",
      "Train loss and acc of batch 57: 48.628456115722656, 0.984375\n",
      "Train loss and acc of batch 58: 48.03274154663086, 1.0\n",
      "Train loss and acc of batch 59: 48.032737731933594, 1.0\n",
      "Train loss and acc of batch 60: 48.0327262878418, 1.0\n",
      "Train loss and acc of batch 61: 48.032718658447266, 1.0\n",
      "Train loss and acc of batch 62: 48.249473571777344, 0.984375\n",
      "Train loss and acc of batch 63: 49.22410202026367, 0.96875\n",
      "Train loss and acc of batch 64: 48.24945068359375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 48.032684326171875, 1.0\n",
      "Train loss and acc of batch 66: 48.03267288208008, 1.0\n",
      "Train loss and acc of batch 67: 48.84513473510742, 0.96875\n",
      "Train loss and acc of batch 68: 48.62836456298828, 0.984375\n",
      "Train loss and acc of batch 69: 48.249412536621094, 0.984375\n",
      "Train loss and acc of batch 70: 48.03263854980469, 1.0\n",
      "Training accuracy and loss of epoch #41: 0.9890, 48.3640\n",
      "Saved model by train loss 48.36396660603268\n",
      "Train loss and acc of batch 0: 48.03262710571289, 1.0\n",
      "Train loss and acc of batch 1: 48.03261947631836, 1.0\n",
      "Train loss and acc of batch 2: 48.31846618652344, 0.984375\n",
      "Train loss and acc of batch 3: 48.249366760253906, 0.984375\n",
      "Train loss and acc of batch 4: 48.0325927734375, 1.0\n",
      "Train loss and acc of batch 5: 49.381507873535156, 0.96875\n",
      "Train loss and acc of batch 6: 48.535194396972656, 0.96875\n",
      "Train loss and acc of batch 7: 48.03256607055664, 1.0\n",
      "Train loss and acc of batch 8: 48.628257751464844, 0.984375\n",
      "Train loss and acc of batch 9: 48.318397521972656, 0.984375\n",
      "Train loss and acc of batch 10: 48.03254318237305, 1.0\n",
      "Train loss and acc of batch 11: 48.03253173828125, 1.0\n",
      "Train loss and acc of batch 12: 48.785743713378906, 0.984375\n",
      "Train loss and acc of batch 13: 48.24927520751953, 0.984375\n",
      "Train loss and acc of batch 14: 48.249267578125, 0.984375\n",
      "Train loss and acc of batch 15: 48.628196716308594, 0.984375\n",
      "Train loss and acc of batch 16: 48.62818908691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.78569793701172, 0.984375\n",
      "Train loss and acc of batch 18: 48.91402053833008, 0.96875\n",
      "Train loss and acc of batch 19: 48.03246307373047, 1.0\n",
      "Train loss and acc of batch 20: 48.03245162963867, 1.0\n",
      "Train loss and acc of batch 21: 48.628143310546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.628135681152344, 0.984375\n",
      "Train loss and acc of batch 23: 48.249183654785156, 0.984375\n",
      "Train loss and acc of batch 24: 48.62812042236328, 0.984375\n",
      "Train loss and acc of batch 25: 48.032405853271484, 1.0\n",
      "Train loss and acc of batch 26: 48.03239822387695, 1.0\n",
      "Train loss and acc of batch 27: 48.03239059448242, 1.0\n",
      "Train loss and acc of batch 28: 48.03237533569336, 1.0\n",
      "Train loss and acc of batch 29: 48.628074645996094, 0.984375\n",
      "Train loss and acc of batch 30: 48.03235626220703, 1.0\n",
      "Train loss and acc of batch 31: 48.249114990234375, 0.984375\n",
      "Train loss and acc of batch 32: 48.03234100341797, 1.0\n",
      "Train loss and acc of batch 33: 48.0323371887207, 1.0\n",
      "Train loss and acc of batch 34: 48.628028869628906, 0.984375\n",
      "Train loss and acc of batch 35: 48.465843200683594, 0.96875\n",
      "Train loss and acc of batch 36: 48.03230667114258, 1.0\n",
      "Train loss and acc of batch 37: 48.7855224609375, 0.984375\n",
      "Train loss and acc of batch 38: 49.38121032714844, 0.96875\n",
      "Train loss and acc of batch 39: 48.249046325683594, 0.984375\n",
      "Train loss and acc of batch 40: 48.03227233886719, 1.0\n",
      "Train loss and acc of batch 41: 49.38119125366211, 0.96875\n",
      "Train loss and acc of batch 42: 48.03225326538086, 1.0\n",
      "Train loss and acc of batch 43: 48.62793731689453, 0.984375\n",
      "Train loss and acc of batch 44: 48.0322380065918, 1.0\n",
      "Train loss and acc of batch 45: 48.62792205810547, 0.984375\n",
      "Train loss and acc of batch 46: 48.31806945800781, 0.984375\n",
      "Train loss and acc of batch 47: 48.03221130371094, 1.0\n",
      "Train loss and acc of batch 48: 48.032203674316406, 1.0\n",
      "Train loss and acc of batch 49: 48.032188415527344, 1.0\n",
      "Train loss and acc of batch 50: 48.62788391113281, 0.984375\n",
      "Train loss and acc of batch 51: 49.38109588623047, 0.96875\n",
      "Train loss and acc of batch 52: 49.28800964355469, 0.953125\n",
      "Train loss and acc of batch 53: 48.03215408325195, 1.0\n",
      "Train loss and acc of batch 54: 48.24890899658203, 0.984375\n",
      "Train loss and acc of batch 55: 48.03213882446289, 1.0\n",
      "Train loss and acc of batch 56: 48.032127380371094, 1.0\n",
      "Train loss and acc of batch 57: 48.62781524658203, 0.984375\n",
      "Train loss and acc of batch 58: 48.032108306884766, 1.0\n",
      "Train loss and acc of batch 59: 48.032100677490234, 1.0\n",
      "Train loss and acc of batch 60: 48.0320930480957, 1.0\n",
      "Train loss and acc of batch 61: 48.03208541870117, 1.0\n",
      "Train loss and acc of batch 62: 48.24884033203125, 0.984375\n",
      "Train loss and acc of batch 63: 49.22346878051758, 0.96875\n",
      "Train loss and acc of batch 64: 48.24882507324219, 0.984375\n",
      "Train loss and acc of batch 65: 48.03204345703125, 1.0\n",
      "Train loss and acc of batch 66: 48.03204345703125, 1.0\n",
      "Train loss and acc of batch 67: 48.84449005126953, 0.96875\n",
      "Train loss and acc of batch 68: 48.627716064453125, 0.984375\n",
      "Train loss and acc of batch 69: 48.248779296875, 0.984375\n",
      "Train loss and acc of batch 70: 48.032005310058594, 1.0\n",
      "Training accuracy and loss of epoch #42: 0.9890, 48.3633\n",
      "Saved model by train loss 48.36333143207389\n",
      "Train loss and acc of batch 0: 48.03199005126953, 1.0\n",
      "Train loss and acc of batch 1: 48.031982421875, 1.0\n",
      "Train loss and acc of batch 2: 48.31782531738281, 0.984375\n",
      "Train loss and acc of batch 3: 48.24873352050781, 0.984375\n",
      "Train loss and acc of batch 4: 48.031959533691406, 1.0\n",
      "Train loss and acc of batch 5: 49.38086700439453, 0.96875\n",
      "Train loss and acc of batch 6: 48.53456115722656, 0.96875\n",
      "Train loss and acc of batch 7: 48.03193283081055, 1.0\n",
      "Train loss and acc of batch 8: 48.62762451171875, 0.984375\n",
      "Train loss and acc of batch 9: 48.31776428222656, 0.984375\n",
      "Train loss and acc of batch 10: 48.03190231323242, 1.0\n",
      "Train loss and acc of batch 11: 48.031890869140625, 1.0\n",
      "Train loss and acc of batch 12: 48.78511428833008, 0.984375\n",
      "Train loss and acc of batch 13: 48.24864196777344, 0.984375\n",
      "Train loss and acc of batch 14: 48.248626708984375, 0.984375\n",
      "Train loss and acc of batch 15: 48.62755584716797, 0.984375\n",
      "Train loss and acc of batch 16: 48.62755584716797, 0.984375\n",
      "Train loss and acc of batch 17: 48.785064697265625, 0.984375\n",
      "Train loss and acc of batch 18: 48.91339111328125, 0.96875\n",
      "Train loss and acc of batch 19: 48.031822204589844, 1.0\n",
      "Train loss and acc of batch 20: 48.03181838989258, 1.0\n",
      "Train loss and acc of batch 21: 48.62750244140625, 0.984375\n",
      "Train loss and acc of batch 22: 48.62749481201172, 0.984375\n",
      "Train loss and acc of batch 23: 48.24855041503906, 0.984375\n",
      "Train loss and acc of batch 24: 48.627471923828125, 0.984375\n",
      "Train loss and acc of batch 25: 48.031768798828125, 1.0\n",
      "Train loss and acc of batch 26: 48.03176498413086, 1.0\n",
      "Train loss and acc of batch 27: 48.03175354003906, 1.0\n",
      "Train loss and acc of batch 28: 48.031742095947266, 1.0\n",
      "Train loss and acc of batch 29: 48.62743377685547, 0.984375\n",
      "Train loss and acc of batch 30: 48.03172302246094, 1.0\n",
      "Train loss and acc of batch 31: 48.24848175048828, 0.984375\n",
      "Train loss and acc of batch 32: 48.03171157836914, 1.0\n",
      "Train loss and acc of batch 33: 48.031700134277344, 1.0\n",
      "Train loss and acc of batch 34: 48.62739562988281, 0.984375\n",
      "Train loss and acc of batch 35: 48.465213775634766, 0.96875\n",
      "Train loss and acc of batch 36: 48.03166961669922, 1.0\n",
      "Train loss and acc of batch 37: 48.78488540649414, 0.984375\n",
      "Train loss and acc of batch 38: 49.380577087402344, 0.96875\n",
      "Train loss and acc of batch 39: 48.24840545654297, 0.984375\n",
      "Train loss and acc of batch 40: 48.03163528442383, 1.0\n",
      "Train loss and acc of batch 41: 49.380550384521484, 0.96875\n",
      "Train loss and acc of batch 42: 48.0316162109375, 1.0\n",
      "Train loss and acc of batch 43: 48.62731170654297, 0.984375\n",
      "Train loss and acc of batch 44: 48.03159713745117, 1.0\n",
      "Train loss and acc of batch 45: 48.627296447753906, 0.984375\n",
      "Train loss and acc of batch 46: 48.31743621826172, 0.984375\n",
      "Train loss and acc of batch 47: 48.03157043457031, 1.0\n",
      "Train loss and acc of batch 48: 48.03156661987305, 1.0\n",
      "Train loss and acc of batch 49: 48.03155517578125, 1.0\n",
      "Train loss and acc of batch 50: 48.62725067138672, 0.984375\n",
      "Train loss and acc of batch 51: 49.380470275878906, 0.96875\n",
      "Train loss and acc of batch 52: 49.2873649597168, 0.953125\n",
      "Train loss and acc of batch 53: 48.031517028808594, 1.0\n",
      "Train loss and acc of batch 54: 48.24827575683594, 0.984375\n",
      "Train loss and acc of batch 55: 48.0315055847168, 1.0\n",
      "Train loss and acc of batch 56: 48.031494140625, 1.0\n",
      "Train loss and acc of batch 57: 48.62718963623047, 0.984375\n",
      "Train loss and acc of batch 58: 48.031471252441406, 1.0\n",
      "Train loss and acc of batch 59: 48.03146743774414, 1.0\n",
      "Train loss and acc of batch 60: 48.03145980834961, 1.0\n",
      "Train loss and acc of batch 61: 48.03144836425781, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 62: 48.248207092285156, 0.984375\n",
      "Train loss and acc of batch 63: 49.222835540771484, 0.96875\n",
      "Train loss and acc of batch 64: 48.248191833496094, 0.984375\n",
      "Train loss and acc of batch 65: 48.03141403198242, 1.0\n",
      "Train loss and acc of batch 66: 48.031402587890625, 1.0\n",
      "Train loss and acc of batch 67: 48.84385681152344, 0.96875\n",
      "Train loss and acc of batch 68: 48.62709045410156, 0.984375\n",
      "Train loss and acc of batch 69: 48.248138427734375, 0.984375\n",
      "Train loss and acc of batch 70: 48.031368255615234, 1.0\n",
      "Training accuracy and loss of epoch #43: 0.9890, 48.3627\n",
      "Saved model by train loss 48.362696150658834\n",
      "Train loss and acc of batch 0: 48.0313606262207, 1.0\n",
      "Train loss and acc of batch 1: 48.03135299682617, 1.0\n",
      "Train loss and acc of batch 2: 48.31719207763672, 0.984375\n",
      "Train loss and acc of batch 3: 48.24810028076172, 0.984375\n",
      "Train loss and acc of batch 4: 48.03132247924805, 1.0\n",
      "Train loss and acc of batch 5: 49.38024139404297, 0.96875\n",
      "Train loss and acc of batch 6: 48.53392028808594, 0.96875\n",
      "Train loss and acc of batch 7: 48.03129577636719, 1.0\n",
      "Train loss and acc of batch 8: 48.626991271972656, 0.984375\n",
      "Train loss and acc of batch 9: 48.31712341308594, 0.984375\n",
      "Train loss and acc of batch 10: 48.03126907348633, 1.0\n",
      "Train loss and acc of batch 11: 48.0312614440918, 1.0\n",
      "Train loss and acc of batch 12: 48.78447723388672, 0.984375\n",
      "Train loss and acc of batch 13: 48.248008728027344, 0.984375\n",
      "Train loss and acc of batch 14: 48.24800109863281, 0.984375\n",
      "Train loss and acc of batch 15: 48.626922607421875, 0.984375\n",
      "Train loss and acc of batch 16: 48.626914978027344, 0.984375\n",
      "Train loss and acc of batch 17: 48.784423828125, 0.984375\n",
      "Train loss and acc of batch 18: 48.91275405883789, 0.96875\n",
      "Train loss and acc of batch 19: 48.03118896484375, 1.0\n",
      "Train loss and acc of batch 20: 48.03118133544922, 1.0\n",
      "Train loss and acc of batch 21: 48.62687683105469, 0.984375\n",
      "Train loss and acc of batch 22: 48.626861572265625, 0.984375\n",
      "Train loss and acc of batch 23: 48.24791717529297, 0.984375\n",
      "Train loss and acc of batch 24: 48.62684631347656, 0.984375\n",
      "Train loss and acc of batch 25: 48.03113555908203, 1.0\n",
      "Train loss and acc of batch 26: 48.031124114990234, 1.0\n",
      "Train loss and acc of batch 27: 48.0311164855957, 1.0\n",
      "Train loss and acc of batch 28: 48.03111267089844, 1.0\n",
      "Train loss and acc of batch 29: 48.626800537109375, 0.984375\n",
      "Train loss and acc of batch 30: 48.031097412109375, 1.0\n",
      "Train loss and acc of batch 31: 48.24784851074219, 0.984375\n",
      "Train loss and acc of batch 32: 48.031070709228516, 1.0\n",
      "Train loss and acc of batch 33: 48.031063079833984, 1.0\n",
      "Train loss and acc of batch 34: 48.62675476074219, 0.984375\n",
      "Train loss and acc of batch 35: 48.46457290649414, 0.96875\n",
      "Train loss and acc of batch 36: 48.031036376953125, 1.0\n",
      "Train loss and acc of batch 37: 48.78425216674805, 0.984375\n",
      "Train loss and acc of batch 38: 49.37994384765625, 0.96875\n",
      "Train loss and acc of batch 39: 48.247772216796875, 0.984375\n",
      "Train loss and acc of batch 40: 48.03099822998047, 1.0\n",
      "Train loss and acc of batch 41: 49.379920959472656, 0.96875\n",
      "Train loss and acc of batch 42: 48.030982971191406, 1.0\n",
      "Train loss and acc of batch 43: 48.626678466796875, 0.984375\n",
      "Train loss and acc of batch 44: 48.030967712402344, 1.0\n",
      "Train loss and acc of batch 45: 48.62665557861328, 0.984375\n",
      "Train loss and acc of batch 46: 48.316802978515625, 0.984375\n",
      "Train loss and acc of batch 47: 48.03093719482422, 1.0\n",
      "Train loss and acc of batch 48: 48.03092956542969, 1.0\n",
      "Train loss and acc of batch 49: 48.030921936035156, 1.0\n",
      "Train loss and acc of batch 50: 48.626609802246094, 0.984375\n",
      "Train loss and acc of batch 51: 49.37982940673828, 0.96875\n",
      "Train loss and acc of batch 52: 49.2867317199707, 0.953125\n",
      "Train loss and acc of batch 53: 48.0308837890625, 1.0\n",
      "Train loss and acc of batch 54: 48.24763488769531, 0.984375\n",
      "Train loss and acc of batch 55: 48.03086853027344, 1.0\n",
      "Train loss and acc of batch 56: 48.030853271484375, 1.0\n",
      "Train loss and acc of batch 57: 48.626556396484375, 0.984375\n",
      "Train loss and acc of batch 58: 48.03084182739258, 1.0\n",
      "Train loss and acc of batch 59: 48.030826568603516, 1.0\n",
      "Train loss and acc of batch 60: 48.030818939208984, 1.0\n",
      "Train loss and acc of batch 61: 48.03081130981445, 1.0\n",
      "Train loss and acc of batch 62: 48.24756622314453, 0.984375\n",
      "Train loss and acc of batch 63: 49.222198486328125, 0.96875\n",
      "Train loss and acc of batch 64: 48.24755096435547, 0.984375\n",
      "Train loss and acc of batch 65: 48.03077697753906, 1.0\n",
      "Train loss and acc of batch 66: 48.03076934814453, 1.0\n",
      "Train loss and acc of batch 67: 48.84322738647461, 0.96875\n",
      "Train loss and acc of batch 68: 48.62644958496094, 0.984375\n",
      "Train loss and acc of batch 69: 48.24750518798828, 0.984375\n",
      "Train loss and acc of batch 70: 48.03073501586914, 1.0\n",
      "Training accuracy and loss of epoch #44: 0.9890, 48.3621\n",
      "Saved model by train loss 48.3620612453407\n",
      "Train loss and acc of batch 0: 48.030723571777344, 1.0\n",
      "Train loss and acc of batch 1: 48.03071594238281, 1.0\n",
      "Train loss and acc of batch 2: 48.316551208496094, 0.984375\n",
      "Train loss and acc of batch 3: 48.247467041015625, 0.984375\n",
      "Train loss and acc of batch 4: 48.03068542480469, 1.0\n",
      "Train loss and acc of batch 5: 49.379600524902344, 0.96875\n",
      "Train loss and acc of batch 6: 48.533287048339844, 0.96875\n",
      "Train loss and acc of batch 7: 48.030662536621094, 1.0\n",
      "Train loss and acc of batch 8: 48.62635040283203, 0.984375\n",
      "Train loss and acc of batch 9: 48.316497802734375, 0.984375\n",
      "Train loss and acc of batch 10: 48.03063201904297, 1.0\n",
      "Train loss and acc of batch 11: 48.03062438964844, 1.0\n",
      "Train loss and acc of batch 12: 48.783843994140625, 0.984375\n",
      "Train loss and acc of batch 13: 48.24737548828125, 0.984375\n",
      "Train loss and acc of batch 14: 48.24736022949219, 0.984375\n",
      "Train loss and acc of batch 15: 48.62628936767578, 0.984375\n",
      "Train loss and acc of batch 16: 48.62628173828125, 0.984375\n",
      "Train loss and acc of batch 17: 48.78379440307617, 0.984375\n",
      "Train loss and acc of batch 18: 48.9121208190918, 0.96875\n",
      "Train loss and acc of batch 19: 48.03055191040039, 1.0\n",
      "Train loss and acc of batch 20: 48.03054428100586, 1.0\n",
      "Train loss and acc of batch 21: 48.62623596191406, 0.984375\n",
      "Train loss and acc of batch 22: 48.62622833251953, 0.984375\n",
      "Train loss and acc of batch 23: 48.247283935546875, 0.984375\n",
      "Train loss and acc of batch 24: 48.62621307373047, 0.984375\n",
      "Train loss and acc of batch 25: 48.03050231933594, 1.0\n",
      "Train loss and acc of batch 26: 48.030494689941406, 1.0\n",
      "Train loss and acc of batch 27: 48.03048324584961, 1.0\n",
      "Train loss and acc of batch 28: 48.03047561645508, 1.0\n",
      "Train loss and acc of batch 29: 48.62616729736328, 0.984375\n",
      "Train loss and acc of batch 30: 48.03045654296875, 1.0\n",
      "Train loss and acc of batch 31: 48.247215270996094, 0.984375\n",
      "Train loss and acc of batch 32: 48.03043746948242, 1.0\n",
      "Train loss and acc of batch 33: 48.030426025390625, 1.0\n",
      "Train loss and acc of batch 34: 48.626121520996094, 0.984375\n",
      "Train loss and acc of batch 35: 48.46393585205078, 0.96875\n",
      "Train loss and acc of batch 36: 48.03040313720703, 1.0\n",
      "Train loss and acc of batch 37: 48.78361892700195, 0.984375\n",
      "Train loss and acc of batch 38: 49.379310607910156, 0.96875\n",
      "Train loss and acc of batch 39: 48.24714660644531, 0.984375\n",
      "Train loss and acc of batch 40: 48.03036880493164, 1.0\n",
      "Train loss and acc of batch 41: 49.3792839050293, 0.96875\n",
      "Train loss and acc of batch 42: 48.03034591674805, 1.0\n",
      "Train loss and acc of batch 43: 48.62603759765625, 0.984375\n",
      "Train loss and acc of batch 44: 48.03033447265625, 1.0\n",
      "Train loss and acc of batch 45: 48.62602233886719, 0.984375\n",
      "Train loss and acc of batch 46: 48.31616973876953, 0.984375\n",
      "Train loss and acc of batch 47: 48.030303955078125, 1.0\n",
      "Train loss and acc of batch 48: 48.03029251098633, 1.0\n",
      "Train loss and acc of batch 49: 48.0302848815918, 1.0\n",
      "Train loss and acc of batch 50: 48.62598419189453, 0.984375\n",
      "Train loss and acc of batch 51: 49.37919616699219, 0.96875\n",
      "Train loss and acc of batch 52: 49.28609848022461, 0.953125\n",
      "Train loss and acc of batch 53: 48.030250549316406, 1.0\n",
      "Train loss and acc of batch 54: 48.24700927734375, 0.984375\n",
      "Train loss and acc of batch 55: 48.03023147583008, 1.0\n",
      "Train loss and acc of batch 56: 48.03022384643555, 1.0\n",
      "Train loss and acc of batch 57: 48.62591552734375, 0.984375\n",
      "Train loss and acc of batch 58: 48.030208587646484, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 59: 48.03019714355469, 1.0\n",
      "Train loss and acc of batch 60: 48.03018569946289, 1.0\n",
      "Train loss and acc of batch 61: 48.030181884765625, 1.0\n",
      "Train loss and acc of batch 62: 48.24693298339844, 0.984375\n",
      "Train loss and acc of batch 63: 49.221561431884766, 0.96875\n",
      "Train loss and acc of batch 64: 48.246917724609375, 0.984375\n",
      "Train loss and acc of batch 65: 48.030147552490234, 1.0\n",
      "Train loss and acc of batch 66: 48.03013229370117, 1.0\n",
      "Train loss and acc of batch 67: 48.842594146728516, 0.96875\n",
      "Train loss and acc of batch 68: 48.625816345214844, 0.984375\n",
      "Train loss and acc of batch 69: 48.24687194824219, 0.984375\n",
      "Train loss and acc of batch 70: 48.030094146728516, 1.0\n",
      "Training accuracy and loss of epoch #45: 0.9890, 48.3614\n",
      "Saved model by train loss 48.36142693103199\n",
      "Train loss and acc of batch 0: 48.03009033203125, 1.0\n",
      "Train loss and acc of batch 1: 48.03008270263672, 1.0\n",
      "Train loss and acc of batch 2: 48.31592559814453, 0.984375\n",
      "Train loss and acc of batch 3: 48.246826171875, 0.984375\n",
      "Train loss and acc of batch 4: 48.03005599975586, 1.0\n",
      "Train loss and acc of batch 5: 49.37896728515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.53265380859375, 0.96875\n",
      "Train loss and acc of batch 7: 48.030025482177734, 1.0\n",
      "Train loss and acc of batch 8: 48.62571716308594, 0.984375\n",
      "Train loss and acc of batch 9: 48.31585693359375, 0.984375\n",
      "Train loss and acc of batch 10: 48.029998779296875, 1.0\n",
      "Train loss and acc of batch 11: 48.029991149902344, 1.0\n",
      "Train loss and acc of batch 12: 48.78321075439453, 0.984375\n",
      "Train loss and acc of batch 13: 48.246734619140625, 0.984375\n",
      "Train loss and acc of batch 14: 48.246726989746094, 0.984375\n",
      "Train loss and acc of batch 15: 48.62565612792969, 0.984375\n",
      "Train loss and acc of batch 16: 48.625648498535156, 0.984375\n",
      "Train loss and acc of batch 17: 48.78316116333008, 0.984375\n",
      "Train loss and acc of batch 18: 48.91148376464844, 0.96875\n",
      "Train loss and acc of batch 19: 48.02992248535156, 1.0\n",
      "Train loss and acc of batch 20: 48.02991485595703, 1.0\n",
      "Train loss and acc of batch 21: 48.62560272216797, 0.984375\n",
      "Train loss and acc of batch 22: 48.625587463378906, 0.984375\n",
      "Train loss and acc of batch 23: 48.24665069580078, 0.984375\n",
      "Train loss and acc of batch 24: 48.625579833984375, 0.984375\n",
      "Train loss and acc of batch 25: 48.029869079589844, 1.0\n",
      "Train loss and acc of batch 26: 48.02985763549805, 1.0\n",
      "Train loss and acc of batch 27: 48.02984619140625, 1.0\n",
      "Train loss and acc of batch 28: 48.02983474731445, 1.0\n",
      "Train loss and acc of batch 29: 48.62553405761719, 0.984375\n",
      "Train loss and acc of batch 30: 48.02981948852539, 1.0\n",
      "Train loss and acc of batch 31: 48.24657440185547, 0.984375\n",
      "Train loss and acc of batch 32: 48.02980422973633, 1.0\n",
      "Train loss and acc of batch 33: 48.0297966003418, 1.0\n",
      "Train loss and acc of batch 34: 48.62548065185547, 0.984375\n",
      "Train loss and acc of batch 35: 48.46331024169922, 0.96875\n",
      "Train loss and acc of batch 36: 48.02976608276367, 1.0\n",
      "Train loss and acc of batch 37: 48.782981872558594, 0.984375\n",
      "Train loss and acc of batch 38: 49.37866973876953, 0.96875\n",
      "Train loss and acc of batch 39: 48.24650573730469, 0.984375\n",
      "Train loss and acc of batch 40: 48.02973175048828, 1.0\n",
      "Train loss and acc of batch 41: 49.37864685058594, 0.96875\n",
      "Train loss and acc of batch 42: 48.02971267700195, 1.0\n",
      "Train loss and acc of batch 43: 48.625404357910156, 0.984375\n",
      "Train loss and acc of batch 44: 48.02969741821289, 1.0\n",
      "Train loss and acc of batch 45: 48.625389099121094, 0.984375\n",
      "Train loss and acc of batch 46: 48.315528869628906, 0.984375\n",
      "Train loss and acc of batch 47: 48.02967071533203, 1.0\n",
      "Train loss and acc of batch 48: 48.0296630859375, 1.0\n",
      "Train loss and acc of batch 49: 48.02964401245117, 1.0\n",
      "Train loss and acc of batch 50: 48.625343322753906, 0.984375\n",
      "Train loss and acc of batch 51: 49.37855529785156, 0.96875\n",
      "Train loss and acc of batch 52: 49.28546905517578, 0.953125\n",
      "Train loss and acc of batch 53: 48.02961730957031, 1.0\n",
      "Train loss and acc of batch 54: 48.246376037597656, 0.984375\n",
      "Train loss and acc of batch 55: 48.029598236083984, 1.0\n",
      "Train loss and acc of batch 56: 48.02959060668945, 1.0\n",
      "Train loss and acc of batch 57: 48.625282287597656, 0.984375\n",
      "Train loss and acc of batch 58: 48.02956771850586, 1.0\n",
      "Train loss and acc of batch 59: 48.02956008911133, 1.0\n",
      "Train loss and acc of batch 60: 48.0295524597168, 1.0\n",
      "Train loss and acc of batch 61: 48.029541015625, 1.0\n",
      "Train loss and acc of batch 62: 48.246299743652344, 0.984375\n",
      "Train loss and acc of batch 63: 49.22092819213867, 0.96875\n",
      "Train loss and acc of batch 64: 48.24627685546875, 0.984375\n",
      "Train loss and acc of batch 65: 48.02950668334961, 1.0\n",
      "Train loss and acc of batch 66: 48.02949905395508, 1.0\n",
      "Train loss and acc of batch 67: 48.841957092285156, 0.96875\n",
      "Train loss and acc of batch 68: 48.62518310546875, 0.984375\n",
      "Train loss and acc of batch 69: 48.246238708496094, 0.984375\n",
      "Train loss and acc of batch 70: 48.02946472167969, 1.0\n",
      "Training accuracy and loss of epoch #46: 0.9890, 48.3608\n",
      "Saved model by train loss 48.36079181080133\n",
      "Train loss and acc of batch 0: 48.02945327758789, 1.0\n",
      "Train loss and acc of batch 1: 48.029441833496094, 1.0\n",
      "Train loss and acc of batch 2: 48.31529235839844, 0.984375\n",
      "Train loss and acc of batch 3: 48.246192932128906, 0.984375\n",
      "Train loss and acc of batch 4: 48.0294189453125, 1.0\n",
      "Train loss and acc of batch 5: 49.378334045410156, 0.96875\n",
      "Train loss and acc of batch 6: 48.53201675415039, 0.96875\n",
      "Train loss and acc of batch 7: 48.029388427734375, 1.0\n",
      "Train loss and acc of batch 8: 48.625083923339844, 0.984375\n",
      "Train loss and acc of batch 9: 48.315223693847656, 0.984375\n",
      "Train loss and acc of batch 10: 48.02936935424805, 1.0\n",
      "Train loss and acc of batch 11: 48.02935791015625, 1.0\n",
      "Train loss and acc of batch 12: 48.78257369995117, 0.984375\n",
      "Train loss and acc of batch 13: 48.24610137939453, 0.984375\n",
      "Train loss and acc of batch 14: 48.24609375, 0.984375\n",
      "Train loss and acc of batch 15: 48.62501525878906, 0.984375\n",
      "Train loss and acc of batch 16: 48.62500762939453, 0.984375\n",
      "Train loss and acc of batch 17: 48.78252410888672, 0.984375\n",
      "Train loss and acc of batch 18: 48.91084671020508, 0.96875\n",
      "Train loss and acc of batch 19: 48.0292854309082, 1.0\n",
      "Train loss and acc of batch 20: 48.02928161621094, 1.0\n",
      "Train loss and acc of batch 21: 48.624961853027344, 0.984375\n",
      "Train loss and acc of batch 22: 48.624961853027344, 0.984375\n",
      "Train loss and acc of batch 23: 48.246009826660156, 0.984375\n",
      "Train loss and acc of batch 24: 48.62493896484375, 0.984375\n",
      "Train loss and acc of batch 25: 48.029232025146484, 1.0\n",
      "Train loss and acc of batch 26: 48.02922058105469, 1.0\n",
      "Train loss and acc of batch 27: 48.029212951660156, 1.0\n",
      "Train loss and acc of batch 28: 48.02920913696289, 1.0\n",
      "Train loss and acc of batch 29: 48.62489318847656, 0.984375\n",
      "Train loss and acc of batch 30: 48.02918243408203, 1.0\n",
      "Train loss and acc of batch 31: 48.245941162109375, 0.984375\n",
      "Train loss and acc of batch 32: 48.029170989990234, 1.0\n",
      "Train loss and acc of batch 33: 48.02915954589844, 1.0\n",
      "Train loss and acc of batch 34: 48.624855041503906, 0.984375\n",
      "Train loss and acc of batch 35: 48.46267318725586, 0.96875\n",
      "Train loss and acc of batch 36: 48.02913284301758, 1.0\n",
      "Train loss and acc of batch 37: 48.782344818115234, 0.984375\n",
      "Train loss and acc of batch 38: 49.37804412841797, 0.96875\n",
      "Train loss and acc of batch 39: 48.245872497558594, 0.984375\n",
      "Train loss and acc of batch 40: 48.02909469604492, 1.0\n",
      "Train loss and acc of batch 41: 49.378013610839844, 0.96875\n",
      "Train loss and acc of batch 42: 48.02907943725586, 1.0\n",
      "Train loss and acc of batch 43: 48.62477111816406, 0.984375\n",
      "Train loss and acc of batch 44: 48.029056549072266, 1.0\n",
      "Train loss and acc of batch 45: 48.624755859375, 0.984375\n",
      "Train loss and acc of batch 46: 48.31489562988281, 0.984375\n",
      "Train loss and acc of batch 47: 48.02903747558594, 1.0\n",
      "Train loss and acc of batch 48: 48.029029846191406, 1.0\n",
      "Train loss and acc of batch 49: 48.02901840209961, 1.0\n",
      "Train loss and acc of batch 50: 48.62471008300781, 0.984375\n",
      "Train loss and acc of batch 51: 49.37792205810547, 0.96875\n",
      "Train loss and acc of batch 52: 49.284828186035156, 0.953125\n",
      "Train loss and acc of batch 53: 48.02897644042969, 1.0\n",
      "Train loss and acc of batch 54: 48.24573516845703, 0.984375\n",
      "Train loss and acc of batch 55: 48.028961181640625, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 56: 48.028953552246094, 1.0\n",
      "Train loss and acc of batch 57: 48.62464904785156, 0.984375\n",
      "Train loss and acc of batch 58: 48.028934478759766, 1.0\n",
      "Train loss and acc of batch 59: 48.028926849365234, 1.0\n",
      "Train loss and acc of batch 60: 48.0289192199707, 1.0\n",
      "Train loss and acc of batch 61: 48.028907775878906, 1.0\n",
      "Train loss and acc of batch 62: 48.24566650390625, 0.984375\n",
      "Train loss and acc of batch 63: 49.22029495239258, 0.96875\n",
      "Train loss and acc of batch 64: 48.24565124511719, 0.984375\n",
      "Train loss and acc of batch 65: 48.028873443603516, 1.0\n",
      "Train loss and acc of batch 66: 48.028865814208984, 1.0\n",
      "Train loss and acc of batch 67: 48.84131622314453, 0.96875\n",
      "Train loss and acc of batch 68: 48.624549865722656, 0.984375\n",
      "Train loss and acc of batch 69: 48.24559783935547, 0.984375\n",
      "Train loss and acc of batch 70: 48.028831481933594, 1.0\n",
      "Training accuracy and loss of epoch #47: 0.9890, 48.3602\n",
      "Saved model by train loss 48.360156959211324\n",
      "Train loss and acc of batch 0: 48.0288200378418, 1.0\n",
      "Train loss and acc of batch 1: 48.02880859375, 1.0\n",
      "Train loss and acc of batch 2: 48.31465148925781, 0.984375\n",
      "Train loss and acc of batch 3: 48.24555969238281, 0.984375\n",
      "Train loss and acc of batch 4: 48.028785705566406, 1.0\n",
      "Train loss and acc of batch 5: 49.37770080566406, 0.96875\n",
      "Train loss and acc of batch 6: 48.5313835144043, 0.96875\n",
      "Train loss and acc of batch 7: 48.02875900268555, 1.0\n",
      "Train loss and acc of batch 8: 48.62445068359375, 0.984375\n",
      "Train loss and acc of batch 9: 48.31459045410156, 0.984375\n",
      "Train loss and acc of batch 10: 48.02872848510742, 1.0\n",
      "Train loss and acc of batch 11: 48.028717041015625, 1.0\n",
      "Train loss and acc of batch 12: 48.78193283081055, 0.984375\n",
      "Train loss and acc of batch 13: 48.24546813964844, 0.984375\n",
      "Train loss and acc of batch 14: 48.245460510253906, 0.984375\n",
      "Train loss and acc of batch 15: 48.6243896484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.62437438964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.781890869140625, 0.984375\n",
      "Train loss and acc of batch 18: 48.910213470458984, 0.96875\n",
      "Train loss and acc of batch 19: 48.028648376464844, 1.0\n",
      "Train loss and acc of batch 20: 48.02864074707031, 1.0\n",
      "Train loss and acc of batch 21: 48.62432861328125, 0.984375\n",
      "Train loss and acc of batch 22: 48.62432098388672, 0.984375\n",
      "Train loss and acc of batch 23: 48.24537658691406, 0.984375\n",
      "Train loss and acc of batch 24: 48.624305725097656, 0.984375\n",
      "Train loss and acc of batch 25: 48.02859115600586, 1.0\n",
      "Train loss and acc of batch 26: 48.028587341308594, 1.0\n",
      "Train loss and acc of batch 27: 48.02857971191406, 1.0\n",
      "Train loss and acc of batch 28: 48.02857208251953, 1.0\n",
      "Train loss and acc of batch 29: 48.62425994873047, 0.984375\n",
      "Train loss and acc of batch 30: 48.0285530090332, 1.0\n",
      "Train loss and acc of batch 31: 48.24530792236328, 0.984375\n",
      "Train loss and acc of batch 32: 48.02853012084961, 1.0\n",
      "Train loss and acc of batch 33: 48.02852249145508, 1.0\n",
      "Train loss and acc of batch 34: 48.62421417236328, 0.984375\n",
      "Train loss and acc of batch 35: 48.4620361328125, 0.96875\n",
      "Train loss and acc of batch 36: 48.028499603271484, 1.0\n",
      "Train loss and acc of batch 37: 48.781715393066406, 0.984375\n",
      "Train loss and acc of batch 38: 49.377403259277344, 0.96875\n",
      "Train loss and acc of batch 39: 48.24523162841797, 0.984375\n",
      "Train loss and acc of batch 40: 48.02846145629883, 1.0\n",
      "Train loss and acc of batch 41: 49.37738037109375, 0.96875\n",
      "Train loss and acc of batch 42: 48.028446197509766, 1.0\n",
      "Train loss and acc of batch 43: 48.62413787841797, 0.984375\n",
      "Train loss and acc of batch 44: 48.02842712402344, 1.0\n",
      "Train loss and acc of batch 45: 48.624114990234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.31426239013672, 0.984375\n",
      "Train loss and acc of batch 47: 48.02840042114258, 1.0\n",
      "Train loss and acc of batch 48: 48.02838897705078, 1.0\n",
      "Train loss and acc of batch 49: 48.02838134765625, 1.0\n",
      "Train loss and acc of batch 50: 48.62407684326172, 0.984375\n",
      "Train loss and acc of batch 51: 49.377288818359375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2841911315918, 0.953125\n",
      "Train loss and acc of batch 53: 48.028343200683594, 1.0\n",
      "Train loss and acc of batch 54: 48.24510192871094, 0.984375\n",
      "Train loss and acc of batch 55: 48.02832794189453, 1.0\n",
      "Train loss and acc of batch 56: 48.0283203125, 1.0\n",
      "Train loss and acc of batch 57: 48.62400817871094, 0.984375\n",
      "Train loss and acc of batch 58: 48.02830123901367, 1.0\n",
      "Train loss and acc of batch 59: 48.028289794921875, 1.0\n",
      "Train loss and acc of batch 60: 48.02828598022461, 1.0\n",
      "Train loss and acc of batch 61: 48.02827072143555, 1.0\n",
      "Train loss and acc of batch 62: 48.245033264160156, 0.984375\n",
      "Train loss and acc of batch 63: 49.219661712646484, 0.96875\n",
      "Train loss and acc of batch 64: 48.24501037597656, 0.984375\n",
      "Train loss and acc of batch 65: 48.02824401855469, 1.0\n",
      "Train loss and acc of batch 66: 48.028228759765625, 1.0\n",
      "Train loss and acc of batch 67: 48.84068298339844, 0.96875\n",
      "Train loss and acc of batch 68: 48.62391662597656, 0.984375\n",
      "Train loss and acc of batch 69: 48.244964599609375, 0.984375\n",
      "Train loss and acc of batch 70: 48.02819061279297, 1.0\n",
      "Training accuracy and loss of epoch #48: 0.9890, 48.3595\n",
      "Saved model by train loss 48.35952183898066\n",
      "Train loss and acc of batch 0: 48.0281867980957, 1.0\n",
      "Train loss and acc of batch 1: 48.028175354003906, 1.0\n",
      "Train loss and acc of batch 2: 48.31402587890625, 0.984375\n",
      "Train loss and acc of batch 3: 48.24491882324219, 0.984375\n",
      "Train loss and acc of batch 4: 48.02814865112305, 1.0\n",
      "Train loss and acc of batch 5: 49.37706756591797, 0.96875\n",
      "Train loss and acc of batch 6: 48.53074645996094, 0.96875\n",
      "Train loss and acc of batch 7: 48.02812194824219, 1.0\n",
      "Train loss and acc of batch 8: 48.623817443847656, 0.984375\n",
      "Train loss and acc of batch 9: 48.31395721435547, 0.984375\n",
      "Train loss and acc of batch 10: 48.02809143066406, 1.0\n",
      "Train loss and acc of batch 11: 48.0280876159668, 1.0\n",
      "Train loss and acc of batch 12: 48.78130340576172, 0.984375\n",
      "Train loss and acc of batch 13: 48.244834899902344, 0.984375\n",
      "Train loss and acc of batch 14: 48.24481964111328, 0.984375\n",
      "Train loss and acc of batch 15: 48.623756408691406, 0.984375\n",
      "Train loss and acc of batch 16: 48.623741149902344, 0.984375\n",
      "Train loss and acc of batch 17: 48.78125762939453, 0.984375\n",
      "Train loss and acc of batch 18: 48.90957260131836, 0.96875\n",
      "Train loss and acc of batch 19: 48.02801513671875, 1.0\n",
      "Train loss and acc of batch 20: 48.02800369262695, 1.0\n",
      "Train loss and acc of batch 21: 48.623695373535156, 0.984375\n",
      "Train loss and acc of batch 22: 48.623695373535156, 0.984375\n",
      "Train loss and acc of batch 23: 48.24474334716797, 0.984375\n",
      "Train loss and acc of batch 24: 48.62367248535156, 0.984375\n",
      "Train loss and acc of batch 25: 48.027957916259766, 1.0\n",
      "Train loss and acc of batch 26: 48.027950286865234, 1.0\n",
      "Train loss and acc of batch 27: 48.02793884277344, 1.0\n",
      "Train loss and acc of batch 28: 48.02793502807617, 1.0\n",
      "Train loss and acc of batch 29: 48.623626708984375, 0.984375\n",
      "Train loss and acc of batch 30: 48.02791976928711, 1.0\n",
      "Train loss and acc of batch 31: 48.24467468261719, 0.984375\n",
      "Train loss and acc of batch 32: 48.027896881103516, 1.0\n",
      "Train loss and acc of batch 33: 48.027889251708984, 1.0\n",
      "Train loss and acc of batch 34: 48.62358093261719, 0.984375\n",
      "Train loss and acc of batch 35: 48.46139907836914, 0.96875\n",
      "Train loss and acc of batch 36: 48.02786636352539, 1.0\n",
      "Train loss and acc of batch 37: 48.78107833862305, 0.984375\n",
      "Train loss and acc of batch 38: 49.37677001953125, 0.96875\n",
      "Train loss and acc of batch 39: 48.244598388671875, 0.984375\n",
      "Train loss and acc of batch 40: 48.027828216552734, 1.0\n",
      "Train loss and acc of batch 41: 49.376747131347656, 0.96875\n",
      "Train loss and acc of batch 42: 48.027809143066406, 1.0\n",
      "Train loss and acc of batch 43: 48.623504638671875, 0.984375\n",
      "Train loss and acc of batch 44: 48.027793884277344, 1.0\n",
      "Train loss and acc of batch 45: 48.62348175048828, 0.984375\n",
      "Train loss and acc of batch 46: 48.313629150390625, 0.984375\n",
      "Train loss and acc of batch 47: 48.02776336669922, 1.0\n",
      "Train loss and acc of batch 48: 48.02775573730469, 1.0\n",
      "Train loss and acc of batch 49: 48.02774429321289, 1.0\n",
      "Train loss and acc of batch 50: 48.623435974121094, 0.984375\n",
      "Train loss and acc of batch 51: 49.37665557861328, 0.96875\n",
      "Train loss and acc of batch 52: 49.28356170654297, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 48.0277099609375, 1.0\n",
      "Train loss and acc of batch 54: 48.244468688964844, 0.984375\n",
      "Train loss and acc of batch 55: 48.02769088745117, 1.0\n",
      "Train loss and acc of batch 56: 48.027687072753906, 1.0\n",
      "Train loss and acc of batch 57: 48.623374938964844, 0.984375\n",
      "Train loss and acc of batch 58: 48.027671813964844, 1.0\n",
      "Train loss and acc of batch 59: 48.02765655517578, 1.0\n",
      "Train loss and acc of batch 60: 48.027645111083984, 1.0\n",
      "Train loss and acc of batch 61: 48.02763748168945, 1.0\n",
      "Train loss and acc of batch 62: 48.24439239501953, 0.984375\n",
      "Train loss and acc of batch 63: 49.219024658203125, 0.96875\n",
      "Train loss and acc of batch 64: 48.24437713623047, 0.984375\n",
      "Train loss and acc of batch 65: 48.02760314941406, 1.0\n",
      "Train loss and acc of batch 66: 48.027591705322266, 1.0\n",
      "Train loss and acc of batch 67: 48.84005355834961, 0.96875\n",
      "Train loss and acc of batch 68: 48.62327575683594, 0.984375\n",
      "Train loss and acc of batch 69: 48.24433135986328, 0.984375\n",
      "Train loss and acc of batch 70: 48.027557373046875, 1.0\n",
      "Training accuracy and loss of epoch #49: 0.9890, 48.3589\n",
      "Saved model by train loss 48.35888730975944\n",
      "Train loss and acc of batch 0: 48.02755355834961, 1.0\n",
      "Train loss and acc of batch 1: 48.02754211425781, 1.0\n",
      "Train loss and acc of batch 2: 48.313385009765625, 0.984375\n",
      "Train loss and acc of batch 3: 48.244285583496094, 0.984375\n",
      "Train loss and acc of batch 4: 48.02751541137695, 1.0\n",
      "Train loss and acc of batch 5: 49.376426696777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.530113220214844, 0.96875\n",
      "Train loss and acc of batch 7: 48.02748489379883, 1.0\n",
      "Train loss and acc of batch 8: 48.62318420410156, 0.984375\n",
      "Train loss and acc of batch 9: 48.313323974609375, 0.984375\n",
      "Train loss and acc of batch 10: 48.027462005615234, 1.0\n",
      "Train loss and acc of batch 11: 48.02745056152344, 1.0\n",
      "Train loss and acc of batch 12: 48.780662536621094, 0.984375\n",
      "Train loss and acc of batch 13: 48.24420166015625, 0.984375\n",
      "Train loss and acc of batch 14: 48.24419403076172, 0.984375\n",
      "Train loss and acc of batch 15: 48.62311553955078, 0.984375\n",
      "Train loss and acc of batch 16: 48.62310791015625, 0.984375\n",
      "Train loss and acc of batch 17: 48.78062057495117, 0.984375\n",
      "Train loss and acc of batch 18: 48.9089469909668, 0.96875\n",
      "Train loss and acc of batch 19: 48.027381896972656, 1.0\n",
      "Train loss and acc of batch 20: 48.02737045288086, 1.0\n",
      "Train loss and acc of batch 21: 48.62306213378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.62305450439453, 0.984375\n",
      "Train loss and acc of batch 23: 48.244110107421875, 0.984375\n",
      "Train loss and acc of batch 24: 48.62303924560547, 0.984375\n",
      "Train loss and acc of batch 25: 48.02732849121094, 1.0\n",
      "Train loss and acc of batch 26: 48.02731704711914, 1.0\n",
      "Train loss and acc of batch 27: 48.02730941772461, 1.0\n",
      "Train loss and acc of batch 28: 48.02730178833008, 1.0\n",
      "Train loss and acc of batch 29: 48.62299346923828, 0.984375\n",
      "Train loss and acc of batch 30: 48.02728271484375, 1.0\n",
      "Train loss and acc of batch 31: 48.24403381347656, 0.984375\n",
      "Train loss and acc of batch 32: 48.02726745605469, 1.0\n",
      "Train loss and acc of batch 33: 48.027252197265625, 1.0\n",
      "Train loss and acc of batch 34: 48.62294006347656, 0.984375\n",
      "Train loss and acc of batch 35: 48.46076583862305, 0.96875\n",
      "Train loss and acc of batch 36: 48.027225494384766, 1.0\n",
      "Train loss and acc of batch 37: 48.78044509887695, 0.984375\n",
      "Train loss and acc of batch 38: 49.376136779785156, 0.96875\n",
      "Train loss and acc of batch 39: 48.24397277832031, 0.984375\n",
      "Train loss and acc of batch 40: 48.027191162109375, 1.0\n",
      "Train loss and acc of batch 41: 49.37611389160156, 0.96875\n",
      "Train loss and acc of batch 42: 48.02717590332031, 1.0\n",
      "Train loss and acc of batch 43: 48.62287139892578, 0.984375\n",
      "Train loss and acc of batch 44: 48.027156829833984, 1.0\n",
      "Train loss and acc of batch 45: 48.62284851074219, 0.984375\n",
      "Train loss and acc of batch 46: 48.31299591064453, 0.984375\n",
      "Train loss and acc of batch 47: 48.02713394165039, 1.0\n",
      "Train loss and acc of batch 48: 48.027122497558594, 1.0\n",
      "Train loss and acc of batch 49: 48.02710723876953, 1.0\n",
      "Train loss and acc of batch 50: 48.622802734375, 0.984375\n",
      "Train loss and acc of batch 51: 49.376014709472656, 0.96875\n",
      "Train loss and acc of batch 52: 49.282928466796875, 0.953125\n",
      "Train loss and acc of batch 53: 48.02708053588867, 1.0\n",
      "Train loss and acc of batch 54: 48.24383544921875, 0.984375\n",
      "Train loss and acc of batch 55: 48.02705764770508, 1.0\n",
      "Train loss and acc of batch 56: 48.02704620361328, 1.0\n",
      "Train loss and acc of batch 57: 48.62274169921875, 0.984375\n",
      "Train loss and acc of batch 58: 48.027034759521484, 1.0\n",
      "Train loss and acc of batch 59: 48.02701950073242, 1.0\n",
      "Train loss and acc of batch 60: 48.027015686035156, 1.0\n",
      "Train loss and acc of batch 61: 48.02700424194336, 1.0\n",
      "Train loss and acc of batch 62: 48.24376678466797, 0.984375\n",
      "Train loss and acc of batch 63: 49.2183952331543, 0.96875\n",
      "Train loss and acc of batch 64: 48.243743896484375, 0.984375\n",
      "Train loss and acc of batch 65: 48.0269660949707, 1.0\n",
      "Train loss and acc of batch 66: 48.02696228027344, 1.0\n",
      "Train loss and acc of batch 67: 48.839412689208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.622642517089844, 0.984375\n",
      "Train loss and acc of batch 69: 48.24369812011719, 0.984375\n",
      "Train loss and acc of batch 70: 48.02692413330078, 1.0\n",
      "Training accuracy and loss of epoch #50: 0.9890, 48.3583\n",
      "Saved model by train loss 48.35825321036325\n",
      "Train loss and acc of batch 0: 48.026920318603516, 1.0\n",
      "Train loss and acc of batch 1: 48.02690505981445, 1.0\n",
      "Train loss and acc of batch 2: 48.31275177001953, 0.984375\n",
      "Train loss and acc of batch 3: 48.24365234375, 0.984375\n",
      "Train loss and acc of batch 4: 48.026878356933594, 1.0\n",
      "Train loss and acc of batch 5: 49.37579345703125, 0.96875\n",
      "Train loss and acc of batch 6: 48.52947998046875, 0.96875\n",
      "Train loss and acc of batch 7: 48.026851654052734, 1.0\n",
      "Train loss and acc of batch 8: 48.62254333496094, 0.984375\n",
      "Train loss and acc of batch 9: 48.31269073486328, 0.984375\n",
      "Train loss and acc of batch 10: 48.026824951171875, 1.0\n",
      "Train loss and acc of batch 11: 48.026817321777344, 1.0\n",
      "Train loss and acc of batch 12: 48.780029296875, 0.984375\n",
      "Train loss and acc of batch 13: 48.243560791015625, 0.984375\n",
      "Train loss and acc of batch 14: 48.243560791015625, 0.984375\n",
      "Train loss and acc of batch 15: 48.62248229980469, 0.984375\n",
      "Train loss and acc of batch 16: 48.622474670410156, 0.984375\n",
      "Train loss and acc of batch 17: 48.77998733520508, 0.984375\n",
      "Train loss and acc of batch 18: 48.90830612182617, 0.96875\n",
      "Train loss and acc of batch 19: 48.0267448425293, 1.0\n",
      "Train loss and acc of batch 20: 48.02674102783203, 1.0\n",
      "Train loss and acc of batch 21: 48.62242889404297, 0.984375\n",
      "Train loss and acc of batch 22: 48.62242126464844, 0.984375\n",
      "Train loss and acc of batch 23: 48.24347686767578, 0.984375\n",
      "Train loss and acc of batch 24: 48.622398376464844, 0.984375\n",
      "Train loss and acc of batch 25: 48.02669143676758, 1.0\n",
      "Train loss and acc of batch 26: 48.02667999267578, 1.0\n",
      "Train loss and acc of batch 27: 48.02667236328125, 1.0\n",
      "Train loss and acc of batch 28: 48.026668548583984, 1.0\n",
      "Train loss and acc of batch 29: 48.622352600097656, 0.984375\n",
      "Train loss and acc of batch 30: 48.02664566040039, 1.0\n",
      "Train loss and acc of batch 31: 48.24340057373047, 0.984375\n",
      "Train loss and acc of batch 32: 48.02663040161133, 1.0\n",
      "Train loss and acc of batch 33: 48.0266227722168, 1.0\n",
      "Train loss and acc of batch 34: 48.622314453125, 0.984375\n",
      "Train loss and acc of batch 35: 48.46013259887695, 0.96875\n",
      "Train loss and acc of batch 36: 48.02659606933594, 1.0\n",
      "Train loss and acc of batch 37: 48.77981185913086, 0.984375\n",
      "Train loss and acc of batch 38: 49.37549591064453, 0.96875\n",
      "Train loss and acc of batch 39: 48.24333190917969, 0.984375\n",
      "Train loss and acc of batch 40: 48.026554107666016, 1.0\n",
      "Train loss and acc of batch 41: 49.3754768371582, 0.96875\n",
      "Train loss and acc of batch 42: 48.026546478271484, 1.0\n",
      "Train loss and acc of batch 43: 48.62223815917969, 0.984375\n",
      "Train loss and acc of batch 44: 48.026519775390625, 1.0\n",
      "Train loss and acc of batch 45: 48.622215270996094, 0.984375\n",
      "Train loss and acc of batch 46: 48.312355041503906, 0.984375\n",
      "Train loss and acc of batch 47: 48.02649688720703, 1.0\n",
      "Train loss and acc of batch 48: 48.026485443115234, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 49: 48.02647399902344, 1.0\n",
      "Train loss and acc of batch 50: 48.622169494628906, 0.984375\n",
      "Train loss and acc of batch 51: 49.37538146972656, 0.96875\n",
      "Train loss and acc of batch 52: 49.28228759765625, 0.953125\n",
      "Train loss and acc of batch 53: 48.02643966674805, 1.0\n",
      "Train loss and acc of batch 54: 48.243194580078125, 0.984375\n",
      "Train loss and acc of batch 55: 48.02642059326172, 1.0\n",
      "Train loss and acc of batch 56: 48.02641677856445, 1.0\n",
      "Train loss and acc of batch 57: 48.622100830078125, 0.984375\n",
      "Train loss and acc of batch 58: 48.02639389038086, 1.0\n",
      "Train loss and acc of batch 59: 48.02638626098633, 1.0\n",
      "Train loss and acc of batch 60: 48.0263786315918, 1.0\n",
      "Train loss and acc of batch 61: 48.026371002197266, 1.0\n",
      "Train loss and acc of batch 62: 48.243125915527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.217750549316406, 0.96875\n",
      "Train loss and acc of batch 64: 48.24311065673828, 0.984375\n",
      "Train loss and acc of batch 65: 48.026336669921875, 1.0\n",
      "Train loss and acc of batch 66: 48.02632141113281, 1.0\n",
      "Train loss and acc of batch 67: 48.83877944946289, 0.96875\n",
      "Train loss and acc of batch 68: 48.62200164794922, 0.984375\n",
      "Train loss and acc of batch 69: 48.24305725097656, 0.984375\n",
      "Train loss and acc of batch 70: 48.02629089355469, 1.0\n",
      "Training accuracy and loss of epoch #51: 0.9890, 48.3576\n",
      "Saved model by train loss 48.35761755285129\n",
      "Train loss and acc of batch 0: 48.026275634765625, 1.0\n",
      "Train loss and acc of batch 1: 48.026268005371094, 1.0\n",
      "Train loss and acc of batch 2: 48.312110900878906, 0.984375\n",
      "Train loss and acc of batch 3: 48.243011474609375, 0.984375\n",
      "Train loss and acc of batch 4: 48.0262451171875, 1.0\n",
      "Train loss and acc of batch 5: 49.375160217285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.528839111328125, 0.96875\n",
      "Train loss and acc of batch 7: 48.02621841430664, 1.0\n",
      "Train loss and acc of batch 8: 48.62190246582031, 0.984375\n",
      "Train loss and acc of batch 9: 48.312049865722656, 0.984375\n",
      "Train loss and acc of batch 10: 48.026187896728516, 1.0\n",
      "Train loss and acc of batch 11: 48.02617645263672, 1.0\n",
      "Train loss and acc of batch 12: 48.77939224243164, 0.984375\n",
      "Train loss and acc of batch 13: 48.24292755126953, 0.984375\n",
      "Train loss and acc of batch 14: 48.242919921875, 0.984375\n",
      "Train loss and acc of batch 15: 48.62184143066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.62183380126953, 0.984375\n",
      "Train loss and acc of batch 17: 48.77935028076172, 0.984375\n",
      "Train loss and acc of batch 18: 48.90767288208008, 0.96875\n",
      "Train loss and acc of batch 19: 48.0261116027832, 1.0\n",
      "Train loss and acc of batch 20: 48.026100158691406, 1.0\n",
      "Train loss and acc of batch 21: 48.621788024902344, 0.984375\n",
      "Train loss and acc of batch 22: 48.62178039550781, 0.984375\n",
      "Train loss and acc of batch 23: 48.242835998535156, 0.984375\n",
      "Train loss and acc of batch 24: 48.62176513671875, 0.984375\n",
      "Train loss and acc of batch 25: 48.02605056762695, 1.0\n",
      "Train loss and acc of batch 26: 48.02605056762695, 1.0\n",
      "Train loss and acc of batch 27: 48.02603530883789, 1.0\n",
      "Train loss and acc of batch 28: 48.026031494140625, 1.0\n",
      "Train loss and acc of batch 29: 48.62171936035156, 0.984375\n",
      "Train loss and acc of batch 30: 48.0260124206543, 1.0\n",
      "Train loss and acc of batch 31: 48.242759704589844, 0.984375\n",
      "Train loss and acc of batch 32: 48.02599334716797, 1.0\n",
      "Train loss and acc of batch 33: 48.02598190307617, 1.0\n",
      "Train loss and acc of batch 34: 48.621673583984375, 0.984375\n",
      "Train loss and acc of batch 35: 48.459495544433594, 0.96875\n",
      "Train loss and acc of batch 36: 48.02595520019531, 1.0\n",
      "Train loss and acc of batch 37: 48.779170989990234, 0.984375\n",
      "Train loss and acc of batch 38: 49.37486267089844, 0.96875\n",
      "Train loss and acc of batch 39: 48.24269104003906, 0.984375\n",
      "Train loss and acc of batch 40: 48.02592086791992, 1.0\n",
      "Train loss and acc of batch 41: 49.37483596801758, 0.96875\n",
      "Train loss and acc of batch 42: 48.02590560913086, 1.0\n",
      "Train loss and acc of batch 43: 48.62159729003906, 0.984375\n",
      "Train loss and acc of batch 44: 48.02588653564453, 1.0\n",
      "Train loss and acc of batch 45: 48.62157440185547, 0.984375\n",
      "Train loss and acc of batch 46: 48.31172180175781, 0.984375\n",
      "Train loss and acc of batch 47: 48.02585220336914, 1.0\n",
      "Train loss and acc of batch 48: 48.025848388671875, 1.0\n",
      "Train loss and acc of batch 49: 48.025840759277344, 1.0\n",
      "Train loss and acc of batch 50: 48.62152862548828, 0.984375\n",
      "Train loss and acc of batch 51: 49.37474822998047, 0.96875\n",
      "Train loss and acc of batch 52: 49.281646728515625, 0.953125\n",
      "Train loss and acc of batch 53: 48.02580261230469, 1.0\n",
      "Train loss and acc of batch 54: 48.24256134033203, 0.984375\n",
      "Train loss and acc of batch 55: 48.025787353515625, 1.0\n",
      "Train loss and acc of batch 56: 48.02577590942383, 1.0\n",
      "Train loss and acc of batch 57: 48.62146759033203, 0.984375\n",
      "Train loss and acc of batch 58: 48.025760650634766, 1.0\n",
      "Train loss and acc of batch 59: 48.02574920654297, 1.0\n",
      "Train loss and acc of batch 60: 48.02573776245117, 1.0\n",
      "Train loss and acc of batch 61: 48.025733947753906, 1.0\n",
      "Train loss and acc of batch 62: 48.24248504638672, 0.984375\n",
      "Train loss and acc of batch 63: 49.21711349487305, 0.96875\n",
      "Train loss and acc of batch 64: 48.242469787597656, 0.984375\n",
      "Train loss and acc of batch 65: 48.025699615478516, 1.0\n",
      "Train loss and acc of batch 66: 48.02568817138672, 1.0\n",
      "Train loss and acc of batch 67: 48.83814239501953, 0.96875\n",
      "Train loss and acc of batch 68: 48.621368408203125, 0.984375\n",
      "Train loss and acc of batch 69: 48.24242401123047, 0.984375\n",
      "Train loss and acc of batch 70: 48.02565002441406, 1.0\n",
      "Training accuracy and loss of epoch #52: 0.9890, 48.3570\n",
      "Saved model by train loss 48.35697990739849\n",
      "Train loss and acc of batch 0: 48.0256462097168, 1.0\n",
      "Train loss and acc of batch 1: 48.025634765625, 1.0\n",
      "Train loss and acc of batch 2: 48.31147766113281, 0.984375\n",
      "Train loss and acc of batch 3: 48.24237823486328, 0.984375\n",
      "Train loss and acc of batch 4: 48.025611877441406, 1.0\n",
      "Train loss and acc of batch 5: 49.37452697753906, 0.96875\n",
      "Train loss and acc of batch 6: 48.52820587158203, 0.96875\n",
      "Train loss and acc of batch 7: 48.02558135986328, 1.0\n",
      "Train loss and acc of batch 8: 48.62127685546875, 0.984375\n",
      "Train loss and acc of batch 9: 48.31141662597656, 0.984375\n",
      "Train loss and acc of batch 10: 48.025550842285156, 1.0\n",
      "Train loss and acc of batch 11: 48.02554702758789, 1.0\n",
      "Train loss and acc of batch 12: 48.77875900268555, 0.984375\n",
      "Train loss and acc of batch 13: 48.24229431152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.242279052734375, 0.984375\n",
      "Train loss and acc of batch 15: 48.6212158203125, 0.984375\n",
      "Train loss and acc of batch 16: 48.62120056152344, 0.984375\n",
      "Train loss and acc of batch 17: 48.77871322631836, 0.984375\n",
      "Train loss and acc of batch 18: 48.90703201293945, 0.96875\n",
      "Train loss and acc of batch 19: 48.02547073364258, 1.0\n",
      "Train loss and acc of batch 20: 48.02546691894531, 1.0\n",
      "Train loss and acc of batch 21: 48.62115478515625, 0.984375\n",
      "Train loss and acc of batch 22: 48.62114715576172, 0.984375\n",
      "Train loss and acc of batch 23: 48.24220275878906, 0.984375\n",
      "Train loss and acc of batch 24: 48.621131896972656, 0.984375\n",
      "Train loss and acc of batch 25: 48.025421142578125, 1.0\n",
      "Train loss and acc of batch 26: 48.02540969848633, 1.0\n",
      "Train loss and acc of batch 27: 48.0254020690918, 1.0\n",
      "Train loss and acc of batch 28: 48.025394439697266, 1.0\n",
      "Train loss and acc of batch 29: 48.62108612060547, 0.984375\n",
      "Train loss and acc of batch 30: 48.02537536621094, 1.0\n",
      "Train loss and acc of batch 31: 48.24213409423828, 0.984375\n",
      "Train loss and acc of batch 32: 48.025352478027344, 1.0\n",
      "Train loss and acc of batch 33: 48.02534866333008, 1.0\n",
      "Train loss and acc of batch 34: 48.62104034423828, 0.984375\n",
      "Train loss and acc of batch 35: 48.458858489990234, 0.96875\n",
      "Train loss and acc of batch 36: 48.02532196044922, 1.0\n",
      "Train loss and acc of batch 37: 48.778533935546875, 0.984375\n",
      "Train loss and acc of batch 38: 49.374229431152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2420654296875, 0.984375\n",
      "Train loss and acc of batch 40: 48.02528762817383, 1.0\n",
      "Train loss and acc of batch 41: 49.374202728271484, 0.96875\n",
      "Train loss and acc of batch 42: 48.025272369384766, 1.0\n",
      "Train loss and acc of batch 43: 48.62096405029297, 0.984375\n",
      "Train loss and acc of batch 44: 48.02524948120117, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 45: 48.620941162109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.31108856201172, 0.984375\n",
      "Train loss and acc of batch 47: 48.02522277832031, 1.0\n",
      "Train loss and acc of batch 48: 48.025211334228516, 1.0\n",
      "Train loss and acc of batch 49: 48.025203704833984, 1.0\n",
      "Train loss and acc of batch 50: 48.62090301513672, 0.984375\n",
      "Train loss and acc of batch 51: 49.374114990234375, 0.96875\n",
      "Train loss and acc of batch 52: 49.28102111816406, 0.953125\n",
      "Train loss and acc of batch 53: 48.025169372558594, 1.0\n",
      "Train loss and acc of batch 54: 48.24192810058594, 0.984375\n",
      "Train loss and acc of batch 55: 48.025150299072266, 1.0\n",
      "Train loss and acc of batch 56: 48.025142669677734, 1.0\n",
      "Train loss and acc of batch 57: 48.62083435058594, 0.984375\n",
      "Train loss and acc of batch 58: 48.02511978149414, 1.0\n",
      "Train loss and acc of batch 59: 48.025115966796875, 1.0\n",
      "Train loss and acc of batch 60: 48.025108337402344, 1.0\n",
      "Train loss and acc of batch 61: 48.02510070800781, 1.0\n",
      "Train loss and acc of batch 62: 48.241851806640625, 0.984375\n",
      "Train loss and acc of batch 63: 49.21648406982422, 0.96875\n",
      "Train loss and acc of batch 64: 48.24183654785156, 0.984375\n",
      "Train loss and acc of batch 65: 48.025062561035156, 1.0\n",
      "Train loss and acc of batch 66: 48.025054931640625, 1.0\n",
      "Train loss and acc of batch 67: 48.83750915527344, 0.96875\n",
      "Train loss and acc of batch 68: 48.62073516845703, 0.984375\n",
      "Train loss and acc of batch 69: 48.241790771484375, 0.984375\n",
      "Train loss and acc of batch 70: 48.0250129699707, 1.0\n",
      "Training accuracy and loss of epoch #53: 0.9890, 48.3563\n",
      "Saved model by train loss 48.35634629155548\n",
      "Train loss and acc of batch 0: 48.02500534057617, 1.0\n",
      "Train loss and acc of batch 1: 48.02499771118164, 1.0\n",
      "Train loss and acc of batch 2: 48.31084442138672, 0.984375\n",
      "Train loss and acc of batch 3: 48.24174499511719, 0.984375\n",
      "Train loss and acc of batch 4: 48.02497482299805, 1.0\n",
      "Train loss and acc of batch 5: 49.37388610839844, 0.96875\n",
      "Train loss and acc of batch 6: 48.52757263183594, 0.96875\n",
      "Train loss and acc of batch 7: 48.02494430541992, 1.0\n",
      "Train loss and acc of batch 8: 48.620643615722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.31078338623047, 0.984375\n",
      "Train loss and acc of batch 10: 48.02492141723633, 1.0\n",
      "Train loss and acc of batch 11: 48.0249137878418, 1.0\n",
      "Train loss and acc of batch 12: 48.77812957763672, 0.984375\n",
      "Train loss and acc of batch 13: 48.24165344238281, 0.984375\n",
      "Train loss and acc of batch 14: 48.24164581298828, 0.984375\n",
      "Train loss and acc of batch 15: 48.620574951171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.620567321777344, 0.984375\n",
      "Train loss and acc of batch 17: 48.778079986572266, 0.984375\n",
      "Train loss and acc of batch 18: 48.90640640258789, 0.96875\n",
      "Train loss and acc of batch 19: 48.024837493896484, 1.0\n",
      "Train loss and acc of batch 20: 48.02482986450195, 1.0\n",
      "Train loss and acc of batch 21: 48.620521545410156, 0.984375\n",
      "Train loss and acc of batch 22: 48.620513916015625, 0.984375\n",
      "Train loss and acc of batch 23: 48.24156951904297, 0.984375\n",
      "Train loss and acc of batch 24: 48.62049102783203, 0.984375\n",
      "Train loss and acc of batch 25: 48.02478790283203, 1.0\n",
      "Train loss and acc of batch 26: 48.02477264404297, 1.0\n",
      "Train loss and acc of batch 27: 48.0247688293457, 1.0\n",
      "Train loss and acc of batch 28: 48.02475357055664, 1.0\n",
      "Train loss and acc of batch 29: 48.620452880859375, 0.984375\n",
      "Train loss and acc of batch 30: 48.02473831176758, 1.0\n",
      "Train loss and acc of batch 31: 48.24150085449219, 0.984375\n",
      "Train loss and acc of batch 32: 48.02471923828125, 1.0\n",
      "Train loss and acc of batch 33: 48.024715423583984, 1.0\n",
      "Train loss and acc of batch 34: 48.62040710449219, 0.984375\n",
      "Train loss and acc of batch 35: 48.45822525024414, 0.96875\n",
      "Train loss and acc of batch 36: 48.024688720703125, 1.0\n",
      "Train loss and acc of batch 37: 48.77790451049805, 0.984375\n",
      "Train loss and acc of batch 38: 49.37359619140625, 0.96875\n",
      "Train loss and acc of batch 39: 48.241424560546875, 0.984375\n",
      "Train loss and acc of batch 40: 48.02465057373047, 1.0\n",
      "Train loss and acc of batch 41: 49.37356948852539, 0.96875\n",
      "Train loss and acc of batch 42: 48.02463150024414, 1.0\n",
      "Train loss and acc of batch 43: 48.620323181152344, 0.984375\n",
      "Train loss and acc of batch 44: 48.02461624145508, 1.0\n",
      "Train loss and acc of batch 45: 48.62030792236328, 0.984375\n",
      "Train loss and acc of batch 46: 48.310447692871094, 0.984375\n",
      "Train loss and acc of batch 47: 48.02458953857422, 1.0\n",
      "Train loss and acc of batch 48: 48.02458190917969, 1.0\n",
      "Train loss and acc of batch 49: 48.02457046508789, 1.0\n",
      "Train loss and acc of batch 50: 48.620262145996094, 0.984375\n",
      "Train loss and acc of batch 51: 49.37347412109375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2803840637207, 0.953125\n",
      "Train loss and acc of batch 53: 48.0245361328125, 1.0\n",
      "Train loss and acc of batch 54: 48.24128723144531, 0.984375\n",
      "Train loss and acc of batch 55: 48.02451705932617, 1.0\n",
      "Train loss and acc of batch 56: 48.024505615234375, 1.0\n",
      "Train loss and acc of batch 57: 48.62019348144531, 0.984375\n",
      "Train loss and acc of batch 58: 48.02449035644531, 1.0\n",
      "Train loss and acc of batch 59: 48.02448272705078, 1.0\n",
      "Train loss and acc of batch 60: 48.024471282958984, 1.0\n",
      "Train loss and acc of batch 61: 48.02445983886719, 1.0\n",
      "Train loss and acc of batch 62: 48.24121856689453, 0.984375\n",
      "Train loss and acc of batch 63: 49.21584701538086, 0.96875\n",
      "Train loss and acc of batch 64: 48.24120330810547, 0.984375\n",
      "Train loss and acc of batch 65: 48.0244255065918, 1.0\n",
      "Train loss and acc of batch 66: 48.024417877197266, 1.0\n",
      "Train loss and acc of batch 67: 48.836875915527344, 0.96875\n",
      "Train loss and acc of batch 68: 48.62010192871094, 0.984375\n",
      "Train loss and acc of batch 69: 48.24115753173828, 0.984375\n",
      "Train loss and acc of batch 70: 48.02437973022461, 1.0\n",
      "Training accuracy and loss of epoch #54: 0.9890, 48.3557\n",
      "Saved model by train loss 48.35571111759669\n",
      "Train loss and acc of batch 0: 48.02437210083008, 1.0\n",
      "Train loss and acc of batch 1: 48.02436447143555, 1.0\n",
      "Train loss and acc of batch 2: 48.310203552246094, 0.984375\n",
      "Train loss and acc of batch 3: 48.241111755371094, 0.984375\n",
      "Train loss and acc of batch 4: 48.02433776855469, 1.0\n",
      "Train loss and acc of batch 5: 49.373252868652344, 0.96875\n",
      "Train loss and acc of batch 6: 48.526939392089844, 0.96875\n",
      "Train loss and acc of batch 7: 48.02431106567383, 1.0\n",
      "Train loss and acc of batch 8: 48.62000274658203, 0.984375\n",
      "Train loss and acc of batch 9: 48.310142517089844, 0.984375\n",
      "Train loss and acc of batch 10: 48.024288177490234, 1.0\n",
      "Train loss and acc of batch 11: 48.02427291870117, 1.0\n",
      "Train loss and acc of batch 12: 48.77749252319336, 0.984375\n",
      "Train loss and acc of batch 13: 48.24102020263672, 0.984375\n",
      "Train loss and acc of batch 14: 48.24101257324219, 0.984375\n",
      "Train loss and acc of batch 15: 48.61994171142578, 0.984375\n",
      "Train loss and acc of batch 16: 48.61993408203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.777442932128906, 0.984375\n",
      "Train loss and acc of batch 18: 48.905765533447266, 0.96875\n",
      "Train loss and acc of batch 19: 48.02420425415039, 1.0\n",
      "Train loss and acc of batch 20: 48.024200439453125, 1.0\n",
      "Train loss and acc of batch 21: 48.61988830566406, 0.984375\n",
      "Train loss and acc of batch 22: 48.61988067626953, 0.984375\n",
      "Train loss and acc of batch 23: 48.240928649902344, 0.984375\n",
      "Train loss and acc of batch 24: 48.61986541748047, 0.984375\n",
      "Train loss and acc of batch 25: 48.02415084838867, 1.0\n",
      "Train loss and acc of batch 26: 48.024139404296875, 1.0\n",
      "Train loss and acc of batch 27: 48.024131774902344, 1.0\n",
      "Train loss and acc of batch 28: 48.02412414550781, 1.0\n",
      "Train loss and acc of batch 29: 48.61981201171875, 0.984375\n",
      "Train loss and acc of batch 30: 48.02410888671875, 1.0\n",
      "Train loss and acc of batch 31: 48.24085998535156, 0.984375\n",
      "Train loss and acc of batch 32: 48.024085998535156, 1.0\n",
      "Train loss and acc of batch 33: 48.024078369140625, 1.0\n",
      "Train loss and acc of batch 34: 48.619773864746094, 0.984375\n",
      "Train loss and acc of batch 35: 48.45759201049805, 0.96875\n",
      "Train loss and acc of batch 36: 48.024051666259766, 1.0\n",
      "Train loss and acc of batch 37: 48.77726745605469, 0.984375\n",
      "Train loss and acc of batch 38: 49.372955322265625, 0.96875\n",
      "Train loss and acc of batch 39: 48.24079132080078, 0.984375\n",
      "Train loss and acc of batch 40: 48.024017333984375, 1.0\n",
      "Train loss and acc of batch 41: 49.37293243408203, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 42: 48.02399826049805, 1.0\n",
      "Train loss and acc of batch 43: 48.61968994140625, 0.984375\n",
      "Train loss and acc of batch 44: 48.023983001708984, 1.0\n",
      "Train loss and acc of batch 45: 48.61967468261719, 0.984375\n",
      "Train loss and acc of batch 46: 48.309814453125, 0.984375\n",
      "Train loss and acc of batch 47: 48.023956298828125, 1.0\n",
      "Train loss and acc of batch 48: 48.02394485473633, 1.0\n",
      "Train loss and acc of batch 49: 48.02393341064453, 1.0\n",
      "Train loss and acc of batch 50: 48.61962890625, 0.984375\n",
      "Train loss and acc of batch 51: 49.37284851074219, 0.96875\n",
      "Train loss and acc of batch 52: 49.27975082397461, 0.953125\n",
      "Train loss and acc of batch 53: 48.023902893066406, 1.0\n",
      "Train loss and acc of batch 54: 48.24065399169922, 0.984375\n",
      "Train loss and acc of batch 55: 48.02388000488281, 1.0\n",
      "Train loss and acc of batch 56: 48.02387237548828, 1.0\n",
      "Train loss and acc of batch 57: 48.61956787109375, 0.984375\n",
      "Train loss and acc of batch 58: 48.02385711669922, 1.0\n",
      "Train loss and acc of batch 59: 48.02384948730469, 1.0\n",
      "Train loss and acc of batch 60: 48.02383804321289, 1.0\n",
      "Train loss and acc of batch 61: 48.02383041381836, 1.0\n",
      "Train loss and acc of batch 62: 48.24058532714844, 0.984375\n",
      "Train loss and acc of batch 63: 49.215213775634766, 0.96875\n",
      "Train loss and acc of batch 64: 48.240570068359375, 0.984375\n",
      "Train loss and acc of batch 65: 48.0237922668457, 1.0\n",
      "Train loss and acc of batch 66: 48.02378463745117, 1.0\n",
      "Train loss and acc of batch 67: 48.836238861083984, 0.96875\n",
      "Train loss and acc of batch 68: 48.61946105957031, 0.984375\n",
      "Train loss and acc of batch 69: 48.240516662597656, 0.984375\n",
      "Train loss and acc of batch 70: 48.02375030517578, 1.0\n",
      "Training accuracy and loss of epoch #55: 0.9890, 48.3551\n",
      "Saved model by train loss 48.35507658837547\n",
      "Train loss and acc of batch 0: 48.023738861083984, 1.0\n",
      "Train loss and acc of batch 1: 48.02373504638672, 1.0\n",
      "Train loss and acc of batch 2: 48.30957794189453, 0.984375\n",
      "Train loss and acc of batch 3: 48.240478515625, 0.984375\n",
      "Train loss and acc of batch 4: 48.023704528808594, 1.0\n",
      "Train loss and acc of batch 5: 49.37261962890625, 0.96875\n",
      "Train loss and acc of batch 6: 48.52629852294922, 0.96875\n",
      "Train loss and acc of batch 7: 48.023677825927734, 1.0\n",
      "Train loss and acc of batch 8: 48.61936950683594, 0.984375\n",
      "Train loss and acc of batch 9: 48.30951690673828, 0.984375\n",
      "Train loss and acc of batch 10: 48.02364730834961, 1.0\n",
      "Train loss and acc of batch 11: 48.02363586425781, 1.0\n",
      "Train loss and acc of batch 12: 48.776851654052734, 0.984375\n",
      "Train loss and acc of batch 13: 48.240386962890625, 0.984375\n",
      "Train loss and acc of batch 14: 48.240379333496094, 0.984375\n",
      "Train loss and acc of batch 15: 48.61930847167969, 0.984375\n",
      "Train loss and acc of batch 16: 48.619300842285156, 0.984375\n",
      "Train loss and acc of batch 17: 48.77681350708008, 0.984375\n",
      "Train loss and acc of batch 18: 48.90513229370117, 0.96875\n",
      "Train loss and acc of batch 19: 48.02356719970703, 1.0\n",
      "Train loss and acc of batch 20: 48.0235595703125, 1.0\n",
      "Train loss and acc of batch 21: 48.61925506591797, 0.984375\n",
      "Train loss and acc of batch 22: 48.61924743652344, 0.984375\n",
      "Train loss and acc of batch 23: 48.24029541015625, 0.984375\n",
      "Train loss and acc of batch 24: 48.619224548339844, 0.984375\n",
      "Train loss and acc of batch 25: 48.02350997924805, 1.0\n",
      "Train loss and acc of batch 26: 48.02350997924805, 1.0\n",
      "Train loss and acc of batch 27: 48.02349853515625, 1.0\n",
      "Train loss and acc of batch 28: 48.02349090576172, 1.0\n",
      "Train loss and acc of batch 29: 48.61918640136719, 0.984375\n",
      "Train loss and acc of batch 30: 48.02347183227539, 1.0\n",
      "Train loss and acc of batch 31: 48.24022674560547, 0.984375\n",
      "Train loss and acc of batch 32: 48.02345657348633, 1.0\n",
      "Train loss and acc of batch 33: 48.02344512939453, 1.0\n",
      "Train loss and acc of batch 34: 48.619140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.45695114135742, 0.96875\n",
      "Train loss and acc of batch 36: 48.02341842651367, 1.0\n",
      "Train loss and acc of batch 37: 48.776634216308594, 0.984375\n",
      "Train loss and acc of batch 38: 49.37232971191406, 0.96875\n",
      "Train loss and acc of batch 39: 48.24015808105469, 0.984375\n",
      "Train loss and acc of batch 40: 48.023380279541016, 1.0\n",
      "Train loss and acc of batch 41: 49.37229537963867, 0.96875\n",
      "Train loss and acc of batch 42: 48.02336120605469, 1.0\n",
      "Train loss and acc of batch 43: 48.619056701660156, 0.984375\n",
      "Train loss and acc of batch 44: 48.02334976196289, 1.0\n",
      "Train loss and acc of batch 45: 48.619041442871094, 0.984375\n",
      "Train loss and acc of batch 46: 48.309181213378906, 0.984375\n",
      "Train loss and acc of batch 47: 48.023319244384766, 1.0\n",
      "Train loss and acc of batch 48: 48.023311614990234, 1.0\n",
      "Train loss and acc of batch 49: 48.02330017089844, 1.0\n",
      "Train loss and acc of batch 50: 48.618995666503906, 0.984375\n",
      "Train loss and acc of batch 51: 49.37220764160156, 0.96875\n",
      "Train loss and acc of batch 52: 49.279117584228516, 0.953125\n",
      "Train loss and acc of batch 53: 48.02326583862305, 1.0\n",
      "Train loss and acc of batch 54: 48.240020751953125, 0.984375\n",
      "Train loss and acc of batch 55: 48.02324676513672, 1.0\n",
      "Train loss and acc of batch 56: 48.02323913574219, 1.0\n",
      "Train loss and acc of batch 57: 48.618934631347656, 0.984375\n",
      "Train loss and acc of batch 58: 48.023223876953125, 1.0\n",
      "Train loss and acc of batch 59: 48.02321243286133, 1.0\n",
      "Train loss and acc of batch 60: 48.0232048034668, 1.0\n",
      "Train loss and acc of batch 61: 48.023193359375, 1.0\n",
      "Train loss and acc of batch 62: 48.23994445800781, 0.984375\n",
      "Train loss and acc of batch 63: 49.214576721191406, 0.96875\n",
      "Train loss and acc of batch 64: 48.23992919921875, 0.984375\n",
      "Train loss and acc of batch 65: 48.02315902709961, 1.0\n",
      "Train loss and acc of batch 66: 48.02315139770508, 1.0\n",
      "Train loss and acc of batch 67: 48.83560562133789, 0.96875\n",
      "Train loss and acc of batch 68: 48.61882781982422, 0.984375\n",
      "Train loss and acc of batch 69: 48.23988342285156, 0.984375\n",
      "Train loss and acc of batch 70: 48.02311325073242, 1.0\n",
      "Training accuracy and loss of epoch #56: 0.9890, 48.3544\n",
      "Saved model by train loss 48.35444227406676\n",
      "Train loss and acc of batch 0: 48.02310562133789, 1.0\n",
      "Train loss and acc of batch 1: 48.02309799194336, 1.0\n",
      "Train loss and acc of batch 2: 48.30894470214844, 0.984375\n",
      "Train loss and acc of batch 3: 48.239845275878906, 0.984375\n",
      "Train loss and acc of batch 4: 48.023075103759766, 1.0\n",
      "Train loss and acc of batch 5: 49.371986389160156, 0.96875\n",
      "Train loss and acc of batch 6: 48.525665283203125, 0.96875\n",
      "Train loss and acc of batch 7: 48.023040771484375, 1.0\n",
      "Train loss and acc of batch 8: 48.618736267089844, 0.984375\n",
      "Train loss and acc of batch 9: 48.308876037597656, 0.984375\n",
      "Train loss and acc of batch 10: 48.023014068603516, 1.0\n",
      "Train loss and acc of batch 11: 48.023006439208984, 1.0\n",
      "Train loss and acc of batch 12: 48.77621841430664, 0.984375\n",
      "Train loss and acc of batch 13: 48.23975372314453, 0.984375\n",
      "Train loss and acc of batch 14: 48.23974609375, 0.984375\n",
      "Train loss and acc of batch 15: 48.618675231933594, 0.984375\n",
      "Train loss and acc of batch 16: 48.61865997314453, 0.984375\n",
      "Train loss and acc of batch 17: 48.776180267333984, 0.984375\n",
      "Train loss and acc of batch 18: 48.904502868652344, 0.96875\n",
      "Train loss and acc of batch 19: 48.02293395996094, 1.0\n",
      "Train loss and acc of batch 20: 48.02292251586914, 1.0\n",
      "Train loss and acc of batch 21: 48.618621826171875, 0.984375\n",
      "Train loss and acc of batch 22: 48.61860656738281, 0.984375\n",
      "Train loss and acc of batch 23: 48.23966979980469, 0.984375\n",
      "Train loss and acc of batch 24: 48.61859130859375, 0.984375\n",
      "Train loss and acc of batch 25: 48.02288055419922, 1.0\n",
      "Train loss and acc of batch 26: 48.02287292480469, 1.0\n",
      "Train loss and acc of batch 27: 48.022865295410156, 1.0\n",
      "Train loss and acc of batch 28: 48.02285385131836, 1.0\n",
      "Train loss and acc of batch 29: 48.61854553222656, 0.984375\n",
      "Train loss and acc of batch 30: 48.02283477783203, 1.0\n",
      "Train loss and acc of batch 31: 48.239593505859375, 0.984375\n",
      "Train loss and acc of batch 32: 48.022823333740234, 1.0\n",
      "Train loss and acc of batch 33: 48.02280807495117, 1.0\n",
      "Train loss and acc of batch 34: 48.618499755859375, 0.984375\n",
      "Train loss and acc of batch 35: 48.456321716308594, 0.96875\n",
      "Train loss and acc of batch 36: 48.02278137207031, 1.0\n",
      "Train loss and acc of batch 37: 48.775997161865234, 0.984375\n",
      "Train loss and acc of batch 38: 49.37168884277344, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 39: 48.23951721191406, 0.984375\n",
      "Train loss and acc of batch 40: 48.02274703979492, 1.0\n",
      "Train loss and acc of batch 41: 49.371665954589844, 0.96875\n",
      "Train loss and acc of batch 42: 48.02273178100586, 1.0\n",
      "Train loss and acc of batch 43: 48.61842346191406, 0.984375\n",
      "Train loss and acc of batch 44: 48.022708892822266, 1.0\n",
      "Train loss and acc of batch 45: 48.618408203125, 0.984375\n",
      "Train loss and acc of batch 46: 48.30854797363281, 0.984375\n",
      "Train loss and acc of batch 47: 48.02268600463867, 1.0\n",
      "Train loss and acc of batch 48: 48.022674560546875, 1.0\n",
      "Train loss and acc of batch 49: 48.022666931152344, 1.0\n",
      "Train loss and acc of batch 50: 48.61836242675781, 0.984375\n",
      "Train loss and acc of batch 51: 49.37157440185547, 0.96875\n",
      "Train loss and acc of batch 52: 49.278480529785156, 0.953125\n",
      "Train loss and acc of batch 53: 48.02262878417969, 1.0\n",
      "Train loss and acc of batch 54: 48.23938751220703, 0.984375\n",
      "Train loss and acc of batch 55: 48.02260971069336, 1.0\n",
      "Train loss and acc of batch 56: 48.022605895996094, 1.0\n",
      "Train loss and acc of batch 57: 48.61829376220703, 0.984375\n",
      "Train loss and acc of batch 58: 48.0225830078125, 1.0\n",
      "Train loss and acc of batch 59: 48.022579193115234, 1.0\n",
      "Train loss and acc of batch 60: 48.0225715637207, 1.0\n",
      "Train loss and acc of batch 61: 48.022560119628906, 1.0\n",
      "Train loss and acc of batch 62: 48.23931121826172, 0.984375\n",
      "Train loss and acc of batch 63: 49.21394348144531, 0.96875\n",
      "Train loss and acc of batch 64: 48.239295959472656, 0.984375\n",
      "Train loss and acc of batch 65: 48.02252197265625, 1.0\n",
      "Train loss and acc of batch 66: 48.02251434326172, 1.0\n",
      "Train loss and acc of batch 67: 48.8349723815918, 0.96875\n",
      "Train loss and acc of batch 68: 48.618202209472656, 0.984375\n",
      "Train loss and acc of batch 69: 48.23925018310547, 0.984375\n",
      "Train loss and acc of batch 70: 48.02248001098633, 1.0\n",
      "Training accuracy and loss of epoch #57: 0.9890, 48.3538\n",
      "Saved model by train loss 48.35380774484554\n",
      "Train loss and acc of batch 0: 48.02246856689453, 1.0\n",
      "Train loss and acc of batch 1: 48.022457122802734, 1.0\n",
      "Train loss and acc of batch 2: 48.30830383300781, 0.984375\n",
      "Train loss and acc of batch 3: 48.23921203613281, 0.984375\n",
      "Train loss and acc of batch 4: 48.022438049316406, 1.0\n",
      "Train loss and acc of batch 5: 49.37134552001953, 0.96875\n",
      "Train loss and acc of batch 6: 48.52503204345703, 0.96875\n",
      "Train loss and acc of batch 7: 48.02240753173828, 1.0\n",
      "Train loss and acc of batch 8: 48.61810302734375, 0.984375\n",
      "Train loss and acc of batch 9: 48.30824279785156, 0.984375\n",
      "Train loss and acc of batch 10: 48.02238082885742, 1.0\n",
      "Train loss and acc of batch 11: 48.02237319946289, 1.0\n",
      "Train loss and acc of batch 12: 48.77558517456055, 0.984375\n",
      "Train loss and acc of batch 13: 48.23912048339844, 0.984375\n",
      "Train loss and acc of batch 14: 48.239105224609375, 0.984375\n",
      "Train loss and acc of batch 15: 48.61803436279297, 0.984375\n",
      "Train loss and acc of batch 16: 48.61802673339844, 0.984375\n",
      "Train loss and acc of batch 17: 48.775543212890625, 0.984375\n",
      "Train loss and acc of batch 18: 48.903865814208984, 0.96875\n",
      "Train loss and acc of batch 19: 48.022300720214844, 1.0\n",
      "Train loss and acc of batch 20: 48.02228927612305, 1.0\n",
      "Train loss and acc of batch 21: 48.61798095703125, 0.984375\n",
      "Train loss and acc of batch 22: 48.61797332763672, 0.984375\n",
      "Train loss and acc of batch 23: 48.23902893066406, 0.984375\n",
      "Train loss and acc of batch 24: 48.617958068847656, 0.984375\n",
      "Train loss and acc of batch 25: 48.022247314453125, 1.0\n",
      "Train loss and acc of batch 26: 48.02223587036133, 1.0\n",
      "Train loss and acc of batch 27: 48.0222282409668, 1.0\n",
      "Train loss and acc of batch 28: 48.022216796875, 1.0\n",
      "Train loss and acc of batch 29: 48.61791229248047, 0.984375\n",
      "Train loss and acc of batch 30: 48.02220153808594, 1.0\n",
      "Train loss and acc of batch 31: 48.23896026611328, 0.984375\n",
      "Train loss and acc of batch 32: 48.022186279296875, 1.0\n",
      "Train loss and acc of batch 33: 48.02217483520508, 1.0\n",
      "Train loss and acc of batch 34: 48.61787414550781, 0.984375\n",
      "Train loss and acc of batch 35: 48.455684661865234, 0.96875\n",
      "Train loss and acc of batch 36: 48.02214813232422, 1.0\n",
      "Train loss and acc of batch 37: 48.77535629272461, 0.984375\n",
      "Train loss and acc of batch 38: 49.371055603027344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2388916015625, 0.984375\n",
      "Train loss and acc of batch 40: 48.02210998535156, 1.0\n",
      "Train loss and acc of batch 41: 49.37103271484375, 0.96875\n",
      "Train loss and acc of batch 42: 48.022090911865234, 1.0\n",
      "Train loss and acc of batch 43: 48.61778259277344, 0.984375\n",
      "Train loss and acc of batch 44: 48.02207565307617, 1.0\n",
      "Train loss and acc of batch 45: 48.617774963378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.30790710449219, 0.984375\n",
      "Train loss and acc of batch 47: 48.02204895019531, 1.0\n",
      "Train loss and acc of batch 48: 48.02204132080078, 1.0\n",
      "Train loss and acc of batch 49: 48.022029876708984, 1.0\n",
      "Train loss and acc of batch 50: 48.61772155761719, 0.984375\n",
      "Train loss and acc of batch 51: 49.370933532714844, 0.96875\n",
      "Train loss and acc of batch 52: 49.2778434753418, 0.953125\n",
      "Train loss and acc of batch 53: 48.02199935913086, 1.0\n",
      "Train loss and acc of batch 54: 48.23875427246094, 0.984375\n",
      "Train loss and acc of batch 55: 48.0219841003418, 1.0\n",
      "Train loss and acc of batch 56: 48.02197265625, 1.0\n",
      "Train loss and acc of batch 57: 48.61766052246094, 0.984375\n",
      "Train loss and acc of batch 58: 48.02195358276367, 1.0\n",
      "Train loss and acc of batch 59: 48.02194595336914, 1.0\n",
      "Train loss and acc of batch 60: 48.02193069458008, 1.0\n",
      "Train loss and acc of batch 61: 48.02192306518555, 1.0\n",
      "Train loss and acc of batch 62: 48.238677978515625, 0.984375\n",
      "Train loss and acc of batch 63: 49.21330642700195, 0.96875\n",
      "Train loss and acc of batch 64: 48.23866271972656, 0.984375\n",
      "Train loss and acc of batch 65: 48.021888732910156, 1.0\n",
      "Train loss and acc of batch 66: 48.021881103515625, 1.0\n",
      "Train loss and acc of batch 67: 48.8343391418457, 0.96875\n",
      "Train loss and acc of batch 68: 48.61756134033203, 0.984375\n",
      "Train loss and acc of batch 69: 48.238616943359375, 0.984375\n",
      "Train loss and acc of batch 70: 48.02184295654297, 1.0\n",
      "Training accuracy and loss of epoch #58: 0.9890, 48.3532\n",
      "Saved model by train loss 48.35317246343048\n",
      "Train loss and acc of batch 0: 48.02183151245117, 1.0\n",
      "Train loss and acc of batch 1: 48.021827697753906, 1.0\n",
      "Train loss and acc of batch 2: 48.30767059326172, 0.984375\n",
      "Train loss and acc of batch 3: 48.23857116699219, 0.984375\n",
      "Train loss and acc of batch 4: 48.02180099487305, 1.0\n",
      "Train loss and acc of batch 5: 49.37071990966797, 0.96875\n",
      "Train loss and acc of batch 6: 48.52439880371094, 0.96875\n",
      "Train loss and acc of batch 7: 48.02177429199219, 1.0\n",
      "Train loss and acc of batch 8: 48.617462158203125, 0.984375\n",
      "Train loss and acc of batch 9: 48.30760955810547, 0.984375\n",
      "Train loss and acc of batch 10: 48.02174758911133, 1.0\n",
      "Train loss and acc of batch 11: 48.02173614501953, 1.0\n",
      "Train loss and acc of batch 12: 48.77495574951172, 0.984375\n",
      "Train loss and acc of batch 13: 48.238487243652344, 0.984375\n",
      "Train loss and acc of batch 14: 48.23847198486328, 0.984375\n",
      "Train loss and acc of batch 15: 48.617401123046875, 0.984375\n",
      "Train loss and acc of batch 16: 48.617393493652344, 0.984375\n",
      "Train loss and acc of batch 17: 48.77490234375, 0.984375\n",
      "Train loss and acc of batch 18: 48.903228759765625, 0.96875\n",
      "Train loss and acc of batch 19: 48.02165985107422, 1.0\n",
      "Train loss and acc of batch 20: 48.02165985107422, 1.0\n",
      "Train loss and acc of batch 21: 48.617347717285156, 0.984375\n",
      "Train loss and acc of batch 22: 48.617332458496094, 0.984375\n",
      "Train loss and acc of batch 23: 48.23839569091797, 0.984375\n",
      "Train loss and acc of batch 24: 48.61732482910156, 0.984375\n",
      "Train loss and acc of batch 25: 48.021610260009766, 1.0\n",
      "Train loss and acc of batch 26: 48.021602630615234, 1.0\n",
      "Train loss and acc of batch 27: 48.02159118652344, 1.0\n",
      "Train loss and acc of batch 28: 48.02157974243164, 1.0\n",
      "Train loss and acc of batch 29: 48.617279052734375, 0.984375\n",
      "Train loss and acc of batch 30: 48.021568298339844, 1.0\n",
      "Train loss and acc of batch 31: 48.238319396972656, 0.984375\n",
      "Train loss and acc of batch 32: 48.02155303955078, 1.0\n",
      "Train loss and acc of batch 33: 48.02153778076172, 1.0\n",
      "Train loss and acc of batch 34: 48.61723327636719, 0.984375\n",
      "Train loss and acc of batch 35: 48.45505142211914, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 36: 48.021507263183594, 1.0\n",
      "Train loss and acc of batch 37: 48.77472686767578, 0.984375\n",
      "Train loss and acc of batch 38: 49.37042236328125, 0.96875\n",
      "Train loss and acc of batch 39: 48.238250732421875, 0.984375\n",
      "Train loss and acc of batch 40: 48.02147674560547, 1.0\n",
      "Train loss and acc of batch 41: 49.37039566040039, 0.96875\n",
      "Train loss and acc of batch 42: 48.021461486816406, 1.0\n",
      "Train loss and acc of batch 43: 48.617149353027344, 0.984375\n",
      "Train loss and acc of batch 44: 48.02144241333008, 1.0\n",
      "Train loss and acc of batch 45: 48.61713409423828, 0.984375\n",
      "Train loss and acc of batch 46: 48.307273864746094, 0.984375\n",
      "Train loss and acc of batch 47: 48.02141189575195, 1.0\n",
      "Train loss and acc of batch 48: 48.02140808105469, 1.0\n",
      "Train loss and acc of batch 49: 48.021400451660156, 1.0\n",
      "Train loss and acc of batch 50: 48.617088317871094, 0.984375\n",
      "Train loss and acc of batch 51: 49.37030792236328, 0.96875\n",
      "Train loss and acc of batch 52: 49.2772102355957, 0.953125\n",
      "Train loss and acc of batch 53: 48.0213623046875, 1.0\n",
      "Train loss and acc of batch 54: 48.238121032714844, 0.984375\n",
      "Train loss and acc of batch 55: 48.02134704589844, 1.0\n",
      "Train loss and acc of batch 56: 48.021331787109375, 1.0\n",
      "Train loss and acc of batch 57: 48.617027282714844, 0.984375\n",
      "Train loss and acc of batch 58: 48.02131271362305, 1.0\n",
      "Train loss and acc of batch 59: 48.02130889892578, 1.0\n",
      "Train loss and acc of batch 60: 48.021297454833984, 1.0\n",
      "Train loss and acc of batch 61: 48.02128601074219, 1.0\n",
      "Train loss and acc of batch 62: 48.23804473876953, 0.984375\n",
      "Train loss and acc of batch 63: 49.212677001953125, 0.96875\n",
      "Train loss and acc of batch 64: 48.23802947998047, 0.984375\n",
      "Train loss and acc of batch 65: 48.02125549316406, 1.0\n",
      "Train loss and acc of batch 66: 48.02124786376953, 1.0\n",
      "Train loss and acc of batch 67: 48.833702087402344, 0.96875\n",
      "Train loss and acc of batch 68: 48.61692810058594, 0.984375\n",
      "Train loss and acc of batch 69: 48.23798370361328, 0.984375\n",
      "Train loss and acc of batch 70: 48.021209716796875, 1.0\n",
      "Training accuracy and loss of epoch #59: 0.9890, 48.3525\n",
      "Saved model by train loss 48.352537719296734\n",
      "Train loss and acc of batch 0: 48.02120590209961, 1.0\n",
      "Train loss and acc of batch 1: 48.02119064331055, 1.0\n",
      "Train loss and acc of batch 2: 48.307029724121094, 0.984375\n",
      "Train loss and acc of batch 3: 48.237937927246094, 0.984375\n",
      "Train loss and acc of batch 4: 48.02116012573242, 1.0\n",
      "Train loss and acc of batch 5: 49.370079040527344, 0.96875\n",
      "Train loss and acc of batch 6: 48.523765563964844, 0.96875\n",
      "Train loss and acc of batch 7: 48.02113723754883, 1.0\n",
      "Train loss and acc of batch 8: 48.61682891845703, 0.984375\n",
      "Train loss and acc of batch 9: 48.306976318359375, 0.984375\n",
      "Train loss and acc of batch 10: 48.0211067199707, 1.0\n",
      "Train loss and acc of batch 11: 48.02110290527344, 1.0\n",
      "Train loss and acc of batch 12: 48.774314880371094, 0.984375\n",
      "Train loss and acc of batch 13: 48.23784637451172, 0.984375\n",
      "Train loss and acc of batch 14: 48.23783874511719, 0.984375\n",
      "Train loss and acc of batch 15: 48.61676025390625, 0.984375\n",
      "Train loss and acc of batch 16: 48.61675262451172, 0.984375\n",
      "Train loss and acc of batch 17: 48.77427291870117, 0.984375\n",
      "Train loss and acc of batch 18: 48.902591705322266, 0.96875\n",
      "Train loss and acc of batch 19: 48.021034240722656, 1.0\n",
      "Train loss and acc of batch 20: 48.021018981933594, 1.0\n",
      "Train loss and acc of batch 21: 48.61671447753906, 0.984375\n",
      "Train loss and acc of batch 22: 48.61670684814453, 0.984375\n",
      "Train loss and acc of batch 23: 48.237762451171875, 0.984375\n",
      "Train loss and acc of batch 24: 48.61668395996094, 0.984375\n",
      "Train loss and acc of batch 25: 48.02098083496094, 1.0\n",
      "Train loss and acc of batch 26: 48.02096939086914, 1.0\n",
      "Train loss and acc of batch 27: 48.020957946777344, 1.0\n",
      "Train loss and acc of batch 28: 48.02095031738281, 1.0\n",
      "Train loss and acc of batch 29: 48.61664581298828, 0.984375\n",
      "Train loss and acc of batch 30: 48.020931243896484, 1.0\n",
      "Train loss and acc of batch 31: 48.23768615722656, 0.984375\n",
      "Train loss and acc of batch 32: 48.02091598510742, 1.0\n",
      "Train loss and acc of batch 33: 48.020904541015625, 1.0\n",
      "Train loss and acc of batch 34: 48.616600036621094, 0.984375\n",
      "Train loss and acc of batch 35: 48.45441436767578, 0.96875\n",
      "Train loss and acc of batch 36: 48.02088165283203, 1.0\n",
      "Train loss and acc of batch 37: 48.77409362792969, 0.984375\n",
      "Train loss and acc of batch 38: 49.369781494140625, 0.96875\n",
      "Train loss and acc of batch 39: 48.23761749267578, 0.984375\n",
      "Train loss and acc of batch 40: 48.020843505859375, 1.0\n",
      "Train loss and acc of batch 41: 49.36975860595703, 0.96875\n",
      "Train loss and acc of batch 42: 48.02082824707031, 1.0\n",
      "Train loss and acc of batch 43: 48.61652374267578, 0.984375\n",
      "Train loss and acc of batch 44: 48.02080535888672, 1.0\n",
      "Train loss and acc of batch 45: 48.61650085449219, 0.984375\n",
      "Train loss and acc of batch 46: 48.306640625, 0.984375\n",
      "Train loss and acc of batch 47: 48.02077865600586, 1.0\n",
      "Train loss and acc of batch 48: 48.02077102661133, 1.0\n",
      "Train loss and acc of batch 49: 48.02075958251953, 1.0\n",
      "Train loss and acc of batch 50: 48.61646270751953, 0.984375\n",
      "Train loss and acc of batch 51: 49.369667053222656, 0.96875\n",
      "Train loss and acc of batch 52: 49.276573181152344, 0.953125\n",
      "Train loss and acc of batch 53: 48.02072525024414, 1.0\n",
      "Train loss and acc of batch 54: 48.23748016357422, 0.984375\n",
      "Train loss and acc of batch 55: 48.02070999145508, 1.0\n",
      "Train loss and acc of batch 56: 48.02070236206055, 1.0\n",
      "Train loss and acc of batch 57: 48.61639404296875, 0.984375\n",
      "Train loss and acc of batch 58: 48.02067947387695, 1.0\n",
      "Train loss and acc of batch 59: 48.02067184448242, 1.0\n",
      "Train loss and acc of batch 60: 48.020660400390625, 1.0\n",
      "Train loss and acc of batch 61: 48.02065658569336, 1.0\n",
      "Train loss and acc of batch 62: 48.237403869628906, 0.984375\n",
      "Train loss and acc of batch 63: 49.212039947509766, 0.96875\n",
      "Train loss and acc of batch 64: 48.237396240234375, 0.984375\n",
      "Train loss and acc of batch 65: 48.0206184387207, 1.0\n",
      "Train loss and acc of batch 66: 48.020606994628906, 1.0\n",
      "Train loss and acc of batch 67: 48.83306884765625, 0.96875\n",
      "Train loss and acc of batch 68: 48.616294860839844, 0.984375\n",
      "Train loss and acc of batch 69: 48.23735046386719, 0.984375\n",
      "Train loss and acc of batch 70: 48.020572662353516, 1.0\n",
      "Training accuracy and loss of epoch #60: 0.9890, 48.3519\n",
      "Saved model by train loss 48.35190276025047\n",
      "Train loss and acc of batch 0: 48.02056121826172, 1.0\n",
      "Train loss and acc of batch 1: 48.02055358886719, 1.0\n",
      "Train loss and acc of batch 2: 48.30640411376953, 0.984375\n",
      "Train loss and acc of batch 3: 48.23729705810547, 0.984375\n",
      "Train loss and acc of batch 4: 48.020530700683594, 1.0\n",
      "Train loss and acc of batch 5: 49.36944580078125, 0.96875\n",
      "Train loss and acc of batch 6: 48.523128509521484, 0.96875\n",
      "Train loss and acc of batch 7: 48.020503997802734, 1.0\n",
      "Train loss and acc of batch 8: 48.61619567871094, 0.984375\n",
      "Train loss and acc of batch 9: 48.30633544921875, 0.984375\n",
      "Train loss and acc of batch 10: 48.020477294921875, 1.0\n",
      "Train loss and acc of batch 11: 48.02046585083008, 1.0\n",
      "Train loss and acc of batch 12: 48.773681640625, 0.984375\n",
      "Train loss and acc of batch 13: 48.237213134765625, 0.984375\n",
      "Train loss and acc of batch 14: 48.23719787597656, 0.984375\n",
      "Train loss and acc of batch 15: 48.61613464355469, 0.984375\n",
      "Train loss and acc of batch 16: 48.616127014160156, 0.984375\n",
      "Train loss and acc of batch 17: 48.77363586425781, 0.984375\n",
      "Train loss and acc of batch 18: 48.90195846557617, 0.96875\n",
      "Train loss and acc of batch 19: 48.02039337158203, 1.0\n",
      "Train loss and acc of batch 20: 48.0203857421875, 1.0\n",
      "Train loss and acc of batch 21: 48.61608123779297, 0.984375\n",
      "Train loss and acc of batch 22: 48.61607360839844, 0.984375\n",
      "Train loss and acc of batch 23: 48.23712921142578, 0.984375\n",
      "Train loss and acc of batch 24: 48.616050720214844, 0.984375\n",
      "Train loss and acc of batch 25: 48.02034378051758, 1.0\n",
      "Train loss and acc of batch 26: 48.02033233642578, 1.0\n",
      "Train loss and acc of batch 27: 48.020320892333984, 1.0\n",
      "Train loss and acc of batch 28: 48.02030944824219, 1.0\n",
      "Train loss and acc of batch 29: 48.61601257324219, 0.984375\n",
      "Train loss and acc of batch 30: 48.02029800415039, 1.0\n",
      "Train loss and acc of batch 31: 48.23705291748047, 0.984375\n",
      "Train loss and acc of batch 32: 48.02027893066406, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 48.020267486572266, 1.0\n",
      "Train loss and acc of batch 34: 48.61595916748047, 0.984375\n",
      "Train loss and acc of batch 35: 48.45378494262695, 0.96875\n",
      "Train loss and acc of batch 36: 48.02024459838867, 1.0\n",
      "Train loss and acc of batch 37: 48.773460388183594, 0.984375\n",
      "Train loss and acc of batch 38: 49.36915588378906, 0.96875\n",
      "Train loss and acc of batch 39: 48.236976623535156, 0.984375\n",
      "Train loss and acc of batch 40: 48.020206451416016, 1.0\n",
      "Train loss and acc of batch 41: 49.3691291809082, 0.96875\n",
      "Train loss and acc of batch 42: 48.02019119262695, 1.0\n",
      "Train loss and acc of batch 43: 48.615882873535156, 0.984375\n",
      "Train loss and acc of batch 44: 48.020172119140625, 1.0\n",
      "Train loss and acc of batch 45: 48.61585998535156, 0.984375\n",
      "Train loss and acc of batch 46: 48.306007385253906, 0.984375\n",
      "Train loss and acc of batch 47: 48.0201416015625, 1.0\n",
      "Train loss and acc of batch 48: 48.020137786865234, 1.0\n",
      "Train loss and acc of batch 49: 48.0201301574707, 1.0\n",
      "Train loss and acc of batch 50: 48.615821838378906, 0.984375\n",
      "Train loss and acc of batch 51: 49.36903381347656, 0.96875\n",
      "Train loss and acc of batch 52: 49.27593994140625, 0.953125\n",
      "Train loss and acc of batch 53: 48.02008819580078, 1.0\n",
      "Train loss and acc of batch 54: 48.236846923828125, 0.984375\n",
      "Train loss and acc of batch 55: 48.02007293701172, 1.0\n",
      "Train loss and acc of batch 56: 48.02006530761719, 1.0\n",
      "Train loss and acc of batch 57: 48.615760803222656, 0.984375\n",
      "Train loss and acc of batch 58: 48.020050048828125, 1.0\n",
      "Train loss and acc of batch 59: 48.02003860473633, 1.0\n",
      "Train loss and acc of batch 60: 48.0200309753418, 1.0\n",
      "Train loss and acc of batch 61: 48.02001953125, 1.0\n",
      "Train loss and acc of batch 62: 48.236778259277344, 0.984375\n",
      "Train loss and acc of batch 63: 49.211402893066406, 0.96875\n",
      "Train loss and acc of batch 64: 48.23675537109375, 0.984375\n",
      "Train loss and acc of batch 65: 48.019981384277344, 1.0\n",
      "Train loss and acc of batch 66: 48.01997756958008, 1.0\n",
      "Train loss and acc of batch 67: 48.83243179321289, 0.96875\n",
      "Train loss and acc of batch 68: 48.61566162109375, 0.984375\n",
      "Train loss and acc of batch 69: 48.23670959472656, 0.984375\n",
      "Train loss and acc of batch 70: 48.01993942260742, 1.0\n",
      "Training accuracy and loss of epoch #61: 0.9890, 48.3513\n",
      "Saved model by train loss 48.35126796238859\n",
      "Train loss and acc of batch 0: 48.01993179321289, 1.0\n",
      "Train loss and acc of batch 1: 48.01992416381836, 1.0\n",
      "Train loss and acc of batch 2: 48.305763244628906, 0.984375\n",
      "Train loss and acc of batch 3: 48.236663818359375, 0.984375\n",
      "Train loss and acc of batch 4: 48.0198974609375, 1.0\n",
      "Train loss and acc of batch 5: 49.36882019042969, 0.96875\n",
      "Train loss and acc of batch 6: 48.52249526977539, 0.96875\n",
      "Train loss and acc of batch 7: 48.019866943359375, 1.0\n",
      "Train loss and acc of batch 8: 48.615562438964844, 0.984375\n",
      "Train loss and acc of batch 9: 48.305702209472656, 0.984375\n",
      "Train loss and acc of batch 10: 48.01984405517578, 1.0\n",
      "Train loss and acc of batch 11: 48.01982879638672, 1.0\n",
      "Train loss and acc of batch 12: 48.773048400878906, 0.984375\n",
      "Train loss and acc of batch 13: 48.23657989501953, 0.984375\n",
      "Train loss and acc of batch 14: 48.23656463623047, 0.984375\n",
      "Train loss and acc of batch 15: 48.615501403808594, 0.984375\n",
      "Train loss and acc of batch 16: 48.61549377441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.77300262451172, 0.984375\n",
      "Train loss and acc of batch 18: 48.90132522583008, 0.96875\n",
      "Train loss and acc of batch 19: 48.0197639465332, 1.0\n",
      "Train loss and acc of batch 20: 48.01975631713867, 1.0\n",
      "Train loss and acc of batch 21: 48.615440368652344, 0.984375\n",
      "Train loss and acc of batch 22: 48.61543273925781, 0.984375\n",
      "Train loss and acc of batch 23: 48.236488342285156, 0.984375\n",
      "Train loss and acc of batch 24: 48.61541748046875, 0.984375\n",
      "Train loss and acc of batch 25: 48.019710540771484, 1.0\n",
      "Train loss and acc of batch 26: 48.01969909667969, 1.0\n",
      "Train loss and acc of batch 27: 48.019691467285156, 1.0\n",
      "Train loss and acc of batch 28: 48.01968002319336, 1.0\n",
      "Train loss and acc of batch 29: 48.61537170410156, 0.984375\n",
      "Train loss and acc of batch 30: 48.0196647644043, 1.0\n",
      "Train loss and acc of batch 31: 48.236419677734375, 0.984375\n",
      "Train loss and acc of batch 32: 48.01964569091797, 1.0\n",
      "Train loss and acc of batch 33: 48.01963806152344, 1.0\n",
      "Train loss and acc of batch 34: 48.615333557128906, 0.984375\n",
      "Train loss and acc of batch 35: 48.453147888183594, 0.96875\n",
      "Train loss and acc of batch 36: 48.01961135864258, 1.0\n",
      "Train loss and acc of batch 37: 48.772823333740234, 0.984375\n",
      "Train loss and acc of batch 38: 49.36851501464844, 0.96875\n",
      "Train loss and acc of batch 39: 48.23634338378906, 0.984375\n",
      "Train loss and acc of batch 40: 48.01957321166992, 1.0\n",
      "Train loss and acc of batch 41: 49.36849594116211, 0.96875\n",
      "Train loss and acc of batch 42: 48.019554138183594, 1.0\n",
      "Train loss and acc of batch 43: 48.61524963378906, 0.984375\n",
      "Train loss and acc of batch 44: 48.01953887939453, 1.0\n",
      "Train loss and acc of batch 45: 48.61522674560547, 0.984375\n",
      "Train loss and acc of batch 46: 48.30537414550781, 0.984375\n",
      "Train loss and acc of batch 47: 48.01951599121094, 1.0\n",
      "Train loss and acc of batch 48: 48.019500732421875, 1.0\n",
      "Train loss and acc of batch 49: 48.01949691772461, 1.0\n",
      "Train loss and acc of batch 50: 48.61518096923828, 0.984375\n",
      "Train loss and acc of batch 51: 49.36840057373047, 0.96875\n",
      "Train loss and acc of batch 52: 49.275306701660156, 0.953125\n",
      "Train loss and acc of batch 53: 48.01946258544922, 1.0\n",
      "Train loss and acc of batch 54: 48.23621368408203, 0.984375\n",
      "Train loss and acc of batch 55: 48.01944351196289, 1.0\n",
      "Train loss and acc of batch 56: 48.019432067871094, 1.0\n",
      "Train loss and acc of batch 57: 48.61511993408203, 0.984375\n",
      "Train loss and acc of batch 58: 48.019412994384766, 1.0\n",
      "Train loss and acc of batch 59: 48.0193977355957, 1.0\n",
      "Train loss and acc of batch 60: 48.01939392089844, 1.0\n",
      "Train loss and acc of batch 61: 48.019386291503906, 1.0\n",
      "Train loss and acc of batch 62: 48.23614501953125, 0.984375\n",
      "Train loss and acc of batch 63: 49.21077346801758, 0.96875\n",
      "Train loss and acc of batch 64: 48.236122131347656, 0.984375\n",
      "Train loss and acc of batch 65: 48.01934814453125, 1.0\n",
      "Train loss and acc of batch 66: 48.019344329833984, 1.0\n",
      "Train loss and acc of batch 67: 48.83179473876953, 0.96875\n",
      "Train loss and acc of batch 68: 48.615020751953125, 0.984375\n",
      "Train loss and acc of batch 69: 48.236083984375, 0.984375\n",
      "Train loss and acc of batch 70: 48.01930618286133, 1.0\n",
      "Training accuracy and loss of epoch #62: 0.9890, 48.3506\n",
      "Saved model by train loss 48.35063418536119\n",
      "Train loss and acc of batch 0: 48.0192985534668, 1.0\n",
      "Train loss and acc of batch 1: 48.019290924072266, 1.0\n",
      "Train loss and acc of batch 2: 48.30513000488281, 0.984375\n",
      "Train loss and acc of batch 3: 48.23603820800781, 0.984375\n",
      "Train loss and acc of batch 4: 48.019264221191406, 1.0\n",
      "Train loss and acc of batch 5: 49.36817932128906, 0.96875\n",
      "Train loss and acc of batch 6: 48.52185821533203, 0.96875\n",
      "Train loss and acc of batch 7: 48.019229888916016, 1.0\n",
      "Train loss and acc of batch 8: 48.61492156982422, 0.984375\n",
      "Train loss and acc of batch 9: 48.30506896972656, 0.984375\n",
      "Train loss and acc of batch 10: 48.01921081542969, 1.0\n",
      "Train loss and acc of batch 11: 48.01919937133789, 1.0\n",
      "Train loss and acc of batch 12: 48.77241516113281, 0.984375\n",
      "Train loss and acc of batch 13: 48.23594665527344, 0.984375\n",
      "Train loss and acc of batch 14: 48.235939025878906, 0.984375\n",
      "Train loss and acc of batch 15: 48.6148681640625, 0.984375\n",
      "Train loss and acc of batch 16: 48.61485290527344, 0.984375\n",
      "Train loss and acc of batch 17: 48.772369384765625, 0.984375\n",
      "Train loss and acc of batch 18: 48.90068817138672, 0.96875\n",
      "Train loss and acc of batch 19: 48.019126892089844, 1.0\n",
      "Train loss and acc of batch 20: 48.01911926269531, 1.0\n",
      "Train loss and acc of batch 21: 48.61481475830078, 0.984375\n",
      "Train loss and acc of batch 22: 48.61479949951172, 0.984375\n",
      "Train loss and acc of batch 23: 48.23585510253906, 0.984375\n",
      "Train loss and acc of batch 24: 48.614784240722656, 0.984375\n",
      "Train loss and acc of batch 25: 48.019073486328125, 1.0\n",
      "Train loss and acc of batch 26: 48.019065856933594, 1.0\n",
      "Train loss and acc of batch 27: 48.0190544128418, 1.0\n",
      "Train loss and acc of batch 28: 48.01905059814453, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 29: 48.61474609375, 0.984375\n",
      "Train loss and acc of batch 30: 48.01902770996094, 1.0\n",
      "Train loss and acc of batch 31: 48.23578643798828, 0.984375\n",
      "Train loss and acc of batch 32: 48.01901626586914, 1.0\n",
      "Train loss and acc of batch 33: 48.01900100708008, 1.0\n",
      "Train loss and acc of batch 34: 48.61469268798828, 0.984375\n",
      "Train loss and acc of batch 35: 48.452510833740234, 0.96875\n",
      "Train loss and acc of batch 36: 48.01897430419922, 1.0\n",
      "Train loss and acc of batch 37: 48.77219009399414, 0.984375\n",
      "Train loss and acc of batch 38: 49.367881774902344, 0.96875\n",
      "Train loss and acc of batch 39: 48.23571014404297, 0.984375\n",
      "Train loss and acc of batch 40: 48.018943786621094, 1.0\n",
      "Train loss and acc of batch 41: 49.367855072021484, 0.96875\n",
      "Train loss and acc of batch 42: 48.018924713134766, 1.0\n",
      "Train loss and acc of batch 43: 48.61461639404297, 0.984375\n",
      "Train loss and acc of batch 44: 48.01890182495117, 1.0\n",
      "Train loss and acc of batch 45: 48.614593505859375, 0.984375\n",
      "Train loss and acc of batch 46: 48.30473327636719, 0.984375\n",
      "Train loss and acc of batch 47: 48.01887512207031, 1.0\n",
      "Train loss and acc of batch 48: 48.01886749267578, 1.0\n",
      "Train loss and acc of batch 49: 48.01885986328125, 1.0\n",
      "Train loss and acc of batch 50: 48.61454772949219, 0.984375\n",
      "Train loss and acc of batch 51: 49.367767333984375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2746696472168, 0.953125\n",
      "Train loss and acc of batch 53: 48.01882553100586, 1.0\n",
      "Train loss and acc of batch 54: 48.23558044433594, 0.984375\n",
      "Train loss and acc of batch 55: 48.01880645751953, 1.0\n",
      "Train loss and acc of batch 56: 48.018798828125, 1.0\n",
      "Train loss and acc of batch 57: 48.61448669433594, 0.984375\n",
      "Train loss and acc of batch 58: 48.01877212524414, 1.0\n",
      "Train loss and acc of batch 59: 48.01876449584961, 1.0\n",
      "Train loss and acc of batch 60: 48.01875686645508, 1.0\n",
      "Train loss and acc of batch 61: 48.01874542236328, 1.0\n",
      "Train loss and acc of batch 62: 48.235504150390625, 0.984375\n",
      "Train loss and acc of batch 63: 49.21013259887695, 0.96875\n",
      "Train loss and acc of batch 64: 48.23548889160156, 0.984375\n",
      "Train loss and acc of batch 65: 48.018714904785156, 1.0\n",
      "Train loss and acc of batch 66: 48.01870346069336, 1.0\n",
      "Train loss and acc of batch 67: 48.83116149902344, 0.96875\n",
      "Train loss and acc of batch 68: 48.61438751220703, 0.984375\n",
      "Train loss and acc of batch 69: 48.235443115234375, 0.984375\n",
      "Train loss and acc of batch 70: 48.01866912841797, 1.0\n",
      "Training accuracy and loss of epoch #63: 0.9890, 48.3500\n",
      "Saved model by train loss 48.34999928004305\n",
      "Train loss and acc of batch 0: 48.01866149902344, 1.0\n",
      "Train loss and acc of batch 1: 48.018646240234375, 1.0\n",
      "Train loss and acc of batch 2: 48.30448913574219, 0.984375\n",
      "Train loss and acc of batch 3: 48.23539733886719, 0.984375\n",
      "Train loss and acc of batch 4: 48.018619537353516, 1.0\n",
      "Train loss and acc of batch 5: 49.36753845214844, 0.96875\n",
      "Train loss and acc of batch 6: 48.52122497558594, 0.96875\n",
      "Train loss and acc of batch 7: 48.01860046386719, 1.0\n",
      "Train loss and acc of batch 8: 48.614288330078125, 0.984375\n",
      "Train loss and acc of batch 9: 48.30442810058594, 0.984375\n",
      "Train loss and acc of batch 10: 48.01856994628906, 1.0\n",
      "Train loss and acc of batch 11: 48.01856231689453, 1.0\n",
      "Train loss and acc of batch 12: 48.77177429199219, 0.984375\n",
      "Train loss and acc of batch 13: 48.235313415527344, 0.984375\n",
      "Train loss and acc of batch 14: 48.23529815673828, 0.984375\n",
      "Train loss and acc of batch 15: 48.614227294921875, 0.984375\n",
      "Train loss and acc of batch 16: 48.614219665527344, 0.984375\n",
      "Train loss and acc of batch 17: 48.771728515625, 0.984375\n",
      "Train loss and acc of batch 18: 48.90005111694336, 0.96875\n",
      "Train loss and acc of batch 19: 48.018489837646484, 1.0\n",
      "Train loss and acc of batch 20: 48.01847839355469, 1.0\n",
      "Train loss and acc of batch 21: 48.614173889160156, 0.984375\n",
      "Train loss and acc of batch 22: 48.614166259765625, 0.984375\n",
      "Train loss and acc of batch 23: 48.23521423339844, 0.984375\n",
      "Train loss and acc of batch 24: 48.61414337158203, 0.984375\n",
      "Train loss and acc of batch 25: 48.018436431884766, 1.0\n",
      "Train loss and acc of batch 26: 48.018428802490234, 1.0\n",
      "Train loss and acc of batch 27: 48.01841735839844, 1.0\n",
      "Train loss and acc of batch 28: 48.018409729003906, 1.0\n",
      "Train loss and acc of batch 29: 48.614105224609375, 0.984375\n",
      "Train loss and acc of batch 30: 48.018394470214844, 1.0\n",
      "Train loss and acc of batch 31: 48.235145568847656, 0.984375\n",
      "Train loss and acc of batch 32: 48.01837158203125, 1.0\n",
      "Train loss and acc of batch 33: 48.01836395263672, 1.0\n",
      "Train loss and acc of batch 34: 48.61405944824219, 0.984375\n",
      "Train loss and acc of batch 35: 48.45187759399414, 0.96875\n",
      "Train loss and acc of batch 36: 48.01833724975586, 1.0\n",
      "Train loss and acc of batch 37: 48.771549224853516, 0.984375\n",
      "Train loss and acc of batch 38: 49.36724853515625, 0.96875\n",
      "Train loss and acc of batch 39: 48.235076904296875, 0.984375\n",
      "Train loss and acc of batch 40: 48.01830291748047, 1.0\n",
      "Train loss and acc of batch 41: 49.367218017578125, 0.96875\n",
      "Train loss and acc of batch 42: 48.018287658691406, 1.0\n",
      "Train loss and acc of batch 43: 48.613975524902344, 0.984375\n",
      "Train loss and acc of batch 44: 48.018272399902344, 1.0\n",
      "Train loss and acc of batch 45: 48.61395263671875, 0.984375\n",
      "Train loss and acc of batch 46: 48.304100036621094, 0.984375\n",
      "Train loss and acc of batch 47: 48.01823806762695, 1.0\n",
      "Train loss and acc of batch 48: 48.018226623535156, 1.0\n",
      "Train loss and acc of batch 49: 48.01822280883789, 1.0\n",
      "Train loss and acc of batch 50: 48.613914489746094, 0.984375\n",
      "Train loss and acc of batch 51: 49.36712646484375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2740364074707, 0.953125\n",
      "Train loss and acc of batch 53: 48.018184661865234, 1.0\n",
      "Train loss and acc of batch 54: 48.23493957519531, 0.984375\n",
      "Train loss and acc of batch 55: 48.01816940307617, 1.0\n",
      "Train loss and acc of batch 56: 48.018157958984375, 1.0\n",
      "Train loss and acc of batch 57: 48.613853454589844, 0.984375\n",
      "Train loss and acc of batch 58: 48.01814270019531, 1.0\n",
      "Train loss and acc of batch 59: 48.01812744140625, 1.0\n",
      "Train loss and acc of batch 60: 48.01811981201172, 1.0\n",
      "Train loss and acc of batch 61: 48.01811599731445, 1.0\n",
      "Train loss and acc of batch 62: 48.23487091064453, 0.984375\n",
      "Train loss and acc of batch 63: 49.20949935913086, 0.96875\n",
      "Train loss and acc of batch 64: 48.23484802246094, 0.984375\n",
      "Train loss and acc of batch 65: 48.0180778503418, 1.0\n",
      "Train loss and acc of batch 66: 48.01807403564453, 1.0\n",
      "Train loss and acc of batch 67: 48.83052444458008, 0.96875\n",
      "Train loss and acc of batch 68: 48.61375427246094, 0.984375\n",
      "Train loss and acc of batch 69: 48.23480987548828, 0.984375\n",
      "Train loss and acc of batch 70: 48.018028259277344, 1.0\n",
      "Training accuracy and loss of epoch #64: 0.9890, 48.3494\n",
      "Saved model by train loss 48.34936195695904\n",
      "Train loss and acc of batch 0: 48.01802444458008, 1.0\n",
      "Train loss and acc of batch 1: 48.01801300048828, 1.0\n",
      "Train loss and acc of batch 2: 48.303863525390625, 0.984375\n",
      "Train loss and acc of batch 3: 48.23475646972656, 0.984375\n",
      "Train loss and acc of batch 4: 48.01799011230469, 1.0\n",
      "Train loss and acc of batch 5: 49.366905212402344, 0.96875\n",
      "Train loss and acc of batch 6: 48.520591735839844, 0.96875\n",
      "Train loss and acc of batch 7: 48.01796340942383, 1.0\n",
      "Train loss and acc of batch 8: 48.61365509033203, 0.984375\n",
      "Train loss and acc of batch 9: 48.303802490234375, 0.984375\n",
      "Train loss and acc of batch 10: 48.017940521240234, 1.0\n",
      "Train loss and acc of batch 11: 48.01792526245117, 1.0\n",
      "Train loss and acc of batch 12: 48.771141052246094, 0.984375\n",
      "Train loss and acc of batch 13: 48.23467254638672, 0.984375\n",
      "Train loss and acc of batch 14: 48.23466491699219, 0.984375\n",
      "Train loss and acc of batch 15: 48.61359405517578, 0.984375\n",
      "Train loss and acc of batch 16: 48.61357879638672, 0.984375\n",
      "Train loss and acc of batch 17: 48.771095275878906, 0.984375\n",
      "Train loss and acc of batch 18: 48.899417877197266, 0.96875\n",
      "Train loss and acc of batch 19: 48.01785659790039, 1.0\n",
      "Train loss and acc of batch 20: 48.01784896850586, 1.0\n",
      "Train loss and acc of batch 21: 48.61354064941406, 0.984375\n",
      "Train loss and acc of batch 22: 48.613525390625, 0.984375\n",
      "Train loss and acc of batch 23: 48.234588623046875, 0.984375\n",
      "Train loss and acc of batch 24: 48.61351013183594, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 25: 48.01780319213867, 1.0\n",
      "Train loss and acc of batch 26: 48.017791748046875, 1.0\n",
      "Train loss and acc of batch 27: 48.01778793334961, 1.0\n",
      "Train loss and acc of batch 28: 48.01777267456055, 1.0\n",
      "Train loss and acc of batch 29: 48.61346435546875, 0.984375\n",
      "Train loss and acc of batch 30: 48.01775360107422, 1.0\n",
      "Train loss and acc of batch 31: 48.23451232910156, 0.984375\n",
      "Train loss and acc of batch 32: 48.017738342285156, 1.0\n",
      "Train loss and acc of batch 33: 48.01772689819336, 1.0\n",
      "Train loss and acc of batch 34: 48.61341857910156, 0.984375\n",
      "Train loss and acc of batch 35: 48.45124435424805, 0.96875\n",
      "Train loss and acc of batch 36: 48.0177001953125, 1.0\n",
      "Train loss and acc of batch 37: 48.77091979980469, 0.984375\n",
      "Train loss and acc of batch 38: 49.366615295410156, 0.96875\n",
      "Train loss and acc of batch 39: 48.23444366455078, 0.984375\n",
      "Train loss and acc of batch 40: 48.01766586303711, 1.0\n",
      "Train loss and acc of batch 41: 49.366580963134766, 0.96875\n",
      "Train loss and acc of batch 42: 48.01765060424805, 1.0\n",
      "Train loss and acc of batch 43: 48.61334228515625, 0.984375\n",
      "Train loss and acc of batch 44: 48.01762771606445, 1.0\n",
      "Train loss and acc of batch 45: 48.61332702636719, 0.984375\n",
      "Train loss and acc of batch 46: 48.30345916748047, 0.984375\n",
      "Train loss and acc of batch 47: 48.01760482788086, 1.0\n",
      "Train loss and acc of batch 48: 48.01759338378906, 1.0\n",
      "Train loss and acc of batch 49: 48.01758575439453, 1.0\n",
      "Train loss and acc of batch 50: 48.61328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.366493225097656, 0.96875\n",
      "Train loss and acc of batch 52: 49.27340316772461, 0.953125\n",
      "Train loss and acc of batch 53: 48.01755142211914, 1.0\n",
      "Train loss and acc of batch 54: 48.23430633544922, 0.984375\n",
      "Train loss and acc of batch 55: 48.01753234863281, 1.0\n",
      "Train loss and acc of batch 56: 48.01752471923828, 1.0\n",
      "Train loss and acc of batch 57: 48.61321258544922, 0.984375\n",
      "Train loss and acc of batch 58: 48.01750564575195, 1.0\n",
      "Train loss and acc of batch 59: 48.01749801635742, 1.0\n",
      "Train loss and acc of batch 60: 48.01749038696289, 1.0\n",
      "Train loss and acc of batch 61: 48.01747512817383, 1.0\n",
      "Train loss and acc of batch 62: 48.234230041503906, 0.984375\n",
      "Train loss and acc of batch 63: 49.2088623046875, 0.96875\n",
      "Train loss and acc of batch 64: 48.234214782714844, 0.984375\n",
      "Train loss and acc of batch 65: 48.0174446105957, 1.0\n",
      "Train loss and acc of batch 66: 48.01743698120117, 1.0\n",
      "Train loss and acc of batch 67: 48.829891204833984, 0.96875\n",
      "Train loss and acc of batch 68: 48.613121032714844, 0.984375\n",
      "Train loss and acc of batch 69: 48.234169006347656, 0.984375\n",
      "Train loss and acc of batch 70: 48.017398834228516, 1.0\n",
      "Training accuracy and loss of epoch #65: 0.9890, 48.3487\n",
      "Saved model by train loss 48.348727320281554\n",
      "Train loss and acc of batch 0: 48.017391204833984, 1.0\n",
      "Train loss and acc of batch 1: 48.01737594604492, 1.0\n",
      "Train loss and acc of batch 2: 48.30322265625, 0.984375\n",
      "Train loss and acc of batch 3: 48.23412322998047, 0.984375\n",
      "Train loss and acc of batch 4: 48.01735305786133, 1.0\n",
      "Train loss and acc of batch 5: 49.36626434326172, 0.96875\n",
      "Train loss and acc of batch 6: 48.519954681396484, 0.96875\n",
      "Train loss and acc of batch 7: 48.01732635498047, 1.0\n",
      "Train loss and acc of batch 8: 48.61302185058594, 0.984375\n",
      "Train loss and acc of batch 9: 48.30316162109375, 0.984375\n",
      "Train loss and acc of batch 10: 48.017303466796875, 1.0\n",
      "Train loss and acc of batch 11: 48.01728820800781, 1.0\n",
      "Train loss and acc of batch 12: 48.77050018310547, 0.984375\n",
      "Train loss and acc of batch 13: 48.234039306640625, 0.984375\n",
      "Train loss and acc of batch 14: 48.234031677246094, 0.984375\n",
      "Train loss and acc of batch 15: 48.612953186035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.612953186035156, 0.984375\n",
      "Train loss and acc of batch 17: 48.77046203613281, 0.984375\n",
      "Train loss and acc of batch 18: 48.898780822753906, 0.96875\n",
      "Train loss and acc of batch 19: 48.017215728759766, 1.0\n",
      "Train loss and acc of batch 20: 48.017208099365234, 1.0\n",
      "Train loss and acc of batch 21: 48.61289978027344, 0.984375\n",
      "Train loss and acc of batch 22: 48.61289978027344, 0.984375\n",
      "Train loss and acc of batch 23: 48.23394775390625, 0.984375\n",
      "Train loss and acc of batch 24: 48.612876892089844, 0.984375\n",
      "Train loss and acc of batch 25: 48.01716995239258, 1.0\n",
      "Train loss and acc of batch 26: 48.017154693603516, 1.0\n",
      "Train loss and acc of batch 27: 48.017147064208984, 1.0\n",
      "Train loss and acc of batch 28: 48.01713943481445, 1.0\n",
      "Train loss and acc of batch 29: 48.612831115722656, 0.984375\n",
      "Train loss and acc of batch 30: 48.01712417602539, 1.0\n",
      "Train loss and acc of batch 31: 48.23387908935547, 0.984375\n",
      "Train loss and acc of batch 32: 48.01710891723633, 1.0\n",
      "Train loss and acc of batch 33: 48.01709747314453, 1.0\n",
      "Train loss and acc of batch 34: 48.61278533935547, 0.984375\n",
      "Train loss and acc of batch 35: 48.45060729980469, 0.96875\n",
      "Train loss and acc of batch 36: 48.01707077026367, 1.0\n",
      "Train loss and acc of batch 37: 48.77027893066406, 0.984375\n",
      "Train loss and acc of batch 38: 49.36597442626953, 0.96875\n",
      "Train loss and acc of batch 39: 48.23381042480469, 0.984375\n",
      "Train loss and acc of batch 40: 48.017032623291016, 1.0\n",
      "Train loss and acc of batch 41: 49.3659553527832, 0.96875\n",
      "Train loss and acc of batch 42: 48.01701354980469, 1.0\n",
      "Train loss and acc of batch 43: 48.612709045410156, 0.984375\n",
      "Train loss and acc of batch 44: 48.016998291015625, 1.0\n",
      "Train loss and acc of batch 45: 48.612693786621094, 0.984375\n",
      "Train loss and acc of batch 46: 48.302833557128906, 0.984375\n",
      "Train loss and acc of batch 47: 48.016971588134766, 1.0\n",
      "Train loss and acc of batch 48: 48.0169563293457, 1.0\n",
      "Train loss and acc of batch 49: 48.0169563293457, 1.0\n",
      "Train loss and acc of batch 50: 48.612648010253906, 0.984375\n",
      "Train loss and acc of batch 51: 49.36585998535156, 0.96875\n",
      "Train loss and acc of batch 52: 49.272762298583984, 0.953125\n",
      "Train loss and acc of batch 53: 48.01691818237305, 1.0\n",
      "Train loss and acc of batch 54: 48.233673095703125, 0.984375\n",
      "Train loss and acc of batch 55: 48.01689529418945, 1.0\n",
      "Train loss and acc of batch 56: 48.01688766479492, 1.0\n",
      "Train loss and acc of batch 57: 48.612579345703125, 0.984375\n",
      "Train loss and acc of batch 58: 48.01687240600586, 1.0\n",
      "Train loss and acc of batch 59: 48.01686096191406, 1.0\n",
      "Train loss and acc of batch 60: 48.0168571472168, 1.0\n",
      "Train loss and acc of batch 61: 48.016845703125, 1.0\n",
      "Train loss and acc of batch 62: 48.233604431152344, 0.984375\n",
      "Train loss and acc of batch 63: 49.208229064941406, 0.96875\n",
      "Train loss and acc of batch 64: 48.23358154296875, 0.984375\n",
      "Train loss and acc of batch 65: 48.016807556152344, 1.0\n",
      "Train loss and acc of batch 66: 48.01680374145508, 1.0\n",
      "Train loss and acc of batch 67: 48.829254150390625, 0.96875\n",
      "Train loss and acc of batch 68: 48.61248779296875, 0.984375\n",
      "Train loss and acc of batch 69: 48.23353576660156, 0.984375\n",
      "Train loss and acc of batch 70: 48.01676559448242, 1.0\n",
      "Training accuracy and loss of epoch #66: 0.9890, 48.3481\n",
      "Saved model by train loss 48.348092737332195\n",
      "Train loss and acc of batch 0: 48.016754150390625, 1.0\n",
      "Train loss and acc of batch 1: 48.01675033569336, 1.0\n",
      "Train loss and acc of batch 2: 48.302589416503906, 0.984375\n",
      "Train loss and acc of batch 3: 48.233489990234375, 0.984375\n",
      "Train loss and acc of batch 4: 48.016719818115234, 1.0\n",
      "Train loss and acc of batch 5: 49.365631103515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.519317626953125, 0.96875\n",
      "Train loss and acc of batch 7: 48.01669692993164, 1.0\n",
      "Train loss and acc of batch 8: 48.61238098144531, 0.984375\n",
      "Train loss and acc of batch 9: 48.302528381347656, 0.984375\n",
      "Train loss and acc of batch 10: 48.016666412353516, 1.0\n",
      "Train loss and acc of batch 11: 48.016658782958984, 1.0\n",
      "Train loss and acc of batch 12: 48.76987075805664, 0.984375\n",
      "Train loss and acc of batch 13: 48.23340606689453, 0.984375\n",
      "Train loss and acc of batch 14: 48.23339080810547, 0.984375\n",
      "Train loss and acc of batch 15: 48.612327575683594, 0.984375\n",
      "Train loss and acc of batch 16: 48.61231231689453, 0.984375\n",
      "Train loss and acc of batch 17: 48.76982879638672, 0.984375\n",
      "Train loss and acc of batch 18: 48.89814758300781, 0.96875\n",
      "Train loss and acc of batch 19: 48.0165901184082, 1.0\n",
      "Train loss and acc of batch 20: 48.016578674316406, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 21: 48.612266540527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.61225891113281, 0.984375\n",
      "Train loss and acc of batch 23: 48.233314514160156, 0.984375\n",
      "Train loss and acc of batch 24: 48.61224365234375, 0.984375\n",
      "Train loss and acc of batch 25: 48.01653289794922, 1.0\n",
      "Train loss and acc of batch 26: 48.01652526855469, 1.0\n",
      "Train loss and acc of batch 27: 48.016510009765625, 1.0\n",
      "Train loss and acc of batch 28: 48.01650619506836, 1.0\n",
      "Train loss and acc of batch 29: 48.61219787597656, 0.984375\n",
      "Train loss and acc of batch 30: 48.0164909362793, 1.0\n",
      "Train loss and acc of batch 31: 48.233238220214844, 0.984375\n",
      "Train loss and acc of batch 32: 48.01647186279297, 1.0\n",
      "Train loss and acc of batch 33: 48.01646041870117, 1.0\n",
      "Train loss and acc of batch 34: 48.612159729003906, 0.984375\n",
      "Train loss and acc of batch 35: 48.44997024536133, 0.96875\n",
      "Train loss and acc of batch 36: 48.01643371582031, 1.0\n",
      "Train loss and acc of batch 37: 48.76964569091797, 0.984375\n",
      "Train loss and acc of batch 38: 49.36534118652344, 0.96875\n",
      "Train loss and acc of batch 39: 48.233177185058594, 0.984375\n",
      "Train loss and acc of batch 40: 48.01639938354492, 1.0\n",
      "Train loss and acc of batch 41: 49.36531448364258, 0.96875\n",
      "Train loss and acc of batch 42: 48.01637649536133, 1.0\n",
      "Train loss and acc of batch 43: 48.61206817626953, 0.984375\n",
      "Train loss and acc of batch 44: 48.016361236572266, 1.0\n",
      "Train loss and acc of batch 45: 48.61205291748047, 0.984375\n",
      "Train loss and acc of batch 46: 48.30220031738281, 0.984375\n",
      "Train loss and acc of batch 47: 48.016334533691406, 1.0\n",
      "Train loss and acc of batch 48: 48.01633071899414, 1.0\n",
      "Train loss and acc of batch 49: 48.016319274902344, 1.0\n",
      "Train loss and acc of batch 50: 48.61200714111328, 0.984375\n",
      "Train loss and acc of batch 51: 49.36522674560547, 0.96875\n",
      "Train loss and acc of batch 52: 49.272125244140625, 0.953125\n",
      "Train loss and acc of batch 53: 48.01628112792969, 1.0\n",
      "Train loss and acc of batch 54: 48.23303985595703, 0.984375\n",
      "Train loss and acc of batch 55: 48.016265869140625, 1.0\n",
      "Train loss and acc of batch 56: 48.016258239746094, 1.0\n",
      "Train loss and acc of batch 57: 48.61194610595703, 0.984375\n",
      "Train loss and acc of batch 58: 48.016231536865234, 1.0\n",
      "Train loss and acc of batch 59: 48.01622772216797, 1.0\n",
      "Train loss and acc of batch 60: 48.01621627807617, 1.0\n",
      "Train loss and acc of batch 61: 48.016212463378906, 1.0\n",
      "Train loss and acc of batch 62: 48.23297119140625, 0.984375\n",
      "Train loss and acc of batch 63: 49.20759201049805, 0.96875\n",
      "Train loss and acc of batch 64: 48.232948303222656, 0.984375\n",
      "Train loss and acc of batch 65: 48.016178131103516, 1.0\n",
      "Train loss and acc of batch 66: 48.01616287231445, 1.0\n",
      "Train loss and acc of batch 67: 48.8286247253418, 0.96875\n",
      "Train loss and acc of batch 68: 48.611846923828125, 0.984375\n",
      "Train loss and acc of batch 69: 48.23290252685547, 0.984375\n",
      "Train loss and acc of batch 70: 48.01612854003906, 1.0\n",
      "Training accuracy and loss of epoch #67: 0.9890, 48.3475\n",
      "Saved model by train loss 48.34745820811097\n",
      "Train loss and acc of batch 0: 48.01612091064453, 1.0\n",
      "Train loss and acc of batch 1: 48.016109466552734, 1.0\n",
      "Train loss and acc of batch 2: 48.30195617675781, 0.984375\n",
      "Train loss and acc of batch 3: 48.23285675048828, 0.984375\n",
      "Train loss and acc of batch 4: 48.01608657836914, 1.0\n",
      "Train loss and acc of batch 5: 49.36500549316406, 0.96875\n",
      "Train loss and acc of batch 6: 48.518680572509766, 0.96875\n",
      "Train loss and acc of batch 7: 48.01605987548828, 1.0\n",
      "Train loss and acc of batch 8: 48.61174774169922, 0.984375\n",
      "Train loss and acc of batch 9: 48.30188751220703, 0.984375\n",
      "Train loss and acc of batch 10: 48.01603698730469, 1.0\n",
      "Train loss and acc of batch 11: 48.01601791381836, 1.0\n",
      "Train loss and acc of batch 12: 48.76923370361328, 0.984375\n",
      "Train loss and acc of batch 13: 48.23277282714844, 0.984375\n",
      "Train loss and acc of batch 14: 48.232757568359375, 0.984375\n",
      "Train loss and acc of batch 15: 48.61168670654297, 0.984375\n",
      "Train loss and acc of batch 16: 48.61167907714844, 0.984375\n",
      "Train loss and acc of batch 17: 48.76919174194336, 0.984375\n",
      "Train loss and acc of batch 18: 48.89751434326172, 0.96875\n",
      "Train loss and acc of batch 19: 48.01595687866211, 1.0\n",
      "Train loss and acc of batch 20: 48.01594543457031, 1.0\n",
      "Train loss and acc of batch 21: 48.61164093017578, 0.984375\n",
      "Train loss and acc of batch 22: 48.61162567138672, 0.984375\n",
      "Train loss and acc of batch 23: 48.23268127441406, 0.984375\n",
      "Train loss and acc of batch 24: 48.611610412597656, 0.984375\n",
      "Train loss and acc of batch 25: 48.01589584350586, 1.0\n",
      "Train loss and acc of batch 26: 48.01588439941406, 1.0\n",
      "Train loss and acc of batch 27: 48.0158805847168, 1.0\n",
      "Train loss and acc of batch 28: 48.015869140625, 1.0\n",
      "Train loss and acc of batch 29: 48.61155700683594, 0.984375\n",
      "Train loss and acc of batch 30: 48.01585388183594, 1.0\n",
      "Train loss and acc of batch 31: 48.23261260986328, 0.984375\n",
      "Train loss and acc of batch 32: 48.01583480834961, 1.0\n",
      "Train loss and acc of batch 33: 48.015830993652344, 1.0\n",
      "Train loss and acc of batch 34: 48.61151885986328, 0.984375\n",
      "Train loss and acc of batch 35: 48.4493408203125, 0.96875\n",
      "Train loss and acc of batch 36: 48.01579666137695, 1.0\n",
      "Train loss and acc of batch 37: 48.76900863647461, 0.984375\n",
      "Train loss and acc of batch 38: 49.364707946777344, 0.96875\n",
      "Train loss and acc of batch 39: 48.23252868652344, 0.984375\n",
      "Train loss and acc of batch 40: 48.01576232910156, 1.0\n",
      "Train loss and acc of batch 41: 49.36468505859375, 0.96875\n",
      "Train loss and acc of batch 42: 48.0157470703125, 1.0\n",
      "Train loss and acc of batch 43: 48.61143493652344, 0.984375\n",
      "Train loss and acc of batch 44: 48.01572799682617, 1.0\n",
      "Train loss and acc of batch 45: 48.611419677734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.30156707763672, 0.984375\n",
      "Train loss and acc of batch 47: 48.01570510864258, 1.0\n",
      "Train loss and acc of batch 48: 48.015689849853516, 1.0\n",
      "Train loss and acc of batch 49: 48.015682220458984, 1.0\n",
      "Train loss and acc of batch 50: 48.61137390136719, 0.984375\n",
      "Train loss and acc of batch 51: 49.364585876464844, 0.96875\n",
      "Train loss and acc of batch 52: 49.27149963378906, 0.953125\n",
      "Train loss and acc of batch 53: 48.01564407348633, 1.0\n",
      "Train loss and acc of batch 54: 48.232398986816406, 0.984375\n",
      "Train loss and acc of batch 55: 48.015628814697266, 1.0\n",
      "Train loss and acc of batch 56: 48.015621185302734, 1.0\n",
      "Train loss and acc of batch 57: 48.61131286621094, 0.984375\n",
      "Train loss and acc of batch 58: 48.015602111816406, 1.0\n",
      "Train loss and acc of batch 59: 48.01559066772461, 1.0\n",
      "Train loss and acc of batch 60: 48.01558303833008, 1.0\n",
      "Train loss and acc of batch 61: 48.01557922363281, 1.0\n",
      "Train loss and acc of batch 62: 48.232330322265625, 0.984375\n",
      "Train loss and acc of batch 63: 49.20695877075195, 0.96875\n",
      "Train loss and acc of batch 64: 48.23230743408203, 0.984375\n",
      "Train loss and acc of batch 65: 48.01553726196289, 1.0\n",
      "Train loss and acc of batch 66: 48.01552963256836, 1.0\n",
      "Train loss and acc of batch 67: 48.82798385620117, 0.96875\n",
      "Train loss and acc of batch 68: 48.61121368408203, 0.984375\n",
      "Train loss and acc of batch 69: 48.232269287109375, 0.984375\n",
      "Train loss and acc of batch 70: 48.01549530029297, 1.0\n",
      "Training accuracy and loss of epoch #68: 0.9890, 48.3468\n",
      "Saved model by train loss 48.3468232490647\n",
      "Train loss and acc of batch 0: 48.01548767089844, 1.0\n",
      "Train loss and acc of batch 1: 48.01547622680664, 1.0\n",
      "Train loss and acc of batch 2: 48.30131530761719, 0.984375\n",
      "Train loss and acc of batch 3: 48.23222351074219, 0.984375\n",
      "Train loss and acc of batch 4: 48.01545333862305, 1.0\n",
      "Train loss and acc of batch 5: 49.36436462402344, 0.96875\n",
      "Train loss and acc of batch 6: 48.51805114746094, 0.96875\n",
      "Train loss and acc of batch 7: 48.015419006347656, 1.0\n",
      "Train loss and acc of batch 8: 48.611114501953125, 0.984375\n",
      "Train loss and acc of batch 9: 48.30125427246094, 0.984375\n",
      "Train loss and acc of batch 10: 48.0153923034668, 1.0\n",
      "Train loss and acc of batch 11: 48.015384674072266, 1.0\n",
      "Train loss and acc of batch 12: 48.76860427856445, 0.984375\n",
      "Train loss and acc of batch 13: 48.23213195800781, 0.984375\n",
      "Train loss and acc of batch 14: 48.23212432861328, 0.984375\n",
      "Train loss and acc of batch 15: 48.611061096191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.611045837402344, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 17: 48.768558502197266, 0.984375\n",
      "Train loss and acc of batch 18: 48.896881103515625, 0.96875\n",
      "Train loss and acc of batch 19: 48.015316009521484, 1.0\n",
      "Train loss and acc of batch 20: 48.01530838012695, 1.0\n",
      "Train loss and acc of batch 21: 48.61100769042969, 0.984375\n",
      "Train loss and acc of batch 22: 48.610992431640625, 0.984375\n",
      "Train loss and acc of batch 23: 48.23204803466797, 0.984375\n",
      "Train loss and acc of batch 24: 48.61096954345703, 0.984375\n",
      "Train loss and acc of batch 25: 48.015262603759766, 1.0\n",
      "Train loss and acc of batch 26: 48.0152587890625, 1.0\n",
      "Train loss and acc of batch 27: 48.0152473449707, 1.0\n",
      "Train loss and acc of batch 28: 48.015235900878906, 1.0\n",
      "Train loss and acc of batch 29: 48.610931396484375, 0.984375\n",
      "Train loss and acc of batch 30: 48.01521682739258, 1.0\n",
      "Train loss and acc of batch 31: 48.23197937011719, 0.984375\n",
      "Train loss and acc of batch 32: 48.015201568603516, 1.0\n",
      "Train loss and acc of batch 33: 48.01518630981445, 1.0\n",
      "Train loss and acc of batch 34: 48.61088562011719, 0.984375\n",
      "Train loss and acc of batch 35: 48.448707580566406, 0.96875\n",
      "Train loss and acc of batch 36: 48.015167236328125, 1.0\n",
      "Train loss and acc of batch 37: 48.76838302612305, 0.984375\n",
      "Train loss and acc of batch 38: 49.36406707763672, 0.96875\n",
      "Train loss and acc of batch 39: 48.231903076171875, 0.984375\n",
      "Train loss and acc of batch 40: 48.01512908935547, 1.0\n",
      "Train loss and acc of batch 41: 49.36404800415039, 0.96875\n",
      "Train loss and acc of batch 42: 48.01511001586914, 1.0\n",
      "Train loss and acc of batch 43: 48.610809326171875, 0.984375\n",
      "Train loss and acc of batch 44: 48.01509475708008, 1.0\n",
      "Train loss and acc of batch 45: 48.61078643798828, 0.984375\n",
      "Train loss and acc of batch 46: 48.300926208496094, 0.984375\n",
      "Train loss and acc of batch 47: 48.01506423950195, 1.0\n",
      "Train loss and acc of batch 48: 48.01505661010742, 1.0\n",
      "Train loss and acc of batch 49: 48.015045166015625, 1.0\n",
      "Train loss and acc of batch 50: 48.610740661621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.36396026611328, 0.96875\n",
      "Train loss and acc of batch 52: 49.27085876464844, 0.953125\n",
      "Train loss and acc of batch 53: 48.015010833740234, 1.0\n",
      "Train loss and acc of batch 54: 48.231773376464844, 0.984375\n",
      "Train loss and acc of batch 55: 48.01499557495117, 1.0\n",
      "Train loss and acc of batch 56: 48.01498794555664, 1.0\n",
      "Train loss and acc of batch 57: 48.610679626464844, 0.984375\n",
      "Train loss and acc of batch 58: 48.01496505737305, 1.0\n",
      "Train loss and acc of batch 59: 48.01496124267578, 1.0\n",
      "Train loss and acc of batch 60: 48.01495361328125, 1.0\n",
      "Train loss and acc of batch 61: 48.01493453979492, 1.0\n",
      "Train loss and acc of batch 62: 48.23169708251953, 0.984375\n",
      "Train loss and acc of batch 63: 49.206321716308594, 0.96875\n",
      "Train loss and acc of batch 64: 48.23168182373047, 0.984375\n",
      "Train loss and acc of batch 65: 48.01490783691406, 1.0\n",
      "Train loss and acc of batch 66: 48.014896392822266, 1.0\n",
      "Train loss and acc of batch 67: 48.82735061645508, 0.96875\n",
      "Train loss and acc of batch 68: 48.61058044433594, 0.984375\n",
      "Train loss and acc of batch 69: 48.23162841796875, 0.984375\n",
      "Train loss and acc of batch 70: 48.014862060546875, 1.0\n",
      "Training accuracy and loss of epoch #69: 0.9890, 48.3462\n",
      "Saved model by train loss 48.34618925712478\n",
      "Train loss and acc of batch 0: 48.014854431152344, 1.0\n",
      "Train loss and acc of batch 1: 48.01484298706055, 1.0\n",
      "Train loss and acc of batch 2: 48.300689697265625, 0.984375\n",
      "Train loss and acc of batch 3: 48.231590270996094, 0.984375\n",
      "Train loss and acc of batch 4: 48.01481628417969, 1.0\n",
      "Train loss and acc of batch 5: 49.363731384277344, 0.96875\n",
      "Train loss and acc of batch 6: 48.51741409301758, 0.96875\n",
      "Train loss and acc of batch 7: 48.01478958129883, 1.0\n",
      "Train loss and acc of batch 8: 48.61048126220703, 0.984375\n",
      "Train loss and acc of batch 9: 48.300621032714844, 0.984375\n",
      "Train loss and acc of batch 10: 48.01476287841797, 1.0\n",
      "Train loss and acc of batch 11: 48.01475524902344, 1.0\n",
      "Train loss and acc of batch 12: 48.767967224121094, 0.984375\n",
      "Train loss and acc of batch 13: 48.23149871826172, 0.984375\n",
      "Train loss and acc of batch 14: 48.23149108886719, 0.984375\n",
      "Train loss and acc of batch 15: 48.61042022705078, 0.984375\n",
      "Train loss and acc of batch 16: 48.61041259765625, 0.984375\n",
      "Train loss and acc of batch 17: 48.76791763305664, 0.984375\n",
      "Train loss and acc of batch 18: 48.896244049072266, 0.96875\n",
      "Train loss and acc of batch 19: 48.014678955078125, 1.0\n",
      "Train loss and acc of batch 20: 48.014671325683594, 1.0\n",
      "Train loss and acc of batch 21: 48.61036682128906, 0.984375\n",
      "Train loss and acc of batch 22: 48.61035919189453, 0.984375\n",
      "Train loss and acc of batch 23: 48.231407165527344, 0.984375\n",
      "Train loss and acc of batch 24: 48.61033630371094, 0.984375\n",
      "Train loss and acc of batch 25: 48.014625549316406, 1.0\n",
      "Train loss and acc of batch 26: 48.014617919921875, 1.0\n",
      "Train loss and acc of batch 27: 48.014610290527344, 1.0\n",
      "Train loss and acc of batch 28: 48.01460647583008, 1.0\n",
      "Train loss and acc of batch 29: 48.61029052734375, 0.984375\n",
      "Train loss and acc of batch 30: 48.014591217041016, 1.0\n",
      "Train loss and acc of batch 31: 48.23133850097656, 0.984375\n",
      "Train loss and acc of batch 32: 48.014564514160156, 1.0\n",
      "Train loss and acc of batch 33: 48.014556884765625, 1.0\n",
      "Train loss and acc of batch 34: 48.61024475097656, 0.984375\n",
      "Train loss and acc of batch 35: 48.44806671142578, 0.96875\n",
      "Train loss and acc of batch 36: 48.0145263671875, 1.0\n",
      "Train loss and acc of batch 37: 48.76774597167969, 0.984375\n",
      "Train loss and acc of batch 38: 49.363441467285156, 0.96875\n",
      "Train loss and acc of batch 39: 48.23126983642578, 0.984375\n",
      "Train loss and acc of batch 40: 48.01449203491211, 1.0\n",
      "Train loss and acc of batch 41: 49.36341094970703, 0.96875\n",
      "Train loss and acc of batch 42: 48.01447677612305, 1.0\n",
      "Train loss and acc of batch 43: 48.61016845703125, 0.984375\n",
      "Train loss and acc of batch 44: 48.014461517333984, 1.0\n",
      "Train loss and acc of batch 45: 48.610145568847656, 0.984375\n",
      "Train loss and acc of batch 46: 48.30029296875, 0.984375\n",
      "Train loss and acc of batch 47: 48.014434814453125, 1.0\n",
      "Train loss and acc of batch 48: 48.01441955566406, 1.0\n",
      "Train loss and acc of batch 49: 48.0144157409668, 1.0\n",
      "Train loss and acc of batch 50: 48.610107421875, 0.984375\n",
      "Train loss and acc of batch 51: 49.363319396972656, 0.96875\n",
      "Train loss and acc of batch 52: 49.27022933959961, 0.953125\n",
      "Train loss and acc of batch 53: 48.01437759399414, 1.0\n",
      "Train loss and acc of batch 54: 48.23113250732422, 0.984375\n",
      "Train loss and acc of batch 55: 48.01436233520508, 1.0\n",
      "Train loss and acc of batch 56: 48.014347076416016, 1.0\n",
      "Train loss and acc of batch 57: 48.61004638671875, 0.984375\n",
      "Train loss and acc of batch 58: 48.01433563232422, 1.0\n",
      "Train loss and acc of batch 59: 48.01432418823242, 1.0\n",
      "Train loss and acc of batch 60: 48.014312744140625, 1.0\n",
      "Train loss and acc of batch 61: 48.014305114746094, 1.0\n",
      "Train loss and acc of batch 62: 48.23106384277344, 0.984375\n",
      "Train loss and acc of batch 63: 49.205692291259766, 0.96875\n",
      "Train loss and acc of batch 64: 48.231040954589844, 0.984375\n",
      "Train loss and acc of batch 65: 48.0142707824707, 1.0\n",
      "Train loss and acc of batch 66: 48.01426315307617, 1.0\n",
      "Train loss and acc of batch 67: 48.826725006103516, 0.96875\n",
      "Train loss and acc of batch 68: 48.609947204589844, 0.984375\n",
      "Train loss and acc of batch 69: 48.23100280761719, 0.984375\n",
      "Train loss and acc of batch 70: 48.014225006103516, 1.0\n",
      "Training accuracy and loss of epoch #70: 0.9890, 48.3456\n",
      "Saved model by train loss 48.3455544592629\n",
      "Train loss and acc of batch 0: 48.014217376708984, 1.0\n",
      "Train loss and acc of batch 1: 48.01420974731445, 1.0\n",
      "Train loss and acc of batch 2: 48.300048828125, 0.984375\n",
      "Train loss and acc of batch 3: 48.23095703125, 0.984375\n",
      "Train loss and acc of batch 4: 48.01417541503906, 1.0\n",
      "Train loss and acc of batch 5: 49.36309814453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.516780853271484, 0.96875\n",
      "Train loss and acc of batch 7: 48.014156341552734, 1.0\n",
      "Train loss and acc of batch 8: 48.60984802246094, 0.984375\n",
      "Train loss and acc of batch 9: 48.29999542236328, 0.984375\n",
      "Train loss and acc of batch 10: 48.014129638671875, 1.0\n",
      "Train loss and acc of batch 11: 48.01411437988281, 1.0\n",
      "Train loss and acc of batch 12: 48.767333984375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 13: 48.230865478515625, 0.984375\n",
      "Train loss and acc of batch 14: 48.230857849121094, 0.984375\n",
      "Train loss and acc of batch 15: 48.609779357910156, 0.984375\n",
      "Train loss and acc of batch 16: 48.609771728515625, 0.984375\n",
      "Train loss and acc of batch 17: 48.76728820800781, 0.984375\n",
      "Train loss and acc of batch 18: 48.895606994628906, 0.96875\n",
      "Train loss and acc of batch 19: 48.01404571533203, 1.0\n",
      "Train loss and acc of batch 20: 48.0140380859375, 1.0\n",
      "Train loss and acc of batch 21: 48.60972595214844, 0.984375\n",
      "Train loss and acc of batch 22: 48.609718322753906, 0.984375\n",
      "Train loss and acc of batch 23: 48.23078155517578, 0.984375\n",
      "Train loss and acc of batch 24: 48.609703063964844, 0.984375\n",
      "Train loss and acc of batch 25: 48.01399612426758, 1.0\n",
      "Train loss and acc of batch 26: 48.01398468017578, 1.0\n",
      "Train loss and acc of batch 27: 48.013973236083984, 1.0\n",
      "Train loss and acc of batch 28: 48.01396942138672, 1.0\n",
      "Train loss and acc of batch 29: 48.609657287597656, 0.984375\n",
      "Train loss and acc of batch 30: 48.013946533203125, 1.0\n",
      "Train loss and acc of batch 31: 48.23070526123047, 0.984375\n",
      "Train loss and acc of batch 32: 48.0139274597168, 1.0\n",
      "Train loss and acc of batch 33: 48.013919830322266, 1.0\n",
      "Train loss and acc of batch 34: 48.609619140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.44743347167969, 0.96875\n",
      "Train loss and acc of batch 36: 48.01389694213867, 1.0\n",
      "Train loss and acc of batch 37: 48.767112731933594, 0.984375\n",
      "Train loss and acc of batch 38: 49.36280059814453, 0.96875\n",
      "Train loss and acc of batch 39: 48.230628967285156, 0.984375\n",
      "Train loss and acc of batch 40: 48.01386260986328, 1.0\n",
      "Train loss and acc of batch 41: 49.36277389526367, 0.96875\n",
      "Train loss and acc of batch 42: 48.01384353637695, 1.0\n",
      "Train loss and acc of batch 43: 48.609535217285156, 0.984375\n",
      "Train loss and acc of batch 44: 48.01382064819336, 1.0\n",
      "Train loss and acc of batch 45: 48.609519958496094, 0.984375\n",
      "Train loss and acc of batch 46: 48.299659729003906, 0.984375\n",
      "Train loss and acc of batch 47: 48.0137939453125, 1.0\n",
      "Train loss and acc of batch 48: 48.013790130615234, 1.0\n",
      "Train loss and acc of batch 49: 48.01377868652344, 1.0\n",
      "Train loss and acc of batch 50: 48.609474182128906, 0.984375\n",
      "Train loss and acc of batch 51: 49.36268615722656, 0.96875\n",
      "Train loss and acc of batch 52: 49.26959228515625, 0.953125\n",
      "Train loss and acc of batch 53: 48.01374435424805, 1.0\n",
      "Train loss and acc of batch 54: 48.230506896972656, 0.984375\n",
      "Train loss and acc of batch 55: 48.01372528076172, 1.0\n",
      "Train loss and acc of batch 56: 48.01371765136719, 1.0\n",
      "Train loss and acc of batch 57: 48.609405517578125, 0.984375\n",
      "Train loss and acc of batch 58: 48.013694763183594, 1.0\n",
      "Train loss and acc of batch 59: 48.01369094848633, 1.0\n",
      "Train loss and acc of batch 60: 48.01367950439453, 1.0\n",
      "Train loss and acc of batch 61: 48.013671875, 1.0\n",
      "Train loss and acc of batch 62: 48.23042297363281, 0.984375\n",
      "Train loss and acc of batch 63: 49.205055236816406, 0.96875\n",
      "Train loss and acc of batch 64: 48.23040771484375, 0.984375\n",
      "Train loss and acc of batch 65: 48.01363754272461, 1.0\n",
      "Train loss and acc of batch 66: 48.01362609863281, 1.0\n",
      "Train loss and acc of batch 67: 48.82608413696289, 0.96875\n",
      "Train loss and acc of batch 68: 48.60931396484375, 0.984375\n",
      "Train loss and acc of batch 69: 48.23036193847656, 0.984375\n",
      "Train loss and acc of batch 70: 48.01359176635742, 1.0\n",
      "Training accuracy and loss of epoch #71: 0.9890, 48.3449\n",
      "Saved model by train loss 48.34491955394476\n",
      "Train loss and acc of batch 0: 48.013580322265625, 1.0\n",
      "Train loss and acc of batch 1: 48.01356887817383, 1.0\n",
      "Train loss and acc of batch 2: 48.29942321777344, 0.984375\n",
      "Train loss and acc of batch 3: 48.230323791503906, 0.984375\n",
      "Train loss and acc of batch 4: 48.013545989990234, 1.0\n",
      "Train loss and acc of batch 5: 49.362457275390625, 0.96875\n",
      "Train loss and acc of batch 6: 48.51613998413086, 0.96875\n",
      "Train loss and acc of batch 7: 48.013519287109375, 1.0\n",
      "Train loss and acc of batch 8: 48.609214782714844, 0.984375\n",
      "Train loss and acc of batch 9: 48.299354553222656, 0.984375\n",
      "Train loss and acc of batch 10: 48.01349639892578, 1.0\n",
      "Train loss and acc of batch 11: 48.013484954833984, 1.0\n",
      "Train loss and acc of batch 12: 48.766693115234375, 0.984375\n",
      "Train loss and acc of batch 13: 48.23023223876953, 0.984375\n",
      "Train loss and acc of batch 14: 48.23021697998047, 0.984375\n",
      "Train loss and acc of batch 15: 48.60914611816406, 0.984375\n",
      "Train loss and acc of batch 16: 48.60914611816406, 0.984375\n",
      "Train loss and acc of batch 17: 48.76665496826172, 0.984375\n",
      "Train loss and acc of batch 18: 48.89497756958008, 0.96875\n",
      "Train loss and acc of batch 19: 48.0134162902832, 1.0\n",
      "Train loss and acc of batch 20: 48.01340103149414, 1.0\n",
      "Train loss and acc of batch 21: 48.609100341796875, 0.984375\n",
      "Train loss and acc of batch 22: 48.60908508300781, 0.984375\n",
      "Train loss and acc of batch 23: 48.230140686035156, 0.984375\n",
      "Train loss and acc of batch 24: 48.60906982421875, 0.984375\n",
      "Train loss and acc of batch 25: 48.013362884521484, 1.0\n",
      "Train loss and acc of batch 26: 48.013343811035156, 1.0\n",
      "Train loss and acc of batch 27: 48.013343811035156, 1.0\n",
      "Train loss and acc of batch 28: 48.013328552246094, 1.0\n",
      "Train loss and acc of batch 29: 48.60902404785156, 0.984375\n",
      "Train loss and acc of batch 30: 48.0133171081543, 1.0\n",
      "Train loss and acc of batch 31: 48.230072021484375, 0.984375\n",
      "Train loss and acc of batch 32: 48.01329803466797, 1.0\n",
      "Train loss and acc of batch 33: 48.01329040527344, 1.0\n",
      "Train loss and acc of batch 34: 48.608978271484375, 0.984375\n",
      "Train loss and acc of batch 35: 48.446800231933594, 0.96875\n",
      "Train loss and acc of batch 36: 48.01326370239258, 1.0\n",
      "Train loss and acc of batch 37: 48.766475677490234, 0.984375\n",
      "Train loss and acc of batch 38: 49.36216735839844, 0.96875\n",
      "Train loss and acc of batch 39: 48.230003356933594, 0.984375\n",
      "Train loss and acc of batch 40: 48.01322555541992, 1.0\n",
      "Train loss and acc of batch 41: 49.362144470214844, 0.96875\n",
      "Train loss and acc of batch 42: 48.013206481933594, 1.0\n",
      "Train loss and acc of batch 43: 48.60889434814453, 0.984375\n",
      "Train loss and acc of batch 44: 48.01319122314453, 1.0\n",
      "Train loss and acc of batch 45: 48.60887908935547, 0.984375\n",
      "Train loss and acc of batch 46: 48.29902648925781, 0.984375\n",
      "Train loss and acc of batch 47: 48.01316452026367, 1.0\n",
      "Train loss and acc of batch 48: 48.013153076171875, 1.0\n",
      "Train loss and acc of batch 49: 48.013145446777344, 1.0\n",
      "Train loss and acc of batch 50: 48.60884094238281, 0.984375\n",
      "Train loss and acc of batch 51: 49.36205291748047, 0.96875\n",
      "Train loss and acc of batch 52: 49.268959045410156, 0.953125\n",
      "Train loss and acc of batch 53: 48.01311492919922, 1.0\n",
      "Train loss and acc of batch 54: 48.22986602783203, 0.984375\n",
      "Train loss and acc of batch 55: 48.01309585571289, 1.0\n",
      "Train loss and acc of batch 56: 48.01307678222656, 1.0\n",
      "Train loss and acc of batch 57: 48.60877227783203, 0.984375\n",
      "Train loss and acc of batch 58: 48.01306915283203, 1.0\n",
      "Train loss and acc of batch 59: 48.01305389404297, 1.0\n",
      "Train loss and acc of batch 60: 48.0130500793457, 1.0\n",
      "Train loss and acc of batch 61: 48.013038635253906, 1.0\n",
      "Train loss and acc of batch 62: 48.22978973388672, 0.984375\n",
      "Train loss and acc of batch 63: 49.20441818237305, 0.96875\n",
      "Train loss and acc of batch 64: 48.22978210449219, 0.984375\n",
      "Train loss and acc of batch 65: 48.01300048828125, 1.0\n",
      "Train loss and acc of batch 66: 48.012996673583984, 1.0\n",
      "Train loss and acc of batch 67: 48.8254508972168, 0.96875\n",
      "Train loss and acc of batch 68: 48.608673095703125, 0.984375\n",
      "Train loss and acc of batch 69: 48.229736328125, 0.984375\n",
      "Train loss and acc of batch 70: 48.0129508972168, 1.0\n",
      "Training accuracy and loss of epoch #72: 0.9890, 48.3443\n",
      "Saved model by train loss 48.34428561573297\n",
      "Train loss and acc of batch 0: 48.01294708251953, 1.0\n",
      "Train loss and acc of batch 1: 48.012943267822266, 1.0\n",
      "Train loss and acc of batch 2: 48.29878234863281, 0.984375\n",
      "Train loss and acc of batch 3: 48.22969055175781, 0.984375\n",
      "Train loss and acc of batch 4: 48.01291275024414, 1.0\n",
      "Train loss and acc of batch 5: 49.36183166503906, 0.96875\n",
      "Train loss and acc of batch 6: 48.5155143737793, 0.96875\n",
      "Train loss and acc of batch 7: 48.01288604736328, 1.0\n",
      "Train loss and acc of batch 8: 48.60858154296875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 9: 48.29872131347656, 0.984375\n",
      "Train loss and acc of batch 10: 48.01286315917969, 1.0\n",
      "Train loss and acc of batch 11: 48.01285171508789, 1.0\n",
      "Train loss and acc of batch 12: 48.76606750488281, 0.984375\n",
      "Train loss and acc of batch 13: 48.229591369628906, 0.984375\n",
      "Train loss and acc of batch 14: 48.229583740234375, 0.984375\n",
      "Train loss and acc of batch 15: 48.6085205078125, 0.984375\n",
      "Train loss and acc of batch 16: 48.60850524902344, 0.984375\n",
      "Train loss and acc of batch 17: 48.766021728515625, 0.984375\n",
      "Train loss and acc of batch 18: 48.894344329833984, 0.96875\n",
      "Train loss and acc of batch 19: 48.01277542114258, 1.0\n",
      "Train loss and acc of batch 20: 48.01277160644531, 1.0\n",
      "Train loss and acc of batch 21: 48.60846710205078, 0.984375\n",
      "Train loss and acc of batch 22: 48.60845184326172, 0.984375\n",
      "Train loss and acc of batch 23: 48.22950744628906, 0.984375\n",
      "Train loss and acc of batch 24: 48.608436584472656, 0.984375\n",
      "Train loss and acc of batch 25: 48.012725830078125, 1.0\n",
      "Train loss and acc of batch 26: 48.01272201538086, 1.0\n",
      "Train loss and acc of batch 27: 48.0127067565918, 1.0\n",
      "Train loss and acc of batch 28: 48.0126953125, 1.0\n",
      "Train loss and acc of batch 29: 48.60839080810547, 0.984375\n",
      "Train loss and acc of batch 30: 48.01267623901367, 1.0\n",
      "Train loss and acc of batch 31: 48.22943878173828, 0.984375\n",
      "Train loss and acc of batch 32: 48.012664794921875, 1.0\n",
      "Train loss and acc of batch 33: 48.01265335083008, 1.0\n",
      "Train loss and acc of batch 34: 48.60835266113281, 0.984375\n",
      "Train loss and acc of batch 35: 48.4461669921875, 0.96875\n",
      "Train loss and acc of batch 36: 48.01262283325195, 1.0\n",
      "Train loss and acc of batch 37: 48.76584243774414, 0.984375\n",
      "Train loss and acc of batch 38: 49.361534118652344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2293701171875, 0.984375\n",
      "Train loss and acc of batch 40: 48.012596130371094, 1.0\n",
      "Train loss and acc of batch 41: 49.36151123046875, 0.96875\n",
      "Train loss and acc of batch 42: 48.012569427490234, 1.0\n",
      "Train loss and acc of batch 43: 48.60826873779297, 0.984375\n",
      "Train loss and acc of batch 44: 48.01255416870117, 1.0\n",
      "Train loss and acc of batch 45: 48.608245849609375, 0.984375\n",
      "Train loss and acc of batch 46: 48.29838562011719, 0.984375\n",
      "Train loss and acc of batch 47: 48.01252746582031, 1.0\n",
      "Train loss and acc of batch 48: 48.01251983642578, 1.0\n",
      "Train loss and acc of batch 49: 48.01251220703125, 1.0\n",
      "Train loss and acc of batch 50: 48.60820007324219, 0.984375\n",
      "Train loss and acc of batch 51: 49.361419677734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2683219909668, 0.953125\n",
      "Train loss and acc of batch 53: 48.01247787475586, 1.0\n",
      "Train loss and acc of batch 54: 48.229225158691406, 0.984375\n",
      "Train loss and acc of batch 55: 48.012454986572266, 1.0\n",
      "Train loss and acc of batch 56: 48.012447357177734, 1.0\n",
      "Train loss and acc of batch 57: 48.60813903808594, 0.984375\n",
      "Train loss and acc of batch 58: 48.012428283691406, 1.0\n",
      "Train loss and acc of batch 59: 48.012420654296875, 1.0\n",
      "Train loss and acc of batch 60: 48.012413024902344, 1.0\n",
      "Train loss and acc of batch 61: 48.01240158081055, 1.0\n",
      "Train loss and acc of batch 62: 48.229164123535156, 0.984375\n",
      "Train loss and acc of batch 63: 49.20378875732422, 0.96875\n",
      "Train loss and acc of batch 64: 48.22914123535156, 0.984375\n",
      "Train loss and acc of batch 65: 48.012367248535156, 1.0\n",
      "Train loss and acc of batch 66: 48.01235580444336, 1.0\n",
      "Train loss and acc of batch 67: 48.8248176574707, 0.96875\n",
      "Train loss and acc of batch 68: 48.60804748535156, 0.984375\n",
      "Train loss and acc of batch 69: 48.229095458984375, 0.984375\n",
      "Train loss and acc of batch 70: 48.012325286865234, 1.0\n",
      "Training accuracy and loss of epoch #73: 0.9890, 48.3437\n",
      "Saved model by train loss 48.343651784977446\n",
      "Train loss and acc of batch 0: 48.01231384277344, 1.0\n",
      "Train loss and acc of batch 1: 48.012306213378906, 1.0\n",
      "Train loss and acc of batch 2: 48.29814910888672, 0.984375\n",
      "Train loss and acc of batch 3: 48.22904968261719, 0.984375\n",
      "Train loss and acc of batch 4: 48.01227569580078, 1.0\n",
      "Train loss and acc of batch 5: 49.36119842529297, 0.96875\n",
      "Train loss and acc of batch 6: 48.51487731933594, 0.96875\n",
      "Train loss and acc of batch 7: 48.01225280761719, 1.0\n",
      "Train loss and acc of batch 8: 48.607940673828125, 0.984375\n",
      "Train loss and acc of batch 9: 48.29808807373047, 0.984375\n",
      "Train loss and acc of batch 10: 48.01222610473633, 1.0\n",
      "Train loss and acc of batch 11: 48.01221466064453, 1.0\n",
      "Train loss and acc of batch 12: 48.76542663574219, 0.984375\n",
      "Train loss and acc of batch 13: 48.228965759277344, 0.984375\n",
      "Train loss and acc of batch 14: 48.22895050048828, 0.984375\n",
      "Train loss and acc of batch 15: 48.607879638671875, 0.984375\n",
      "Train loss and acc of batch 16: 48.607872009277344, 0.984375\n",
      "Train loss and acc of batch 17: 48.765384674072266, 0.984375\n",
      "Train loss and acc of batch 18: 48.893707275390625, 0.96875\n",
      "Train loss and acc of batch 19: 48.012149810791016, 1.0\n",
      "Train loss and acc of batch 20: 48.01213455200195, 1.0\n",
      "Train loss and acc of batch 21: 48.607826232910156, 0.984375\n",
      "Train loss and acc of batch 22: 48.607818603515625, 0.984375\n",
      "Train loss and acc of batch 23: 48.22886657714844, 0.984375\n",
      "Train loss and acc of batch 24: 48.60780334472656, 0.984375\n",
      "Train loss and acc of batch 25: 48.012088775634766, 1.0\n",
      "Train loss and acc of batch 26: 48.012081146240234, 1.0\n",
      "Train loss and acc of batch 27: 48.0120735168457, 1.0\n",
      "Train loss and acc of batch 28: 48.01206588745117, 1.0\n",
      "Train loss and acc of batch 29: 48.607757568359375, 0.984375\n",
      "Train loss and acc of batch 30: 48.012046813964844, 1.0\n",
      "Train loss and acc of batch 31: 48.228797912597656, 0.984375\n",
      "Train loss and acc of batch 32: 48.012027740478516, 1.0\n",
      "Train loss and acc of batch 33: 48.01202392578125, 1.0\n",
      "Train loss and acc of batch 34: 48.60771179199219, 0.984375\n",
      "Train loss and acc of batch 35: 48.44552993774414, 0.96875\n",
      "Train loss and acc of batch 36: 48.011993408203125, 1.0\n",
      "Train loss and acc of batch 37: 48.765201568603516, 0.984375\n",
      "Train loss and acc of batch 38: 49.36090087890625, 0.96875\n",
      "Train loss and acc of batch 39: 48.228729248046875, 0.984375\n",
      "Train loss and acc of batch 40: 48.01195526123047, 1.0\n",
      "Train loss and acc of batch 41: 49.36087417602539, 0.96875\n",
      "Train loss and acc of batch 42: 48.011940002441406, 1.0\n",
      "Train loss and acc of batch 43: 48.607627868652344, 0.984375\n",
      "Train loss and acc of batch 44: 48.01192092895508, 1.0\n",
      "Train loss and acc of batch 45: 48.60761260986328, 0.984375\n",
      "Train loss and acc of batch 46: 48.297760009765625, 0.984375\n",
      "Train loss and acc of batch 47: 48.011898040771484, 1.0\n",
      "Train loss and acc of batch 48: 48.01188659667969, 1.0\n",
      "Train loss and acc of batch 49: 48.01187515258789, 1.0\n",
      "Train loss and acc of batch 50: 48.607566833496094, 0.984375\n",
      "Train loss and acc of batch 51: 49.36077880859375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2676887512207, 0.953125\n",
      "Train loss and acc of batch 53: 48.011837005615234, 1.0\n",
      "Train loss and acc of batch 54: 48.22859191894531, 0.984375\n",
      "Train loss and acc of batch 55: 48.01182556152344, 1.0\n",
      "Train loss and acc of batch 56: 48.01181411743164, 1.0\n",
      "Train loss and acc of batch 57: 48.607505798339844, 0.984375\n",
      "Train loss and acc of batch 58: 48.01179504394531, 1.0\n",
      "Train loss and acc of batch 59: 48.011783599853516, 1.0\n",
      "Train loss and acc of batch 60: 48.011775970458984, 1.0\n",
      "Train loss and acc of batch 61: 48.01176834106445, 1.0\n",
      "Train loss and acc of batch 62: 48.22852325439453, 0.984375\n",
      "Train loss and acc of batch 63: 49.203155517578125, 0.96875\n",
      "Train loss and acc of batch 64: 48.22850036621094, 0.984375\n",
      "Train loss and acc of batch 65: 48.01173400878906, 1.0\n",
      "Train loss and acc of batch 66: 48.011722564697266, 1.0\n",
      "Train loss and acc of batch 67: 48.82417678833008, 0.96875\n",
      "Train loss and acc of batch 68: 48.60740661621094, 0.984375\n",
      "Train loss and acc of batch 69: 48.22846221923828, 0.984375\n",
      "Train loss and acc of batch 70: 48.011688232421875, 1.0\n",
      "Training accuracy and loss of epoch #74: 0.9890, 48.3430\n",
      "Saved model by train loss 48.343016342378\n",
      "Train loss and acc of batch 0: 48.01167678833008, 1.0\n",
      "Train loss and acc of batch 1: 48.01166915893555, 1.0\n",
      "Train loss and acc of batch 2: 48.297508239746094, 0.984375\n",
      "Train loss and acc of batch 3: 48.228416442871094, 0.984375\n",
      "Train loss and acc of batch 4: 48.01164627075195, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 5: 49.360557556152344, 0.96875\n",
      "Train loss and acc of batch 6: 48.514244079589844, 0.96875\n",
      "Train loss and acc of batch 7: 48.01161575317383, 1.0\n",
      "Train loss and acc of batch 8: 48.60730743408203, 0.984375\n",
      "Train loss and acc of batch 9: 48.297454833984375, 0.984375\n",
      "Train loss and acc of batch 10: 48.0115852355957, 1.0\n",
      "Train loss and acc of batch 11: 48.01158142089844, 1.0\n",
      "Train loss and acc of batch 12: 48.76479721069336, 0.984375\n",
      "Train loss and acc of batch 13: 48.22832489013672, 0.984375\n",
      "Train loss and acc of batch 14: 48.22832489013672, 0.984375\n",
      "Train loss and acc of batch 15: 48.60724639892578, 0.984375\n",
      "Train loss and acc of batch 16: 48.60723114013672, 0.984375\n",
      "Train loss and acc of batch 17: 48.76475143432617, 0.984375\n",
      "Train loss and acc of batch 18: 48.893070220947266, 0.96875\n",
      "Train loss and acc of batch 19: 48.011512756347656, 1.0\n",
      "Train loss and acc of batch 20: 48.01150131225586, 1.0\n",
      "Train loss and acc of batch 21: 48.60719299316406, 0.984375\n",
      "Train loss and acc of batch 22: 48.60718536376953, 0.984375\n",
      "Train loss and acc of batch 23: 48.228233337402344, 0.984375\n",
      "Train loss and acc of batch 24: 48.60716247558594, 0.984375\n",
      "Train loss and acc of batch 25: 48.01145553588867, 1.0\n",
      "Train loss and acc of batch 26: 48.01144790649414, 1.0\n",
      "Train loss and acc of batch 27: 48.011436462402344, 1.0\n",
      "Train loss and acc of batch 28: 48.01142501831055, 1.0\n",
      "Train loss and acc of batch 29: 48.60711669921875, 0.984375\n",
      "Train loss and acc of batch 30: 48.011409759521484, 1.0\n",
      "Train loss and acc of batch 31: 48.22816467285156, 0.984375\n",
      "Train loss and acc of batch 32: 48.011390686035156, 1.0\n",
      "Train loss and acc of batch 33: 48.011383056640625, 1.0\n",
      "Train loss and acc of batch 34: 48.607078552246094, 0.984375\n",
      "Train loss and acc of batch 35: 48.44489288330078, 0.96875\n",
      "Train loss and acc of batch 36: 48.011356353759766, 1.0\n",
      "Train loss and acc of batch 37: 48.76456832885742, 0.984375\n",
      "Train loss and acc of batch 38: 49.360260009765625, 0.96875\n",
      "Train loss and acc of batch 39: 48.22808837890625, 0.984375\n",
      "Train loss and acc of batch 40: 48.011322021484375, 1.0\n",
      "Train loss and acc of batch 41: 49.36023712158203, 0.96875\n",
      "Train loss and acc of batch 42: 48.01130676269531, 1.0\n",
      "Train loss and acc of batch 43: 48.60700225830078, 0.984375\n",
      "Train loss and acc of batch 44: 48.01128387451172, 1.0\n",
      "Train loss and acc of batch 45: 48.60697937011719, 0.984375\n",
      "Train loss and acc of batch 46: 48.297119140625, 0.984375\n",
      "Train loss and acc of batch 47: 48.01125717163086, 1.0\n",
      "Train loss and acc of batch 48: 48.01124954223633, 1.0\n",
      "Train loss and acc of batch 49: 48.01123809814453, 1.0\n",
      "Train loss and acc of batch 50: 48.60693359375, 0.984375\n",
      "Train loss and acc of batch 51: 49.360145568847656, 0.96875\n",
      "Train loss and acc of batch 52: 49.267051696777344, 0.953125\n",
      "Train loss and acc of batch 53: 48.01120376586914, 1.0\n",
      "Train loss and acc of batch 54: 48.22795867919922, 0.984375\n",
      "Train loss and acc of batch 55: 48.01118469238281, 1.0\n",
      "Train loss and acc of batch 56: 48.01117706298828, 1.0\n",
      "Train loss and acc of batch 57: 48.60687255859375, 0.984375\n",
      "Train loss and acc of batch 58: 48.01115798950195, 1.0\n",
      "Train loss and acc of batch 59: 48.01115036010742, 1.0\n",
      "Train loss and acc of batch 60: 48.01113510131836, 1.0\n",
      "Train loss and acc of batch 61: 48.011131286621094, 1.0\n",
      "Train loss and acc of batch 62: 48.22789001464844, 0.984375\n",
      "Train loss and acc of batch 63: 49.202518463134766, 0.96875\n",
      "Train loss and acc of batch 64: 48.227874755859375, 0.984375\n",
      "Train loss and acc of batch 65: 48.0110969543457, 1.0\n",
      "Train loss and acc of batch 66: 48.011085510253906, 1.0\n",
      "Train loss and acc of batch 67: 48.82354736328125, 0.96875\n",
      "Train loss and acc of batch 68: 48.606773376464844, 0.984375\n",
      "Train loss and acc of batch 69: 48.22782897949219, 0.984375\n",
      "Train loss and acc of batch 70: 48.01105499267578, 1.0\n",
      "Training accuracy and loss of epoch #75: 0.9890, 48.3424\n",
      "Saved model by train loss 48.342380846050425\n",
      "Train loss and acc of batch 0: 48.01104736328125, 1.0\n",
      "Train loss and acc of batch 1: 48.01103591918945, 1.0\n",
      "Train loss and acc of batch 2: 48.29688262939453, 0.984375\n",
      "Train loss and acc of batch 3: 48.22777557373047, 0.984375\n",
      "Train loss and acc of batch 4: 48.011009216308594, 1.0\n",
      "Train loss and acc of batch 5: 49.35992431640625, 0.96875\n",
      "Train loss and acc of batch 6: 48.513607025146484, 0.96875\n",
      "Train loss and acc of batch 7: 48.010986328125, 1.0\n",
      "Train loss and acc of batch 8: 48.60667419433594, 0.984375\n",
      "Train loss and acc of batch 9: 48.29680633544922, 0.984375\n",
      "Train loss and acc of batch 10: 48.01095199584961, 1.0\n",
      "Train loss and acc of batch 11: 48.01094436645508, 1.0\n",
      "Train loss and acc of batch 12: 48.764156341552734, 0.984375\n",
      "Train loss and acc of batch 13: 48.227691650390625, 0.984375\n",
      "Train loss and acc of batch 14: 48.22767639160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.60661315917969, 0.984375\n",
      "Train loss and acc of batch 16: 48.606597900390625, 0.984375\n",
      "Train loss and acc of batch 17: 48.76410675048828, 0.984375\n",
      "Train loss and acc of batch 18: 48.892433166503906, 0.96875\n",
      "Train loss and acc of batch 19: 48.01087188720703, 1.0\n",
      "Train loss and acc of batch 20: 48.010860443115234, 1.0\n",
      "Train loss and acc of batch 21: 48.60655975341797, 0.984375\n",
      "Train loss and acc of batch 22: 48.606544494628906, 0.984375\n",
      "Train loss and acc of batch 23: 48.22760009765625, 0.984375\n",
      "Train loss and acc of batch 24: 48.60652160644531, 0.984375\n",
      "Train loss and acc of batch 25: 48.01082229614258, 1.0\n",
      "Train loss and acc of batch 26: 48.01081085205078, 1.0\n",
      "Train loss and acc of batch 27: 48.01080322265625, 1.0\n",
      "Train loss and acc of batch 28: 48.01078796386719, 1.0\n",
      "Train loss and acc of batch 29: 48.606483459472656, 0.984375\n",
      "Train loss and acc of batch 30: 48.01077651977539, 1.0\n",
      "Train loss and acc of batch 31: 48.22752380371094, 0.984375\n",
      "Train loss and acc of batch 32: 48.0107536315918, 1.0\n",
      "Train loss and acc of batch 33: 48.01074981689453, 1.0\n",
      "Train loss and acc of batch 34: 48.60643768310547, 0.984375\n",
      "Train loss and acc of batch 35: 48.44426345825195, 0.96875\n",
      "Train loss and acc of batch 36: 48.010719299316406, 1.0\n",
      "Train loss and acc of batch 37: 48.76393127441406, 0.984375\n",
      "Train loss and acc of batch 38: 49.35962677001953, 0.96875\n",
      "Train loss and acc of batch 39: 48.227455139160156, 0.984375\n",
      "Train loss and acc of batch 40: 48.01068115234375, 1.0\n",
      "Train loss and acc of batch 41: 49.35960006713867, 0.96875\n",
      "Train loss and acc of batch 42: 48.01066589355469, 1.0\n",
      "Train loss and acc of batch 43: 48.606361389160156, 0.984375\n",
      "Train loss and acc of batch 44: 48.010650634765625, 1.0\n",
      "Train loss and acc of batch 45: 48.60633850097656, 0.984375\n",
      "Train loss and acc of batch 46: 48.296485900878906, 0.984375\n",
      "Train loss and acc of batch 47: 48.010623931884766, 1.0\n",
      "Train loss and acc of batch 48: 48.01061248779297, 1.0\n",
      "Train loss and acc of batch 49: 48.01060104370117, 1.0\n",
      "Train loss and acc of batch 50: 48.606292724609375, 0.984375\n",
      "Train loss and acc of batch 51: 49.35950469970703, 0.96875\n",
      "Train loss and acc of batch 52: 49.266414642333984, 0.953125\n",
      "Train loss and acc of batch 53: 48.010562896728516, 1.0\n",
      "Train loss and acc of batch 54: 48.227317810058594, 0.984375\n",
      "Train loss and acc of batch 55: 48.01055145263672, 1.0\n",
      "Train loss and acc of batch 56: 48.01054382324219, 1.0\n",
      "Train loss and acc of batch 57: 48.606231689453125, 0.984375\n",
      "Train loss and acc of batch 58: 48.010528564453125, 1.0\n",
      "Train loss and acc of batch 59: 48.0105094909668, 1.0\n",
      "Train loss and acc of batch 60: 48.01050567626953, 1.0\n",
      "Train loss and acc of batch 61: 48.010494232177734, 1.0\n",
      "Train loss and acc of batch 62: 48.22724914550781, 0.984375\n",
      "Train loss and acc of batch 63: 49.20188522338867, 0.96875\n",
      "Train loss and acc of batch 64: 48.22723388671875, 0.984375\n",
      "Train loss and acc of batch 65: 48.010459899902344, 1.0\n",
      "Train loss and acc of batch 66: 48.01045608520508, 1.0\n",
      "Train loss and acc of batch 67: 48.822906494140625, 0.96875\n",
      "Train loss and acc of batch 68: 48.60613250732422, 0.984375\n",
      "Train loss and acc of batch 69: 48.22718811035156, 0.984375\n",
      "Train loss and acc of batch 70: 48.01041030883789, 1.0\n",
      "Training accuracy and loss of epoch #76: 0.9890, 48.3417\n",
      "Saved model by train loss 48.34174400651958\n",
      "Train loss and acc of batch 0: 48.010406494140625, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 1: 48.01040267944336, 1.0\n",
      "Train loss and acc of batch 2: 48.296241760253906, 0.984375\n",
      "Train loss and acc of batch 3: 48.227142333984375, 0.984375\n",
      "Train loss and acc of batch 4: 48.010372161865234, 1.0\n",
      "Train loss and acc of batch 5: 49.359283447265625, 0.96875\n",
      "Train loss and acc of batch 6: 48.51297378540039, 0.96875\n",
      "Train loss and acc of batch 7: 48.01034927368164, 1.0\n",
      "Train loss and acc of batch 8: 48.60603332519531, 0.984375\n",
      "Train loss and acc of batch 9: 48.296180725097656, 0.984375\n",
      "Train loss and acc of batch 10: 48.010311126708984, 1.0\n",
      "Train loss and acc of batch 11: 48.01030349731445, 1.0\n",
      "Train loss and acc of batch 12: 48.76352310180664, 0.984375\n",
      "Train loss and acc of batch 13: 48.22705841064453, 0.984375\n",
      "Train loss and acc of batch 14: 48.22705078125, 0.984375\n",
      "Train loss and acc of batch 15: 48.60597229003906, 0.984375\n",
      "Train loss and acc of batch 16: 48.60596466064453, 0.984375\n",
      "Train loss and acc of batch 17: 48.76347732543945, 0.984375\n",
      "Train loss and acc of batch 18: 48.89180374145508, 0.96875\n",
      "Train loss and acc of batch 19: 48.01023483276367, 1.0\n",
      "Train loss and acc of batch 20: 48.01022720336914, 1.0\n",
      "Train loss and acc of batch 21: 48.605918884277344, 0.984375\n",
      "Train loss and acc of batch 22: 48.60591125488281, 0.984375\n",
      "Train loss and acc of batch 23: 48.226966857910156, 0.984375\n",
      "Train loss and acc of batch 24: 48.60589599609375, 0.984375\n",
      "Train loss and acc of batch 25: 48.01018142700195, 1.0\n",
      "Train loss and acc of batch 26: 48.01017379760742, 1.0\n",
      "Train loss and acc of batch 27: 48.010162353515625, 1.0\n",
      "Train loss and acc of batch 28: 48.01015853881836, 1.0\n",
      "Train loss and acc of batch 29: 48.60585021972656, 0.984375\n",
      "Train loss and acc of batch 30: 48.010135650634766, 1.0\n",
      "Train loss and acc of batch 31: 48.226898193359375, 0.984375\n",
      "Train loss and acc of batch 32: 48.01012420654297, 1.0\n",
      "Train loss and acc of batch 33: 48.01011276245117, 1.0\n",
      "Train loss and acc of batch 34: 48.605804443359375, 0.984375\n",
      "Train loss and acc of batch 35: 48.44362258911133, 0.96875\n",
      "Train loss and acc of batch 36: 48.01008224487305, 1.0\n",
      "Train loss and acc of batch 37: 48.763301849365234, 0.984375\n",
      "Train loss and acc of batch 38: 49.35899353027344, 0.96875\n",
      "Train loss and acc of batch 39: 48.22682189941406, 0.984375\n",
      "Train loss and acc of batch 40: 48.010047912597656, 1.0\n",
      "Train loss and acc of batch 41: 49.35896682739258, 0.96875\n",
      "Train loss and acc of batch 42: 48.01002883911133, 1.0\n",
      "Train loss and acc of batch 43: 48.60572814941406, 0.984375\n",
      "Train loss and acc of batch 44: 48.010009765625, 1.0\n",
      "Train loss and acc of batch 45: 48.60570526123047, 0.984375\n",
      "Train loss and acc of batch 46: 48.29584503173828, 0.984375\n",
      "Train loss and acc of batch 47: 48.00999069213867, 1.0\n",
      "Train loss and acc of batch 48: 48.009979248046875, 1.0\n",
      "Train loss and acc of batch 49: 48.00996780395508, 1.0\n",
      "Train loss and acc of batch 50: 48.60565948486328, 0.984375\n",
      "Train loss and acc of batch 51: 49.35887145996094, 0.96875\n",
      "Train loss and acc of batch 52: 49.265785217285156, 0.953125\n",
      "Train loss and acc of batch 53: 48.00992965698242, 1.0\n",
      "Train loss and acc of batch 54: 48.2266845703125, 0.984375\n",
      "Train loss and acc of batch 55: 48.009918212890625, 1.0\n",
      "Train loss and acc of batch 56: 48.00990676879883, 1.0\n",
      "Train loss and acc of batch 57: 48.6055908203125, 0.984375\n",
      "Train loss and acc of batch 58: 48.0098876953125, 1.0\n",
      "Train loss and acc of batch 59: 48.00988006591797, 1.0\n",
      "Train loss and acc of batch 60: 48.00987243652344, 1.0\n",
      "Train loss and acc of batch 61: 48.009864807128906, 1.0\n",
      "Train loss and acc of batch 62: 48.22661590576172, 0.984375\n",
      "Train loss and acc of batch 63: 49.20124435424805, 0.96875\n",
      "Train loss and acc of batch 64: 48.226600646972656, 0.984375\n",
      "Train loss and acc of batch 65: 48.00982666015625, 1.0\n",
      "Train loss and acc of batch 66: 48.00981521606445, 1.0\n",
      "Train loss and acc of batch 67: 48.82227325439453, 0.96875\n",
      "Train loss and acc of batch 68: 48.605499267578125, 0.984375\n",
      "Train loss and acc of batch 69: 48.22655487060547, 0.984375\n",
      "Train loss and acc of batch 70: 48.00978469848633, 1.0\n",
      "Training accuracy and loss of epoch #77: 0.9890, 48.3411\n",
      "Saved model by train loss 48.3411093698421\n",
      "Train loss and acc of batch 0: 48.009769439697266, 1.0\n",
      "Train loss and acc of batch 1: 48.009761810302734, 1.0\n",
      "Train loss and acc of batch 2: 48.29560852050781, 0.984375\n",
      "Train loss and acc of batch 3: 48.22650909423828, 0.984375\n",
      "Train loss and acc of batch 4: 48.00973892211914, 1.0\n",
      "Train loss and acc of batch 5: 49.35865783691406, 0.96875\n",
      "Train loss and acc of batch 6: 48.51233673095703, 0.96875\n",
      "Train loss and acc of batch 7: 48.00971221923828, 1.0\n",
      "Train loss and acc of batch 8: 48.60540008544922, 0.984375\n",
      "Train loss and acc of batch 9: 48.29553985595703, 0.984375\n",
      "Train loss and acc of batch 10: 48.009681701660156, 1.0\n",
      "Train loss and acc of batch 11: 48.009674072265625, 1.0\n",
      "Train loss and acc of batch 12: 48.76288986206055, 0.984375\n",
      "Train loss and acc of batch 13: 48.22642517089844, 0.984375\n",
      "Train loss and acc of batch 14: 48.226409912109375, 0.984375\n",
      "Train loss and acc of batch 15: 48.60533905029297, 0.984375\n",
      "Train loss and acc of batch 16: 48.60533142089844, 0.984375\n",
      "Train loss and acc of batch 17: 48.76284408569336, 0.984375\n",
      "Train loss and acc of batch 18: 48.89116668701172, 0.96875\n",
      "Train loss and acc of batch 19: 48.00960159301758, 1.0\n",
      "Train loss and acc of batch 20: 48.00959396362305, 1.0\n",
      "Train loss and acc of batch 21: 48.60528564453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.60527801513672, 0.984375\n",
      "Train loss and acc of batch 23: 48.22632598876953, 0.984375\n",
      "Train loss and acc of batch 24: 48.605255126953125, 0.984375\n",
      "Train loss and acc of batch 25: 48.009544372558594, 1.0\n",
      "Train loss and acc of batch 26: 48.009544372558594, 1.0\n",
      "Train loss and acc of batch 27: 48.0095329284668, 1.0\n",
      "Train loss and acc of batch 28: 48.009517669677734, 1.0\n",
      "Train loss and acc of batch 29: 48.60520935058594, 0.984375\n",
      "Train loss and acc of batch 30: 48.00950622558594, 1.0\n",
      "Train loss and acc of batch 31: 48.22625732421875, 0.984375\n",
      "Train loss and acc of batch 32: 48.00948715209961, 1.0\n",
      "Train loss and acc of batch 33: 48.00947189331055, 1.0\n",
      "Train loss and acc of batch 34: 48.60517120361328, 0.984375\n",
      "Train loss and acc of batch 35: 48.4429931640625, 0.96875\n",
      "Train loss and acc of batch 36: 48.00945281982422, 1.0\n",
      "Train loss and acc of batch 37: 48.76266098022461, 0.984375\n",
      "Train loss and acc of batch 38: 49.358360290527344, 0.96875\n",
      "Train loss and acc of batch 39: 48.22618865966797, 0.984375\n",
      "Train loss and acc of batch 40: 48.00941467285156, 1.0\n",
      "Train loss and acc of batch 41: 49.358333587646484, 0.96875\n",
      "Train loss and acc of batch 42: 48.009395599365234, 1.0\n",
      "Train loss and acc of batch 43: 48.60508728027344, 0.984375\n",
      "Train loss and acc of batch 44: 48.00938034057617, 1.0\n",
      "Train loss and acc of batch 45: 48.605072021484375, 0.984375\n",
      "Train loss and acc of batch 46: 48.29521179199219, 0.984375\n",
      "Train loss and acc of batch 47: 48.00935363769531, 1.0\n",
      "Train loss and acc of batch 48: 48.00934600830078, 1.0\n",
      "Train loss and acc of batch 49: 48.009334564208984, 1.0\n",
      "Train loss and acc of batch 50: 48.60502624511719, 0.984375\n",
      "Train loss and acc of batch 51: 49.358245849609375, 0.96875\n",
      "Train loss and acc of batch 52: 49.26514434814453, 0.953125\n",
      "Train loss and acc of batch 53: 48.009300231933594, 1.0\n",
      "Train loss and acc of batch 54: 48.226051330566406, 0.984375\n",
      "Train loss and acc of batch 55: 48.00928497314453, 1.0\n",
      "Train loss and acc of batch 56: 48.00926971435547, 1.0\n",
      "Train loss and acc of batch 57: 48.60496520996094, 0.984375\n",
      "Train loss and acc of batch 58: 48.00925064086914, 1.0\n",
      "Train loss and acc of batch 59: 48.009246826171875, 1.0\n",
      "Train loss and acc of batch 60: 48.00923538208008, 1.0\n",
      "Train loss and acc of batch 61: 48.00923156738281, 1.0\n",
      "Train loss and acc of batch 62: 48.225982666015625, 0.984375\n",
      "Train loss and acc of batch 63: 49.20061111450195, 0.96875\n",
      "Train loss and acc of batch 64: 48.22596740722656, 0.984375\n",
      "Train loss and acc of batch 65: 48.009193420410156, 1.0\n",
      "Train loss and acc of batch 66: 48.009178161621094, 1.0\n",
      "Train loss and acc of batch 67: 48.82164001464844, 0.96875\n",
      "Train loss and acc of batch 68: 48.60486602783203, 0.984375\n",
      "Train loss and acc of batch 69: 48.225921630859375, 0.984375\n",
      "Train loss and acc of batch 70: 48.0091438293457, 1.0\n",
      "Training accuracy and loss of epoch #78: 0.9890, 48.3405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.34047494807714\n",
      "Train loss and acc of batch 0: 48.00914001464844, 1.0\n",
      "Train loss and acc of batch 1: 48.00912857055664, 1.0\n",
      "Train loss and acc of batch 2: 48.29497528076172, 0.984375\n",
      "Train loss and acc of batch 3: 48.22587585449219, 0.984375\n",
      "Train loss and acc of batch 4: 48.00910186767578, 1.0\n",
      "Train loss and acc of batch 5: 49.35801696777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.51169967651367, 0.96875\n",
      "Train loss and acc of batch 7: 48.00907516479492, 1.0\n",
      "Train loss and acc of batch 8: 48.604759216308594, 0.984375\n",
      "Train loss and acc of batch 9: 48.29490661621094, 0.984375\n",
      "Train loss and acc of batch 10: 48.00904846191406, 1.0\n",
      "Train loss and acc of batch 11: 48.00904083251953, 1.0\n",
      "Train loss and acc of batch 12: 48.76225662231445, 0.984375\n",
      "Train loss and acc of batch 13: 48.22578430175781, 0.984375\n",
      "Train loss and acc of batch 14: 48.22577667236328, 0.984375\n",
      "Train loss and acc of batch 15: 48.604705810546875, 0.984375\n",
      "Train loss and acc of batch 16: 48.604698181152344, 0.984375\n",
      "Train loss and acc of batch 17: 48.762210845947266, 0.984375\n",
      "Train loss and acc of batch 18: 48.890525817871094, 0.96875\n",
      "Train loss and acc of batch 19: 48.00897216796875, 1.0\n",
      "Train loss and acc of batch 20: 48.00896072387695, 1.0\n",
      "Train loss and acc of batch 21: 48.60466003417969, 0.984375\n",
      "Train loss and acc of batch 22: 48.604644775390625, 0.984375\n",
      "Train loss and acc of batch 23: 48.22569274902344, 0.984375\n",
      "Train loss and acc of batch 24: 48.60462188720703, 0.984375\n",
      "Train loss and acc of batch 25: 48.008914947509766, 1.0\n",
      "Train loss and acc of batch 26: 48.00890350341797, 1.0\n",
      "Train loss and acc of batch 27: 48.00889587402344, 1.0\n",
      "Train loss and acc of batch 28: 48.008888244628906, 1.0\n",
      "Train loss and acc of batch 29: 48.604583740234375, 0.984375\n",
      "Train loss and acc of batch 30: 48.00886917114258, 1.0\n",
      "Train loss and acc of batch 31: 48.225624084472656, 0.984375\n",
      "Train loss and acc of batch 32: 48.00885009765625, 1.0\n",
      "Train loss and acc of batch 33: 48.008846282958984, 1.0\n",
      "Train loss and acc of batch 34: 48.60453796386719, 0.984375\n",
      "Train loss and acc of batch 35: 48.442359924316406, 0.96875\n",
      "Train loss and acc of batch 36: 48.00881576538086, 1.0\n",
      "Train loss and acc of batch 37: 48.762027740478516, 0.984375\n",
      "Train loss and acc of batch 38: 49.35771942138672, 0.96875\n",
      "Train loss and acc of batch 39: 48.225555419921875, 0.984375\n",
      "Train loss and acc of batch 40: 48.00878143310547, 1.0\n",
      "Train loss and acc of batch 41: 49.357696533203125, 0.96875\n",
      "Train loss and acc of batch 42: 48.008766174316406, 1.0\n",
      "Train loss and acc of batch 43: 48.604454040527344, 0.984375\n",
      "Train loss and acc of batch 44: 48.00874710083008, 1.0\n",
      "Train loss and acc of batch 45: 48.60443878173828, 0.984375\n",
      "Train loss and acc of batch 46: 48.294586181640625, 0.984375\n",
      "Train loss and acc of batch 47: 48.00871658325195, 1.0\n",
      "Train loss and acc of batch 48: 48.00871276855469, 1.0\n",
      "Train loss and acc of batch 49: 48.008697509765625, 1.0\n",
      "Train loss and acc of batch 50: 48.604393005371094, 0.984375\n",
      "Train loss and acc of batch 51: 49.35760498046875, 0.96875\n",
      "Train loss and acc of batch 52: 49.2645149230957, 0.953125\n",
      "Train loss and acc of batch 53: 48.008663177490234, 1.0\n",
      "Train loss and acc of batch 54: 48.22541809082031, 0.984375\n",
      "Train loss and acc of batch 55: 48.008644104003906, 1.0\n",
      "Train loss and acc of batch 56: 48.00864028930664, 1.0\n",
      "Train loss and acc of batch 57: 48.604331970214844, 0.984375\n",
      "Train loss and acc of batch 58: 48.00862503051758, 1.0\n",
      "Train loss and acc of batch 59: 48.008609771728516, 1.0\n",
      "Train loss and acc of batch 60: 48.00859832763672, 1.0\n",
      "Train loss and acc of batch 61: 48.00859069824219, 1.0\n",
      "Train loss and acc of batch 62: 48.22534942626953, 0.984375\n",
      "Train loss and acc of batch 63: 49.19997787475586, 0.96875\n",
      "Train loss and acc of batch 64: 48.22532653808594, 0.984375\n",
      "Train loss and acc of batch 65: 48.0085563659668, 1.0\n",
      "Train loss and acc of batch 66: 48.008544921875, 1.0\n",
      "Train loss and acc of batch 67: 48.821006774902344, 0.96875\n",
      "Train loss and acc of batch 68: 48.60423278808594, 0.984375\n",
      "Train loss and acc of batch 69: 48.22528839111328, 0.984375\n",
      "Train loss and acc of batch 70: 48.008514404296875, 1.0\n",
      "Training accuracy and loss of epoch #79: 0.9890, 48.3398\n",
      "Saved model by train loss 48.33984084868095\n",
      "Train loss and acc of batch 0: 48.008506774902344, 1.0\n",
      "Train loss and acc of batch 1: 48.00849914550781, 1.0\n",
      "Train loss and acc of batch 2: 48.294342041015625, 0.984375\n",
      "Train loss and acc of batch 3: 48.225242614746094, 0.984375\n",
      "Train loss and acc of batch 4: 48.00847244262695, 1.0\n",
      "Train loss and acc of batch 5: 49.357383728027344, 0.96875\n",
      "Train loss and acc of batch 6: 48.51106643676758, 0.96875\n",
      "Train loss and acc of batch 7: 48.00843811035156, 1.0\n",
      "Train loss and acc of batch 8: 48.60413360595703, 0.984375\n",
      "Train loss and acc of batch 9: 48.294273376464844, 0.984375\n",
      "Train loss and acc of batch 10: 48.00841522216797, 1.0\n",
      "Train loss and acc of batch 11: 48.00840377807617, 1.0\n",
      "Train loss and acc of batch 12: 48.761619567871094, 0.984375\n",
      "Train loss and acc of batch 13: 48.22515106201172, 0.984375\n",
      "Train loss and acc of batch 14: 48.22514343261719, 0.984375\n",
      "Train loss and acc of batch 15: 48.60407257080078, 0.984375\n",
      "Train loss and acc of batch 16: 48.60405731201172, 0.984375\n",
      "Train loss and acc of batch 17: 48.761573791503906, 0.984375\n",
      "Train loss and acc of batch 18: 48.889892578125, 0.96875\n",
      "Train loss and acc of batch 19: 48.008331298828125, 1.0\n",
      "Train loss and acc of batch 20: 48.008323669433594, 1.0\n",
      "Train loss and acc of batch 21: 48.60401916503906, 0.984375\n",
      "Train loss and acc of batch 22: 48.60400390625, 0.984375\n",
      "Train loss and acc of batch 23: 48.225059509277344, 0.984375\n",
      "Train loss and acc of batch 24: 48.60398864746094, 0.984375\n",
      "Train loss and acc of batch 25: 48.00828170776367, 1.0\n",
      "Train loss and acc of batch 26: 48.00827407836914, 1.0\n",
      "Train loss and acc of batch 27: 48.008262634277344, 1.0\n",
      "Train loss and acc of batch 28: 48.00825500488281, 1.0\n",
      "Train loss and acc of batch 29: 48.60395050048828, 0.984375\n",
      "Train loss and acc of batch 30: 48.008235931396484, 1.0\n",
      "Train loss and acc of batch 31: 48.22499084472656, 0.984375\n",
      "Train loss and acc of batch 32: 48.00821304321289, 1.0\n",
      "Train loss and acc of batch 33: 48.008209228515625, 1.0\n",
      "Train loss and acc of batch 34: 48.60389709472656, 0.984375\n",
      "Train loss and acc of batch 35: 48.44171905517578, 0.96875\n",
      "Train loss and acc of batch 36: 48.008182525634766, 1.0\n",
      "Train loss and acc of batch 37: 48.76140213012695, 0.984375\n",
      "Train loss and acc of batch 38: 49.357093811035156, 0.96875\n",
      "Train loss and acc of batch 39: 48.22491455078125, 0.984375\n",
      "Train loss and acc of batch 40: 48.00814437866211, 1.0\n",
      "Train loss and acc of batch 41: 49.35706329345703, 0.96875\n",
      "Train loss and acc of batch 42: 48.00812911987305, 1.0\n",
      "Train loss and acc of batch 43: 48.60382080078125, 0.984375\n",
      "Train loss and acc of batch 44: 48.00811004638672, 1.0\n",
      "Train loss and acc of batch 45: 48.60380554199219, 0.984375\n",
      "Train loss and acc of batch 46: 48.2939453125, 0.984375\n",
      "Train loss and acc of batch 47: 48.00808334350586, 1.0\n",
      "Train loss and acc of batch 48: 48.00807189941406, 1.0\n",
      "Train loss and acc of batch 49: 48.00806427001953, 1.0\n",
      "Train loss and acc of batch 50: 48.603759765625, 0.984375\n",
      "Train loss and acc of batch 51: 49.35697937011719, 0.96875\n",
      "Train loss and acc of batch 52: 49.26388168334961, 0.953125\n",
      "Train loss and acc of batch 53: 48.008026123046875, 1.0\n",
      "Train loss and acc of batch 54: 48.22478485107422, 0.984375\n",
      "Train loss and acc of batch 55: 48.00801086425781, 1.0\n",
      "Train loss and acc of batch 56: 48.00800323486328, 1.0\n",
      "Train loss and acc of batch 57: 48.60369873046875, 0.984375\n",
      "Train loss and acc of batch 58: 48.00798797607422, 1.0\n",
      "Train loss and acc of batch 59: 48.007972717285156, 1.0\n",
      "Train loss and acc of batch 60: 48.007965087890625, 1.0\n",
      "Train loss and acc of batch 61: 48.00796127319336, 1.0\n",
      "Train loss and acc of batch 62: 48.22471618652344, 0.984375\n",
      "Train loss and acc of batch 63: 49.1993408203125, 0.96875\n",
      "Train loss and acc of batch 64: 48.224700927734375, 0.984375\n",
      "Train loss and acc of batch 65: 48.00792694091797, 1.0\n",
      "Train loss and acc of batch 66: 48.00791931152344, 1.0\n",
      "Train loss and acc of batch 67: 48.820369720458984, 0.96875\n",
      "Train loss and acc of batch 68: 48.603599548339844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 48.22465515136719, 0.984375\n",
      "Train loss and acc of batch 70: 48.00788116455078, 1.0\n",
      "Training accuracy and loss of epoch #80: 0.9890, 48.3392\n",
      "Saved model by train loss 48.33920669555664\n",
      "Train loss and acc of batch 0: 48.00787353515625, 1.0\n",
      "Train loss and acc of batch 1: 48.00786209106445, 1.0\n",
      "Train loss and acc of batch 2: 48.293701171875, 0.984375\n",
      "Train loss and acc of batch 3: 48.224609375, 0.984375\n",
      "Train loss and acc of batch 4: 48.00783157348633, 1.0\n",
      "Train loss and acc of batch 5: 49.35675048828125, 0.96875\n",
      "Train loss and acc of batch 6: 48.510433197021484, 0.96875\n",
      "Train loss and acc of batch 7: 48.00780487060547, 1.0\n",
      "Train loss and acc of batch 8: 48.60350036621094, 0.984375\n",
      "Train loss and acc of batch 9: 48.29364776611328, 0.984375\n",
      "Train loss and acc of batch 10: 48.00777816772461, 1.0\n",
      "Train loss and acc of batch 11: 48.00777053833008, 1.0\n",
      "Train loss and acc of batch 12: 48.760986328125, 0.984375\n",
      "Train loss and acc of batch 13: 48.224517822265625, 0.984375\n",
      "Train loss and acc of batch 14: 48.224510192871094, 0.984375\n",
      "Train loss and acc of batch 15: 48.60343933105469, 0.984375\n",
      "Train loss and acc of batch 16: 48.603431701660156, 0.984375\n",
      "Train loss and acc of batch 17: 48.76094055175781, 0.984375\n",
      "Train loss and acc of batch 18: 48.889259338378906, 0.96875\n",
      "Train loss and acc of batch 19: 48.00769805908203, 1.0\n",
      "Train loss and acc of batch 20: 48.0076904296875, 1.0\n",
      "Train loss and acc of batch 21: 48.60337829589844, 0.984375\n",
      "Train loss and acc of batch 22: 48.60337829589844, 0.984375\n",
      "Train loss and acc of batch 23: 48.22443389892578, 0.984375\n",
      "Train loss and acc of batch 24: 48.603355407714844, 0.984375\n",
      "Train loss and acc of batch 25: 48.00764465332031, 1.0\n",
      "Train loss and acc of batch 26: 48.00763702392578, 1.0\n",
      "Train loss and acc of batch 27: 48.00762939453125, 1.0\n",
      "Train loss and acc of batch 28: 48.00762176513672, 1.0\n",
      "Train loss and acc of batch 29: 48.603309631347656, 0.984375\n",
      "Train loss and acc of batch 30: 48.007606506347656, 1.0\n",
      "Train loss and acc of batch 31: 48.22435760498047, 0.984375\n",
      "Train loss and acc of batch 32: 48.00758743286133, 1.0\n",
      "Train loss and acc of batch 33: 48.007572174072266, 1.0\n",
      "Train loss and acc of batch 34: 48.60326385498047, 0.984375\n",
      "Train loss and acc of batch 35: 48.44108581542969, 0.96875\n",
      "Train loss and acc of batch 36: 48.00754928588867, 1.0\n",
      "Train loss and acc of batch 37: 48.760765075683594, 0.984375\n",
      "Train loss and acc of batch 38: 49.35645294189453, 0.96875\n",
      "Train loss and acc of batch 39: 48.22428894042969, 0.984375\n",
      "Train loss and acc of batch 40: 48.007511138916016, 1.0\n",
      "Train loss and acc of batch 41: 49.35643005371094, 0.96875\n",
      "Train loss and acc of batch 42: 48.00748825073242, 1.0\n",
      "Train loss and acc of batch 43: 48.603187561035156, 0.984375\n",
      "Train loss and acc of batch 44: 48.007476806640625, 1.0\n",
      "Train loss and acc of batch 45: 48.603172302246094, 0.984375\n",
      "Train loss and acc of batch 46: 48.293304443359375, 0.984375\n",
      "Train loss and acc of batch 47: 48.007450103759766, 1.0\n",
      "Train loss and acc of batch 48: 48.00743865966797, 1.0\n",
      "Train loss and acc of batch 49: 48.00743103027344, 1.0\n",
      "Train loss and acc of batch 50: 48.603126525878906, 0.984375\n",
      "Train loss and acc of batch 51: 49.35633850097656, 0.96875\n",
      "Train loss and acc of batch 52: 49.26324462890625, 0.953125\n",
      "Train loss and acc of batch 53: 48.00740051269531, 1.0\n",
      "Train loss and acc of batch 54: 48.224143981933594, 0.984375\n",
      "Train loss and acc of batch 55: 48.007381439208984, 1.0\n",
      "Train loss and acc of batch 56: 48.00736999511719, 1.0\n",
      "Train loss and acc of batch 57: 48.603057861328125, 0.984375\n",
      "Train loss and acc of batch 58: 48.007354736328125, 1.0\n",
      "Train loss and acc of batch 59: 48.00734329223633, 1.0\n",
      "Train loss and acc of batch 60: 48.00733184814453, 1.0\n",
      "Train loss and acc of batch 61: 48.00732421875, 1.0\n",
      "Train loss and acc of batch 62: 48.22407531738281, 0.984375\n",
      "Train loss and acc of batch 63: 49.198707580566406, 0.96875\n",
      "Train loss and acc of batch 64: 48.22406005859375, 0.984375\n",
      "Train loss and acc of batch 65: 48.007293701171875, 1.0\n",
      "Train loss and acc of batch 66: 48.00727844238281, 1.0\n",
      "Train loss and acc of batch 67: 48.819740295410156, 0.96875\n",
      "Train loss and acc of batch 68: 48.60296630859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.224021911621094, 0.984375\n",
      "Train loss and acc of batch 70: 48.00724411010742, 1.0\n",
      "Training accuracy and loss of epoch #81: 0.9890, 48.3386\n",
      "Saved model by train loss 48.33857254243233\n",
      "Train loss and acc of batch 0: 48.007232666015625, 1.0\n",
      "Train loss and acc of batch 1: 48.007225036621094, 1.0\n",
      "Train loss and acc of batch 2: 48.29307556152344, 0.984375\n",
      "Train loss and acc of batch 3: 48.223976135253906, 0.984375\n",
      "Train loss and acc of batch 4: 48.007198333740234, 1.0\n",
      "Train loss and acc of batch 5: 49.356117248535156, 0.96875\n",
      "Train loss and acc of batch 6: 48.509796142578125, 0.96875\n",
      "Train loss and acc of batch 7: 48.00717544555664, 1.0\n",
      "Train loss and acc of batch 8: 48.60285949707031, 0.984375\n",
      "Train loss and acc of batch 9: 48.293006896972656, 0.984375\n",
      "Train loss and acc of batch 10: 48.00714874267578, 1.0\n",
      "Train loss and acc of batch 11: 48.007137298583984, 1.0\n",
      "Train loss and acc of batch 12: 48.760353088378906, 0.984375\n",
      "Train loss and acc of batch 13: 48.223876953125, 0.984375\n",
      "Train loss and acc of batch 14: 48.223876953125, 0.984375\n",
      "Train loss and acc of batch 15: 48.602806091308594, 0.984375\n",
      "Train loss and acc of batch 16: 48.60279846191406, 0.984375\n",
      "Train loss and acc of batch 17: 48.76030731201172, 0.984375\n",
      "Train loss and acc of batch 18: 48.88862609863281, 0.96875\n",
      "Train loss and acc of batch 19: 48.0070686340332, 1.0\n",
      "Train loss and acc of batch 20: 48.00705337524414, 1.0\n",
      "Train loss and acc of batch 21: 48.602752685546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.60273742675781, 0.984375\n",
      "Train loss and acc of batch 23: 48.223793029785156, 0.984375\n",
      "Train loss and acc of batch 24: 48.60272216796875, 0.984375\n",
      "Train loss and acc of batch 25: 48.007015228271484, 1.0\n",
      "Train loss and acc of batch 26: 48.00700378417969, 1.0\n",
      "Train loss and acc of batch 27: 48.00699234008789, 1.0\n",
      "Train loss and acc of batch 28: 48.00698471069336, 1.0\n",
      "Train loss and acc of batch 29: 48.60267639160156, 0.984375\n",
      "Train loss and acc of batch 30: 48.00696563720703, 1.0\n",
      "Train loss and acc of batch 31: 48.223724365234375, 0.984375\n",
      "Train loss and acc of batch 32: 48.00695037841797, 1.0\n",
      "Train loss and acc of batch 33: 48.00694274902344, 1.0\n",
      "Train loss and acc of batch 34: 48.602630615234375, 0.984375\n",
      "Train loss and acc of batch 35: 48.440452575683594, 0.96875\n",
      "Train loss and acc of batch 36: 48.00691223144531, 1.0\n",
      "Train loss and acc of batch 37: 48.760128021240234, 0.984375\n",
      "Train loss and acc of batch 38: 49.35581970214844, 0.96875\n",
      "Train loss and acc of batch 39: 48.22364807128906, 0.984375\n",
      "Train loss and acc of batch 40: 48.00688171386719, 1.0\n",
      "Train loss and acc of batch 41: 49.35578918457031, 0.96875\n",
      "Train loss and acc of batch 42: 48.00686264038086, 1.0\n",
      "Train loss and acc of batch 43: 48.60254669189453, 0.984375\n",
      "Train loss and acc of batch 44: 48.0068473815918, 1.0\n",
      "Train loss and acc of batch 45: 48.60253143310547, 0.984375\n",
      "Train loss and acc of batch 46: 48.29267883300781, 0.984375\n",
      "Train loss and acc of batch 47: 48.00681686401367, 1.0\n",
      "Train loss and acc of batch 48: 48.006805419921875, 1.0\n",
      "Train loss and acc of batch 49: 48.006797790527344, 1.0\n",
      "Train loss and acc of batch 50: 48.60248565673828, 0.984375\n",
      "Train loss and acc of batch 51: 49.35570526123047, 0.96875\n",
      "Train loss and acc of batch 52: 49.262611389160156, 0.953125\n",
      "Train loss and acc of batch 53: 48.00676345825195, 1.0\n",
      "Train loss and acc of batch 54: 48.22351837158203, 0.984375\n",
      "Train loss and acc of batch 55: 48.006744384765625, 1.0\n",
      "Train loss and acc of batch 56: 48.00673294067383, 1.0\n",
      "Train loss and acc of batch 57: 48.60242462158203, 0.984375\n",
      "Train loss and acc of batch 58: 48.006717681884766, 1.0\n",
      "Train loss and acc of batch 59: 48.00670623779297, 1.0\n",
      "Train loss and acc of batch 60: 48.00669860839844, 1.0\n",
      "Train loss and acc of batch 61: 48.006690979003906, 1.0\n",
      "Train loss and acc of batch 62: 48.22344207763672, 0.984375\n",
      "Train loss and acc of batch 63: 49.19807434082031, 0.96875\n",
      "Train loss and acc of batch 64: 48.223426818847656, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 48.006656646728516, 1.0\n",
      "Train loss and acc of batch 66: 48.00664520263672, 1.0\n",
      "Train loss and acc of batch 67: 48.8191032409668, 0.96875\n",
      "Train loss and acc of batch 68: 48.602333068847656, 0.984375\n",
      "Train loss and acc of batch 69: 48.22338104248047, 0.984375\n",
      "Train loss and acc of batch 70: 48.0066032409668, 1.0\n",
      "Training accuracy and loss of epoch #82: 0.9890, 48.3379\n",
      "Saved model by train loss 48.33793790575484\n",
      "Train loss and acc of batch 0: 48.00659942626953, 1.0\n",
      "Train loss and acc of batch 1: 48.006595611572266, 1.0\n",
      "Train loss and acc of batch 2: 48.29243469238281, 0.984375\n",
      "Train loss and acc of batch 3: 48.22333526611328, 0.984375\n",
      "Train loss and acc of batch 4: 48.00656509399414, 1.0\n",
      "Train loss and acc of batch 5: 49.35548400878906, 0.96875\n",
      "Train loss and acc of batch 6: 48.5091667175293, 0.96875\n",
      "Train loss and acc of batch 7: 48.006534576416016, 1.0\n",
      "Train loss and acc of batch 8: 48.60223388671875, 0.984375\n",
      "Train loss and acc of batch 9: 48.29237365722656, 0.984375\n",
      "Train loss and acc of batch 10: 48.00651550292969, 1.0\n",
      "Train loss and acc of batch 11: 48.00650405883789, 1.0\n",
      "Train loss and acc of batch 12: 48.75971984863281, 0.984375\n",
      "Train loss and acc of batch 13: 48.22325134277344, 0.984375\n",
      "Train loss and acc of batch 14: 48.223236083984375, 0.984375\n",
      "Train loss and acc of batch 15: 48.60216522216797, 0.984375\n",
      "Train loss and acc of batch 16: 48.60215759277344, 0.984375\n",
      "Train loss and acc of batch 17: 48.759674072265625, 0.984375\n",
      "Train loss and acc of batch 18: 48.887996673583984, 0.96875\n",
      "Train loss and acc of batch 19: 48.006431579589844, 1.0\n",
      "Train loss and acc of batch 20: 48.00642395019531, 1.0\n",
      "Train loss and acc of batch 21: 48.60211181640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.60210418701172, 0.984375\n",
      "Train loss and acc of batch 23: 48.22315979003906, 0.984375\n",
      "Train loss and acc of batch 24: 48.602088928222656, 0.984375\n",
      "Train loss and acc of batch 25: 48.006378173828125, 1.0\n",
      "Train loss and acc of batch 26: 48.006370544433594, 1.0\n",
      "Train loss and acc of batch 27: 48.0063591003418, 1.0\n",
      "Train loss and acc of batch 28: 48.00634765625, 1.0\n",
      "Train loss and acc of batch 29: 48.60204315185547, 0.984375\n",
      "Train loss and acc of batch 30: 48.00632858276367, 1.0\n",
      "Train loss and acc of batch 31: 48.22309112548828, 0.984375\n",
      "Train loss and acc of batch 32: 48.00631332397461, 1.0\n",
      "Train loss and acc of batch 33: 48.006309509277344, 1.0\n",
      "Train loss and acc of batch 34: 48.60199737548828, 0.984375\n",
      "Train loss and acc of batch 35: 48.4398193359375, 0.96875\n",
      "Train loss and acc of batch 36: 48.00627899169922, 1.0\n",
      "Train loss and acc of batch 37: 48.75949478149414, 0.984375\n",
      "Train loss and acc of batch 38: 49.355186462402344, 0.96875\n",
      "Train loss and acc of batch 39: 48.22301483154297, 0.984375\n",
      "Train loss and acc of batch 40: 48.00624084472656, 1.0\n",
      "Train loss and acc of batch 41: 49.35516357421875, 0.96875\n",
      "Train loss and acc of batch 42: 48.0062255859375, 1.0\n",
      "Train loss and acc of batch 43: 48.60191345214844, 0.984375\n",
      "Train loss and acc of batch 44: 48.00620651245117, 1.0\n",
      "Train loss and acc of batch 45: 48.601898193359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.29204559326172, 0.984375\n",
      "Train loss and acc of batch 47: 48.00618362426758, 1.0\n",
      "Train loss and acc of batch 48: 48.00617599487305, 1.0\n",
      "Train loss and acc of batch 49: 48.006160736083984, 1.0\n",
      "Train loss and acc of batch 50: 48.60186004638672, 0.984375\n",
      "Train loss and acc of batch 51: 49.355072021484375, 0.96875\n",
      "Train loss and acc of batch 52: 49.26197814941406, 0.953125\n",
      "Train loss and acc of batch 53: 48.00612258911133, 1.0\n",
      "Train loss and acc of batch 54: 48.22288513183594, 0.984375\n",
      "Train loss and acc of batch 55: 48.00611114501953, 1.0\n",
      "Train loss and acc of batch 56: 48.006099700927734, 1.0\n",
      "Train loss and acc of batch 57: 48.60179138183594, 0.984375\n",
      "Train loss and acc of batch 58: 48.00608444213867, 1.0\n",
      "Train loss and acc of batch 59: 48.006072998046875, 1.0\n",
      "Train loss and acc of batch 60: 48.006065368652344, 1.0\n",
      "Train loss and acc of batch 61: 48.00605773925781, 1.0\n",
      "Train loss and acc of batch 62: 48.222808837890625, 0.984375\n",
      "Train loss and acc of batch 63: 49.19743728637695, 0.96875\n",
      "Train loss and acc of batch 64: 48.22279357910156, 0.984375\n",
      "Train loss and acc of batch 65: 48.006019592285156, 1.0\n",
      "Train loss and acc of batch 66: 48.00601577758789, 1.0\n",
      "Train loss and acc of batch 67: 48.8184700012207, 0.96875\n",
      "Train loss and acc of batch 68: 48.60169219970703, 0.984375\n",
      "Train loss and acc of batch 69: 48.222747802734375, 0.984375\n",
      "Train loss and acc of batch 70: 48.005977630615234, 1.0\n",
      "Training accuracy and loss of epoch #83: 0.9890, 48.3373\n",
      "Saved model by train loss 48.33730386008679\n",
      "Train loss and acc of batch 0: 48.00596618652344, 1.0\n",
      "Train loss and acc of batch 1: 48.00595474243164, 1.0\n",
      "Train loss and acc of batch 2: 48.29180145263672, 0.984375\n",
      "Train loss and acc of batch 3: 48.22270202636719, 0.984375\n",
      "Train loss and acc of batch 4: 48.00593185424805, 1.0\n",
      "Train loss and acc of batch 5: 49.35484313964844, 0.96875\n",
      "Train loss and acc of batch 6: 48.50852966308594, 0.96875\n",
      "Train loss and acc of batch 7: 48.00590515136719, 1.0\n",
      "Train loss and acc of batch 8: 48.601593017578125, 0.984375\n",
      "Train loss and acc of batch 9: 48.29174041748047, 0.984375\n",
      "Train loss and acc of batch 10: 48.00587463378906, 1.0\n",
      "Train loss and acc of batch 11: 48.005863189697266, 1.0\n",
      "Train loss and acc of batch 12: 48.75908660888672, 0.984375\n",
      "Train loss and acc of batch 13: 48.22261047363281, 0.984375\n",
      "Train loss and acc of batch 14: 48.22261047363281, 0.984375\n",
      "Train loss and acc of batch 15: 48.601531982421875, 0.984375\n",
      "Train loss and acc of batch 16: 48.601524353027344, 0.984375\n",
      "Train loss and acc of batch 17: 48.759037017822266, 0.984375\n",
      "Train loss and acc of batch 18: 48.88736343383789, 0.96875\n",
      "Train loss and acc of batch 19: 48.005794525146484, 1.0\n",
      "Train loss and acc of batch 20: 48.00578689575195, 1.0\n",
      "Train loss and acc of batch 21: 48.60148620605469, 0.984375\n",
      "Train loss and acc of batch 22: 48.601470947265625, 0.984375\n",
      "Train loss and acc of batch 23: 48.22252655029297, 0.984375\n",
      "Train loss and acc of batch 24: 48.60144805908203, 0.984375\n",
      "Train loss and acc of batch 25: 48.005741119384766, 1.0\n",
      "Train loss and acc of batch 26: 48.0057373046875, 1.0\n",
      "Train loss and acc of batch 27: 48.0057258605957, 1.0\n",
      "Train loss and acc of batch 28: 48.00571823120117, 1.0\n",
      "Train loss and acc of batch 29: 48.601409912109375, 0.984375\n",
      "Train loss and acc of batch 30: 48.00569534301758, 1.0\n",
      "Train loss and acc of batch 31: 48.222450256347656, 0.984375\n",
      "Train loss and acc of batch 32: 48.00568389892578, 1.0\n",
      "Train loss and acc of batch 33: 48.005672454833984, 1.0\n",
      "Train loss and acc of batch 34: 48.60136413574219, 0.984375\n",
      "Train loss and acc of batch 35: 48.439186096191406, 0.96875\n",
      "Train loss and acc of batch 36: 48.00564193725586, 1.0\n",
      "Train loss and acc of batch 37: 48.75886154174805, 0.984375\n",
      "Train loss and acc of batch 38: 49.35454559326172, 0.96875\n",
      "Train loss and acc of batch 39: 48.222381591796875, 0.984375\n",
      "Train loss and acc of batch 40: 48.005611419677734, 1.0\n",
      "Train loss and acc of batch 41: 49.35452651977539, 0.96875\n",
      "Train loss and acc of batch 42: 48.005592346191406, 1.0\n",
      "Train loss and acc of batch 43: 48.601280212402344, 0.984375\n",
      "Train loss and acc of batch 44: 48.00556945800781, 1.0\n",
      "Train loss and acc of batch 45: 48.60126495361328, 0.984375\n",
      "Train loss and acc of batch 46: 48.291412353515625, 0.984375\n",
      "Train loss and acc of batch 47: 48.00554656982422, 1.0\n",
      "Train loss and acc of batch 48: 48.00553512573242, 1.0\n",
      "Train loss and acc of batch 49: 48.005531311035156, 1.0\n",
      "Train loss and acc of batch 50: 48.601226806640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.35443878173828, 0.96875\n",
      "Train loss and acc of batch 52: 49.26133728027344, 0.953125\n",
      "Train loss and acc of batch 53: 48.005489349365234, 1.0\n",
      "Train loss and acc of batch 54: 48.222251892089844, 0.984375\n",
      "Train loss and acc of batch 55: 48.00547790527344, 1.0\n",
      "Train loss and acc of batch 56: 48.00546646118164, 1.0\n",
      "Train loss and acc of batch 57: 48.601158142089844, 0.984375\n",
      "Train loss and acc of batch 58: 48.00544738769531, 1.0\n",
      "Train loss and acc of batch 59: 48.005435943603516, 1.0\n",
      "Train loss and acc of batch 60: 48.00543212890625, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 61: 48.00542068481445, 1.0\n",
      "Train loss and acc of batch 62: 48.22217559814453, 0.984375\n",
      "Train loss and acc of batch 63: 49.196807861328125, 0.96875\n",
      "Train loss and acc of batch 64: 48.22216033935547, 0.984375\n",
      "Train loss and acc of batch 65: 48.00538635253906, 1.0\n",
      "Train loss and acc of batch 66: 48.005374908447266, 1.0\n",
      "Train loss and acc of batch 67: 48.81782913208008, 0.96875\n",
      "Train loss and acc of batch 68: 48.60105895996094, 0.984375\n",
      "Train loss and acc of batch 69: 48.22211456298828, 0.984375\n",
      "Train loss and acc of batch 70: 48.00534439086914, 1.0\n",
      "Training accuracy and loss of epoch #84: 0.9890, 48.3367\n",
      "Saved model by train loss 48.336669062224914\n",
      "Train loss and acc of batch 0: 48.005332946777344, 1.0\n",
      "Train loss and acc of batch 1: 48.00532531738281, 1.0\n",
      "Train loss and acc of batch 2: 48.291168212890625, 0.984375\n",
      "Train loss and acc of batch 3: 48.222076416015625, 0.984375\n",
      "Train loss and acc of batch 4: 48.00529098510742, 1.0\n",
      "Train loss and acc of batch 5: 49.354209899902344, 0.96875\n",
      "Train loss and acc of batch 6: 48.507896423339844, 0.96875\n",
      "Train loss and acc of batch 7: 48.00526809692383, 1.0\n",
      "Train loss and acc of batch 8: 48.60095977783203, 0.984375\n",
      "Train loss and acc of batch 9: 48.291099548339844, 0.984375\n",
      "Train loss and acc of batch 10: 48.0052375793457, 1.0\n",
      "Train loss and acc of batch 11: 48.0052375793457, 1.0\n",
      "Train loss and acc of batch 12: 48.75844955444336, 0.984375\n",
      "Train loss and acc of batch 13: 48.22197723388672, 0.984375\n",
      "Train loss and acc of batch 14: 48.22196960449219, 0.984375\n",
      "Train loss and acc of batch 15: 48.60089874267578, 0.984375\n",
      "Train loss and acc of batch 16: 48.60089111328125, 0.984375\n",
      "Train loss and acc of batch 17: 48.75840759277344, 0.984375\n",
      "Train loss and acc of batch 18: 48.886722564697266, 0.96875\n",
      "Train loss and acc of batch 19: 48.00516128540039, 1.0\n",
      "Train loss and acc of batch 20: 48.00515365600586, 1.0\n",
      "Train loss and acc of batch 21: 48.60084533691406, 0.984375\n",
      "Train loss and acc of batch 22: 48.60083770751953, 0.984375\n",
      "Train loss and acc of batch 23: 48.221885681152344, 0.984375\n",
      "Train loss and acc of batch 24: 48.60081481933594, 0.984375\n",
      "Train loss and acc of batch 25: 48.00510787963867, 1.0\n",
      "Train loss and acc of batch 26: 48.00510025024414, 1.0\n",
      "Train loss and acc of batch 27: 48.005088806152344, 1.0\n",
      "Train loss and acc of batch 28: 48.00508499145508, 1.0\n",
      "Train loss and acc of batch 29: 48.60077667236328, 0.984375\n",
      "Train loss and acc of batch 30: 48.00506591796875, 1.0\n",
      "Train loss and acc of batch 31: 48.221824645996094, 0.984375\n",
      "Train loss and acc of batch 32: 48.005043029785156, 1.0\n",
      "Train loss and acc of batch 33: 48.005035400390625, 1.0\n",
      "Train loss and acc of batch 34: 48.600730895996094, 0.984375\n",
      "Train loss and acc of batch 35: 48.43854904174805, 0.96875\n",
      "Train loss and acc of batch 36: 48.005008697509766, 1.0\n",
      "Train loss and acc of batch 37: 48.75822830200195, 0.984375\n",
      "Train loss and acc of batch 38: 49.353912353515625, 0.96875\n",
      "Train loss and acc of batch 39: 48.22174835205078, 0.984375\n",
      "Train loss and acc of batch 40: 48.00497817993164, 1.0\n",
      "Train loss and acc of batch 41: 49.35388946533203, 0.96875\n",
      "Train loss and acc of batch 42: 48.00495910644531, 1.0\n",
      "Train loss and acc of batch 43: 48.60064697265625, 0.984375\n",
      "Train loss and acc of batch 44: 48.00494384765625, 1.0\n",
      "Train loss and acc of batch 45: 48.60063171386719, 0.984375\n",
      "Train loss and acc of batch 46: 48.290771484375, 0.984375\n",
      "Train loss and acc of batch 47: 48.004913330078125, 1.0\n",
      "Train loss and acc of batch 48: 48.004905700683594, 1.0\n",
      "Train loss and acc of batch 49: 48.0048942565918, 1.0\n",
      "Train loss and acc of batch 50: 48.6005859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.35380554199219, 0.96875\n",
      "Train loss and acc of batch 52: 49.260704040527344, 0.953125\n",
      "Train loss and acc of batch 53: 48.004859924316406, 1.0\n",
      "Train loss and acc of batch 54: 48.22161865234375, 0.984375\n",
      "Train loss and acc of batch 55: 48.00484085083008, 1.0\n",
      "Train loss and acc of batch 56: 48.00482940673828, 1.0\n",
      "Train loss and acc of batch 57: 48.60052490234375, 0.984375\n",
      "Train loss and acc of batch 58: 48.004817962646484, 1.0\n",
      "Train loss and acc of batch 59: 48.00480651855469, 1.0\n",
      "Train loss and acc of batch 60: 48.004791259765625, 1.0\n",
      "Train loss and acc of batch 61: 48.004783630371094, 1.0\n",
      "Train loss and acc of batch 62: 48.22154235839844, 0.984375\n",
      "Train loss and acc of batch 63: 49.19617462158203, 0.96875\n",
      "Train loss and acc of batch 64: 48.221519470214844, 0.984375\n",
      "Train loss and acc of batch 65: 48.00475311279297, 1.0\n",
      "Train loss and acc of batch 66: 48.00474166870117, 1.0\n",
      "Train loss and acc of batch 67: 48.81719970703125, 0.96875\n",
      "Train loss and acc of batch 68: 48.600425720214844, 0.984375\n",
      "Train loss and acc of batch 69: 48.22148132324219, 0.984375\n",
      "Train loss and acc of batch 70: 48.004703521728516, 1.0\n",
      "Training accuracy and loss of epoch #85: 0.9890, 48.3360\n",
      "Saved model by train loss 48.33603474791621\n",
      "Train loss and acc of batch 0: 48.004695892333984, 1.0\n",
      "Train loss and acc of batch 1: 48.00469207763672, 1.0\n",
      "Train loss and acc of batch 2: 48.29053497314453, 0.984375\n",
      "Train loss and acc of batch 3: 48.221435546875, 0.984375\n",
      "Train loss and acc of batch 4: 48.00465774536133, 1.0\n",
      "Train loss and acc of batch 5: 49.35357666015625, 0.96875\n",
      "Train loss and acc of batch 6: 48.50726318359375, 0.96875\n",
      "Train loss and acc of batch 7: 48.004634857177734, 1.0\n",
      "Train loss and acc of batch 8: 48.60032653808594, 0.984375\n",
      "Train loss and acc of batch 9: 48.29046630859375, 0.984375\n",
      "Train loss and acc of batch 10: 48.004608154296875, 1.0\n",
      "Train loss and acc of batch 11: 48.00459289550781, 1.0\n",
      "Train loss and acc of batch 12: 48.7578125, 0.984375\n",
      "Train loss and acc of batch 13: 48.221343994140625, 0.984375\n",
      "Train loss and acc of batch 14: 48.221336364746094, 0.984375\n",
      "Train loss and acc of batch 15: 48.60026550292969, 0.984375\n",
      "Train loss and acc of batch 16: 48.600257873535156, 0.984375\n",
      "Train loss and acc of batch 17: 48.75776672363281, 0.984375\n",
      "Train loss and acc of batch 18: 48.886085510253906, 0.96875\n",
      "Train loss and acc of batch 19: 48.0045280456543, 1.0\n",
      "Train loss and acc of batch 20: 48.004520416259766, 1.0\n",
      "Train loss and acc of batch 21: 48.60021209716797, 0.984375\n",
      "Train loss and acc of batch 22: 48.60020446777344, 0.984375\n",
      "Train loss and acc of batch 23: 48.22126007080078, 0.984375\n",
      "Train loss and acc of batch 24: 48.600189208984375, 0.984375\n",
      "Train loss and acc of batch 25: 48.00447463989258, 1.0\n",
      "Train loss and acc of batch 26: 48.00446319580078, 1.0\n",
      "Train loss and acc of batch 27: 48.00445556640625, 1.0\n",
      "Train loss and acc of batch 28: 48.00444412231445, 1.0\n",
      "Train loss and acc of batch 29: 48.60014343261719, 0.984375\n",
      "Train loss and acc of batch 30: 48.00442886352539, 1.0\n",
      "Train loss and acc of batch 31: 48.22118377685547, 0.984375\n",
      "Train loss and acc of batch 32: 48.00440979003906, 1.0\n",
      "Train loss and acc of batch 33: 48.00440216064453, 1.0\n",
      "Train loss and acc of batch 34: 48.60009765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.43791198730469, 0.96875\n",
      "Train loss and acc of batch 36: 48.00437545776367, 1.0\n",
      "Train loss and acc of batch 37: 48.757591247558594, 0.984375\n",
      "Train loss and acc of batch 38: 49.35328674316406, 0.96875\n",
      "Train loss and acc of batch 39: 48.221107482910156, 0.984375\n",
      "Train loss and acc of batch 40: 48.00434112548828, 1.0\n",
      "Train loss and acc of batch 41: 49.35325622558594, 0.96875\n",
      "Train loss and acc of batch 42: 48.00432205200195, 1.0\n",
      "Train loss and acc of batch 43: 48.60002136230469, 0.984375\n",
      "Train loss and acc of batch 44: 48.00430679321289, 1.0\n",
      "Train loss and acc of batch 45: 48.599998474121094, 0.984375\n",
      "Train loss and acc of batch 46: 48.290138244628906, 0.984375\n",
      "Train loss and acc of batch 47: 48.00428009033203, 1.0\n",
      "Train loss and acc of batch 48: 48.0042724609375, 1.0\n",
      "Train loss and acc of batch 49: 48.00425720214844, 1.0\n",
      "Train loss and acc of batch 50: 48.599952697753906, 0.984375\n",
      "Train loss and acc of batch 51: 49.35316467285156, 0.96875\n",
      "Train loss and acc of batch 52: 49.260074615478516, 0.953125\n",
      "Train loss and acc of batch 53: 48.00422286987305, 1.0\n",
      "Train loss and acc of batch 54: 48.220977783203125, 0.984375\n",
      "Train loss and acc of batch 55: 48.00420379638672, 1.0\n",
      "Train loss and acc of batch 56: 48.00419616699219, 1.0\n",
      "Train loss and acc of batch 57: 48.599884033203125, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 58: 48.004180908203125, 1.0\n",
      "Train loss and acc of batch 59: 48.00416946411133, 1.0\n",
      "Train loss and acc of batch 60: 48.0041618347168, 1.0\n",
      "Train loss and acc of batch 61: 48.004150390625, 1.0\n",
      "Train loss and acc of batch 62: 48.220909118652344, 0.984375\n",
      "Train loss and acc of batch 63: 49.195533752441406, 0.96875\n",
      "Train loss and acc of batch 64: 48.22089385986328, 0.984375\n",
      "Train loss and acc of batch 65: 48.004119873046875, 1.0\n",
      "Train loss and acc of batch 66: 48.00410842895508, 1.0\n",
      "Train loss and acc of batch 67: 48.81656265258789, 0.96875\n",
      "Train loss and acc of batch 68: 48.59979248046875, 0.984375\n",
      "Train loss and acc of batch 69: 48.220848083496094, 0.984375\n",
      "Train loss and acc of batch 70: 48.00407409667969, 1.0\n",
      "Training accuracy and loss of epoch #86: 0.9890, 48.3354\n",
      "Saved model by train loss 48.335400272423115\n",
      "Train loss and acc of batch 0: 48.00406265258789, 1.0\n",
      "Train loss and acc of batch 1: 48.004051208496094, 1.0\n",
      "Train loss and acc of batch 2: 48.28990173339844, 0.984375\n",
      "Train loss and acc of batch 3: 48.220802307128906, 0.984375\n",
      "Train loss and acc of batch 4: 48.0040283203125, 1.0\n",
      "Train loss and acc of batch 5: 49.352943420410156, 0.96875\n",
      "Train loss and acc of batch 6: 48.50662612915039, 0.96875\n",
      "Train loss and acc of batch 7: 48.00400161743164, 1.0\n",
      "Train loss and acc of batch 8: 48.599693298339844, 0.984375\n",
      "Train loss and acc of batch 9: 48.289833068847656, 0.984375\n",
      "Train loss and acc of batch 10: 48.00397872924805, 1.0\n",
      "Train loss and acc of batch 11: 48.00396728515625, 1.0\n",
      "Train loss and acc of batch 12: 48.757179260253906, 0.984375\n",
      "Train loss and acc of batch 13: 48.22071075439453, 0.984375\n",
      "Train loss and acc of batch 14: 48.220703125, 0.984375\n",
      "Train loss and acc of batch 15: 48.599632263183594, 0.984375\n",
      "Train loss and acc of batch 16: 48.59962463378906, 0.984375\n",
      "Train loss and acc of batch 17: 48.75713348388672, 0.984375\n",
      "Train loss and acc of batch 18: 48.885459899902344, 0.96875\n",
      "Train loss and acc of batch 19: 48.00389099121094, 1.0\n",
      "Train loss and acc of batch 20: 48.003883361816406, 1.0\n",
      "Train loss and acc of batch 21: 48.599578857421875, 0.984375\n",
      "Train loss and acc of batch 22: 48.599571228027344, 0.984375\n",
      "Train loss and acc of batch 23: 48.220619201660156, 0.984375\n",
      "Train loss and acc of batch 24: 48.59954833984375, 0.984375\n",
      "Train loss and acc of batch 25: 48.003841400146484, 1.0\n",
      "Train loss and acc of batch 26: 48.00382995605469, 1.0\n",
      "Train loss and acc of batch 27: 48.003822326660156, 1.0\n",
      "Train loss and acc of batch 28: 48.00381088256836, 1.0\n",
      "Train loss and acc of batch 29: 48.59950256347656, 0.984375\n",
      "Train loss and acc of batch 30: 48.0037956237793, 1.0\n",
      "Train loss and acc of batch 31: 48.220550537109375, 0.984375\n",
      "Train loss and acc of batch 32: 48.0037841796875, 1.0\n",
      "Train loss and acc of batch 33: 48.00376892089844, 1.0\n",
      "Train loss and acc of batch 34: 48.599456787109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.43727493286133, 0.96875\n",
      "Train loss and acc of batch 36: 48.00374221801758, 1.0\n",
      "Train loss and acc of batch 37: 48.7569580078125, 0.984375\n",
      "Train loss and acc of batch 38: 49.35264587402344, 0.96875\n",
      "Train loss and acc of batch 39: 48.220481872558594, 0.984375\n",
      "Train loss and acc of batch 40: 48.00370407104492, 1.0\n",
      "Train loss and acc of batch 41: 49.352622985839844, 0.96875\n",
      "Train loss and acc of batch 42: 48.003684997558594, 1.0\n",
      "Train loss and acc of batch 43: 48.59938049316406, 0.984375\n",
      "Train loss and acc of batch 44: 48.00366973876953, 1.0\n",
      "Train loss and acc of batch 45: 48.599365234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.28950500488281, 0.984375\n",
      "Train loss and acc of batch 47: 48.0036506652832, 1.0\n",
      "Train loss and acc of batch 48: 48.003631591796875, 1.0\n",
      "Train loss and acc of batch 49: 48.003623962402344, 1.0\n",
      "Train loss and acc of batch 50: 48.59931945800781, 0.984375\n",
      "Train loss and acc of batch 51: 49.35253143310547, 0.96875\n",
      "Train loss and acc of batch 52: 49.259437561035156, 0.953125\n",
      "Train loss and acc of batch 53: 48.00359344482422, 1.0\n",
      "Train loss and acc of batch 54: 48.22034454345703, 0.984375\n",
      "Train loss and acc of batch 55: 48.00357437133789, 1.0\n",
      "Train loss and acc of batch 56: 48.003562927246094, 1.0\n",
      "Train loss and acc of batch 57: 48.59925079345703, 0.984375\n",
      "Train loss and acc of batch 58: 48.003543853759766, 1.0\n",
      "Train loss and acc of batch 59: 48.003536224365234, 1.0\n",
      "Train loss and acc of batch 60: 48.00353240966797, 1.0\n",
      "Train loss and acc of batch 61: 48.003517150878906, 1.0\n",
      "Train loss and acc of batch 62: 48.22027587890625, 0.984375\n",
      "Train loss and acc of batch 63: 49.19490051269531, 0.96875\n",
      "Train loss and acc of batch 64: 48.22026062011719, 0.984375\n",
      "Train loss and acc of batch 65: 48.003482818603516, 1.0\n",
      "Train loss and acc of batch 66: 48.003475189208984, 1.0\n",
      "Train loss and acc of batch 67: 48.81593322753906, 0.96875\n",
      "Train loss and acc of batch 68: 48.599159240722656, 0.984375\n",
      "Train loss and acc of batch 69: 48.22021484375, 0.984375\n",
      "Train loss and acc of batch 70: 48.00343322753906, 1.0\n",
      "Training accuracy and loss of epoch #87: 0.9890, 48.3348\n",
      "Saved model by train loss 48.334766334211324\n",
      "Train loss and acc of batch 0: 48.0034294128418, 1.0\n",
      "Train loss and acc of batch 1: 48.003421783447266, 1.0\n",
      "Train loss and acc of batch 2: 48.28926086425781, 0.984375\n",
      "Train loss and acc of batch 3: 48.22016906738281, 0.984375\n",
      "Train loss and acc of batch 4: 48.00339126586914, 1.0\n",
      "Train loss and acc of batch 5: 49.35231018066406, 0.96875\n",
      "Train loss and acc of batch 6: 48.50598907470703, 0.96875\n",
      "Train loss and acc of batch 7: 48.00336456298828, 1.0\n",
      "Train loss and acc of batch 8: 48.59906005859375, 0.984375\n",
      "Train loss and acc of batch 9: 48.28919982910156, 0.984375\n",
      "Train loss and acc of batch 10: 48.00334167480469, 1.0\n",
      "Train loss and acc of batch 11: 48.003334045410156, 1.0\n",
      "Train loss and acc of batch 12: 48.75654602050781, 0.984375\n",
      "Train loss and acc of batch 13: 48.220069885253906, 0.984375\n",
      "Train loss and acc of batch 14: 48.220069885253906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5989990234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.59898376464844, 0.984375\n",
      "Train loss and acc of batch 17: 48.75650405883789, 0.984375\n",
      "Train loss and acc of batch 18: 48.884822845458984, 0.96875\n",
      "Train loss and acc of batch 19: 48.003257751464844, 1.0\n",
      "Train loss and acc of batch 20: 48.00324630737305, 1.0\n",
      "Train loss and acc of batch 21: 48.59893798828125, 0.984375\n",
      "Train loss and acc of batch 22: 48.59893035888672, 0.984375\n",
      "Train loss and acc of batch 23: 48.21998596191406, 0.984375\n",
      "Train loss and acc of batch 24: 48.598915100097656, 0.984375\n",
      "Train loss and acc of batch 25: 48.00320053100586, 1.0\n",
      "Train loss and acc of batch 26: 48.00319290161133, 1.0\n",
      "Train loss and acc of batch 27: 48.00318145751953, 1.0\n",
      "Train loss and acc of batch 28: 48.003173828125, 1.0\n",
      "Train loss and acc of batch 29: 48.59886932373047, 0.984375\n",
      "Train loss and acc of batch 30: 48.00315856933594, 1.0\n",
      "Train loss and acc of batch 31: 48.21991729736328, 0.984375\n",
      "Train loss and acc of batch 32: 48.003143310546875, 1.0\n",
      "Train loss and acc of batch 33: 48.00313186645508, 1.0\n",
      "Train loss and acc of batch 34: 48.59883117675781, 0.984375\n",
      "Train loss and acc of batch 35: 48.436641693115234, 0.96875\n",
      "Train loss and acc of batch 36: 48.00310134887695, 1.0\n",
      "Train loss and acc of batch 37: 48.756317138671875, 0.984375\n",
      "Train loss and acc of batch 38: 49.352012634277344, 0.96875\n",
      "Train loss and acc of batch 39: 48.21984100341797, 0.984375\n",
      "Train loss and acc of batch 40: 48.003074645996094, 1.0\n",
      "Train loss and acc of batch 41: 49.351985931396484, 0.96875\n",
      "Train loss and acc of batch 42: 48.003047943115234, 1.0\n",
      "Train loss and acc of batch 43: 48.59874725341797, 0.984375\n",
      "Train loss and acc of batch 44: 48.00303268432617, 1.0\n",
      "Train loss and acc of batch 45: 48.598724365234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.28886413574219, 0.984375\n",
      "Train loss and acc of batch 47: 48.00300979614258, 1.0\n",
      "Train loss and acc of batch 48: 48.002994537353516, 1.0\n",
      "Train loss and acc of batch 49: 48.002986907958984, 1.0\n",
      "Train loss and acc of batch 50: 48.59867858886719, 0.984375\n",
      "Train loss and acc of batch 51: 49.351898193359375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2588005065918, 0.953125\n",
      "Train loss and acc of batch 53: 48.002952575683594, 1.0\n",
      "Train loss and acc of batch 54: 48.219703674316406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 55: 48.002933502197266, 1.0\n",
      "Train loss and acc of batch 56: 48.002925872802734, 1.0\n",
      "Train loss and acc of batch 57: 48.59861755371094, 0.984375\n",
      "Train loss and acc of batch 58: 48.002906799316406, 1.0\n",
      "Train loss and acc of batch 59: 48.002899169921875, 1.0\n",
      "Train loss and acc of batch 60: 48.00288772583008, 1.0\n",
      "Train loss and acc of batch 61: 48.00288009643555, 1.0\n",
      "Train loss and acc of batch 62: 48.219635009765625, 0.984375\n",
      "Train loss and acc of batch 63: 49.19426727294922, 0.96875\n",
      "Train loss and acc of batch 64: 48.21961212158203, 0.984375\n",
      "Train loss and acc of batch 65: 48.00284194946289, 1.0\n",
      "Train loss and acc of batch 66: 48.002838134765625, 1.0\n",
      "Train loss and acc of batch 67: 48.8152961730957, 0.96875\n",
      "Train loss and acc of batch 68: 48.59851837158203, 0.984375\n",
      "Train loss and acc of batch 69: 48.219573974609375, 0.984375\n",
      "Train loss and acc of batch 70: 48.002803802490234, 1.0\n",
      "Training accuracy and loss of epoch #88: 0.9890, 48.3341\n",
      "Saved model by train loss 48.33412949468048\n",
      "Train loss and acc of batch 0: 48.00278854370117, 1.0\n",
      "Train loss and acc of batch 1: 48.002784729003906, 1.0\n",
      "Train loss and acc of batch 2: 48.28862762451172, 0.984375\n",
      "Train loss and acc of batch 3: 48.21952819824219, 0.984375\n",
      "Train loss and acc of batch 4: 48.00275802612305, 1.0\n",
      "Train loss and acc of batch 5: 49.35167694091797, 0.96875\n",
      "Train loss and acc of batch 6: 48.50535583496094, 0.96875\n",
      "Train loss and acc of batch 7: 48.00272750854492, 1.0\n",
      "Train loss and acc of batch 8: 48.598419189453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.28856658935547, 0.984375\n",
      "Train loss and acc of batch 10: 48.00270080566406, 1.0\n",
      "Train loss and acc of batch 11: 48.002689361572266, 1.0\n",
      "Train loss and acc of batch 12: 48.75590515136719, 0.984375\n",
      "Train loss and acc of batch 13: 48.219444274902344, 0.984375\n",
      "Train loss and acc of batch 14: 48.21942901611328, 0.984375\n",
      "Train loss and acc of batch 15: 48.598358154296875, 0.984375\n",
      "Train loss and acc of batch 16: 48.598350524902344, 0.984375\n",
      "Train loss and acc of batch 17: 48.755863189697266, 0.984375\n",
      "Train loss and acc of batch 18: 48.88418197631836, 0.96875\n",
      "Train loss and acc of batch 19: 48.00262451171875, 1.0\n",
      "Train loss and acc of batch 20: 48.00260925292969, 1.0\n",
      "Train loss and acc of batch 21: 48.598304748535156, 0.984375\n",
      "Train loss and acc of batch 22: 48.598297119140625, 0.984375\n",
      "Train loss and acc of batch 23: 48.21935272216797, 0.984375\n",
      "Train loss and acc of batch 24: 48.59827423095703, 0.984375\n",
      "Train loss and acc of batch 25: 48.00257110595703, 1.0\n",
      "Train loss and acc of batch 26: 48.002559661865234, 1.0\n",
      "Train loss and acc of batch 27: 48.0025520324707, 1.0\n",
      "Train loss and acc of batch 28: 48.002540588378906, 1.0\n",
      "Train loss and acc of batch 29: 48.598236083984375, 0.984375\n",
      "Train loss and acc of batch 30: 48.002525329589844, 1.0\n",
      "Train loss and acc of batch 31: 48.219276428222656, 0.984375\n",
      "Train loss and acc of batch 32: 48.002506256103516, 1.0\n",
      "Train loss and acc of batch 33: 48.00249481201172, 1.0\n",
      "Train loss and acc of batch 34: 48.59819030761719, 0.984375\n",
      "Train loss and acc of batch 35: 48.436004638671875, 0.96875\n",
      "Train loss and acc of batch 36: 48.002471923828125, 1.0\n",
      "Train loss and acc of batch 37: 48.75568389892578, 0.984375\n",
      "Train loss and acc of batch 38: 49.35137176513672, 0.96875\n",
      "Train loss and acc of batch 39: 48.219200134277344, 0.984375\n",
      "Train loss and acc of batch 40: 48.00243377685547, 1.0\n",
      "Train loss and acc of batch 41: 49.35135269165039, 0.96875\n",
      "Train loss and acc of batch 42: 48.00241470336914, 1.0\n",
      "Train loss and acc of batch 43: 48.598106384277344, 0.984375\n",
      "Train loss and acc of batch 44: 48.00239944458008, 1.0\n",
      "Train loss and acc of batch 45: 48.59809112548828, 0.984375\n",
      "Train loss and acc of batch 46: 48.288230895996094, 0.984375\n",
      "Train loss and acc of batch 47: 48.00236892700195, 1.0\n",
      "Train loss and acc of batch 48: 48.00236511230469, 1.0\n",
      "Train loss and acc of batch 49: 48.00235366821289, 1.0\n",
      "Train loss and acc of batch 50: 48.598045349121094, 0.984375\n",
      "Train loss and acc of batch 51: 49.35125732421875, 0.96875\n",
      "Train loss and acc of batch 52: 49.25816345214844, 0.953125\n",
      "Train loss and acc of batch 53: 48.002315521240234, 1.0\n",
      "Train loss and acc of batch 54: 48.21907043457031, 0.984375\n",
      "Train loss and acc of batch 55: 48.00230026245117, 1.0\n",
      "Train loss and acc of batch 56: 48.00229263305664, 1.0\n",
      "Train loss and acc of batch 57: 48.59797668457031, 0.984375\n",
      "Train loss and acc of batch 58: 48.00227355957031, 1.0\n",
      "Train loss and acc of batch 59: 48.00226593017578, 1.0\n",
      "Train loss and acc of batch 60: 48.00225067138672, 1.0\n",
      "Train loss and acc of batch 61: 48.00224685668945, 1.0\n",
      "Train loss and acc of batch 62: 48.21900177001953, 0.984375\n",
      "Train loss and acc of batch 63: 49.193634033203125, 0.96875\n",
      "Train loss and acc of batch 64: 48.21898651123047, 0.984375\n",
      "Train loss and acc of batch 65: 48.00221252441406, 1.0\n",
      "Train loss and acc of batch 66: 48.002197265625, 1.0\n",
      "Train loss and acc of batch 67: 48.81465530395508, 0.96875\n",
      "Train loss and acc of batch 68: 48.597877502441406, 0.984375\n",
      "Train loss and acc of batch 69: 48.21894073486328, 0.984375\n",
      "Train loss and acc of batch 70: 48.002166748046875, 1.0\n",
      "Training accuracy and loss of epoch #89: 0.9890, 48.3335\n",
      "Saved model by train loss 48.33349367598413\n",
      "Train loss and acc of batch 0: 48.002159118652344, 1.0\n",
      "Train loss and acc of batch 1: 48.00214767456055, 1.0\n",
      "Train loss and acc of batch 2: 48.287994384765625, 0.984375\n",
      "Train loss and acc of batch 3: 48.218894958496094, 0.984375\n",
      "Train loss and acc of batch 4: 48.00212478637695, 1.0\n",
      "Train loss and acc of batch 5: 49.351036071777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.50471878051758, 0.96875\n",
      "Train loss and acc of batch 7: 48.00209426879883, 1.0\n",
      "Train loss and acc of batch 8: 48.59778594970703, 0.984375\n",
      "Train loss and acc of batch 9: 48.287925720214844, 0.984375\n",
      "Train loss and acc of batch 10: 48.00206756591797, 1.0\n",
      "Train loss and acc of batch 11: 48.00205993652344, 1.0\n",
      "Train loss and acc of batch 12: 48.75527572631836, 0.984375\n",
      "Train loss and acc of batch 13: 48.21880340576172, 0.984375\n",
      "Train loss and acc of batch 14: 48.21879577636719, 0.984375\n",
      "Train loss and acc of batch 15: 48.59772491455078, 0.984375\n",
      "Train loss and acc of batch 16: 48.59771728515625, 0.984375\n",
      "Train loss and acc of batch 17: 48.75522994995117, 0.984375\n",
      "Train loss and acc of batch 18: 48.88355255126953, 0.96875\n",
      "Train loss and acc of batch 19: 48.001991271972656, 1.0\n",
      "Train loss and acc of batch 20: 48.001976013183594, 1.0\n",
      "Train loss and acc of batch 21: 48.59767150878906, 0.984375\n",
      "Train loss and acc of batch 22: 48.59765625, 0.984375\n",
      "Train loss and acc of batch 23: 48.218711853027344, 0.984375\n",
      "Train loss and acc of batch 24: 48.59764099121094, 0.984375\n",
      "Train loss and acc of batch 25: 48.001930236816406, 1.0\n",
      "Train loss and acc of batch 26: 48.00192642211914, 1.0\n",
      "Train loss and acc of batch 27: 48.00191879272461, 1.0\n",
      "Train loss and acc of batch 28: 48.00191116333008, 1.0\n",
      "Train loss and acc of batch 29: 48.59760284423828, 0.984375\n",
      "Train loss and acc of batch 30: 48.001888275146484, 1.0\n",
      "Train loss and acc of batch 31: 48.21864318847656, 0.984375\n",
      "Train loss and acc of batch 32: 48.001869201660156, 1.0\n",
      "Train loss and acc of batch 33: 48.001861572265625, 1.0\n",
      "Train loss and acc of batch 34: 48.59754943847656, 0.984375\n",
      "Train loss and acc of batch 35: 48.43537902832031, 0.96875\n",
      "Train loss and acc of batch 36: 48.001834869384766, 1.0\n",
      "Train loss and acc of batch 37: 48.75505065917969, 0.984375\n",
      "Train loss and acc of batch 38: 49.350738525390625, 0.96875\n",
      "Train loss and acc of batch 39: 48.21857452392578, 0.984375\n",
      "Train loss and acc of batch 40: 48.001800537109375, 1.0\n",
      "Train loss and acc of batch 41: 49.3507194519043, 0.96875\n",
      "Train loss and acc of batch 42: 48.00178146362305, 1.0\n",
      "Train loss and acc of batch 43: 48.59748077392578, 0.984375\n",
      "Train loss and acc of batch 44: 48.001766204833984, 1.0\n",
      "Train loss and acc of batch 45: 48.597450256347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.28759765625, 0.984375\n",
      "Train loss and acc of batch 47: 48.00173568725586, 1.0\n",
      "Train loss and acc of batch 48: 48.00172805786133, 1.0\n",
      "Train loss and acc of batch 49: 48.00172424316406, 1.0\n",
      "Train loss and acc of batch 50: 48.597412109375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 51: 49.350624084472656, 0.96875\n",
      "Train loss and acc of batch 52: 49.257530212402344, 0.953125\n",
      "Train loss and acc of batch 53: 48.001678466796875, 1.0\n",
      "Train loss and acc of batch 54: 48.21844482421875, 0.984375\n",
      "Train loss and acc of batch 55: 48.00166702270508, 1.0\n",
      "Train loss and acc of batch 56: 48.00165557861328, 1.0\n",
      "Train loss and acc of batch 57: 48.59735107421875, 0.984375\n",
      "Train loss and acc of batch 58: 48.00164031982422, 1.0\n",
      "Train loss and acc of batch 59: 48.00162887573242, 1.0\n",
      "Train loss and acc of batch 60: 48.00162124633789, 1.0\n",
      "Train loss and acc of batch 61: 48.001609802246094, 1.0\n",
      "Train loss and acc of batch 62: 48.21836853027344, 0.984375\n",
      "Train loss and acc of batch 63: 49.1929931640625, 0.96875\n",
      "Train loss and acc of batch 64: 48.218345642089844, 0.984375\n",
      "Train loss and acc of batch 65: 48.0015754699707, 1.0\n",
      "Train loss and acc of batch 66: 48.001564025878906, 1.0\n",
      "Train loss and acc of batch 67: 48.814022064208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.597251892089844, 0.984375\n",
      "Train loss and acc of batch 69: 48.21830749511719, 0.984375\n",
      "Train loss and acc of batch 70: 48.001529693603516, 1.0\n",
      "Training accuracy and loss of epoch #90: 0.9890, 48.3329\n",
      "Saved model by train loss 48.33285973777234\n",
      "Train loss and acc of batch 0: 48.001522064208984, 1.0\n",
      "Train loss and acc of batch 1: 48.00151443481445, 1.0\n",
      "Train loss and acc of batch 2: 48.28736114501953, 0.984375\n",
      "Train loss and acc of batch 3: 48.21826171875, 0.984375\n",
      "Train loss and acc of batch 4: 48.001487731933594, 1.0\n",
      "Train loss and acc of batch 5: 49.35040283203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.50408935546875, 0.96875\n",
      "Train loss and acc of batch 7: 48.00145721435547, 1.0\n",
      "Train loss and acc of batch 8: 48.59715270996094, 0.984375\n",
      "Train loss and acc of batch 9: 48.28729248046875, 0.984375\n",
      "Train loss and acc of batch 10: 48.00143051147461, 1.0\n",
      "Train loss and acc of batch 11: 48.00142288208008, 1.0\n",
      "Train loss and acc of batch 12: 48.754642486572266, 0.984375\n",
      "Train loss and acc of batch 13: 48.218170166015625, 0.984375\n",
      "Train loss and acc of batch 14: 48.218162536621094, 0.984375\n",
      "Train loss and acc of batch 15: 48.59709167480469, 0.984375\n",
      "Train loss and acc of batch 16: 48.597084045410156, 0.984375\n",
      "Train loss and acc of batch 17: 48.75459289550781, 0.984375\n",
      "Train loss and acc of batch 18: 48.882911682128906, 0.96875\n",
      "Train loss and acc of batch 19: 48.00135040283203, 1.0\n",
      "Train loss and acc of batch 20: 48.0013427734375, 1.0\n",
      "Train loss and acc of batch 21: 48.59703063964844, 0.984375\n",
      "Train loss and acc of batch 22: 48.597023010253906, 0.984375\n",
      "Train loss and acc of batch 23: 48.21807861328125, 0.984375\n",
      "Train loss and acc of batch 24: 48.597007751464844, 0.984375\n",
      "Train loss and acc of batch 25: 48.00129699707031, 1.0\n",
      "Train loss and acc of batch 26: 48.00129318237305, 1.0\n",
      "Train loss and acc of batch 27: 48.00128173828125, 1.0\n",
      "Train loss and acc of batch 28: 48.00127410888672, 1.0\n",
      "Train loss and acc of batch 29: 48.596961975097656, 0.984375\n",
      "Train loss and acc of batch 30: 48.00125503540039, 1.0\n",
      "Train loss and acc of batch 31: 48.21800994873047, 0.984375\n",
      "Train loss and acc of batch 32: 48.00123596191406, 1.0\n",
      "Train loss and acc of batch 33: 48.00122833251953, 1.0\n",
      "Train loss and acc of batch 34: 48.596923828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.43474197387695, 0.96875\n",
      "Train loss and acc of batch 36: 48.00120162963867, 1.0\n",
      "Train loss and acc of batch 37: 48.754417419433594, 0.984375\n",
      "Train loss and acc of batch 38: 49.35010528564453, 0.96875\n",
      "Train loss and acc of batch 39: 48.21794128417969, 0.984375\n",
      "Train loss and acc of batch 40: 48.00115966796875, 1.0\n",
      "Train loss and acc of batch 41: 49.35008239746094, 0.96875\n",
      "Train loss and acc of batch 42: 48.00114822387695, 1.0\n",
      "Train loss and acc of batch 43: 48.596839904785156, 0.984375\n",
      "Train loss and acc of batch 44: 48.00113296508789, 1.0\n",
      "Train loss and acc of batch 45: 48.596824645996094, 0.984375\n",
      "Train loss and acc of batch 46: 48.286956787109375, 0.984375\n",
      "Train loss and acc of batch 47: 48.001102447509766, 1.0\n",
      "Train loss and acc of batch 48: 48.00109100341797, 1.0\n",
      "Train loss and acc of batch 49: 48.00109100341797, 1.0\n",
      "Train loss and acc of batch 50: 48.596778869628906, 0.984375\n",
      "Train loss and acc of batch 51: 49.34999084472656, 0.96875\n",
      "Train loss and acc of batch 52: 49.25689697265625, 0.953125\n",
      "Train loss and acc of batch 53: 48.00104904174805, 1.0\n",
      "Train loss and acc of batch 54: 48.217803955078125, 0.984375\n",
      "Train loss and acc of batch 55: 48.00102615356445, 1.0\n",
      "Train loss and acc of batch 56: 48.00102233886719, 1.0\n",
      "Train loss and acc of batch 57: 48.596710205078125, 0.984375\n",
      "Train loss and acc of batch 58: 48.00100326538086, 1.0\n",
      "Train loss and acc of batch 59: 48.00099563598633, 1.0\n",
      "Train loss and acc of batch 60: 48.0009880065918, 1.0\n",
      "Train loss and acc of batch 61: 48.0009765625, 1.0\n",
      "Train loss and acc of batch 62: 48.217735290527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.19236373901367, 0.96875\n",
      "Train loss and acc of batch 64: 48.21771240234375, 0.984375\n",
      "Train loss and acc of batch 65: 48.00094223022461, 1.0\n",
      "Train loss and acc of batch 66: 48.00093460083008, 1.0\n",
      "Train loss and acc of batch 67: 48.81338882446289, 0.96875\n",
      "Train loss and acc of batch 68: 48.59661102294922, 0.984375\n",
      "Train loss and acc of batch 69: 48.21766662597656, 0.984375\n",
      "Train loss and acc of batch 70: 48.00089645385742, 1.0\n",
      "Training accuracy and loss of epoch #91: 0.9890, 48.3322\n",
      "Saved model by train loss 48.33222499363859\n",
      "Train loss and acc of batch 0: 48.00088882446289, 1.0\n",
      "Train loss and acc of batch 1: 48.00088119506836, 1.0\n",
      "Train loss and acc of batch 2: 48.286720275878906, 0.984375\n",
      "Train loss and acc of batch 3: 48.217620849609375, 0.984375\n",
      "Train loss and acc of batch 4: 48.000850677490234, 1.0\n",
      "Train loss and acc of batch 5: 49.349769592285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.503456115722656, 0.96875\n",
      "Train loss and acc of batch 7: 48.000823974609375, 1.0\n",
      "Train loss and acc of batch 8: 48.59651184082031, 0.984375\n",
      "Train loss and acc of batch 9: 48.286659240722656, 0.984375\n",
      "Train loss and acc of batch 10: 48.00080108642578, 1.0\n",
      "Train loss and acc of batch 11: 48.00078582763672, 1.0\n",
      "Train loss and acc of batch 12: 48.75400161743164, 0.984375\n",
      "Train loss and acc of batch 13: 48.21753692626953, 0.984375\n",
      "Train loss and acc of batch 14: 48.217529296875, 0.984375\n",
      "Train loss and acc of batch 15: 48.596458435058594, 0.984375\n",
      "Train loss and acc of batch 16: 48.59644317626953, 0.984375\n",
      "Train loss and acc of batch 17: 48.75395584106445, 0.984375\n",
      "Train loss and acc of batch 18: 48.88227844238281, 0.96875\n",
      "Train loss and acc of batch 19: 48.0007209777832, 1.0\n",
      "Train loss and acc of batch 20: 48.000709533691406, 1.0\n",
      "Train loss and acc of batch 21: 48.596397399902344, 0.984375\n",
      "Train loss and acc of batch 22: 48.596397399902344, 0.984375\n",
      "Train loss and acc of batch 23: 48.217445373535156, 0.984375\n",
      "Train loss and acc of batch 24: 48.59637451171875, 0.984375\n",
      "Train loss and acc of batch 25: 48.00065994262695, 1.0\n",
      "Train loss and acc of batch 26: 48.00065612792969, 1.0\n",
      "Train loss and acc of batch 27: 48.00064468383789, 1.0\n",
      "Train loss and acc of batch 28: 48.00063705444336, 1.0\n",
      "Train loss and acc of batch 29: 48.59632873535156, 0.984375\n",
      "Train loss and acc of batch 30: 48.0006217956543, 1.0\n",
      "Train loss and acc of batch 31: 48.217376708984375, 0.984375\n",
      "Train loss and acc of batch 32: 48.00060272216797, 1.0\n",
      "Train loss and acc of batch 33: 48.00059509277344, 1.0\n",
      "Train loss and acc of batch 34: 48.596282958984375, 0.984375\n",
      "Train loss and acc of batch 35: 48.43410110473633, 0.96875\n",
      "Train loss and acc of batch 36: 48.00056457519531, 1.0\n",
      "Train loss and acc of batch 37: 48.753780364990234, 0.984375\n",
      "Train loss and acc of batch 38: 49.34947204589844, 0.96875\n",
      "Train loss and acc of batch 39: 48.21730041503906, 0.984375\n",
      "Train loss and acc of batch 40: 48.00053024291992, 1.0\n",
      "Train loss and acc of batch 41: 49.34944534301758, 0.96875\n",
      "Train loss and acc of batch 42: 48.000511169433594, 1.0\n",
      "Train loss and acc of batch 43: 48.59620666503906, 0.984375\n",
      "Train loss and acc of batch 44: 48.00049591064453, 1.0\n",
      "Train loss and acc of batch 45: 48.59618377685547, 0.984375\n",
      "Train loss and acc of batch 46: 48.28633117675781, 0.984375\n",
      "Train loss and acc of batch 47: 48.00046920776367, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 48: 48.000457763671875, 1.0\n",
      "Train loss and acc of batch 49: 48.000450134277344, 1.0\n",
      "Train loss and acc of batch 50: 48.59613800048828, 0.984375\n",
      "Train loss and acc of batch 51: 49.34935760498047, 0.96875\n",
      "Train loss and acc of batch 52: 49.256263732910156, 0.953125\n",
      "Train loss and acc of batch 53: 48.00041580200195, 1.0\n",
      "Train loss and acc of batch 54: 48.21717071533203, 0.984375\n",
      "Train loss and acc of batch 55: 48.000396728515625, 1.0\n",
      "Train loss and acc of batch 56: 48.000389099121094, 1.0\n",
      "Train loss and acc of batch 57: 48.59608459472656, 0.984375\n",
      "Train loss and acc of batch 58: 48.000370025634766, 1.0\n",
      "Train loss and acc of batch 59: 48.000362396240234, 1.0\n",
      "Train loss and acc of batch 60: 48.00035095214844, 1.0\n",
      "Train loss and acc of batch 61: 48.000343322753906, 1.0\n",
      "Train loss and acc of batch 62: 48.21709442138672, 0.984375\n",
      "Train loss and acc of batch 63: 49.19172668457031, 0.96875\n",
      "Train loss and acc of batch 64: 48.217079162597656, 0.984375\n",
      "Train loss and acc of batch 65: 48.000308990478516, 1.0\n",
      "Train loss and acc of batch 66: 48.00029754638672, 1.0\n",
      "Train loss and acc of batch 67: 48.8127555847168, 0.96875\n",
      "Train loss and acc of batch 68: 48.595977783203125, 0.984375\n",
      "Train loss and acc of batch 69: 48.21703338623047, 0.984375\n",
      "Train loss and acc of batch 70: 48.00025939941406, 1.0\n",
      "Training accuracy and loss of epoch #92: 0.9890, 48.3316\n",
      "Saved model by train loss 48.33159014204858\n",
      "Train loss and acc of batch 0: 48.0002555847168, 1.0\n",
      "Train loss and acc of batch 1: 48.000244140625, 1.0\n",
      "Train loss and acc of batch 2: 48.28608703613281, 0.984375\n",
      "Train loss and acc of batch 3: 48.21698760986328, 0.984375\n",
      "Train loss and acc of batch 4: 48.00021743774414, 1.0\n",
      "Train loss and acc of batch 5: 49.34913635253906, 0.96875\n",
      "Train loss and acc of batch 6: 48.50281524658203, 0.96875\n",
      "Train loss and acc of batch 7: 48.00019073486328, 1.0\n",
      "Train loss and acc of batch 8: 48.59588623046875, 0.984375\n",
      "Train loss and acc of batch 9: 48.28602600097656, 0.984375\n",
      "Train loss and acc of batch 10: 48.000160217285156, 1.0\n",
      "Train loss and acc of batch 11: 48.000152587890625, 1.0\n",
      "Train loss and acc of batch 12: 48.75336837768555, 0.984375\n",
      "Train loss and acc of batch 13: 48.21690368652344, 0.984375\n",
      "Train loss and acc of batch 14: 48.216896057128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5958251953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.59580993652344, 0.984375\n",
      "Train loss and acc of batch 17: 48.753326416015625, 0.984375\n",
      "Train loss and acc of batch 18: 48.881649017333984, 0.96875\n",
      "Train loss and acc of batch 19: 48.00008010864258, 1.0\n",
      "Train loss and acc of batch 20: 48.00007247924805, 1.0\n",
      "Train loss and acc of batch 21: 48.59576416015625, 0.984375\n",
      "Train loss and acc of batch 22: 48.59575653076172, 0.984375\n",
      "Train loss and acc of batch 23: 48.216819763183594, 0.984375\n",
      "Train loss and acc of batch 24: 48.595741271972656, 0.984375\n",
      "Train loss and acc of batch 25: 48.00003433227539, 1.0\n",
      "Train loss and acc of batch 26: 48.00001907348633, 1.0\n",
      "Train loss and acc of batch 27: 48.0000114440918, 1.0\n",
      "Train loss and acc of batch 28: 48.0, 1.0\n",
      "Train loss and acc of batch 29: 48.59569549560547, 0.984375\n",
      "Train loss and acc of batch 30: 47.99998474121094, 1.0\n",
      "Train loss and acc of batch 31: 48.21674346923828, 0.984375\n",
      "Train loss and acc of batch 32: 47.999969482421875, 1.0\n",
      "Train loss and acc of batch 33: 47.99995803833008, 1.0\n",
      "Train loss and acc of batch 34: 48.59564971923828, 0.984375\n",
      "Train loss and acc of batch 35: 48.433467864990234, 0.96875\n",
      "Train loss and acc of batch 36: 47.99993133544922, 1.0\n",
      "Train loss and acc of batch 37: 48.753150939941406, 0.984375\n",
      "Train loss and acc of batch 38: 49.348838806152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.21666717529297, 0.984375\n",
      "Train loss and acc of batch 40: 47.99989700317383, 1.0\n",
      "Train loss and acc of batch 41: 49.348812103271484, 0.96875\n",
      "Train loss and acc of batch 42: 47.999874114990234, 1.0\n",
      "Train loss and acc of batch 43: 48.59556579589844, 0.984375\n",
      "Train loss and acc of batch 44: 47.99986267089844, 1.0\n",
      "Train loss and acc of batch 45: 48.595550537109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.28569793701172, 0.984375\n",
      "Train loss and acc of batch 47: 47.99983215332031, 1.0\n",
      "Train loss and acc of batch 48: 47.99982452392578, 1.0\n",
      "Train loss and acc of batch 49: 47.999813079833984, 1.0\n",
      "Train loss and acc of batch 50: 48.59551239013672, 0.984375\n",
      "Train loss and acc of batch 51: 49.348724365234375, 0.96875\n",
      "Train loss and acc of batch 52: 49.25563049316406, 0.953125\n",
      "Train loss and acc of batch 53: 47.99978256225586, 1.0\n",
      "Train loss and acc of batch 54: 48.21653747558594, 0.984375\n",
      "Train loss and acc of batch 55: 47.999759674072266, 1.0\n",
      "Train loss and acc of batch 56: 47.99974822998047, 1.0\n",
      "Train loss and acc of batch 57: 48.59544372558594, 0.984375\n",
      "Train loss and acc of batch 58: 47.99973678588867, 1.0\n",
      "Train loss and acc of batch 59: 47.999725341796875, 1.0\n",
      "Train loss and acc of batch 60: 47.99972152709961, 1.0\n",
      "Train loss and acc of batch 61: 47.99971008300781, 1.0\n",
      "Train loss and acc of batch 62: 48.216468811035156, 0.984375\n",
      "Train loss and acc of batch 63: 49.19109344482422, 0.96875\n",
      "Train loss and acc of batch 64: 48.21644592285156, 0.984375\n",
      "Train loss and acc of batch 65: 47.99967575073242, 1.0\n",
      "Train loss and acc of batch 66: 47.99966049194336, 1.0\n",
      "Train loss and acc of batch 67: 48.8121223449707, 0.96875\n",
      "Train loss and acc of batch 68: 48.59535217285156, 0.984375\n",
      "Train loss and acc of batch 69: 48.216400146484375, 0.984375\n",
      "Train loss and acc of batch 70: 47.9996223449707, 1.0\n",
      "Training accuracy and loss of epoch #93: 0.9890, 48.3310\n",
      "Saved model by train loss 48.33095631129305\n",
      "Train loss and acc of batch 0: 47.99961853027344, 1.0\n",
      "Train loss and acc of batch 1: 47.999610900878906, 1.0\n",
      "Train loss and acc of batch 2: 48.28545379638672, 0.984375\n",
      "Train loss and acc of batch 3: 48.21635437011719, 0.984375\n",
      "Train loss and acc of batch 4: 47.99958419799805, 1.0\n",
      "Train loss and acc of batch 5: 49.34849548339844, 0.96875\n",
      "Train loss and acc of batch 6: 48.50217819213867, 0.96875\n",
      "Train loss and acc of batch 7: 47.99955749511719, 1.0\n",
      "Train loss and acc of batch 8: 48.595245361328125, 0.984375\n",
      "Train loss and acc of batch 9: 48.28538513183594, 0.984375\n",
      "Train loss and acc of batch 10: 47.99953079223633, 1.0\n",
      "Train loss and acc of batch 11: 47.99951934814453, 1.0\n",
      "Train loss and acc of batch 12: 48.75273895263672, 0.984375\n",
      "Train loss and acc of batch 13: 48.21626281738281, 0.984375\n",
      "Train loss and acc of batch 14: 48.21626281738281, 0.984375\n",
      "Train loss and acc of batch 15: 48.595184326171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.595176696777344, 0.984375\n",
      "Train loss and acc of batch 17: 48.752689361572266, 0.984375\n",
      "Train loss and acc of batch 18: 48.881011962890625, 0.96875\n",
      "Train loss and acc of batch 19: 47.99945068359375, 1.0\n",
      "Train loss and acc of batch 20: 47.99943923950195, 1.0\n",
      "Train loss and acc of batch 21: 48.595130920410156, 0.984375\n",
      "Train loss and acc of batch 22: 48.595123291015625, 0.984375\n",
      "Train loss and acc of batch 23: 48.21617889404297, 0.984375\n",
      "Train loss and acc of batch 24: 48.59510803222656, 0.984375\n",
      "Train loss and acc of batch 25: 47.99939727783203, 1.0\n",
      "Train loss and acc of batch 26: 47.9993896484375, 1.0\n",
      "Train loss and acc of batch 27: 47.9993782043457, 1.0\n",
      "Train loss and acc of batch 28: 47.999366760253906, 1.0\n",
      "Train loss and acc of batch 29: 48.595062255859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.999351501464844, 1.0\n",
      "Train loss and acc of batch 31: 48.21611022949219, 0.984375\n",
      "Train loss and acc of batch 32: 47.999332427978516, 1.0\n",
      "Train loss and acc of batch 33: 47.999324798583984, 1.0\n",
      "Train loss and acc of batch 34: 48.59501647949219, 0.984375\n",
      "Train loss and acc of batch 35: 48.43283462524414, 0.96875\n",
      "Train loss and acc of batch 36: 47.99929428100586, 1.0\n",
      "Train loss and acc of batch 37: 48.75251007080078, 0.984375\n",
      "Train loss and acc of batch 38: 49.34819793701172, 0.96875\n",
      "Train loss and acc of batch 39: 48.216033935546875, 0.984375\n",
      "Train loss and acc of batch 40: 47.999263763427734, 1.0\n",
      "Train loss and acc of batch 41: 49.34817886352539, 0.96875\n",
      "Train loss and acc of batch 42: 47.99924087524414, 1.0\n",
      "Train loss and acc of batch 43: 48.594940185546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.99922561645508, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 45: 48.59491729736328, 0.984375\n",
      "Train loss and acc of batch 46: 48.285057067871094, 0.984375\n",
      "Train loss and acc of batch 47: 47.999202728271484, 1.0\n",
      "Train loss and acc of batch 48: 47.99919128417969, 1.0\n",
      "Train loss and acc of batch 49: 47.999176025390625, 1.0\n",
      "Train loss and acc of batch 50: 48.594871520996094, 0.984375\n",
      "Train loss and acc of batch 51: 49.34808349609375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2549934387207, 0.953125\n",
      "Train loss and acc of batch 53: 47.999149322509766, 1.0\n",
      "Train loss and acc of batch 54: 48.215904235839844, 0.984375\n",
      "Train loss and acc of batch 55: 47.99912643432617, 1.0\n",
      "Train loss and acc of batch 56: 47.99911880493164, 1.0\n",
      "Train loss and acc of batch 57: 48.594810485839844, 0.984375\n",
      "Train loss and acc of batch 58: 47.99910354614258, 1.0\n",
      "Train loss and acc of batch 59: 47.99909210205078, 1.0\n",
      "Train loss and acc of batch 60: 47.99908447265625, 1.0\n",
      "Train loss and acc of batch 61: 47.99907302856445, 1.0\n",
      "Train loss and acc of batch 62: 48.21582794189453, 0.984375\n",
      "Train loss and acc of batch 63: 49.190460205078125, 0.96875\n",
      "Train loss and acc of batch 64: 48.21581268310547, 0.984375\n",
      "Train loss and acc of batch 65: 47.9990348815918, 1.0\n",
      "Train loss and acc of batch 66: 47.999027252197266, 1.0\n",
      "Train loss and acc of batch 67: 48.811485290527344, 0.96875\n",
      "Train loss and acc of batch 68: 48.59471893310547, 0.984375\n",
      "Train loss and acc of batch 69: 48.21576690673828, 0.984375\n",
      "Train loss and acc of batch 70: 47.99899673461914, 1.0\n",
      "Training accuracy and loss of epoch #94: 0.9890, 48.3303\n",
      "Saved model by train loss 48.33032151343117\n",
      "Train loss and acc of batch 0: 47.998985290527344, 1.0\n",
      "Train loss and acc of batch 1: 47.99897766113281, 1.0\n",
      "Train loss and acc of batch 2: 48.284820556640625, 0.984375\n",
      "Train loss and acc of batch 3: 48.215728759765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.99894714355469, 1.0\n",
      "Train loss and acc of batch 5: 49.347869873046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.50155258178711, 0.96875\n",
      "Train loss and acc of batch 7: 47.99891662597656, 1.0\n",
      "Train loss and acc of batch 8: 48.59461212158203, 0.984375\n",
      "Train loss and acc of batch 9: 48.284751892089844, 0.984375\n",
      "Train loss and acc of batch 10: 47.998897552490234, 1.0\n",
      "Train loss and acc of batch 11: 47.9988899230957, 1.0\n",
      "Train loss and acc of batch 12: 48.75210189819336, 0.984375\n",
      "Train loss and acc of batch 13: 48.21563720703125, 0.984375\n",
      "Train loss and acc of batch 14: 48.21562957763672, 0.984375\n",
      "Train loss and acc of batch 15: 48.59455108642578, 0.984375\n",
      "Train loss and acc of batch 16: 48.59454345703125, 0.984375\n",
      "Train loss and acc of batch 17: 48.75205612182617, 0.984375\n",
      "Train loss and acc of batch 18: 48.88037872314453, 0.96875\n",
      "Train loss and acc of batch 19: 47.998817443847656, 1.0\n",
      "Train loss and acc of batch 20: 47.998809814453125, 1.0\n",
      "Train loss and acc of batch 21: 48.59449768066406, 0.984375\n",
      "Train loss and acc of batch 22: 48.59449005126953, 0.984375\n",
      "Train loss and acc of batch 23: 48.215538024902344, 0.984375\n",
      "Train loss and acc of batch 24: 48.59447479248047, 0.984375\n",
      "Train loss and acc of batch 25: 47.99876403808594, 1.0\n",
      "Train loss and acc of batch 26: 47.998748779296875, 1.0\n",
      "Train loss and acc of batch 27: 47.99874496459961, 1.0\n",
      "Train loss and acc of batch 28: 47.998741149902344, 1.0\n",
      "Train loss and acc of batch 29: 48.59442138671875, 0.984375\n",
      "Train loss and acc of batch 30: 47.998714447021484, 1.0\n",
      "Train loss and acc of batch 31: 48.21546936035156, 0.984375\n",
      "Train loss and acc of batch 32: 47.99869918823242, 1.0\n",
      "Train loss and acc of batch 33: 47.99869155883789, 1.0\n",
      "Train loss and acc of batch 34: 48.594383239746094, 0.984375\n",
      "Train loss and acc of batch 35: 48.43220138549805, 0.96875\n",
      "Train loss and acc of batch 36: 47.99866485595703, 1.0\n",
      "Train loss and acc of batch 37: 48.75187301635742, 0.984375\n",
      "Train loss and acc of batch 38: 49.347572326660156, 0.96875\n",
      "Train loss and acc of batch 39: 48.21540069580078, 0.984375\n",
      "Train loss and acc of batch 40: 47.998626708984375, 1.0\n",
      "Train loss and acc of batch 41: 49.3475456237793, 0.96875\n",
      "Train loss and acc of batch 42: 47.99861526489258, 1.0\n",
      "Train loss and acc of batch 43: 48.59429931640625, 0.984375\n",
      "Train loss and acc of batch 44: 47.99858856201172, 1.0\n",
      "Train loss and acc of batch 45: 48.59428405761719, 0.984375\n",
      "Train loss and acc of batch 46: 48.284423828125, 0.984375\n",
      "Train loss and acc of batch 47: 47.998565673828125, 1.0\n",
      "Train loss and acc of batch 48: 47.99856185913086, 1.0\n",
      "Train loss and acc of batch 49: 47.9985466003418, 1.0\n",
      "Train loss and acc of batch 50: 48.59423828125, 0.984375\n",
      "Train loss and acc of batch 51: 49.347450256347656, 0.96875\n",
      "Train loss and acc of batch 52: 49.25436019897461, 0.953125\n",
      "Train loss and acc of batch 53: 47.99851608276367, 1.0\n",
      "Train loss and acc of batch 54: 48.21526336669922, 0.984375\n",
      "Train loss and acc of batch 55: 47.99849319458008, 1.0\n",
      "Train loss and acc of batch 56: 47.99848937988281, 1.0\n",
      "Train loss and acc of batch 57: 48.59417724609375, 0.984375\n",
      "Train loss and acc of batch 58: 47.99846267700195, 1.0\n",
      "Train loss and acc of batch 59: 47.99845886230469, 1.0\n",
      "Train loss and acc of batch 60: 47.99844741821289, 1.0\n",
      "Train loss and acc of batch 61: 47.998443603515625, 1.0\n",
      "Train loss and acc of batch 62: 48.21520233154297, 0.984375\n",
      "Train loss and acc of batch 63: 49.189823150634766, 0.96875\n",
      "Train loss and acc of batch 64: 48.215179443359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.99839782714844, 1.0\n",
      "Train loss and acc of batch 66: 47.99839401245117, 1.0\n",
      "Train loss and acc of batch 67: 48.81085205078125, 0.96875\n",
      "Train loss and acc of batch 68: 48.594078063964844, 0.984375\n",
      "Train loss and acc of batch 69: 48.21513366699219, 0.984375\n",
      "Train loss and acc of batch 70: 47.99836349487305, 1.0\n",
      "Training accuracy and loss of epoch #95: 0.9890, 48.3297\n",
      "Saved model by train loss 48.329688005044424\n",
      "Train loss and acc of batch 0: 47.99835205078125, 1.0\n",
      "Train loss and acc of batch 1: 47.99834060668945, 1.0\n",
      "Train loss and acc of batch 2: 48.28418731689453, 0.984375\n",
      "Train loss and acc of batch 3: 48.215087890625, 0.984375\n",
      "Train loss and acc of batch 4: 47.99831771850586, 1.0\n",
      "Train loss and acc of batch 5: 49.34722900390625, 0.96875\n",
      "Train loss and acc of batch 6: 48.500911712646484, 0.96875\n",
      "Train loss and acc of batch 7: 47.998291015625, 1.0\n",
      "Train loss and acc of batch 8: 48.59397888183594, 0.984375\n",
      "Train loss and acc of batch 9: 48.28412628173828, 0.984375\n",
      "Train loss and acc of batch 10: 47.998260498046875, 1.0\n",
      "Train loss and acc of batch 11: 47.99824905395508, 1.0\n",
      "Train loss and acc of batch 12: 48.751468658447266, 0.984375\n",
      "Train loss and acc of batch 13: 48.215003967285156, 0.984375\n",
      "Train loss and acc of batch 14: 48.214988708496094, 0.984375\n",
      "Train loss and acc of batch 15: 48.59391784667969, 0.984375\n",
      "Train loss and acc of batch 16: 48.593910217285156, 0.984375\n",
      "Train loss and acc of batch 17: 48.75142288208008, 0.984375\n",
      "Train loss and acc of batch 18: 48.87974548339844, 0.96875\n",
      "Train loss and acc of batch 19: 47.99818801879883, 1.0\n",
      "Train loss and acc of batch 20: 47.9981689453125, 1.0\n",
      "Train loss and acc of batch 21: 48.59386444091797, 0.984375\n",
      "Train loss and acc of batch 22: 48.59385681152344, 0.984375\n",
      "Train loss and acc of batch 23: 48.21491241455078, 0.984375\n",
      "Train loss and acc of batch 24: 48.593833923339844, 0.984375\n",
      "Train loss and acc of batch 25: 47.99812316894531, 1.0\n",
      "Train loss and acc of batch 26: 47.99811935424805, 1.0\n",
      "Train loss and acc of batch 27: 47.998111724853516, 1.0\n",
      "Train loss and acc of batch 28: 47.99810028076172, 1.0\n",
      "Train loss and acc of batch 29: 48.59379577636719, 0.984375\n",
      "Train loss and acc of batch 30: 47.998085021972656, 1.0\n",
      "Train loss and acc of batch 31: 48.21483612060547, 0.984375\n",
      "Train loss and acc of batch 32: 47.99806594848633, 1.0\n",
      "Train loss and acc of batch 33: 47.99805450439453, 1.0\n",
      "Train loss and acc of batch 34: 48.59375, 0.984375\n",
      "Train loss and acc of batch 35: 48.43156814575195, 0.96875\n",
      "Train loss and acc of batch 36: 47.99803161621094, 1.0\n",
      "Train loss and acc of batch 37: 48.751243591308594, 0.984375\n",
      "Train loss and acc of batch 38: 49.34693145751953, 0.96875\n",
      "Train loss and acc of batch 39: 48.214759826660156, 0.984375\n",
      "Train loss and acc of batch 40: 47.99799346923828, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.3469123840332, 0.96875\n",
      "Train loss and acc of batch 42: 47.99797821044922, 1.0\n",
      "Train loss and acc of batch 43: 48.593666076660156, 0.984375\n",
      "Train loss and acc of batch 44: 47.99795913696289, 1.0\n",
      "Train loss and acc of batch 45: 48.593650817871094, 0.984375\n",
      "Train loss and acc of batch 46: 48.28379821777344, 0.984375\n",
      "Train loss and acc of batch 47: 47.9979362487793, 1.0\n",
      "Train loss and acc of batch 48: 47.997920989990234, 1.0\n",
      "Train loss and acc of batch 49: 47.9979133605957, 1.0\n",
      "Train loss and acc of batch 50: 48.59361267089844, 0.984375\n",
      "Train loss and acc of batch 51: 49.34681701660156, 0.96875\n",
      "Train loss and acc of batch 52: 49.25372314453125, 0.953125\n",
      "Train loss and acc of batch 53: 47.99787521362305, 1.0\n",
      "Train loss and acc of batch 54: 48.214637756347656, 0.984375\n",
      "Train loss and acc of batch 55: 47.997859954833984, 1.0\n",
      "Train loss and acc of batch 56: 47.99785232543945, 1.0\n",
      "Train loss and acc of batch 57: 48.593544006347656, 0.984375\n",
      "Train loss and acc of batch 58: 47.99783706665039, 1.0\n",
      "Train loss and acc of batch 59: 47.997825622558594, 1.0\n",
      "Train loss and acc of batch 60: 47.99781799316406, 1.0\n",
      "Train loss and acc of batch 61: 47.997806549072266, 1.0\n",
      "Train loss and acc of batch 62: 48.214561462402344, 0.984375\n",
      "Train loss and acc of batch 63: 49.18919372558594, 0.96875\n",
      "Train loss and acc of batch 64: 48.21454620361328, 0.984375\n",
      "Train loss and acc of batch 65: 47.997772216796875, 1.0\n",
      "Train loss and acc of batch 66: 47.99775695800781, 1.0\n",
      "Train loss and acc of batch 67: 48.81021499633789, 0.96875\n",
      "Train loss and acc of batch 68: 48.59344482421875, 0.984375\n",
      "Train loss and acc of batch 69: 48.214500427246094, 0.984375\n",
      "Train loss and acc of batch 70: 47.99772644042969, 1.0\n",
      "Training accuracy and loss of epoch #96: 0.9890, 48.3291\n",
      "Saved model by train loss 48.3290541742889\n",
      "Train loss and acc of batch 0: 47.997718811035156, 1.0\n",
      "Train loss and acc of batch 1: 47.99770736694336, 1.0\n",
      "Train loss and acc of batch 2: 48.28355407714844, 0.984375\n",
      "Train loss and acc of batch 3: 48.214454650878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.997676849365234, 1.0\n",
      "Train loss and acc of batch 5: 49.346595764160156, 0.96875\n",
      "Train loss and acc of batch 6: 48.500282287597656, 0.96875\n",
      "Train loss and acc of batch 7: 47.997657775878906, 1.0\n",
      "Train loss and acc of batch 8: 48.593353271484375, 0.984375\n",
      "Train loss and acc of batch 9: 48.283485412597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.997623443603516, 1.0\n",
      "Train loss and acc of batch 11: 47.997615814208984, 1.0\n",
      "Train loss and acc of batch 12: 48.75083541870117, 0.984375\n",
      "Train loss and acc of batch 13: 48.21436309814453, 0.984375\n",
      "Train loss and acc of batch 14: 48.21435546875, 0.984375\n",
      "Train loss and acc of batch 15: 48.593284606933594, 0.984375\n",
      "Train loss and acc of batch 16: 48.59327697753906, 0.984375\n",
      "Train loss and acc of batch 17: 48.75079345703125, 0.984375\n",
      "Train loss and acc of batch 18: 48.87910842895508, 0.96875\n",
      "Train loss and acc of batch 19: 47.9975471496582, 1.0\n",
      "Train loss and acc of batch 20: 47.99753952026367, 1.0\n",
      "Train loss and acc of batch 21: 48.593231201171875, 0.984375\n",
      "Train loss and acc of batch 22: 48.593223571777344, 0.984375\n",
      "Train loss and acc of batch 23: 48.21427917480469, 0.984375\n",
      "Train loss and acc of batch 24: 48.59320068359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.997493743896484, 1.0\n",
      "Train loss and acc of batch 26: 47.99748611450195, 1.0\n",
      "Train loss and acc of batch 27: 47.997474670410156, 1.0\n",
      "Train loss and acc of batch 28: 47.997467041015625, 1.0\n",
      "Train loss and acc of batch 29: 48.593162536621094, 0.984375\n",
      "Train loss and acc of batch 30: 47.9974479675293, 1.0\n",
      "Train loss and acc of batch 31: 48.214202880859375, 0.984375\n",
      "Train loss and acc of batch 32: 47.9974250793457, 1.0\n",
      "Train loss and acc of batch 33: 47.99742126464844, 1.0\n",
      "Train loss and acc of batch 34: 48.593116760253906, 0.984375\n",
      "Train loss and acc of batch 35: 48.43092727661133, 0.96875\n",
      "Train loss and acc of batch 36: 47.99739074707031, 1.0\n",
      "Train loss and acc of batch 37: 48.7506103515625, 0.984375\n",
      "Train loss and acc of batch 38: 49.34629821777344, 0.96875\n",
      "Train loss and acc of batch 39: 48.214134216308594, 0.984375\n",
      "Train loss and acc of batch 40: 47.99735641479492, 1.0\n",
      "Train loss and acc of batch 41: 49.346275329589844, 0.96875\n",
      "Train loss and acc of batch 42: 47.99734115600586, 1.0\n",
      "Train loss and acc of batch 43: 48.593040466308594, 0.984375\n",
      "Train loss and acc of batch 44: 47.9973258972168, 1.0\n",
      "Train loss and acc of batch 45: 48.59302520751953, 0.984375\n",
      "Train loss and acc of batch 46: 48.28315734863281, 0.984375\n",
      "Train loss and acc of batch 47: 47.99729537963867, 1.0\n",
      "Train loss and acc of batch 48: 47.997291564941406, 1.0\n",
      "Train loss and acc of batch 49: 47.997276306152344, 1.0\n",
      "Train loss and acc of batch 50: 48.59297180175781, 0.984375\n",
      "Train loss and acc of batch 51: 49.34618377685547, 0.96875\n",
      "Train loss and acc of batch 52: 49.25309371948242, 0.953125\n",
      "Train loss and acc of batch 53: 47.99724578857422, 1.0\n",
      "Train loss and acc of batch 54: 48.21399688720703, 0.984375\n",
      "Train loss and acc of batch 55: 47.997222900390625, 1.0\n",
      "Train loss and acc of batch 56: 47.99721908569336, 1.0\n",
      "Train loss and acc of batch 57: 48.59291076660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.99720001220703, 1.0\n",
      "Train loss and acc of batch 59: 47.9971923828125, 1.0\n",
      "Train loss and acc of batch 60: 47.99717712402344, 1.0\n",
      "Train loss and acc of batch 61: 47.997169494628906, 1.0\n",
      "Train loss and acc of batch 62: 48.21392822265625, 0.984375\n",
      "Train loss and acc of batch 63: 49.18855285644531, 0.96875\n",
      "Train loss and acc of batch 64: 48.213905334472656, 0.984375\n",
      "Train loss and acc of batch 65: 47.997135162353516, 1.0\n",
      "Train loss and acc of batch 66: 47.997127532958984, 1.0\n",
      "Train loss and acc of batch 67: 48.80958557128906, 0.96875\n",
      "Train loss and acc of batch 68: 48.592811584472656, 0.984375\n",
      "Train loss and acc of batch 69: 48.21385955810547, 0.984375\n",
      "Train loss and acc of batch 70: 47.997093200683594, 1.0\n",
      "Training accuracy and loss of epoch #97: 0.9890, 48.3284\n",
      "Saved model by train loss 48.32841959133954\n",
      "Train loss and acc of batch 0: 47.9970817565918, 1.0\n",
      "Train loss and acc of batch 1: 47.997074127197266, 1.0\n",
      "Train loss and acc of batch 2: 48.282920837402344, 0.984375\n",
      "Train loss and acc of batch 3: 48.21381378173828, 0.984375\n",
      "Train loss and acc of batch 4: 47.99704360961914, 1.0\n",
      "Train loss and acc of batch 5: 49.34596252441406, 0.96875\n",
      "Train loss and acc of batch 6: 48.49964141845703, 0.96875\n",
      "Train loss and acc of batch 7: 47.99701690673828, 1.0\n",
      "Train loss and acc of batch 8: 48.59271240234375, 0.984375\n",
      "Train loss and acc of batch 9: 48.28285217285156, 0.984375\n",
      "Train loss and acc of batch 10: 47.99699401855469, 1.0\n",
      "Train loss and acc of batch 11: 47.99698257446289, 1.0\n",
      "Train loss and acc of batch 12: 48.75019836425781, 0.984375\n",
      "Train loss and acc of batch 13: 48.21372985839844, 0.984375\n",
      "Train loss and acc of batch 14: 48.213722229003906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5926513671875, 0.984375\n",
      "Train loss and acc of batch 16: 48.59264373779297, 0.984375\n",
      "Train loss and acc of batch 17: 48.750152587890625, 0.984375\n",
      "Train loss and acc of batch 18: 48.878475189208984, 0.96875\n",
      "Train loss and acc of batch 19: 47.99690628051758, 1.0\n",
      "Train loss and acc of batch 20: 47.99689865112305, 1.0\n",
      "Train loss and acc of batch 21: 48.59259033203125, 0.984375\n",
      "Train loss and acc of batch 22: 48.59259033203125, 0.984375\n",
      "Train loss and acc of batch 23: 48.21363830566406, 0.984375\n",
      "Train loss and acc of batch 24: 48.59257507324219, 0.984375\n",
      "Train loss and acc of batch 25: 47.996856689453125, 1.0\n",
      "Train loss and acc of batch 26: 47.996849060058594, 1.0\n",
      "Train loss and acc of batch 27: 47.99684143066406, 1.0\n",
      "Train loss and acc of batch 28: 47.996829986572266, 1.0\n",
      "Train loss and acc of batch 29: 48.59252166748047, 0.984375\n",
      "Train loss and acc of batch 30: 47.9968147277832, 1.0\n",
      "Train loss and acc of batch 31: 48.21356964111328, 0.984375\n",
      "Train loss and acc of batch 32: 47.996795654296875, 1.0\n",
      "Train loss and acc of batch 33: 47.996788024902344, 1.0\n",
      "Train loss and acc of batch 34: 48.59247589111328, 0.984375\n",
      "Train loss and acc of batch 35: 48.4302978515625, 0.96875\n",
      "Train loss and acc of batch 36: 47.99675750732422, 1.0\n",
      "Train loss and acc of batch 37: 48.749977111816406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 38: 49.345664978027344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2135009765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.99672317504883, 1.0\n",
      "Train loss and acc of batch 41: 49.34564208984375, 0.96875\n",
      "Train loss and acc of batch 42: 47.9967041015625, 1.0\n",
      "Train loss and acc of batch 43: 48.59239959716797, 0.984375\n",
      "Train loss and acc of batch 44: 47.9966926574707, 1.0\n",
      "Train loss and acc of batch 45: 48.592384338378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.28252410888672, 0.984375\n",
      "Train loss and acc of batch 47: 47.99665832519531, 1.0\n",
      "Train loss and acc of batch 48: 47.996646881103516, 1.0\n",
      "Train loss and acc of batch 49: 47.996646881103516, 1.0\n",
      "Train loss and acc of batch 50: 48.59233093261719, 0.984375\n",
      "Train loss and acc of batch 51: 49.345550537109375, 0.96875\n",
      "Train loss and acc of batch 52: 49.252464294433594, 0.953125\n",
      "Train loss and acc of batch 53: 47.996604919433594, 1.0\n",
      "Train loss and acc of batch 54: 48.21336364746094, 0.984375\n",
      "Train loss and acc of batch 55: 47.9965934753418, 1.0\n",
      "Train loss and acc of batch 56: 47.996578216552734, 1.0\n",
      "Train loss and acc of batch 57: 48.59226989746094, 0.984375\n",
      "Train loss and acc of batch 58: 47.996559143066406, 1.0\n",
      "Train loss and acc of batch 59: 47.99655532836914, 1.0\n",
      "Train loss and acc of batch 60: 47.99654769897461, 1.0\n",
      "Train loss and acc of batch 61: 47.99654006958008, 1.0\n",
      "Train loss and acc of batch 62: 48.213287353515625, 0.984375\n",
      "Train loss and acc of batch 63: 49.187923431396484, 0.96875\n",
      "Train loss and acc of batch 64: 48.21327209472656, 0.984375\n",
      "Train loss and acc of batch 65: 47.99650192260742, 1.0\n",
      "Train loss and acc of batch 66: 47.99649429321289, 1.0\n",
      "Train loss and acc of batch 67: 48.80894470214844, 0.96875\n",
      "Train loss and acc of batch 68: 48.59217834472656, 0.984375\n",
      "Train loss and acc of batch 69: 48.213226318359375, 0.984375\n",
      "Train loss and acc of batch 70: 47.996456146240234, 1.0\n",
      "Training accuracy and loss of epoch #98: 0.9890, 48.3278\n",
      "Saved model by train loss 48.32778414874009\n",
      "Train loss and acc of batch 0: 47.99645233154297, 1.0\n",
      "Train loss and acc of batch 1: 47.99644088745117, 1.0\n",
      "Train loss and acc of batch 2: 48.28227996826172, 0.984375\n",
      "Train loss and acc of batch 3: 48.21318817138672, 0.984375\n",
      "Train loss and acc of batch 4: 47.99641036987305, 1.0\n",
      "Train loss and acc of batch 5: 49.34532165527344, 0.96875\n",
      "Train loss and acc of batch 6: 48.4990119934082, 0.96875\n",
      "Train loss and acc of batch 7: 47.99638366699219, 1.0\n",
      "Train loss and acc of batch 8: 48.592079162597656, 0.984375\n",
      "Train loss and acc of batch 9: 48.28221893310547, 0.984375\n",
      "Train loss and acc of batch 10: 47.99635314941406, 1.0\n",
      "Train loss and acc of batch 11: 47.99635314941406, 1.0\n",
      "Train loss and acc of batch 12: 48.74956512451172, 0.984375\n",
      "Train loss and acc of batch 13: 48.213096618652344, 0.984375\n",
      "Train loss and acc of batch 14: 48.21308135986328, 0.984375\n",
      "Train loss and acc of batch 15: 48.592010498046875, 0.984375\n",
      "Train loss and acc of batch 16: 48.592002868652344, 0.984375\n",
      "Train loss and acc of batch 17: 48.7495231628418, 0.984375\n",
      "Train loss and acc of batch 18: 48.877838134765625, 0.96875\n",
      "Train loss and acc of batch 19: 47.99627685546875, 1.0\n",
      "Train loss and acc of batch 20: 47.99626922607422, 1.0\n",
      "Train loss and acc of batch 21: 48.591957092285156, 0.984375\n",
      "Train loss and acc of batch 22: 48.591949462890625, 0.984375\n",
      "Train loss and acc of batch 23: 48.21300506591797, 0.984375\n",
      "Train loss and acc of batch 24: 48.59193420410156, 0.984375\n",
      "Train loss and acc of batch 25: 47.99622344970703, 1.0\n",
      "Train loss and acc of batch 26: 47.9962158203125, 1.0\n",
      "Train loss and acc of batch 27: 47.9962043762207, 1.0\n",
      "Train loss and acc of batch 28: 47.99619674682617, 1.0\n",
      "Train loss and acc of batch 29: 48.591880798339844, 0.984375\n",
      "Train loss and acc of batch 30: 47.996177673339844, 1.0\n",
      "Train loss and acc of batch 31: 48.21293640136719, 0.984375\n",
      "Train loss and acc of batch 32: 47.99616241455078, 1.0\n",
      "Train loss and acc of batch 33: 47.996158599853516, 1.0\n",
      "Train loss and acc of batch 34: 48.59184265136719, 0.984375\n",
      "Train loss and acc of batch 35: 48.42966079711914, 0.96875\n",
      "Train loss and acc of batch 36: 47.99612808227539, 1.0\n",
      "Train loss and acc of batch 37: 48.74934005737305, 0.984375\n",
      "Train loss and acc of batch 38: 49.34503173828125, 0.96875\n",
      "Train loss and acc of batch 39: 48.212860107421875, 0.984375\n",
      "Train loss and acc of batch 40: 47.996097564697266, 1.0\n",
      "Train loss and acc of batch 41: 49.34500503540039, 0.96875\n",
      "Train loss and acc of batch 42: 47.996070861816406, 1.0\n",
      "Train loss and acc of batch 43: 48.591758728027344, 0.984375\n",
      "Train loss and acc of batch 44: 47.996055603027344, 1.0\n",
      "Train loss and acc of batch 45: 48.59175109863281, 0.984375\n",
      "Train loss and acc of batch 46: 48.281898498535156, 0.984375\n",
      "Train loss and acc of batch 47: 47.99602508544922, 1.0\n",
      "Train loss and acc of batch 48: 47.99601364135742, 1.0\n",
      "Train loss and acc of batch 49: 47.99600601196289, 1.0\n",
      "Train loss and acc of batch 50: 48.591705322265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.34491729736328, 0.96875\n",
      "Train loss and acc of batch 52: 49.2518196105957, 0.953125\n",
      "Train loss and acc of batch 53: 47.995975494384766, 1.0\n",
      "Train loss and acc of batch 54: 48.21272277832031, 0.984375\n",
      "Train loss and acc of batch 55: 47.99595642089844, 1.0\n",
      "Train loss and acc of batch 56: 47.99594497680664, 1.0\n",
      "Train loss and acc of batch 57: 48.591644287109375, 0.984375\n",
      "Train loss and acc of batch 58: 47.99592971801758, 1.0\n",
      "Train loss and acc of batch 59: 47.99592208862305, 1.0\n",
      "Train loss and acc of batch 60: 47.99591064453125, 1.0\n",
      "Train loss and acc of batch 61: 47.99590301513672, 1.0\n",
      "Train loss and acc of batch 62: 48.21266174316406, 0.984375\n",
      "Train loss and acc of batch 63: 49.18728256225586, 0.96875\n",
      "Train loss and acc of batch 64: 48.21263885498047, 0.984375\n",
      "Train loss and acc of batch 65: 47.99586868286133, 1.0\n",
      "Train loss and acc of batch 66: 47.995853424072266, 1.0\n",
      "Train loss and acc of batch 67: 48.808319091796875, 0.96875\n",
      "Train loss and acc of batch 68: 48.59154510498047, 0.984375\n",
      "Train loss and acc of batch 69: 48.21260070800781, 0.984375\n",
      "Train loss and acc of batch 70: 47.995819091796875, 1.0\n",
      "Training accuracy and loss of epoch #99: 0.9890, 48.3271\n",
      "Saved model by train loss 48.327149941887654\n",
      "Train loss and acc of batch 0: 47.99580764770508, 1.0\n",
      "Train loss and acc of batch 1: 47.99580383300781, 1.0\n",
      "Train loss and acc of batch 2: 48.281654357910156, 0.984375\n",
      "Train loss and acc of batch 3: 48.212554931640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.99577713012695, 1.0\n",
      "Train loss and acc of batch 5: 49.344688415527344, 0.96875\n",
      "Train loss and acc of batch 6: 48.49837112426758, 0.96875\n",
      "Train loss and acc of batch 7: 47.995750427246094, 1.0\n",
      "Train loss and acc of batch 8: 48.59144592285156, 0.984375\n",
      "Train loss and acc of batch 9: 48.281585693359375, 0.984375\n",
      "Train loss and acc of batch 10: 47.995723724365234, 1.0\n",
      "Train loss and acc of batch 11: 47.99571228027344, 1.0\n",
      "Train loss and acc of batch 12: 48.748931884765625, 0.984375\n",
      "Train loss and acc of batch 13: 48.21246337890625, 0.984375\n",
      "Train loss and acc of batch 14: 48.21244812011719, 0.984375\n",
      "Train loss and acc of batch 15: 48.59138488769531, 0.984375\n",
      "Train loss and acc of batch 16: 48.59137725830078, 0.984375\n",
      "Train loss and acc of batch 17: 48.74888610839844, 0.984375\n",
      "Train loss and acc of batch 18: 48.87720489501953, 0.96875\n",
      "Train loss and acc of batch 19: 47.99564743041992, 1.0\n",
      "Train loss and acc of batch 20: 47.995635986328125, 1.0\n",
      "Train loss and acc of batch 21: 48.591331481933594, 0.984375\n",
      "Train loss and acc of batch 22: 48.59131622314453, 0.984375\n",
      "Train loss and acc of batch 23: 48.212371826171875, 0.984375\n",
      "Train loss and acc of batch 24: 48.59130096435547, 0.984375\n",
      "Train loss and acc of batch 25: 47.99559020996094, 1.0\n",
      "Train loss and acc of batch 26: 47.995582580566406, 1.0\n",
      "Train loss and acc of batch 27: 47.995574951171875, 1.0\n",
      "Train loss and acc of batch 28: 47.99555969238281, 1.0\n",
      "Train loss and acc of batch 29: 48.59125518798828, 0.984375\n",
      "Train loss and acc of batch 30: 47.995548248291016, 1.0\n",
      "Train loss and acc of batch 31: 48.212303161621094, 0.984375\n",
      "Train loss and acc of batch 32: 47.99552536010742, 1.0\n",
      "Train loss and acc of batch 33: 47.99551773071289, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 34: 48.591209411621094, 0.984375\n",
      "Train loss and acc of batch 35: 48.42903137207031, 0.96875\n",
      "Train loss and acc of batch 36: 47.99549102783203, 1.0\n",
      "Train loss and acc of batch 37: 48.74870300292969, 0.984375\n",
      "Train loss and acc of batch 38: 49.344398498535156, 0.96875\n",
      "Train loss and acc of batch 39: 48.21222686767578, 0.984375\n",
      "Train loss and acc of batch 40: 47.99545669555664, 1.0\n",
      "Train loss and acc of batch 41: 49.34437561035156, 0.96875\n",
      "Train loss and acc of batch 42: 47.99543762207031, 1.0\n",
      "Train loss and acc of batch 43: 48.59112548828125, 0.984375\n",
      "Train loss and acc of batch 44: 47.99542236328125, 1.0\n",
      "Train loss and acc of batch 45: 48.591102600097656, 0.984375\n",
      "Train loss and acc of batch 46: 48.28125, 0.984375\n",
      "Train loss and acc of batch 47: 47.99538803100586, 1.0\n",
      "Train loss and acc of batch 48: 47.995384216308594, 1.0\n",
      "Train loss and acc of batch 49: 47.9953727722168, 1.0\n",
      "Train loss and acc of batch 50: 48.591064453125, 0.984375\n",
      "Train loss and acc of batch 51: 49.344276428222656, 0.96875\n",
      "Train loss and acc of batch 52: 49.25118637084961, 0.953125\n",
      "Train loss and acc of batch 53: 47.995338439941406, 1.0\n",
      "Train loss and acc of batch 54: 48.21209716796875, 0.984375\n",
      "Train loss and acc of batch 55: 47.99531936645508, 1.0\n",
      "Train loss and acc of batch 56: 47.99530792236328, 1.0\n",
      "Train loss and acc of batch 57: 48.59100341796875, 0.984375\n",
      "Train loss and acc of batch 58: 47.99529266357422, 1.0\n",
      "Train loss and acc of batch 59: 47.99528121948242, 1.0\n",
      "Train loss and acc of batch 60: 47.99527359008789, 1.0\n",
      "Train loss and acc of batch 61: 47.99526596069336, 1.0\n",
      "Train loss and acc of batch 62: 48.21202087402344, 0.984375\n",
      "Train loss and acc of batch 63: 49.18665313720703, 0.96875\n",
      "Train loss and acc of batch 64: 48.212005615234375, 0.984375\n",
      "Train loss and acc of batch 65: 47.9952278137207, 1.0\n",
      "Train loss and acc of batch 66: 47.99522018432617, 1.0\n",
      "Train loss and acc of batch 67: 48.807674407958984, 0.96875\n",
      "Train loss and acc of batch 68: 48.590904235839844, 0.984375\n",
      "Train loss and acc of batch 69: 48.21195983886719, 0.984375\n",
      "Train loss and acc of batch 70: 47.995182037353516, 1.0\n",
      "Training accuracy and loss of epoch #100: 0.9890, 48.3265\n",
      "Saved model by train loss 48.32651498284138\n",
      "Train loss and acc of batch 0: 47.995174407958984, 1.0\n",
      "Train loss and acc of batch 1: 47.99516677856445, 1.0\n",
      "Train loss and acc of batch 2: 48.281005859375, 0.984375\n",
      "Train loss and acc of batch 3: 48.2119140625, 0.984375\n",
      "Train loss and acc of batch 4: 47.995140075683594, 1.0\n",
      "Train loss and acc of batch 5: 49.34405517578125, 0.96875\n",
      "Train loss and acc of batch 6: 48.49774169921875, 0.96875\n",
      "Train loss and acc of batch 7: 47.99510955810547, 1.0\n",
      "Train loss and acc of batch 8: 48.59080505371094, 0.984375\n",
      "Train loss and acc of batch 9: 48.28094482421875, 0.984375\n",
      "Train loss and acc of batch 10: 47.995086669921875, 1.0\n",
      "Train loss and acc of batch 11: 47.995079040527344, 1.0\n",
      "Train loss and acc of batch 12: 48.748294830322266, 0.984375\n",
      "Train loss and acc of batch 13: 48.211822509765625, 0.984375\n",
      "Train loss and acc of batch 14: 48.211822509765625, 0.984375\n",
      "Train loss and acc of batch 15: 48.59074401855469, 0.984375\n",
      "Train loss and acc of batch 16: 48.590728759765625, 0.984375\n",
      "Train loss and acc of batch 17: 48.74824905395508, 0.984375\n",
      "Train loss and acc of batch 18: 48.87656784057617, 0.96875\n",
      "Train loss and acc of batch 19: 47.9950065612793, 1.0\n",
      "Train loss and acc of batch 20: 47.9949951171875, 1.0\n",
      "Train loss and acc of batch 21: 48.59069061279297, 0.984375\n",
      "Train loss and acc of batch 22: 48.59068298339844, 0.984375\n",
      "Train loss and acc of batch 23: 48.21173858642578, 0.984375\n",
      "Train loss and acc of batch 24: 48.590660095214844, 0.984375\n",
      "Train loss and acc of batch 25: 47.99495315551758, 1.0\n",
      "Train loss and acc of batch 26: 47.99494171142578, 1.0\n",
      "Train loss and acc of batch 27: 47.99493408203125, 1.0\n",
      "Train loss and acc of batch 28: 47.994930267333984, 1.0\n",
      "Train loss and acc of batch 29: 48.59062194824219, 0.984375\n",
      "Train loss and acc of batch 30: 47.994903564453125, 1.0\n",
      "Train loss and acc of batch 31: 48.21166229248047, 0.984375\n",
      "Train loss and acc of batch 32: 47.99488830566406, 1.0\n",
      "Train loss and acc of batch 33: 47.9948844909668, 1.0\n",
      "Train loss and acc of batch 34: 48.590576171875, 0.984375\n",
      "Train loss and acc of batch 35: 48.42838668823242, 0.96875\n",
      "Train loss and acc of batch 36: 47.99485397338867, 1.0\n",
      "Train loss and acc of batch 37: 48.74806594848633, 0.984375\n",
      "Train loss and acc of batch 38: 49.34375762939453, 0.96875\n",
      "Train loss and acc of batch 39: 48.21159362792969, 0.984375\n",
      "Train loss and acc of batch 40: 47.994815826416016, 1.0\n",
      "Train loss and acc of batch 41: 49.34373474121094, 0.96875\n",
      "Train loss and acc of batch 42: 47.99480056762695, 1.0\n",
      "Train loss and acc of batch 43: 48.590492248535156, 0.984375\n",
      "Train loss and acc of batch 44: 47.994781494140625, 1.0\n",
      "Train loss and acc of batch 45: 48.59046936035156, 0.984375\n",
      "Train loss and acc of batch 46: 48.280616760253906, 0.984375\n",
      "Train loss and acc of batch 47: 47.99475860595703, 1.0\n",
      "Train loss and acc of batch 48: 47.994747161865234, 1.0\n",
      "Train loss and acc of batch 49: 47.9947395324707, 1.0\n",
      "Train loss and acc of batch 50: 48.590431213378906, 0.984375\n",
      "Train loss and acc of batch 51: 49.34364318847656, 0.96875\n",
      "Train loss and acc of batch 52: 49.25054931640625, 0.953125\n",
      "Train loss and acc of batch 53: 47.99470138549805, 1.0\n",
      "Train loss and acc of batch 54: 48.211456298828125, 0.984375\n",
      "Train loss and acc of batch 55: 47.99468231201172, 1.0\n",
      "Train loss and acc of batch 56: 47.99467849731445, 1.0\n",
      "Train loss and acc of batch 57: 48.590370178222656, 0.984375\n",
      "Train loss and acc of batch 58: 47.99465560913086, 1.0\n",
      "Train loss and acc of batch 59: 47.99464797973633, 1.0\n",
      "Train loss and acc of batch 60: 47.9946403503418, 1.0\n",
      "Train loss and acc of batch 61: 47.994632720947266, 1.0\n",
      "Train loss and acc of batch 62: 48.211387634277344, 0.984375\n",
      "Train loss and acc of batch 63: 49.186012268066406, 0.96875\n",
      "Train loss and acc of batch 64: 48.21137237548828, 0.984375\n",
      "Train loss and acc of batch 65: 47.99459457397461, 1.0\n",
      "Train loss and acc of batch 66: 47.99458694458008, 1.0\n",
      "Train loss and acc of batch 67: 48.807044982910156, 0.96875\n",
      "Train loss and acc of batch 68: 48.59027099609375, 0.984375\n",
      "Train loss and acc of batch 69: 48.21131896972656, 0.984375\n",
      "Train loss and acc of batch 70: 47.99455261230469, 1.0\n",
      "Training accuracy and loss of epoch #101: 0.9890, 48.3259\n",
      "Saved model by train loss 48.3258784119512\n",
      "Train loss and acc of batch 0: 47.99454116821289, 1.0\n",
      "Train loss and acc of batch 1: 47.99453353881836, 1.0\n",
      "Train loss and acc of batch 2: 48.280372619628906, 0.984375\n",
      "Train loss and acc of batch 3: 48.211280822753906, 0.984375\n",
      "Train loss and acc of batch 4: 47.9945068359375, 1.0\n",
      "Train loss and acc of batch 5: 49.343421936035156, 0.96875\n",
      "Train loss and acc of batch 6: 48.49710464477539, 0.96875\n",
      "Train loss and acc of batch 7: 47.99448013305664, 1.0\n",
      "Train loss and acc of batch 8: 48.590171813964844, 0.984375\n",
      "Train loss and acc of batch 9: 48.280311584472656, 0.984375\n",
      "Train loss and acc of batch 10: 47.99445343017578, 1.0\n",
      "Train loss and acc of batch 11: 47.994441986083984, 1.0\n",
      "Train loss and acc of batch 12: 48.747657775878906, 0.984375\n",
      "Train loss and acc of batch 13: 48.21119689941406, 0.984375\n",
      "Train loss and acc of batch 14: 48.211181640625, 0.984375\n",
      "Train loss and acc of batch 15: 48.590110778808594, 0.984375\n",
      "Train loss and acc of batch 16: 48.59010314941406, 0.984375\n",
      "Train loss and acc of batch 17: 48.74761199951172, 0.984375\n",
      "Train loss and acc of batch 18: 48.875938415527344, 0.96875\n",
      "Train loss and acc of batch 19: 47.9943733215332, 1.0\n",
      "Train loss and acc of batch 20: 47.99435806274414, 1.0\n",
      "Train loss and acc of batch 21: 48.590057373046875, 0.984375\n",
      "Train loss and acc of batch 22: 48.590049743652344, 0.984375\n",
      "Train loss and acc of batch 23: 48.211097717285156, 0.984375\n",
      "Train loss and acc of batch 24: 48.59002685546875, 0.984375\n",
      "Train loss and acc of batch 25: 47.99431610107422, 1.0\n",
      "Train loss and acc of batch 26: 47.99430847167969, 1.0\n",
      "Train loss and acc of batch 27: 47.994300842285156, 1.0\n",
      "Train loss and acc of batch 28: 47.994293212890625, 1.0\n",
      "Train loss and acc of batch 29: 48.58998107910156, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 30: 47.9942741394043, 1.0\n",
      "Train loss and acc of batch 31: 48.211029052734375, 0.984375\n",
      "Train loss and acc of batch 32: 47.994258880615234, 1.0\n",
      "Train loss and acc of batch 33: 47.99424362182617, 1.0\n",
      "Train loss and acc of batch 34: 48.589935302734375, 0.984375\n",
      "Train loss and acc of batch 35: 48.427757263183594, 0.96875\n",
      "Train loss and acc of batch 36: 47.99422073364258, 1.0\n",
      "Train loss and acc of batch 37: 48.7474365234375, 0.984375\n",
      "Train loss and acc of batch 38: 49.34312438964844, 0.96875\n",
      "Train loss and acc of batch 39: 48.21095275878906, 0.984375\n",
      "Train loss and acc of batch 40: 47.99418258666992, 1.0\n",
      "Train loss and acc of batch 41: 49.34310531616211, 0.96875\n",
      "Train loss and acc of batch 42: 47.99416732788086, 1.0\n",
      "Train loss and acc of batch 43: 48.58985900878906, 0.984375\n",
      "Train loss and acc of batch 44: 47.99414825439453, 1.0\n",
      "Train loss and acc of batch 45: 48.58983612060547, 0.984375\n",
      "Train loss and acc of batch 46: 48.27998352050781, 0.984375\n",
      "Train loss and acc of batch 47: 47.994117736816406, 1.0\n",
      "Train loss and acc of batch 48: 47.99411392211914, 1.0\n",
      "Train loss and acc of batch 49: 47.994102478027344, 1.0\n",
      "Train loss and acc of batch 50: 48.58979797363281, 0.984375\n",
      "Train loss and acc of batch 51: 49.34300994873047, 0.96875\n",
      "Train loss and acc of batch 52: 49.24991989135742, 0.953125\n",
      "Train loss and acc of batch 53: 47.99406433105469, 1.0\n",
      "Train loss and acc of batch 54: 48.21082305908203, 0.984375\n",
      "Train loss and acc of batch 55: 47.99405288696289, 1.0\n",
      "Train loss and acc of batch 56: 47.994041442871094, 1.0\n",
      "Train loss and acc of batch 57: 48.58973693847656, 0.984375\n",
      "Train loss and acc of batch 58: 47.9940299987793, 1.0\n",
      "Train loss and acc of batch 59: 47.9940185546875, 1.0\n",
      "Train loss and acc of batch 60: 47.9940071105957, 1.0\n",
      "Train loss and acc of batch 61: 47.99399948120117, 1.0\n",
      "Train loss and acc of batch 62: 48.21075439453125, 0.984375\n",
      "Train loss and acc of batch 63: 49.18538284301758, 0.96875\n",
      "Train loss and acc of batch 64: 48.210731506347656, 0.984375\n",
      "Train loss and acc of batch 65: 47.993961334228516, 1.0\n",
      "Train loss and acc of batch 66: 47.993953704833984, 1.0\n",
      "Train loss and acc of batch 67: 48.80640411376953, 0.96875\n",
      "Train loss and acc of batch 68: 48.589637756347656, 0.984375\n",
      "Train loss and acc of batch 69: 48.210693359375, 0.984375\n",
      "Train loss and acc of batch 70: 47.99391555786133, 1.0\n",
      "Training accuracy and loss of epoch #102: 0.9890, 48.3252\n",
      "Saved model by train loss 48.3252446349238\n",
      "Train loss and acc of batch 0: 47.9939079284668, 1.0\n",
      "Train loss and acc of batch 1: 47.993900299072266, 1.0\n",
      "Train loss and acc of batch 2: 48.27973937988281, 0.984375\n",
      "Train loss and acc of batch 3: 48.21064758300781, 0.984375\n",
      "Train loss and acc of batch 4: 47.993865966796875, 1.0\n",
      "Train loss and acc of batch 5: 49.34278106689453, 0.96875\n",
      "Train loss and acc of batch 6: 48.49646759033203, 0.96875\n",
      "Train loss and acc of batch 7: 47.99384307861328, 1.0\n",
      "Train loss and acc of batch 8: 48.58953857421875, 0.984375\n",
      "Train loss and acc of batch 9: 48.279685974121094, 0.984375\n",
      "Train loss and acc of batch 10: 47.99381637573242, 1.0\n",
      "Train loss and acc of batch 11: 47.99380874633789, 1.0\n",
      "Train loss and acc of batch 12: 48.74702453613281, 0.984375\n",
      "Train loss and acc of batch 13: 48.21055603027344, 0.984375\n",
      "Train loss and acc of batch 14: 48.210548400878906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5894775390625, 0.984375\n",
      "Train loss and acc of batch 16: 48.58946990966797, 0.984375\n",
      "Train loss and acc of batch 17: 48.746986389160156, 0.984375\n",
      "Train loss and acc of batch 18: 48.87529754638672, 0.96875\n",
      "Train loss and acc of batch 19: 47.993736267089844, 1.0\n",
      "Train loss and acc of batch 20: 47.99372863769531, 1.0\n",
      "Train loss and acc of batch 21: 48.58941650390625, 0.984375\n",
      "Train loss and acc of batch 22: 48.58940887451172, 0.984375\n",
      "Train loss and acc of batch 23: 48.21046447753906, 0.984375\n",
      "Train loss and acc of batch 24: 48.589393615722656, 0.984375\n",
      "Train loss and acc of batch 25: 47.99368667602539, 1.0\n",
      "Train loss and acc of batch 26: 47.99367904663086, 1.0\n",
      "Train loss and acc of batch 27: 47.9936637878418, 1.0\n",
      "Train loss and acc of batch 28: 47.99365997314453, 1.0\n",
      "Train loss and acc of batch 29: 48.58935546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.9936408996582, 1.0\n",
      "Train loss and acc of batch 31: 48.21039581298828, 0.984375\n",
      "Train loss and acc of batch 32: 47.99361801147461, 1.0\n",
      "Train loss and acc of batch 33: 47.99360656738281, 1.0\n",
      "Train loss and acc of batch 34: 48.58930206298828, 0.984375\n",
      "Train loss and acc of batch 35: 48.427120208740234, 0.96875\n",
      "Train loss and acc of batch 36: 47.993587493896484, 1.0\n",
      "Train loss and acc of batch 37: 48.746803283691406, 0.984375\n",
      "Train loss and acc of batch 38: 49.342491149902344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2103271484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.993553161621094, 1.0\n",
      "Train loss and acc of batch 41: 49.342464447021484, 0.96875\n",
      "Train loss and acc of batch 42: 47.993534088134766, 1.0\n",
      "Train loss and acc of batch 43: 48.58922576904297, 0.984375\n",
      "Train loss and acc of batch 44: 47.99351119995117, 1.0\n",
      "Train loss and acc of batch 45: 48.589210510253906, 0.984375\n",
      "Train loss and acc of batch 46: 48.27935028076172, 0.984375\n",
      "Train loss and acc of batch 47: 47.99348449707031, 1.0\n",
      "Train loss and acc of batch 48: 47.99348068237305, 1.0\n",
      "Train loss and acc of batch 49: 47.99346923828125, 1.0\n",
      "Train loss and acc of batch 50: 48.58916473388672, 0.984375\n",
      "Train loss and acc of batch 51: 49.342376708984375, 0.96875\n",
      "Train loss and acc of batch 52: 49.24928283691406, 0.953125\n",
      "Train loss and acc of batch 53: 47.99343490600586, 1.0\n",
      "Train loss and acc of batch 54: 48.21018981933594, 0.984375\n",
      "Train loss and acc of batch 55: 47.99341583251953, 1.0\n",
      "Train loss and acc of batch 56: 47.993408203125, 1.0\n",
      "Train loss and acc of batch 57: 48.58910369873047, 0.984375\n",
      "Train loss and acc of batch 58: 47.99338912963867, 1.0\n",
      "Train loss and acc of batch 59: 47.99338150024414, 1.0\n",
      "Train loss and acc of batch 60: 47.993370056152344, 1.0\n",
      "Train loss and acc of batch 61: 47.99336242675781, 1.0\n",
      "Train loss and acc of batch 62: 48.210113525390625, 0.984375\n",
      "Train loss and acc of batch 63: 49.18474578857422, 0.96875\n",
      "Train loss and acc of batch 64: 48.21009826660156, 0.984375\n",
      "Train loss and acc of batch 65: 47.99332809448242, 1.0\n",
      "Train loss and acc of batch 66: 47.993316650390625, 1.0\n",
      "Train loss and acc of batch 67: 48.80577850341797, 0.96875\n",
      "Train loss and acc of batch 68: 48.58900451660156, 0.984375\n",
      "Train loss and acc of batch 69: 48.210052490234375, 0.984375\n",
      "Train loss and acc of batch 70: 47.993282318115234, 1.0\n",
      "Training accuracy and loss of epoch #103: 0.9890, 48.3246\n",
      "Saved model by train loss 48.32461032061509\n",
      "Train loss and acc of batch 0: 47.9932746887207, 1.0\n",
      "Train loss and acc of batch 1: 47.99326705932617, 1.0\n",
      "Train loss and acc of batch 2: 48.27910614013672, 0.984375\n",
      "Train loss and acc of batch 3: 48.21000671386719, 0.984375\n",
      "Train loss and acc of batch 4: 47.99323654174805, 1.0\n",
      "Train loss and acc of batch 5: 49.34215545654297, 0.96875\n",
      "Train loss and acc of batch 6: 48.49583435058594, 0.96875\n",
      "Train loss and acc of batch 7: 47.99320983886719, 1.0\n",
      "Train loss and acc of batch 8: 48.588905334472656, 0.984375\n",
      "Train loss and acc of batch 9: 48.27904510498047, 0.984375\n",
      "Train loss and acc of batch 10: 47.993186950683594, 1.0\n",
      "Train loss and acc of batch 11: 47.99317932128906, 1.0\n",
      "Train loss and acc of batch 12: 48.74638748168945, 0.984375\n",
      "Train loss and acc of batch 13: 48.209922790527344, 0.984375\n",
      "Train loss and acc of batch 14: 48.20991516113281, 0.984375\n",
      "Train loss and acc of batch 15: 48.588844299316406, 0.984375\n",
      "Train loss and acc of batch 16: 48.588829040527344, 0.984375\n",
      "Train loss and acc of batch 17: 48.74634552001953, 0.984375\n",
      "Train loss and acc of batch 18: 48.874664306640625, 0.96875\n",
      "Train loss and acc of batch 19: 47.99310302734375, 1.0\n",
      "Train loss and acc of batch 20: 47.99309158325195, 1.0\n",
      "Train loss and acc of batch 21: 48.58879089355469, 0.984375\n",
      "Train loss and acc of batch 22: 48.588775634765625, 0.984375\n",
      "Train loss and acc of batch 23: 48.20983123779297, 0.984375\n",
      "Train loss and acc of batch 24: 48.58876037597656, 0.984375\n",
      "Train loss and acc of batch 25: 47.99304962158203, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 26: 47.9930419921875, 1.0\n",
      "Train loss and acc of batch 27: 47.99303436279297, 1.0\n",
      "Train loss and acc of batch 28: 47.993019104003906, 1.0\n",
      "Train loss and acc of batch 29: 48.588714599609375, 0.984375\n",
      "Train loss and acc of batch 30: 47.993003845214844, 1.0\n",
      "Train loss and acc of batch 31: 48.20976257324219, 0.984375\n",
      "Train loss and acc of batch 32: 47.99298858642578, 1.0\n",
      "Train loss and acc of batch 33: 47.992977142333984, 1.0\n",
      "Train loss and acc of batch 34: 48.58866882324219, 0.984375\n",
      "Train loss and acc of batch 35: 48.426490783691406, 0.96875\n",
      "Train loss and acc of batch 36: 47.992950439453125, 1.0\n",
      "Train loss and acc of batch 37: 48.74616622924805, 0.984375\n",
      "Train loss and acc of batch 38: 49.34185791015625, 0.96875\n",
      "Train loss and acc of batch 39: 48.209693908691406, 0.984375\n",
      "Train loss and acc of batch 40: 47.992916107177734, 1.0\n",
      "Train loss and acc of batch 41: 49.34183883666992, 0.96875\n",
      "Train loss and acc of batch 42: 47.992897033691406, 1.0\n",
      "Train loss and acc of batch 43: 48.588592529296875, 0.984375\n",
      "Train loss and acc of batch 44: 47.99287796020508, 1.0\n",
      "Train loss and acc of batch 45: 48.58856964111328, 0.984375\n",
      "Train loss and acc of batch 46: 48.278717041015625, 0.984375\n",
      "Train loss and acc of batch 47: 47.992855072021484, 1.0\n",
      "Train loss and acc of batch 48: 47.99284362792969, 1.0\n",
      "Train loss and acc of batch 49: 47.99283981323242, 1.0\n",
      "Train loss and acc of batch 50: 48.588523864746094, 0.984375\n",
      "Train loss and acc of batch 51: 49.34174346923828, 0.96875\n",
      "Train loss and acc of batch 52: 49.248653411865234, 0.953125\n",
      "Train loss and acc of batch 53: 47.9927978515625, 1.0\n",
      "Train loss and acc of batch 54: 48.209556579589844, 0.984375\n",
      "Train loss and acc of batch 55: 47.99277877807617, 1.0\n",
      "Train loss and acc of batch 56: 47.99277114868164, 1.0\n",
      "Train loss and acc of batch 57: 48.588462829589844, 0.984375\n",
      "Train loss and acc of batch 58: 47.992759704589844, 1.0\n",
      "Train loss and acc of batch 59: 47.99274444580078, 1.0\n",
      "Train loss and acc of batch 60: 47.992740631103516, 1.0\n",
      "Train loss and acc of batch 61: 47.99272537231445, 1.0\n",
      "Train loss and acc of batch 62: 48.20948028564453, 0.984375\n",
      "Train loss and acc of batch 63: 49.184112548828125, 0.96875\n",
      "Train loss and acc of batch 64: 48.20946502685547, 0.984375\n",
      "Train loss and acc of batch 65: 47.99269104003906, 1.0\n",
      "Train loss and acc of batch 66: 47.9926872253418, 1.0\n",
      "Train loss and acc of batch 67: 48.805137634277344, 0.96875\n",
      "Train loss and acc of batch 68: 48.58837127685547, 0.984375\n",
      "Train loss and acc of batch 69: 48.20942687988281, 0.984375\n",
      "Train loss and acc of batch 70: 47.992645263671875, 1.0\n",
      "Training accuracy and loss of epoch #104: 0.9890, 48.3240\n",
      "Saved model by train loss 48.32397622121891\n",
      "Train loss and acc of batch 0: 47.992637634277344, 1.0\n",
      "Train loss and acc of batch 1: 47.99262619018555, 1.0\n",
      "Train loss and acc of batch 2: 48.278472900390625, 0.984375\n",
      "Train loss and acc of batch 3: 48.209373474121094, 0.984375\n",
      "Train loss and acc of batch 4: 47.99260330200195, 1.0\n",
      "Train loss and acc of batch 5: 49.341522216796875, 0.96875\n",
      "Train loss and acc of batch 6: 48.49520492553711, 0.96875\n",
      "Train loss and acc of batch 7: 47.99257278442383, 1.0\n",
      "Train loss and acc of batch 8: 48.58827209472656, 0.984375\n",
      "Train loss and acc of batch 9: 48.278411865234375, 0.984375\n",
      "Train loss and acc of batch 10: 47.992549896240234, 1.0\n",
      "Train loss and acc of batch 11: 47.9925422668457, 1.0\n",
      "Train loss and acc of batch 12: 48.745758056640625, 0.984375\n",
      "Train loss and acc of batch 13: 48.20928955078125, 0.984375\n",
      "Train loss and acc of batch 14: 48.20927429199219, 0.984375\n",
      "Train loss and acc of batch 15: 48.58820343017578, 0.984375\n",
      "Train loss and acc of batch 16: 48.58819580078125, 0.984375\n",
      "Train loss and acc of batch 17: 48.74571228027344, 0.984375\n",
      "Train loss and acc of batch 18: 48.87403106689453, 0.96875\n",
      "Train loss and acc of batch 19: 47.992469787597656, 1.0\n",
      "Train loss and acc of batch 20: 47.99246597290039, 1.0\n",
      "Train loss and acc of batch 21: 48.58815002441406, 0.984375\n",
      "Train loss and acc of batch 22: 48.58814239501953, 0.984375\n",
      "Train loss and acc of batch 23: 48.209197998046875, 0.984375\n",
      "Train loss and acc of batch 24: 48.58812713623047, 0.984375\n",
      "Train loss and acc of batch 25: 47.99241638183594, 1.0\n",
      "Train loss and acc of batch 26: 47.99240493774414, 1.0\n",
      "Train loss and acc of batch 27: 47.99239730834961, 1.0\n",
      "Train loss and acc of batch 28: 47.99238967895508, 1.0\n",
      "Train loss and acc of batch 29: 48.58808135986328, 0.984375\n",
      "Train loss and acc of batch 30: 47.992366790771484, 1.0\n",
      "Train loss and acc of batch 31: 48.209129333496094, 0.984375\n",
      "Train loss and acc of batch 32: 47.99235153198242, 1.0\n",
      "Train loss and acc of batch 33: 47.99234390258789, 1.0\n",
      "Train loss and acc of batch 34: 48.588035583496094, 0.984375\n",
      "Train loss and acc of batch 35: 48.42585372924805, 0.96875\n",
      "Train loss and acc of batch 36: 47.99231719970703, 1.0\n",
      "Train loss and acc of batch 37: 48.74553298950195, 0.984375\n",
      "Train loss and acc of batch 38: 49.341224670410156, 0.96875\n",
      "Train loss and acc of batch 39: 48.20906066894531, 0.984375\n",
      "Train loss and acc of batch 40: 47.99228286743164, 1.0\n",
      "Train loss and acc of batch 41: 49.34120178222656, 0.96875\n",
      "Train loss and acc of batch 42: 47.99225997924805, 1.0\n",
      "Train loss and acc of batch 43: 48.58795166015625, 0.984375\n",
      "Train loss and acc of batch 44: 47.99224090576172, 1.0\n",
      "Train loss and acc of batch 45: 48.58794403076172, 0.984375\n",
      "Train loss and acc of batch 46: 48.278076171875, 0.984375\n",
      "Train loss and acc of batch 47: 47.99222183227539, 1.0\n",
      "Train loss and acc of batch 48: 47.99221420288086, 1.0\n",
      "Train loss and acc of batch 49: 47.9921989440918, 1.0\n",
      "Train loss and acc of batch 50: 48.587890625, 0.984375\n",
      "Train loss and acc of batch 51: 49.34111022949219, 0.96875\n",
      "Train loss and acc of batch 52: 49.24801254272461, 0.953125\n",
      "Train loss and acc of batch 53: 47.99216842651367, 1.0\n",
      "Train loss and acc of batch 54: 48.20892333984375, 0.984375\n",
      "Train loss and acc of batch 55: 47.992149353027344, 1.0\n",
      "Train loss and acc of batch 56: 47.99214172363281, 1.0\n",
      "Train loss and acc of batch 57: 48.58782958984375, 0.984375\n",
      "Train loss and acc of batch 58: 47.99211883544922, 1.0\n",
      "Train loss and acc of batch 59: 47.99211120605469, 1.0\n",
      "Train loss and acc of batch 60: 47.992103576660156, 1.0\n",
      "Train loss and acc of batch 61: 47.992095947265625, 1.0\n",
      "Train loss and acc of batch 62: 48.20884704589844, 0.984375\n",
      "Train loss and acc of batch 63: 49.18347930908203, 0.96875\n",
      "Train loss and acc of batch 64: 48.208831787109375, 0.984375\n",
      "Train loss and acc of batch 65: 47.992061614990234, 1.0\n",
      "Train loss and acc of batch 66: 47.99205017089844, 1.0\n",
      "Train loss and acc of batch 67: 48.804508209228516, 0.96875\n",
      "Train loss and acc of batch 68: 48.587738037109375, 0.984375\n",
      "Train loss and acc of batch 69: 48.20878601074219, 0.984375\n",
      "Train loss and acc of batch 70: 47.99201583862305, 1.0\n",
      "Training accuracy and loss of epoch #105: 0.9890, 48.3233\n",
      "Saved model by train loss 48.323341960638345\n",
      "Train loss and acc of batch 0: 47.99200439453125, 1.0\n",
      "Train loss and acc of batch 1: 47.99199295043945, 1.0\n",
      "Train loss and acc of batch 2: 48.27783966064453, 0.984375\n",
      "Train loss and acc of batch 3: 48.208740234375, 0.984375\n",
      "Train loss and acc of batch 4: 47.99197006225586, 1.0\n",
      "Train loss and acc of batch 5: 49.34088897705078, 0.96875\n",
      "Train loss and acc of batch 6: 48.49456787109375, 0.96875\n",
      "Train loss and acc of batch 7: 47.991943359375, 1.0\n",
      "Train loss and acc of batch 8: 48.58763122558594, 0.984375\n",
      "Train loss and acc of batch 9: 48.27777862548828, 0.984375\n",
      "Train loss and acc of batch 10: 47.99191665649414, 1.0\n",
      "Train loss and acc of batch 11: 47.99190902709961, 1.0\n",
      "Train loss and acc of batch 12: 48.745121002197266, 0.984375\n",
      "Train loss and acc of batch 13: 48.208656311035156, 0.984375\n",
      "Train loss and acc of batch 14: 48.208641052246094, 0.984375\n",
      "Train loss and acc of batch 15: 48.58757019042969, 0.984375\n",
      "Train loss and acc of batch 16: 48.587562561035156, 0.984375\n",
      "Train loss and acc of batch 17: 48.74507522583008, 0.984375\n",
      "Train loss and acc of batch 18: 48.87339782714844, 0.96875\n",
      "Train loss and acc of batch 19: 47.9918327331543, 1.0\n",
      "Train loss and acc of batch 20: 47.991825103759766, 1.0\n",
      "Train loss and acc of batch 21: 48.5875244140625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 22: 48.58750915527344, 0.984375\n",
      "Train loss and acc of batch 23: 48.20856475830078, 0.984375\n",
      "Train loss and acc of batch 24: 48.587493896484375, 0.984375\n",
      "Train loss and acc of batch 25: 47.991783142089844, 1.0\n",
      "Train loss and acc of batch 26: 47.99177169799805, 1.0\n",
      "Train loss and acc of batch 27: 47.991764068603516, 1.0\n",
      "Train loss and acc of batch 28: 47.991756439208984, 1.0\n",
      "Train loss and acc of batch 29: 48.587440490722656, 0.984375\n",
      "Train loss and acc of batch 30: 47.99174118041992, 1.0\n",
      "Train loss and acc of batch 31: 48.20848846435547, 0.984375\n",
      "Train loss and acc of batch 32: 47.991722106933594, 1.0\n",
      "Train loss and acc of batch 33: 47.99171447753906, 1.0\n",
      "Train loss and acc of batch 34: 48.58740234375, 0.984375\n",
      "Train loss and acc of batch 35: 48.42522430419922, 0.96875\n",
      "Train loss and acc of batch 36: 47.9916877746582, 1.0\n",
      "Train loss and acc of batch 37: 48.744895935058594, 0.984375\n",
      "Train loss and acc of batch 38: 49.34059143066406, 0.96875\n",
      "Train loss and acc of batch 39: 48.20841979980469, 0.984375\n",
      "Train loss and acc of batch 40: 47.99164581298828, 1.0\n",
      "Train loss and acc of batch 41: 49.34056854248047, 0.96875\n",
      "Train loss and acc of batch 42: 47.99163055419922, 1.0\n",
      "Train loss and acc of batch 43: 48.587318420410156, 0.984375\n",
      "Train loss and acc of batch 44: 47.99161148071289, 1.0\n",
      "Train loss and acc of batch 45: 48.587303161621094, 0.984375\n",
      "Train loss and acc of batch 46: 48.27745056152344, 0.984375\n",
      "Train loss and acc of batch 47: 47.99158477783203, 1.0\n",
      "Train loss and acc of batch 48: 47.9915771484375, 1.0\n",
      "Train loss and acc of batch 49: 47.99156951904297, 1.0\n",
      "Train loss and acc of batch 50: 48.58726501464844, 0.984375\n",
      "Train loss and acc of batch 51: 49.340476989746094, 0.96875\n",
      "Train loss and acc of batch 52: 49.24738693237305, 0.953125\n",
      "Train loss and acc of batch 53: 47.99153137207031, 1.0\n",
      "Train loss and acc of batch 54: 48.208290100097656, 0.984375\n",
      "Train loss and acc of batch 55: 47.99151611328125, 1.0\n",
      "Train loss and acc of batch 56: 47.99150466918945, 1.0\n",
      "Train loss and acc of batch 57: 48.587196350097656, 0.984375\n",
      "Train loss and acc of batch 58: 47.99148941040039, 1.0\n",
      "Train loss and acc of batch 59: 47.99148178100586, 1.0\n",
      "Train loss and acc of batch 60: 47.9914665222168, 1.0\n",
      "Train loss and acc of batch 61: 47.991458892822266, 1.0\n",
      "Train loss and acc of batch 62: 48.208213806152344, 0.984375\n",
      "Train loss and acc of batch 63: 49.18284606933594, 0.96875\n",
      "Train loss and acc of batch 64: 48.20820617675781, 0.984375\n",
      "Train loss and acc of batch 65: 47.99142837524414, 1.0\n",
      "Train loss and acc of batch 66: 47.99142074584961, 1.0\n",
      "Train loss and acc of batch 67: 48.80387878417969, 0.96875\n",
      "Train loss and acc of batch 68: 48.58709716796875, 0.984375\n",
      "Train loss and acc of batch 69: 48.208160400390625, 0.984375\n",
      "Train loss and acc of batch 70: 47.99137878417969, 1.0\n",
      "Training accuracy and loss of epoch #106: 0.9890, 48.3227\n",
      "Saved model by train loss 48.322708667164115\n",
      "Train loss and acc of batch 0: 47.991371154785156, 1.0\n",
      "Train loss and acc of batch 1: 47.99135971069336, 1.0\n",
      "Train loss and acc of batch 2: 48.27720642089844, 0.984375\n",
      "Train loss and acc of batch 3: 48.208106994628906, 0.984375\n",
      "Train loss and acc of batch 4: 47.99134063720703, 1.0\n",
      "Train loss and acc of batch 5: 49.340248107910156, 0.96875\n",
      "Train loss and acc of batch 6: 48.493934631347656, 0.96875\n",
      "Train loss and acc of batch 7: 47.991310119628906, 1.0\n",
      "Train loss and acc of batch 8: 48.587005615234375, 0.984375\n",
      "Train loss and acc of batch 9: 48.27714538574219, 0.984375\n",
      "Train loss and acc of batch 10: 47.99128341674805, 1.0\n",
      "Train loss and acc of batch 11: 47.99127197265625, 1.0\n",
      "Train loss and acc of batch 12: 48.74448776245117, 0.984375\n",
      "Train loss and acc of batch 13: 48.20802307128906, 0.984375\n",
      "Train loss and acc of batch 14: 48.2080078125, 0.984375\n",
      "Train loss and acc of batch 15: 48.586936950683594, 0.984375\n",
      "Train loss and acc of batch 16: 48.58692932128906, 0.984375\n",
      "Train loss and acc of batch 17: 48.74444580078125, 0.984375\n",
      "Train loss and acc of batch 18: 48.872764587402344, 0.96875\n",
      "Train loss and acc of batch 19: 47.99120330810547, 1.0\n",
      "Train loss and acc of batch 20: 47.99119186401367, 1.0\n",
      "Train loss and acc of batch 21: 48.586891174316406, 0.984375\n",
      "Train loss and acc of batch 22: 48.586875915527344, 0.984375\n",
      "Train loss and acc of batch 23: 48.20793151855469, 0.984375\n",
      "Train loss and acc of batch 24: 48.58686065673828, 0.984375\n",
      "Train loss and acc of batch 25: 47.991153717041016, 1.0\n",
      "Train loss and acc of batch 26: 47.99113845825195, 1.0\n",
      "Train loss and acc of batch 27: 47.99113082885742, 1.0\n",
      "Train loss and acc of batch 28: 47.991119384765625, 1.0\n",
      "Train loss and acc of batch 29: 48.586814880371094, 0.984375\n",
      "Train loss and acc of batch 30: 47.99110412597656, 1.0\n",
      "Train loss and acc of batch 31: 48.207862854003906, 0.984375\n",
      "Train loss and acc of batch 32: 47.991085052490234, 1.0\n",
      "Train loss and acc of batch 33: 47.9910774230957, 1.0\n",
      "Train loss and acc of batch 34: 48.586769104003906, 0.984375\n",
      "Train loss and acc of batch 35: 48.424591064453125, 0.96875\n",
      "Train loss and acc of batch 36: 47.991050720214844, 1.0\n",
      "Train loss and acc of batch 37: 48.744266510009766, 0.984375\n",
      "Train loss and acc of batch 38: 49.33995819091797, 0.96875\n",
      "Train loss and acc of batch 39: 48.207786560058594, 0.984375\n",
      "Train loss and acc of batch 40: 47.99101638793945, 1.0\n",
      "Train loss and acc of batch 41: 49.33993148803711, 0.96875\n",
      "Train loss and acc of batch 42: 47.99099349975586, 1.0\n",
      "Train loss and acc of batch 43: 48.586692810058594, 0.984375\n",
      "Train loss and acc of batch 44: 47.9909782409668, 1.0\n",
      "Train loss and acc of batch 45: 48.586669921875, 0.984375\n",
      "Train loss and acc of batch 46: 48.276817321777344, 0.984375\n",
      "Train loss and acc of batch 47: 47.99094772338867, 1.0\n",
      "Train loss and acc of batch 48: 47.990943908691406, 1.0\n",
      "Train loss and acc of batch 49: 47.990936279296875, 1.0\n",
      "Train loss and acc of batch 50: 48.58662414550781, 0.984375\n",
      "Train loss and acc of batch 51: 49.33984375, 0.96875\n",
      "Train loss and acc of batch 52: 49.24674987792969, 0.953125\n",
      "Train loss and acc of batch 53: 47.990901947021484, 1.0\n",
      "Train loss and acc of batch 54: 48.20765686035156, 0.984375\n",
      "Train loss and acc of batch 55: 47.99087905883789, 1.0\n",
      "Train loss and acc of batch 56: 47.990867614746094, 1.0\n",
      "Train loss and acc of batch 57: 48.58656311035156, 0.984375\n",
      "Train loss and acc of batch 58: 47.9908561706543, 1.0\n",
      "Train loss and acc of batch 59: 47.9908447265625, 1.0\n",
      "Train loss and acc of batch 60: 47.99083709716797, 1.0\n",
      "Train loss and acc of batch 61: 47.99082565307617, 1.0\n",
      "Train loss and acc of batch 62: 48.20758056640625, 0.984375\n",
      "Train loss and acc of batch 63: 49.182212829589844, 0.96875\n",
      "Train loss and acc of batch 64: 48.20756530761719, 0.984375\n",
      "Train loss and acc of batch 65: 47.990787506103516, 1.0\n",
      "Train loss and acc of batch 66: 47.990779876708984, 1.0\n",
      "Train loss and acc of batch 67: 48.80323791503906, 0.96875\n",
      "Train loss and acc of batch 68: 48.58647155761719, 0.984375\n",
      "Train loss and acc of batch 69: 48.20751190185547, 0.984375\n",
      "Train loss and acc of batch 70: 47.990745544433594, 1.0\n",
      "Training accuracy and loss of epoch #107: 0.9890, 48.3221\n",
      "Saved model by train loss 48.32207483640859\n",
      "Train loss and acc of batch 0: 47.99073791503906, 1.0\n",
      "Train loss and acc of batch 1: 47.99073028564453, 1.0\n",
      "Train loss and acc of batch 2: 48.276573181152344, 0.984375\n",
      "Train loss and acc of batch 3: 48.20747375488281, 0.984375\n",
      "Train loss and acc of batch 4: 47.99070358276367, 1.0\n",
      "Train loss and acc of batch 5: 49.33961486816406, 0.96875\n",
      "Train loss and acc of batch 6: 48.4932975769043, 0.96875\n",
      "Train loss and acc of batch 7: 47.99067306518555, 1.0\n",
      "Train loss and acc of batch 8: 48.58636474609375, 0.984375\n",
      "Train loss and acc of batch 9: 48.27650451660156, 0.984375\n",
      "Train loss and acc of batch 10: 47.99065017700195, 1.0\n",
      "Train loss and acc of batch 11: 47.99064254760742, 1.0\n",
      "Train loss and acc of batch 12: 48.74385452270508, 0.984375\n",
      "Train loss and acc of batch 13: 48.20738220214844, 0.984375\n",
      "Train loss and acc of batch 14: 48.207374572753906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5863037109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.58629608154297, 0.984375\n",
      "Train loss and acc of batch 17: 48.74380874633789, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 18: 48.872127532958984, 0.96875\n",
      "Train loss and acc of batch 19: 47.990570068359375, 1.0\n",
      "Train loss and acc of batch 20: 47.99055480957031, 1.0\n",
      "Train loss and acc of batch 21: 48.58625030517578, 0.984375\n",
      "Train loss and acc of batch 22: 48.58624267578125, 0.984375\n",
      "Train loss and acc of batch 23: 48.207298278808594, 0.984375\n",
      "Train loss and acc of batch 24: 48.586219787597656, 0.984375\n",
      "Train loss and acc of batch 25: 47.990516662597656, 1.0\n",
      "Train loss and acc of batch 26: 47.990501403808594, 1.0\n",
      "Train loss and acc of batch 27: 47.99049377441406, 1.0\n",
      "Train loss and acc of batch 28: 47.99048614501953, 1.0\n",
      "Train loss and acc of batch 29: 48.586181640625, 0.984375\n",
      "Train loss and acc of batch 30: 47.99047088623047, 1.0\n",
      "Train loss and acc of batch 31: 48.20722198486328, 0.984375\n",
      "Train loss and acc of batch 32: 47.99045181274414, 1.0\n",
      "Train loss and acc of batch 33: 47.99044418334961, 1.0\n",
      "Train loss and acc of batch 34: 48.58612823486328, 0.984375\n",
      "Train loss and acc of batch 35: 48.4239501953125, 0.96875\n",
      "Train loss and acc of batch 36: 47.99041748046875, 1.0\n",
      "Train loss and acc of batch 37: 48.74363327026367, 0.984375\n",
      "Train loss and acc of batch 38: 49.339324951171875, 0.96875\n",
      "Train loss and acc of batch 39: 48.2071533203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.99038314819336, 1.0\n",
      "Train loss and acc of batch 41: 49.33929443359375, 0.96875\n",
      "Train loss and acc of batch 42: 47.990360260009766, 1.0\n",
      "Train loss and acc of batch 43: 48.58605194091797, 0.984375\n",
      "Train loss and acc of batch 44: 47.9903450012207, 1.0\n",
      "Train loss and acc of batch 45: 48.586036682128906, 0.984375\n",
      "Train loss and acc of batch 46: 48.27618408203125, 0.984375\n",
      "Train loss and acc of batch 47: 47.99032211303711, 1.0\n",
      "Train loss and acc of batch 48: 47.99031066894531, 1.0\n",
      "Train loss and acc of batch 49: 47.99029541015625, 1.0\n",
      "Train loss and acc of batch 50: 48.58599090576172, 0.984375\n",
      "Train loss and acc of batch 51: 49.339202880859375, 0.96875\n",
      "Train loss and acc of batch 52: 49.24611282348633, 0.953125\n",
      "Train loss and acc of batch 53: 47.99026870727539, 1.0\n",
      "Train loss and acc of batch 54: 48.20701599121094, 0.984375\n",
      "Train loss and acc of batch 55: 47.99024963378906, 1.0\n",
      "Train loss and acc of batch 56: 47.990238189697266, 1.0\n",
      "Train loss and acc of batch 57: 48.58592987060547, 0.984375\n",
      "Train loss and acc of batch 58: 47.99021911621094, 1.0\n",
      "Train loss and acc of batch 59: 47.990211486816406, 1.0\n",
      "Train loss and acc of batch 60: 47.99020004272461, 1.0\n",
      "Train loss and acc of batch 61: 47.99019241333008, 1.0\n",
      "Train loss and acc of batch 62: 48.206947326660156, 0.984375\n",
      "Train loss and acc of batch 63: 49.181575775146484, 0.96875\n",
      "Train loss and acc of batch 64: 48.206932067871094, 0.984375\n",
      "Train loss and acc of batch 65: 47.990150451660156, 1.0\n",
      "Train loss and acc of batch 66: 47.990150451660156, 1.0\n",
      "Train loss and acc of batch 67: 48.802608489990234, 0.96875\n",
      "Train loss and acc of batch 68: 48.58583068847656, 0.984375\n",
      "Train loss and acc of batch 69: 48.206886291503906, 0.984375\n",
      "Train loss and acc of batch 70: 47.9901123046875, 1.0\n",
      "Training accuracy and loss of epoch #108: 0.9890, 48.3214\n",
      "Saved model by train loss 48.321439931090445\n",
      "Train loss and acc of batch 0: 47.9901008605957, 1.0\n",
      "Train loss and acc of batch 1: 47.99009704589844, 1.0\n",
      "Train loss and acc of batch 2: 48.27593231201172, 0.984375\n",
      "Train loss and acc of batch 3: 48.20684051513672, 0.984375\n",
      "Train loss and acc of batch 4: 47.99007034301758, 1.0\n",
      "Train loss and acc of batch 5: 49.3389892578125, 0.96875\n",
      "Train loss and acc of batch 6: 48.4926643371582, 0.96875\n",
      "Train loss and acc of batch 7: 47.99003601074219, 1.0\n",
      "Train loss and acc of batch 8: 48.585731506347656, 0.984375\n",
      "Train loss and acc of batch 9: 48.27587127685547, 0.984375\n",
      "Train loss and acc of batch 10: 47.990013122558594, 1.0\n",
      "Train loss and acc of batch 11: 47.9900016784668, 1.0\n",
      "Train loss and acc of batch 12: 48.743221282958984, 0.984375\n",
      "Train loss and acc of batch 13: 48.206756591796875, 0.984375\n",
      "Train loss and acc of batch 14: 48.20674133300781, 0.984375\n",
      "Train loss and acc of batch 15: 48.585670471191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.585662841796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.7431755065918, 0.984375\n",
      "Train loss and acc of batch 18: 48.871498107910156, 0.96875\n",
      "Train loss and acc of batch 19: 47.98993682861328, 1.0\n",
      "Train loss and acc of batch 20: 47.989925384521484, 1.0\n",
      "Train loss and acc of batch 21: 48.58561706542969, 0.984375\n",
      "Train loss and acc of batch 22: 48.585601806640625, 0.984375\n",
      "Train loss and acc of batch 23: 48.2066650390625, 0.984375\n",
      "Train loss and acc of batch 24: 48.585594177246094, 0.984375\n",
      "Train loss and acc of batch 25: 47.98987579345703, 1.0\n",
      "Train loss and acc of batch 26: 47.989871978759766, 1.0\n",
      "Train loss and acc of batch 27: 47.989864349365234, 1.0\n",
      "Train loss and acc of batch 28: 47.98985290527344, 1.0\n",
      "Train loss and acc of batch 29: 48.585548400878906, 0.984375\n",
      "Train loss and acc of batch 30: 47.98983383178711, 1.0\n",
      "Train loss and acc of batch 31: 48.20658874511719, 0.984375\n",
      "Train loss and acc of batch 32: 47.98982238769531, 1.0\n",
      "Train loss and acc of batch 33: 47.989810943603516, 1.0\n",
      "Train loss and acc of batch 34: 48.58550262451172, 0.984375\n",
      "Train loss and acc of batch 35: 48.423316955566406, 0.96875\n",
      "Train loss and acc of batch 36: 47.98978042602539, 1.0\n",
      "Train loss and acc of batch 37: 48.74299240112305, 0.984375\n",
      "Train loss and acc of batch 38: 49.33869171142578, 0.96875\n",
      "Train loss and acc of batch 39: 48.206520080566406, 0.984375\n",
      "Train loss and acc of batch 40: 47.989749908447266, 1.0\n",
      "Train loss and acc of batch 41: 49.33866500854492, 0.96875\n",
      "Train loss and acc of batch 42: 47.989723205566406, 1.0\n",
      "Train loss and acc of batch 43: 48.585418701171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.989707946777344, 1.0\n",
      "Train loss and acc of batch 45: 48.58540344238281, 0.984375\n",
      "Train loss and acc of batch 46: 48.275550842285156, 0.984375\n",
      "Train loss and acc of batch 47: 47.98968505859375, 1.0\n",
      "Train loss and acc of batch 48: 47.98967361450195, 1.0\n",
      "Train loss and acc of batch 49: 47.98966598510742, 1.0\n",
      "Train loss and acc of batch 50: 48.585357666015625, 0.984375\n",
      "Train loss and acc of batch 51: 49.33856964111328, 0.96875\n",
      "Train loss and acc of batch 52: 49.245479583740234, 0.953125\n",
      "Train loss and acc of batch 53: 47.989627838134766, 1.0\n",
      "Train loss and acc of batch 54: 48.206382751464844, 0.984375\n",
      "Train loss and acc of batch 55: 47.9896125793457, 1.0\n",
      "Train loss and acc of batch 56: 47.98960494995117, 1.0\n",
      "Train loss and acc of batch 57: 48.585296630859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.989585876464844, 1.0\n",
      "Train loss and acc of batch 59: 47.98957443237305, 1.0\n",
      "Train loss and acc of batch 60: 47.989566802978516, 1.0\n",
      "Train loss and acc of batch 61: 47.98956298828125, 1.0\n",
      "Train loss and acc of batch 62: 48.20631408691406, 0.984375\n",
      "Train loss and acc of batch 63: 49.18094253540039, 0.96875\n",
      "Train loss and acc of batch 64: 48.20629119873047, 0.984375\n",
      "Train loss and acc of batch 65: 47.98952102661133, 1.0\n",
      "Train loss and acc of batch 66: 47.9895133972168, 1.0\n",
      "Train loss and acc of batch 67: 48.80196762084961, 0.96875\n",
      "Train loss and acc of batch 68: 48.58519744873047, 0.984375\n",
      "Train loss and acc of batch 69: 48.20625305175781, 0.984375\n",
      "Train loss and acc of batch 70: 47.989479064941406, 1.0\n",
      "Training accuracy and loss of epoch #109: 0.9890, 48.3208\n",
      "Saved model by train loss 48.32080610033492\n",
      "Train loss and acc of batch 0: 47.98946762084961, 1.0\n",
      "Train loss and acc of batch 1: 47.98945999145508, 1.0\n",
      "Train loss and acc of batch 2: 48.275299072265625, 0.984375\n",
      "Train loss and acc of batch 3: 48.206207275390625, 0.984375\n",
      "Train loss and acc of batch 4: 47.98943328857422, 1.0\n",
      "Train loss and acc of batch 5: 49.338348388671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.49203109741211, 0.96875\n",
      "Train loss and acc of batch 7: 47.98940658569336, 1.0\n",
      "Train loss and acc of batch 8: 48.58509826660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.275238037109375, 0.984375\n",
      "Train loss and acc of batch 10: 47.989376068115234, 1.0\n",
      "Train loss and acc of batch 11: 47.98937225341797, 1.0\n",
      "Train loss and acc of batch 12: 48.742584228515625, 0.984375\n",
      "Train loss and acc of batch 13: 48.20611572265625, 0.984375\n",
      "Train loss and acc of batch 14: 48.20611572265625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 15: 48.58503723144531, 0.984375\n",
      "Train loss and acc of batch 16: 48.58502197265625, 0.984375\n",
      "Train loss and acc of batch 17: 48.7425422668457, 0.984375\n",
      "Train loss and acc of batch 18: 48.87086486816406, 0.96875\n",
      "Train loss and acc of batch 19: 47.98929977416992, 1.0\n",
      "Train loss and acc of batch 20: 47.98929214477539, 1.0\n",
      "Train loss and acc of batch 21: 48.584983825683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.58497619628906, 0.984375\n",
      "Train loss and acc of batch 23: 48.206031799316406, 0.984375\n",
      "Train loss and acc of batch 24: 48.58495330810547, 0.984375\n",
      "Train loss and acc of batch 25: 47.9892463684082, 1.0\n",
      "Train loss and acc of batch 26: 47.98923873901367, 1.0\n",
      "Train loss and acc of batch 27: 47.98923110961914, 1.0\n",
      "Train loss and acc of batch 28: 47.989219665527344, 1.0\n",
      "Train loss and acc of batch 29: 48.58491516113281, 0.984375\n",
      "Train loss and acc of batch 30: 47.989200592041016, 1.0\n",
      "Train loss and acc of batch 31: 48.205955505371094, 0.984375\n",
      "Train loss and acc of batch 32: 47.98918151855469, 1.0\n",
      "Train loss and acc of batch 33: 47.989173889160156, 1.0\n",
      "Train loss and acc of batch 34: 48.584869384765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.42268371582031, 0.96875\n",
      "Train loss and acc of batch 36: 47.9891471862793, 1.0\n",
      "Train loss and acc of batch 37: 48.74236297607422, 0.984375\n",
      "Train loss and acc of batch 38: 49.338050842285156, 0.96875\n",
      "Train loss and acc of batch 39: 48.20588684082031, 0.984375\n",
      "Train loss and acc of batch 40: 47.989112854003906, 1.0\n",
      "Train loss and acc of batch 41: 49.33803176879883, 0.96875\n",
      "Train loss and acc of batch 42: 47.98909378051758, 1.0\n",
      "Train loss and acc of batch 43: 48.58479309082031, 0.984375\n",
      "Train loss and acc of batch 44: 47.989078521728516, 1.0\n",
      "Train loss and acc of batch 45: 48.58477020263672, 0.984375\n",
      "Train loss and acc of batch 46: 48.27490997314453, 0.984375\n",
      "Train loss and acc of batch 47: 47.989044189453125, 1.0\n",
      "Train loss and acc of batch 48: 47.98904037475586, 1.0\n",
      "Train loss and acc of batch 49: 47.98903274536133, 1.0\n",
      "Train loss and acc of batch 50: 48.58472442626953, 0.984375\n",
      "Train loss and acc of batch 51: 49.33793640136719, 0.96875\n",
      "Train loss and acc of batch 52: 49.244842529296875, 0.953125\n",
      "Train loss and acc of batch 53: 47.98899459838867, 1.0\n",
      "Train loss and acc of batch 54: 48.20575714111328, 0.984375\n",
      "Train loss and acc of batch 55: 47.98897933959961, 1.0\n",
      "Train loss and acc of batch 56: 47.98897171020508, 1.0\n",
      "Train loss and acc of batch 57: 48.58465576171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.988956451416016, 1.0\n",
      "Train loss and acc of batch 59: 47.98894119262695, 1.0\n",
      "Train loss and acc of batch 60: 47.988929748535156, 1.0\n",
      "Train loss and acc of batch 61: 47.988922119140625, 1.0\n",
      "Train loss and acc of batch 62: 48.20568084716797, 0.984375\n",
      "Train loss and acc of batch 63: 49.1803092956543, 0.96875\n",
      "Train loss and acc of batch 64: 48.205665588378906, 0.984375\n",
      "Train loss and acc of batch 65: 47.988887786865234, 1.0\n",
      "Train loss and acc of batch 66: 47.98887634277344, 1.0\n",
      "Train loss and acc of batch 67: 48.80133819580078, 0.96875\n",
      "Train loss and acc of batch 68: 48.584564208984375, 0.984375\n",
      "Train loss and acc of batch 69: 48.20561981201172, 0.984375\n",
      "Train loss and acc of batch 70: 47.98884582519531, 1.0\n",
      "Training accuracy and loss of epoch #110: 0.9890, 48.3202\n",
      "Saved model by train loss 48.32017221585126\n",
      "Train loss and acc of batch 0: 47.98883819580078, 1.0\n",
      "Train loss and acc of batch 1: 47.98883056640625, 1.0\n",
      "Train loss and acc of batch 2: 48.27467346191406, 0.984375\n",
      "Train loss and acc of batch 3: 48.20556640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.988800048828125, 1.0\n",
      "Train loss and acc of batch 5: 49.33771514892578, 0.96875\n",
      "Train loss and acc of batch 6: 48.49140167236328, 0.96875\n",
      "Train loss and acc of batch 7: 47.988773345947266, 1.0\n",
      "Train loss and acc of batch 8: 48.58446502685547, 0.984375\n",
      "Train loss and acc of batch 9: 48.27460479736328, 0.984375\n",
      "Train loss and acc of batch 10: 47.988746643066406, 1.0\n",
      "Train loss and acc of batch 11: 47.988739013671875, 1.0\n",
      "Train loss and acc of batch 12: 48.7419548034668, 0.984375\n",
      "Train loss and acc of batch 13: 48.205482482910156, 0.984375\n",
      "Train loss and acc of batch 14: 48.205474853515625, 0.984375\n",
      "Train loss and acc of batch 15: 48.58440399169922, 0.984375\n",
      "Train loss and acc of batch 16: 48.58439636230469, 0.984375\n",
      "Train loss and acc of batch 17: 48.741905212402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.8702278137207, 0.96875\n",
      "Train loss and acc of batch 19: 47.98866653442383, 1.0\n",
      "Train loss and acc of batch 20: 47.9886589050293, 1.0\n",
      "Train loss and acc of batch 21: 48.5843505859375, 0.984375\n",
      "Train loss and acc of batch 22: 48.58434295654297, 0.984375\n",
      "Train loss and acc of batch 23: 48.20539093017578, 0.984375\n",
      "Train loss and acc of batch 24: 48.584320068359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.98861312866211, 1.0\n",
      "Train loss and acc of batch 26: 47.98860168457031, 1.0\n",
      "Train loss and acc of batch 27: 47.98859405517578, 1.0\n",
      "Train loss and acc of batch 28: 47.988590240478516, 1.0\n",
      "Train loss and acc of batch 29: 48.58428192138672, 0.984375\n",
      "Train loss and acc of batch 30: 47.98856735229492, 1.0\n",
      "Train loss and acc of batch 31: 48.205322265625, 0.984375\n",
      "Train loss and acc of batch 32: 47.98854446411133, 1.0\n",
      "Train loss and acc of batch 33: 47.98854064941406, 1.0\n",
      "Train loss and acc of batch 34: 48.584228515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.422054290771484, 0.96875\n",
      "Train loss and acc of batch 36: 47.98851776123047, 1.0\n",
      "Train loss and acc of batch 37: 48.741729736328125, 0.984375\n",
      "Train loss and acc of batch 38: 49.33741760253906, 0.96875\n",
      "Train loss and acc of batch 39: 48.20525360107422, 0.984375\n",
      "Train loss and acc of batch 40: 47.98847579956055, 1.0\n",
      "Train loss and acc of batch 41: 49.33739471435547, 0.96875\n",
      "Train loss and acc of batch 42: 47.98845672607422, 1.0\n",
      "Train loss and acc of batch 43: 48.58415985107422, 0.984375\n",
      "Train loss and acc of batch 44: 47.98844528198242, 1.0\n",
      "Train loss and acc of batch 45: 48.584136962890625, 0.984375\n",
      "Train loss and acc of batch 46: 48.27427673339844, 0.984375\n",
      "Train loss and acc of batch 47: 47.98841857910156, 1.0\n",
      "Train loss and acc of batch 48: 47.9884033203125, 1.0\n",
      "Train loss and acc of batch 49: 47.988399505615234, 1.0\n",
      "Train loss and acc of batch 50: 48.58409118652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.337303161621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.24421310424805, 0.953125\n",
      "Train loss and acc of batch 53: 47.98836135864258, 1.0\n",
      "Train loss and acc of batch 54: 48.205116271972656, 0.984375\n",
      "Train loss and acc of batch 55: 47.988346099853516, 1.0\n",
      "Train loss and acc of batch 56: 47.98833465576172, 1.0\n",
      "Train loss and acc of batch 57: 48.58403015136719, 0.984375\n",
      "Train loss and acc of batch 58: 47.988319396972656, 1.0\n",
      "Train loss and acc of batch 59: 47.98830795288086, 1.0\n",
      "Train loss and acc of batch 60: 47.98830032348633, 1.0\n",
      "Train loss and acc of batch 61: 47.98828887939453, 1.0\n",
      "Train loss and acc of batch 62: 48.205047607421875, 0.984375\n",
      "Train loss and acc of batch 63: 49.1796760559082, 0.96875\n",
      "Train loss and acc of batch 64: 48.20502471923828, 0.984375\n",
      "Train loss and acc of batch 65: 47.98825454711914, 1.0\n",
      "Train loss and acc of batch 66: 47.98824691772461, 1.0\n",
      "Train loss and acc of batch 67: 48.80070114135742, 0.96875\n",
      "Train loss and acc of batch 68: 48.58393096923828, 0.984375\n",
      "Train loss and acc of batch 69: 48.204978942871094, 0.984375\n",
      "Train loss and acc of batch 70: 47.98820877075195, 1.0\n",
      "Training accuracy and loss of epoch #111: 0.9890, 48.3195\n",
      "Saved model by train loss 48.31953854628012\n",
      "Train loss and acc of batch 0: 47.98820114135742, 1.0\n",
      "Train loss and acc of batch 1: 47.98819351196289, 1.0\n",
      "Train loss and acc of batch 2: 48.27403259277344, 0.984375\n",
      "Train loss and acc of batch 3: 48.20494079589844, 0.984375\n",
      "Train loss and acc of batch 4: 47.98816680908203, 1.0\n",
      "Train loss and acc of batch 5: 49.33708190917969, 0.96875\n",
      "Train loss and acc of batch 6: 48.49076461791992, 0.96875\n",
      "Train loss and acc of batch 7: 47.98814010620117, 1.0\n",
      "Train loss and acc of batch 8: 48.583831787109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.27397155761719, 0.984375\n",
      "Train loss and acc of batch 10: 47.98810958862305, 1.0\n",
      "Train loss and acc of batch 11: 47.988101959228516, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 12: 48.74131774902344, 0.984375\n",
      "Train loss and acc of batch 13: 48.20484924316406, 0.984375\n",
      "Train loss and acc of batch 14: 48.20484161376953, 0.984375\n",
      "Train loss and acc of batch 15: 48.583770751953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.583763122558594, 0.984375\n",
      "Train loss and acc of batch 17: 48.74127197265625, 0.984375\n",
      "Train loss and acc of batch 18: 48.86959457397461, 0.96875\n",
      "Train loss and acc of batch 19: 47.98802947998047, 1.0\n",
      "Train loss and acc of batch 20: 47.9880256652832, 1.0\n",
      "Train loss and acc of batch 21: 48.583709716796875, 0.984375\n",
      "Train loss and acc of batch 22: 48.583709716796875, 0.984375\n",
      "Train loss and acc of batch 23: 48.20476531982422, 0.984375\n",
      "Train loss and acc of batch 24: 48.58368682861328, 0.984375\n",
      "Train loss and acc of batch 25: 47.98797607421875, 1.0\n",
      "Train loss and acc of batch 26: 47.98796844482422, 1.0\n",
      "Train loss and acc of batch 27: 47.98795700073242, 1.0\n",
      "Train loss and acc of batch 28: 47.987953186035156, 1.0\n",
      "Train loss and acc of batch 29: 48.583641052246094, 0.984375\n",
      "Train loss and acc of batch 30: 47.98793411254883, 1.0\n",
      "Train loss and acc of batch 31: 48.204689025878906, 0.984375\n",
      "Train loss and acc of batch 32: 47.987911224365234, 1.0\n",
      "Train loss and acc of batch 33: 47.98790740966797, 1.0\n",
      "Train loss and acc of batch 34: 48.58360290527344, 0.984375\n",
      "Train loss and acc of batch 35: 48.42141342163086, 0.96875\n",
      "Train loss and acc of batch 36: 47.98788070678711, 1.0\n",
      "Train loss and acc of batch 37: 48.741092681884766, 0.984375\n",
      "Train loss and acc of batch 38: 49.33678436279297, 0.96875\n",
      "Train loss and acc of batch 39: 48.204620361328125, 0.984375\n",
      "Train loss and acc of batch 40: 47.98783874511719, 1.0\n",
      "Train loss and acc of batch 41: 49.336761474609375, 0.96875\n",
      "Train loss and acc of batch 42: 47.987831115722656, 1.0\n",
      "Train loss and acc of batch 43: 48.583518981933594, 0.984375\n",
      "Train loss and acc of batch 44: 47.98780822753906, 1.0\n",
      "Train loss and acc of batch 45: 48.58350372314453, 0.984375\n",
      "Train loss and acc of batch 46: 48.27363586425781, 0.984375\n",
      "Train loss and acc of batch 47: 47.9877815246582, 1.0\n",
      "Train loss and acc of batch 48: 47.98776626586914, 1.0\n",
      "Train loss and acc of batch 49: 47.987762451171875, 1.0\n",
      "Train loss and acc of batch 50: 48.583457946777344, 0.984375\n",
      "Train loss and acc of batch 51: 49.336669921875, 0.96875\n",
      "Train loss and acc of batch 52: 49.24357986450195, 0.953125\n",
      "Train loss and acc of batch 53: 47.98773193359375, 1.0\n",
      "Train loss and acc of batch 54: 48.20448303222656, 0.984375\n",
      "Train loss and acc of batch 55: 47.987709045410156, 1.0\n",
      "Train loss and acc of batch 56: 47.98770523071289, 1.0\n",
      "Train loss and acc of batch 57: 48.583396911621094, 0.984375\n",
      "Train loss and acc of batch 58: 47.98767852783203, 1.0\n",
      "Train loss and acc of batch 59: 47.9876708984375, 1.0\n",
      "Train loss and acc of batch 60: 47.9876594543457, 1.0\n",
      "Train loss and acc of batch 61: 47.98765563964844, 1.0\n",
      "Train loss and acc of batch 62: 48.20440673828125, 0.984375\n",
      "Train loss and acc of batch 63: 49.17903518676758, 0.96875\n",
      "Train loss and acc of batch 64: 48.20439147949219, 0.984375\n",
      "Train loss and acc of batch 65: 47.98761749267578, 1.0\n",
      "Train loss and acc of batch 66: 47.98760986328125, 1.0\n",
      "Train loss and acc of batch 67: 48.80006790161133, 0.96875\n",
      "Train loss and acc of batch 68: 48.583290100097656, 0.984375\n",
      "Train loss and acc of batch 69: 48.204345703125, 0.984375\n",
      "Train loss and acc of batch 70: 47.98757553100586, 1.0\n",
      "Training accuracy and loss of epoch #112: 0.9890, 48.3189\n",
      "Saved model by train loss 48.31890353350572\n",
      "Train loss and acc of batch 0: 47.98756408691406, 1.0\n",
      "Train loss and acc of batch 1: 47.98755645751953, 1.0\n",
      "Train loss and acc of batch 2: 48.273399353027344, 0.984375\n",
      "Train loss and acc of batch 3: 48.20429992675781, 0.984375\n",
      "Train loss and acc of batch 4: 47.98753356933594, 1.0\n",
      "Train loss and acc of batch 5: 49.33644104003906, 0.96875\n",
      "Train loss and acc of batch 6: 48.4901237487793, 0.96875\n",
      "Train loss and acc of batch 7: 47.98750305175781, 1.0\n",
      "Train loss and acc of batch 8: 48.58319854736328, 0.984375\n",
      "Train loss and acc of batch 9: 48.273338317871094, 0.984375\n",
      "Train loss and acc of batch 10: 47.98747634887695, 1.0\n",
      "Train loss and acc of batch 11: 47.987464904785156, 1.0\n",
      "Train loss and acc of batch 12: 48.74067687988281, 0.984375\n",
      "Train loss and acc of batch 13: 48.20421600341797, 0.984375\n",
      "Train loss and acc of batch 14: 48.204200744628906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5831298828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.5831298828125, 0.984375\n",
      "Train loss and acc of batch 17: 48.74063491821289, 0.984375\n",
      "Train loss and acc of batch 18: 48.868961334228516, 0.96875\n",
      "Train loss and acc of batch 19: 47.987396240234375, 1.0\n",
      "Train loss and acc of batch 20: 47.98738479614258, 1.0\n",
      "Train loss and acc of batch 21: 48.58307647705078, 0.984375\n",
      "Train loss and acc of batch 22: 48.58306884765625, 0.984375\n",
      "Train loss and acc of batch 23: 48.204124450683594, 0.984375\n",
      "Train loss and acc of batch 24: 48.58305358886719, 0.984375\n",
      "Train loss and acc of batch 25: 47.98733901977539, 1.0\n",
      "Train loss and acc of batch 26: 47.98733139038086, 1.0\n",
      "Train loss and acc of batch 27: 47.98731994628906, 1.0\n",
      "Train loss and acc of batch 28: 47.98731231689453, 1.0\n",
      "Train loss and acc of batch 29: 48.5830078125, 0.984375\n",
      "Train loss and acc of batch 30: 47.98729705810547, 1.0\n",
      "Train loss and acc of batch 31: 48.20405578613281, 0.984375\n",
      "Train loss and acc of batch 32: 47.987281799316406, 1.0\n",
      "Train loss and acc of batch 33: 47.98726272583008, 1.0\n",
      "Train loss and acc of batch 34: 48.58296203613281, 0.984375\n",
      "Train loss and acc of batch 35: 48.420780181884766, 0.96875\n",
      "Train loss and acc of batch 36: 47.987247467041016, 1.0\n",
      "Train loss and acc of batch 37: 48.740455627441406, 0.984375\n",
      "Train loss and acc of batch 38: 49.336143493652344, 0.96875\n",
      "Train loss and acc of batch 39: 48.2039794921875, 0.984375\n",
      "Train loss and acc of batch 40: 47.98720932006836, 1.0\n",
      "Train loss and acc of batch 41: 49.33612060546875, 0.96875\n",
      "Train loss and acc of batch 42: 47.987186431884766, 1.0\n",
      "Train loss and acc of batch 43: 48.58287811279297, 0.984375\n",
      "Train loss and acc of batch 44: 47.9871711730957, 1.0\n",
      "Train loss and acc of batch 45: 48.582862854003906, 0.984375\n",
      "Train loss and acc of batch 46: 48.27301025390625, 0.984375\n",
      "Train loss and acc of batch 47: 47.98714828491211, 1.0\n",
      "Train loss and acc of batch 48: 47.98713302612305, 1.0\n",
      "Train loss and acc of batch 49: 47.987125396728516, 1.0\n",
      "Train loss and acc of batch 50: 48.58281707763672, 0.984375\n",
      "Train loss and acc of batch 51: 49.336029052734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.24293518066406, 0.953125\n",
      "Train loss and acc of batch 53: 47.987091064453125, 1.0\n",
      "Train loss and acc of batch 54: 48.20384979248047, 0.984375\n",
      "Train loss and acc of batch 55: 47.9870719909668, 1.0\n",
      "Train loss and acc of batch 56: 47.987064361572266, 1.0\n",
      "Train loss and acc of batch 57: 48.58275604248047, 0.984375\n",
      "Train loss and acc of batch 58: 47.98704528808594, 1.0\n",
      "Train loss and acc of batch 59: 47.987037658691406, 1.0\n",
      "Train loss and acc of batch 60: 47.987030029296875, 1.0\n",
      "Train loss and acc of batch 61: 47.98701858520508, 1.0\n",
      "Train loss and acc of batch 62: 48.203773498535156, 0.984375\n",
      "Train loss and acc of batch 63: 49.17840576171875, 0.96875\n",
      "Train loss and acc of batch 64: 48.203758239746094, 0.984375\n",
      "Train loss and acc of batch 65: 47.98698425292969, 1.0\n",
      "Train loss and acc of batch 66: 47.986976623535156, 1.0\n",
      "Train loss and acc of batch 67: 48.799434661865234, 0.96875\n",
      "Train loss and acc of batch 68: 48.58265686035156, 0.984375\n",
      "Train loss and acc of batch 69: 48.203712463378906, 0.984375\n",
      "Train loss and acc of batch 70: 47.986934661865234, 1.0\n",
      "Training accuracy and loss of epoch #113: 0.9890, 48.3183\n",
      "Saved model by train loss 48.31826701634367\n",
      "Train loss and acc of batch 0: 47.9869270324707, 1.0\n",
      "Train loss and acc of batch 1: 47.98691940307617, 1.0\n",
      "Train loss and acc of batch 2: 48.27276611328125, 0.984375\n",
      "Train loss and acc of batch 3: 48.20366668701172, 0.984375\n",
      "Train loss and acc of batch 4: 47.98689651489258, 1.0\n",
      "Train loss and acc of batch 5: 49.33580780029297, 0.96875\n",
      "Train loss and acc of batch 6: 48.48949432373047, 0.96875\n",
      "Train loss and acc of batch 7: 47.98686599731445, 1.0\n",
      "Train loss and acc of batch 8: 48.582557678222656, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 9: 48.27269744873047, 0.984375\n",
      "Train loss and acc of batch 10: 47.986839294433594, 1.0\n",
      "Train loss and acc of batch 11: 47.98683166503906, 1.0\n",
      "Train loss and acc of batch 12: 48.740047454833984, 0.984375\n",
      "Train loss and acc of batch 13: 48.203582763671875, 0.984375\n",
      "Train loss and acc of batch 14: 48.20356750488281, 0.984375\n",
      "Train loss and acc of batch 15: 48.582496643066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.582489013671875, 0.984375\n",
      "Train loss and acc of batch 17: 48.7400016784668, 0.984375\n",
      "Train loss and acc of batch 18: 48.86832046508789, 0.96875\n",
      "Train loss and acc of batch 19: 47.98676300048828, 1.0\n",
      "Train loss and acc of batch 20: 47.986751556396484, 1.0\n",
      "Train loss and acc of batch 21: 48.58244323730469, 0.984375\n",
      "Train loss and acc of batch 22: 48.582435607910156, 0.984375\n",
      "Train loss and acc of batch 23: 48.2034912109375, 0.984375\n",
      "Train loss and acc of batch 24: 48.582420349121094, 0.984375\n",
      "Train loss and acc of batch 25: 47.98670959472656, 1.0\n",
      "Train loss and acc of batch 26: 47.986698150634766, 1.0\n",
      "Train loss and acc of batch 27: 47.986690521240234, 1.0\n",
      "Train loss and acc of batch 28: 47.98667526245117, 1.0\n",
      "Train loss and acc of batch 29: 48.582366943359375, 0.984375\n",
      "Train loss and acc of batch 30: 47.98666000366211, 1.0\n",
      "Train loss and acc of batch 31: 48.20342254638672, 0.984375\n",
      "Train loss and acc of batch 32: 47.98664474487305, 1.0\n",
      "Train loss and acc of batch 33: 47.986637115478516, 1.0\n",
      "Train loss and acc of batch 34: 48.58232879638672, 0.984375\n",
      "Train loss and acc of batch 35: 48.42014694213867, 0.96875\n",
      "Train loss and acc of batch 36: 47.98660659790039, 1.0\n",
      "Train loss and acc of batch 37: 48.73982620239258, 0.984375\n",
      "Train loss and acc of batch 38: 49.33551025390625, 0.96875\n",
      "Train loss and acc of batch 39: 48.203346252441406, 0.984375\n",
      "Train loss and acc of batch 40: 47.986572265625, 1.0\n",
      "Train loss and acc of batch 41: 49.33549118041992, 0.96875\n",
      "Train loss and acc of batch 42: 47.98655319213867, 1.0\n",
      "Train loss and acc of batch 43: 48.582244873046875, 0.984375\n",
      "Train loss and acc of batch 44: 47.98653793334961, 1.0\n",
      "Train loss and acc of batch 45: 48.58222961425781, 0.984375\n",
      "Train loss and acc of batch 46: 48.272369384765625, 0.984375\n",
      "Train loss and acc of batch 47: 47.98651123046875, 1.0\n",
      "Train loss and acc of batch 48: 47.98650360107422, 1.0\n",
      "Train loss and acc of batch 49: 47.98649597167969, 1.0\n",
      "Train loss and acc of batch 50: 48.582183837890625, 0.984375\n",
      "Train loss and acc of batch 51: 49.33540344238281, 0.96875\n",
      "Train loss and acc of batch 52: 49.2423095703125, 0.953125\n",
      "Train loss and acc of batch 53: 47.98645782470703, 1.0\n",
      "Train loss and acc of batch 54: 48.203216552734375, 0.984375\n",
      "Train loss and acc of batch 55: 47.9864387512207, 1.0\n",
      "Train loss and acc of batch 56: 47.986427307128906, 1.0\n",
      "Train loss and acc of batch 57: 48.582122802734375, 0.984375\n",
      "Train loss and acc of batch 58: 47.986412048339844, 1.0\n",
      "Train loss and acc of batch 59: 47.98640441894531, 1.0\n",
      "Train loss and acc of batch 60: 47.98639678955078, 1.0\n",
      "Train loss and acc of batch 61: 47.986385345458984, 1.0\n",
      "Train loss and acc of batch 62: 48.203147888183594, 0.984375\n",
      "Train loss and acc of batch 63: 49.177772521972656, 0.96875\n",
      "Train loss and acc of batch 64: 48.203125, 0.984375\n",
      "Train loss and acc of batch 65: 47.986351013183594, 1.0\n",
      "Train loss and acc of batch 66: 47.9863395690918, 1.0\n",
      "Train loss and acc of batch 67: 48.798797607421875, 0.96875\n",
      "Train loss and acc of batch 68: 48.58202362060547, 0.984375\n",
      "Train loss and acc of batch 69: 48.20307922363281, 0.984375\n",
      "Train loss and acc of batch 70: 47.98630905151367, 1.0\n",
      "Training accuracy and loss of epoch #114: 0.9890, 48.3176\n",
      "Saved model by train loss 48.3176332930444\n",
      "Train loss and acc of batch 0: 47.98629379272461, 1.0\n",
      "Train loss and acc of batch 1: 47.98628616333008, 1.0\n",
      "Train loss and acc of batch 2: 48.272132873535156, 0.984375\n",
      "Train loss and acc of batch 3: 48.203033447265625, 0.984375\n",
      "Train loss and acc of batch 4: 47.98625946044922, 1.0\n",
      "Train loss and acc of batch 5: 49.335182189941406, 0.96875\n",
      "Train loss and acc of batch 6: 48.488861083984375, 0.96875\n",
      "Train loss and acc of batch 7: 47.986236572265625, 1.0\n",
      "Train loss and acc of batch 8: 48.58192443847656, 0.984375\n",
      "Train loss and acc of batch 9: 48.272071838378906, 0.984375\n",
      "Train loss and acc of batch 10: 47.986209869384766, 1.0\n",
      "Train loss and acc of batch 11: 47.9861946105957, 1.0\n",
      "Train loss and acc of batch 12: 48.73941421508789, 0.984375\n",
      "Train loss and acc of batch 13: 48.20294189453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.20293426513672, 0.984375\n",
      "Train loss and acc of batch 15: 48.58186340332031, 0.984375\n",
      "Train loss and acc of batch 16: 48.58185577392578, 0.984375\n",
      "Train loss and acc of batch 17: 48.7393684387207, 0.984375\n",
      "Train loss and acc of batch 18: 48.86769104003906, 0.96875\n",
      "Train loss and acc of batch 19: 47.98612594604492, 1.0\n",
      "Train loss and acc of batch 20: 47.98611831665039, 1.0\n",
      "Train loss and acc of batch 21: 48.581809997558594, 0.984375\n",
      "Train loss and acc of batch 22: 48.58180236816406, 0.984375\n",
      "Train loss and acc of batch 23: 48.202850341796875, 0.984375\n",
      "Train loss and acc of batch 24: 48.581787109375, 0.984375\n",
      "Train loss and acc of batch 25: 47.9860725402832, 1.0\n",
      "Train loss and acc of batch 26: 47.986061096191406, 1.0\n",
      "Train loss and acc of batch 27: 47.986053466796875, 1.0\n",
      "Train loss and acc of batch 28: 47.98604965209961, 1.0\n",
      "Train loss and acc of batch 29: 48.58174133300781, 0.984375\n",
      "Train loss and acc of batch 30: 47.98602294921875, 1.0\n",
      "Train loss and acc of batch 31: 48.202781677246094, 0.984375\n",
      "Train loss and acc of batch 32: 47.98600769042969, 1.0\n",
      "Train loss and acc of batch 33: 47.986000061035156, 1.0\n",
      "Train loss and acc of batch 34: 48.581695556640625, 0.984375\n",
      "Train loss and acc of batch 35: 48.41951370239258, 0.96875\n",
      "Train loss and acc of batch 36: 47.98596954345703, 1.0\n",
      "Train loss and acc of batch 37: 48.73918914794922, 0.984375\n",
      "Train loss and acc of batch 38: 49.33488464355469, 0.96875\n",
      "Train loss and acc of batch 39: 48.20271301269531, 0.984375\n",
      "Train loss and acc of batch 40: 47.98593521118164, 1.0\n",
      "Train loss and acc of batch 41: 49.33485794067383, 0.96875\n",
      "Train loss and acc of batch 42: 47.98591995239258, 1.0\n",
      "Train loss and acc of batch 43: 48.58161926269531, 0.984375\n",
      "Train loss and acc of batch 44: 47.985904693603516, 1.0\n",
      "Train loss and acc of batch 45: 48.58158874511719, 0.984375\n",
      "Train loss and acc of batch 46: 48.27174377441406, 0.984375\n",
      "Train loss and acc of batch 47: 47.985877990722656, 1.0\n",
      "Train loss and acc of batch 48: 47.985870361328125, 1.0\n",
      "Train loss and acc of batch 49: 47.985862731933594, 1.0\n",
      "Train loss and acc of batch 50: 48.58155059814453, 0.984375\n",
      "Train loss and acc of batch 51: 49.33477020263672, 0.96875\n",
      "Train loss and acc of batch 52: 49.24167251586914, 0.953125\n",
      "Train loss and acc of batch 53: 47.9858283996582, 1.0\n",
      "Train loss and acc of batch 54: 48.20257568359375, 0.984375\n",
      "Train loss and acc of batch 55: 47.98580551147461, 1.0\n",
      "Train loss and acc of batch 56: 47.98579406738281, 1.0\n",
      "Train loss and acc of batch 57: 48.58148956298828, 0.984375\n",
      "Train loss and acc of batch 58: 47.98577880859375, 1.0\n",
      "Train loss and acc of batch 59: 47.98577117919922, 1.0\n",
      "Train loss and acc of batch 60: 47.98576354980469, 1.0\n",
      "Train loss and acc of batch 61: 47.98575210571289, 1.0\n",
      "Train loss and acc of batch 62: 48.20250701904297, 0.984375\n",
      "Train loss and acc of batch 63: 49.17713928222656, 0.96875\n",
      "Train loss and acc of batch 64: 48.202491760253906, 0.984375\n",
      "Train loss and acc of batch 65: 47.9857177734375, 1.0\n",
      "Train loss and acc of batch 66: 47.9857063293457, 1.0\n",
      "Train loss and acc of batch 67: 48.79816818237305, 0.96875\n",
      "Train loss and acc of batch 68: 48.581390380859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.20243835449219, 0.984375\n",
      "Train loss and acc of batch 70: 47.98567199707031, 1.0\n",
      "Training accuracy and loss of epoch #115: 0.9890, 48.3170\n",
      "Saved model by train loss 48.31699956974513\n",
      "Train loss and acc of batch 0: 47.98566436767578, 1.0\n",
      "Train loss and acc of batch 1: 47.98565673828125, 1.0\n",
      "Train loss and acc of batch 2: 48.27149963378906, 0.984375\n",
      "Train loss and acc of batch 3: 48.20240020751953, 0.984375\n",
      "Train loss and acc of batch 4: 47.985626220703125, 1.0\n",
      "Train loss and acc of batch 5: 49.33454895019531, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 6: 48.48822784423828, 0.96875\n",
      "Train loss and acc of batch 7: 47.985599517822266, 1.0\n",
      "Train loss and acc of batch 8: 48.581298828125, 0.984375\n",
      "Train loss and acc of batch 9: 48.27143859863281, 0.984375\n",
      "Train loss and acc of batch 10: 47.98557662963867, 1.0\n",
      "Train loss and acc of batch 11: 47.98556900024414, 1.0\n",
      "Train loss and acc of batch 12: 48.7387809753418, 0.984375\n",
      "Train loss and acc of batch 13: 48.202308654785156, 0.984375\n",
      "Train loss and acc of batch 14: 48.202301025390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.58123016357422, 0.984375\n",
      "Train loss and acc of batch 16: 48.58122253417969, 0.984375\n",
      "Train loss and acc of batch 17: 48.738739013671875, 0.984375\n",
      "Train loss and acc of batch 18: 48.86705780029297, 0.96875\n",
      "Train loss and acc of batch 19: 47.985496520996094, 1.0\n",
      "Train loss and acc of batch 20: 47.9854850769043, 1.0\n",
      "Train loss and acc of batch 21: 48.5811767578125, 0.984375\n",
      "Train loss and acc of batch 22: 48.58116912841797, 0.984375\n",
      "Train loss and acc of batch 23: 48.20222473144531, 0.984375\n",
      "Train loss and acc of batch 24: 48.581146240234375, 0.984375\n",
      "Train loss and acc of batch 25: 47.98543930053711, 1.0\n",
      "Train loss and acc of batch 26: 47.98543167114258, 1.0\n",
      "Train loss and acc of batch 27: 47.98542022705078, 1.0\n",
      "Train loss and acc of batch 28: 47.98541259765625, 1.0\n",
      "Train loss and acc of batch 29: 48.58110809326172, 0.984375\n",
      "Train loss and acc of batch 30: 47.98539733886719, 1.0\n",
      "Train loss and acc of batch 31: 48.2021484375, 0.984375\n",
      "Train loss and acc of batch 32: 47.98537826538086, 1.0\n",
      "Train loss and acc of batch 33: 47.98537063598633, 1.0\n",
      "Train loss and acc of batch 34: 48.58106231689453, 0.984375\n",
      "Train loss and acc of batch 35: 48.418880462646484, 0.96875\n",
      "Train loss and acc of batch 36: 47.9853401184082, 1.0\n",
      "Train loss and acc of batch 37: 48.73855209350586, 0.984375\n",
      "Train loss and acc of batch 38: 49.334251403808594, 0.96875\n",
      "Train loss and acc of batch 39: 48.20207977294922, 0.984375\n",
      "Train loss and acc of batch 40: 47.98530578613281, 1.0\n",
      "Train loss and acc of batch 41: 49.33422088623047, 0.96875\n",
      "Train loss and acc of batch 42: 47.985286712646484, 1.0\n",
      "Train loss and acc of batch 43: 48.58097839355469, 0.984375\n",
      "Train loss and acc of batch 44: 47.98527145385742, 1.0\n",
      "Train loss and acc of batch 45: 48.580963134765625, 0.984375\n",
      "Train loss and acc of batch 46: 48.27111053466797, 0.984375\n",
      "Train loss and acc of batch 47: 47.98524475097656, 1.0\n",
      "Train loss and acc of batch 48: 47.985233306884766, 1.0\n",
      "Train loss and acc of batch 49: 47.985225677490234, 1.0\n",
      "Train loss and acc of batch 50: 48.58091735839844, 0.984375\n",
      "Train loss and acc of batch 51: 49.334129333496094, 0.96875\n",
      "Train loss and acc of batch 52: 49.24103927612305, 0.953125\n",
      "Train loss and acc of batch 53: 47.98518753051758, 1.0\n",
      "Train loss and acc of batch 54: 48.201942443847656, 0.984375\n",
      "Train loss and acc of batch 55: 47.985172271728516, 1.0\n",
      "Train loss and acc of batch 56: 47.985164642333984, 1.0\n",
      "Train loss and acc of batch 57: 48.58085632324219, 0.984375\n",
      "Train loss and acc of batch 58: 47.985145568847656, 1.0\n",
      "Train loss and acc of batch 59: 47.985137939453125, 1.0\n",
      "Train loss and acc of batch 60: 47.985130310058594, 1.0\n",
      "Train loss and acc of batch 61: 47.9851188659668, 1.0\n",
      "Train loss and acc of batch 62: 48.201881408691406, 0.984375\n",
      "Train loss and acc of batch 63: 49.17650604248047, 0.96875\n",
      "Train loss and acc of batch 64: 48.20185089111328, 0.984375\n",
      "Train loss and acc of batch 65: 47.98508071899414, 1.0\n",
      "Train loss and acc of batch 66: 47.98507308959961, 1.0\n",
      "Train loss and acc of batch 67: 48.79753112792969, 0.96875\n",
      "Train loss and acc of batch 68: 48.58075714111328, 0.984375\n",
      "Train loss and acc of batch 69: 48.201812744140625, 0.984375\n",
      "Train loss and acc of batch 70: 47.98503875732422, 1.0\n",
      "Training accuracy and loss of epoch #116: 0.9890, 48.3164\n",
      "Saved model by train loss 48.31636665236782\n",
      "Train loss and acc of batch 0: 47.98502731323242, 1.0\n",
      "Train loss and acc of batch 1: 47.98501968383789, 1.0\n",
      "Train loss and acc of batch 2: 48.27086639404297, 0.984375\n",
      "Train loss and acc of batch 3: 48.20176696777344, 0.984375\n",
      "Train loss and acc of batch 4: 47.98499298095703, 1.0\n",
      "Train loss and acc of batch 5: 49.33390808105469, 0.96875\n",
      "Train loss and acc of batch 6: 48.48759460449219, 0.96875\n",
      "Train loss and acc of batch 7: 47.98496627807617, 1.0\n",
      "Train loss and acc of batch 8: 48.580657958984375, 0.984375\n",
      "Train loss and acc of batch 9: 48.27079772949219, 0.984375\n",
      "Train loss and acc of batch 10: 47.98493576049805, 1.0\n",
      "Train loss and acc of batch 11: 47.984928131103516, 1.0\n",
      "Train loss and acc of batch 12: 48.7381477355957, 0.984375\n",
      "Train loss and acc of batch 13: 48.20167541503906, 0.984375\n",
      "Train loss and acc of batch 14: 48.20166778564453, 0.984375\n",
      "Train loss and acc of batch 15: 48.580596923828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.580589294433594, 0.984375\n",
      "Train loss and acc of batch 17: 48.738101959228516, 0.984375\n",
      "Train loss and acc of batch 18: 48.86642074584961, 0.96875\n",
      "Train loss and acc of batch 19: 47.984859466552734, 1.0\n",
      "Train loss and acc of batch 20: 47.9848518371582, 1.0\n",
      "Train loss and acc of batch 21: 48.580543518066406, 0.984375\n",
      "Train loss and acc of batch 22: 48.580528259277344, 0.984375\n",
      "Train loss and acc of batch 23: 48.20159149169922, 0.984375\n",
      "Train loss and acc of batch 24: 48.58051300048828, 0.984375\n",
      "Train loss and acc of batch 25: 47.984806060791016, 1.0\n",
      "Train loss and acc of batch 26: 47.984798431396484, 1.0\n",
      "Train loss and acc of batch 27: 47.98479080200195, 1.0\n",
      "Train loss and acc of batch 28: 47.98477554321289, 1.0\n",
      "Train loss and acc of batch 29: 48.580474853515625, 0.984375\n",
      "Train loss and acc of batch 30: 47.984764099121094, 1.0\n",
      "Train loss and acc of batch 31: 48.20152282714844, 0.984375\n",
      "Train loss and acc of batch 32: 47.98474884033203, 1.0\n",
      "Train loss and acc of batch 33: 47.9847297668457, 1.0\n",
      "Train loss and acc of batch 34: 48.58042907714844, 0.984375\n",
      "Train loss and acc of batch 35: 48.418243408203125, 0.96875\n",
      "Train loss and acc of batch 36: 47.98470687866211, 1.0\n",
      "Train loss and acc of batch 37: 48.73792266845703, 0.984375\n",
      "Train loss and acc of batch 38: 49.33361053466797, 0.96875\n",
      "Train loss and acc of batch 39: 48.201446533203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.98467254638672, 1.0\n",
      "Train loss and acc of batch 41: 49.333595275878906, 0.96875\n",
      "Train loss and acc of batch 42: 47.98465347290039, 1.0\n",
      "Train loss and acc of batch 43: 48.580345153808594, 0.984375\n",
      "Train loss and acc of batch 44: 47.98463439941406, 1.0\n",
      "Train loss and acc of batch 45: 48.58032989501953, 0.984375\n",
      "Train loss and acc of batch 46: 48.270469665527344, 0.984375\n",
      "Train loss and acc of batch 47: 47.9846076965332, 1.0\n",
      "Train loss and acc of batch 48: 47.98460006713867, 1.0\n",
      "Train loss and acc of batch 49: 47.98459243774414, 1.0\n",
      "Train loss and acc of batch 50: 48.580284118652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.33349609375, 0.96875\n",
      "Train loss and acc of batch 52: 49.24040603637695, 0.953125\n",
      "Train loss and acc of batch 53: 47.984554290771484, 1.0\n",
      "Train loss and acc of batch 54: 48.201316833496094, 0.984375\n",
      "Train loss and acc of batch 55: 47.984535217285156, 1.0\n",
      "Train loss and acc of batch 56: 47.984527587890625, 1.0\n",
      "Train loss and acc of batch 57: 48.580223083496094, 0.984375\n",
      "Train loss and acc of batch 58: 47.9845085144043, 1.0\n",
      "Train loss and acc of batch 59: 47.984500885009766, 1.0\n",
      "Train loss and acc of batch 60: 47.9844970703125, 1.0\n",
      "Train loss and acc of batch 61: 47.98448181152344, 1.0\n",
      "Train loss and acc of batch 62: 48.20124053955078, 0.984375\n",
      "Train loss and acc of batch 63: 49.17586898803711, 0.96875\n",
      "Train loss and acc of batch 64: 48.20122528076172, 0.984375\n",
      "Train loss and acc of batch 65: 47.98444747924805, 1.0\n",
      "Train loss and acc of batch 66: 47.98443603515625, 1.0\n",
      "Train loss and acc of batch 67: 48.79689407348633, 0.96875\n",
      "Train loss and acc of batch 68: 48.58012390136719, 0.984375\n",
      "Train loss and acc of batch 69: 48.20117950439453, 0.984375\n",
      "Train loss and acc of batch 70: 47.984405517578125, 1.0\n",
      "Training accuracy and loss of epoch #117: 0.9890, 48.3157\n",
      "Saved model by train loss 48.31573201569034\n",
      "Train loss and acc of batch 0: 47.984397888183594, 1.0\n",
      "Train loss and acc of batch 1: 47.9843864440918, 1.0\n",
      "Train loss and acc of batch 2: 48.270233154296875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 3: 48.201133728027344, 0.984375\n",
      "Train loss and acc of batch 4: 47.98435974121094, 1.0\n",
      "Train loss and acc of batch 5: 49.333274841308594, 0.96875\n",
      "Train loss and acc of batch 6: 48.48695755004883, 0.96875\n",
      "Train loss and acc of batch 7: 47.98433303833008, 1.0\n",
      "Train loss and acc of batch 8: 48.58002471923828, 0.984375\n",
      "Train loss and acc of batch 9: 48.270164489746094, 0.984375\n",
      "Train loss and acc of batch 10: 47.98430633544922, 1.0\n",
      "Train loss and acc of batch 11: 47.98429870605469, 1.0\n",
      "Train loss and acc of batch 12: 48.73751449584961, 0.984375\n",
      "Train loss and acc of batch 13: 48.20104217529297, 0.984375\n",
      "Train loss and acc of batch 14: 48.20103454589844, 0.984375\n",
      "Train loss and acc of batch 15: 48.5799560546875, 0.984375\n",
      "Train loss and acc of batch 16: 48.5799560546875, 0.984375\n",
      "Train loss and acc of batch 17: 48.73746109008789, 0.984375\n",
      "Train loss and acc of batch 18: 48.86578369140625, 0.96875\n",
      "Train loss and acc of batch 19: 47.98422622680664, 1.0\n",
      "Train loss and acc of batch 20: 47.98421859741211, 1.0\n",
      "Train loss and acc of batch 21: 48.57991027832031, 0.984375\n",
      "Train loss and acc of batch 22: 48.57990264892578, 0.984375\n",
      "Train loss and acc of batch 23: 48.200950622558594, 0.984375\n",
      "Train loss and acc of batch 24: 48.57987976074219, 0.984375\n",
      "Train loss and acc of batch 25: 47.98417282104492, 1.0\n",
      "Train loss and acc of batch 26: 47.984169006347656, 1.0\n",
      "Train loss and acc of batch 27: 47.984153747558594, 1.0\n",
      "Train loss and acc of batch 28: 47.98414993286133, 1.0\n",
      "Train loss and acc of batch 29: 48.579833984375, 0.984375\n",
      "Train loss and acc of batch 30: 47.984127044677734, 1.0\n",
      "Train loss and acc of batch 31: 48.20088195800781, 0.984375\n",
      "Train loss and acc of batch 32: 47.98410415649414, 1.0\n",
      "Train loss and acc of batch 33: 47.984100341796875, 1.0\n",
      "Train loss and acc of batch 34: 48.57978820800781, 0.984375\n",
      "Train loss and acc of batch 35: 48.41761016845703, 0.96875\n",
      "Train loss and acc of batch 36: 47.98407745361328, 1.0\n",
      "Train loss and acc of batch 37: 48.73728942871094, 0.984375\n",
      "Train loss and acc of batch 38: 49.332977294921875, 0.96875\n",
      "Train loss and acc of batch 39: 48.20081329345703, 0.984375\n",
      "Train loss and acc of batch 40: 47.984039306640625, 1.0\n",
      "Train loss and acc of batch 41: 49.33295822143555, 0.96875\n",
      "Train loss and acc of batch 42: 47.98402404785156, 1.0\n",
      "Train loss and acc of batch 43: 48.5797119140625, 0.984375\n",
      "Train loss and acc of batch 44: 47.9840087890625, 1.0\n",
      "Train loss and acc of batch 45: 48.57969665527344, 0.984375\n",
      "Train loss and acc of batch 46: 48.26982879638672, 0.984375\n",
      "Train loss and acc of batch 47: 47.983978271484375, 1.0\n",
      "Train loss and acc of batch 48: 47.98396682739258, 1.0\n",
      "Train loss and acc of batch 49: 47.98395919799805, 1.0\n",
      "Train loss and acc of batch 50: 48.57965087890625, 0.984375\n",
      "Train loss and acc of batch 51: 49.332862854003906, 0.96875\n",
      "Train loss and acc of batch 52: 49.239768981933594, 0.953125\n",
      "Train loss and acc of batch 53: 47.983924865722656, 1.0\n",
      "Train loss and acc of batch 54: 48.20067596435547, 0.984375\n",
      "Train loss and acc of batch 55: 47.98390579223633, 1.0\n",
      "Train loss and acc of batch 56: 47.9838981628418, 1.0\n",
      "Train loss and acc of batch 57: 48.57958984375, 0.984375\n",
      "Train loss and acc of batch 58: 47.98387908935547, 1.0\n",
      "Train loss and acc of batch 59: 47.983863830566406, 1.0\n",
      "Train loss and acc of batch 60: 47.983856201171875, 1.0\n",
      "Train loss and acc of batch 61: 47.98385238647461, 1.0\n",
      "Train loss and acc of batch 62: 48.20060729980469, 0.984375\n",
      "Train loss and acc of batch 63: 49.175235748291016, 0.96875\n",
      "Train loss and acc of batch 64: 48.200592041015625, 0.984375\n",
      "Train loss and acc of batch 65: 47.98381805419922, 1.0\n",
      "Train loss and acc of batch 66: 47.98380661010742, 1.0\n",
      "Train loss and acc of batch 67: 48.7962646484375, 0.96875\n",
      "Train loss and acc of batch 68: 48.579490661621094, 0.984375\n",
      "Train loss and acc of batch 69: 48.200538635253906, 0.984375\n",
      "Train loss and acc of batch 70: 47.98377227783203, 1.0\n",
      "Training accuracy and loss of epoch #118: 0.9890, 48.3151\n",
      "Saved model by train loss 48.31509834611919\n",
      "Train loss and acc of batch 0: 47.983760833740234, 1.0\n",
      "Train loss and acc of batch 1: 47.98375701904297, 1.0\n",
      "Train loss and acc of batch 2: 48.26959991455078, 0.984375\n",
      "Train loss and acc of batch 3: 48.20049285888672, 0.984375\n",
      "Train loss and acc of batch 4: 47.983726501464844, 1.0\n",
      "Train loss and acc of batch 5: 49.3326416015625, 0.96875\n",
      "Train loss and acc of batch 6: 48.486324310302734, 0.96875\n",
      "Train loss and acc of batch 7: 47.983699798583984, 1.0\n",
      "Train loss and acc of batch 8: 48.57939147949219, 0.984375\n",
      "Train loss and acc of batch 9: 48.26953887939453, 0.984375\n",
      "Train loss and acc of batch 10: 47.983673095703125, 1.0\n",
      "Train loss and acc of batch 11: 47.98366165161133, 1.0\n",
      "Train loss and acc of batch 12: 48.73687744140625, 0.984375\n",
      "Train loss and acc of batch 13: 48.200416564941406, 0.984375\n",
      "Train loss and acc of batch 14: 48.200401306152344, 0.984375\n",
      "Train loss and acc of batch 15: 48.57933044433594, 0.984375\n",
      "Train loss and acc of batch 16: 48.579315185546875, 0.984375\n",
      "Train loss and acc of batch 17: 48.73683166503906, 0.984375\n",
      "Train loss and acc of batch 18: 48.86515426635742, 0.96875\n",
      "Train loss and acc of batch 19: 47.98358917236328, 1.0\n",
      "Train loss and acc of batch 20: 47.98358154296875, 1.0\n",
      "Train loss and acc of batch 21: 48.57927703857422, 0.984375\n",
      "Train loss and acc of batch 22: 48.57926940917969, 0.984375\n",
      "Train loss and acc of batch 23: 48.20032501220703, 0.984375\n",
      "Train loss and acc of batch 24: 48.579246520996094, 0.984375\n",
      "Train loss and acc of batch 25: 47.98353576660156, 1.0\n",
      "Train loss and acc of batch 26: 47.98352813720703, 1.0\n",
      "Train loss and acc of batch 27: 47.983524322509766, 1.0\n",
      "Train loss and acc of batch 28: 47.98351287841797, 1.0\n",
      "Train loss and acc of batch 29: 48.57920837402344, 0.984375\n",
      "Train loss and acc of batch 30: 47.98349380493164, 1.0\n",
      "Train loss and acc of batch 31: 48.20024871826172, 0.984375\n",
      "Train loss and acc of batch 32: 47.98347854614258, 1.0\n",
      "Train loss and acc of batch 33: 47.983463287353516, 1.0\n",
      "Train loss and acc of batch 34: 48.57916259765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.41697692871094, 0.96875\n",
      "Train loss and acc of batch 36: 47.983436584472656, 1.0\n",
      "Train loss and acc of batch 37: 48.736656188964844, 0.984375\n",
      "Train loss and acc of batch 38: 49.33235168457031, 0.96875\n",
      "Train loss and acc of batch 39: 48.200172424316406, 0.984375\n",
      "Train loss and acc of batch 40: 47.98340606689453, 1.0\n",
      "Train loss and acc of batch 41: 49.33232116699219, 0.96875\n",
      "Train loss and acc of batch 42: 47.9833869934082, 1.0\n",
      "Train loss and acc of batch 43: 48.579078674316406, 0.984375\n",
      "Train loss and acc of batch 44: 47.983367919921875, 1.0\n",
      "Train loss and acc of batch 45: 48.57905578613281, 0.984375\n",
      "Train loss and acc of batch 46: 48.269203186035156, 0.984375\n",
      "Train loss and acc of batch 47: 47.983341217041016, 1.0\n",
      "Train loss and acc of batch 48: 47.983333587646484, 1.0\n",
      "Train loss and acc of batch 49: 47.98332214355469, 1.0\n",
      "Train loss and acc of batch 50: 48.579017639160156, 0.984375\n",
      "Train loss and acc of batch 51: 49.33222961425781, 0.96875\n",
      "Train loss and acc of batch 52: 49.23914337158203, 0.953125\n",
      "Train loss and acc of batch 53: 47.9832878112793, 1.0\n",
      "Train loss and acc of batch 54: 48.200042724609375, 0.984375\n",
      "Train loss and acc of batch 55: 47.983272552490234, 1.0\n",
      "Train loss and acc of batch 56: 47.98326110839844, 1.0\n",
      "Train loss and acc of batch 57: 48.578956604003906, 0.984375\n",
      "Train loss and acc of batch 58: 47.983238220214844, 1.0\n",
      "Train loss and acc of batch 59: 47.98323440551758, 1.0\n",
      "Train loss and acc of batch 60: 47.98322677612305, 1.0\n",
      "Train loss and acc of batch 61: 47.98321533203125, 1.0\n",
      "Train loss and acc of batch 62: 48.199974060058594, 0.984375\n",
      "Train loss and acc of batch 63: 49.17460250854492, 0.96875\n",
      "Train loss and acc of batch 64: 48.199951171875, 0.984375\n",
      "Train loss and acc of batch 65: 47.983184814453125, 1.0\n",
      "Train loss and acc of batch 66: 47.983177185058594, 1.0\n",
      "Train loss and acc of batch 67: 48.79562759399414, 0.96875\n",
      "Train loss and acc of batch 68: 48.578857421875, 0.984375\n",
      "Train loss and acc of batch 69: 48.199913024902344, 0.984375\n",
      "Train loss and acc of batch 70: 47.98313522338867, 1.0\n",
      "Training accuracy and loss of epoch #119: 0.9890, 48.3145\n",
      "Saved model by train loss 48.31446478400432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.983131408691406, 1.0\n",
      "Train loss and acc of batch 1: 47.983116149902344, 1.0\n",
      "Train loss and acc of batch 2: 48.26896667480469, 0.984375\n",
      "Train loss and acc of batch 3: 48.199867248535156, 0.984375\n",
      "Train loss and acc of batch 4: 47.983089447021484, 1.0\n",
      "Train loss and acc of batch 5: 49.332008361816406, 0.96875\n",
      "Train loss and acc of batch 6: 48.48569107055664, 0.96875\n",
      "Train loss and acc of batch 7: 47.983062744140625, 1.0\n",
      "Train loss and acc of batch 8: 48.578758239746094, 0.984375\n",
      "Train loss and acc of batch 9: 48.268898010253906, 0.984375\n",
      "Train loss and acc of batch 10: 47.98303985595703, 1.0\n",
      "Train loss and acc of batch 11: 47.983028411865234, 1.0\n",
      "Train loss and acc of batch 12: 48.73624038696289, 0.984375\n",
      "Train loss and acc of batch 13: 48.19977569580078, 0.984375\n",
      "Train loss and acc of batch 14: 48.19977569580078, 0.984375\n",
      "Train loss and acc of batch 15: 48.578697204589844, 0.984375\n",
      "Train loss and acc of batch 16: 48.57868194580078, 0.984375\n",
      "Train loss and acc of batch 17: 48.73619842529297, 0.984375\n",
      "Train loss and acc of batch 18: 48.86451721191406, 0.96875\n",
      "Train loss and acc of batch 19: 47.98295974731445, 1.0\n",
      "Train loss and acc of batch 20: 47.98294448852539, 1.0\n",
      "Train loss and acc of batch 21: 48.578636169433594, 0.984375\n",
      "Train loss and acc of batch 22: 48.578636169433594, 0.984375\n",
      "Train loss and acc of batch 23: 48.19969177246094, 0.984375\n",
      "Train loss and acc of batch 24: 48.57861328125, 0.984375\n",
      "Train loss and acc of batch 25: 47.982906341552734, 1.0\n",
      "Train loss and acc of batch 26: 47.98289108276367, 1.0\n",
      "Train loss and acc of batch 27: 47.982887268066406, 1.0\n",
      "Train loss and acc of batch 28: 47.98288345336914, 1.0\n",
      "Train loss and acc of batch 29: 48.57856750488281, 0.984375\n",
      "Train loss and acc of batch 30: 47.98285675048828, 1.0\n",
      "Train loss and acc of batch 31: 48.199615478515625, 0.984375\n",
      "Train loss and acc of batch 32: 47.98284149169922, 1.0\n",
      "Train loss and acc of batch 33: 47.98283386230469, 1.0\n",
      "Train loss and acc of batch 34: 48.578521728515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.416343688964844, 0.96875\n",
      "Train loss and acc of batch 36: 47.98280715942383, 1.0\n",
      "Train loss and acc of batch 37: 48.73602294921875, 0.984375\n",
      "Train loss and acc of batch 38: 49.33171081542969, 0.96875\n",
      "Train loss and acc of batch 39: 48.199546813964844, 0.984375\n",
      "Train loss and acc of batch 40: 47.98276901245117, 1.0\n",
      "Train loss and acc of batch 41: 49.33168411254883, 0.96875\n",
      "Train loss and acc of batch 42: 47.982757568359375, 1.0\n",
      "Train loss and acc of batch 43: 48.57843780517578, 0.984375\n",
      "Train loss and acc of batch 44: 47.98273468017578, 1.0\n",
      "Train loss and acc of batch 45: 48.57843017578125, 0.984375\n",
      "Train loss and acc of batch 46: 48.26856994628906, 0.984375\n",
      "Train loss and acc of batch 47: 47.98270797729492, 1.0\n",
      "Train loss and acc of batch 48: 47.982696533203125, 1.0\n",
      "Train loss and acc of batch 49: 47.98268508911133, 1.0\n",
      "Train loss and acc of batch 50: 48.57838439941406, 0.984375\n",
      "Train loss and acc of batch 51: 49.33159637451172, 0.96875\n",
      "Train loss and acc of batch 52: 49.23850631713867, 0.953125\n",
      "Train loss and acc of batch 53: 47.98265838623047, 1.0\n",
      "Train loss and acc of batch 54: 48.19940185546875, 0.984375\n",
      "Train loss and acc of batch 55: 47.982635498046875, 1.0\n",
      "Train loss and acc of batch 56: 47.98263168334961, 1.0\n",
      "Train loss and acc of batch 57: 48.57831573486328, 0.984375\n",
      "Train loss and acc of batch 58: 47.982608795166016, 1.0\n",
      "Train loss and acc of batch 59: 47.98259735107422, 1.0\n",
      "Train loss and acc of batch 60: 47.98259353637695, 1.0\n",
      "Train loss and acc of batch 61: 47.982582092285156, 1.0\n",
      "Train loss and acc of batch 62: 48.19933319091797, 0.984375\n",
      "Train loss and acc of batch 63: 49.17396545410156, 0.96875\n",
      "Train loss and acc of batch 64: 48.19932556152344, 0.984375\n",
      "Train loss and acc of batch 65: 47.9825439453125, 1.0\n",
      "Train loss and acc of batch 66: 47.982540130615234, 1.0\n",
      "Train loss and acc of batch 67: 48.79499816894531, 0.96875\n",
      "Train loss and acc of batch 68: 48.578216552734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.19927215576172, 0.984375\n",
      "Train loss and acc of batch 70: 47.982505798339844, 1.0\n",
      "Training accuracy and loss of epoch #120: 0.9890, 48.3138\n",
      "Saved model by train loss 48.31383025478309\n",
      "Train loss and acc of batch 0: 47.98249053955078, 1.0\n",
      "Train loss and acc of batch 1: 47.98248291015625, 1.0\n",
      "Train loss and acc of batch 2: 48.26832580566406, 0.984375\n",
      "Train loss and acc of batch 3: 48.19923400878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.982460021972656, 1.0\n",
      "Train loss and acc of batch 5: 49.33136749267578, 0.96875\n",
      "Train loss and acc of batch 6: 48.48505783081055, 0.96875\n",
      "Train loss and acc of batch 7: 47.9824333190918, 1.0\n",
      "Train loss and acc of batch 8: 48.578125, 0.984375\n",
      "Train loss and acc of batch 9: 48.26826477050781, 0.984375\n",
      "Train loss and acc of batch 10: 47.98240661621094, 1.0\n",
      "Train loss and acc of batch 11: 47.982391357421875, 1.0\n",
      "Train loss and acc of batch 12: 48.73561096191406, 0.984375\n",
      "Train loss and acc of batch 13: 48.199134826660156, 0.984375\n",
      "Train loss and acc of batch 14: 48.199127197265625, 0.984375\n",
      "Train loss and acc of batch 15: 48.57805633544922, 0.984375\n",
      "Train loss and acc of batch 16: 48.57804870605469, 0.984375\n",
      "Train loss and acc of batch 17: 48.735565185546875, 0.984375\n",
      "Train loss and acc of batch 18: 48.8638916015625, 0.96875\n",
      "Train loss and acc of batch 19: 47.98231887817383, 1.0\n",
      "Train loss and acc of batch 20: 47.98231506347656, 1.0\n",
      "Train loss and acc of batch 21: 48.57801055908203, 0.984375\n",
      "Train loss and acc of batch 22: 48.57799530029297, 0.984375\n",
      "Train loss and acc of batch 23: 48.19905090332031, 0.984375\n",
      "Train loss and acc of batch 24: 48.57798767089844, 0.984375\n",
      "Train loss and acc of batch 25: 47.982269287109375, 1.0\n",
      "Train loss and acc of batch 26: 47.982261657714844, 1.0\n",
      "Train loss and acc of batch 27: 47.98225021362305, 1.0\n",
      "Train loss and acc of batch 28: 47.98223876953125, 1.0\n",
      "Train loss and acc of batch 29: 48.57793426513672, 0.984375\n",
      "Train loss and acc of batch 30: 47.98221969604492, 1.0\n",
      "Train loss and acc of batch 31: 48.19898223876953, 0.984375\n",
      "Train loss and acc of batch 32: 47.98221206665039, 1.0\n",
      "Train loss and acc of batch 33: 47.982200622558594, 1.0\n",
      "Train loss and acc of batch 34: 48.57788848876953, 0.984375\n",
      "Train loss and acc of batch 35: 48.41571044921875, 0.96875\n",
      "Train loss and acc of batch 36: 47.98217010498047, 1.0\n",
      "Train loss and acc of batch 37: 48.735389709472656, 0.984375\n",
      "Train loss and acc of batch 38: 49.331085205078125, 0.96875\n",
      "Train loss and acc of batch 39: 48.19891357421875, 0.984375\n",
      "Train loss and acc of batch 40: 47.982139587402344, 1.0\n",
      "Train loss and acc of batch 41: 49.3310546875, 0.96875\n",
      "Train loss and acc of batch 42: 47.982112884521484, 1.0\n",
      "Train loss and acc of batch 43: 48.57781219482422, 0.984375\n",
      "Train loss and acc of batch 44: 47.98209762573242, 1.0\n",
      "Train loss and acc of batch 45: 48.577796936035156, 0.984375\n",
      "Train loss and acc of batch 46: 48.26793670654297, 0.984375\n",
      "Train loss and acc of batch 47: 47.98207092285156, 1.0\n",
      "Train loss and acc of batch 48: 47.98206329345703, 1.0\n",
      "Train loss and acc of batch 49: 47.982059478759766, 1.0\n",
      "Train loss and acc of batch 50: 48.57774353027344, 0.984375\n",
      "Train loss and acc of batch 51: 49.330963134765625, 0.96875\n",
      "Train loss and acc of batch 52: 49.23787307739258, 0.953125\n",
      "Train loss and acc of batch 53: 47.98202133178711, 1.0\n",
      "Train loss and acc of batch 54: 48.19878387451172, 0.984375\n",
      "Train loss and acc of batch 55: 47.98200225830078, 1.0\n",
      "Train loss and acc of batch 56: 47.981990814208984, 1.0\n",
      "Train loss and acc of batch 57: 48.57768249511719, 0.984375\n",
      "Train loss and acc of batch 58: 47.981971740722656, 1.0\n",
      "Train loss and acc of batch 59: 47.98196792602539, 1.0\n",
      "Train loss and acc of batch 60: 47.98196029663086, 1.0\n",
      "Train loss and acc of batch 61: 47.9819450378418, 1.0\n",
      "Train loss and acc of batch 62: 48.198707580566406, 0.984375\n",
      "Train loss and acc of batch 63: 49.173336029052734, 0.96875\n",
      "Train loss and acc of batch 64: 48.19868469238281, 0.984375\n",
      "Train loss and acc of batch 65: 47.98191452026367, 1.0\n",
      "Train loss and acc of batch 66: 47.98190689086914, 1.0\n",
      "Train loss and acc of batch 67: 48.79436111450195, 0.96875\n",
      "Train loss and acc of batch 68: 48.57759094238281, 0.984375\n",
      "Train loss and acc of batch 69: 48.198638916015625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 70: 47.98186492919922, 1.0\n",
      "Training accuracy and loss of epoch #121: 0.9890, 48.3132\n",
      "Saved model by train loss 48.31319626284317\n",
      "Train loss and acc of batch 0: 47.98185729980469, 1.0\n",
      "Train loss and acc of batch 1: 47.981849670410156, 1.0\n",
      "Train loss and acc of batch 2: 48.26769256591797, 0.984375\n",
      "Train loss and acc of batch 3: 48.19860076904297, 0.984375\n",
      "Train loss and acc of batch 4: 47.98181915283203, 1.0\n",
      "Train loss and acc of batch 5: 49.33074188232422, 0.96875\n",
      "Train loss and acc of batch 6: 48.48442459106445, 0.96875\n",
      "Train loss and acc of batch 7: 47.98179626464844, 1.0\n",
      "Train loss and acc of batch 8: 48.577491760253906, 0.984375\n",
      "Train loss and acc of batch 9: 48.26763916015625, 0.984375\n",
      "Train loss and acc of batch 10: 47.98176956176758, 1.0\n",
      "Train loss and acc of batch 11: 47.98176574707031, 1.0\n",
      "Train loss and acc of batch 12: 48.7349739074707, 0.984375\n",
      "Train loss and acc of batch 13: 48.198509216308594, 0.984375\n",
      "Train loss and acc of batch 14: 48.19850158691406, 0.984375\n",
      "Train loss and acc of batch 15: 48.577430725097656, 0.984375\n",
      "Train loss and acc of batch 16: 48.577415466308594, 0.984375\n",
      "Train loss and acc of batch 17: 48.73493194580078, 0.984375\n",
      "Train loss and acc of batch 18: 48.863250732421875, 0.96875\n",
      "Train loss and acc of batch 19: 47.981693267822266, 1.0\n",
      "Train loss and acc of batch 20: 47.981685638427734, 1.0\n",
      "Train loss and acc of batch 21: 48.577369689941406, 0.984375\n",
      "Train loss and acc of batch 22: 48.577362060546875, 0.984375\n",
      "Train loss and acc of batch 23: 48.19841003417969, 0.984375\n",
      "Train loss and acc of batch 24: 48.57734680175781, 0.984375\n",
      "Train loss and acc of batch 25: 47.98163986206055, 1.0\n",
      "Train loss and acc of batch 26: 47.98162841796875, 1.0\n",
      "Train loss and acc of batch 27: 47.98162078857422, 1.0\n",
      "Train loss and acc of batch 28: 47.98160934448242, 1.0\n",
      "Train loss and acc of batch 29: 48.577293395996094, 0.984375\n",
      "Train loss and acc of batch 30: 47.98159408569336, 1.0\n",
      "Train loss and acc of batch 31: 48.19834899902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.981571197509766, 1.0\n",
      "Train loss and acc of batch 33: 47.9815673828125, 1.0\n",
      "Train loss and acc of batch 34: 48.57726287841797, 0.984375\n",
      "Train loss and acc of batch 35: 48.41507339477539, 0.96875\n",
      "Train loss and acc of batch 36: 47.981536865234375, 1.0\n",
      "Train loss and acc of batch 37: 48.73474884033203, 0.984375\n",
      "Train loss and acc of batch 38: 49.3304443359375, 0.96875\n",
      "Train loss and acc of batch 39: 48.198280334472656, 0.984375\n",
      "Train loss and acc of batch 40: 47.981502532958984, 1.0\n",
      "Train loss and acc of batch 41: 49.330421447753906, 0.96875\n",
      "Train loss and acc of batch 42: 47.98148727416992, 1.0\n",
      "Train loss and acc of batch 43: 48.577171325683594, 0.984375\n",
      "Train loss and acc of batch 44: 47.981468200683594, 1.0\n",
      "Train loss and acc of batch 45: 48.57715606689453, 0.984375\n",
      "Train loss and acc of batch 46: 48.267295837402344, 0.984375\n",
      "Train loss and acc of batch 47: 47.98143768310547, 1.0\n",
      "Train loss and acc of batch 48: 47.98143768310547, 1.0\n",
      "Train loss and acc of batch 49: 47.981422424316406, 1.0\n",
      "Train loss and acc of batch 50: 48.577117919921875, 0.984375\n",
      "Train loss and acc of batch 51: 49.33032989501953, 0.96875\n",
      "Train loss and acc of batch 52: 49.23723602294922, 0.953125\n",
      "Train loss and acc of batch 53: 47.981388092041016, 1.0\n",
      "Train loss and acc of batch 54: 48.19813537597656, 0.984375\n",
      "Train loss and acc of batch 55: 47.98136901855469, 1.0\n",
      "Train loss and acc of batch 56: 47.98136520385742, 1.0\n",
      "Train loss and acc of batch 57: 48.577049255371094, 0.984375\n",
      "Train loss and acc of batch 58: 47.98134231567383, 1.0\n",
      "Train loss and acc of batch 59: 47.9813346862793, 1.0\n",
      "Train loss and acc of batch 60: 47.981319427490234, 1.0\n",
      "Train loss and acc of batch 61: 47.981319427490234, 1.0\n",
      "Train loss and acc of batch 62: 48.19807434082031, 0.984375\n",
      "Train loss and acc of batch 63: 49.172698974609375, 0.96875\n",
      "Train loss and acc of batch 64: 48.19805145263672, 0.984375\n",
      "Train loss and acc of batch 65: 47.98127746582031, 1.0\n",
      "Train loss and acc of batch 66: 47.98126983642578, 1.0\n",
      "Train loss and acc of batch 67: 48.793731689453125, 0.96875\n",
      "Train loss and acc of batch 68: 48.57695007324219, 0.984375\n",
      "Train loss and acc of batch 69: 48.19801330566406, 0.984375\n",
      "Train loss and acc of batch 70: 47.981239318847656, 1.0\n",
      "Training accuracy and loss of epoch #122: 0.9890, 48.3126\n",
      "Saved model by train loss 48.31256286191269\n",
      "Train loss and acc of batch 0: 47.981224060058594, 1.0\n",
      "Train loss and acc of batch 1: 47.98122024536133, 1.0\n",
      "Train loss and acc of batch 2: 48.267059326171875, 0.984375\n",
      "Train loss and acc of batch 3: 48.197959899902344, 0.984375\n",
      "Train loss and acc of batch 4: 47.98119354248047, 1.0\n",
      "Train loss and acc of batch 5: 49.330108642578125, 0.96875\n",
      "Train loss and acc of batch 6: 48.48379135131836, 0.96875\n",
      "Train loss and acc of batch 7: 47.98116683959961, 1.0\n",
      "Train loss and acc of batch 8: 48.57685089111328, 0.984375\n",
      "Train loss and acc of batch 9: 48.266998291015625, 0.984375\n",
      "Train loss and acc of batch 10: 47.981136322021484, 1.0\n",
      "Train loss and acc of batch 11: 47.98112106323242, 1.0\n",
      "Train loss and acc of batch 12: 48.73434066772461, 0.984375\n",
      "Train loss and acc of batch 13: 48.1978759765625, 0.984375\n",
      "Train loss and acc of batch 14: 48.19786071777344, 0.984375\n",
      "Train loss and acc of batch 15: 48.57679748535156, 0.984375\n",
      "Train loss and acc of batch 16: 48.5767822265625, 0.984375\n",
      "Train loss and acc of batch 17: 48.73429489135742, 0.984375\n",
      "Train loss and acc of batch 18: 48.86262130737305, 0.96875\n",
      "Train loss and acc of batch 19: 47.98106002807617, 1.0\n",
      "Train loss and acc of batch 20: 47.98104476928711, 1.0\n",
      "Train loss and acc of batch 21: 48.576744079589844, 0.984375\n",
      "Train loss and acc of batch 22: 48.57672882080078, 0.984375\n",
      "Train loss and acc of batch 23: 48.197784423828125, 0.984375\n",
      "Train loss and acc of batch 24: 48.57671356201172, 0.984375\n",
      "Train loss and acc of batch 25: 47.98099899291992, 1.0\n",
      "Train loss and acc of batch 26: 47.98099136352539, 1.0\n",
      "Train loss and acc of batch 27: 47.980987548828125, 1.0\n",
      "Train loss and acc of batch 28: 47.98097229003906, 1.0\n",
      "Train loss and acc of batch 29: 48.57667541503906, 0.984375\n",
      "Train loss and acc of batch 30: 47.980953216552734, 1.0\n",
      "Train loss and acc of batch 31: 48.19770812988281, 0.984375\n",
      "Train loss and acc of batch 32: 47.98094177246094, 1.0\n",
      "Train loss and acc of batch 33: 47.98093032836914, 1.0\n",
      "Train loss and acc of batch 34: 48.576622009277344, 0.984375\n",
      "Train loss and acc of batch 35: 48.41444778442383, 0.96875\n",
      "Train loss and acc of batch 36: 47.98090362548828, 1.0\n",
      "Train loss and acc of batch 37: 48.7341194152832, 0.984375\n",
      "Train loss and acc of batch 38: 49.329811096191406, 0.96875\n",
      "Train loss and acc of batch 39: 48.19763946533203, 0.984375\n",
      "Train loss and acc of batch 40: 47.98086929321289, 1.0\n",
      "Train loss and acc of batch 41: 49.32978439331055, 0.96875\n",
      "Train loss and acc of batch 42: 47.98085021972656, 1.0\n",
      "Train loss and acc of batch 43: 48.57654571533203, 0.984375\n",
      "Train loss and acc of batch 44: 47.9808349609375, 1.0\n",
      "Train loss and acc of batch 45: 48.57652282714844, 0.984375\n",
      "Train loss and acc of batch 46: 48.26667022705078, 0.984375\n",
      "Train loss and acc of batch 47: 47.980804443359375, 1.0\n",
      "Train loss and acc of batch 48: 47.98080062866211, 1.0\n",
      "Train loss and acc of batch 49: 47.98078918457031, 1.0\n",
      "Train loss and acc of batch 50: 48.57647705078125, 0.984375\n",
      "Train loss and acc of batch 51: 49.32969665527344, 0.96875\n",
      "Train loss and acc of batch 52: 49.23659896850586, 0.953125\n",
      "Train loss and acc of batch 53: 47.98074722290039, 1.0\n",
      "Train loss and acc of batch 54: 48.197509765625, 0.984375\n",
      "Train loss and acc of batch 55: 47.980735778808594, 1.0\n",
      "Train loss and acc of batch 56: 47.9807243347168, 1.0\n",
      "Train loss and acc of batch 57: 48.57642364501953, 0.984375\n",
      "Train loss and acc of batch 58: 47.980709075927734, 1.0\n",
      "Train loss and acc of batch 59: 47.98069381713867, 1.0\n",
      "Train loss and acc of batch 60: 47.98069381713867, 1.0\n",
      "Train loss and acc of batch 61: 47.98067855834961, 1.0\n",
      "Train loss and acc of batch 62: 48.19744110107422, 0.984375\n",
      "Train loss and acc of batch 63: 49.17206573486328, 0.96875\n",
      "Train loss and acc of batch 64: 48.197418212890625, 0.984375\n",
      "Train loss and acc of batch 65: 47.98064422607422, 1.0\n",
      "Train loss and acc of batch 66: 47.98064041137695, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 67: 48.7930908203125, 0.96875\n",
      "Train loss and acc of batch 68: 48.576316833496094, 0.984375\n",
      "Train loss and acc of batch 69: 48.19737243652344, 0.984375\n",
      "Train loss and acc of batch 70: 47.98059844970703, 1.0\n",
      "Training accuracy and loss of epoch #123: 0.9890, 48.3119\n",
      "Saved model by train loss 48.31192860133211\n",
      "Train loss and acc of batch 0: 47.980594635009766, 1.0\n",
      "Train loss and acc of batch 1: 47.9805793762207, 1.0\n",
      "Train loss and acc of batch 2: 48.26642608642578, 0.984375\n",
      "Train loss and acc of batch 3: 48.19733428955078, 0.984375\n",
      "Train loss and acc of batch 4: 47.98055648803711, 1.0\n",
      "Train loss and acc of batch 5: 49.3294677734375, 0.96875\n",
      "Train loss and acc of batch 6: 48.483154296875, 0.96875\n",
      "Train loss and acc of batch 7: 47.980525970458984, 1.0\n",
      "Train loss and acc of batch 8: 48.57622528076172, 0.984375\n",
      "Train loss and acc of batch 9: 48.26636505126953, 0.984375\n",
      "Train loss and acc of batch 10: 47.980499267578125, 1.0\n",
      "Train loss and acc of batch 11: 47.980491638183594, 1.0\n",
      "Train loss and acc of batch 12: 48.73371124267578, 0.984375\n",
      "Train loss and acc of batch 13: 48.197235107421875, 0.984375\n",
      "Train loss and acc of batch 14: 48.197235107421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.57615661621094, 0.984375\n",
      "Train loss and acc of batch 16: 48.576148986816406, 0.984375\n",
      "Train loss and acc of batch 17: 48.73366928100586, 0.984375\n",
      "Train loss and acc of batch 18: 48.86198043823242, 0.96875\n",
      "Train loss and acc of batch 19: 47.98041915893555, 1.0\n",
      "Train loss and acc of batch 20: 47.98041534423828, 1.0\n",
      "Train loss and acc of batch 21: 48.57610321044922, 0.984375\n",
      "Train loss and acc of batch 22: 48.57609558105469, 0.984375\n",
      "Train loss and acc of batch 23: 48.19715118408203, 0.984375\n",
      "Train loss and acc of batch 24: 48.576080322265625, 0.984375\n",
      "Train loss and acc of batch 25: 47.98036575317383, 1.0\n",
      "Train loss and acc of batch 26: 47.9803581237793, 1.0\n",
      "Train loss and acc of batch 27: 47.980350494384766, 1.0\n",
      "Train loss and acc of batch 28: 47.9803466796875, 1.0\n",
      "Train loss and acc of batch 29: 48.57603454589844, 0.984375\n",
      "Train loss and acc of batch 30: 47.980323791503906, 1.0\n",
      "Train loss and acc of batch 31: 48.19708251953125, 0.984375\n",
      "Train loss and acc of batch 32: 47.98030471801758, 1.0\n",
      "Train loss and acc of batch 33: 47.98029708862305, 1.0\n",
      "Train loss and acc of batch 34: 48.57598876953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.4138069152832, 0.96875\n",
      "Train loss and acc of batch 36: 47.98027420043945, 1.0\n",
      "Train loss and acc of batch 37: 48.73348617553711, 0.984375\n",
      "Train loss and acc of batch 38: 49.32917785644531, 0.96875\n",
      "Train loss and acc of batch 39: 48.19700622558594, 0.984375\n",
      "Train loss and acc of batch 40: 47.980228424072266, 1.0\n",
      "Train loss and acc of batch 41: 49.32915496826172, 0.96875\n",
      "Train loss and acc of batch 42: 47.9802131652832, 1.0\n",
      "Train loss and acc of batch 43: 48.575904846191406, 0.984375\n",
      "Train loss and acc of batch 44: 47.98019790649414, 1.0\n",
      "Train loss and acc of batch 45: 48.575889587402344, 0.984375\n",
      "Train loss and acc of batch 46: 48.26603698730469, 0.984375\n",
      "Train loss and acc of batch 47: 47.98017120361328, 1.0\n",
      "Train loss and acc of batch 48: 47.980159759521484, 1.0\n",
      "Train loss and acc of batch 49: 47.98015213012695, 1.0\n",
      "Train loss and acc of batch 50: 48.57585144042969, 0.984375\n",
      "Train loss and acc of batch 51: 49.329063415527344, 0.96875\n",
      "Train loss and acc of batch 52: 49.235965728759766, 0.953125\n",
      "Train loss and acc of batch 53: 47.98012161254883, 1.0\n",
      "Train loss and acc of batch 54: 48.196868896484375, 0.984375\n",
      "Train loss and acc of batch 55: 47.9801025390625, 1.0\n",
      "Train loss and acc of batch 56: 47.9800910949707, 1.0\n",
      "Train loss and acc of batch 57: 48.575782775878906, 0.984375\n",
      "Train loss and acc of batch 58: 47.980072021484375, 1.0\n",
      "Train loss and acc of batch 59: 47.98006820678711, 1.0\n",
      "Train loss and acc of batch 60: 47.98005676269531, 1.0\n",
      "Train loss and acc of batch 61: 47.980045318603516, 1.0\n",
      "Train loss and acc of batch 62: 48.196800231933594, 0.984375\n",
      "Train loss and acc of batch 63: 49.171424865722656, 0.96875\n",
      "Train loss and acc of batch 64: 48.19678497314453, 0.984375\n",
      "Train loss and acc of batch 65: 47.98000717163086, 1.0\n",
      "Train loss and acc of batch 66: 47.97999954223633, 1.0\n",
      "Train loss and acc of batch 67: 48.792457580566406, 0.96875\n",
      "Train loss and acc of batch 68: 48.57568359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.19673156738281, 0.984375\n",
      "Train loss and acc of batch 70: 47.97996139526367, 1.0\n",
      "Training accuracy and loss of epoch #124: 0.9890, 48.3113\n",
      "Saved model by train loss 48.31129401838276\n",
      "Train loss and acc of batch 0: 47.97995376586914, 1.0\n",
      "Train loss and acc of batch 1: 47.97994613647461, 1.0\n",
      "Train loss and acc of batch 2: 48.265785217285156, 0.984375\n",
      "Train loss and acc of batch 3: 48.196685791015625, 0.984375\n",
      "Train loss and acc of batch 4: 47.97991943359375, 1.0\n",
      "Train loss and acc of batch 5: 49.328826904296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.48251724243164, 0.96875\n",
      "Train loss and acc of batch 7: 47.979896545410156, 1.0\n",
      "Train loss and acc of batch 8: 48.575584411621094, 0.984375\n",
      "Train loss and acc of batch 9: 48.265724182128906, 0.984375\n",
      "Train loss and acc of batch 10: 47.97986602783203, 1.0\n",
      "Train loss and acc of batch 11: 47.97985076904297, 1.0\n",
      "Train loss and acc of batch 12: 48.733070373535156, 0.984375\n",
      "Train loss and acc of batch 13: 48.19660186767578, 0.984375\n",
      "Train loss and acc of batch 14: 48.19659423828125, 0.984375\n",
      "Train loss and acc of batch 15: 48.575523376464844, 0.984375\n",
      "Train loss and acc of batch 16: 48.57551574707031, 0.984375\n",
      "Train loss and acc of batch 17: 48.7330207824707, 0.984375\n",
      "Train loss and acc of batch 18: 48.86134719848633, 0.96875\n",
      "Train loss and acc of batch 19: 47.97977828979492, 1.0\n",
      "Train loss and acc of batch 20: 47.979774475097656, 1.0\n",
      "Train loss and acc of batch 21: 48.575469970703125, 0.984375\n",
      "Train loss and acc of batch 22: 48.57545471191406, 0.984375\n",
      "Train loss and acc of batch 23: 48.196510314941406, 0.984375\n",
      "Train loss and acc of batch 24: 48.57544708251953, 0.984375\n",
      "Train loss and acc of batch 25: 47.97972869873047, 1.0\n",
      "Train loss and acc of batch 26: 47.9797248840332, 1.0\n",
      "Train loss and acc of batch 27: 47.97970962524414, 1.0\n",
      "Train loss and acc of batch 28: 47.97970199584961, 1.0\n",
      "Train loss and acc of batch 29: 48.57539367675781, 0.984375\n",
      "Train loss and acc of batch 30: 47.97969436645508, 1.0\n",
      "Train loss and acc of batch 31: 48.196441650390625, 0.984375\n",
      "Train loss and acc of batch 32: 47.979671478271484, 1.0\n",
      "Train loss and acc of batch 33: 47.97965621948242, 1.0\n",
      "Train loss and acc of batch 34: 48.575347900390625, 0.984375\n",
      "Train loss and acc of batch 35: 48.41317367553711, 0.96875\n",
      "Train loss and acc of batch 36: 47.97963333129883, 1.0\n",
      "Train loss and acc of batch 37: 48.732845306396484, 0.984375\n",
      "Train loss and acc of batch 38: 49.32854461669922, 0.96875\n",
      "Train loss and acc of batch 39: 48.196372985839844, 0.984375\n",
      "Train loss and acc of batch 40: 47.979591369628906, 1.0\n",
      "Train loss and acc of batch 41: 49.328514099121094, 0.96875\n",
      "Train loss and acc of batch 42: 47.979576110839844, 1.0\n",
      "Train loss and acc of batch 43: 48.57527160644531, 0.984375\n",
      "Train loss and acc of batch 44: 47.979557037353516, 1.0\n",
      "Train loss and acc of batch 45: 48.57525634765625, 0.984375\n",
      "Train loss and acc of batch 46: 48.26539611816406, 0.984375\n",
      "Train loss and acc of batch 47: 47.979530334472656, 1.0\n",
      "Train loss and acc of batch 48: 47.979522705078125, 1.0\n",
      "Train loss and acc of batch 49: 47.97951889038086, 1.0\n",
      "Train loss and acc of batch 50: 48.57521057128906, 0.984375\n",
      "Train loss and acc of batch 51: 49.32842254638672, 0.96875\n",
      "Train loss and acc of batch 52: 49.23533248901367, 0.953125\n",
      "Train loss and acc of batch 53: 47.9794807434082, 1.0\n",
      "Train loss and acc of batch 54: 48.19623565673828, 0.984375\n",
      "Train loss and acc of batch 55: 47.979461669921875, 1.0\n",
      "Train loss and acc of batch 56: 47.97945022583008, 1.0\n",
      "Train loss and acc of batch 57: 48.57514953613281, 0.984375\n",
      "Train loss and acc of batch 58: 47.979434967041016, 1.0\n",
      "Train loss and acc of batch 59: 47.97943115234375, 1.0\n",
      "Train loss and acc of batch 60: 47.97941970825195, 1.0\n",
      "Train loss and acc of batch 61: 47.97940444946289, 1.0\n",
      "Train loss and acc of batch 62: 48.1961669921875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 63: 49.17079544067383, 0.96875\n",
      "Train loss and acc of batch 64: 48.196144104003906, 0.984375\n",
      "Train loss and acc of batch 65: 47.979373931884766, 1.0\n",
      "Train loss and acc of batch 66: 47.9793701171875, 1.0\n",
      "Train loss and acc of batch 67: 48.79182052612305, 0.96875\n",
      "Train loss and acc of batch 68: 48.575042724609375, 0.984375\n",
      "Train loss and acc of batch 69: 48.19610595703125, 0.984375\n",
      "Train loss and acc of batch 70: 47.97932815551758, 1.0\n",
      "Training accuracy and loss of epoch #125: 0.9890, 48.3107\n",
      "Saved model by train loss 48.31065664157062\n",
      "Train loss and acc of batch 0: 47.97932052612305, 1.0\n",
      "Train loss and acc of batch 1: 47.979312896728516, 1.0\n",
      "Train loss and acc of batch 2: 48.26515197753906, 0.984375\n",
      "Train loss and acc of batch 3: 48.19606018066406, 0.984375\n",
      "Train loss and acc of batch 4: 47.97928237915039, 1.0\n",
      "Train loss and acc of batch 5: 49.32820129394531, 0.96875\n",
      "Train loss and acc of batch 6: 48.48188781738281, 0.96875\n",
      "Train loss and acc of batch 7: 47.97925567626953, 1.0\n",
      "Train loss and acc of batch 8: 48.57494354248047, 0.984375\n",
      "Train loss and acc of batch 9: 48.265098571777344, 0.984375\n",
      "Train loss and acc of batch 10: 47.97922897338867, 1.0\n",
      "Train loss and acc of batch 11: 47.979225158691406, 1.0\n",
      "Train loss and acc of batch 12: 48.7324333190918, 0.984375\n",
      "Train loss and acc of batch 13: 48.19596862792969, 0.984375\n",
      "Train loss and acc of batch 14: 48.195953369140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.57488250732422, 0.984375\n",
      "Train loss and acc of batch 16: 48.57487487792969, 0.984375\n",
      "Train loss and acc of batch 17: 48.73239517211914, 0.984375\n",
      "Train loss and acc of batch 18: 48.86071014404297, 0.96875\n",
      "Train loss and acc of batch 19: 47.979148864746094, 1.0\n",
      "Train loss and acc of batch 20: 47.97914123535156, 1.0\n",
      "Train loss and acc of batch 21: 48.57483673095703, 0.984375\n",
      "Train loss and acc of batch 22: 48.57482147216797, 0.984375\n",
      "Train loss and acc of batch 23: 48.195884704589844, 0.984375\n",
      "Train loss and acc of batch 24: 48.574806213378906, 0.984375\n",
      "Train loss and acc of batch 25: 47.979095458984375, 1.0\n",
      "Train loss and acc of batch 26: 47.979087829589844, 1.0\n",
      "Train loss and acc of batch 27: 47.97907638549805, 1.0\n",
      "Train loss and acc of batch 28: 47.979068756103516, 1.0\n",
      "Train loss and acc of batch 29: 48.57476043701172, 0.984375\n",
      "Train loss and acc of batch 30: 47.97904968261719, 1.0\n",
      "Train loss and acc of batch 31: 48.19580841064453, 0.984375\n",
      "Train loss and acc of batch 32: 47.979034423828125, 1.0\n",
      "Train loss and acc of batch 33: 47.979026794433594, 1.0\n",
      "Train loss and acc of batch 34: 48.57471466064453, 0.984375\n",
      "Train loss and acc of batch 35: 48.41253662109375, 0.96875\n",
      "Train loss and acc of batch 36: 47.979000091552734, 1.0\n",
      "Train loss and acc of batch 37: 48.73221206665039, 0.984375\n",
      "Train loss and acc of batch 38: 49.327911376953125, 0.96875\n",
      "Train loss and acc of batch 39: 48.19573211669922, 0.984375\n",
      "Train loss and acc of batch 40: 47.978965759277344, 1.0\n",
      "Train loss and acc of batch 41: 49.327880859375, 0.96875\n",
      "Train loss and acc of batch 42: 47.978946685791016, 1.0\n",
      "Train loss and acc of batch 43: 48.57463073730469, 0.984375\n",
      "Train loss and acc of batch 44: 47.97892761230469, 1.0\n",
      "Train loss and acc of batch 45: 48.574623107910156, 0.984375\n",
      "Train loss and acc of batch 46: 48.26476287841797, 0.984375\n",
      "Train loss and acc of batch 47: 47.97890090942383, 1.0\n",
      "Train loss and acc of batch 48: 47.9788932800293, 1.0\n",
      "Train loss and acc of batch 49: 47.9788818359375, 1.0\n",
      "Train loss and acc of batch 50: 48.57457733154297, 0.984375\n",
      "Train loss and acc of batch 51: 49.327789306640625, 0.96875\n",
      "Train loss and acc of batch 52: 49.23469543457031, 0.953125\n",
      "Train loss and acc of batch 53: 47.97884750366211, 1.0\n",
      "Train loss and acc of batch 54: 48.19560241699219, 0.984375\n",
      "Train loss and acc of batch 55: 47.97882843017578, 1.0\n",
      "Train loss and acc of batch 56: 47.978824615478516, 1.0\n",
      "Train loss and acc of batch 57: 48.57451629638672, 0.984375\n",
      "Train loss and acc of batch 58: 47.97880172729492, 1.0\n",
      "Train loss and acc of batch 59: 47.97879409790039, 1.0\n",
      "Train loss and acc of batch 60: 47.978782653808594, 1.0\n",
      "Train loss and acc of batch 61: 47.97877502441406, 1.0\n",
      "Train loss and acc of batch 62: 48.195533752441406, 0.984375\n",
      "Train loss and acc of batch 63: 49.17015838623047, 0.96875\n",
      "Train loss and acc of batch 64: 48.195518493652344, 0.984375\n",
      "Train loss and acc of batch 65: 47.97874069213867, 1.0\n",
      "Train loss and acc of batch 66: 47.97872543334961, 1.0\n",
      "Train loss and acc of batch 67: 48.79118728637695, 0.96875\n",
      "Train loss and acc of batch 68: 48.57440948486328, 0.984375\n",
      "Train loss and acc of batch 69: 48.195472717285156, 0.984375\n",
      "Train loss and acc of batch 70: 47.97869110107422, 1.0\n",
      "Training accuracy and loss of epoch #126: 0.9890, 48.3100\n",
      "Saved model by train loss 48.31002291827134\n",
      "Train loss and acc of batch 0: 47.97868347167969, 1.0\n",
      "Train loss and acc of batch 1: 47.97867965698242, 1.0\n",
      "Train loss and acc of batch 2: 48.26451873779297, 0.984375\n",
      "Train loss and acc of batch 3: 48.19542694091797, 0.984375\n",
      "Train loss and acc of batch 4: 47.97865295410156, 1.0\n",
      "Train loss and acc of batch 5: 49.32756805419922, 0.96875\n",
      "Train loss and acc of batch 6: 48.48125076293945, 0.96875\n",
      "Train loss and acc of batch 7: 47.97862243652344, 1.0\n",
      "Train loss and acc of batch 8: 48.574317932128906, 0.984375\n",
      "Train loss and acc of batch 9: 48.26445770263672, 0.984375\n",
      "Train loss and acc of batch 10: 47.97859573364258, 1.0\n",
      "Train loss and acc of batch 11: 47.97858810424805, 1.0\n",
      "Train loss and acc of batch 12: 48.731807708740234, 0.984375\n",
      "Train loss and acc of batch 13: 48.195335388183594, 0.984375\n",
      "Train loss and acc of batch 14: 48.19532775878906, 0.984375\n",
      "Train loss and acc of batch 15: 48.574256896972656, 0.984375\n",
      "Train loss and acc of batch 16: 48.574241638183594, 0.984375\n",
      "Train loss and acc of batch 17: 48.73175811767578, 0.984375\n",
      "Train loss and acc of batch 18: 48.860076904296875, 0.96875\n",
      "Train loss and acc of batch 19: 47.978515625, 1.0\n",
      "Train loss and acc of batch 20: 47.9785041809082, 1.0\n",
      "Train loss and acc of batch 21: 48.57420349121094, 0.984375\n",
      "Train loss and acc of batch 22: 48.574195861816406, 0.984375\n",
      "Train loss and acc of batch 23: 48.19524383544922, 0.984375\n",
      "Train loss and acc of batch 24: 48.57417297363281, 0.984375\n",
      "Train loss and acc of batch 25: 47.97846221923828, 1.0\n",
      "Train loss and acc of batch 26: 47.97845458984375, 1.0\n",
      "Train loss and acc of batch 27: 47.97844696044922, 1.0\n",
      "Train loss and acc of batch 28: 47.97843933105469, 1.0\n",
      "Train loss and acc of batch 29: 48.574134826660156, 0.984375\n",
      "Train loss and acc of batch 30: 47.978416442871094, 1.0\n",
      "Train loss and acc of batch 31: 48.19517517089844, 0.984375\n",
      "Train loss and acc of batch 32: 47.97840118408203, 1.0\n",
      "Train loss and acc of batch 33: 47.978389739990234, 1.0\n",
      "Train loss and acc of batch 34: 48.57408142089844, 0.984375\n",
      "Train loss and acc of batch 35: 48.411903381347656, 0.96875\n",
      "Train loss and acc of batch 36: 47.978363037109375, 1.0\n",
      "Train loss and acc of batch 37: 48.7315788269043, 0.984375\n",
      "Train loss and acc of batch 38: 49.3272705078125, 0.96875\n",
      "Train loss and acc of batch 39: 48.195098876953125, 0.984375\n",
      "Train loss and acc of batch 40: 47.978328704833984, 1.0\n",
      "Train loss and acc of batch 41: 49.32725143432617, 0.96875\n",
      "Train loss and acc of batch 42: 47.978309631347656, 1.0\n",
      "Train loss and acc of batch 43: 48.574005126953125, 0.984375\n",
      "Train loss and acc of batch 44: 47.978294372558594, 1.0\n",
      "Train loss and acc of batch 45: 48.57398986816406, 0.984375\n",
      "Train loss and acc of batch 46: 48.264129638671875, 0.984375\n",
      "Train loss and acc of batch 47: 47.97826385498047, 1.0\n",
      "Train loss and acc of batch 48: 47.9782600402832, 1.0\n",
      "Train loss and acc of batch 49: 47.978248596191406, 1.0\n",
      "Train loss and acc of batch 50: 48.573944091796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.32716369628906, 0.96875\n",
      "Train loss and acc of batch 52: 49.23406219482422, 0.953125\n",
      "Train loss and acc of batch 53: 47.97821044921875, 1.0\n",
      "Train loss and acc of batch 54: 48.194969177246094, 0.984375\n",
      "Train loss and acc of batch 55: 47.978187561035156, 1.0\n",
      "Train loss and acc of batch 56: 47.978187561035156, 1.0\n",
      "Train loss and acc of batch 57: 48.573883056640625, 0.984375\n",
      "Train loss and acc of batch 58: 47.978172302246094, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 59: 47.9781608581543, 1.0\n",
      "Train loss and acc of batch 60: 47.9781494140625, 1.0\n",
      "Train loss and acc of batch 61: 47.9781379699707, 1.0\n",
      "Train loss and acc of batch 62: 48.19490051269531, 0.984375\n",
      "Train loss and acc of batch 63: 49.169532775878906, 0.96875\n",
      "Train loss and acc of batch 64: 48.19488525390625, 0.984375\n",
      "Train loss and acc of batch 65: 47.97810363769531, 1.0\n",
      "Train loss and acc of batch 66: 47.97809982299805, 1.0\n",
      "Train loss and acc of batch 67: 48.790550231933594, 0.96875\n",
      "Train loss and acc of batch 68: 48.57378387451172, 0.984375\n",
      "Train loss and acc of batch 69: 48.19483184814453, 0.984375\n",
      "Train loss and acc of batch 70: 47.97806167602539, 1.0\n",
      "Training accuracy and loss of epoch #127: 0.9890, 48.3094\n",
      "Saved model by train loss 48.309389839709645\n",
      "Train loss and acc of batch 0: 47.978050231933594, 1.0\n",
      "Train loss and acc of batch 1: 47.97804260253906, 1.0\n",
      "Train loss and acc of batch 2: 48.263885498046875, 0.984375\n",
      "Train loss and acc of batch 3: 48.194793701171875, 0.984375\n",
      "Train loss and acc of batch 4: 47.9780158996582, 1.0\n",
      "Train loss and acc of batch 5: 49.326934814453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.48061752319336, 0.96875\n",
      "Train loss and acc of batch 7: 47.97799301147461, 1.0\n",
      "Train loss and acc of batch 8: 48.57368469238281, 0.984375\n",
      "Train loss and acc of batch 9: 48.263824462890625, 0.984375\n",
      "Train loss and acc of batch 10: 47.977962493896484, 1.0\n",
      "Train loss and acc of batch 11: 47.97795486450195, 1.0\n",
      "Train loss and acc of batch 12: 48.731170654296875, 0.984375\n",
      "Train loss and acc of batch 13: 48.1947021484375, 0.984375\n",
      "Train loss and acc of batch 14: 48.19469451904297, 0.984375\n",
      "Train loss and acc of batch 15: 48.57362365722656, 0.984375\n",
      "Train loss and acc of batch 16: 48.57361602783203, 0.984375\n",
      "Train loss and acc of batch 17: 48.73112106323242, 0.984375\n",
      "Train loss and acc of batch 18: 48.85944366455078, 0.96875\n",
      "Train loss and acc of batch 19: 47.977882385253906, 1.0\n",
      "Train loss and acc of batch 20: 47.977874755859375, 1.0\n",
      "Train loss and acc of batch 21: 48.573570251464844, 0.984375\n",
      "Train loss and acc of batch 22: 48.57355499267578, 0.984375\n",
      "Train loss and acc of batch 23: 48.194618225097656, 0.984375\n",
      "Train loss and acc of batch 24: 48.57353973388672, 0.984375\n",
      "Train loss and acc of batch 25: 47.97782897949219, 1.0\n",
      "Train loss and acc of batch 26: 47.977821350097656, 1.0\n",
      "Train loss and acc of batch 27: 47.97780990600586, 1.0\n",
      "Train loss and acc of batch 28: 47.97780227661133, 1.0\n",
      "Train loss and acc of batch 29: 48.57349395751953, 0.984375\n",
      "Train loss and acc of batch 30: 47.977787017822266, 1.0\n",
      "Train loss and acc of batch 31: 48.194541931152344, 0.984375\n",
      "Train loss and acc of batch 32: 47.97776412963867, 1.0\n",
      "Train loss and acc of batch 33: 47.97775650024414, 1.0\n",
      "Train loss and acc of batch 34: 48.573455810546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.4112663269043, 0.96875\n",
      "Train loss and acc of batch 36: 47.97773361206055, 1.0\n",
      "Train loss and acc of batch 37: 48.7309455871582, 0.984375\n",
      "Train loss and acc of batch 38: 49.326637268066406, 0.96875\n",
      "Train loss and acc of batch 39: 48.19447326660156, 0.984375\n",
      "Train loss and acc of batch 40: 47.97769546508789, 1.0\n",
      "Train loss and acc of batch 41: 49.32661437988281, 0.96875\n",
      "Train loss and acc of batch 42: 47.9776725769043, 1.0\n",
      "Train loss and acc of batch 43: 48.57337188720703, 0.984375\n",
      "Train loss and acc of batch 44: 47.977664947509766, 1.0\n",
      "Train loss and acc of batch 45: 48.57335662841797, 0.984375\n",
      "Train loss and acc of batch 46: 48.26349639892578, 0.984375\n",
      "Train loss and acc of batch 47: 47.97763442993164, 1.0\n",
      "Train loss and acc of batch 48: 47.977622985839844, 1.0\n",
      "Train loss and acc of batch 49: 47.97761917114258, 1.0\n",
      "Train loss and acc of batch 50: 48.57331085205078, 0.984375\n",
      "Train loss and acc of batch 51: 49.32652282714844, 0.96875\n",
      "Train loss and acc of batch 52: 49.233428955078125, 0.953125\n",
      "Train loss and acc of batch 53: 47.97758483886719, 1.0\n",
      "Train loss and acc of batch 54: 48.1943359375, 0.984375\n",
      "Train loss and acc of batch 55: 47.977561950683594, 1.0\n",
      "Train loss and acc of batch 56: 47.9775505065918, 1.0\n",
      "Train loss and acc of batch 57: 48.57324981689453, 0.984375\n",
      "Train loss and acc of batch 58: 47.9775390625, 1.0\n",
      "Train loss and acc of batch 59: 47.97752380371094, 1.0\n",
      "Train loss and acc of batch 60: 47.977516174316406, 1.0\n",
      "Train loss and acc of batch 61: 47.977508544921875, 1.0\n",
      "Train loss and acc of batch 62: 48.19426727294922, 0.984375\n",
      "Train loss and acc of batch 63: 49.16889572143555, 0.96875\n",
      "Train loss and acc of batch 64: 48.194244384765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.97747039794922, 1.0\n",
      "Train loss and acc of batch 66: 47.97746276855469, 1.0\n",
      "Train loss and acc of batch 67: 48.789920806884766, 0.96875\n",
      "Train loss and acc of batch 68: 48.573150634765625, 0.984375\n",
      "Train loss and acc of batch 69: 48.19419860839844, 0.984375\n",
      "Train loss and acc of batch 70: 47.97742462158203, 1.0\n",
      "Training accuracy and loss of epoch #128: 0.9890, 48.3088\n",
      "Saved model by train loss 48.308756438779156\n",
      "Train loss and acc of batch 0: 47.977420806884766, 1.0\n",
      "Train loss and acc of batch 1: 47.977413177490234, 1.0\n",
      "Train loss and acc of batch 2: 48.26325225830078, 0.984375\n",
      "Train loss and acc of batch 3: 48.19416046142578, 0.984375\n",
      "Train loss and acc of batch 4: 47.977386474609375, 1.0\n",
      "Train loss and acc of batch 5: 49.32630157470703, 0.96875\n",
      "Train loss and acc of batch 6: 48.479984283447266, 0.96875\n",
      "Train loss and acc of batch 7: 47.97735595703125, 1.0\n",
      "Train loss and acc of batch 8: 48.57304382324219, 0.984375\n",
      "Train loss and acc of batch 9: 48.26319122314453, 0.984375\n",
      "Train loss and acc of batch 10: 47.977333068847656, 1.0\n",
      "Train loss and acc of batch 11: 47.977325439453125, 1.0\n",
      "Train loss and acc of batch 12: 48.730533599853516, 0.984375\n",
      "Train loss and acc of batch 13: 48.194068908691406, 0.984375\n",
      "Train loss and acc of batch 14: 48.194053649902344, 0.984375\n",
      "Train loss and acc of batch 15: 48.57299041748047, 0.984375\n",
      "Train loss and acc of batch 16: 48.572975158691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.730491638183594, 0.984375\n",
      "Train loss and acc of batch 18: 48.85881042480469, 0.96875\n",
      "Train loss and acc of batch 19: 47.97724533081055, 1.0\n",
      "Train loss and acc of batch 20: 47.97724151611328, 1.0\n",
      "Train loss and acc of batch 21: 48.57292938232422, 0.984375\n",
      "Train loss and acc of batch 22: 48.57292175292969, 0.984375\n",
      "Train loss and acc of batch 23: 48.19397735595703, 0.984375\n",
      "Train loss and acc of batch 24: 48.572906494140625, 0.984375\n",
      "Train loss and acc of batch 25: 47.97719955444336, 1.0\n",
      "Train loss and acc of batch 26: 47.97718811035156, 1.0\n",
      "Train loss and acc of batch 27: 47.97718048095703, 1.0\n",
      "Train loss and acc of batch 28: 47.977169036865234, 1.0\n",
      "Train loss and acc of batch 29: 48.57286071777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.97714614868164, 1.0\n",
      "Train loss and acc of batch 31: 48.19390869140625, 0.984375\n",
      "Train loss and acc of batch 32: 47.977134704589844, 1.0\n",
      "Train loss and acc of batch 33: 47.97711944580078, 1.0\n",
      "Train loss and acc of batch 34: 48.57281494140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.41062927246094, 0.96875\n",
      "Train loss and acc of batch 36: 47.97709655761719, 1.0\n",
      "Train loss and acc of batch 37: 48.73031234741211, 0.984375\n",
      "Train loss and acc of batch 38: 49.32600402832031, 0.96875\n",
      "Train loss and acc of batch 39: 48.19384002685547, 0.984375\n",
      "Train loss and acc of batch 40: 47.9770622253418, 1.0\n",
      "Train loss and acc of batch 41: 49.32597732543945, 0.96875\n",
      "Train loss and acc of batch 42: 47.97704315185547, 1.0\n",
      "Train loss and acc of batch 43: 48.57273864746094, 0.984375\n",
      "Train loss and acc of batch 44: 47.977020263671875, 1.0\n",
      "Train loss and acc of batch 45: 48.572715759277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.26286315917969, 0.984375\n",
      "Train loss and acc of batch 47: 47.97699737548828, 1.0\n",
      "Train loss and acc of batch 48: 47.976993560791016, 1.0\n",
      "Train loss and acc of batch 49: 47.97697830200195, 1.0\n",
      "Train loss and acc of batch 50: 48.572669982910156, 0.984375\n",
      "Train loss and acc of batch 51: 49.325889587402344, 0.96875\n",
      "Train loss and acc of batch 52: 49.23279571533203, 0.953125\n",
      "Train loss and acc of batch 53: 47.97694778442383, 1.0\n",
      "Train loss and acc of batch 54: 48.193702697753906, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 55: 47.9769287109375, 1.0\n",
      "Train loss and acc of batch 56: 47.9769172668457, 1.0\n",
      "Train loss and acc of batch 57: 48.572608947753906, 0.984375\n",
      "Train loss and acc of batch 58: 47.97689437866211, 1.0\n",
      "Train loss and acc of batch 59: 47.97689437866211, 1.0\n",
      "Train loss and acc of batch 60: 47.97688674926758, 1.0\n",
      "Train loss and acc of batch 61: 47.97687530517578, 1.0\n",
      "Train loss and acc of batch 62: 48.193626403808594, 0.984375\n",
      "Train loss and acc of batch 63: 49.16825485229492, 0.96875\n",
      "Train loss and acc of batch 64: 48.19361114501953, 0.984375\n",
      "Train loss and acc of batch 65: 47.97684097290039, 1.0\n",
      "Train loss and acc of batch 66: 47.97683334350586, 1.0\n",
      "Train loss and acc of batch 67: 48.78928756713867, 0.96875\n",
      "Train loss and acc of batch 68: 48.57251739501953, 0.984375\n",
      "Train loss and acc of batch 69: 48.193565368652344, 0.984375\n",
      "Train loss and acc of batch 70: 47.97679138183594, 1.0\n",
      "Training accuracy and loss of epoch #129: 0.9890, 48.3081\n",
      "Saved model by train loss 48.308121802101674\n",
      "Train loss and acc of batch 0: 47.976783752441406, 1.0\n",
      "Train loss and acc of batch 1: 47.97677230834961, 1.0\n",
      "Train loss and acc of batch 2: 48.26261901855469, 0.984375\n",
      "Train loss and acc of batch 3: 48.19352722167969, 0.984375\n",
      "Train loss and acc of batch 4: 47.976749420166016, 1.0\n",
      "Train loss and acc of batch 5: 49.325660705566406, 0.96875\n",
      "Train loss and acc of batch 6: 48.479347229003906, 0.96875\n",
      "Train loss and acc of batch 7: 47.97671890258789, 1.0\n",
      "Train loss and acc of batch 8: 48.572418212890625, 0.984375\n",
      "Train loss and acc of batch 9: 48.26255798339844, 0.984375\n",
      "Train loss and acc of batch 10: 47.9766960144043, 1.0\n",
      "Train loss and acc of batch 11: 47.976688385009766, 1.0\n",
      "Train loss and acc of batch 12: 48.72990417480469, 0.984375\n",
      "Train loss and acc of batch 13: 48.19343566894531, 0.984375\n",
      "Train loss and acc of batch 14: 48.19342041015625, 0.984375\n",
      "Train loss and acc of batch 15: 48.572349548339844, 0.984375\n",
      "Train loss and acc of batch 16: 48.57234191894531, 0.984375\n",
      "Train loss and acc of batch 17: 48.7298583984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.858177185058594, 0.96875\n",
      "Train loss and acc of batch 19: 47.97661590576172, 1.0\n",
      "Train loss and acc of batch 20: 47.97660827636719, 1.0\n",
      "Train loss and acc of batch 21: 48.572296142578125, 0.984375\n",
      "Train loss and acc of batch 22: 48.572288513183594, 0.984375\n",
      "Train loss and acc of batch 23: 47.97658157348633, 1.0\n",
      "Train loss and acc of batch 24: 48.572265625, 0.984375\n",
      "Train loss and acc of batch 25: 47.976566314697266, 1.0\n",
      "Train loss and acc of batch 26: 47.9765510559082, 1.0\n",
      "Train loss and acc of batch 27: 47.97654342651367, 1.0\n",
      "Train loss and acc of batch 28: 47.976531982421875, 1.0\n",
      "Train loss and acc of batch 29: 48.57221984863281, 0.984375\n",
      "Train loss and acc of batch 30: 47.97651290893555, 1.0\n",
      "Train loss and acc of batch 31: 48.193275451660156, 0.984375\n",
      "Train loss and acc of batch 32: 47.976497650146484, 1.0\n",
      "Train loss and acc of batch 33: 47.97649383544922, 1.0\n",
      "Train loss and acc of batch 34: 48.572181701660156, 0.984375\n",
      "Train loss and acc of batch 35: 48.40999984741211, 0.96875\n",
      "Train loss and acc of batch 36: 47.976463317871094, 1.0\n",
      "Train loss and acc of batch 37: 48.72967529296875, 0.984375\n",
      "Train loss and acc of batch 38: 49.32537078857422, 0.96875\n",
      "Train loss and acc of batch 39: 48.193206787109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.9764289855957, 1.0\n",
      "Train loss and acc of batch 41: 49.32534408569336, 0.96875\n",
      "Train loss and acc of batch 42: 47.976409912109375, 1.0\n",
      "Train loss and acc of batch 43: 48.57209777832031, 0.984375\n",
      "Train loss and acc of batch 44: 47.97639083862305, 1.0\n",
      "Train loss and acc of batch 45: 48.57208251953125, 0.984375\n",
      "Train loss and acc of batch 46: 48.262229919433594, 0.984375\n",
      "Train loss and acc of batch 47: 47.97636413574219, 1.0\n",
      "Train loss and acc of batch 48: 47.97636032104492, 1.0\n",
      "Train loss and acc of batch 49: 47.97634506225586, 1.0\n",
      "Train loss and acc of batch 50: 48.572044372558594, 0.984375\n",
      "Train loss and acc of batch 51: 49.32525634765625, 0.96875\n",
      "Train loss and acc of batch 52: 49.23216247558594, 0.953125\n",
      "Train loss and acc of batch 53: 47.976314544677734, 1.0\n",
      "Train loss and acc of batch 54: 48.19306945800781, 0.984375\n",
      "Train loss and acc of batch 55: 47.976295471191406, 1.0\n",
      "Train loss and acc of batch 56: 47.97628402709961, 1.0\n",
      "Train loss and acc of batch 57: 48.57196807861328, 0.984375\n",
      "Train loss and acc of batch 58: 47.97626495361328, 1.0\n",
      "Train loss and acc of batch 59: 47.976261138916016, 1.0\n",
      "Train loss and acc of batch 60: 47.97624969482422, 1.0\n",
      "Train loss and acc of batch 61: 47.97624206542969, 1.0\n",
      "Train loss and acc of batch 62: 48.19300079345703, 0.984375\n",
      "Train loss and acc of batch 63: 49.16762161254883, 0.96875\n",
      "Train loss and acc of batch 64: 48.19297790527344, 0.984375\n",
      "Train loss and acc of batch 65: 47.976200103759766, 1.0\n",
      "Train loss and acc of batch 66: 47.9761962890625, 1.0\n",
      "Train loss and acc of batch 67: 48.78865432739258, 0.96875\n",
      "Train loss and acc of batch 68: 48.571876525878906, 0.984375\n",
      "Train loss and acc of batch 69: 48.19293212890625, 0.984375\n",
      "Train loss and acc of batch 70: 47.97616195678711, 1.0\n",
      "Training accuracy and loss of epoch #130: 0.9892, 48.3044\n",
      "Saved model by train acc 0.9892165492957746\n",
      "Saved model by train loss 48.30443465541786\n",
      "Train loss and acc of batch 0: 47.97614669799805, 1.0\n",
      "Train loss and acc of batch 1: 47.97614288330078, 1.0\n",
      "Train loss and acc of batch 2: 48.261985778808594, 0.984375\n",
      "Train loss and acc of batch 3: 48.19288635253906, 0.984375\n",
      "Train loss and acc of batch 4: 47.97611618041992, 1.0\n",
      "Train loss and acc of batch 5: 49.32502746582031, 0.96875\n",
      "Train loss and acc of batch 6: 48.47871398925781, 0.96875\n",
      "Train loss and acc of batch 7: 47.97608947753906, 1.0\n",
      "Train loss and acc of batch 8: 48.57178497314453, 0.984375\n",
      "Train loss and acc of batch 9: 48.261924743652344, 0.984375\n",
      "Train loss and acc of batch 10: 47.9760627746582, 1.0\n",
      "Train loss and acc of batch 11: 47.976051330566406, 1.0\n",
      "Train loss and acc of batch 12: 48.729270935058594, 0.984375\n",
      "Train loss and acc of batch 13: 48.19280242919922, 0.984375\n",
      "Train loss and acc of batch 14: 48.192787170410156, 0.984375\n",
      "Train loss and acc of batch 15: 48.57171630859375, 0.984375\n",
      "Train loss and acc of batch 16: 48.57171630859375, 0.984375\n",
      "Train loss and acc of batch 17: 48.729217529296875, 0.984375\n",
      "Train loss and acc of batch 18: 48.8575439453125, 0.96875\n",
      "Train loss and acc of batch 19: 47.975982666015625, 1.0\n",
      "Train loss and acc of batch 20: 47.975975036621094, 1.0\n",
      "Train loss and acc of batch 21: 48.57166290283203, 0.984375\n",
      "Train loss and acc of batch 22: 48.57164764404297, 0.984375\n",
      "Train loss and acc of batch 23: 47.97594451904297, 1.0\n",
      "Train loss and acc of batch 24: 48.57164001464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.97592544555664, 1.0\n",
      "Train loss and acc of batch 26: 47.975921630859375, 1.0\n",
      "Train loss and acc of batch 27: 47.97591018676758, 1.0\n",
      "Train loss and acc of batch 28: 47.97589874267578, 1.0\n",
      "Train loss and acc of batch 29: 48.57159423828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.97588348388672, 1.0\n",
      "Train loss and acc of batch 31: 48.19263458251953, 0.984375\n",
      "Train loss and acc of batch 32: 47.97586441040039, 1.0\n",
      "Train loss and acc of batch 33: 47.97585678100586, 1.0\n",
      "Train loss and acc of batch 34: 48.57154846191406, 0.984375\n",
      "Train loss and acc of batch 35: 48.40937042236328, 0.96875\n",
      "Train loss and acc of batch 36: 47.975830078125, 1.0\n",
      "Train loss and acc of batch 37: 48.72904586791992, 0.984375\n",
      "Train loss and acc of batch 38: 49.324737548828125, 0.96875\n",
      "Train loss and acc of batch 39: 48.19256591796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.97579574584961, 1.0\n",
      "Train loss and acc of batch 41: 49.32471466064453, 0.96875\n",
      "Train loss and acc of batch 42: 47.975772857666016, 1.0\n",
      "Train loss and acc of batch 43: 48.57147216796875, 0.984375\n",
      "Train loss and acc of batch 44: 47.97575759887695, 1.0\n",
      "Train loss and acc of batch 45: 48.571449279785156, 0.984375\n",
      "Train loss and acc of batch 46: 48.26158905029297, 0.984375\n",
      "Train loss and acc of batch 47: 47.97573471069336, 1.0\n",
      "Train loss and acc of batch 48: 47.97572326660156, 1.0\n",
      "Train loss and acc of batch 49: 47.97571563720703, 1.0\n",
      "Train loss and acc of batch 50: 48.57140350341797, 0.984375\n",
      "Train loss and acc of batch 51: 49.324623107910156, 0.96875\n",
      "Train loss and acc of batch 52: 49.231529235839844, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.97567367553711, 1.0\n",
      "Train loss and acc of batch 54: 48.19243621826172, 0.984375\n",
      "Train loss and acc of batch 55: 47.97566223144531, 1.0\n",
      "Train loss and acc of batch 56: 47.975650787353516, 1.0\n",
      "Train loss and acc of batch 57: 48.57134246826172, 0.984375\n",
      "Train loss and acc of batch 58: 47.97563171386719, 1.0\n",
      "Train loss and acc of batch 59: 47.97562026977539, 1.0\n",
      "Train loss and acc of batch 60: 47.97561264038086, 1.0\n",
      "Train loss and acc of batch 61: 47.97560501098633, 1.0\n",
      "Train loss and acc of batch 62: 48.192359924316406, 0.984375\n",
      "Train loss and acc of batch 63: 49.166996002197266, 0.96875\n",
      "Train loss and acc of batch 64: 48.192344665527344, 0.984375\n",
      "Train loss and acc of batch 65: 47.97557067871094, 1.0\n",
      "Train loss and acc of batch 66: 47.975563049316406, 1.0\n",
      "Train loss and acc of batch 67: 48.78801727294922, 0.96875\n",
      "Train loss and acc of batch 68: 48.57124328613281, 0.984375\n",
      "Train loss and acc of batch 69: 48.192298889160156, 0.984375\n",
      "Train loss and acc of batch 70: 47.97552490234375, 1.0\n",
      "Training accuracy and loss of epoch #131: 0.9892, 48.3038\n",
      "Saved model by train loss 48.30380087839046\n",
      "Train loss and acc of batch 0: 47.97551727294922, 1.0\n",
      "Train loss and acc of batch 1: 47.97550964355469, 1.0\n",
      "Train loss and acc of batch 2: 48.26134490966797, 0.984375\n",
      "Train loss and acc of batch 3: 48.1922607421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.97547912597656, 1.0\n",
      "Train loss and acc of batch 5: 49.32440185546875, 0.96875\n",
      "Train loss and acc of batch 6: 48.478084564208984, 0.96875\n",
      "Train loss and acc of batch 7: 47.9754524230957, 1.0\n",
      "Train loss and acc of batch 8: 48.571144104003906, 0.984375\n",
      "Train loss and acc of batch 9: 48.26128387451172, 0.984375\n",
      "Train loss and acc of batch 10: 47.975425720214844, 1.0\n",
      "Train loss and acc of batch 11: 47.97541809082031, 1.0\n",
      "Train loss and acc of batch 12: 48.72863006591797, 0.984375\n",
      "Train loss and acc of batch 13: 48.192169189453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.192161560058594, 0.984375\n",
      "Train loss and acc of batch 15: 48.571083068847656, 0.984375\n",
      "Train loss and acc of batch 16: 48.571075439453125, 0.984375\n",
      "Train loss and acc of batch 17: 48.72858810424805, 0.984375\n",
      "Train loss and acc of batch 18: 48.85690689086914, 0.96875\n",
      "Train loss and acc of batch 19: 47.97534942626953, 1.0\n",
      "Train loss and acc of batch 20: 47.97533416748047, 1.0\n",
      "Train loss and acc of batch 21: 48.57102966308594, 0.984375\n",
      "Train loss and acc of batch 22: 48.571022033691406, 0.984375\n",
      "Train loss and acc of batch 23: 47.975311279296875, 1.0\n",
      "Train loss and acc of batch 24: 48.571006774902344, 0.984375\n",
      "Train loss and acc of batch 25: 47.97529220581055, 1.0\n",
      "Train loss and acc of batch 26: 47.975284576416016, 1.0\n",
      "Train loss and acc of batch 27: 47.97527313232422, 1.0\n",
      "Train loss and acc of batch 28: 47.97526931762695, 1.0\n",
      "Train loss and acc of batch 29: 48.570960998535156, 0.984375\n",
      "Train loss and acc of batch 30: 47.97524642944336, 1.0\n",
      "Train loss and acc of batch 31: 48.19200134277344, 0.984375\n",
      "Train loss and acc of batch 32: 47.9752311706543, 1.0\n",
      "Train loss and acc of batch 33: 47.975223541259766, 1.0\n",
      "Train loss and acc of batch 34: 48.57091522216797, 0.984375\n",
      "Train loss and acc of batch 35: 48.408729553222656, 0.96875\n",
      "Train loss and acc of batch 36: 47.97520065307617, 1.0\n",
      "Train loss and acc of batch 37: 48.7284049987793, 0.984375\n",
      "Train loss and acc of batch 38: 49.32410430908203, 0.96875\n",
      "Train loss and acc of batch 39: 48.191932678222656, 0.984375\n",
      "Train loss and acc of batch 40: 47.97515869140625, 1.0\n",
      "Train loss and acc of batch 41: 49.32407760620117, 0.96875\n",
      "Train loss and acc of batch 42: 47.97514724731445, 1.0\n",
      "Train loss and acc of batch 43: 48.570831298828125, 0.984375\n",
      "Train loss and acc of batch 44: 47.97512435913086, 1.0\n",
      "Train loss and acc of batch 45: 48.57081604003906, 0.984375\n",
      "Train loss and acc of batch 46: 48.260955810546875, 0.984375\n",
      "Train loss and acc of batch 47: 47.97509765625, 1.0\n",
      "Train loss and acc of batch 48: 47.975093841552734, 1.0\n",
      "Train loss and acc of batch 49: 47.97507858276367, 1.0\n",
      "Train loss and acc of batch 50: 48.570777893066406, 0.984375\n",
      "Train loss and acc of batch 51: 49.32398223876953, 0.96875\n",
      "Train loss and acc of batch 52: 49.230892181396484, 0.953125\n",
      "Train loss and acc of batch 53: 47.97504425048828, 1.0\n",
      "Train loss and acc of batch 54: 48.191795349121094, 0.984375\n",
      "Train loss and acc of batch 55: 47.97502517700195, 1.0\n",
      "Train loss and acc of batch 56: 47.97502136230469, 1.0\n",
      "Train loss and acc of batch 57: 48.570709228515625, 0.984375\n",
      "Train loss and acc of batch 58: 47.974998474121094, 1.0\n",
      "Train loss and acc of batch 59: 47.97499084472656, 1.0\n",
      "Train loss and acc of batch 60: 47.974979400634766, 1.0\n",
      "Train loss and acc of batch 61: 47.9749755859375, 1.0\n",
      "Train loss and acc of batch 62: 48.19172668457031, 0.984375\n",
      "Train loss and acc of batch 63: 49.16635513305664, 0.96875\n",
      "Train loss and acc of batch 64: 48.19171142578125, 0.984375\n",
      "Train loss and acc of batch 65: 47.974937438964844, 1.0\n",
      "Train loss and acc of batch 66: 47.97492980957031, 1.0\n",
      "Train loss and acc of batch 67: 48.787384033203125, 0.96875\n",
      "Train loss and acc of batch 68: 48.57061004638672, 0.984375\n",
      "Train loss and acc of batch 69: 48.19166564941406, 0.984375\n",
      "Train loss and acc of batch 70: 47.974891662597656, 1.0\n",
      "Training accuracy and loss of epoch #132: 0.9892, 48.3032\n",
      "Saved model by train loss 48.30316683272241\n",
      "Train loss and acc of batch 0: 47.97488021850586, 1.0\n",
      "Train loss and acc of batch 1: 47.97487258911133, 1.0\n",
      "Train loss and acc of batch 2: 48.260711669921875, 0.984375\n",
      "Train loss and acc of batch 3: 48.191619873046875, 0.984375\n",
      "Train loss and acc of batch 4: 47.974849700927734, 1.0\n",
      "Train loss and acc of batch 5: 49.323760986328125, 0.96875\n",
      "Train loss and acc of batch 6: 48.477447509765625, 0.96875\n",
      "Train loss and acc of batch 7: 47.974822998046875, 1.0\n",
      "Train loss and acc of batch 8: 48.57051086425781, 0.984375\n",
      "Train loss and acc of batch 9: 48.260658264160156, 0.984375\n",
      "Train loss and acc of batch 10: 47.97480010986328, 1.0\n",
      "Train loss and acc of batch 11: 47.97478103637695, 1.0\n",
      "Train loss and acc of batch 12: 48.727996826171875, 0.984375\n",
      "Train loss and acc of batch 13: 48.1915283203125, 0.984375\n",
      "Train loss and acc of batch 14: 48.19152069091797, 0.984375\n",
      "Train loss and acc of batch 15: 48.57044982910156, 0.984375\n",
      "Train loss and acc of batch 16: 48.57044219970703, 0.984375\n",
      "Train loss and acc of batch 17: 48.72795486450195, 0.984375\n",
      "Train loss and acc of batch 18: 48.85627746582031, 0.96875\n",
      "Train loss and acc of batch 19: 47.97471618652344, 1.0\n",
      "Train loss and acc of batch 20: 47.974700927734375, 1.0\n",
      "Train loss and acc of batch 21: 48.570396423339844, 0.984375\n",
      "Train loss and acc of batch 22: 48.57038879394531, 0.984375\n",
      "Train loss and acc of batch 23: 47.97468185424805, 1.0\n",
      "Train loss and acc of batch 24: 48.57036590576172, 0.984375\n",
      "Train loss and acc of batch 25: 47.97465515136719, 1.0\n",
      "Train loss and acc of batch 26: 47.97465133666992, 1.0\n",
      "Train loss and acc of batch 27: 47.97464370727539, 1.0\n",
      "Train loss and acc of batch 28: 47.97462844848633, 1.0\n",
      "Train loss and acc of batch 29: 48.57032775878906, 0.984375\n",
      "Train loss and acc of batch 30: 47.974613189697266, 1.0\n",
      "Train loss and acc of batch 31: 48.191368103027344, 0.984375\n",
      "Train loss and acc of batch 32: 47.9745979309082, 1.0\n",
      "Train loss and acc of batch 33: 47.97458267211914, 1.0\n",
      "Train loss and acc of batch 34: 48.570281982421875, 0.984375\n",
      "Train loss and acc of batch 35: 48.408103942871094, 0.96875\n",
      "Train loss and acc of batch 36: 47.97455978393555, 1.0\n",
      "Train loss and acc of batch 37: 48.727779388427734, 0.984375\n",
      "Train loss and acc of batch 38: 49.32347106933594, 0.96875\n",
      "Train loss and acc of batch 39: 48.19129180908203, 0.984375\n",
      "Train loss and acc of batch 40: 47.974525451660156, 1.0\n",
      "Train loss and acc of batch 41: 49.32344055175781, 0.96875\n",
      "Train loss and acc of batch 42: 47.97450637817383, 1.0\n",
      "Train loss and acc of batch 43: 48.57019805908203, 0.984375\n",
      "Train loss and acc of batch 44: 47.974491119384766, 1.0\n",
      "Train loss and acc of batch 45: 48.57018280029297, 0.984375\n",
      "Train loss and acc of batch 46: 48.26032257080078, 0.984375\n",
      "Train loss and acc of batch 47: 47.974456787109375, 1.0\n",
      "Train loss and acc of batch 48: 47.97445297241211, 1.0\n",
      "Train loss and acc of batch 49: 47.974449157714844, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 50: 48.57013702392578, 0.984375\n",
      "Train loss and acc of batch 51: 49.32334899902344, 0.96875\n",
      "Train loss and acc of batch 52: 49.23025894165039, 0.953125\n",
      "Train loss and acc of batch 53: 47.974403381347656, 1.0\n",
      "Train loss and acc of batch 54: 48.19116973876953, 0.984375\n",
      "Train loss and acc of batch 55: 47.97439193725586, 1.0\n",
      "Train loss and acc of batch 56: 47.97438049316406, 1.0\n",
      "Train loss and acc of batch 57: 48.57007598876953, 0.984375\n",
      "Train loss and acc of batch 58: 47.974361419677734, 1.0\n",
      "Train loss and acc of batch 59: 47.9743537902832, 1.0\n",
      "Train loss and acc of batch 60: 47.97434997558594, 1.0\n",
      "Train loss and acc of batch 61: 47.974334716796875, 1.0\n",
      "Train loss and acc of batch 62: 48.19109344482422, 0.984375\n",
      "Train loss and acc of batch 63: 49.16572570800781, 0.96875\n",
      "Train loss and acc of batch 64: 48.191078186035156, 0.984375\n",
      "Train loss and acc of batch 65: 47.97430419921875, 1.0\n",
      "Train loss and acc of batch 66: 47.97429275512695, 1.0\n",
      "Train loss and acc of batch 67: 48.786746978759766, 0.96875\n",
      "Train loss and acc of batch 68: 48.569976806640625, 0.984375\n",
      "Train loss and acc of batch 69: 48.19103240966797, 0.984375\n",
      "Train loss and acc of batch 70: 47.9742546081543, 1.0\n",
      "Training accuracy and loss of epoch #133: 0.9892, 48.3025\n",
      "Saved model by train loss 48.30253224977305\n",
      "Train loss and acc of batch 0: 47.974246978759766, 1.0\n",
      "Train loss and acc of batch 1: 47.97423553466797, 1.0\n",
      "Train loss and acc of batch 2: 48.26008605957031, 0.984375\n",
      "Train loss and acc of batch 3: 48.19098663330078, 0.984375\n",
      "Train loss and acc of batch 4: 47.97420883178711, 1.0\n",
      "Train loss and acc of batch 5: 49.32312774658203, 0.96875\n",
      "Train loss and acc of batch 6: 48.47681427001953, 0.96875\n",
      "Train loss and acc of batch 7: 47.974185943603516, 1.0\n",
      "Train loss and acc of batch 8: 48.56987762451172, 0.984375\n",
      "Train loss and acc of batch 9: 48.26002502441406, 0.984375\n",
      "Train loss and acc of batch 10: 47.97415542602539, 1.0\n",
      "Train loss and acc of batch 11: 47.974151611328125, 1.0\n",
      "Train loss and acc of batch 12: 48.72736740112305, 0.984375\n",
      "Train loss and acc of batch 13: 48.190895080566406, 0.984375\n",
      "Train loss and acc of batch 14: 48.190887451171875, 0.984375\n",
      "Train loss and acc of batch 15: 48.56980895996094, 0.984375\n",
      "Train loss and acc of batch 16: 48.56980895996094, 0.984375\n",
      "Train loss and acc of batch 17: 48.72732162475586, 0.984375\n",
      "Train loss and acc of batch 18: 48.85563659667969, 0.96875\n",
      "Train loss and acc of batch 19: 47.97407913208008, 1.0\n",
      "Train loss and acc of batch 20: 47.97407150268555, 1.0\n",
      "Train loss and acc of batch 21: 48.56976318359375, 0.984375\n",
      "Train loss and acc of batch 22: 48.56975555419922, 0.984375\n",
      "Train loss and acc of batch 23: 47.97404861450195, 1.0\n",
      "Train loss and acc of batch 24: 48.569732666015625, 0.984375\n",
      "Train loss and acc of batch 25: 47.974021911621094, 1.0\n",
      "Train loss and acc of batch 26: 47.9740104675293, 1.0\n",
      "Train loss and acc of batch 27: 47.97400665283203, 1.0\n",
      "Train loss and acc of batch 28: 47.9739990234375, 1.0\n",
      "Train loss and acc of batch 29: 48.56968688964844, 0.984375\n",
      "Train loss and acc of batch 30: 47.97398376464844, 1.0\n",
      "Train loss and acc of batch 31: 48.19073486328125, 0.984375\n",
      "Train loss and acc of batch 32: 47.97395706176758, 1.0\n",
      "Train loss and acc of batch 33: 47.97395324707031, 1.0\n",
      "Train loss and acc of batch 34: 48.56964874267578, 0.984375\n",
      "Train loss and acc of batch 35: 48.407466888427734, 0.96875\n",
      "Train loss and acc of batch 36: 47.973934173583984, 1.0\n",
      "Train loss and acc of batch 37: 48.727142333984375, 0.984375\n",
      "Train loss and acc of batch 38: 49.322837829589844, 0.96875\n",
      "Train loss and acc of batch 39: 48.19066619873047, 0.984375\n",
      "Train loss and acc of batch 40: 47.97389221191406, 1.0\n",
      "Train loss and acc of batch 41: 49.32280731201172, 0.96875\n",
      "Train loss and acc of batch 42: 47.973873138427734, 1.0\n",
      "Train loss and acc of batch 43: 48.56956481933594, 0.984375\n",
      "Train loss and acc of batch 44: 47.97385787963867, 1.0\n",
      "Train loss and acc of batch 45: 48.569549560546875, 0.984375\n",
      "Train loss and acc of batch 46: 48.25968933105469, 0.984375\n",
      "Train loss and acc of batch 47: 47.97383117675781, 1.0\n",
      "Train loss and acc of batch 48: 47.973819732666016, 1.0\n",
      "Train loss and acc of batch 49: 47.973812103271484, 1.0\n",
      "Train loss and acc of batch 50: 48.56950378417969, 0.984375\n",
      "Train loss and acc of batch 51: 49.322715759277344, 0.96875\n",
      "Train loss and acc of batch 52: 49.2296257019043, 0.953125\n",
      "Train loss and acc of batch 53: 47.973777770996094, 1.0\n",
      "Train loss and acc of batch 54: 48.190528869628906, 0.984375\n",
      "Train loss and acc of batch 55: 47.9737548828125, 1.0\n",
      "Train loss and acc of batch 56: 47.97374725341797, 1.0\n",
      "Train loss and acc of batch 57: 48.56944274902344, 0.984375\n",
      "Train loss and acc of batch 58: 47.973731994628906, 1.0\n",
      "Train loss and acc of batch 59: 47.973724365234375, 1.0\n",
      "Train loss and acc of batch 60: 47.97371292114258, 1.0\n",
      "Train loss and acc of batch 61: 47.97370147705078, 1.0\n",
      "Train loss and acc of batch 62: 48.190460205078125, 0.984375\n",
      "Train loss and acc of batch 63: 49.16508865356445, 0.96875\n",
      "Train loss and acc of batch 64: 48.19044494628906, 0.984375\n",
      "Train loss and acc of batch 65: 47.97366714477539, 1.0\n",
      "Train loss and acc of batch 66: 47.97365951538086, 1.0\n",
      "Train loss and acc of batch 67: 48.7861213684082, 0.96875\n",
      "Train loss and acc of batch 68: 48.56934356689453, 0.984375\n",
      "Train loss and acc of batch 69: 48.190391540527344, 0.984375\n",
      "Train loss and acc of batch 70: 47.97362518310547, 1.0\n",
      "Training accuracy and loss of epoch #134: 0.9892, 48.3019\n",
      "Saved model by train loss 48.301898526473785\n",
      "Train loss and acc of batch 0: 47.973609924316406, 1.0\n",
      "Train loss and acc of batch 1: 47.973609924316406, 1.0\n",
      "Train loss and acc of batch 2: 48.25945281982422, 0.984375\n",
      "Train loss and acc of batch 3: 48.19035339355469, 0.984375\n",
      "Train loss and acc of batch 4: 47.97357940673828, 1.0\n",
      "Train loss and acc of batch 5: 49.32249450683594, 0.96875\n",
      "Train loss and acc of batch 6: 48.47617721557617, 0.96875\n",
      "Train loss and acc of batch 7: 47.97355270385742, 1.0\n",
      "Train loss and acc of batch 8: 48.569244384765625, 0.984375\n",
      "Train loss and acc of batch 9: 48.25938415527344, 0.984375\n",
      "Train loss and acc of batch 10: 47.97352981567383, 1.0\n",
      "Train loss and acc of batch 11: 47.9735221862793, 1.0\n",
      "Train loss and acc of batch 12: 48.72673034667969, 0.984375\n",
      "Train loss and acc of batch 13: 48.19025421142578, 0.984375\n",
      "Train loss and acc of batch 14: 48.19025421142578, 0.984375\n",
      "Train loss and acc of batch 15: 48.569183349609375, 0.984375\n",
      "Train loss and acc of batch 16: 48.569175720214844, 0.984375\n",
      "Train loss and acc of batch 17: 48.7266845703125, 0.984375\n",
      "Train loss and acc of batch 18: 48.85500717163086, 0.96875\n",
      "Train loss and acc of batch 19: 47.973445892333984, 1.0\n",
      "Train loss and acc of batch 20: 47.97343826293945, 1.0\n",
      "Train loss and acc of batch 21: 48.569122314453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.569122314453125, 0.984375\n",
      "Train loss and acc of batch 23: 47.973411560058594, 1.0\n",
      "Train loss and acc of batch 24: 48.56909942626953, 0.984375\n",
      "Train loss and acc of batch 25: 47.973392486572266, 1.0\n",
      "Train loss and acc of batch 26: 47.973388671875, 1.0\n",
      "Train loss and acc of batch 27: 47.97337341308594, 1.0\n",
      "Train loss and acc of batch 28: 47.973365783691406, 1.0\n",
      "Train loss and acc of batch 29: 48.569053649902344, 0.984375\n",
      "Train loss and acc of batch 30: 47.97334671020508, 1.0\n",
      "Train loss and acc of batch 31: 48.190101623535156, 0.984375\n",
      "Train loss and acc of batch 32: 47.973331451416016, 1.0\n",
      "Train loss and acc of batch 33: 47.97332000732422, 1.0\n",
      "Train loss and acc of batch 34: 48.56901550292969, 0.984375\n",
      "Train loss and acc of batch 35: 48.40683364868164, 0.96875\n",
      "Train loss and acc of batch 36: 47.97329330444336, 1.0\n",
      "Train loss and acc of batch 37: 48.72650909423828, 0.984375\n",
      "Train loss and acc of batch 38: 49.32219696044922, 0.96875\n",
      "Train loss and acc of batch 39: 48.190032958984375, 0.984375\n",
      "Train loss and acc of batch 40: 47.973262786865234, 1.0\n",
      "Train loss and acc of batch 41: 49.32217788696289, 0.96875\n",
      "Train loss and acc of batch 42: 47.973243713378906, 1.0\n",
      "Train loss and acc of batch 43: 48.568939208984375, 0.984375\n",
      "Train loss and acc of batch 44: 47.97322082519531, 1.0\n",
      "Train loss and acc of batch 45: 48.56891632080078, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 46: 48.259056091308594, 0.984375\n",
      "Train loss and acc of batch 47: 47.97319412231445, 1.0\n",
      "Train loss and acc of batch 48: 47.97319412231445, 1.0\n",
      "Train loss and acc of batch 49: 47.973175048828125, 1.0\n",
      "Train loss and acc of batch 50: 48.568870544433594, 0.984375\n",
      "Train loss and acc of batch 51: 49.32208251953125, 0.96875\n",
      "Train loss and acc of batch 52: 49.2289924621582, 0.953125\n",
      "Train loss and acc of batch 53: 47.973140716552734, 1.0\n",
      "Train loss and acc of batch 54: 48.189903259277344, 0.984375\n",
      "Train loss and acc of batch 55: 47.97312545776367, 1.0\n",
      "Train loss and acc of batch 56: 47.97311782836914, 1.0\n",
      "Train loss and acc of batch 57: 48.568809509277344, 0.984375\n",
      "Train loss and acc of batch 58: 47.97309112548828, 1.0\n",
      "Train loss and acc of batch 59: 47.97309112548828, 1.0\n",
      "Train loss and acc of batch 60: 47.973079681396484, 1.0\n",
      "Train loss and acc of batch 61: 47.97307205200195, 1.0\n",
      "Train loss and acc of batch 62: 48.18982696533203, 0.984375\n",
      "Train loss and acc of batch 63: 49.164459228515625, 0.96875\n",
      "Train loss and acc of batch 64: 48.18980407714844, 0.984375\n",
      "Train loss and acc of batch 65: 47.97303771972656, 1.0\n",
      "Train loss and acc of batch 66: 47.9730224609375, 1.0\n",
      "Train loss and acc of batch 67: 48.785484313964844, 0.96875\n",
      "Train loss and acc of batch 68: 48.56871032714844, 0.984375\n",
      "Train loss and acc of batch 69: 48.18976593017578, 0.984375\n",
      "Train loss and acc of batch 70: 47.972991943359375, 1.0\n",
      "Training accuracy and loss of epoch #135: 0.9892, 48.3013\n",
      "Saved model by train loss 48.301265555368346\n",
      "Train loss and acc of batch 0: 47.972984313964844, 1.0\n",
      "Train loss and acc of batch 1: 47.97296905517578, 1.0\n",
      "Train loss and acc of batch 2: 48.258811950683594, 0.984375\n",
      "Train loss and acc of batch 3: 48.189720153808594, 0.984375\n",
      "Train loss and acc of batch 4: 47.97294616699219, 1.0\n",
      "Train loss and acc of batch 5: 49.321861267089844, 0.96875\n",
      "Train loss and acc of batch 6: 48.475547790527344, 0.96875\n",
      "Train loss and acc of batch 7: 47.97291564941406, 1.0\n",
      "Train loss and acc of batch 8: 48.56861114501953, 0.984375\n",
      "Train loss and acc of batch 9: 48.258750915527344, 0.984375\n",
      "Train loss and acc of batch 10: 47.972896575927734, 1.0\n",
      "Train loss and acc of batch 11: 47.97288131713867, 1.0\n",
      "Train loss and acc of batch 12: 48.726097106933594, 0.984375\n",
      "Train loss and acc of batch 13: 48.18962860107422, 0.984375\n",
      "Train loss and acc of batch 14: 48.18962097167969, 0.984375\n",
      "Train loss and acc of batch 15: 48.56855010986328, 0.984375\n",
      "Train loss and acc of batch 16: 48.56853485107422, 0.984375\n",
      "Train loss and acc of batch 17: 48.72605514526367, 0.984375\n",
      "Train loss and acc of batch 18: 48.854373931884766, 0.96875\n",
      "Train loss and acc of batch 19: 47.97281265258789, 1.0\n",
      "Train loss and acc of batch 20: 47.97280502319336, 1.0\n",
      "Train loss and acc of batch 21: 48.56849670410156, 0.984375\n",
      "Train loss and acc of batch 22: 48.56848907470703, 0.984375\n",
      "Train loss and acc of batch 23: 48.189537048339844, 0.984375\n",
      "Train loss and acc of batch 24: 48.56847381591797, 0.984375\n",
      "Train loss and acc of batch 25: 47.97275924682617, 1.0\n",
      "Train loss and acc of batch 26: 47.97275161743164, 1.0\n",
      "Train loss and acc of batch 27: 47.97274398803711, 1.0\n",
      "Train loss and acc of batch 28: 47.97273254394531, 1.0\n",
      "Train loss and acc of batch 29: 48.56842041015625, 0.984375\n",
      "Train loss and acc of batch 30: 47.97270965576172, 1.0\n",
      "Train loss and acc of batch 31: 48.18946838378906, 0.984375\n",
      "Train loss and acc of batch 32: 47.972694396972656, 1.0\n",
      "Train loss and acc of batch 33: 47.972686767578125, 1.0\n",
      "Train loss and acc of batch 34: 48.56837463378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.40620040893555, 0.96875\n",
      "Train loss and acc of batch 36: 47.972660064697266, 1.0\n",
      "Train loss and acc of batch 37: 48.72587585449219, 0.984375\n",
      "Train loss and acc of batch 38: 49.321571350097656, 0.96875\n",
      "Train loss and acc of batch 39: 48.18939971923828, 0.984375\n",
      "Train loss and acc of batch 40: 47.97262191772461, 1.0\n",
      "Train loss and acc of batch 41: 49.32154846191406, 0.96875\n",
      "Train loss and acc of batch 42: 47.97260665893555, 1.0\n",
      "Train loss and acc of batch 43: 48.56829071044922, 0.984375\n",
      "Train loss and acc of batch 44: 47.97258758544922, 1.0\n",
      "Train loss and acc of batch 45: 48.568275451660156, 0.984375\n",
      "Train loss and acc of batch 46: 48.2584228515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.972564697265625, 1.0\n",
      "Train loss and acc of batch 48: 47.97255325317383, 1.0\n",
      "Train loss and acc of batch 49: 47.9725456237793, 1.0\n",
      "Train loss and acc of batch 50: 48.5682373046875, 0.984375\n",
      "Train loss and acc of batch 51: 49.321449279785156, 0.96875\n",
      "Train loss and acc of batch 52: 49.22835922241211, 0.953125\n",
      "Train loss and acc of batch 53: 47.97250747680664, 1.0\n",
      "Train loss and acc of batch 54: 48.18927001953125, 0.984375\n",
      "Train loss and acc of batch 55: 47.97249221801758, 1.0\n",
      "Train loss and acc of batch 56: 47.97248458862305, 1.0\n",
      "Train loss and acc of batch 57: 48.56816864013672, 0.984375\n",
      "Train loss and acc of batch 58: 47.972469329833984, 1.0\n",
      "Train loss and acc of batch 59: 47.972450256347656, 1.0\n",
      "Train loss and acc of batch 60: 47.97244644165039, 1.0\n",
      "Train loss and acc of batch 61: 47.972434997558594, 1.0\n",
      "Train loss and acc of batch 62: 48.189186096191406, 0.984375\n",
      "Train loss and acc of batch 63: 49.163818359375, 0.96875\n",
      "Train loss and acc of batch 64: 48.189178466796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.9724006652832, 1.0\n",
      "Train loss and acc of batch 66: 47.97239303588867, 1.0\n",
      "Train loss and acc of batch 67: 48.784847259521484, 0.96875\n",
      "Train loss and acc of batch 68: 48.56806945800781, 0.984375\n",
      "Train loss and acc of batch 69: 48.18913269042969, 0.984375\n",
      "Train loss and acc of batch 70: 47.97235107421875, 1.0\n",
      "Training accuracy and loss of epoch #136: 0.9890, 48.3037\n",
      "Train loss and acc of batch 0: 47.97234344482422, 1.0\n",
      "Train loss and acc of batch 1: 47.97233963012695, 1.0\n",
      "Train loss and acc of batch 2: 48.2581787109375, 0.984375\n",
      "Train loss and acc of batch 3: 48.18907928466797, 0.984375\n",
      "Train loss and acc of batch 4: 47.97230911254883, 1.0\n",
      "Train loss and acc of batch 5: 49.32122039794922, 0.96875\n",
      "Train loss and acc of batch 6: 48.474910736083984, 0.96875\n",
      "Train loss and acc of batch 7: 47.972286224365234, 1.0\n",
      "Train loss and acc of batch 8: 48.56797790527344, 0.984375\n",
      "Train loss and acc of batch 9: 48.25811767578125, 0.984375\n",
      "Train loss and acc of batch 10: 47.97225570678711, 1.0\n",
      "Train loss and acc of batch 11: 47.97224807739258, 1.0\n",
      "Train loss and acc of batch 12: 48.725467681884766, 0.984375\n",
      "Train loss and acc of batch 13: 48.188987731933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.18898010253906, 0.984375\n",
      "Train loss and acc of batch 15: 48.56791687011719, 0.984375\n",
      "Train loss and acc of batch 16: 48.567901611328125, 0.984375\n",
      "Train loss and acc of batch 17: 48.72541427612305, 0.984375\n",
      "Train loss and acc of batch 18: 48.853736877441406, 0.96875\n",
      "Train loss and acc of batch 19: 47.97217559814453, 1.0\n",
      "Train loss and acc of batch 20: 47.97216796875, 1.0\n",
      "Train loss and acc of batch 21: 48.56785583496094, 0.984375\n",
      "Train loss and acc of batch 22: 48.56785583496094, 0.984375\n",
      "Train loss and acc of batch 23: 48.18890380859375, 0.984375\n",
      "Train loss and acc of batch 24: 48.567832946777344, 0.984375\n",
      "Train loss and acc of batch 25: 47.97212219238281, 1.0\n",
      "Train loss and acc of batch 26: 47.97211837768555, 1.0\n",
      "Train loss and acc of batch 27: 47.97209930419922, 1.0\n",
      "Train loss and acc of batch 28: 47.97209167480469, 1.0\n",
      "Train loss and acc of batch 29: 48.567787170410156, 0.984375\n",
      "Train loss and acc of batch 30: 47.972076416015625, 1.0\n",
      "Train loss and acc of batch 31: 48.18883514404297, 0.984375\n",
      "Train loss and acc of batch 32: 47.97205352783203, 1.0\n",
      "Train loss and acc of batch 33: 47.972049713134766, 1.0\n",
      "Train loss and acc of batch 34: 48.56774139404297, 0.984375\n",
      "Train loss and acc of batch 35: 48.40556335449219, 0.96875\n",
      "Train loss and acc of batch 36: 47.972023010253906, 1.0\n",
      "Train loss and acc of batch 37: 48.72523880004883, 0.984375\n",
      "Train loss and acc of batch 38: 49.3209228515625, 0.96875\n",
      "Train loss and acc of batch 39: 48.18876647949219, 0.984375\n",
      "Train loss and acc of batch 40: 47.97199249267578, 1.0\n",
      "Train loss and acc of batch 41: 49.32090377807617, 0.96875\n",
      "Train loss and acc of batch 42: 47.97196960449219, 1.0\n",
      "Train loss and acc of batch 43: 48.567665100097656, 0.984375\n",
      "Train loss and acc of batch 44: 47.97195053100586, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 45: 48.56764221191406, 0.984375\n",
      "Train loss and acc of batch 46: 48.257781982421875, 0.984375\n",
      "Train loss and acc of batch 47: 47.971923828125, 1.0\n",
      "Train loss and acc of batch 48: 47.97191619873047, 1.0\n",
      "Train loss and acc of batch 49: 47.97190856933594, 1.0\n",
      "Train loss and acc of batch 50: 48.567604064941406, 0.984375\n",
      "Train loss and acc of batch 51: 49.32081604003906, 0.96875\n",
      "Train loss and acc of batch 52: 49.22772216796875, 0.953125\n",
      "Train loss and acc of batch 53: 47.97187042236328, 1.0\n",
      "Train loss and acc of batch 54: 48.188629150390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.97185516357422, 1.0\n",
      "Train loss and acc of batch 56: 47.97184371948242, 1.0\n",
      "Train loss and acc of batch 57: 48.567535400390625, 0.984375\n",
      "Train loss and acc of batch 58: 47.97182846069336, 1.0\n",
      "Train loss and acc of batch 59: 47.97182083129883, 1.0\n",
      "Train loss and acc of batch 60: 47.971805572509766, 1.0\n",
      "Train loss and acc of batch 61: 47.971797943115234, 1.0\n",
      "Train loss and acc of batch 62: 48.188560485839844, 0.984375\n",
      "Train loss and acc of batch 63: 49.163185119628906, 0.96875\n",
      "Train loss and acc of batch 64: 48.18853759765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.97176742553711, 1.0\n",
      "Train loss and acc of batch 66: 47.97175216674805, 1.0\n",
      "Train loss and acc of batch 67: 48.78420639038086, 0.96875\n",
      "Train loss and acc of batch 68: 48.56744384765625, 0.984375\n",
      "Train loss and acc of batch 69: 48.18849182128906, 0.984375\n",
      "Train loss and acc of batch 70: 47.971717834472656, 1.0\n",
      "Training accuracy and loss of epoch #137: 0.9890, 48.3030\n",
      "Train loss and acc of batch 0: 47.97171401977539, 1.0\n",
      "Train loss and acc of batch 1: 47.971702575683594, 1.0\n",
      "Train loss and acc of batch 2: 48.257545471191406, 0.984375\n",
      "Train loss and acc of batch 3: 48.188446044921875, 0.984375\n",
      "Train loss and acc of batch 4: 47.97167205810547, 1.0\n",
      "Train loss and acc of batch 5: 49.320594787597656, 0.96875\n",
      "Train loss and acc of batch 6: 48.474273681640625, 0.96875\n",
      "Train loss and acc of batch 7: 47.97165298461914, 1.0\n",
      "Train loss and acc of batch 8: 48.567344665527344, 0.984375\n",
      "Train loss and acc of batch 9: 48.257484436035156, 0.984375\n",
      "Train loss and acc of batch 10: 47.971622467041016, 1.0\n",
      "Train loss and acc of batch 11: 47.97161865234375, 1.0\n",
      "Train loss and acc of batch 12: 48.72482681274414, 0.984375\n",
      "Train loss and acc of batch 13: 48.1883544921875, 0.984375\n",
      "Train loss and acc of batch 14: 48.1883544921875, 0.984375\n",
      "Train loss and acc of batch 15: 48.567283630371094, 0.984375\n",
      "Train loss and acc of batch 16: 48.56726837158203, 0.984375\n",
      "Train loss and acc of batch 17: 48.72477722167969, 0.984375\n",
      "Train loss and acc of batch 18: 48.85310363769531, 0.96875\n",
      "Train loss and acc of batch 19: 47.97154235839844, 1.0\n",
      "Train loss and acc of batch 20: 47.97153091430664, 1.0\n",
      "Train loss and acc of batch 21: 48.567222595214844, 0.984375\n",
      "Train loss and acc of batch 22: 48.56721496582031, 0.984375\n",
      "Train loss and acc of batch 23: 48.188270568847656, 0.984375\n",
      "Train loss and acc of batch 24: 48.56719970703125, 0.984375\n",
      "Train loss and acc of batch 25: 47.971492767333984, 1.0\n",
      "Train loss and acc of batch 26: 47.97148132324219, 1.0\n",
      "Train loss and acc of batch 27: 47.97146987915039, 1.0\n",
      "Train loss and acc of batch 28: 47.971458435058594, 1.0\n",
      "Train loss and acc of batch 29: 48.56715393066406, 0.984375\n",
      "Train loss and acc of batch 30: 47.9714469909668, 1.0\n",
      "Train loss and acc of batch 31: 48.188194274902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.9714241027832, 1.0\n",
      "Train loss and acc of batch 33: 47.97141647338867, 1.0\n",
      "Train loss and acc of batch 34: 48.567108154296875, 0.984375\n",
      "Train loss and acc of batch 35: 48.404930114746094, 0.96875\n",
      "Train loss and acc of batch 36: 47.97139358520508, 1.0\n",
      "Train loss and acc of batch 37: 48.72460174560547, 0.984375\n",
      "Train loss and acc of batch 38: 49.32029724121094, 0.96875\n",
      "Train loss and acc of batch 39: 48.18812561035156, 0.984375\n",
      "Train loss and acc of batch 40: 47.971351623535156, 1.0\n",
      "Train loss and acc of batch 41: 49.32027053833008, 0.96875\n",
      "Train loss and acc of batch 42: 47.971336364746094, 1.0\n",
      "Train loss and acc of batch 43: 48.56703186035156, 0.984375\n",
      "Train loss and acc of batch 44: 47.971317291259766, 1.0\n",
      "Train loss and acc of batch 45: 48.56700897216797, 0.984375\n",
      "Train loss and acc of batch 46: 48.25714874267578, 0.984375\n",
      "Train loss and acc of batch 47: 47.97129440307617, 1.0\n",
      "Train loss and acc of batch 48: 47.971282958984375, 1.0\n",
      "Train loss and acc of batch 49: 47.971275329589844, 1.0\n",
      "Train loss and acc of batch 50: 48.56697082519531, 0.984375\n",
      "Train loss and acc of batch 51: 49.32018280029297, 0.96875\n",
      "Train loss and acc of batch 52: 49.22709274291992, 0.953125\n",
      "Train loss and acc of batch 53: 47.97124099731445, 1.0\n",
      "Train loss and acc of batch 54: 48.18798828125, 0.984375\n",
      "Train loss and acc of batch 55: 47.971221923828125, 1.0\n",
      "Train loss and acc of batch 56: 47.97120666503906, 1.0\n",
      "Train loss and acc of batch 57: 48.56690216064453, 0.984375\n",
      "Train loss and acc of batch 58: 47.971195220947266, 1.0\n",
      "Train loss and acc of batch 59: 47.971187591552734, 1.0\n",
      "Train loss and acc of batch 60: 47.97117614746094, 1.0\n",
      "Train loss and acc of batch 61: 47.971168518066406, 1.0\n",
      "Train loss and acc of batch 62: 48.18791961669922, 0.984375\n",
      "Train loss and acc of batch 63: 49.16255569458008, 0.96875\n",
      "Train loss and acc of batch 64: 48.187904357910156, 0.984375\n",
      "Train loss and acc of batch 65: 47.97113037109375, 1.0\n",
      "Train loss and acc of batch 66: 47.97112274169922, 1.0\n",
      "Train loss and acc of batch 67: 48.78358459472656, 0.96875\n",
      "Train loss and acc of batch 68: 48.566802978515625, 0.984375\n",
      "Train loss and acc of batch 69: 48.18785858154297, 0.984375\n",
      "Train loss and acc of batch 70: 47.97108459472656, 1.0\n",
      "Training accuracy and loss of epoch #138: 0.9890, 48.3024\n",
      "Train loss and acc of batch 0: 47.97107696533203, 1.0\n",
      "Train loss and acc of batch 1: 47.9710693359375, 1.0\n",
      "Train loss and acc of batch 2: 48.25691223144531, 0.984375\n",
      "Train loss and acc of batch 3: 48.18781280517578, 0.984375\n",
      "Train loss and acc of batch 4: 47.971046447753906, 1.0\n",
      "Train loss and acc of batch 5: 49.31995391845703, 0.96875\n",
      "Train loss and acc of batch 6: 48.473636627197266, 0.96875\n",
      "Train loss and acc of batch 7: 47.97101593017578, 1.0\n",
      "Train loss and acc of batch 8: 48.56670379638672, 0.984375\n",
      "Train loss and acc of batch 9: 48.25685119628906, 0.984375\n",
      "Train loss and acc of batch 10: 47.97099304199219, 1.0\n",
      "Train loss and acc of batch 11: 47.970977783203125, 1.0\n",
      "Train loss and acc of batch 12: 48.72419357299805, 0.984375\n",
      "Train loss and acc of batch 13: 48.187721252441406, 0.984375\n",
      "Train loss and acc of batch 14: 48.187713623046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.566650390625, 0.984375\n",
      "Train loss and acc of batch 16: 48.566627502441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.724151611328125, 0.984375\n",
      "Train loss and acc of batch 18: 48.852474212646484, 0.96875\n",
      "Train loss and acc of batch 19: 47.970909118652344, 1.0\n",
      "Train loss and acc of batch 20: 47.97090148925781, 1.0\n",
      "Train loss and acc of batch 21: 48.56658935546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.56658172607422, 0.984375\n",
      "Train loss and acc of batch 23: 48.18763732910156, 0.984375\n",
      "Train loss and acc of batch 24: 48.566566467285156, 0.984375\n",
      "Train loss and acc of batch 25: 47.97085952758789, 1.0\n",
      "Train loss and acc of batch 26: 47.97084426879883, 1.0\n",
      "Train loss and acc of batch 27: 47.9708366394043, 1.0\n",
      "Train loss and acc of batch 28: 47.9708251953125, 1.0\n",
      "Train loss and acc of batch 29: 48.56652069091797, 0.984375\n",
      "Train loss and acc of batch 30: 47.97080993652344, 1.0\n",
      "Train loss and acc of batch 31: 48.18756866455078, 0.984375\n",
      "Train loss and acc of batch 32: 47.970794677734375, 1.0\n",
      "Train loss and acc of batch 33: 47.97077941894531, 1.0\n",
      "Train loss and acc of batch 34: 48.56647491455078, 0.984375\n",
      "Train loss and acc of batch 35: 48.404293060302734, 0.96875\n",
      "Train loss and acc of batch 36: 47.97075653076172, 1.0\n",
      "Train loss and acc of batch 37: 48.723976135253906, 0.984375\n",
      "Train loss and acc of batch 38: 49.319664001464844, 0.96875\n",
      "Train loss and acc of batch 39: 48.18749237060547, 0.984375\n",
      "Train loss and acc of batch 40: 47.97072219848633, 1.0\n",
      "Train loss and acc of batch 41: 49.31963348388672, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 42: 47.970703125, 1.0\n",
      "Train loss and acc of batch 43: 48.56639099121094, 0.984375\n",
      "Train loss and acc of batch 44: 47.970680236816406, 1.0\n",
      "Train loss and acc of batch 45: 48.566375732421875, 0.984375\n",
      "Train loss and acc of batch 46: 48.25652313232422, 0.984375\n",
      "Train loss and acc of batch 47: 47.97065734863281, 1.0\n",
      "Train loss and acc of batch 48: 47.97064971923828, 1.0\n",
      "Train loss and acc of batch 49: 47.97063446044922, 1.0\n",
      "Train loss and acc of batch 50: 48.56632995605469, 0.984375\n",
      "Train loss and acc of batch 51: 49.319549560546875, 0.96875\n",
      "Train loss and acc of batch 52: 49.22645950317383, 0.953125\n",
      "Train loss and acc of batch 53: 47.97060012817383, 1.0\n",
      "Train loss and acc of batch 54: 48.18736267089844, 0.984375\n",
      "Train loss and acc of batch 55: 47.9705810546875, 1.0\n",
      "Train loss and acc of batch 56: 47.970577239990234, 1.0\n",
      "Train loss and acc of batch 57: 48.56626892089844, 0.984375\n",
      "Train loss and acc of batch 58: 47.97055435180664, 1.0\n",
      "Train loss and acc of batch 59: 47.970550537109375, 1.0\n",
      "Train loss and acc of batch 60: 47.970542907714844, 1.0\n",
      "Train loss and acc of batch 61: 47.97053146362305, 1.0\n",
      "Train loss and acc of batch 62: 48.187286376953125, 0.984375\n",
      "Train loss and acc of batch 63: 49.16191864013672, 0.96875\n",
      "Train loss and acc of batch 64: 48.18727111816406, 0.984375\n",
      "Train loss and acc of batch 65: 47.97050094604492, 1.0\n",
      "Train loss and acc of batch 66: 47.970489501953125, 1.0\n",
      "Train loss and acc of batch 67: 48.78294372558594, 0.96875\n",
      "Train loss and acc of batch 68: 48.56616973876953, 0.984375\n",
      "Train loss and acc of batch 69: 48.187225341796875, 0.984375\n",
      "Train loss and acc of batch 70: 47.97045135498047, 1.0\n",
      "Training accuracy and loss of epoch #139: 0.9890, 48.3018\n",
      "Train loss and acc of batch 0: 47.97044372558594, 1.0\n",
      "Train loss and acc of batch 1: 47.970428466796875, 1.0\n",
      "Train loss and acc of batch 2: 48.25627899169922, 0.984375\n",
      "Train loss and acc of batch 3: 48.18717956542969, 0.984375\n",
      "Train loss and acc of batch 4: 47.97040939331055, 1.0\n",
      "Train loss and acc of batch 5: 49.31932830810547, 0.96875\n",
      "Train loss and acc of batch 6: 48.47300338745117, 0.96875\n",
      "Train loss and acc of batch 7: 47.97037887573242, 1.0\n",
      "Train loss and acc of batch 8: 48.566078186035156, 0.984375\n",
      "Train loss and acc of batch 9: 48.25621032714844, 0.984375\n",
      "Train loss and acc of batch 10: 47.97035217285156, 1.0\n",
      "Train loss and acc of batch 11: 47.97034454345703, 1.0\n",
      "Train loss and acc of batch 12: 48.72356033325195, 0.984375\n",
      "Train loss and acc of batch 13: 48.18708801269531, 0.984375\n",
      "Train loss and acc of batch 14: 48.18708038330078, 0.984375\n",
      "Train loss and acc of batch 15: 48.566009521484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.566001892089844, 0.984375\n",
      "Train loss and acc of batch 17: 48.723514556884766, 0.984375\n",
      "Train loss and acc of batch 18: 48.85183334350586, 0.96875\n",
      "Train loss and acc of batch 19: 47.97027587890625, 1.0\n",
      "Train loss and acc of batch 20: 47.97026443481445, 1.0\n",
      "Train loss and acc of batch 21: 48.565956115722656, 0.984375\n",
      "Train loss and acc of batch 22: 48.565956115722656, 0.984375\n",
      "Train loss and acc of batch 23: 48.18700408935547, 0.984375\n",
      "Train loss and acc of batch 24: 48.56593322753906, 0.984375\n",
      "Train loss and acc of batch 25: 47.97022247314453, 1.0\n",
      "Train loss and acc of batch 26: 47.970211029052734, 1.0\n",
      "Train loss and acc of batch 27: 47.9702033996582, 1.0\n",
      "Train loss and acc of batch 28: 47.970191955566406, 1.0\n",
      "Train loss and acc of batch 29: 48.565879821777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.970176696777344, 1.0\n",
      "Train loss and acc of batch 31: 48.18693542480469, 0.984375\n",
      "Train loss and acc of batch 32: 47.97015380859375, 1.0\n",
      "Train loss and acc of batch 33: 47.97015380859375, 1.0\n",
      "Train loss and acc of batch 34: 48.56584167480469, 0.984375\n",
      "Train loss and acc of batch 35: 48.40365982055664, 0.96875\n",
      "Train loss and acc of batch 36: 47.970123291015625, 1.0\n",
      "Train loss and acc of batch 37: 48.723331451416016, 0.984375\n",
      "Train loss and acc of batch 38: 49.31903076171875, 0.96875\n",
      "Train loss and acc of batch 39: 48.186859130859375, 0.984375\n",
      "Train loss and acc of batch 40: 47.97008514404297, 1.0\n",
      "Train loss and acc of batch 41: 49.31900405883789, 0.96875\n",
      "Train loss and acc of batch 42: 47.97006607055664, 1.0\n",
      "Train loss and acc of batch 43: 48.565757751464844, 0.984375\n",
      "Train loss and acc of batch 44: 47.97005081176758, 1.0\n",
      "Train loss and acc of batch 45: 48.56574249267578, 0.984375\n",
      "Train loss and acc of batch 46: 48.255882263183594, 0.984375\n",
      "Train loss and acc of batch 47: 47.970027923583984, 1.0\n",
      "Train loss and acc of batch 48: 47.97001647949219, 1.0\n",
      "Train loss and acc of batch 49: 47.970008850097656, 1.0\n",
      "Train loss and acc of batch 50: 48.565704345703125, 0.984375\n",
      "Train loss and acc of batch 51: 49.31891632080078, 0.96875\n",
      "Train loss and acc of batch 52: 49.2258186340332, 0.953125\n",
      "Train loss and acc of batch 53: 47.969970703125, 1.0\n",
      "Train loss and acc of batch 54: 48.186729431152344, 0.984375\n",
      "Train loss and acc of batch 55: 47.96995544433594, 1.0\n",
      "Train loss and acc of batch 56: 47.96994400024414, 1.0\n",
      "Train loss and acc of batch 57: 48.565635681152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.96992874145508, 1.0\n",
      "Train loss and acc of batch 59: 47.96991729736328, 1.0\n",
      "Train loss and acc of batch 60: 47.96990966796875, 1.0\n",
      "Train loss and acc of batch 61: 47.96990203857422, 1.0\n",
      "Train loss and acc of batch 62: 48.18665313720703, 0.984375\n",
      "Train loss and acc of batch 63: 49.161285400390625, 0.96875\n",
      "Train loss and acc of batch 64: 48.18663787841797, 0.984375\n",
      "Train loss and acc of batch 65: 47.96985626220703, 1.0\n",
      "Train loss and acc of batch 66: 47.96985626220703, 1.0\n",
      "Train loss and acc of batch 67: 48.782310485839844, 0.96875\n",
      "Train loss and acc of batch 68: 48.56553649902344, 0.984375\n",
      "Train loss and acc of batch 69: 48.18659210205078, 0.984375\n",
      "Train loss and acc of batch 70: 47.96981430053711, 1.0\n",
      "Training accuracy and loss of epoch #140: 0.9890, 48.3011\n",
      "Saved model by train loss 48.301146547559284\n",
      "Train loss and acc of batch 0: 47.96980667114258, 1.0\n",
      "Train loss and acc of batch 1: 47.96980285644531, 1.0\n",
      "Train loss and acc of batch 2: 48.255638122558594, 0.984375\n",
      "Train loss and acc of batch 3: 48.186546325683594, 0.984375\n",
      "Train loss and acc of batch 4: 47.96977615356445, 1.0\n",
      "Train loss and acc of batch 5: 49.318687438964844, 0.96875\n",
      "Train loss and acc of batch 6: 48.472373962402344, 0.96875\n",
      "Train loss and acc of batch 7: 47.96975326538086, 1.0\n",
      "Train loss and acc of batch 8: 48.56543731689453, 0.984375\n",
      "Train loss and acc of batch 9: 48.255577087402344, 0.984375\n",
      "Train loss and acc of batch 10: 47.96971893310547, 1.0\n",
      "Train loss and acc of batch 11: 47.96971130371094, 1.0\n",
      "Train loss and acc of batch 12: 48.72292709350586, 0.984375\n",
      "Train loss and acc of batch 13: 48.18645477294922, 0.984375\n",
      "Train loss and acc of batch 14: 48.18644714355469, 0.984375\n",
      "Train loss and acc of batch 15: 48.56537628173828, 0.984375\n",
      "Train loss and acc of batch 16: 48.56536865234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.722877502441406, 0.984375\n",
      "Train loss and acc of batch 18: 48.85120391845703, 0.96875\n",
      "Train loss and acc of batch 19: 47.96963882446289, 1.0\n",
      "Train loss and acc of batch 20: 47.969635009765625, 1.0\n",
      "Train loss and acc of batch 21: 48.565330505371094, 0.984375\n",
      "Train loss and acc of batch 22: 48.56531524658203, 0.984375\n",
      "Train loss and acc of batch 23: 48.186370849609375, 0.984375\n",
      "Train loss and acc of batch 24: 48.56529998779297, 0.984375\n",
      "Train loss and acc of batch 25: 47.96958541870117, 1.0\n",
      "Train loss and acc of batch 26: 47.969581604003906, 1.0\n",
      "Train loss and acc of batch 27: 47.969566345214844, 1.0\n",
      "Train loss and acc of batch 28: 47.96956253051758, 1.0\n",
      "Train loss and acc of batch 29: 48.56525421142578, 0.984375\n",
      "Train loss and acc of batch 30: 47.969539642333984, 1.0\n",
      "Train loss and acc of batch 31: 48.18629455566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.96952438354492, 1.0\n",
      "Train loss and acc of batch 33: 47.969512939453125, 1.0\n",
      "Train loss and acc of batch 34: 48.565208435058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.40303421020508, 0.96875\n",
      "Train loss and acc of batch 36: 47.969486236572266, 1.0\n",
      "Train loss and acc of batch 37: 48.72270584106445, 0.984375\n",
      "Train loss and acc of batch 38: 49.318389892578125, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 39: 48.18622589111328, 0.984375\n",
      "Train loss and acc of batch 40: 47.969459533691406, 1.0\n",
      "Train loss and acc of batch 41: 49.3183708190918, 0.96875\n",
      "Train loss and acc of batch 42: 47.96943664550781, 1.0\n",
      "Train loss and acc of batch 43: 48.56513214111328, 0.984375\n",
      "Train loss and acc of batch 44: 47.969417572021484, 1.0\n",
      "Train loss and acc of batch 45: 48.56510925292969, 0.984375\n",
      "Train loss and acc of batch 46: 48.25525665283203, 0.984375\n",
      "Train loss and acc of batch 47: 47.96938705444336, 1.0\n",
      "Train loss and acc of batch 48: 47.969383239746094, 1.0\n",
      "Train loss and acc of batch 49: 47.96937561035156, 1.0\n",
      "Train loss and acc of batch 50: 48.5650634765625, 0.984375\n",
      "Train loss and acc of batch 51: 49.31828308105469, 0.96875\n",
      "Train loss and acc of batch 52: 49.225181579589844, 0.953125\n",
      "Train loss and acc of batch 53: 47.969337463378906, 1.0\n",
      "Train loss and acc of batch 54: 48.18608856201172, 0.984375\n",
      "Train loss and acc of batch 55: 47.96931838989258, 1.0\n",
      "Train loss and acc of batch 56: 47.96931076049805, 1.0\n",
      "Train loss and acc of batch 57: 48.56500244140625, 0.984375\n",
      "Train loss and acc of batch 58: 47.96929168701172, 1.0\n",
      "Train loss and acc of batch 59: 47.96928405761719, 1.0\n",
      "Train loss and acc of batch 60: 47.96927261352539, 1.0\n",
      "Train loss and acc of batch 61: 47.96926498413086, 1.0\n",
      "Train loss and acc of batch 62: 48.18601989746094, 0.984375\n",
      "Train loss and acc of batch 63: 49.16065216064453, 0.96875\n",
      "Train loss and acc of batch 64: 48.185997009277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.969234466552734, 1.0\n",
      "Train loss and acc of batch 66: 47.96921920776367, 1.0\n",
      "Train loss and acc of batch 67: 48.78167724609375, 0.96875\n",
      "Train loss and acc of batch 68: 48.564903259277344, 0.984375\n",
      "Train loss and acc of batch 69: 48.18595886230469, 0.984375\n",
      "Train loss and acc of batch 70: 47.96918487548828, 1.0\n",
      "Training accuracy and loss of epoch #141: 0.9890, 48.3005\n",
      "Saved model by train loss 48.300512985444406\n",
      "Train loss and acc of batch 0: 47.96917724609375, 1.0\n",
      "Train loss and acc of batch 1: 47.96916961669922, 1.0\n",
      "Train loss and acc of batch 2: 48.25502014160156, 0.984375\n",
      "Train loss and acc of batch 3: 48.1859130859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.969139099121094, 1.0\n",
      "Train loss and acc of batch 5: 49.31805419921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.471736907958984, 0.96875\n",
      "Train loss and acc of batch 7: 47.9691162109375, 1.0\n",
      "Train loss and acc of batch 8: 48.56481170654297, 0.984375\n",
      "Train loss and acc of batch 9: 48.25495147705078, 0.984375\n",
      "Train loss and acc of batch 10: 47.96908950805664, 1.0\n",
      "Train loss and acc of batch 11: 47.96908187866211, 1.0\n",
      "Train loss and acc of batch 12: 48.7222900390625, 0.984375\n",
      "Train loss and acc of batch 13: 48.185829162597656, 0.984375\n",
      "Train loss and acc of batch 14: 48.185813903808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.56474304199219, 0.984375\n",
      "Train loss and acc of batch 16: 48.564735412597656, 0.984375\n",
      "Train loss and acc of batch 17: 48.722251892089844, 0.984375\n",
      "Train loss and acc of batch 18: 48.85056686401367, 0.96875\n",
      "Train loss and acc of batch 19: 47.9690055847168, 1.0\n",
      "Train loss and acc of batch 20: 47.968997955322266, 1.0\n",
      "Train loss and acc of batch 21: 48.564697265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.56468200683594, 0.984375\n",
      "Train loss and acc of batch 23: 48.18573760986328, 0.984375\n",
      "Train loss and acc of batch 24: 48.564666748046875, 0.984375\n",
      "Train loss and acc of batch 25: 47.96895217895508, 1.0\n",
      "Train loss and acc of batch 26: 47.96894073486328, 1.0\n",
      "Train loss and acc of batch 27: 47.968936920166016, 1.0\n",
      "Train loss and acc of batch 28: 47.96892547607422, 1.0\n",
      "Train loss and acc of batch 29: 48.56462097167969, 0.984375\n",
      "Train loss and acc of batch 30: 47.96891403198242, 1.0\n",
      "Train loss and acc of batch 31: 48.18566131591797, 0.984375\n",
      "Train loss and acc of batch 32: 47.96889114379883, 1.0\n",
      "Train loss and acc of batch 33: 47.9688835144043, 1.0\n",
      "Train loss and acc of batch 34: 48.5645751953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.40239715576172, 0.96875\n",
      "Train loss and acc of batch 36: 47.96885681152344, 1.0\n",
      "Train loss and acc of batch 37: 48.722068786621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.31776428222656, 0.96875\n",
      "Train loss and acc of batch 39: 48.18559265136719, 0.984375\n",
      "Train loss and acc of batch 40: 47.96881866455078, 1.0\n",
      "Train loss and acc of batch 41: 49.3177375793457, 0.96875\n",
      "Train loss and acc of batch 42: 47.96880340576172, 1.0\n",
      "Train loss and acc of batch 43: 48.564491271972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.96878433227539, 1.0\n",
      "Train loss and acc of batch 45: 48.56446838378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.254615783691406, 0.984375\n",
      "Train loss and acc of batch 47: 47.968753814697266, 1.0\n",
      "Train loss and acc of batch 48: 47.968746185302734, 1.0\n",
      "Train loss and acc of batch 49: 47.9687385559082, 1.0\n",
      "Train loss and acc of batch 50: 48.56443786621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.31764221191406, 0.96875\n",
      "Train loss and acc of batch 52: 49.22455596923828, 0.953125\n",
      "Train loss and acc of batch 53: 47.96870040893555, 1.0\n",
      "Train loss and acc of batch 54: 48.185455322265625, 0.984375\n",
      "Train loss and acc of batch 55: 47.968685150146484, 1.0\n",
      "Train loss and acc of batch 56: 47.96867752075195, 1.0\n",
      "Train loss and acc of batch 57: 48.564369201660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.968666076660156, 1.0\n",
      "Train loss and acc of batch 59: 47.96864700317383, 1.0\n",
      "Train loss and acc of batch 60: 47.9686393737793, 1.0\n",
      "Train loss and acc of batch 61: 47.9686279296875, 1.0\n",
      "Train loss and acc of batch 62: 48.185386657714844, 0.984375\n",
      "Train loss and acc of batch 63: 49.16001892089844, 0.96875\n",
      "Train loss and acc of batch 64: 48.18536376953125, 0.984375\n",
      "Train loss and acc of batch 65: 47.968597412109375, 1.0\n",
      "Train loss and acc of batch 66: 47.96859359741211, 1.0\n",
      "Train loss and acc of batch 67: 48.781044006347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.56427001953125, 0.984375\n",
      "Train loss and acc of batch 69: 48.185325622558594, 0.984375\n",
      "Train loss and acc of batch 70: 47.96854782104492, 1.0\n",
      "Training accuracy and loss of epoch #142: 0.9890, 48.2999\n",
      "Saved model by train loss 48.29987985315457\n",
      "Train loss and acc of batch 0: 47.968544006347656, 1.0\n",
      "Train loss and acc of batch 1: 47.96853256225586, 1.0\n",
      "Train loss and acc of batch 2: 48.25437927246094, 0.984375\n",
      "Train loss and acc of batch 3: 48.185279846191406, 0.984375\n",
      "Train loss and acc of batch 4: 47.968505859375, 1.0\n",
      "Train loss and acc of batch 5: 49.317420959472656, 0.96875\n",
      "Train loss and acc of batch 6: 48.471107482910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.968475341796875, 1.0\n",
      "Train loss and acc of batch 8: 48.564170837402344, 0.984375\n",
      "Train loss and acc of batch 9: 48.25431823730469, 0.984375\n",
      "Train loss and acc of batch 10: 47.96845626831055, 1.0\n",
      "Train loss and acc of batch 11: 47.96844482421875, 1.0\n",
      "Train loss and acc of batch 12: 48.72166442871094, 0.984375\n",
      "Train loss and acc of batch 13: 48.18518829345703, 0.984375\n",
      "Train loss and acc of batch 14: 48.1851806640625, 0.984375\n",
      "Train loss and acc of batch 15: 48.564117431640625, 0.984375\n",
      "Train loss and acc of batch 16: 48.56410217285156, 0.984375\n",
      "Train loss and acc of batch 17: 48.721614837646484, 0.984375\n",
      "Train loss and acc of batch 18: 48.849937438964844, 0.96875\n",
      "Train loss and acc of batch 19: 47.96836853027344, 1.0\n",
      "Train loss and acc of batch 20: 47.968360900878906, 1.0\n",
      "Train loss and acc of batch 21: 48.564056396484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.564048767089844, 0.984375\n",
      "Train loss and acc of batch 23: 48.18510437011719, 0.984375\n",
      "Train loss and acc of batch 24: 48.56403350830078, 0.984375\n",
      "Train loss and acc of batch 25: 47.968318939208984, 1.0\n",
      "Train loss and acc of batch 26: 47.96831130981445, 1.0\n",
      "Train loss and acc of batch 27: 47.968299865722656, 1.0\n",
      "Train loss and acc of batch 28: 47.968292236328125, 1.0\n",
      "Train loss and acc of batch 29: 48.563987731933594, 0.984375\n",
      "Train loss and acc of batch 30: 47.96826934814453, 1.0\n",
      "Train loss and acc of batch 31: 48.185035705566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.968257904052734, 1.0\n",
      "Train loss and acc of batch 33: 47.9682502746582, 1.0\n",
      "Train loss and acc of batch 34: 48.563941955566406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 35: 48.401756286621094, 0.96875\n",
      "Train loss and acc of batch 36: 47.96821975708008, 1.0\n",
      "Train loss and acc of batch 37: 48.721439361572266, 0.984375\n",
      "Train loss and acc of batch 38: 49.31713104248047, 0.96875\n",
      "Train loss and acc of batch 39: 48.184959411621094, 0.984375\n",
      "Train loss and acc of batch 40: 47.96818161010742, 1.0\n",
      "Train loss and acc of batch 41: 49.31710433959961, 0.96875\n",
      "Train loss and acc of batch 42: 47.96816635131836, 1.0\n",
      "Train loss and acc of batch 43: 48.563865661621094, 0.984375\n",
      "Train loss and acc of batch 44: 47.96814727783203, 1.0\n",
      "Train loss and acc of batch 45: 48.5638427734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.25398254394531, 0.984375\n",
      "Train loss and acc of batch 47: 47.96812057495117, 1.0\n",
      "Train loss and acc of batch 48: 47.96811294555664, 1.0\n",
      "Train loss and acc of batch 49: 47.968101501464844, 1.0\n",
      "Train loss and acc of batch 50: 48.56379699707031, 0.984375\n",
      "Train loss and acc of batch 51: 49.3170166015625, 0.96875\n",
      "Train loss and acc of batch 52: 49.22391891479492, 0.953125\n",
      "Train loss and acc of batch 53: 47.96807098388672, 1.0\n",
      "Train loss and acc of batch 54: 48.18482971191406, 0.984375\n",
      "Train loss and acc of batch 55: 47.968048095703125, 1.0\n",
      "Train loss and acc of batch 56: 47.968040466308594, 1.0\n",
      "Train loss and acc of batch 57: 48.56373596191406, 0.984375\n",
      "Train loss and acc of batch 58: 47.96802520751953, 1.0\n",
      "Train loss and acc of batch 59: 47.968017578125, 1.0\n",
      "Train loss and acc of batch 60: 47.96800994873047, 1.0\n",
      "Train loss and acc of batch 61: 47.96800231933594, 1.0\n",
      "Train loss and acc of batch 62: 48.18475341796875, 0.984375\n",
      "Train loss and acc of batch 63: 49.15937805175781, 0.96875\n",
      "Train loss and acc of batch 64: 48.18473815917969, 0.984375\n",
      "Train loss and acc of batch 65: 47.96796417236328, 1.0\n",
      "Train loss and acc of batch 66: 47.967952728271484, 1.0\n",
      "Train loss and acc of batch 67: 48.78041076660156, 0.96875\n",
      "Train loss and acc of batch 68: 48.56364440917969, 0.984375\n",
      "Train loss and acc of batch 69: 48.1846923828125, 0.984375\n",
      "Train loss and acc of batch 70: 47.96792221069336, 1.0\n",
      "Training accuracy and loss of epoch #143: 0.9890, 48.2992\n",
      "Saved model by train loss 48.299246183583435\n",
      "Train loss and acc of batch 0: 47.96790313720703, 1.0\n",
      "Train loss and acc of batch 1: 47.967899322509766, 1.0\n",
      "Train loss and acc of batch 2: 48.253746032714844, 0.984375\n",
      "Train loss and acc of batch 3: 48.18464660644531, 0.984375\n",
      "Train loss and acc of batch 4: 47.96786880493164, 1.0\n",
      "Train loss and acc of batch 5: 49.31678771972656, 0.96875\n",
      "Train loss and acc of batch 6: 48.4704704284668, 0.96875\n",
      "Train loss and acc of batch 7: 47.96784210205078, 1.0\n",
      "Train loss and acc of batch 8: 48.56353759765625, 0.984375\n",
      "Train loss and acc of batch 9: 48.25367736816406, 0.984375\n",
      "Train loss and acc of batch 10: 47.96781921386719, 1.0\n",
      "Train loss and acc of batch 11: 47.96781539916992, 1.0\n",
      "Train loss and acc of batch 12: 48.72102355957031, 0.984375\n",
      "Train loss and acc of batch 13: 48.18455505371094, 0.984375\n",
      "Train loss and acc of batch 14: 48.184547424316406, 0.984375\n",
      "Train loss and acc of batch 15: 48.5634765625, 0.984375\n",
      "Train loss and acc of batch 16: 48.56346893310547, 0.984375\n",
      "Train loss and acc of batch 17: 48.72098159790039, 0.984375\n",
      "Train loss and acc of batch 18: 48.84930419921875, 0.96875\n",
      "Train loss and acc of batch 19: 47.96773910522461, 1.0\n",
      "Train loss and acc of batch 20: 47.96773147583008, 1.0\n",
      "Train loss and acc of batch 21: 48.56342315673828, 0.984375\n",
      "Train loss and acc of batch 22: 48.56341552734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.96769714355469, 1.0\n",
      "Train loss and acc of batch 24: 48.563392639160156, 0.984375\n",
      "Train loss and acc of batch 25: 47.967689514160156, 1.0\n",
      "Train loss and acc of batch 26: 47.967681884765625, 1.0\n",
      "Train loss and acc of batch 27: 47.96767044067383, 1.0\n",
      "Train loss and acc of batch 28: 47.96765899658203, 1.0\n",
      "Train loss and acc of batch 29: 48.56334686279297, 0.984375\n",
      "Train loss and acc of batch 30: 47.96764373779297, 1.0\n",
      "Train loss and acc of batch 31: 48.18439483642578, 0.984375\n",
      "Train loss and acc of batch 32: 47.967620849609375, 1.0\n",
      "Train loss and acc of batch 33: 47.967613220214844, 1.0\n",
      "Train loss and acc of batch 34: 48.56330871582031, 0.984375\n",
      "Train loss and acc of batch 35: 48.401123046875, 0.96875\n",
      "Train loss and acc of batch 36: 47.96759033203125, 1.0\n",
      "Train loss and acc of batch 37: 48.72079849243164, 0.984375\n",
      "Train loss and acc of batch 38: 49.316497802734375, 0.96875\n",
      "Train loss and acc of batch 39: 48.184326171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.967552185058594, 1.0\n",
      "Train loss and acc of batch 41: 49.31646728515625, 0.96875\n",
      "Train loss and acc of batch 42: 47.96753692626953, 1.0\n",
      "Train loss and acc of batch 43: 48.56322479248047, 0.984375\n",
      "Train loss and acc of batch 44: 47.9675178527832, 1.0\n",
      "Train loss and acc of batch 45: 48.563209533691406, 0.984375\n",
      "Train loss and acc of batch 46: 48.25335693359375, 0.984375\n",
      "Train loss and acc of batch 47: 47.967491149902344, 1.0\n",
      "Train loss and acc of batch 48: 47.96747970581055, 1.0\n",
      "Train loss and acc of batch 49: 47.967472076416016, 1.0\n",
      "Train loss and acc of batch 50: 48.56316375732422, 0.984375\n",
      "Train loss and acc of batch 51: 49.316375732421875, 0.96875\n",
      "Train loss and acc of batch 52: 49.22328186035156, 0.953125\n",
      "Train loss and acc of batch 53: 47.967437744140625, 1.0\n",
      "Train loss and acc of batch 54: 48.18418884277344, 0.984375\n",
      "Train loss and acc of batch 55: 47.9674186706543, 1.0\n",
      "Train loss and acc of batch 56: 47.967411041259766, 1.0\n",
      "Train loss and acc of batch 57: 48.56310272216797, 0.984375\n",
      "Train loss and acc of batch 58: 47.96739196777344, 1.0\n",
      "Train loss and acc of batch 59: 47.967384338378906, 1.0\n",
      "Train loss and acc of batch 60: 47.967369079589844, 1.0\n",
      "Train loss and acc of batch 61: 47.96736526489258, 1.0\n",
      "Train loss and acc of batch 62: 48.184120178222656, 0.984375\n",
      "Train loss and acc of batch 63: 49.158748626708984, 0.96875\n",
      "Train loss and acc of batch 64: 48.184104919433594, 0.984375\n",
      "Train loss and acc of batch 65: 47.96732711791992, 1.0\n",
      "Train loss and acc of batch 66: 47.96731948852539, 1.0\n",
      "Train loss and acc of batch 67: 48.77977752685547, 0.96875\n",
      "Train loss and acc of batch 68: 48.56300354003906, 0.984375\n",
      "Train loss and acc of batch 69: 48.184059143066406, 0.984375\n",
      "Train loss and acc of batch 70: 47.96728515625, 1.0\n",
      "Training accuracy and loss of epoch #144: 0.9892, 48.2956\n",
      "Saved model by train loss 48.29555887571523\n",
      "Train loss and acc of batch 0: 47.96727752685547, 1.0\n",
      "Train loss and acc of batch 1: 47.96726608276367, 1.0\n",
      "Train loss and acc of batch 2: 48.25311279296875, 0.984375\n",
      "Train loss and acc of batch 3: 48.18401336669922, 0.984375\n",
      "Train loss and acc of batch 4: 47.96723937988281, 1.0\n",
      "Train loss and acc of batch 5: 49.31615447998047, 0.96875\n",
      "Train loss and acc of batch 6: 48.46984100341797, 0.96875\n",
      "Train loss and acc of batch 7: 47.96721267700195, 1.0\n",
      "Train loss and acc of batch 8: 48.562904357910156, 0.984375\n",
      "Train loss and acc of batch 9: 48.25304412841797, 0.984375\n",
      "Train loss and acc of batch 10: 47.967185974121094, 1.0\n",
      "Train loss and acc of batch 11: 47.96717834472656, 1.0\n",
      "Train loss and acc of batch 12: 48.72039794921875, 0.984375\n",
      "Train loss and acc of batch 13: 48.183921813964844, 0.984375\n",
      "Train loss and acc of batch 14: 48.18391418457031, 0.984375\n",
      "Train loss and acc of batch 15: 48.562843322753906, 0.984375\n",
      "Train loss and acc of batch 16: 48.562828063964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.72034454345703, 0.984375\n",
      "Train loss and acc of batch 18: 48.84866714477539, 0.96875\n",
      "Train loss and acc of batch 19: 47.96710968017578, 1.0\n",
      "Train loss and acc of batch 20: 47.96709442138672, 1.0\n",
      "Train loss and acc of batch 21: 48.56278991699219, 0.984375\n",
      "Train loss and acc of batch 22: 48.562782287597656, 0.984375\n",
      "Train loss and acc of batch 23: 47.967071533203125, 1.0\n",
      "Train loss and acc of batch 24: 48.56275939941406, 0.984375\n",
      "Train loss and acc of batch 25: 47.9670524597168, 1.0\n",
      "Train loss and acc of batch 26: 47.967041015625, 1.0\n",
      "Train loss and acc of batch 27: 47.96703338623047, 1.0\n",
      "Train loss and acc of batch 28: 47.96702575683594, 1.0\n",
      "Train loss and acc of batch 29: 48.562721252441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.96700668334961, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 31: 48.18376159667969, 0.984375\n",
      "Train loss and acc of batch 32: 47.96698760986328, 1.0\n",
      "Train loss and acc of batch 33: 47.96697998046875, 1.0\n",
      "Train loss and acc of batch 34: 48.56267547607422, 0.984375\n",
      "Train loss and acc of batch 35: 48.40049362182617, 0.96875\n",
      "Train loss and acc of batch 36: 47.96695327758789, 1.0\n",
      "Train loss and acc of batch 37: 48.72016906738281, 0.984375\n",
      "Train loss and acc of batch 38: 49.31586456298828, 0.96875\n",
      "Train loss and acc of batch 39: 48.183692932128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.9669189453125, 1.0\n",
      "Train loss and acc of batch 41: 49.315834045410156, 0.96875\n",
      "Train loss and acc of batch 42: 47.96690368652344, 1.0\n",
      "Train loss and acc of batch 43: 48.562591552734375, 0.984375\n",
      "Train loss and acc of batch 44: 47.96688461303711, 1.0\n",
      "Train loss and acc of batch 45: 48.56256866455078, 0.984375\n",
      "Train loss and acc of batch 46: 48.252716064453125, 0.984375\n",
      "Train loss and acc of batch 47: 47.96685791015625, 1.0\n",
      "Train loss and acc of batch 48: 47.96685028076172, 1.0\n",
      "Train loss and acc of batch 49: 47.96683883666992, 1.0\n",
      "Train loss and acc of batch 50: 48.562530517578125, 0.984375\n",
      "Train loss and acc of batch 51: 49.31574249267578, 0.96875\n",
      "Train loss and acc of batch 52: 49.222652435302734, 0.953125\n",
      "Train loss and acc of batch 53: 47.966800689697266, 1.0\n",
      "Train loss and acc of batch 54: 48.183555603027344, 0.984375\n",
      "Train loss and acc of batch 55: 47.96678161621094, 1.0\n",
      "Train loss and acc of batch 56: 47.96677780151367, 1.0\n",
      "Train loss and acc of batch 57: 48.562469482421875, 0.984375\n",
      "Train loss and acc of batch 58: 47.96675491333008, 1.0\n",
      "Train loss and acc of batch 59: 47.96674728393555, 1.0\n",
      "Train loss and acc of batch 60: 47.966739654541016, 1.0\n",
      "Train loss and acc of batch 61: 47.96672821044922, 1.0\n",
      "Train loss and acc of batch 62: 48.18348693847656, 0.984375\n",
      "Train loss and acc of batch 63: 49.15811538696289, 0.96875\n",
      "Train loss and acc of batch 64: 48.18346405029297, 0.984375\n",
      "Train loss and acc of batch 65: 47.96669387817383, 1.0\n",
      "Train loss and acc of batch 66: 47.96668243408203, 1.0\n",
      "Train loss and acc of batch 67: 48.779144287109375, 0.96875\n",
      "Train loss and acc of batch 68: 48.56237030029297, 0.984375\n",
      "Train loss and acc of batch 69: 48.18342590332031, 0.984375\n",
      "Train loss and acc of batch 70: 47.966651916503906, 1.0\n",
      "Training accuracy and loss of epoch #145: 0.9892, 48.2949\n",
      "Saved model by train loss 48.29492525987222\n",
      "Train loss and acc of batch 0: 47.966644287109375, 1.0\n",
      "Train loss and acc of batch 1: 47.96663284301758, 1.0\n",
      "Train loss and acc of batch 2: 48.252471923828125, 0.984375\n",
      "Train loss and acc of batch 3: 48.183380126953125, 0.984375\n",
      "Train loss and acc of batch 4: 47.96660232543945, 1.0\n",
      "Train loss and acc of batch 5: 49.315521240234375, 0.96875\n",
      "Train loss and acc of batch 6: 48.469207763671875, 0.96875\n",
      "Train loss and acc of batch 7: 47.96657943725586, 1.0\n",
      "Train loss and acc of batch 8: 48.562278747558594, 0.984375\n",
      "Train loss and acc of batch 9: 48.252410888671875, 0.984375\n",
      "Train loss and acc of batch 10: 47.966552734375, 1.0\n",
      "Train loss and acc of batch 11: 47.9665412902832, 1.0\n",
      "Train loss and acc of batch 12: 48.71975326538086, 0.984375\n",
      "Train loss and acc of batch 13: 48.18328857421875, 0.984375\n",
      "Train loss and acc of batch 14: 48.18328094482422, 0.984375\n",
      "Train loss and acc of batch 15: 48.56220245361328, 0.984375\n",
      "Train loss and acc of batch 16: 48.56220245361328, 0.984375\n",
      "Train loss and acc of batch 17: 48.71971130371094, 0.984375\n",
      "Train loss and acc of batch 18: 48.8480339050293, 0.96875\n",
      "Train loss and acc of batch 19: 47.96647262573242, 1.0\n",
      "Train loss and acc of batch 20: 47.96646499633789, 1.0\n",
      "Train loss and acc of batch 21: 48.562156677246094, 0.984375\n",
      "Train loss and acc of batch 22: 48.56214904785156, 0.984375\n",
      "Train loss and acc of batch 23: 48.183204650878906, 0.984375\n",
      "Train loss and acc of batch 24: 48.56212615966797, 0.984375\n",
      "Train loss and acc of batch 25: 47.9664192199707, 1.0\n",
      "Train loss and acc of batch 26: 47.966407775878906, 1.0\n",
      "Train loss and acc of batch 27: 47.966400146484375, 1.0\n",
      "Train loss and acc of batch 28: 47.966392517089844, 1.0\n",
      "Train loss and acc of batch 29: 48.56208038330078, 0.984375\n",
      "Train loss and acc of batch 30: 47.966373443603516, 1.0\n",
      "Train loss and acc of batch 31: 48.183128356933594, 0.984375\n",
      "Train loss and acc of batch 32: 47.96635055541992, 1.0\n",
      "Train loss and acc of batch 33: 47.96635055541992, 1.0\n",
      "Train loss and acc of batch 34: 48.562042236328125, 0.984375\n",
      "Train loss and acc of batch 35: 48.39986038208008, 0.96875\n",
      "Train loss and acc of batch 36: 47.9663200378418, 1.0\n",
      "Train loss and acc of batch 37: 48.719539642333984, 0.984375\n",
      "Train loss and acc of batch 38: 49.315223693847656, 0.96875\n",
      "Train loss and acc of batch 39: 48.18305969238281, 0.984375\n",
      "Train loss and acc of batch 40: 47.96628189086914, 1.0\n",
      "Train loss and acc of batch 41: 49.31520462036133, 0.96875\n",
      "Train loss and acc of batch 42: 47.96626663208008, 1.0\n",
      "Train loss and acc of batch 43: 48.56195831298828, 0.984375\n",
      "Train loss and acc of batch 44: 47.96624755859375, 1.0\n",
      "Train loss and acc of batch 45: 48.56194305419922, 0.984375\n",
      "Train loss and acc of batch 46: 48.25208282470703, 0.984375\n",
      "Train loss and acc of batch 47: 47.966224670410156, 1.0\n",
      "Train loss and acc of batch 48: 47.96621322631836, 1.0\n",
      "Train loss and acc of batch 49: 47.96620178222656, 1.0\n",
      "Train loss and acc of batch 50: 48.56189727783203, 0.984375\n",
      "Train loss and acc of batch 51: 49.31511688232422, 0.96875\n",
      "Train loss and acc of batch 52: 49.22201919555664, 0.953125\n",
      "Train loss and acc of batch 53: 47.966163635253906, 1.0\n",
      "Train loss and acc of batch 54: 48.18292236328125, 0.984375\n",
      "Train loss and acc of batch 55: 47.966148376464844, 1.0\n",
      "Train loss and acc of batch 56: 47.96614074707031, 1.0\n",
      "Train loss and acc of batch 57: 48.56182861328125, 0.984375\n",
      "Train loss and acc of batch 58: 47.96612548828125, 1.0\n",
      "Train loss and acc of batch 59: 47.96611404418945, 1.0\n",
      "Train loss and acc of batch 60: 47.966102600097656, 1.0\n",
      "Train loss and acc of batch 61: 47.96609878540039, 1.0\n",
      "Train loss and acc of batch 62: 48.18285369873047, 0.984375\n",
      "Train loss and acc of batch 63: 49.1574821472168, 0.96875\n",
      "Train loss and acc of batch 64: 48.182830810546875, 0.984375\n",
      "Train loss and acc of batch 65: 47.966060638427734, 1.0\n",
      "Train loss and acc of batch 66: 47.96605682373047, 1.0\n",
      "Train loss and acc of batch 67: 48.77851104736328, 0.96875\n",
      "Train loss and acc of batch 68: 48.561729431152344, 0.984375\n",
      "Train loss and acc of batch 69: 48.18278503417969, 0.984375\n",
      "Train loss and acc of batch 70: 47.96601867675781, 1.0\n",
      "Training accuracy and loss of epoch #146: 0.9890, 48.2973\n",
      "Train loss and acc of batch 0: 47.96600341796875, 1.0\n",
      "Train loss and acc of batch 1: 47.965999603271484, 1.0\n",
      "Train loss and acc of batch 2: 48.25184631347656, 0.984375\n",
      "Train loss and acc of batch 3: 48.18274688720703, 0.984375\n",
      "Train loss and acc of batch 4: 47.965972900390625, 1.0\n",
      "Train loss and acc of batch 5: 49.31488800048828, 0.96875\n",
      "Train loss and acc of batch 6: 48.46856689453125, 0.96875\n",
      "Train loss and acc of batch 7: 47.9659423828125, 1.0\n",
      "Train loss and acc of batch 8: 48.56163787841797, 0.984375\n",
      "Train loss and acc of batch 9: 48.25178527832031, 0.984375\n",
      "Train loss and acc of batch 10: 47.965919494628906, 1.0\n",
      "Train loss and acc of batch 11: 47.96590805053711, 1.0\n",
      "Train loss and acc of batch 12: 48.71912384033203, 0.984375\n",
      "Train loss and acc of batch 13: 48.182655334472656, 0.984375\n",
      "Train loss and acc of batch 14: 48.182647705078125, 0.984375\n",
      "Train loss and acc of batch 15: 48.56157684326172, 0.984375\n",
      "Train loss and acc of batch 16: 48.56156921386719, 0.984375\n",
      "Train loss and acc of batch 17: 48.719078063964844, 0.984375\n",
      "Train loss and acc of batch 18: 48.84740447998047, 0.96875\n",
      "Train loss and acc of batch 19: 47.96583938598633, 1.0\n",
      "Train loss and acc of batch 20: 47.9658317565918, 1.0\n",
      "Train loss and acc of batch 21: 48.5615234375, 0.984375\n",
      "Train loss and acc of batch 22: 48.56151580810547, 0.984375\n",
      "Train loss and acc of batch 23: 48.18257141113281, 0.984375\n",
      "Train loss and acc of batch 24: 48.561492919921875, 0.984375\n",
      "Train loss and acc of batch 25: 47.965789794921875, 1.0\n",
      "Train loss and acc of batch 26: 47.96577835083008, 1.0\n",
      "Train loss and acc of batch 27: 47.96576690673828, 1.0\n",
      "Train loss and acc of batch 28: 47.965763092041016, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 29: 48.56144714355469, 0.984375\n",
      "Train loss and acc of batch 30: 47.96574020385742, 1.0\n",
      "Train loss and acc of batch 31: 48.1824951171875, 0.984375\n",
      "Train loss and acc of batch 32: 47.965728759765625, 1.0\n",
      "Train loss and acc of batch 33: 47.96571350097656, 1.0\n",
      "Train loss and acc of batch 34: 48.5614013671875, 0.984375\n",
      "Train loss and acc of batch 35: 48.39922332763672, 0.96875\n",
      "Train loss and acc of batch 36: 47.96569061279297, 1.0\n",
      "Train loss and acc of batch 37: 48.718902587890625, 0.984375\n",
      "Train loss and acc of batch 38: 49.31459045410156, 0.96875\n",
      "Train loss and acc of batch 39: 48.18242645263672, 0.984375\n",
      "Train loss and acc of batch 40: 47.96565246582031, 1.0\n",
      "Train loss and acc of batch 41: 49.31456756591797, 0.96875\n",
      "Train loss and acc of batch 42: 47.96562957763672, 1.0\n",
      "Train loss and acc of batch 43: 48.56132507324219, 0.984375\n",
      "Train loss and acc of batch 44: 47.965614318847656, 1.0\n",
      "Train loss and acc of batch 45: 48.561309814453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.25144958496094, 0.984375\n",
      "Train loss and acc of batch 47: 47.9655876159668, 1.0\n",
      "Train loss and acc of batch 48: 47.965576171875, 1.0\n",
      "Train loss and acc of batch 49: 47.965572357177734, 1.0\n",
      "Train loss and acc of batch 50: 48.56126403808594, 0.984375\n",
      "Train loss and acc of batch 51: 49.314476013183594, 0.96875\n",
      "Train loss and acc of batch 52: 49.22138214111328, 0.953125\n",
      "Train loss and acc of batch 53: 47.965538024902344, 1.0\n",
      "Train loss and acc of batch 54: 48.182289123535156, 0.984375\n",
      "Train loss and acc of batch 55: 47.965518951416016, 1.0\n",
      "Train loss and acc of batch 56: 47.96550369262695, 1.0\n",
      "Train loss and acc of batch 57: 48.56120300292969, 0.984375\n",
      "Train loss and acc of batch 58: 47.96548843383789, 1.0\n",
      "Train loss and acc of batch 59: 47.96548080444336, 1.0\n",
      "Train loss and acc of batch 60: 47.965476989746094, 1.0\n",
      "Train loss and acc of batch 61: 47.965457916259766, 1.0\n",
      "Train loss and acc of batch 62: 48.182212829589844, 0.984375\n",
      "Train loss and acc of batch 63: 49.15684509277344, 0.96875\n",
      "Train loss and acc of batch 64: 48.18220520019531, 0.984375\n",
      "Train loss and acc of batch 65: 47.96542739868164, 1.0\n",
      "Train loss and acc of batch 66: 47.965415954589844, 1.0\n",
      "Train loss and acc of batch 67: 48.77787780761719, 0.96875\n",
      "Train loss and acc of batch 68: 48.56110382080078, 0.984375\n",
      "Train loss and acc of batch 69: 48.182159423828125, 0.984375\n",
      "Train loss and acc of batch 70: 47.96538162231445, 1.0\n",
      "Training accuracy and loss of epoch #147: 0.9890, 48.2967\n",
      "Train loss and acc of batch 0: 47.96537780761719, 1.0\n",
      "Train loss and acc of batch 1: 47.965362548828125, 1.0\n",
      "Train loss and acc of batch 2: 48.25120544433594, 0.984375\n",
      "Train loss and acc of batch 3: 48.18211364746094, 0.984375\n",
      "Train loss and acc of batch 4: 47.96533966064453, 1.0\n",
      "Train loss and acc of batch 5: 49.31425476074219, 0.96875\n",
      "Train loss and acc of batch 6: 48.46794128417969, 0.96875\n",
      "Train loss and acc of batch 7: 47.96531295776367, 1.0\n",
      "Train loss and acc of batch 8: 48.561004638671875, 0.984375\n",
      "Train loss and acc of batch 9: 48.25114440917969, 0.984375\n",
      "Train loss and acc of batch 10: 47.96529006958008, 1.0\n",
      "Train loss and acc of batch 11: 47.96527862548828, 1.0\n",
      "Train loss and acc of batch 12: 48.7184944152832, 0.984375\n",
      "Train loss and acc of batch 13: 48.18202209472656, 0.984375\n",
      "Train loss and acc of batch 14: 48.18201446533203, 0.984375\n",
      "Train loss and acc of batch 15: 48.560943603515625, 0.984375\n",
      "Train loss and acc of batch 16: 48.560935974121094, 0.984375\n",
      "Train loss and acc of batch 17: 48.718448638916016, 0.984375\n",
      "Train loss and acc of batch 18: 48.846763610839844, 0.96875\n",
      "Train loss and acc of batch 19: 47.96520233154297, 1.0\n",
      "Train loss and acc of batch 20: 47.96519088745117, 1.0\n",
      "Train loss and acc of batch 21: 48.560890197753906, 0.984375\n",
      "Train loss and acc of batch 22: 48.560874938964844, 0.984375\n",
      "Train loss and acc of batch 23: 47.965171813964844, 1.0\n",
      "Train loss and acc of batch 24: 48.56085968017578, 0.984375\n",
      "Train loss and acc of batch 25: 47.965152740478516, 1.0\n",
      "Train loss and acc of batch 26: 47.965145111083984, 1.0\n",
      "Train loss and acc of batch 27: 47.96512985229492, 1.0\n",
      "Train loss and acc of batch 28: 47.96512222290039, 1.0\n",
      "Train loss and acc of batch 29: 48.560813903808594, 0.984375\n",
      "Train loss and acc of batch 30: 47.96510314941406, 1.0\n",
      "Train loss and acc of batch 31: 48.181861877441406, 0.984375\n",
      "Train loss and acc of batch 32: 47.965087890625, 1.0\n",
      "Train loss and acc of batch 33: 47.96508026123047, 1.0\n",
      "Train loss and acc of batch 34: 48.560768127441406, 0.984375\n",
      "Train loss and acc of batch 35: 48.398590087890625, 0.96875\n",
      "Train loss and acc of batch 36: 47.96505355834961, 1.0\n",
      "Train loss and acc of batch 37: 48.718265533447266, 0.984375\n",
      "Train loss and acc of batch 38: 49.31395721435547, 0.96875\n",
      "Train loss and acc of batch 39: 48.181793212890625, 0.984375\n",
      "Train loss and acc of batch 40: 47.96501922607422, 1.0\n",
      "Train loss and acc of batch 41: 49.313934326171875, 0.96875\n",
      "Train loss and acc of batch 42: 47.96500015258789, 1.0\n",
      "Train loss and acc of batch 43: 48.560691833496094, 0.984375\n",
      "Train loss and acc of batch 44: 47.96498489379883, 1.0\n",
      "Train loss and acc of batch 45: 48.56067657470703, 0.984375\n",
      "Train loss and acc of batch 46: 48.250816345214844, 0.984375\n",
      "Train loss and acc of batch 47: 47.9649543762207, 1.0\n",
      "Train loss and acc of batch 48: 47.96494674682617, 1.0\n",
      "Train loss and acc of batch 49: 47.96493911743164, 1.0\n",
      "Train loss and acc of batch 50: 48.56062316894531, 0.984375\n",
      "Train loss and acc of batch 51: 49.3138427734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.22075271606445, 0.953125\n",
      "Train loss and acc of batch 53: 47.964900970458984, 1.0\n",
      "Train loss and acc of batch 54: 48.181663513183594, 0.984375\n",
      "Train loss and acc of batch 55: 47.964881896972656, 1.0\n",
      "Train loss and acc of batch 56: 47.964874267578125, 1.0\n",
      "Train loss and acc of batch 57: 48.56056213378906, 0.984375\n",
      "Train loss and acc of batch 58: 47.9648551940918, 1.0\n",
      "Train loss and acc of batch 59: 47.964839935302734, 1.0\n",
      "Train loss and acc of batch 60: 47.96483612060547, 1.0\n",
      "Train loss and acc of batch 61: 47.96482849121094, 1.0\n",
      "Train loss and acc of batch 62: 48.18157958984375, 0.984375\n",
      "Train loss and acc of batch 63: 49.156211853027344, 0.96875\n",
      "Train loss and acc of batch 64: 48.181556701660156, 0.984375\n",
      "Train loss and acc of batch 65: 47.96479034423828, 1.0\n",
      "Train loss and acc of batch 66: 47.96478271484375, 1.0\n",
      "Train loss and acc of batch 67: 48.77724075317383, 0.96875\n",
      "Train loss and acc of batch 68: 48.56047058105469, 0.984375\n",
      "Train loss and acc of batch 69: 48.1815185546875, 0.984375\n",
      "Train loss and acc of batch 70: 47.96474838256836, 1.0\n",
      "Training accuracy and loss of epoch #148: 0.9892, 48.2930\n",
      "Saved model by train loss 48.29302376760563\n",
      "Train loss and acc of batch 0: 47.96474075317383, 1.0\n",
      "Train loss and acc of batch 1: 47.96472930908203, 1.0\n",
      "Train loss and acc of batch 2: 48.250572204589844, 0.984375\n",
      "Train loss and acc of batch 3: 48.18147277832031, 0.984375\n",
      "Train loss and acc of batch 4: 47.96470260620117, 1.0\n",
      "Train loss and acc of batch 5: 49.31361389160156, 0.96875\n",
      "Train loss and acc of batch 6: 48.46730422973633, 0.96875\n",
      "Train loss and acc of batch 7: 47.96467208862305, 1.0\n",
      "Train loss and acc of batch 8: 48.56036376953125, 0.984375\n",
      "Train loss and acc of batch 9: 48.250511169433594, 0.984375\n",
      "Train loss and acc of batch 10: 47.96464920043945, 1.0\n",
      "Train loss and acc of batch 11: 47.964637756347656, 1.0\n",
      "Train loss and acc of batch 12: 48.71785354614258, 0.984375\n",
      "Train loss and acc of batch 13: 48.18138122558594, 0.984375\n",
      "Train loss and acc of batch 14: 48.18138122558594, 0.984375\n",
      "Train loss and acc of batch 15: 48.560302734375, 0.984375\n",
      "Train loss and acc of batch 16: 48.56029510498047, 0.984375\n",
      "Train loss and acc of batch 17: 48.717811584472656, 0.984375\n",
      "Train loss and acc of batch 18: 48.84613037109375, 0.96875\n",
      "Train loss and acc of batch 19: 47.964569091796875, 1.0\n",
      "Train loss and acc of batch 20: 47.964561462402344, 1.0\n",
      "Train loss and acc of batch 21: 48.56024932861328, 0.984375\n",
      "Train loss and acc of batch 22: 48.56024169921875, 0.984375\n",
      "Train loss and acc of batch 23: 47.96453094482422, 1.0\n",
      "Train loss and acc of batch 24: 48.56022644042969, 0.984375\n",
      "Train loss and acc of batch 25: 47.964515686035156, 1.0\n",
      "Train loss and acc of batch 26: 47.96450424194336, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 27: 47.964500427246094, 1.0\n",
      "Train loss and acc of batch 28: 47.96448516845703, 1.0\n",
      "Train loss and acc of batch 29: 48.5601806640625, 0.984375\n",
      "Train loss and acc of batch 30: 47.96446990966797, 1.0\n",
      "Train loss and acc of batch 31: 48.18122100830078, 0.984375\n",
      "Train loss and acc of batch 32: 47.964447021484375, 1.0\n",
      "Train loss and acc of batch 33: 47.96444320678711, 1.0\n",
      "Train loss and acc of batch 34: 48.560142517089844, 0.984375\n",
      "Train loss and acc of batch 35: 48.397953033447266, 0.96875\n",
      "Train loss and acc of batch 36: 47.964412689208984, 1.0\n",
      "Train loss and acc of batch 37: 48.717628479003906, 0.984375\n",
      "Train loss and acc of batch 38: 49.313323974609375, 0.96875\n",
      "Train loss and acc of batch 39: 48.18115234375, 0.984375\n",
      "Train loss and acc of batch 40: 47.964378356933594, 1.0\n",
      "Train loss and acc of batch 41: 49.31330108642578, 0.96875\n",
      "Train loss and acc of batch 42: 47.9643669128418, 1.0\n",
      "Train loss and acc of batch 43: 48.56005859375, 0.984375\n",
      "Train loss and acc of batch 44: 47.9643440246582, 1.0\n",
      "Train loss and acc of batch 45: 48.560035705566406, 0.984375\n",
      "Train loss and acc of batch 46: 48.25017547607422, 0.984375\n",
      "Train loss and acc of batch 47: 47.964317321777344, 1.0\n",
      "Train loss and acc of batch 48: 47.96430969238281, 1.0\n",
      "Train loss and acc of batch 49: 47.964298248291016, 1.0\n",
      "Train loss and acc of batch 50: 48.55999755859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.313201904296875, 0.96875\n",
      "Train loss and acc of batch 52: 49.220115661621094, 0.953125\n",
      "Train loss and acc of batch 53: 47.96426773071289, 1.0\n",
      "Train loss and acc of batch 54: 48.18102264404297, 0.984375\n",
      "Train loss and acc of batch 55: 47.96424865722656, 1.0\n",
      "Train loss and acc of batch 56: 47.96424102783203, 1.0\n",
      "Train loss and acc of batch 57: 48.55992889404297, 0.984375\n",
      "Train loss and acc of batch 58: 47.9642219543457, 1.0\n",
      "Train loss and acc of batch 59: 47.96420669555664, 1.0\n",
      "Train loss and acc of batch 60: 47.96419906616211, 1.0\n",
      "Train loss and acc of batch 61: 47.96419143676758, 1.0\n",
      "Train loss and acc of batch 62: 48.18095397949219, 0.984375\n",
      "Train loss and acc of batch 63: 49.155574798583984, 0.96875\n",
      "Train loss and acc of batch 64: 48.180931091308594, 0.984375\n",
      "Train loss and acc of batch 65: 47.96415328979492, 1.0\n",
      "Train loss and acc of batch 66: 47.964149475097656, 1.0\n",
      "Train loss and acc of batch 67: 48.776607513427734, 0.96875\n",
      "Train loss and acc of batch 68: 48.55982971191406, 0.984375\n",
      "Train loss and acc of batch 69: 48.180885314941406, 0.984375\n",
      "Train loss and acc of batch 70: 47.964111328125, 1.0\n",
      "Training accuracy and loss of epoch #149: 0.9892, 48.2924\n",
      "Saved model by train loss 48.2923874653561\n",
      "Train loss and acc of batch 0: 47.96410369873047, 1.0\n",
      "Train loss and acc of batch 1: 47.964088439941406, 1.0\n",
      "Train loss and acc of batch 2: 48.24993896484375, 0.984375\n",
      "Train loss and acc of batch 3: 48.18083953857422, 0.984375\n",
      "Train loss and acc of batch 4: 47.96406936645508, 1.0\n",
      "Train loss and acc of batch 5: 49.31298065185547, 0.96875\n",
      "Train loss and acc of batch 6: 48.46666717529297, 0.96875\n",
      "Train loss and acc of batch 7: 47.96404266357422, 1.0\n",
      "Train loss and acc of batch 8: 48.559730529785156, 0.984375\n",
      "Train loss and acc of batch 9: 48.2498779296875, 0.984375\n",
      "Train loss and acc of batch 10: 47.96401596069336, 1.0\n",
      "Train loss and acc of batch 11: 47.96400451660156, 1.0\n",
      "Train loss and acc of batch 12: 48.717220306396484, 0.984375\n",
      "Train loss and acc of batch 13: 48.180755615234375, 0.984375\n",
      "Train loss and acc of batch 14: 48.180747985839844, 0.984375\n",
      "Train loss and acc of batch 15: 48.55967712402344, 0.984375\n",
      "Train loss and acc of batch 16: 48.559661865234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.71717071533203, 0.984375\n",
      "Train loss and acc of batch 18: 48.845497131347656, 0.96875\n",
      "Train loss and acc of batch 19: 47.963932037353516, 1.0\n",
      "Train loss and acc of batch 20: 47.96392822265625, 1.0\n",
      "Train loss and acc of batch 21: 48.55961608886719, 0.984375\n",
      "Train loss and acc of batch 22: 48.559608459472656, 0.984375\n",
      "Train loss and acc of batch 23: 48.1806640625, 0.984375\n",
      "Train loss and acc of batch 24: 48.559593200683594, 0.984375\n",
      "Train loss and acc of batch 25: 47.9638786315918, 1.0\n",
      "Train loss and acc of batch 26: 47.963871002197266, 1.0\n",
      "Train loss and acc of batch 27: 47.96385955810547, 1.0\n",
      "Train loss and acc of batch 28: 47.96385192871094, 1.0\n",
      "Train loss and acc of batch 29: 48.559547424316406, 0.984375\n",
      "Train loss and acc of batch 30: 47.963829040527344, 1.0\n",
      "Train loss and acc of batch 31: 48.18058776855469, 0.984375\n",
      "Train loss and acc of batch 32: 47.96381759643555, 1.0\n",
      "Train loss and acc of batch 33: 47.963809967041016, 1.0\n",
      "Train loss and acc of batch 34: 48.55950164794922, 0.984375\n",
      "Train loss and acc of batch 35: 48.39731979370117, 0.96875\n",
      "Train loss and acc of batch 36: 47.963783264160156, 1.0\n",
      "Train loss and acc of batch 37: 48.71699905395508, 0.984375\n",
      "Train loss and acc of batch 38: 49.31268310546875, 0.96875\n",
      "Train loss and acc of batch 39: 48.180519104003906, 0.984375\n",
      "Train loss and acc of batch 40: 47.9637451171875, 1.0\n",
      "Train loss and acc of batch 41: 49.31266784667969, 0.96875\n",
      "Train loss and acc of batch 42: 47.96372604370117, 1.0\n",
      "Train loss and acc of batch 43: 48.559425354003906, 0.984375\n",
      "Train loss and acc of batch 44: 47.96371078491211, 1.0\n",
      "Train loss and acc of batch 45: 48.55940246582031, 0.984375\n",
      "Train loss and acc of batch 46: 48.249542236328125, 0.984375\n",
      "Train loss and acc of batch 47: 47.96368408203125, 1.0\n",
      "Train loss and acc of batch 48: 47.96367263793945, 1.0\n",
      "Train loss and acc of batch 49: 47.96366882324219, 1.0\n",
      "Train loss and acc of batch 50: 48.559364318847656, 0.984375\n",
      "Train loss and acc of batch 51: 49.31257629394531, 0.96875\n",
      "Train loss and acc of batch 52: 49.21947479248047, 0.953125\n",
      "Train loss and acc of batch 53: 47.96363067626953, 1.0\n",
      "Train loss and acc of batch 54: 48.180381774902344, 0.984375\n",
      "Train loss and acc of batch 55: 47.96361541748047, 1.0\n",
      "Train loss and acc of batch 56: 47.963600158691406, 1.0\n",
      "Train loss and acc of batch 57: 48.559295654296875, 0.984375\n",
      "Train loss and acc of batch 58: 47.96358871459961, 1.0\n",
      "Train loss and acc of batch 59: 47.96357345581055, 1.0\n",
      "Train loss and acc of batch 60: 47.96356964111328, 1.0\n",
      "Train loss and acc of batch 61: 47.963558197021484, 1.0\n",
      "Train loss and acc of batch 62: 48.18031311035156, 0.984375\n",
      "Train loss and acc of batch 63: 49.15494155883789, 0.96875\n",
      "Train loss and acc of batch 64: 48.1802978515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.963523864746094, 1.0\n",
      "Train loss and acc of batch 66: 47.9635124206543, 1.0\n",
      "Train loss and acc of batch 67: 48.775970458984375, 0.96875\n",
      "Train loss and acc of batch 68: 48.55919647216797, 0.984375\n",
      "Train loss and acc of batch 69: 48.18025207519531, 0.984375\n",
      "Train loss and acc of batch 70: 47.963478088378906, 1.0\n",
      "Training accuracy and loss of epoch #150: 0.9890, 48.2948\n",
      "Train loss and acc of batch 0: 47.963470458984375, 1.0\n",
      "Train loss and acc of batch 1: 47.963462829589844, 1.0\n",
      "Train loss and acc of batch 2: 48.249298095703125, 0.984375\n",
      "Train loss and acc of batch 3: 48.180206298828125, 0.984375\n",
      "Train loss and acc of batch 4: 47.96343231201172, 1.0\n",
      "Train loss and acc of batch 5: 49.312347412109375, 0.96875\n",
      "Train loss and acc of batch 6: 48.466033935546875, 0.96875\n",
      "Train loss and acc of batch 7: 47.963409423828125, 1.0\n",
      "Train loss and acc of batch 8: 48.55909729003906, 0.984375\n",
      "Train loss and acc of batch 9: 48.249244689941406, 0.984375\n",
      "Train loss and acc of batch 10: 47.96337890625, 1.0\n",
      "Train loss and acc of batch 11: 47.96337127685547, 1.0\n",
      "Train loss and acc of batch 12: 48.716583251953125, 0.984375\n",
      "Train loss and acc of batch 13: 48.18011474609375, 0.984375\n",
      "Train loss and acc of batch 14: 48.18010711669922, 0.984375\n",
      "Train loss and acc of batch 15: 48.559043884277344, 0.984375\n",
      "Train loss and acc of batch 16: 48.55902862548828, 0.984375\n",
      "Train loss and acc of batch 17: 48.7165412902832, 0.984375\n",
      "Train loss and acc of batch 18: 48.8448600769043, 0.96875\n",
      "Train loss and acc of batch 19: 47.96329879760742, 1.0\n",
      "Train loss and acc of batch 20: 47.96329116821289, 1.0\n",
      "Train loss and acc of batch 21: 48.558982849121094, 0.984375\n",
      "Train loss and acc of batch 22: 48.55897521972656, 0.984375\n",
      "Train loss and acc of batch 23: 48.180030822753906, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 24: 48.5589599609375, 0.984375\n",
      "Train loss and acc of batch 25: 47.9632453918457, 1.0\n",
      "Train loss and acc of batch 26: 47.96323776245117, 1.0\n",
      "Train loss and acc of batch 27: 47.963226318359375, 1.0\n",
      "Train loss and acc of batch 28: 47.96322250366211, 1.0\n",
      "Train loss and acc of batch 29: 48.55891418457031, 0.984375\n",
      "Train loss and acc of batch 30: 47.96320343017578, 1.0\n",
      "Train loss and acc of batch 31: 48.179954528808594, 0.984375\n",
      "Train loss and acc of batch 32: 47.96318435668945, 1.0\n",
      "Train loss and acc of batch 33: 47.963172912597656, 1.0\n",
      "Train loss and acc of batch 34: 48.558868408203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.39668655395508, 0.96875\n",
      "Train loss and acc of batch 36: 47.96315002441406, 1.0\n",
      "Train loss and acc of batch 37: 48.71636199951172, 0.984375\n",
      "Train loss and acc of batch 38: 49.31205749511719, 0.96875\n",
      "Train loss and acc of batch 39: 48.17988586425781, 0.984375\n",
      "Train loss and acc of batch 40: 47.96311569213867, 1.0\n",
      "Train loss and acc of batch 41: 49.31202697753906, 0.96875\n",
      "Train loss and acc of batch 42: 47.96309280395508, 1.0\n",
      "Train loss and acc of batch 43: 48.55879211425781, 0.984375\n",
      "Train loss and acc of batch 44: 47.963077545166016, 1.0\n",
      "Train loss and acc of batch 45: 48.55877685546875, 0.984375\n",
      "Train loss and acc of batch 46: 48.24890899658203, 0.984375\n",
      "Train loss and acc of batch 47: 47.96304702758789, 1.0\n",
      "Train loss and acc of batch 48: 47.963043212890625, 1.0\n",
      "Train loss and acc of batch 49: 47.96303176879883, 1.0\n",
      "Train loss and acc of batch 50: 48.55873107910156, 0.984375\n",
      "Train loss and acc of batch 51: 49.31193542480469, 0.96875\n",
      "Train loss and acc of batch 52: 49.218849182128906, 0.953125\n",
      "Train loss and acc of batch 53: 47.96299743652344, 1.0\n",
      "Train loss and acc of batch 54: 48.17975616455078, 0.984375\n",
      "Train loss and acc of batch 55: 47.962974548339844, 1.0\n",
      "Train loss and acc of batch 56: 47.96297073364258, 1.0\n",
      "Train loss and acc of batch 57: 48.55866241455078, 0.984375\n",
      "Train loss and acc of batch 58: 47.96295166015625, 1.0\n",
      "Train loss and acc of batch 59: 47.962947845458984, 1.0\n",
      "Train loss and acc of batch 60: 47.96293258666992, 1.0\n",
      "Train loss and acc of batch 61: 47.962928771972656, 1.0\n",
      "Train loss and acc of batch 62: 48.1796875, 0.984375\n",
      "Train loss and acc of batch 63: 49.15431213378906, 0.96875\n",
      "Train loss and acc of batch 64: 48.179664611816406, 0.984375\n",
      "Train loss and acc of batch 65: 47.962890625, 1.0\n",
      "Train loss and acc of batch 66: 47.9628791809082, 1.0\n",
      "Train loss and acc of batch 67: 48.77534103393555, 0.96875\n",
      "Train loss and acc of batch 68: 48.558563232421875, 0.984375\n",
      "Train loss and acc of batch 69: 48.17961120605469, 0.984375\n",
      "Train loss and acc of batch 70: 47.96284484863281, 1.0\n",
      "Training accuracy and loss of epoch #151: 0.9890, 48.2942\n",
      "Train loss and acc of batch 0: 47.962833404541016, 1.0\n",
      "Train loss and acc of batch 1: 47.96282958984375, 1.0\n",
      "Train loss and acc of batch 2: 48.24867248535156, 0.984375\n",
      "Train loss and acc of batch 3: 48.17957305908203, 0.984375\n",
      "Train loss and acc of batch 4: 47.96280288696289, 1.0\n",
      "Train loss and acc of batch 5: 49.31172180175781, 0.96875\n",
      "Train loss and acc of batch 6: 48.46540069580078, 0.96875\n",
      "Train loss and acc of batch 7: 47.96277618408203, 1.0\n",
      "Train loss and acc of batch 8: 48.5584716796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.24860382080078, 0.984375\n",
      "Train loss and acc of batch 10: 47.96275329589844, 1.0\n",
      "Train loss and acc of batch 11: 47.962738037109375, 1.0\n",
      "Train loss and acc of batch 12: 48.7159538269043, 0.984375\n",
      "Train loss and acc of batch 13: 48.17948913574219, 0.984375\n",
      "Train loss and acc of batch 14: 48.179473876953125, 0.984375\n",
      "Train loss and acc of batch 15: 48.55840301513672, 0.984375\n",
      "Train loss and acc of batch 16: 48.55839538574219, 0.984375\n",
      "Train loss and acc of batch 17: 48.71590805053711, 0.984375\n",
      "Train loss and acc of batch 18: 48.84423065185547, 0.96875\n",
      "Train loss and acc of batch 19: 47.96267318725586, 1.0\n",
      "Train loss and acc of batch 20: 47.96265411376953, 1.0\n",
      "Train loss and acc of batch 21: 48.558349609375, 0.984375\n",
      "Train loss and acc of batch 22: 48.55834197998047, 0.984375\n",
      "Train loss and acc of batch 23: 48.17939758300781, 0.984375\n",
      "Train loss and acc of batch 24: 48.558326721191406, 0.984375\n",
      "Train loss and acc of batch 25: 47.962615966796875, 1.0\n",
      "Train loss and acc of batch 26: 47.96260070800781, 1.0\n",
      "Train loss and acc of batch 27: 47.96259689331055, 1.0\n",
      "Train loss and acc of batch 28: 47.96258544921875, 1.0\n",
      "Train loss and acc of batch 29: 48.55828094482422, 0.984375\n",
      "Train loss and acc of batch 30: 47.96257019042969, 1.0\n",
      "Train loss and acc of batch 31: 48.17932891845703, 0.984375\n",
      "Train loss and acc of batch 32: 47.96255111694336, 1.0\n",
      "Train loss and acc of batch 33: 47.962547302246094, 1.0\n",
      "Train loss and acc of batch 34: 48.55823516845703, 0.984375\n",
      "Train loss and acc of batch 35: 48.396053314208984, 0.96875\n",
      "Train loss and acc of batch 36: 47.96251678466797, 1.0\n",
      "Train loss and acc of batch 37: 48.715728759765625, 0.984375\n",
      "Train loss and acc of batch 38: 49.31141662597656, 0.96875\n",
      "Train loss and acc of batch 39: 48.17926025390625, 0.984375\n",
      "Train loss and acc of batch 40: 47.96247863769531, 1.0\n",
      "Train loss and acc of batch 41: 49.311397552490234, 0.96875\n",
      "Train loss and acc of batch 42: 47.96246337890625, 1.0\n",
      "Train loss and acc of batch 43: 48.55815124511719, 0.984375\n",
      "Train loss and acc of batch 44: 47.96244430541992, 1.0\n",
      "Train loss and acc of batch 45: 48.558135986328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.24827575683594, 0.984375\n",
      "Train loss and acc of batch 47: 47.96241760253906, 1.0\n",
      "Train loss and acc of batch 48: 47.96240997314453, 1.0\n",
      "Train loss and acc of batch 49: 47.962398529052734, 1.0\n",
      "Train loss and acc of batch 50: 48.55809020996094, 0.984375\n",
      "Train loss and acc of batch 51: 49.311309814453125, 0.96875\n",
      "Train loss and acc of batch 52: 49.21821212768555, 0.953125\n",
      "Train loss and acc of batch 53: 47.96236801147461, 1.0\n",
      "Train loss and acc of batch 54: 48.179115295410156, 0.984375\n",
      "Train loss and acc of batch 55: 47.962345123291016, 1.0\n",
      "Train loss and acc of batch 56: 47.962337493896484, 1.0\n",
      "Train loss and acc of batch 57: 48.55802917480469, 0.984375\n",
      "Train loss and acc of batch 58: 47.96232223510742, 1.0\n",
      "Train loss and acc of batch 59: 47.96230697631836, 1.0\n",
      "Train loss and acc of batch 60: 47.962303161621094, 1.0\n",
      "Train loss and acc of batch 61: 47.9622917175293, 1.0\n",
      "Train loss and acc of batch 62: 48.179054260253906, 0.984375\n",
      "Train loss and acc of batch 63: 49.1536750793457, 0.96875\n",
      "Train loss and acc of batch 64: 48.17903137207031, 0.984375\n",
      "Train loss and acc of batch 65: 47.962257385253906, 1.0\n",
      "Train loss and acc of batch 66: 47.96224594116211, 1.0\n",
      "Train loss and acc of batch 67: 48.77470779418945, 0.96875\n",
      "Train loss and acc of batch 68: 48.55792999267578, 0.984375\n",
      "Train loss and acc of batch 69: 48.178985595703125, 0.984375\n",
      "Train loss and acc of batch 70: 47.962215423583984, 1.0\n",
      "Training accuracy and loss of epoch #152: 0.9890, 48.2935\n",
      "Train loss and acc of batch 0: 47.96220397949219, 1.0\n",
      "Train loss and acc of batch 1: 47.962196350097656, 1.0\n",
      "Train loss and acc of batch 2: 48.24803924560547, 0.984375\n",
      "Train loss and acc of batch 3: 48.17893981933594, 0.984375\n",
      "Train loss and acc of batch 4: 47.96216583251953, 1.0\n",
      "Train loss and acc of batch 5: 49.31108856201172, 0.96875\n",
      "Train loss and acc of batch 6: 48.46477127075195, 0.96875\n",
      "Train loss and acc of batch 7: 47.96214294433594, 1.0\n",
      "Train loss and acc of batch 8: 48.557830810546875, 0.984375\n",
      "Train loss and acc of batch 9: 48.24797058105469, 0.984375\n",
      "Train loss and acc of batch 10: 47.96211624145508, 1.0\n",
      "Train loss and acc of batch 11: 47.962100982666016, 1.0\n",
      "Train loss and acc of batch 12: 48.7153205871582, 0.984375\n",
      "Train loss and acc of batch 13: 48.17884826660156, 0.984375\n",
      "Train loss and acc of batch 14: 48.17884826660156, 0.984375\n",
      "Train loss and acc of batch 15: 48.557769775390625, 0.984375\n",
      "Train loss and acc of batch 16: 48.557762145996094, 0.984375\n",
      "Train loss and acc of batch 17: 48.715274810791016, 0.984375\n",
      "Train loss and acc of batch 18: 48.843597412109375, 0.96875\n",
      "Train loss and acc of batch 19: 47.9620361328125, 1.0\n",
      "Train loss and acc of batch 20: 47.9620246887207, 1.0\n",
      "Train loss and acc of batch 21: 48.557716369628906, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 22: 48.557708740234375, 0.984375\n",
      "Train loss and acc of batch 23: 48.17875671386719, 0.984375\n",
      "Train loss and acc of batch 24: 48.55769348144531, 0.984375\n",
      "Train loss and acc of batch 25: 47.96197509765625, 1.0\n",
      "Train loss and acc of batch 26: 47.961971282958984, 1.0\n",
      "Train loss and acc of batch 27: 47.96196365356445, 1.0\n",
      "Train loss and acc of batch 28: 47.96195602416992, 1.0\n",
      "Train loss and acc of batch 29: 48.557640075683594, 0.984375\n",
      "Train loss and acc of batch 30: 47.96193313598633, 1.0\n",
      "Train loss and acc of batch 31: 48.178688049316406, 0.984375\n",
      "Train loss and acc of batch 32: 47.96192169189453, 1.0\n",
      "Train loss and acc of batch 33: 47.96190643310547, 1.0\n",
      "Train loss and acc of batch 34: 48.55760192871094, 0.984375\n",
      "Train loss and acc of batch 35: 48.39542007446289, 0.96875\n",
      "Train loss and acc of batch 36: 47.96187973022461, 1.0\n",
      "Train loss and acc of batch 37: 48.71509552001953, 0.984375\n",
      "Train loss and acc of batch 38: 49.310791015625, 0.96875\n",
      "Train loss and acc of batch 39: 48.178619384765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.96184539794922, 1.0\n",
      "Train loss and acc of batch 41: 49.31076431274414, 0.96875\n",
      "Train loss and acc of batch 42: 47.961830139160156, 1.0\n",
      "Train loss and acc of batch 43: 48.557525634765625, 0.984375\n",
      "Train loss and acc of batch 44: 47.96180725097656, 1.0\n",
      "Train loss and acc of batch 45: 48.55750274658203, 0.984375\n",
      "Train loss and acc of batch 46: 48.247650146484375, 0.984375\n",
      "Train loss and acc of batch 47: 47.961788177490234, 1.0\n",
      "Train loss and acc of batch 48: 47.96177291870117, 1.0\n",
      "Train loss and acc of batch 49: 47.96176528930664, 1.0\n",
      "Train loss and acc of batch 50: 48.557456970214844, 0.984375\n",
      "Train loss and acc of batch 51: 49.31067657470703, 0.96875\n",
      "Train loss and acc of batch 52: 49.21758270263672, 0.953125\n",
      "Train loss and acc of batch 53: 47.961727142333984, 1.0\n",
      "Train loss and acc of batch 54: 48.17848205566406, 0.984375\n",
      "Train loss and acc of batch 55: 47.96171188354492, 1.0\n",
      "Train loss and acc of batch 56: 47.96170425415039, 1.0\n",
      "Train loss and acc of batch 57: 48.557395935058594, 0.984375\n",
      "Train loss and acc of batch 58: 47.96168518066406, 1.0\n",
      "Train loss and acc of batch 59: 47.961673736572266, 1.0\n",
      "Train loss and acc of batch 60: 47.961669921875, 1.0\n",
      "Train loss and acc of batch 61: 47.96166229248047, 1.0\n",
      "Train loss and acc of batch 62: 48.17841339111328, 0.984375\n",
      "Train loss and acc of batch 63: 49.153045654296875, 0.96875\n",
      "Train loss and acc of batch 64: 48.17839813232422, 0.984375\n",
      "Train loss and acc of batch 65: 47.96162414550781, 1.0\n",
      "Train loss and acc of batch 66: 47.961612701416016, 1.0\n",
      "Train loss and acc of batch 67: 48.77406692504883, 0.96875\n",
      "Train loss and acc of batch 68: 48.55729675292969, 0.984375\n",
      "Train loss and acc of batch 69: 48.17835235595703, 0.984375\n",
      "Train loss and acc of batch 70: 47.961578369140625, 1.0\n",
      "Training accuracy and loss of epoch #153: 0.9890, 48.2929\n",
      "Train loss and acc of batch 0: 47.961570739746094, 1.0\n",
      "Train loss and acc of batch 1: 47.96156311035156, 1.0\n",
      "Train loss and acc of batch 2: 48.247406005859375, 0.984375\n",
      "Train loss and acc of batch 3: 48.178306579589844, 0.984375\n",
      "Train loss and acc of batch 4: 47.96153259277344, 1.0\n",
      "Train loss and acc of batch 5: 49.310447692871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.46413040161133, 0.96875\n",
      "Train loss and acc of batch 7: 47.96150588989258, 1.0\n",
      "Train loss and acc of batch 8: 48.55720520019531, 0.984375\n",
      "Train loss and acc of batch 9: 48.247344970703125, 0.984375\n",
      "Train loss and acc of batch 10: 47.96147537231445, 1.0\n",
      "Train loss and acc of batch 11: 47.96147155761719, 1.0\n",
      "Train loss and acc of batch 12: 48.71468734741211, 0.984375\n",
      "Train loss and acc of batch 13: 48.17822265625, 0.984375\n",
      "Train loss and acc of batch 14: 48.17820739746094, 0.984375\n",
      "Train loss and acc of batch 15: 48.55713653564453, 0.984375\n",
      "Train loss and acc of batch 16: 48.55712127685547, 0.984375\n",
      "Train loss and acc of batch 17: 48.71464538574219, 0.984375\n",
      "Train loss and acc of batch 18: 48.842960357666016, 0.96875\n",
      "Train loss and acc of batch 19: 47.96139907836914, 1.0\n",
      "Train loss and acc of batch 20: 47.96139144897461, 1.0\n",
      "Train loss and acc of batch 21: 48.55708312988281, 0.984375\n",
      "Train loss and acc of batch 22: 48.55707550048828, 0.984375\n",
      "Train loss and acc of batch 23: 48.178131103515625, 0.984375\n",
      "Train loss and acc of batch 24: 48.55705261230469, 0.984375\n",
      "Train loss and acc of batch 25: 47.96134567260742, 1.0\n",
      "Train loss and acc of batch 26: 47.96133804321289, 1.0\n",
      "Train loss and acc of batch 27: 47.96133041381836, 1.0\n",
      "Train loss and acc of batch 28: 47.96131896972656, 1.0\n",
      "Train loss and acc of batch 29: 48.55701446533203, 0.984375\n",
      "Train loss and acc of batch 30: 47.9613037109375, 1.0\n",
      "Train loss and acc of batch 31: 48.17805480957031, 0.984375\n",
      "Train loss and acc of batch 32: 47.96128463745117, 1.0\n",
      "Train loss and acc of batch 33: 47.961273193359375, 1.0\n",
      "Train loss and acc of batch 34: 48.556968688964844, 0.984375\n",
      "Train loss and acc of batch 35: 48.3947868347168, 0.96875\n",
      "Train loss and acc of batch 36: 47.96125030517578, 1.0\n",
      "Train loss and acc of batch 37: 48.7144660949707, 0.984375\n",
      "Train loss and acc of batch 38: 49.310150146484375, 0.96875\n",
      "Train loss and acc of batch 39: 48.17798614501953, 0.984375\n",
      "Train loss and acc of batch 40: 47.961212158203125, 1.0\n",
      "Train loss and acc of batch 41: 49.31013107299805, 0.96875\n",
      "Train loss and acc of batch 42: 47.96119689941406, 1.0\n",
      "Train loss and acc of batch 43: 48.556884765625, 0.984375\n",
      "Train loss and acc of batch 44: 47.961177825927734, 1.0\n",
      "Train loss and acc of batch 45: 48.55687713623047, 0.984375\n",
      "Train loss and acc of batch 46: 48.24700927734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.961151123046875, 1.0\n",
      "Train loss and acc of batch 48: 47.961143493652344, 1.0\n",
      "Train loss and acc of batch 49: 47.96113204956055, 1.0\n",
      "Train loss and acc of batch 50: 48.55682373046875, 0.984375\n",
      "Train loss and acc of batch 51: 49.31004333496094, 0.96875\n",
      "Train loss and acc of batch 52: 49.21694564819336, 0.953125\n",
      "Train loss and acc of batch 53: 47.96109390258789, 1.0\n",
      "Train loss and acc of batch 54: 48.17784881591797, 0.984375\n",
      "Train loss and acc of batch 55: 47.96107864379883, 1.0\n",
      "Train loss and acc of batch 56: 47.9610710144043, 1.0\n",
      "Train loss and acc of batch 57: 48.5567626953125, 0.984375\n",
      "Train loss and acc of batch 58: 47.961055755615234, 1.0\n",
      "Train loss and acc of batch 59: 47.96104431152344, 1.0\n",
      "Train loss and acc of batch 60: 47.961029052734375, 1.0\n",
      "Train loss and acc of batch 61: 47.96102523803711, 1.0\n",
      "Train loss and acc of batch 62: 48.17778015136719, 0.984375\n",
      "Train loss and acc of batch 63: 49.15241241455078, 0.96875\n",
      "Train loss and acc of batch 64: 48.177764892578125, 0.984375\n",
      "Train loss and acc of batch 65: 47.96099090576172, 1.0\n",
      "Train loss and acc of batch 66: 47.96097946166992, 1.0\n",
      "Train loss and acc of batch 67: 48.7734375, 0.96875\n",
      "Train loss and acc of batch 68: 48.556663513183594, 0.984375\n",
      "Train loss and acc of batch 69: 48.17771911621094, 0.984375\n",
      "Train loss and acc of batch 70: 47.960941314697266, 1.0\n",
      "Training accuracy and loss of epoch #154: 0.9890, 48.2923\n",
      "Saved model by train loss 48.29227286325374\n",
      "Train loss and acc of batch 0: 47.9609375, 1.0\n",
      "Train loss and acc of batch 1: 47.96092987060547, 1.0\n",
      "Train loss and acc of batch 2: 48.24677276611328, 0.984375\n",
      "Train loss and acc of batch 3: 48.17766571044922, 0.984375\n",
      "Train loss and acc of batch 4: 47.96090316772461, 1.0\n",
      "Train loss and acc of batch 5: 49.309814453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.463497161865234, 0.96875\n",
      "Train loss and acc of batch 7: 47.960872650146484, 1.0\n",
      "Train loss and acc of batch 8: 48.55656433105469, 0.984375\n",
      "Train loss and acc of batch 9: 48.2467041015625, 0.984375\n",
      "Train loss and acc of batch 10: 47.96084213256836, 1.0\n",
      "Train loss and acc of batch 11: 47.96083450317383, 1.0\n",
      "Train loss and acc of batch 12: 48.71405029296875, 0.984375\n",
      "Train loss and acc of batch 13: 48.177581787109375, 0.984375\n",
      "Train loss and acc of batch 14: 48.177574157714844, 0.984375\n",
      "Train loss and acc of batch 15: 48.55650329589844, 0.984375\n",
      "Train loss and acc of batch 16: 48.556495666503906, 0.984375\n",
      "Train loss and acc of batch 17: 48.71400451660156, 0.984375\n",
      "Train loss and acc of batch 18: 48.84232711791992, 0.96875\n",
      "Train loss and acc of batch 19: 47.96076583862305, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 20: 47.96075439453125, 1.0\n",
      "Train loss and acc of batch 21: 48.55644989013672, 0.984375\n",
      "Train loss and acc of batch 22: 48.55644226074219, 0.984375\n",
      "Train loss and acc of batch 23: 48.17749786376953, 0.984375\n",
      "Train loss and acc of batch 24: 48.556427001953125, 0.984375\n",
      "Train loss and acc of batch 25: 47.96071243286133, 1.0\n",
      "Train loss and acc of batch 26: 47.96070098876953, 1.0\n",
      "Train loss and acc of batch 27: 47.960693359375, 1.0\n",
      "Train loss and acc of batch 28: 47.96068572998047, 1.0\n",
      "Train loss and acc of batch 29: 48.55638122558594, 0.984375\n",
      "Train loss and acc of batch 30: 47.96067428588867, 1.0\n",
      "Train loss and acc of batch 31: 48.17742156982422, 0.984375\n",
      "Train loss and acc of batch 32: 47.96064758300781, 1.0\n",
      "Train loss and acc of batch 33: 47.96063995361328, 1.0\n",
      "Train loss and acc of batch 34: 48.55633544921875, 0.984375\n",
      "Train loss and acc of batch 35: 48.3941535949707, 0.96875\n",
      "Train loss and acc of batch 36: 47.960609436035156, 1.0\n",
      "Train loss and acc of batch 37: 48.713829040527344, 0.984375\n",
      "Train loss and acc of batch 38: 49.30952453613281, 0.96875\n",
      "Train loss and acc of batch 39: 48.17735290527344, 0.984375\n",
      "Train loss and acc of batch 40: 47.960575103759766, 1.0\n",
      "Train loss and acc of batch 41: 49.30949783325195, 0.96875\n",
      "Train loss and acc of batch 42: 47.9605598449707, 1.0\n",
      "Train loss and acc of batch 43: 48.55625915527344, 0.984375\n",
      "Train loss and acc of batch 44: 47.96054458618164, 1.0\n",
      "Train loss and acc of batch 45: 48.556236267089844, 0.984375\n",
      "Train loss and acc of batch 46: 48.246376037597656, 0.984375\n",
      "Train loss and acc of batch 47: 47.960514068603516, 1.0\n",
      "Train loss and acc of batch 48: 47.960506439208984, 1.0\n",
      "Train loss and acc of batch 49: 47.96049880981445, 1.0\n",
      "Train loss and acc of batch 50: 48.556190490722656, 0.984375\n",
      "Train loss and acc of batch 51: 49.30940246582031, 0.96875\n",
      "Train loss and acc of batch 52: 49.216312408447266, 0.953125\n",
      "Train loss and acc of batch 53: 47.9604606628418, 1.0\n",
      "Train loss and acc of batch 54: 48.177215576171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.96044158935547, 1.0\n",
      "Train loss and acc of batch 56: 47.9604377746582, 1.0\n",
      "Train loss and acc of batch 57: 48.556129455566406, 0.984375\n",
      "Train loss and acc of batch 58: 47.96042251586914, 1.0\n",
      "Train loss and acc of batch 59: 47.96040725708008, 1.0\n",
      "Train loss and acc of batch 60: 47.96039962768555, 1.0\n",
      "Train loss and acc of batch 61: 47.960391998291016, 1.0\n",
      "Train loss and acc of batch 62: 48.177146911621094, 0.984375\n",
      "Train loss and acc of batch 63: 49.15177536010742, 0.96875\n",
      "Train loss and acc of batch 64: 48.1771240234375, 0.984375\n",
      "Train loss and acc of batch 65: 47.96035385131836, 1.0\n",
      "Train loss and acc of batch 66: 47.96034622192383, 1.0\n",
      "Train loss and acc of batch 67: 48.772804260253906, 0.96875\n",
      "Train loss and acc of batch 68: 48.5560302734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.177085876464844, 0.984375\n",
      "Train loss and acc of batch 70: 47.96031188964844, 1.0\n",
      "Training accuracy and loss of epoch #155: 0.9890, 48.2916\n",
      "Saved model by train loss 48.29163849521691\n",
      "Train loss and acc of batch 0: 47.960304260253906, 1.0\n",
      "Train loss and acc of batch 1: 47.960296630859375, 1.0\n",
      "Train loss and acc of batch 2: 48.246131896972656, 0.984375\n",
      "Train loss and acc of batch 3: 48.177040100097656, 0.984375\n",
      "Train loss and acc of batch 4: 47.96026611328125, 1.0\n",
      "Train loss and acc of batch 5: 49.309181213378906, 0.96875\n",
      "Train loss and acc of batch 6: 48.46286392211914, 0.96875\n",
      "Train loss and acc of batch 7: 47.960235595703125, 1.0\n",
      "Train loss and acc of batch 8: 48.555931091308594, 0.984375\n",
      "Train loss and acc of batch 9: 48.24607849121094, 0.984375\n",
      "Train loss and acc of batch 10: 47.96021270751953, 1.0\n",
      "Train loss and acc of batch 11: 47.960205078125, 1.0\n",
      "Train loss and acc of batch 12: 48.713417053222656, 0.984375\n",
      "Train loss and acc of batch 13: 48.17694854736328, 0.984375\n",
      "Train loss and acc of batch 14: 48.17694091796875, 0.984375\n",
      "Train loss and acc of batch 15: 48.555870056152344, 0.984375\n",
      "Train loss and acc of batch 16: 48.55586242675781, 0.984375\n",
      "Train loss and acc of batch 17: 48.71337127685547, 0.984375\n",
      "Train loss and acc of batch 18: 48.841697692871094, 0.96875\n",
      "Train loss and acc of batch 19: 47.96013259887695, 1.0\n",
      "Train loss and acc of batch 20: 47.96012878417969, 1.0\n",
      "Train loss and acc of batch 21: 48.555809020996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.555809020996094, 0.984375\n",
      "Train loss and acc of batch 23: 48.176856994628906, 0.984375\n",
      "Train loss and acc of batch 24: 48.55579376220703, 0.984375\n",
      "Train loss and acc of batch 25: 47.960079193115234, 1.0\n",
      "Train loss and acc of batch 26: 47.9600715637207, 1.0\n",
      "Train loss and acc of batch 27: 47.96005630493164, 1.0\n",
      "Train loss and acc of batch 28: 47.96005630493164, 1.0\n",
      "Train loss and acc of batch 29: 48.555747985839844, 0.984375\n",
      "Train loss and acc of batch 30: 47.96003341674805, 1.0\n",
      "Train loss and acc of batch 31: 48.176788330078125, 0.984375\n",
      "Train loss and acc of batch 32: 47.960018157958984, 1.0\n",
      "Train loss and acc of batch 33: 47.96001052856445, 1.0\n",
      "Train loss and acc of batch 34: 48.555694580078125, 0.984375\n",
      "Train loss and acc of batch 35: 48.393516540527344, 0.96875\n",
      "Train loss and acc of batch 36: 47.95998001098633, 1.0\n",
      "Train loss and acc of batch 37: 48.71319580078125, 0.984375\n",
      "Train loss and acc of batch 38: 49.30889129638672, 0.96875\n",
      "Train loss and acc of batch 39: 48.176719665527344, 0.984375\n",
      "Train loss and acc of batch 40: 47.95994186401367, 1.0\n",
      "Train loss and acc of batch 41: 49.30886459350586, 0.96875\n",
      "Train loss and acc of batch 42: 47.95992660522461, 1.0\n",
      "Train loss and acc of batch 43: 48.55561828613281, 0.984375\n",
      "Train loss and acc of batch 44: 47.95990753173828, 1.0\n",
      "Train loss and acc of batch 45: 48.55560302734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.24574279785156, 0.984375\n",
      "Train loss and acc of batch 47: 47.95988082885742, 1.0\n",
      "Train loss and acc of batch 48: 47.95987319946289, 1.0\n",
      "Train loss and acc of batch 49: 47.959861755371094, 1.0\n",
      "Train loss and acc of batch 50: 48.55555725097656, 0.984375\n",
      "Train loss and acc of batch 51: 49.30876922607422, 0.96875\n",
      "Train loss and acc of batch 52: 49.21567916870117, 0.953125\n",
      "Train loss and acc of batch 53: 47.95983123779297, 1.0\n",
      "Train loss and acc of batch 54: 48.17658233642578, 0.984375\n",
      "Train loss and acc of batch 55: 47.95981216430664, 1.0\n",
      "Train loss and acc of batch 56: 47.95980453491211, 1.0\n",
      "Train loss and acc of batch 57: 48.55549621582031, 0.984375\n",
      "Train loss and acc of batch 58: 47.959781646728516, 1.0\n",
      "Train loss and acc of batch 59: 47.95977783203125, 1.0\n",
      "Train loss and acc of batch 60: 47.95977020263672, 1.0\n",
      "Train loss and acc of batch 61: 47.95975875854492, 1.0\n",
      "Train loss and acc of batch 62: 48.176513671875, 0.984375\n",
      "Train loss and acc of batch 63: 49.15113830566406, 0.96875\n",
      "Train loss and acc of batch 64: 48.176490783691406, 0.984375\n",
      "Train loss and acc of batch 65: 47.959720611572266, 1.0\n",
      "Train loss and acc of batch 66: 47.959712982177734, 1.0\n",
      "Train loss and acc of batch 67: 48.77217102050781, 0.96875\n",
      "Train loss and acc of batch 68: 48.555397033691406, 0.984375\n",
      "Train loss and acc of batch 69: 48.17645263671875, 0.984375\n",
      "Train loss and acc of batch 70: 47.959678649902344, 1.0\n",
      "Training accuracy and loss of epoch #156: 0.9890, 48.2910\n",
      "Saved model by train loss 48.29100509428642\n",
      "Train loss and acc of batch 0: 47.95967102050781, 1.0\n",
      "Train loss and acc of batch 1: 47.959659576416016, 1.0\n",
      "Train loss and acc of batch 2: 48.245506286621094, 0.984375\n",
      "Train loss and acc of batch 3: 48.17640686035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.95963668823242, 1.0\n",
      "Train loss and acc of batch 5: 49.30854797363281, 0.96875\n",
      "Train loss and acc of batch 6: 48.46222686767578, 0.96875\n",
      "Train loss and acc of batch 7: 47.9596061706543, 1.0\n",
      "Train loss and acc of batch 8: 48.5552978515625, 0.984375\n",
      "Train loss and acc of batch 9: 48.245445251464844, 0.984375\n",
      "Train loss and acc of batch 10: 47.95957565307617, 1.0\n",
      "Train loss and acc of batch 11: 47.959571838378906, 1.0\n",
      "Train loss and acc of batch 12: 48.71278381347656, 0.984375\n",
      "Train loss and acc of batch 13: 48.17632293701172, 0.984375\n",
      "Train loss and acc of batch 14: 48.176307678222656, 0.984375\n",
      "Train loss and acc of batch 15: 48.55523681640625, 0.984375\n",
      "Train loss and acc of batch 16: 48.55522155761719, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 17: 48.712738037109375, 0.984375\n",
      "Train loss and acc of batch 18: 48.841064453125, 0.96875\n",
      "Train loss and acc of batch 19: 47.959503173828125, 1.0\n",
      "Train loss and acc of batch 20: 47.95948791503906, 1.0\n",
      "Train loss and acc of batch 21: 48.55518341064453, 0.984375\n",
      "Train loss and acc of batch 22: 48.55516815185547, 0.984375\n",
      "Train loss and acc of batch 23: 48.176231384277344, 0.984375\n",
      "Train loss and acc of batch 24: 48.555152893066406, 0.984375\n",
      "Train loss and acc of batch 25: 47.95944595336914, 1.0\n",
      "Train loss and acc of batch 26: 47.95943832397461, 1.0\n",
      "Train loss and acc of batch 27: 47.95943069458008, 1.0\n",
      "Train loss and acc of batch 28: 47.95941925048828, 1.0\n",
      "Train loss and acc of batch 29: 48.55510711669922, 0.984375\n",
      "Train loss and acc of batch 30: 47.95940017700195, 1.0\n",
      "Train loss and acc of batch 31: 48.17616271972656, 0.984375\n",
      "Train loss and acc of batch 32: 47.95938491821289, 1.0\n",
      "Train loss and acc of batch 33: 47.959373474121094, 1.0\n",
      "Train loss and acc of batch 34: 48.55506896972656, 0.984375\n",
      "Train loss and acc of batch 35: 48.39288330078125, 0.96875\n",
      "Train loss and acc of batch 36: 47.9593505859375, 1.0\n",
      "Train loss and acc of batch 37: 48.71255874633789, 0.984375\n",
      "Train loss and acc of batch 38: 49.308258056640625, 0.96875\n",
      "Train loss and acc of batch 39: 48.17608642578125, 0.984375\n",
      "Train loss and acc of batch 40: 47.95931625366211, 1.0\n",
      "Train loss and acc of batch 41: 49.308231353759766, 0.96875\n",
      "Train loss and acc of batch 42: 47.95929718017578, 1.0\n",
      "Train loss and acc of batch 43: 48.55499267578125, 0.984375\n",
      "Train loss and acc of batch 44: 47.95927429199219, 1.0\n",
      "Train loss and acc of batch 45: 48.554969787597656, 0.984375\n",
      "Train loss and acc of batch 46: 48.2451171875, 0.984375\n",
      "Train loss and acc of batch 47: 47.95924758911133, 1.0\n",
      "Train loss and acc of batch 48: 47.9592399597168, 1.0\n",
      "Train loss and acc of batch 49: 47.959232330322266, 1.0\n",
      "Train loss and acc of batch 50: 48.554931640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.308135986328125, 0.96875\n",
      "Train loss and acc of batch 52: 49.21504211425781, 0.953125\n",
      "Train loss and acc of batch 53: 47.95919418334961, 1.0\n",
      "Train loss and acc of batch 54: 48.17595672607422, 0.984375\n",
      "Train loss and acc of batch 55: 47.95917892456055, 1.0\n",
      "Train loss and acc of batch 56: 47.95916748046875, 1.0\n",
      "Train loss and acc of batch 57: 48.55486297607422, 0.984375\n",
      "Train loss and acc of batch 58: 47.95914840698242, 1.0\n",
      "Train loss and acc of batch 59: 47.95914077758789, 1.0\n",
      "Train loss and acc of batch 60: 47.95913314819336, 1.0\n",
      "Train loss and acc of batch 61: 47.95912551879883, 1.0\n",
      "Train loss and acc of batch 62: 48.175880432128906, 0.984375\n",
      "Train loss and acc of batch 63: 49.150508880615234, 0.96875\n",
      "Train loss and acc of batch 64: 48.175865173339844, 0.984375\n",
      "Train loss and acc of batch 65: 47.95908737182617, 1.0\n",
      "Train loss and acc of batch 66: 47.959075927734375, 1.0\n",
      "Train loss and acc of batch 67: 48.77153778076172, 0.96875\n",
      "Train loss and acc of batch 68: 48.55476379394531, 0.984375\n",
      "Train loss and acc of batch 69: 48.175819396972656, 0.984375\n",
      "Train loss and acc of batch 70: 47.95904541015625, 1.0\n",
      "Training accuracy and loss of epoch #157: 0.9890, 48.2904\n",
      "Saved model by train loss 48.290372445549764\n",
      "Train loss and acc of batch 0: 47.95903778076172, 1.0\n",
      "Train loss and acc of batch 1: 47.95902633666992, 1.0\n",
      "Train loss and acc of batch 2: 48.244873046875, 0.984375\n",
      "Train loss and acc of batch 3: 48.17577362060547, 0.984375\n",
      "Train loss and acc of batch 4: 47.95899963378906, 1.0\n",
      "Train loss and acc of batch 5: 49.30791473388672, 0.96875\n",
      "Train loss and acc of batch 6: 48.46160125732422, 0.96875\n",
      "Train loss and acc of batch 7: 47.95897674560547, 1.0\n",
      "Train loss and acc of batch 8: 48.554664611816406, 0.984375\n",
      "Train loss and acc of batch 9: 48.24480438232422, 0.984375\n",
      "Train loss and acc of batch 10: 47.958946228027344, 1.0\n",
      "Train loss and acc of batch 11: 47.95893859863281, 1.0\n",
      "Train loss and acc of batch 12: 48.712154388427734, 0.984375\n",
      "Train loss and acc of batch 13: 48.175682067871094, 0.984375\n",
      "Train loss and acc of batch 14: 48.17567443847656, 0.984375\n",
      "Train loss and acc of batch 15: 48.554603576660156, 0.984375\n",
      "Train loss and acc of batch 16: 48.554595947265625, 0.984375\n",
      "Train loss and acc of batch 17: 48.71210479736328, 0.984375\n",
      "Train loss and acc of batch 18: 48.84042739868164, 0.96875\n",
      "Train loss and acc of batch 19: 47.958866119384766, 1.0\n",
      "Train loss and acc of batch 20: 47.95885467529297, 1.0\n",
      "Train loss and acc of batch 21: 48.55455017089844, 0.984375\n",
      "Train loss and acc of batch 22: 48.554542541503906, 0.984375\n",
      "Train loss and acc of batch 23: 48.17559814453125, 0.984375\n",
      "Train loss and acc of batch 24: 48.554527282714844, 0.984375\n",
      "Train loss and acc of batch 25: 47.95881271362305, 1.0\n",
      "Train loss and acc of batch 26: 47.958805084228516, 1.0\n",
      "Train loss and acc of batch 27: 47.958797454833984, 1.0\n",
      "Train loss and acc of batch 28: 47.95878982543945, 1.0\n",
      "Train loss and acc of batch 29: 48.554481506347656, 0.984375\n",
      "Train loss and acc of batch 30: 47.958770751953125, 1.0\n",
      "Train loss and acc of batch 31: 48.17552185058594, 0.984375\n",
      "Train loss and acc of batch 32: 47.95874786376953, 1.0\n",
      "Train loss and acc of batch 33: 47.958740234375, 1.0\n",
      "Train loss and acc of batch 34: 48.55442810058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.39225769042969, 0.96875\n",
      "Train loss and acc of batch 36: 47.95871353149414, 1.0\n",
      "Train loss and acc of batch 37: 48.71192932128906, 0.984375\n",
      "Train loss and acc of batch 38: 49.30762481689453, 0.96875\n",
      "Train loss and acc of batch 39: 48.175445556640625, 0.984375\n",
      "Train loss and acc of batch 40: 47.95867919921875, 1.0\n",
      "Train loss and acc of batch 41: 49.307594299316406, 0.96875\n",
      "Train loss and acc of batch 42: 47.95866012573242, 1.0\n",
      "Train loss and acc of batch 43: 48.554359436035156, 0.984375\n",
      "Train loss and acc of batch 44: 47.958648681640625, 1.0\n",
      "Train loss and acc of batch 45: 48.55433654785156, 0.984375\n",
      "Train loss and acc of batch 46: 48.244476318359375, 0.984375\n",
      "Train loss and acc of batch 47: 47.958614349365234, 1.0\n",
      "Train loss and acc of batch 48: 47.9586067199707, 1.0\n",
      "Train loss and acc of batch 49: 47.95860290527344, 1.0\n",
      "Train loss and acc of batch 50: 48.554290771484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.30750274658203, 0.96875\n",
      "Train loss and acc of batch 52: 49.214412689208984, 0.953125\n",
      "Train loss and acc of batch 53: 47.958560943603516, 1.0\n",
      "Train loss and acc of batch 54: 48.175315856933594, 0.984375\n",
      "Train loss and acc of batch 55: 47.95854568481445, 1.0\n",
      "Train loss and acc of batch 56: 47.958534240722656, 1.0\n",
      "Train loss and acc of batch 57: 48.554229736328125, 0.984375\n",
      "Train loss and acc of batch 58: 47.95852279663086, 1.0\n",
      "Train loss and acc of batch 59: 47.95851135253906, 1.0\n",
      "Train loss and acc of batch 60: 47.958499908447266, 1.0\n",
      "Train loss and acc of batch 61: 47.958492279052734, 1.0\n",
      "Train loss and acc of batch 62: 48.17524719238281, 0.984375\n",
      "Train loss and acc of batch 63: 49.149879455566406, 0.96875\n",
      "Train loss and acc of batch 64: 48.17523193359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.95845413208008, 1.0\n",
      "Train loss and acc of batch 66: 47.95845031738281, 1.0\n",
      "Train loss and acc of batch 67: 48.77090072631836, 0.96875\n",
      "Train loss and acc of batch 68: 48.55413055419922, 0.984375\n",
      "Train loss and acc of batch 69: 48.17518615722656, 0.984375\n",
      "Train loss and acc of batch 70: 47.95840835571289, 1.0\n",
      "Training accuracy and loss of epoch #158: 0.9890, 48.2897\n",
      "Saved model by train loss 48.28973931325993\n",
      "Train loss and acc of batch 0: 47.95840072631836, 1.0\n",
      "Train loss and acc of batch 1: 47.958396911621094, 1.0\n",
      "Train loss and acc of batch 2: 48.244239807128906, 0.984375\n",
      "Train loss and acc of batch 3: 48.175140380859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.9583625793457, 1.0\n",
      "Train loss and acc of batch 5: 49.307281494140625, 0.96875\n",
      "Train loss and acc of batch 6: 48.460968017578125, 0.96875\n",
      "Train loss and acc of batch 7: 47.95833969116211, 1.0\n",
      "Train loss and acc of batch 8: 48.55403137207031, 0.984375\n",
      "Train loss and acc of batch 9: 48.244178771972656, 0.984375\n",
      "Train loss and acc of batch 10: 47.95831298828125, 1.0\n",
      "Train loss and acc of batch 11: 47.95830535888672, 1.0\n",
      "Train loss and acc of batch 12: 48.711517333984375, 0.984375\n",
      "Train loss and acc of batch 13: 48.175048828125, 0.984375\n",
      "Train loss and acc of batch 14: 48.17504119873047, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 15: 48.55397033691406, 0.984375\n",
      "Train loss and acc of batch 16: 48.55396270751953, 0.984375\n",
      "Train loss and acc of batch 17: 48.71147537231445, 0.984375\n",
      "Train loss and acc of batch 18: 48.83979797363281, 0.96875\n",
      "Train loss and acc of batch 19: 47.95823287963867, 1.0\n",
      "Train loss and acc of batch 20: 47.95822525024414, 1.0\n",
      "Train loss and acc of batch 21: 48.553916931152344, 0.984375\n",
      "Train loss and acc of batch 22: 48.55390930175781, 0.984375\n",
      "Train loss and acc of batch 23: 48.174964904785156, 0.984375\n",
      "Train loss and acc of batch 24: 48.55389404296875, 0.984375\n",
      "Train loss and acc of batch 25: 47.95817947387695, 1.0\n",
      "Train loss and acc of batch 26: 47.95817184448242, 1.0\n",
      "Train loss and acc of batch 27: 47.95815658569336, 1.0\n",
      "Train loss and acc of batch 28: 47.95815658569336, 1.0\n",
      "Train loss and acc of batch 29: 48.55384826660156, 0.984375\n",
      "Train loss and acc of batch 30: 47.95813751220703, 1.0\n",
      "Train loss and acc of batch 31: 48.174888610839844, 0.984375\n",
      "Train loss and acc of batch 32: 47.9581184387207, 1.0\n",
      "Train loss and acc of batch 33: 47.95810317993164, 1.0\n",
      "Train loss and acc of batch 34: 48.553802490234375, 0.984375\n",
      "Train loss and acc of batch 35: 48.39161682128906, 0.96875\n",
      "Train loss and acc of batch 36: 47.95808029174805, 1.0\n",
      "Train loss and acc of batch 37: 48.711299896240234, 0.984375\n",
      "Train loss and acc of batch 38: 49.30699157714844, 0.96875\n",
      "Train loss and acc of batch 39: 48.17481994628906, 0.984375\n",
      "Train loss and acc of batch 40: 47.958045959472656, 1.0\n",
      "Train loss and acc of batch 41: 49.30696105957031, 0.96875\n",
      "Train loss and acc of batch 42: 47.958030700683594, 1.0\n",
      "Train loss and acc of batch 43: 48.55371856689453, 0.984375\n",
      "Train loss and acc of batch 44: 47.958011627197266, 1.0\n",
      "Train loss and acc of batch 45: 48.55370330810547, 0.984375\n",
      "Train loss and acc of batch 46: 48.24384307861328, 0.984375\n",
      "Train loss and acc of batch 47: 47.957984924316406, 1.0\n",
      "Train loss and acc of batch 48: 47.957977294921875, 1.0\n",
      "Train loss and acc of batch 49: 47.95796585083008, 1.0\n",
      "Train loss and acc of batch 50: 48.55365753173828, 0.984375\n",
      "Train loss and acc of batch 51: 49.30687713623047, 0.96875\n",
      "Train loss and acc of batch 52: 49.213775634765625, 0.953125\n",
      "Train loss and acc of batch 53: 47.957923889160156, 1.0\n",
      "Train loss and acc of batch 54: 48.1746826171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.95791244506836, 1.0\n",
      "Train loss and acc of batch 56: 47.95790100097656, 1.0\n",
      "Train loss and acc of batch 57: 48.55359649658203, 0.984375\n",
      "Train loss and acc of batch 58: 47.9578857421875, 1.0\n",
      "Train loss and acc of batch 59: 47.95787811279297, 1.0\n",
      "Train loss and acc of batch 60: 47.95786666870117, 1.0\n",
      "Train loss and acc of batch 61: 47.957855224609375, 1.0\n",
      "Train loss and acc of batch 62: 48.17460632324219, 0.984375\n",
      "Train loss and acc of batch 63: 49.14924240112305, 0.96875\n",
      "Train loss and acc of batch 64: 48.174591064453125, 0.984375\n",
      "Train loss and acc of batch 65: 47.95782470703125, 1.0\n",
      "Train loss and acc of batch 66: 47.95781707763672, 1.0\n",
      "Train loss and acc of batch 67: 48.7702751159668, 0.96875\n",
      "Train loss and acc of batch 68: 48.553497314453125, 0.984375\n",
      "Train loss and acc of batch 69: 48.17455291748047, 0.984375\n",
      "Train loss and acc of batch 70: 47.9577751159668, 1.0\n",
      "Training accuracy and loss of epoch #159: 0.9890, 48.2891\n",
      "Saved model by train loss 48.289105966057576\n",
      "Train loss and acc of batch 0: 47.957767486572266, 1.0\n",
      "Train loss and acc of batch 1: 47.95775604248047, 1.0\n",
      "Train loss and acc of batch 2: 48.24360656738281, 0.984375\n",
      "Train loss and acc of batch 3: 48.17450714111328, 0.984375\n",
      "Train loss and acc of batch 4: 47.95773696899414, 1.0\n",
      "Train loss and acc of batch 5: 49.30664825439453, 0.96875\n",
      "Train loss and acc of batch 6: 48.460330963134766, 0.96875\n",
      "Train loss and acc of batch 7: 47.957706451416016, 1.0\n",
      "Train loss and acc of batch 8: 48.55339813232422, 0.984375\n",
      "Train loss and acc of batch 9: 48.24353790283203, 0.984375\n",
      "Train loss and acc of batch 10: 47.95768356323242, 1.0\n",
      "Train loss and acc of batch 11: 47.95766830444336, 1.0\n",
      "Train loss and acc of batch 12: 48.71088409423828, 0.984375\n",
      "Train loss and acc of batch 13: 48.174415588378906, 0.984375\n",
      "Train loss and acc of batch 14: 48.174407958984375, 0.984375\n",
      "Train loss and acc of batch 15: 48.55333709716797, 0.984375\n",
      "Train loss and acc of batch 16: 48.553321838378906, 0.984375\n",
      "Train loss and acc of batch 17: 48.71084213256836, 0.984375\n",
      "Train loss and acc of batch 18: 48.83916091918945, 0.96875\n",
      "Train loss and acc of batch 19: 47.95759963989258, 1.0\n",
      "Train loss and acc of batch 20: 47.95758819580078, 1.0\n",
      "Train loss and acc of batch 21: 48.55328369140625, 0.984375\n",
      "Train loss and acc of batch 22: 48.55327606201172, 0.984375\n",
      "Train loss and acc of batch 23: 48.17433166503906, 0.984375\n",
      "Train loss and acc of batch 24: 48.553253173828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.957550048828125, 1.0\n",
      "Train loss and acc of batch 26: 47.95753479003906, 1.0\n",
      "Train loss and acc of batch 27: 47.95752716064453, 1.0\n",
      "Train loss and acc of batch 28: 47.957515716552734, 1.0\n",
      "Train loss and acc of batch 29: 48.55320739746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.95750045776367, 1.0\n",
      "Train loss and acc of batch 31: 48.17425537109375, 0.984375\n",
      "Train loss and acc of batch 32: 47.957481384277344, 1.0\n",
      "Train loss and acc of batch 33: 47.95747375488281, 1.0\n",
      "Train loss and acc of batch 34: 48.55316925048828, 0.984375\n",
      "Train loss and acc of batch 35: 48.39098358154297, 0.96875\n",
      "Train loss and acc of batch 36: 47.95744705200195, 1.0\n",
      "Train loss and acc of batch 37: 48.71066665649414, 0.984375\n",
      "Train loss and acc of batch 38: 49.30635070800781, 0.96875\n",
      "Train loss and acc of batch 39: 48.17417907714844, 0.984375\n",
      "Train loss and acc of batch 40: 47.95741271972656, 1.0\n",
      "Train loss and acc of batch 41: 49.30632781982422, 0.96875\n",
      "Train loss and acc of batch 42: 47.957393646240234, 1.0\n",
      "Train loss and acc of batch 43: 48.55308532714844, 0.984375\n",
      "Train loss and acc of batch 44: 47.95737838745117, 1.0\n",
      "Train loss and acc of batch 45: 48.553070068359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.24320983886719, 0.984375\n",
      "Train loss and acc of batch 47: 47.95734786987305, 1.0\n",
      "Train loss and acc of batch 48: 47.95734405517578, 1.0\n",
      "Train loss and acc of batch 49: 47.95732879638672, 1.0\n",
      "Train loss and acc of batch 50: 48.55302429199219, 0.984375\n",
      "Train loss and acc of batch 51: 49.306236267089844, 0.96875\n",
      "Train loss and acc of batch 52: 49.21314239501953, 0.953125\n",
      "Train loss and acc of batch 53: 47.95729446411133, 1.0\n",
      "Train loss and acc of batch 54: 48.174049377441406, 0.984375\n",
      "Train loss and acc of batch 55: 47.957279205322266, 1.0\n",
      "Train loss and acc of batch 56: 47.95726776123047, 1.0\n",
      "Train loss and acc of batch 57: 48.552955627441406, 0.984375\n",
      "Train loss and acc of batch 58: 47.95724868774414, 1.0\n",
      "Train loss and acc of batch 59: 47.95724105834961, 1.0\n",
      "Train loss and acc of batch 60: 47.95723342895508, 1.0\n",
      "Train loss and acc of batch 61: 47.95722198486328, 1.0\n",
      "Train loss and acc of batch 62: 48.173980712890625, 0.984375\n",
      "Train loss and acc of batch 63: 49.14860916137695, 0.96875\n",
      "Train loss and acc of batch 64: 48.17396545410156, 0.984375\n",
      "Train loss and acc of batch 65: 47.957191467285156, 1.0\n",
      "Train loss and acc of batch 66: 47.95718002319336, 1.0\n",
      "Train loss and acc of batch 67: 48.76963424682617, 0.96875\n",
      "Train loss and acc of batch 68: 48.55286407470703, 0.984375\n",
      "Train loss and acc of batch 69: 48.173912048339844, 0.984375\n",
      "Train loss and acc of batch 70: 47.95713806152344, 1.0\n",
      "Training accuracy and loss of epoch #160: 0.9890, 48.2885\n",
      "Saved model by train loss 48.28847127565196\n",
      "Train loss and acc of batch 0: 47.95712661743164, 1.0\n",
      "Train loss and acc of batch 1: 47.95711898803711, 1.0\n",
      "Train loss and acc of batch 2: 48.24296569824219, 0.984375\n",
      "Train loss and acc of batch 3: 48.173866271972656, 0.984375\n",
      "Train loss and acc of batch 4: 47.957096099853516, 1.0\n",
      "Train loss and acc of batch 5: 49.30601501464844, 0.96875\n",
      "Train loss and acc of batch 6: 48.459693908691406, 0.96875\n",
      "Train loss and acc of batch 7: 47.957069396972656, 1.0\n",
      "Train loss and acc of batch 8: 48.552764892578125, 0.984375\n",
      "Train loss and acc of batch 9: 48.24290466308594, 0.984375\n",
      "Train loss and acc of batch 10: 47.9570426940918, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 11: 47.957035064697266, 1.0\n",
      "Train loss and acc of batch 12: 48.71025085449219, 0.984375\n",
      "Train loss and acc of batch 13: 48.17378234863281, 0.984375\n",
      "Train loss and acc of batch 14: 48.17376708984375, 0.984375\n",
      "Train loss and acc of batch 15: 48.552696228027344, 0.984375\n",
      "Train loss and acc of batch 16: 48.55268859863281, 0.984375\n",
      "Train loss and acc of batch 17: 48.710205078125, 0.984375\n",
      "Train loss and acc of batch 18: 48.838523864746094, 0.96875\n",
      "Train loss and acc of batch 19: 47.95696258544922, 1.0\n",
      "Train loss and acc of batch 20: 47.95695114135742, 1.0\n",
      "Train loss and acc of batch 21: 48.552642822265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.552635192871094, 0.984375\n",
      "Train loss and acc of batch 23: 48.17369079589844, 0.984375\n",
      "Train loss and acc of batch 24: 48.55261993408203, 0.984375\n",
      "Train loss and acc of batch 25: 47.9569091796875, 1.0\n",
      "Train loss and acc of batch 26: 47.95690155029297, 1.0\n",
      "Train loss and acc of batch 27: 47.95689010620117, 1.0\n",
      "Train loss and acc of batch 28: 47.956878662109375, 1.0\n",
      "Train loss and acc of batch 29: 48.552574157714844, 0.984375\n",
      "Train loss and acc of batch 30: 47.95685958862305, 1.0\n",
      "Train loss and acc of batch 31: 48.173622131347656, 0.984375\n",
      "Train loss and acc of batch 32: 47.956844329833984, 1.0\n",
      "Train loss and acc of batch 33: 47.95684051513672, 1.0\n",
      "Train loss and acc of batch 34: 48.552528381347656, 0.984375\n",
      "Train loss and acc of batch 35: 48.390350341796875, 0.96875\n",
      "Train loss and acc of batch 36: 47.956809997558594, 1.0\n",
      "Train loss and acc of batch 37: 48.710025787353516, 0.984375\n",
      "Train loss and acc of batch 38: 49.30571746826172, 0.96875\n",
      "Train loss and acc of batch 39: 48.173553466796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.9567756652832, 1.0\n",
      "Train loss and acc of batch 41: 49.305694580078125, 0.96875\n",
      "Train loss and acc of batch 42: 47.956756591796875, 1.0\n",
      "Train loss and acc of batch 43: 48.55244445800781, 0.984375\n",
      "Train loss and acc of batch 44: 47.95673751831055, 1.0\n",
      "Train loss and acc of batch 45: 48.55242919921875, 0.984375\n",
      "Train loss and acc of batch 46: 48.242576599121094, 0.984375\n",
      "Train loss and acc of batch 47: 47.95671081542969, 1.0\n",
      "Train loss and acc of batch 48: 47.956703186035156, 1.0\n",
      "Train loss and acc of batch 49: 47.956695556640625, 1.0\n",
      "Train loss and acc of batch 50: 48.552391052246094, 0.984375\n",
      "Train loss and acc of batch 51: 49.30560302734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.21250534057617, 0.953125\n",
      "Train loss and acc of batch 53: 47.956661224365234, 1.0\n",
      "Train loss and acc of batch 54: 48.17341613769531, 0.984375\n",
      "Train loss and acc of batch 55: 47.956642150878906, 1.0\n",
      "Train loss and acc of batch 56: 47.956634521484375, 1.0\n",
      "Train loss and acc of batch 57: 48.55232238769531, 0.984375\n",
      "Train loss and acc of batch 58: 47.95661163330078, 1.0\n",
      "Train loss and acc of batch 59: 47.95660400390625, 1.0\n",
      "Train loss and acc of batch 60: 47.95659637451172, 1.0\n",
      "Train loss and acc of batch 61: 47.95658874511719, 1.0\n",
      "Train loss and acc of batch 62: 48.17334747314453, 0.984375\n",
      "Train loss and acc of batch 63: 49.147972106933594, 0.96875\n",
      "Train loss and acc of batch 64: 48.17332458496094, 0.984375\n",
      "Train loss and acc of batch 65: 47.95655059814453, 1.0\n",
      "Train loss and acc of batch 66: 47.95654296875, 1.0\n",
      "Train loss and acc of batch 67: 48.76899719238281, 0.96875\n",
      "Train loss and acc of batch 68: 48.552223205566406, 0.984375\n",
      "Train loss and acc of batch 69: 48.17327880859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.95650863647461, 1.0\n",
      "Training accuracy and loss of epoch #161: 0.9890, 48.2878\n",
      "Saved model by train loss 48.28783475848991\n",
      "Train loss and acc of batch 0: 47.95649719238281, 1.0\n",
      "Train loss and acc of batch 1: 47.95648956298828, 1.0\n",
      "Train loss and acc of batch 2: 48.242332458496094, 0.984375\n",
      "Train loss and acc of batch 3: 48.17323303222656, 0.984375\n",
      "Train loss and acc of batch 4: 47.95646286010742, 1.0\n",
      "Train loss and acc of batch 5: 49.305381774902344, 0.96875\n",
      "Train loss and acc of batch 6: 48.45906448364258, 0.96875\n",
      "Train loss and acc of batch 7: 47.95643997192383, 1.0\n",
      "Train loss and acc of batch 8: 48.55213165283203, 0.984375\n",
      "Train loss and acc of batch 9: 48.242271423339844, 0.984375\n",
      "Train loss and acc of batch 10: 47.9564094543457, 1.0\n",
      "Train loss and acc of batch 11: 47.956398010253906, 1.0\n",
      "Train loss and acc of batch 12: 48.709617614746094, 0.984375\n",
      "Train loss and acc of batch 13: 48.17314910888672, 0.984375\n",
      "Train loss and acc of batch 14: 48.173133850097656, 0.984375\n",
      "Train loss and acc of batch 15: 48.55206298828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.55205535888672, 0.984375\n",
      "Train loss and acc of batch 17: 48.70956802368164, 0.984375\n",
      "Train loss and acc of batch 18: 48.837890625, 0.96875\n",
      "Train loss and acc of batch 19: 47.956329345703125, 1.0\n",
      "Train loss and acc of batch 20: 47.95632553100586, 1.0\n",
      "Train loss and acc of batch 21: 48.55201721191406, 0.984375\n",
      "Train loss and acc of batch 22: 48.552001953125, 0.984375\n",
      "Train loss and acc of batch 23: 48.173057556152344, 0.984375\n",
      "Train loss and acc of batch 24: 48.55198669433594, 0.984375\n",
      "Train loss and acc of batch 25: 47.95627212524414, 1.0\n",
      "Train loss and acc of batch 26: 47.956260681152344, 1.0\n",
      "Train loss and acc of batch 27: 47.95625686645508, 1.0\n",
      "Train loss and acc of batch 28: 47.95624542236328, 1.0\n",
      "Train loss and acc of batch 29: 48.55194091796875, 0.984375\n",
      "Train loss and acc of batch 30: 47.95622634887695, 1.0\n",
      "Train loss and acc of batch 31: 48.17298889160156, 0.984375\n",
      "Train loss and acc of batch 32: 47.95621109008789, 1.0\n",
      "Train loss and acc of batch 33: 47.95620346069336, 1.0\n",
      "Train loss and acc of batch 34: 48.551902770996094, 0.984375\n",
      "Train loss and acc of batch 35: 48.38971710205078, 0.96875\n",
      "Train loss and acc of batch 36: 47.95616912841797, 1.0\n",
      "Train loss and acc of batch 37: 48.70939254760742, 0.984375\n",
      "Train loss and acc of batch 38: 49.305084228515625, 0.96875\n",
      "Train loss and acc of batch 39: 48.17291259765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.956138610839844, 1.0\n",
      "Train loss and acc of batch 41: 49.30506134033203, 0.96875\n",
      "Train loss and acc of batch 42: 47.95612335205078, 1.0\n",
      "Train loss and acc of batch 43: 48.55181121826172, 0.984375\n",
      "Train loss and acc of batch 44: 47.95610046386719, 1.0\n",
      "Train loss and acc of batch 45: 48.551795959472656, 0.984375\n",
      "Train loss and acc of batch 46: 48.24193572998047, 0.984375\n",
      "Train loss and acc of batch 47: 47.95608139038086, 1.0\n",
      "Train loss and acc of batch 48: 47.95606994628906, 1.0\n",
      "Train loss and acc of batch 49: 47.95606231689453, 1.0\n",
      "Train loss and acc of batch 50: 48.55175018310547, 0.984375\n",
      "Train loss and acc of batch 51: 49.304962158203125, 0.96875\n",
      "Train loss and acc of batch 52: 49.21187210083008, 0.953125\n",
      "Train loss and acc of batch 53: 47.956024169921875, 1.0\n",
      "Train loss and acc of batch 54: 48.17277526855469, 0.984375\n",
      "Train loss and acc of batch 55: 47.95600891113281, 1.0\n",
      "Train loss and acc of batch 56: 47.955997467041016, 1.0\n",
      "Train loss and acc of batch 57: 48.55168914794922, 0.984375\n",
      "Train loss and acc of batch 58: 47.95597839355469, 1.0\n",
      "Train loss and acc of batch 59: 47.955970764160156, 1.0\n",
      "Train loss and acc of batch 60: 47.955963134765625, 1.0\n",
      "Train loss and acc of batch 61: 47.955955505371094, 1.0\n",
      "Train loss and acc of batch 62: 48.17271423339844, 0.984375\n",
      "Train loss and acc of batch 63: 49.147335052490234, 0.96875\n",
      "Train loss and acc of batch 64: 48.172691345214844, 0.984375\n",
      "Train loss and acc of batch 65: 47.955909729003906, 1.0\n",
      "Train loss and acc of batch 66: 47.955909729003906, 1.0\n",
      "Train loss and acc of batch 67: 48.76836395263672, 0.96875\n",
      "Train loss and acc of batch 68: 48.55158996582031, 0.984375\n",
      "Train loss and acc of batch 69: 48.172645568847656, 0.984375\n",
      "Train loss and acc of batch 70: 47.955875396728516, 1.0\n",
      "Training accuracy and loss of epoch #162: 0.9890, 48.2872\n",
      "Saved model by train loss 48.28720076654999\n",
      "Train loss and acc of batch 0: 47.95586395263672, 1.0\n",
      "Train loss and acc of batch 1: 47.95585250854492, 1.0\n",
      "Train loss and acc of batch 2: 48.24169921875, 0.984375\n",
      "Train loss and acc of batch 3: 48.17259979248047, 0.984375\n",
      "Train loss and acc of batch 4: 47.95582962036133, 1.0\n",
      "Train loss and acc of batch 5: 49.30474853515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.45842742919922, 0.96875\n",
      "Train loss and acc of batch 7: 47.955806732177734, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 8: 48.551490783691406, 0.984375\n",
      "Train loss and acc of batch 9: 48.24163818359375, 0.984375\n",
      "Train loss and acc of batch 10: 47.955772399902344, 1.0\n",
      "Train loss and acc of batch 11: 47.95576095581055, 1.0\n",
      "Train loss and acc of batch 12: 48.708980560302734, 0.984375\n",
      "Train loss and acc of batch 13: 48.172515869140625, 0.984375\n",
      "Train loss and acc of batch 14: 48.172508239746094, 0.984375\n",
      "Train loss and acc of batch 15: 48.551429748535156, 0.984375\n",
      "Train loss and acc of batch 16: 48.551422119140625, 0.984375\n",
      "Train loss and acc of batch 17: 48.70893478393555, 0.984375\n",
      "Train loss and acc of batch 18: 48.837257385253906, 0.96875\n",
      "Train loss and acc of batch 19: 47.9556999206543, 1.0\n",
      "Train loss and acc of batch 20: 47.955684661865234, 1.0\n",
      "Train loss and acc of batch 21: 48.55138397216797, 0.984375\n",
      "Train loss and acc of batch 22: 48.551368713378906, 0.984375\n",
      "Train loss and acc of batch 23: 48.17242431640625, 0.984375\n",
      "Train loss and acc of batch 24: 48.551353454589844, 0.984375\n",
      "Train loss and acc of batch 25: 47.95563888549805, 1.0\n",
      "Train loss and acc of batch 26: 47.95563507080078, 1.0\n",
      "Train loss and acc of batch 27: 47.955623626708984, 1.0\n",
      "Train loss and acc of batch 28: 47.95561599731445, 1.0\n",
      "Train loss and acc of batch 29: 48.551307678222656, 0.984375\n",
      "Train loss and acc of batch 30: 47.955596923828125, 1.0\n",
      "Train loss and acc of batch 31: 48.17234802246094, 0.984375\n",
      "Train loss and acc of batch 32: 47.95558166503906, 1.0\n",
      "Train loss and acc of batch 33: 47.955570220947266, 1.0\n",
      "Train loss and acc of batch 34: 48.55126190185547, 0.984375\n",
      "Train loss and acc of batch 35: 48.38908386230469, 0.96875\n",
      "Train loss and acc of batch 36: 47.955543518066406, 1.0\n",
      "Train loss and acc of batch 37: 48.708763122558594, 0.984375\n",
      "Train loss and acc of batch 38: 49.30445098876953, 0.96875\n",
      "Train loss and acc of batch 39: 48.172279357910156, 0.984375\n",
      "Train loss and acc of batch 40: 47.955509185791016, 1.0\n",
      "Train loss and acc of batch 41: 49.30442428588867, 0.96875\n",
      "Train loss and acc of batch 42: 47.95549392700195, 1.0\n",
      "Train loss and acc of batch 43: 48.551177978515625, 0.984375\n",
      "Train loss and acc of batch 44: 47.95547103881836, 1.0\n",
      "Train loss and acc of batch 45: 48.55116271972656, 0.984375\n",
      "Train loss and acc of batch 46: 48.241310119628906, 0.984375\n",
      "Train loss and acc of batch 47: 47.955448150634766, 1.0\n",
      "Train loss and acc of batch 48: 47.95543670654297, 1.0\n",
      "Train loss and acc of batch 49: 47.95542907714844, 1.0\n",
      "Train loss and acc of batch 50: 48.551124572753906, 0.984375\n",
      "Train loss and acc of batch 51: 49.30433654785156, 0.96875\n",
      "Train loss and acc of batch 52: 49.211238861083984, 0.953125\n",
      "Train loss and acc of batch 53: 47.95539093017578, 1.0\n",
      "Train loss and acc of batch 54: 48.172142028808594, 0.984375\n",
      "Train loss and acc of batch 55: 47.95537567138672, 1.0\n",
      "Train loss and acc of batch 56: 47.95536422729492, 1.0\n",
      "Train loss and acc of batch 57: 48.551055908203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.95534896850586, 1.0\n",
      "Train loss and acc of batch 59: 47.95533752441406, 1.0\n",
      "Train loss and acc of batch 60: 47.95532989501953, 1.0\n",
      "Train loss and acc of batch 61: 47.955322265625, 1.0\n",
      "Train loss and acc of batch 62: 48.17207336425781, 0.984375\n",
      "Train loss and acc of batch 63: 49.146705627441406, 0.96875\n",
      "Train loss and acc of batch 64: 48.17205810546875, 0.984375\n",
      "Train loss and acc of batch 65: 47.95528793334961, 1.0\n",
      "Train loss and acc of batch 66: 47.95527648925781, 1.0\n",
      "Train loss and acc of batch 67: 48.76772689819336, 0.96875\n",
      "Train loss and acc of batch 68: 48.55095672607422, 0.984375\n",
      "Train loss and acc of batch 69: 48.17201232910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.955238342285156, 1.0\n",
      "Training accuracy and loss of epoch #163: 0.9890, 48.2866\n",
      "Saved model by train loss 48.286567902900806\n",
      "Train loss and acc of batch 0: 47.955230712890625, 1.0\n",
      "Train loss and acc of batch 1: 47.95521926879883, 1.0\n",
      "Train loss and acc of batch 2: 48.241065979003906, 0.984375\n",
      "Train loss and acc of batch 3: 48.171966552734375, 0.984375\n",
      "Train loss and acc of batch 4: 47.9552001953125, 1.0\n",
      "Train loss and acc of batch 5: 49.304107666015625, 0.96875\n",
      "Train loss and acc of batch 6: 48.45779800415039, 0.96875\n",
      "Train loss and acc of batch 7: 47.955169677734375, 1.0\n",
      "Train loss and acc of batch 8: 48.550865173339844, 0.984375\n",
      "Train loss and acc of batch 9: 48.240997314453125, 0.984375\n",
      "Train loss and acc of batch 10: 47.95513916015625, 1.0\n",
      "Train loss and acc of batch 11: 47.95513153076172, 1.0\n",
      "Train loss and acc of batch 12: 48.70834732055664, 0.984375\n",
      "Train loss and acc of batch 13: 48.17188262939453, 0.984375\n",
      "Train loss and acc of batch 14: 48.17186737060547, 0.984375\n",
      "Train loss and acc of batch 15: 48.55079650878906, 0.984375\n",
      "Train loss and acc of batch 16: 48.55078887939453, 0.984375\n",
      "Train loss and acc of batch 17: 48.70830535888672, 0.984375\n",
      "Train loss and acc of batch 18: 48.83662414550781, 0.96875\n",
      "Train loss and acc of batch 19: 47.95506286621094, 1.0\n",
      "Train loss and acc of batch 20: 47.95505142211914, 1.0\n",
      "Train loss and acc of batch 21: 48.550743103027344, 0.984375\n",
      "Train loss and acc of batch 22: 48.550743103027344, 0.984375\n",
      "Train loss and acc of batch 23: 48.171791076660156, 0.984375\n",
      "Train loss and acc of batch 24: 48.55071258544922, 0.984375\n",
      "Train loss and acc of batch 25: 47.95500946044922, 1.0\n",
      "Train loss and acc of batch 26: 47.95499801635742, 1.0\n",
      "Train loss and acc of batch 27: 47.954994201660156, 1.0\n",
      "Train loss and acc of batch 28: 47.954978942871094, 1.0\n",
      "Train loss and acc of batch 29: 48.55067443847656, 0.984375\n",
      "Train loss and acc of batch 30: 47.95496368408203, 1.0\n",
      "Train loss and acc of batch 31: 48.171722412109375, 0.984375\n",
      "Train loss and acc of batch 32: 47.9549446105957, 1.0\n",
      "Train loss and acc of batch 33: 47.95493698120117, 1.0\n",
      "Train loss and acc of batch 34: 48.550628662109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.388450622558594, 0.96875\n",
      "Train loss and acc of batch 36: 47.95491409301758, 1.0\n",
      "Train loss and acc of batch 37: 48.70812225341797, 0.984375\n",
      "Train loss and acc of batch 38: 49.30381774902344, 0.96875\n",
      "Train loss and acc of batch 39: 48.17164611816406, 0.984375\n",
      "Train loss and acc of batch 40: 47.954872131347656, 1.0\n",
      "Train loss and acc of batch 41: 49.30378723144531, 0.96875\n",
      "Train loss and acc of batch 42: 47.954856872558594, 1.0\n",
      "Train loss and acc of batch 43: 48.55055236816406, 0.984375\n",
      "Train loss and acc of batch 44: 47.954837799072266, 1.0\n",
      "Train loss and acc of batch 45: 48.550537109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.24067687988281, 0.984375\n",
      "Train loss and acc of batch 47: 47.954811096191406, 1.0\n",
      "Train loss and acc of batch 48: 47.954803466796875, 1.0\n",
      "Train loss and acc of batch 49: 47.95479202270508, 1.0\n",
      "Train loss and acc of batch 50: 48.55049133300781, 0.984375\n",
      "Train loss and acc of batch 51: 49.30370330810547, 0.96875\n",
      "Train loss and acc of batch 52: 49.21060562133789, 0.953125\n",
      "Train loss and acc of batch 53: 47.95475387573242, 1.0\n",
      "Train loss and acc of batch 54: 48.17151641845703, 0.984375\n",
      "Train loss and acc of batch 55: 47.95473861694336, 1.0\n",
      "Train loss and acc of batch 56: 47.95473098754883, 1.0\n",
      "Train loss and acc of batch 57: 48.55042266845703, 0.984375\n",
      "Train loss and acc of batch 58: 47.954715728759766, 1.0\n",
      "Train loss and acc of batch 59: 47.954708099365234, 1.0\n",
      "Train loss and acc of batch 60: 47.954689025878906, 1.0\n",
      "Train loss and acc of batch 61: 47.95468521118164, 1.0\n",
      "Train loss and acc of batch 62: 48.17144775390625, 0.984375\n",
      "Train loss and acc of batch 63: 49.14607238769531, 0.96875\n",
      "Train loss and acc of batch 64: 48.17143249511719, 0.984375\n",
      "Train loss and acc of batch 65: 47.95465087890625, 1.0\n",
      "Train loss and acc of batch 66: 47.95464324951172, 1.0\n",
      "Train loss and acc of batch 67: 48.76709747314453, 0.96875\n",
      "Train loss and acc of batch 68: 48.550323486328125, 0.984375\n",
      "Train loss and acc of batch 69: 48.17137908935547, 0.984375\n",
      "Train loss and acc of batch 70: 47.95460510253906, 1.0\n",
      "Training accuracy and loss of epoch #164: 0.9890, 48.2859\n",
      "Saved model by train loss 48.28593450197032\n",
      "Train loss and acc of batch 0: 47.95459747314453, 1.0\n",
      "Train loss and acc of batch 1: 47.95458984375, 1.0\n",
      "Train loss and acc of batch 2: 48.24043273925781, 0.984375\n",
      "Train loss and acc of batch 3: 48.17133331298828, 0.984375\n",
      "Train loss and acc of batch 4: 47.95456314086914, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 5: 49.30347442626953, 0.96875\n",
      "Train loss and acc of batch 6: 48.45716094970703, 0.96875\n",
      "Train loss and acc of batch 7: 47.95453643798828, 1.0\n",
      "Train loss and acc of batch 8: 48.55023193359375, 0.984375\n",
      "Train loss and acc of batch 9: 48.24036407470703, 0.984375\n",
      "Train loss and acc of batch 10: 47.95450973510742, 1.0\n",
      "Train loss and acc of batch 11: 47.954498291015625, 1.0\n",
      "Train loss and acc of batch 12: 48.70771026611328, 0.984375\n",
      "Train loss and acc of batch 13: 48.171241760253906, 0.984375\n",
      "Train loss and acc of batch 14: 48.171234130859375, 0.984375\n",
      "Train loss and acc of batch 15: 48.55016326904297, 0.984375\n",
      "Train loss and acc of batch 16: 48.55015563964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.707664489746094, 0.984375\n",
      "Train loss and acc of batch 18: 48.83599090576172, 0.96875\n",
      "Train loss and acc of batch 19: 47.95442581176758, 1.0\n",
      "Train loss and acc of batch 20: 47.95442199707031, 1.0\n",
      "Train loss and acc of batch 21: 48.55010986328125, 0.984375\n",
      "Train loss and acc of batch 22: 48.55010223388672, 0.984375\n",
      "Train loss and acc of batch 23: 48.17115783691406, 0.984375\n",
      "Train loss and acc of batch 24: 48.550086975097656, 0.984375\n",
      "Train loss and acc of batch 25: 47.95437240600586, 1.0\n",
      "Train loss and acc of batch 26: 47.95436096191406, 1.0\n",
      "Train loss and acc of batch 27: 47.95435333251953, 1.0\n",
      "Train loss and acc of batch 28: 47.954341888427734, 1.0\n",
      "Train loss and acc of batch 29: 48.55004119873047, 0.984375\n",
      "Train loss and acc of batch 30: 47.95433044433594, 1.0\n",
      "Train loss and acc of batch 31: 48.17108917236328, 0.984375\n",
      "Train loss and acc of batch 32: 47.954315185546875, 1.0\n",
      "Train loss and acc of batch 33: 47.95429992675781, 1.0\n",
      "Train loss and acc of batch 34: 48.54999542236328, 0.984375\n",
      "Train loss and acc of batch 35: 48.387813568115234, 0.96875\n",
      "Train loss and acc of batch 36: 47.95427703857422, 1.0\n",
      "Train loss and acc of batch 37: 48.70749282836914, 0.984375\n",
      "Train loss and acc of batch 38: 49.303184509277344, 0.96875\n",
      "Train loss and acc of batch 39: 48.17101287841797, 0.984375\n",
      "Train loss and acc of batch 40: 47.9542350769043, 1.0\n",
      "Train loss and acc of batch 41: 49.303157806396484, 0.96875\n",
      "Train loss and acc of batch 42: 47.954219818115234, 1.0\n",
      "Train loss and acc of batch 43: 48.54991912841797, 0.984375\n",
      "Train loss and acc of batch 44: 47.95420455932617, 1.0\n",
      "Train loss and acc of batch 45: 48.549896240234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.24004364013672, 0.984375\n",
      "Train loss and acc of batch 47: 47.95417785644531, 1.0\n",
      "Train loss and acc of batch 48: 47.95417022705078, 1.0\n",
      "Train loss and acc of batch 49: 47.95416259765625, 1.0\n",
      "Train loss and acc of batch 50: 48.54985046386719, 0.984375\n",
      "Train loss and acc of batch 51: 49.303070068359375, 0.96875\n",
      "Train loss and acc of batch 52: 49.2099723815918, 0.953125\n",
      "Train loss and acc of batch 53: 47.954124450683594, 1.0\n",
      "Train loss and acc of batch 54: 48.170875549316406, 0.984375\n",
      "Train loss and acc of batch 55: 47.954105377197266, 1.0\n",
      "Train loss and acc of batch 56: 47.95409393310547, 1.0\n",
      "Train loss and acc of batch 57: 48.54978942871094, 0.984375\n",
      "Train loss and acc of batch 58: 47.954078674316406, 1.0\n",
      "Train loss and acc of batch 59: 47.954071044921875, 1.0\n",
      "Train loss and acc of batch 60: 47.954063415527344, 1.0\n",
      "Train loss and acc of batch 61: 47.95405197143555, 1.0\n",
      "Train loss and acc of batch 62: 48.170806884765625, 0.984375\n",
      "Train loss and acc of batch 63: 49.14543533325195, 0.96875\n",
      "Train loss and acc of batch 64: 48.17079162597656, 0.984375\n",
      "Train loss and acc of batch 65: 47.95402145385742, 1.0\n",
      "Train loss and acc of batch 66: 47.954010009765625, 1.0\n",
      "Train loss and acc of batch 67: 48.7664680480957, 0.96875\n",
      "Train loss and acc of batch 68: 48.54969024658203, 0.984375\n",
      "Train loss and acc of batch 69: 48.170745849609375, 0.984375\n",
      "Train loss and acc of batch 70: 47.95397186279297, 1.0\n",
      "Training accuracy and loss of epoch #165: 0.9890, 48.2853\n",
      "Saved model by train loss 48.28530018766161\n",
      "Train loss and acc of batch 0: 47.95396423339844, 1.0\n",
      "Train loss and acc of batch 1: 47.95395278930664, 1.0\n",
      "Train loss and acc of batch 2: 48.23979187011719, 0.984375\n",
      "Train loss and acc of batch 3: 48.17070007324219, 0.984375\n",
      "Train loss and acc of batch 4: 47.95392608642578, 1.0\n",
      "Train loss and acc of batch 5: 49.30284881591797, 0.96875\n",
      "Train loss and acc of batch 6: 48.4565315246582, 0.96875\n",
      "Train loss and acc of batch 7: 47.95389938354492, 1.0\n",
      "Train loss and acc of batch 8: 48.549591064453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.23973846435547, 0.984375\n",
      "Train loss and acc of batch 10: 47.95387649536133, 1.0\n",
      "Train loss and acc of batch 11: 47.9538688659668, 1.0\n",
      "Train loss and acc of batch 12: 48.70707702636719, 0.984375\n",
      "Train loss and acc of batch 13: 48.17060852050781, 0.984375\n",
      "Train loss and acc of batch 14: 48.17060089111328, 0.984375\n",
      "Train loss and acc of batch 15: 48.549530029296875, 0.984375\n",
      "Train loss and acc of batch 16: 48.549522399902344, 0.984375\n",
      "Train loss and acc of batch 17: 48.70703887939453, 0.984375\n",
      "Train loss and acc of batch 18: 48.83535385131836, 0.96875\n",
      "Train loss and acc of batch 19: 47.953792572021484, 1.0\n",
      "Train loss and acc of batch 20: 47.95378494262695, 1.0\n",
      "Train loss and acc of batch 21: 48.549476623535156, 0.984375\n",
      "Train loss and acc of batch 22: 48.549468994140625, 0.984375\n",
      "Train loss and acc of batch 23: 48.17052459716797, 0.984375\n",
      "Train loss and acc of batch 24: 48.54945373535156, 0.984375\n",
      "Train loss and acc of batch 25: 47.953739166259766, 1.0\n",
      "Train loss and acc of batch 26: 47.953731536865234, 1.0\n",
      "Train loss and acc of batch 27: 47.95372009277344, 1.0\n",
      "Train loss and acc of batch 28: 47.95371627807617, 1.0\n",
      "Train loss and acc of batch 29: 48.549400329589844, 0.984375\n",
      "Train loss and acc of batch 30: 47.95369338989258, 1.0\n",
      "Train loss and acc of batch 31: 48.17045593261719, 0.984375\n",
      "Train loss and acc of batch 32: 47.95368194580078, 1.0\n",
      "Train loss and acc of batch 33: 47.953670501708984, 1.0\n",
      "Train loss and acc of batch 34: 48.54936218261719, 0.984375\n",
      "Train loss and acc of batch 35: 48.387176513671875, 0.96875\n",
      "Train loss and acc of batch 36: 47.953643798828125, 1.0\n",
      "Train loss and acc of batch 37: 48.70685577392578, 0.984375\n",
      "Train loss and acc of batch 38: 49.30255126953125, 0.96875\n",
      "Train loss and acc of batch 39: 48.170379638671875, 0.984375\n",
      "Train loss and acc of batch 40: 47.953609466552734, 1.0\n",
      "Train loss and acc of batch 41: 49.302520751953125, 0.96875\n",
      "Train loss and acc of batch 42: 47.953590393066406, 1.0\n",
      "Train loss and acc of batch 43: 48.549278259277344, 0.984375\n",
      "Train loss and acc of batch 44: 47.95357131958008, 1.0\n",
      "Train loss and acc of batch 45: 48.54926300048828, 0.984375\n",
      "Train loss and acc of batch 46: 48.239402770996094, 0.984375\n",
      "Train loss and acc of batch 47: 47.95354461669922, 1.0\n",
      "Train loss and acc of batch 48: 47.95353317260742, 1.0\n",
      "Train loss and acc of batch 49: 47.95352554321289, 1.0\n",
      "Train loss and acc of batch 50: 48.549224853515625, 0.984375\n",
      "Train loss and acc of batch 51: 49.30242919921875, 0.96875\n",
      "Train loss and acc of batch 52: 49.20934295654297, 0.953125\n",
      "Train loss and acc of batch 53: 47.953495025634766, 1.0\n",
      "Train loss and acc of batch 54: 48.17024230957031, 0.984375\n",
      "Train loss and acc of batch 55: 47.95347213745117, 1.0\n",
      "Train loss and acc of batch 56: 47.95346450805664, 1.0\n",
      "Train loss and acc of batch 57: 48.54914855957031, 0.984375\n",
      "Train loss and acc of batch 58: 47.95344161987305, 1.0\n",
      "Train loss and acc of batch 59: 47.95343780517578, 1.0\n",
      "Train loss and acc of batch 60: 47.95343017578125, 1.0\n",
      "Train loss and acc of batch 61: 47.95342254638672, 1.0\n",
      "Train loss and acc of batch 62: 48.17017364501953, 0.984375\n",
      "Train loss and acc of batch 63: 49.14480209350586, 0.96875\n",
      "Train loss and acc of batch 64: 48.17015838623047, 0.984375\n",
      "Train loss and acc of batch 65: 47.95338439941406, 1.0\n",
      "Train loss and acc of batch 66: 47.95337677001953, 1.0\n",
      "Train loss and acc of batch 67: 48.76583480834961, 0.96875\n",
      "Train loss and acc of batch 68: 48.54905700683594, 0.984375\n",
      "Train loss and acc of batch 69: 48.17011260986328, 0.984375\n",
      "Train loss and acc of batch 70: 47.953338623046875, 1.0\n",
      "Training accuracy and loss of epoch #166: 0.9890, 48.2847\n",
      "Saved model by train loss 48.284666625546734\n",
      "Train loss and acc of batch 0: 47.953330993652344, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 1: 47.95331954956055, 1.0\n",
      "Train loss and acc of batch 2: 48.239166259765625, 0.984375\n",
      "Train loss and acc of batch 3: 48.170066833496094, 0.984375\n",
      "Train loss and acc of batch 4: 47.95329666137695, 1.0\n",
      "Train loss and acc of batch 5: 49.302207946777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.45589065551758, 0.96875\n",
      "Train loss and acc of batch 7: 47.953269958496094, 1.0\n",
      "Train loss and acc of batch 8: 48.54895782470703, 0.984375\n",
      "Train loss and acc of batch 9: 48.239097595214844, 0.984375\n",
      "Train loss and acc of batch 10: 47.9532470703125, 1.0\n",
      "Train loss and acc of batch 11: 47.95323181152344, 1.0\n",
      "Train loss and acc of batch 12: 48.70644760131836, 0.984375\n",
      "Train loss and acc of batch 13: 48.16997528076172, 0.984375\n",
      "Train loss and acc of batch 14: 48.169960021972656, 0.984375\n",
      "Train loss and acc of batch 15: 48.54889678955078, 0.984375\n",
      "Train loss and acc of batch 16: 48.54888916015625, 0.984375\n",
      "Train loss and acc of batch 17: 48.70640182495117, 0.984375\n",
      "Train loss and acc of batch 18: 48.8347282409668, 0.96875\n",
      "Train loss and acc of batch 19: 47.953163146972656, 1.0\n",
      "Train loss and acc of batch 20: 47.95315170288086, 1.0\n",
      "Train loss and acc of batch 21: 48.54884338378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.54883575439453, 0.984375\n",
      "Train loss and acc of batch 23: 48.169891357421875, 0.984375\n",
      "Train loss and acc of batch 24: 48.54882049560547, 0.984375\n",
      "Train loss and acc of batch 25: 47.95310974121094, 1.0\n",
      "Train loss and acc of batch 26: 47.95309829711914, 1.0\n",
      "Train loss and acc of batch 27: 47.95309066772461, 1.0\n",
      "Train loss and acc of batch 28: 47.95307922363281, 1.0\n",
      "Train loss and acc of batch 29: 48.54877471923828, 0.984375\n",
      "Train loss and acc of batch 30: 47.95306396484375, 1.0\n",
      "Train loss and acc of batch 31: 48.16981506347656, 0.984375\n",
      "Train loss and acc of batch 32: 47.95304489135742, 1.0\n",
      "Train loss and acc of batch 33: 47.95303726196289, 1.0\n",
      "Train loss and acc of batch 34: 48.548728942871094, 0.984375\n",
      "Train loss and acc of batch 35: 48.38654708862305, 0.96875\n",
      "Train loss and acc of batch 36: 47.953006744384766, 1.0\n",
      "Train loss and acc of batch 37: 48.70622253417969, 0.984375\n",
      "Train loss and acc of batch 38: 49.301918029785156, 0.96875\n",
      "Train loss and acc of batch 39: 48.16974639892578, 0.984375\n",
      "Train loss and acc of batch 40: 47.952972412109375, 1.0\n",
      "Train loss and acc of batch 41: 49.30189514160156, 0.96875\n",
      "Train loss and acc of batch 42: 47.95295333862305, 1.0\n",
      "Train loss and acc of batch 43: 48.54864501953125, 0.984375\n",
      "Train loss and acc of batch 44: 47.952938079833984, 1.0\n",
      "Train loss and acc of batch 45: 48.54862976074219, 0.984375\n",
      "Train loss and acc of batch 46: 48.23877716064453, 0.984375\n",
      "Train loss and acc of batch 47: 47.95291519165039, 1.0\n",
      "Train loss and acc of batch 48: 47.952903747558594, 1.0\n",
      "Train loss and acc of batch 49: 47.95289611816406, 1.0\n",
      "Train loss and acc of batch 50: 48.548583984375, 0.984375\n",
      "Train loss and acc of batch 51: 49.30180358886719, 0.96875\n",
      "Train loss and acc of batch 52: 49.208709716796875, 0.953125\n",
      "Train loss and acc of batch 53: 47.952857971191406, 1.0\n",
      "Train loss and acc of batch 54: 48.16961669921875, 0.984375\n",
      "Train loss and acc of batch 55: 47.95284652709961, 1.0\n",
      "Train loss and acc of batch 56: 47.95282745361328, 1.0\n",
      "Train loss and acc of batch 57: 48.54852294921875, 0.984375\n",
      "Train loss and acc of batch 58: 47.952816009521484, 1.0\n",
      "Train loss and acc of batch 59: 47.95280075073242, 1.0\n",
      "Train loss and acc of batch 60: 47.952796936035156, 1.0\n",
      "Train loss and acc of batch 61: 47.952789306640625, 1.0\n",
      "Train loss and acc of batch 62: 48.16954040527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.14417266845703, 0.96875\n",
      "Train loss and acc of batch 64: 48.169525146484375, 0.984375\n",
      "Train loss and acc of batch 65: 47.95275115966797, 1.0\n",
      "Train loss and acc of batch 66: 47.95274353027344, 1.0\n",
      "Train loss and acc of batch 67: 48.765193939208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.548431396484375, 0.984375\n",
      "Train loss and acc of batch 69: 48.16947937011719, 0.984375\n",
      "Train loss and acc of batch 70: 47.952701568603516, 1.0\n",
      "Training accuracy and loss of epoch #167: 0.9890, 48.2840\n",
      "Saved model by train loss 48.28403392308195\n",
      "Train loss and acc of batch 0: 47.952693939208984, 1.0\n",
      "Train loss and acc of batch 1: 47.95269012451172, 1.0\n",
      "Train loss and acc of batch 2: 48.23853302001953, 0.984375\n",
      "Train loss and acc of batch 3: 48.16944122314453, 0.984375\n",
      "Train loss and acc of batch 4: 47.952659606933594, 1.0\n",
      "Train loss and acc of batch 5: 49.30157470703125, 0.96875\n",
      "Train loss and acc of batch 6: 48.45526123046875, 0.96875\n",
      "Train loss and acc of batch 7: 47.952632904052734, 1.0\n",
      "Train loss and acc of batch 8: 48.54832458496094, 0.984375\n",
      "Train loss and acc of batch 9: 48.23846435546875, 0.984375\n",
      "Train loss and acc of batch 10: 47.95261001586914, 1.0\n",
      "Train loss and acc of batch 11: 47.95260238647461, 1.0\n",
      "Train loss and acc of batch 12: 48.705814361572266, 0.984375\n",
      "Train loss and acc of batch 13: 48.169349670410156, 0.984375\n",
      "Train loss and acc of batch 14: 48.169334411621094, 0.984375\n",
      "Train loss and acc of batch 15: 48.54826354980469, 0.984375\n",
      "Train loss and acc of batch 16: 48.548255920410156, 0.984375\n",
      "Train loss and acc of batch 17: 48.70576858520508, 0.984375\n",
      "Train loss and acc of batch 18: 48.83408737182617, 0.96875\n",
      "Train loss and acc of batch 19: 47.9525260925293, 1.0\n",
      "Train loss and acc of batch 20: 47.95252227783203, 1.0\n",
      "Train loss and acc of batch 21: 48.54821014404297, 0.984375\n",
      "Train loss and acc of batch 22: 48.54820251464844, 0.984375\n",
      "Train loss and acc of batch 23: 48.16925048828125, 0.984375\n",
      "Train loss and acc of batch 24: 48.548179626464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.952476501464844, 1.0\n",
      "Train loss and acc of batch 26: 47.95246887207031, 1.0\n",
      "Train loss and acc of batch 27: 47.95245361328125, 1.0\n",
      "Train loss and acc of batch 28: 47.95244598388672, 1.0\n",
      "Train loss and acc of batch 29: 48.54814147949219, 0.984375\n",
      "Train loss and acc of batch 30: 47.95242691040039, 1.0\n",
      "Train loss and acc of batch 31: 48.169189453125, 0.984375\n",
      "Train loss and acc of batch 32: 47.952415466308594, 1.0\n",
      "Train loss and acc of batch 33: 47.95240020751953, 1.0\n",
      "Train loss and acc of batch 34: 48.548095703125, 0.984375\n",
      "Train loss and acc of batch 35: 48.38591384887695, 0.96875\n",
      "Train loss and acc of batch 36: 47.95237731933594, 1.0\n",
      "Train loss and acc of batch 37: 48.705589294433594, 0.984375\n",
      "Train loss and acc of batch 38: 49.30128479003906, 0.96875\n",
      "Train loss and acc of batch 39: 48.16911315917969, 0.984375\n",
      "Train loss and acc of batch 40: 47.95234298706055, 1.0\n",
      "Train loss and acc of batch 41: 49.3012580871582, 0.96875\n",
      "Train loss and acc of batch 42: 47.95232391357422, 1.0\n",
      "Train loss and acc of batch 43: 48.54801940917969, 0.984375\n",
      "Train loss and acc of batch 44: 47.952301025390625, 1.0\n",
      "Train loss and acc of batch 45: 48.547996520996094, 0.984375\n",
      "Train loss and acc of batch 46: 48.238136291503906, 0.984375\n",
      "Train loss and acc of batch 47: 47.95227813720703, 1.0\n",
      "Train loss and acc of batch 48: 47.9522705078125, 1.0\n",
      "Train loss and acc of batch 49: 47.95226287841797, 1.0\n",
      "Train loss and acc of batch 50: 48.547950744628906, 0.984375\n",
      "Train loss and acc of batch 51: 49.301170349121094, 0.96875\n",
      "Train loss and acc of batch 52: 49.20806884765625, 0.953125\n",
      "Train loss and acc of batch 53: 47.95222854614258, 1.0\n",
      "Train loss and acc of batch 54: 48.168983459472656, 0.984375\n",
      "Train loss and acc of batch 55: 47.95220184326172, 1.0\n",
      "Train loss and acc of batch 56: 47.95219802856445, 1.0\n",
      "Train loss and acc of batch 57: 48.547889709472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.952178955078125, 1.0\n",
      "Train loss and acc of batch 59: 47.95217514038086, 1.0\n",
      "Train loss and acc of batch 60: 47.9521598815918, 1.0\n",
      "Train loss and acc of batch 61: 47.952152252197266, 1.0\n",
      "Train loss and acc of batch 62: 48.168907165527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.14353561401367, 0.96875\n",
      "Train loss and acc of batch 64: 48.16889190673828, 0.984375\n",
      "Train loss and acc of batch 65: 47.95211410522461, 1.0\n",
      "Train loss and acc of batch 66: 47.95210647583008, 1.0\n",
      "Train loss and acc of batch 67: 48.76456832885742, 0.96875\n",
      "Train loss and acc of batch 68: 48.54779052734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.168846130371094, 0.984375\n",
      "Train loss and acc of batch 70: 47.95207214355469, 1.0\n",
      "Training accuracy and loss of epoch #168: 0.9890, 48.2834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.28340036096707\n",
      "Train loss and acc of batch 0: 47.95206832885742, 1.0\n",
      "Train loss and acc of batch 1: 47.95205307006836, 1.0\n",
      "Train loss and acc of batch 2: 48.23789978027344, 0.984375\n",
      "Train loss and acc of batch 3: 48.168792724609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.9520263671875, 1.0\n",
      "Train loss and acc of batch 5: 49.30094909667969, 0.96875\n",
      "Train loss and acc of batch 6: 48.454627990722656, 0.96875\n",
      "Train loss and acc of batch 7: 47.952003479003906, 1.0\n",
      "Train loss and acc of batch 8: 48.547691345214844, 0.984375\n",
      "Train loss and acc of batch 9: 48.237831115722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.95197296142578, 1.0\n",
      "Train loss and acc of batch 11: 47.951969146728516, 1.0\n",
      "Train loss and acc of batch 12: 48.705177307128906, 0.984375\n",
      "Train loss and acc of batch 13: 48.16871643066406, 0.984375\n",
      "Train loss and acc of batch 14: 48.168701171875, 0.984375\n",
      "Train loss and acc of batch 15: 48.547630310058594, 0.984375\n",
      "Train loss and acc of batch 16: 48.54762268066406, 0.984375\n",
      "Train loss and acc of batch 17: 48.70513153076172, 0.984375\n",
      "Train loss and acc of batch 18: 48.83345413208008, 0.96875\n",
      "Train loss and acc of batch 19: 47.9518928527832, 1.0\n",
      "Train loss and acc of batch 20: 47.951881408691406, 1.0\n",
      "Train loss and acc of batch 21: 48.547584533691406, 0.984375\n",
      "Train loss and acc of batch 22: 48.547569274902344, 0.984375\n",
      "Train loss and acc of batch 23: 48.168617248535156, 0.984375\n",
      "Train loss and acc of batch 24: 48.54754638671875, 0.984375\n",
      "Train loss and acc of batch 25: 47.95184326171875, 1.0\n",
      "Train loss and acc of batch 26: 47.95182800292969, 1.0\n",
      "Train loss and acc of batch 27: 47.95182418823242, 1.0\n",
      "Train loss and acc of batch 28: 47.951812744140625, 1.0\n",
      "Train loss and acc of batch 29: 48.547508239746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.95180130004883, 1.0\n",
      "Train loss and acc of batch 31: 48.168548583984375, 0.984375\n",
      "Train loss and acc of batch 32: 47.951778411865234, 1.0\n",
      "Train loss and acc of batch 33: 47.95177459716797, 1.0\n",
      "Train loss and acc of batch 34: 48.547462463378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.38528060913086, 0.96875\n",
      "Train loss and acc of batch 36: 47.951744079589844, 1.0\n",
      "Train loss and acc of batch 37: 48.7049560546875, 0.984375\n",
      "Train loss and acc of batch 38: 49.30065155029297, 0.96875\n",
      "Train loss and acc of batch 39: 48.168479919433594, 0.984375\n",
      "Train loss and acc of batch 40: 47.95170593261719, 1.0\n",
      "Train loss and acc of batch 41: 49.300621032714844, 0.96875\n",
      "Train loss and acc of batch 42: 47.951690673828125, 1.0\n",
      "Train loss and acc of batch 43: 48.54737854003906, 0.984375\n",
      "Train loss and acc of batch 44: 47.95167541503906, 1.0\n",
      "Train loss and acc of batch 45: 48.54735565185547, 0.984375\n",
      "Train loss and acc of batch 46: 48.23750305175781, 0.984375\n",
      "Train loss and acc of batch 47: 47.95164108276367, 1.0\n",
      "Train loss and acc of batch 48: 47.95163345336914, 1.0\n",
      "Train loss and acc of batch 49: 47.95162582397461, 1.0\n",
      "Train loss and acc of batch 50: 48.547325134277344, 0.984375\n",
      "Train loss and acc of batch 51: 49.30052947998047, 0.96875\n",
      "Train loss and acc of batch 52: 49.20743942260742, 0.953125\n",
      "Train loss and acc of batch 53: 47.95158767700195, 1.0\n",
      "Train loss and acc of batch 54: 48.16834259033203, 0.984375\n",
      "Train loss and acc of batch 55: 47.95157241821289, 1.0\n",
      "Train loss and acc of batch 56: 47.951560974121094, 1.0\n",
      "Train loss and acc of batch 57: 48.54725646972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.95155334472656, 1.0\n",
      "Train loss and acc of batch 59: 47.9515380859375, 1.0\n",
      "Train loss and acc of batch 60: 47.9515266418457, 1.0\n",
      "Train loss and acc of batch 61: 47.95151901245117, 1.0\n",
      "Train loss and acc of batch 62: 48.16827392578125, 0.984375\n",
      "Train loss and acc of batch 63: 49.142906188964844, 0.96875\n",
      "Train loss and acc of batch 64: 48.16825866699219, 0.984375\n",
      "Train loss and acc of batch 65: 47.95148468017578, 1.0\n",
      "Train loss and acc of batch 66: 47.95147705078125, 1.0\n",
      "Train loss and acc of batch 67: 48.76393127441406, 0.96875\n",
      "Train loss and acc of batch 68: 48.547149658203125, 0.984375\n",
      "Train loss and acc of batch 69: 48.168212890625, 0.984375\n",
      "Train loss and acc of batch 70: 47.951438903808594, 1.0\n",
      "Training accuracy and loss of epoch #169: 0.9890, 48.2828\n",
      "Saved model by train loss 48.28276647648341\n",
      "Train loss and acc of batch 0: 47.95143127441406, 1.0\n",
      "Train loss and acc of batch 1: 47.951419830322266, 1.0\n",
      "Train loss and acc of batch 2: 48.23725891113281, 0.984375\n",
      "Train loss and acc of batch 3: 48.16816711425781, 0.984375\n",
      "Train loss and acc of batch 4: 47.951393127441406, 1.0\n",
      "Train loss and acc of batch 5: 49.30030822753906, 0.96875\n",
      "Train loss and acc of batch 6: 48.45399475097656, 0.96875\n",
      "Train loss and acc of batch 7: 47.95136642456055, 1.0\n",
      "Train loss and acc of batch 8: 48.54705810546875, 0.984375\n",
      "Train loss and acc of batch 9: 48.237205505371094, 0.984375\n",
      "Train loss and acc of batch 10: 47.95133972167969, 1.0\n",
      "Train loss and acc of batch 11: 47.95132827758789, 1.0\n",
      "Train loss and acc of batch 12: 48.70454788208008, 0.984375\n",
      "Train loss and acc of batch 13: 48.16807556152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.168067932128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.54700469970703, 0.984375\n",
      "Train loss and acc of batch 16: 48.54698944091797, 0.984375\n",
      "Train loss and acc of batch 17: 48.70450210571289, 0.984375\n",
      "Train loss and acc of batch 18: 48.832820892333984, 0.96875\n",
      "Train loss and acc of batch 19: 47.95125961303711, 1.0\n",
      "Train loss and acc of batch 20: 47.95125198364258, 1.0\n",
      "Train loss and acc of batch 21: 48.54694366455078, 0.984375\n",
      "Train loss and acc of batch 22: 48.54693603515625, 0.984375\n",
      "Train loss and acc of batch 23: 48.167991638183594, 0.984375\n",
      "Train loss and acc of batch 24: 48.546913146972656, 0.984375\n",
      "Train loss and acc of batch 25: 47.951202392578125, 1.0\n",
      "Train loss and acc of batch 26: 47.95119857788086, 1.0\n",
      "Train loss and acc of batch 27: 47.95119094848633, 1.0\n",
      "Train loss and acc of batch 28: 47.9511833190918, 1.0\n",
      "Train loss and acc of batch 29: 48.546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.9511604309082, 1.0\n",
      "Train loss and acc of batch 31: 48.16791534423828, 0.984375\n",
      "Train loss and acc of batch 32: 47.951141357421875, 1.0\n",
      "Train loss and acc of batch 33: 47.95113754272461, 1.0\n",
      "Train loss and acc of batch 34: 48.54682922363281, 0.984375\n",
      "Train loss and acc of batch 35: 48.384647369384766, 0.96875\n",
      "Train loss and acc of batch 36: 47.951107025146484, 1.0\n",
      "Train loss and acc of batch 37: 48.70432662963867, 0.984375\n",
      "Train loss and acc of batch 38: 49.300010681152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.1678466796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.951072692871094, 1.0\n",
      "Train loss and acc of batch 41: 49.29998779296875, 0.96875\n",
      "Train loss and acc of batch 42: 47.951053619384766, 1.0\n",
      "Train loss and acc of batch 43: 48.54674530029297, 0.984375\n",
      "Train loss and acc of batch 44: 47.95103454589844, 1.0\n",
      "Train loss and acc of batch 45: 48.546730041503906, 0.984375\n",
      "Train loss and acc of batch 46: 48.23686981201172, 0.984375\n",
      "Train loss and acc of batch 47: 47.951011657714844, 1.0\n",
      "Train loss and acc of batch 48: 47.95100021362305, 1.0\n",
      "Train loss and acc of batch 49: 47.95098876953125, 1.0\n",
      "Train loss and acc of batch 50: 48.54668426513672, 0.984375\n",
      "Train loss and acc of batch 51: 49.299903869628906, 0.96875\n",
      "Train loss and acc of batch 52: 49.20680618286133, 0.953125\n",
      "Train loss and acc of batch 53: 47.950950622558594, 1.0\n",
      "Train loss and acc of batch 54: 48.16771697998047, 0.984375\n",
      "Train loss and acc of batch 55: 47.95093536376953, 1.0\n",
      "Train loss and acc of batch 56: 47.950931549072266, 1.0\n",
      "Train loss and acc of batch 57: 48.546630859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.95091247558594, 1.0\n",
      "Train loss and acc of batch 59: 47.950904846191406, 1.0\n",
      "Train loss and acc of batch 60: 47.950897216796875, 1.0\n",
      "Train loss and acc of batch 61: 47.95088577270508, 1.0\n",
      "Train loss and acc of batch 62: 48.167640686035156, 0.984375\n",
      "Train loss and acc of batch 63: 49.142269134521484, 0.96875\n",
      "Train loss and acc of batch 64: 48.167625427246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.95085144042969, 1.0\n",
      "Train loss and acc of batch 66: 47.950843811035156, 1.0\n",
      "Train loss and acc of batch 67: 48.76329803466797, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 68: 48.54652404785156, 0.984375\n",
      "Train loss and acc of batch 69: 48.167579650878906, 0.984375\n",
      "Train loss and acc of batch 70: 47.9508056640625, 1.0\n",
      "Training accuracy and loss of epoch #170: 0.9890, 48.2821\n",
      "Saved model by train loss 48.28213296809667\n",
      "Train loss and acc of batch 0: 47.9507942199707, 1.0\n",
      "Train loss and acc of batch 1: 47.95078659057617, 1.0\n",
      "Train loss and acc of batch 2: 48.23663330078125, 0.984375\n",
      "Train loss and acc of batch 3: 48.16753387451172, 0.984375\n",
      "Train loss and acc of batch 4: 47.95075988769531, 1.0\n",
      "Train loss and acc of batch 5: 49.29967498779297, 0.96875\n",
      "Train loss and acc of batch 6: 48.4533576965332, 0.96875\n",
      "Train loss and acc of batch 7: 47.95073318481445, 1.0\n",
      "Train loss and acc of batch 8: 48.546424865722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.236572265625, 0.984375\n",
      "Train loss and acc of batch 10: 47.950706481933594, 1.0\n",
      "Train loss and acc of batch 11: 47.95069885253906, 1.0\n",
      "Train loss and acc of batch 12: 48.70391082763672, 0.984375\n",
      "Train loss and acc of batch 13: 48.167449951171875, 0.984375\n",
      "Train loss and acc of batch 14: 48.167442321777344, 0.984375\n",
      "Train loss and acc of batch 15: 48.546363830566406, 0.984375\n",
      "Train loss and acc of batch 16: 48.546356201171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.70386505126953, 0.984375\n",
      "Train loss and acc of batch 18: 48.832191467285156, 0.96875\n",
      "Train loss and acc of batch 19: 47.950626373291016, 1.0\n",
      "Train loss and acc of batch 20: 47.950618743896484, 1.0\n",
      "Train loss and acc of batch 21: 48.54631042480469, 0.984375\n",
      "Train loss and acc of batch 22: 48.546302795410156, 0.984375\n",
      "Train loss and acc of batch 23: 48.1673583984375, 0.984375\n",
      "Train loss and acc of batch 24: 48.546287536621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.95057678222656, 1.0\n",
      "Train loss and acc of batch 26: 47.9505615234375, 1.0\n",
      "Train loss and acc of batch 27: 47.95055389404297, 1.0\n",
      "Train loss and acc of batch 28: 47.95054244995117, 1.0\n",
      "Train loss and acc of batch 29: 48.546234130859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.950531005859375, 1.0\n",
      "Train loss and acc of batch 31: 48.16728973388672, 0.984375\n",
      "Train loss and acc of batch 32: 47.95050811767578, 1.0\n",
      "Train loss and acc of batch 33: 47.95050048828125, 1.0\n",
      "Train loss and acc of batch 34: 48.54618835449219, 0.984375\n",
      "Train loss and acc of batch 35: 48.384010314941406, 0.96875\n",
      "Train loss and acc of batch 36: 47.95048141479492, 1.0\n",
      "Train loss and acc of batch 37: 48.70368957519531, 0.984375\n",
      "Train loss and acc of batch 38: 49.29938507080078, 0.96875\n",
      "Train loss and acc of batch 39: 48.167213439941406, 0.984375\n",
      "Train loss and acc of batch 40: 47.950435638427734, 1.0\n",
      "Train loss and acc of batch 41: 49.29935836791992, 0.96875\n",
      "Train loss and acc of batch 42: 47.95042419433594, 1.0\n",
      "Train loss and acc of batch 43: 48.546112060546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.95040512084961, 1.0\n",
      "Train loss and acc of batch 45: 48.54609680175781, 0.984375\n",
      "Train loss and acc of batch 46: 48.236244201660156, 0.984375\n",
      "Train loss and acc of batch 47: 47.95037841796875, 1.0\n",
      "Train loss and acc of batch 48: 47.95036697387695, 1.0\n",
      "Train loss and acc of batch 49: 47.95035934448242, 1.0\n",
      "Train loss and acc of batch 50: 48.546058654785156, 0.984375\n",
      "Train loss and acc of batch 51: 49.29926300048828, 0.96875\n",
      "Train loss and acc of batch 52: 49.206172943115234, 0.953125\n",
      "Train loss and acc of batch 53: 47.95032501220703, 1.0\n",
      "Train loss and acc of batch 54: 48.167076110839844, 0.984375\n",
      "Train loss and acc of batch 55: 47.95030975341797, 1.0\n",
      "Train loss and acc of batch 56: 47.95029067993164, 1.0\n",
      "Train loss and acc of batch 57: 48.545989990234375, 0.984375\n",
      "Train loss and acc of batch 58: 47.950279235839844, 1.0\n",
      "Train loss and acc of batch 59: 47.95027160644531, 1.0\n",
      "Train loss and acc of batch 60: 47.950260162353516, 1.0\n",
      "Train loss and acc of batch 61: 47.950252532958984, 1.0\n",
      "Train loss and acc of batch 62: 48.16700744628906, 0.984375\n",
      "Train loss and acc of batch 63: 49.14163589477539, 0.96875\n",
      "Train loss and acc of batch 64: 48.1669921875, 0.984375\n",
      "Train loss and acc of batch 65: 47.95021438598633, 1.0\n",
      "Train loss and acc of batch 66: 47.9502067565918, 1.0\n",
      "Train loss and acc of batch 67: 48.762664794921875, 0.96875\n",
      "Train loss and acc of batch 68: 48.54589080810547, 0.984375\n",
      "Train loss and acc of batch 69: 48.16694641113281, 0.984375\n",
      "Train loss and acc of batch 70: 47.950172424316406, 1.0\n",
      "Training accuracy and loss of epoch #171: 0.9890, 48.2815\n",
      "Saved model by train loss 48.281499835806834\n",
      "Train loss and acc of batch 0: 47.95016098022461, 1.0\n",
      "Train loss and acc of batch 1: 47.95015335083008, 1.0\n",
      "Train loss and acc of batch 2: 48.235992431640625, 0.984375\n",
      "Train loss and acc of batch 3: 48.166900634765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.950130462646484, 1.0\n",
      "Train loss and acc of batch 5: 49.299041748046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.45272445678711, 0.96875\n",
      "Train loss and acc of batch 7: 47.950103759765625, 1.0\n",
      "Train loss and acc of batch 8: 48.54578399658203, 0.984375\n",
      "Train loss and acc of batch 9: 48.235939025878906, 0.984375\n",
      "Train loss and acc of batch 10: 47.950077056884766, 1.0\n",
      "Train loss and acc of batch 11: 47.95006561279297, 1.0\n",
      "Train loss and acc of batch 12: 48.70327377319336, 0.984375\n",
      "Train loss and acc of batch 13: 48.16680908203125, 0.984375\n",
      "Train loss and acc of batch 14: 48.16680145263672, 0.984375\n",
      "Train loss and acc of batch 15: 48.54573059082031, 0.984375\n",
      "Train loss and acc of batch 16: 48.54572296142578, 0.984375\n",
      "Train loss and acc of batch 17: 48.7032356262207, 0.984375\n",
      "Train loss and acc of batch 18: 48.83155822753906, 0.96875\n",
      "Train loss and acc of batch 19: 47.949989318847656, 1.0\n",
      "Train loss and acc of batch 20: 47.949981689453125, 1.0\n",
      "Train loss and acc of batch 21: 48.545677185058594, 0.984375\n",
      "Train loss and acc of batch 22: 48.54566192626953, 0.984375\n",
      "Train loss and acc of batch 23: 48.166725158691406, 0.984375\n",
      "Train loss and acc of batch 24: 48.545654296875, 0.984375\n",
      "Train loss and acc of batch 25: 47.94994354248047, 1.0\n",
      "Train loss and acc of batch 26: 47.949928283691406, 1.0\n",
      "Train loss and acc of batch 27: 47.94992446899414, 1.0\n",
      "Train loss and acc of batch 28: 47.949913024902344, 1.0\n",
      "Train loss and acc of batch 29: 48.54560852050781, 0.984375\n",
      "Train loss and acc of batch 30: 47.949893951416016, 1.0\n",
      "Train loss and acc of batch 31: 48.166648864746094, 0.984375\n",
      "Train loss and acc of batch 32: 47.94987869262695, 1.0\n",
      "Train loss and acc of batch 33: 47.949867248535156, 1.0\n",
      "Train loss and acc of batch 34: 48.545562744140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.38337707519531, 0.96875\n",
      "Train loss and acc of batch 36: 47.9498405456543, 1.0\n",
      "Train loss and acc of batch 37: 48.70305633544922, 0.984375\n",
      "Train loss and acc of batch 38: 49.29875183105469, 0.96875\n",
      "Train loss and acc of batch 39: 48.16658020019531, 0.984375\n",
      "Train loss and acc of batch 40: 47.949806213378906, 1.0\n",
      "Train loss and acc of batch 41: 49.29872131347656, 0.96875\n",
      "Train loss and acc of batch 42: 47.94978713989258, 1.0\n",
      "Train loss and acc of batch 43: 48.54547882080078, 0.984375\n",
      "Train loss and acc of batch 44: 47.949771881103516, 1.0\n",
      "Train loss and acc of batch 45: 48.54546356201172, 0.984375\n",
      "Train loss and acc of batch 46: 48.23561096191406, 0.984375\n",
      "Train loss and acc of batch 47: 47.94974136352539, 1.0\n",
      "Train loss and acc of batch 48: 47.94973373413086, 1.0\n",
      "Train loss and acc of batch 49: 47.94972229003906, 1.0\n",
      "Train loss and acc of batch 50: 48.54541778564453, 0.984375\n",
      "Train loss and acc of batch 51: 49.29862976074219, 0.96875\n",
      "Train loss and acc of batch 52: 49.20553970336914, 0.953125\n",
      "Train loss and acc of batch 53: 47.94969177246094, 1.0\n",
      "Train loss and acc of batch 54: 48.16645050048828, 0.984375\n",
      "Train loss and acc of batch 55: 47.949668884277344, 1.0\n",
      "Train loss and acc of batch 56: 47.94966125488281, 1.0\n",
      "Train loss and acc of batch 57: 48.54535675048828, 0.984375\n",
      "Train loss and acc of batch 58: 47.949642181396484, 1.0\n",
      "Train loss and acc of batch 59: 47.94963455200195, 1.0\n",
      "Train loss and acc of batch 60: 47.94963073730469, 1.0\n",
      "Train loss and acc of batch 61: 47.94961929321289, 1.0\n",
      "Train loss and acc of batch 62: 48.16637420654297, 0.984375\n",
      "Train loss and acc of batch 63: 49.14100646972656, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 64: 48.166351318359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.9495849609375, 1.0\n",
      "Train loss and acc of batch 66: 47.94957733154297, 1.0\n",
      "Train loss and acc of batch 67: 48.76203155517578, 0.96875\n",
      "Train loss and acc of batch 68: 48.545257568359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.16630554199219, 0.984375\n",
      "Train loss and acc of batch 70: 47.94953536987305, 1.0\n",
      "Training accuracy and loss of epoch #172: 0.9890, 48.2809\n",
      "Saved model by train loss 48.28086584386691\n",
      "Train loss and acc of batch 0: 47.94953155517578, 1.0\n",
      "Train loss and acc of batch 1: 47.949520111083984, 1.0\n",
      "Train loss and acc of batch 2: 48.23536682128906, 0.984375\n",
      "Train loss and acc of batch 3: 48.16626739501953, 0.984375\n",
      "Train loss and acc of batch 4: 47.949493408203125, 1.0\n",
      "Train loss and acc of batch 5: 49.29840850830078, 0.96875\n",
      "Train loss and acc of batch 6: 48.45209503173828, 0.96875\n",
      "Train loss and acc of batch 7: 47.949462890625, 1.0\n",
      "Train loss and acc of batch 8: 48.54515838623047, 0.984375\n",
      "Train loss and acc of batch 9: 48.23529815673828, 0.984375\n",
      "Train loss and acc of batch 10: 47.94944381713867, 1.0\n",
      "Train loss and acc of batch 11: 47.949432373046875, 1.0\n",
      "Train loss and acc of batch 12: 48.70265197753906, 0.984375\n",
      "Train loss and acc of batch 13: 48.166175842285156, 0.984375\n",
      "Train loss and acc of batch 14: 48.166168212890625, 0.984375\n",
      "Train loss and acc of batch 15: 48.54509735107422, 0.984375\n",
      "Train loss and acc of batch 16: 48.54508972167969, 0.984375\n",
      "Train loss and acc of batch 17: 48.702598571777344, 0.984375\n",
      "Train loss and acc of batch 18: 48.83092498779297, 0.96875\n",
      "Train loss and acc of batch 19: 47.94935989379883, 1.0\n",
      "Train loss and acc of batch 20: 47.9493522644043, 1.0\n",
      "Train loss and acc of batch 21: 48.5450439453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.54503631591797, 0.984375\n",
      "Train loss and acc of batch 23: 48.16609191894531, 0.984375\n",
      "Train loss and acc of batch 24: 48.545013427734375, 0.984375\n",
      "Train loss and acc of batch 25: 47.94930648803711, 1.0\n",
      "Train loss and acc of batch 26: 47.94929504394531, 1.0\n",
      "Train loss and acc of batch 27: 47.94928741455078, 1.0\n",
      "Train loss and acc of batch 28: 47.949275970458984, 1.0\n",
      "Train loss and acc of batch 29: 48.54496765136719, 0.984375\n",
      "Train loss and acc of batch 30: 47.949256896972656, 1.0\n",
      "Train loss and acc of batch 31: 48.166015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.94923782348633, 1.0\n",
      "Train loss and acc of batch 33: 47.94923400878906, 1.0\n",
      "Train loss and acc of batch 34: 48.544921875, 0.984375\n",
      "Train loss and acc of batch 35: 48.38274002075195, 0.96875\n",
      "Train loss and acc of batch 36: 47.94920349121094, 1.0\n",
      "Train loss and acc of batch 37: 48.70241928100586, 0.984375\n",
      "Train loss and acc of batch 38: 49.29811096191406, 0.96875\n",
      "Train loss and acc of batch 39: 48.16594696044922, 0.984375\n",
      "Train loss and acc of batch 40: 47.94916915893555, 1.0\n",
      "Train loss and acc of batch 41: 49.29808807373047, 0.96875\n",
      "Train loss and acc of batch 42: 47.94915008544922, 1.0\n",
      "Train loss and acc of batch 43: 48.54484558105469, 0.984375\n",
      "Train loss and acc of batch 44: 47.94913101196289, 1.0\n",
      "Train loss and acc of batch 45: 48.544822692871094, 0.984375\n",
      "Train loss and acc of batch 46: 48.23497009277344, 0.984375\n",
      "Train loss and acc of batch 47: 47.9491081237793, 1.0\n",
      "Train loss and acc of batch 48: 47.949100494384766, 1.0\n",
      "Train loss and acc of batch 49: 47.94908905029297, 1.0\n",
      "Train loss and acc of batch 50: 48.54478454589844, 0.984375\n",
      "Train loss and acc of batch 51: 49.297996520996094, 0.96875\n",
      "Train loss and acc of batch 52: 49.20490646362305, 0.953125\n",
      "Train loss and acc of batch 53: 47.94905471801758, 1.0\n",
      "Train loss and acc of batch 54: 48.165809631347656, 0.984375\n",
      "Train loss and acc of batch 55: 47.94903564453125, 1.0\n",
      "Train loss and acc of batch 56: 47.94902801513672, 1.0\n",
      "Train loss and acc of batch 57: 48.544715881347656, 0.984375\n",
      "Train loss and acc of batch 58: 47.949005126953125, 1.0\n",
      "Train loss and acc of batch 59: 47.948997497558594, 1.0\n",
      "Train loss and acc of batch 60: 47.94898986816406, 1.0\n",
      "Train loss and acc of batch 61: 47.94898223876953, 1.0\n",
      "Train loss and acc of batch 62: 48.165740966796875, 0.984375\n",
      "Train loss and acc of batch 63: 49.14036560058594, 0.96875\n",
      "Train loss and acc of batch 64: 48.16571807861328, 0.984375\n",
      "Train loss and acc of batch 65: 47.94894790649414, 1.0\n",
      "Train loss and acc of batch 66: 47.94894027709961, 1.0\n",
      "Train loss and acc of batch 67: 48.76139450073242, 0.96875\n",
      "Train loss and acc of batch 68: 48.54461669921875, 0.984375\n",
      "Train loss and acc of batch 69: 48.165672302246094, 0.984375\n",
      "Train loss and acc of batch 70: 47.94890213012695, 1.0\n",
      "Training accuracy and loss of epoch #173: 0.9890, 48.2802\n",
      "Saved model by train loss 48.28023072363625\n",
      "Train loss and acc of batch 0: 47.94889450073242, 1.0\n",
      "Train loss and acc of batch 1: 47.94887924194336, 1.0\n",
      "Train loss and acc of batch 2: 48.23472595214844, 0.984375\n",
      "Train loss and acc of batch 3: 48.165626525878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.948856353759766, 1.0\n",
      "Train loss and acc of batch 5: 49.29777526855469, 0.96875\n",
      "Train loss and acc of batch 6: 48.45145797729492, 0.96875\n",
      "Train loss and acc of batch 7: 47.94883346557617, 1.0\n",
      "Train loss and acc of batch 8: 48.544517517089844, 0.984375\n",
      "Train loss and acc of batch 9: 48.234657287597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.94880676269531, 1.0\n",
      "Train loss and acc of batch 11: 47.948795318603516, 1.0\n",
      "Train loss and acc of batch 12: 48.70201110839844, 0.984375\n",
      "Train loss and acc of batch 13: 48.165550231933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.16553497314453, 0.984375\n",
      "Train loss and acc of batch 15: 48.544464111328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.54444885253906, 0.984375\n",
      "Train loss and acc of batch 17: 48.701961517333984, 0.984375\n",
      "Train loss and acc of batch 18: 48.83028793334961, 0.96875\n",
      "Train loss and acc of batch 19: 47.94872283935547, 1.0\n",
      "Train loss and acc of batch 20: 47.94871520996094, 1.0\n",
      "Train loss and acc of batch 21: 48.544410705566406, 0.984375\n",
      "Train loss and acc of batch 22: 48.544403076171875, 0.984375\n",
      "Train loss and acc of batch 23: 48.16545104980469, 0.984375\n",
      "Train loss and acc of batch 24: 48.54438018798828, 0.984375\n",
      "Train loss and acc of batch 25: 47.94866943359375, 1.0\n",
      "Train loss and acc of batch 26: 47.94866180419922, 1.0\n",
      "Train loss and acc of batch 27: 47.94865036010742, 1.0\n",
      "Train loss and acc of batch 28: 47.948646545410156, 1.0\n",
      "Train loss and acc of batch 29: 48.544334411621094, 0.984375\n",
      "Train loss and acc of batch 30: 47.94862365722656, 1.0\n",
      "Train loss and acc of batch 31: 48.165382385253906, 0.984375\n",
      "Train loss and acc of batch 32: 47.9486083984375, 1.0\n",
      "Train loss and acc of batch 33: 47.9485969543457, 1.0\n",
      "Train loss and acc of batch 34: 48.544288635253906, 0.984375\n",
      "Train loss and acc of batch 35: 48.382110595703125, 0.96875\n",
      "Train loss and acc of batch 36: 47.948577880859375, 1.0\n",
      "Train loss and acc of batch 37: 48.701786041259766, 0.984375\n",
      "Train loss and acc of batch 38: 49.29747009277344, 0.96875\n",
      "Train loss and acc of batch 39: 48.165313720703125, 0.984375\n",
      "Train loss and acc of batch 40: 47.94853973388672, 1.0\n",
      "Train loss and acc of batch 41: 49.297454833984375, 0.96875\n",
      "Train loss and acc of batch 42: 47.94851303100586, 1.0\n",
      "Train loss and acc of batch 43: 48.544212341308594, 0.984375\n",
      "Train loss and acc of batch 44: 47.9484977722168, 1.0\n",
      "Train loss and acc of batch 45: 48.544189453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.234336853027344, 0.984375\n",
      "Train loss and acc of batch 47: 47.9484748840332, 1.0\n",
      "Train loss and acc of batch 48: 47.948463439941406, 1.0\n",
      "Train loss and acc of batch 49: 47.94845962524414, 1.0\n",
      "Train loss and acc of batch 50: 48.544151306152344, 0.984375\n",
      "Train loss and acc of batch 51: 49.29736328125, 0.96875\n",
      "Train loss and acc of batch 52: 49.20426940917969, 0.953125\n",
      "Train loss and acc of batch 53: 47.94841766357422, 1.0\n",
      "Train loss and acc of batch 54: 48.16517639160156, 0.984375\n",
      "Train loss and acc of batch 55: 47.948402404785156, 1.0\n",
      "Train loss and acc of batch 56: 47.94839096069336, 1.0\n",
      "Train loss and acc of batch 57: 48.54408264160156, 0.984375\n",
      "Train loss and acc of batch 58: 47.9483757019043, 1.0\n",
      "Train loss and acc of batch 59: 47.9483642578125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 60: 47.94835662841797, 1.0\n",
      "Train loss and acc of batch 61: 47.94834518432617, 1.0\n",
      "Train loss and acc of batch 62: 48.16510009765625, 0.984375\n",
      "Train loss and acc of batch 63: 49.13973617553711, 0.96875\n",
      "Train loss and acc of batch 64: 48.16509246826172, 0.984375\n",
      "Train loss and acc of batch 65: 47.94831466674805, 1.0\n",
      "Train loss and acc of batch 66: 47.94830322265625, 1.0\n",
      "Train loss and acc of batch 67: 48.76076126098633, 0.96875\n",
      "Train loss and acc of batch 68: 48.54399108886719, 0.984375\n",
      "Train loss and acc of batch 69: 48.16504669189453, 0.984375\n",
      "Train loss and acc of batch 70: 47.948265075683594, 1.0\n",
      "Training accuracy and loss of epoch #174: 0.9890, 48.2796\n",
      "Saved model by train loss 48.27959630187129\n",
      "Train loss and acc of batch 0: 47.94825744628906, 1.0\n",
      "Train loss and acc of batch 1: 47.9482536315918, 1.0\n",
      "Train loss and acc of batch 2: 48.234092712402344, 0.984375\n",
      "Train loss and acc of batch 3: 48.165000915527344, 0.984375\n",
      "Train loss and acc of batch 4: 47.94822311401367, 1.0\n",
      "Train loss and acc of batch 5: 49.297142028808594, 0.96875\n",
      "Train loss and acc of batch 6: 48.45082473754883, 0.96875\n",
      "Train loss and acc of batch 7: 47.94820022583008, 1.0\n",
      "Train loss and acc of batch 8: 48.54389190673828, 0.984375\n",
      "Train loss and acc of batch 9: 48.234031677246094, 0.984375\n",
      "Train loss and acc of batch 10: 47.94816589355469, 1.0\n",
      "Train loss and acc of batch 11: 47.94816207885742, 1.0\n",
      "Train loss and acc of batch 12: 48.70137405395508, 0.984375\n",
      "Train loss and acc of batch 13: 48.16490173339844, 0.984375\n",
      "Train loss and acc of batch 14: 48.164894104003906, 0.984375\n",
      "Train loss and acc of batch 15: 48.54383087158203, 0.984375\n",
      "Train loss and acc of batch 16: 48.54381561279297, 0.984375\n",
      "Train loss and acc of batch 17: 48.701332092285156, 0.984375\n",
      "Train loss and acc of batch 18: 48.82965087890625, 0.96875\n",
      "Train loss and acc of batch 19: 47.948089599609375, 1.0\n",
      "Train loss and acc of batch 20: 47.948081970214844, 1.0\n",
      "Train loss and acc of batch 21: 48.54377746582031, 0.984375\n",
      "Train loss and acc of batch 22: 48.54376983642578, 0.984375\n",
      "Train loss and acc of batch 23: 48.164825439453125, 0.984375\n",
      "Train loss and acc of batch 24: 48.54374694824219, 0.984375\n",
      "Train loss and acc of batch 25: 47.948036193847656, 1.0\n",
      "Train loss and acc of batch 26: 47.94803237915039, 1.0\n",
      "Train loss and acc of batch 27: 47.94801712036133, 1.0\n",
      "Train loss and acc of batch 28: 47.9480094909668, 1.0\n",
      "Train loss and acc of batch 29: 48.543701171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.947994232177734, 1.0\n",
      "Train loss and acc of batch 31: 48.16474914550781, 0.984375\n",
      "Train loss and acc of batch 32: 47.947975158691406, 1.0\n",
      "Train loss and acc of batch 33: 47.94796371459961, 1.0\n",
      "Train loss and acc of batch 34: 48.543663024902344, 0.984375\n",
      "Train loss and acc of batch 35: 48.38147735595703, 0.96875\n",
      "Train loss and acc of batch 36: 47.947940826416016, 1.0\n",
      "Train loss and acc of batch 37: 48.70115661621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.296844482421875, 0.96875\n",
      "Train loss and acc of batch 39: 48.16468048095703, 0.984375\n",
      "Train loss and acc of batch 40: 47.947906494140625, 1.0\n",
      "Train loss and acc of batch 41: 49.296817779541016, 0.96875\n",
      "Train loss and acc of batch 42: 47.9478874206543, 1.0\n",
      "Train loss and acc of batch 43: 48.5435791015625, 0.984375\n",
      "Train loss and acc of batch 44: 47.94786834716797, 1.0\n",
      "Train loss and acc of batch 45: 48.54356384277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.23370361328125, 0.984375\n",
      "Train loss and acc of batch 47: 47.947837829589844, 1.0\n",
      "Train loss and acc of batch 48: 47.94783401489258, 1.0\n",
      "Train loss and acc of batch 49: 47.94782257080078, 1.0\n",
      "Train loss and acc of batch 50: 48.54351806640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.296730041503906, 0.96875\n",
      "Train loss and acc of batch 52: 49.203636169433594, 0.953125\n",
      "Train loss and acc of batch 53: 47.94778823852539, 1.0\n",
      "Train loss and acc of batch 54: 48.16455078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.94776916503906, 1.0\n",
      "Train loss and acc of batch 56: 47.94776153564453, 1.0\n",
      "Train loss and acc of batch 57: 48.54344940185547, 0.984375\n",
      "Train loss and acc of batch 58: 47.9477424621582, 1.0\n",
      "Train loss and acc of batch 59: 47.94773483276367, 1.0\n",
      "Train loss and acc of batch 60: 47.94772720336914, 1.0\n",
      "Train loss and acc of batch 61: 47.947715759277344, 1.0\n",
      "Train loss and acc of batch 62: 48.16447448730469, 0.984375\n",
      "Train loss and acc of batch 63: 49.139102935791016, 0.96875\n",
      "Train loss and acc of batch 64: 48.164451599121094, 0.984375\n",
      "Train loss and acc of batch 65: 47.94768142700195, 1.0\n",
      "Train loss and acc of batch 66: 47.947669982910156, 1.0\n",
      "Train loss and acc of batch 67: 48.7601318359375, 0.96875\n",
      "Train loss and acc of batch 68: 48.543357849121094, 0.984375\n",
      "Train loss and acc of batch 69: 48.164405822753906, 0.984375\n",
      "Train loss and acc of batch 70: 47.9476318359375, 1.0\n",
      "Training accuracy and loss of epoch #175: 0.9890, 48.2790\n",
      "Saved model by train loss 48.27896381431902\n",
      "Train loss and acc of batch 0: 47.947628021240234, 1.0\n",
      "Train loss and acc of batch 1: 47.9476203918457, 1.0\n",
      "Train loss and acc of batch 2: 48.23345947265625, 0.984375\n",
      "Train loss and acc of batch 3: 48.16436004638672, 0.984375\n",
      "Train loss and acc of batch 4: 47.947593688964844, 1.0\n",
      "Train loss and acc of batch 5: 49.2965087890625, 0.96875\n",
      "Train loss and acc of batch 6: 48.4501838684082, 0.96875\n",
      "Train loss and acc of batch 7: 47.94756317138672, 1.0\n",
      "Train loss and acc of batch 8: 48.54325866699219, 0.984375\n",
      "Train loss and acc of batch 9: 48.2333984375, 0.984375\n",
      "Train loss and acc of batch 10: 47.947540283203125, 1.0\n",
      "Train loss and acc of batch 11: 47.94752883911133, 1.0\n",
      "Train loss and acc of batch 12: 48.700740814208984, 0.984375\n",
      "Train loss and acc of batch 13: 48.164276123046875, 0.984375\n",
      "Train loss and acc of batch 14: 48.16426086425781, 0.984375\n",
      "Train loss and acc of batch 15: 48.543190002441406, 0.984375\n",
      "Train loss and acc of batch 16: 48.543190002441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.70069885253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.82902145385742, 0.96875\n",
      "Train loss and acc of batch 19: 47.94746017456055, 1.0\n",
      "Train loss and acc of batch 20: 47.94744873046875, 1.0\n",
      "Train loss and acc of batch 21: 48.54314422607422, 0.984375\n",
      "Train loss and acc of batch 22: 48.54313659667969, 0.984375\n",
      "Train loss and acc of batch 23: 48.1641845703125, 0.984375\n",
      "Train loss and acc of batch 24: 48.543121337890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.9473991394043, 1.0\n",
      "Train loss and acc of batch 26: 47.947391510009766, 1.0\n",
      "Train loss and acc of batch 27: 47.9473876953125, 1.0\n",
      "Train loss and acc of batch 28: 47.94737243652344, 1.0\n",
      "Train loss and acc of batch 29: 48.54307556152344, 0.984375\n",
      "Train loss and acc of batch 30: 47.947357177734375, 1.0\n",
      "Train loss and acc of batch 31: 48.16411590576172, 0.984375\n",
      "Train loss and acc of batch 32: 47.94734191894531, 1.0\n",
      "Train loss and acc of batch 33: 47.94733810424805, 1.0\n",
      "Train loss and acc of batch 34: 48.54302215576172, 0.984375\n",
      "Train loss and acc of batch 35: 48.38084411621094, 0.96875\n",
      "Train loss and acc of batch 36: 47.94730758666992, 1.0\n",
      "Train loss and acc of batch 37: 48.70051956176758, 0.984375\n",
      "Train loss and acc of batch 38: 49.29621124267578, 0.96875\n",
      "Train loss and acc of batch 39: 48.164039611816406, 0.984375\n",
      "Train loss and acc of batch 40: 47.947269439697266, 1.0\n",
      "Train loss and acc of batch 41: 49.29618835449219, 0.96875\n",
      "Train loss and acc of batch 42: 47.94725036621094, 1.0\n",
      "Train loss and acc of batch 43: 48.542945861816406, 0.984375\n",
      "Train loss and acc of batch 44: 47.94723129272461, 1.0\n",
      "Train loss and acc of batch 45: 48.54292297363281, 0.984375\n",
      "Train loss and acc of batch 46: 48.233070373535156, 0.984375\n",
      "Train loss and acc of batch 47: 47.94721221923828, 1.0\n",
      "Train loss and acc of batch 48: 47.94719696044922, 1.0\n",
      "Train loss and acc of batch 49: 47.94718933105469, 1.0\n",
      "Train loss and acc of batch 50: 48.542877197265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.29609680175781, 0.96875\n",
      "Train loss and acc of batch 52: 49.203006744384766, 0.953125\n",
      "Train loss and acc of batch 53: 47.9471549987793, 1.0\n",
      "Train loss and acc of batch 54: 48.163909912109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.94713592529297, 1.0\n",
      "Train loss and acc of batch 56: 47.94712448120117, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 57: 48.542823791503906, 0.984375\n",
      "Train loss and acc of batch 58: 47.94710922241211, 1.0\n",
      "Train loss and acc of batch 59: 47.94709777832031, 1.0\n",
      "Train loss and acc of batch 60: 47.94709396362305, 1.0\n",
      "Train loss and acc of batch 61: 47.94708251953125, 1.0\n",
      "Train loss and acc of batch 62: 48.163841247558594, 0.984375\n",
      "Train loss and acc of batch 63: 49.138465881347656, 0.96875\n",
      "Train loss and acc of batch 64: 48.163818359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.947044372558594, 1.0\n",
      "Train loss and acc of batch 66: 47.94703674316406, 1.0\n",
      "Train loss and acc of batch 67: 48.759490966796875, 0.96875\n",
      "Train loss and acc of batch 68: 48.542724609375, 0.984375\n",
      "Train loss and acc of batch 69: 48.16377258300781, 0.984375\n",
      "Train loss and acc of batch 70: 47.946998596191406, 1.0\n",
      "Training accuracy and loss of epoch #176: 0.9890, 48.2783\n",
      "Saved model by train loss 48.27832992983536\n",
      "Train loss and acc of batch 0: 47.946990966796875, 1.0\n",
      "Train loss and acc of batch 1: 47.946983337402344, 1.0\n",
      "Train loss and acc of batch 2: 48.232826232910156, 0.984375\n",
      "Train loss and acc of batch 3: 48.163734436035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.94696044921875, 1.0\n",
      "Train loss and acc of batch 5: 49.295875549316406, 0.96875\n",
      "Train loss and acc of batch 6: 48.44955825805664, 0.96875\n",
      "Train loss and acc of batch 7: 47.94692611694336, 1.0\n",
      "Train loss and acc of batch 8: 48.542625427246094, 0.984375\n",
      "Train loss and acc of batch 9: 48.23277282714844, 0.984375\n",
      "Train loss and acc of batch 10: 47.946903228759766, 1.0\n",
      "Train loss and acc of batch 11: 47.94689178466797, 1.0\n",
      "Train loss and acc of batch 12: 48.70011520385742, 0.984375\n",
      "Train loss and acc of batch 13: 48.16364288330078, 0.984375\n",
      "Train loss and acc of batch 14: 48.16363525390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.54255676269531, 0.984375\n",
      "Train loss and acc of batch 16: 48.54254913330078, 0.984375\n",
      "Train loss and acc of batch 17: 48.70006561279297, 0.984375\n",
      "Train loss and acc of batch 18: 48.82838439941406, 0.96875\n",
      "Train loss and acc of batch 19: 47.94682693481445, 1.0\n",
      "Train loss and acc of batch 20: 47.94681930541992, 1.0\n",
      "Train loss and acc of batch 21: 48.542503356933594, 0.984375\n",
      "Train loss and acc of batch 22: 48.54249572753906, 0.984375\n",
      "Train loss and acc of batch 23: 48.16355895996094, 0.984375\n",
      "Train loss and acc of batch 24: 48.54248046875, 0.984375\n",
      "Train loss and acc of batch 25: 47.94676971435547, 1.0\n",
      "Train loss and acc of batch 26: 47.94676208496094, 1.0\n",
      "Train loss and acc of batch 27: 47.94675064086914, 1.0\n",
      "Train loss and acc of batch 28: 47.94674301147461, 1.0\n",
      "Train loss and acc of batch 29: 48.54243469238281, 0.984375\n",
      "Train loss and acc of batch 30: 47.94672393798828, 1.0\n",
      "Train loss and acc of batch 31: 48.163482666015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.94670867919922, 1.0\n",
      "Train loss and acc of batch 33: 47.94670104980469, 1.0\n",
      "Train loss and acc of batch 34: 48.542396545410156, 0.984375\n",
      "Train loss and acc of batch 35: 48.38020706176758, 0.96875\n",
      "Train loss and acc of batch 36: 47.94667053222656, 1.0\n",
      "Train loss and acc of batch 37: 48.69989013671875, 0.984375\n",
      "Train loss and acc of batch 38: 49.295570373535156, 0.96875\n",
      "Train loss and acc of batch 39: 48.16340637207031, 0.984375\n",
      "Train loss and acc of batch 40: 47.94663619995117, 1.0\n",
      "Train loss and acc of batch 41: 49.295555114746094, 0.96875\n",
      "Train loss and acc of batch 42: 47.946624755859375, 1.0\n",
      "Train loss and acc of batch 43: 48.54231262207031, 0.984375\n",
      "Train loss and acc of batch 44: 47.946598052978516, 1.0\n",
      "Train loss and acc of batch 45: 48.54229736328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.23242950439453, 0.984375\n",
      "Train loss and acc of batch 47: 47.94657516479492, 1.0\n",
      "Train loss and acc of batch 48: 47.94656753540039, 1.0\n",
      "Train loss and acc of batch 49: 47.94655990600586, 1.0\n",
      "Train loss and acc of batch 50: 48.54225158691406, 0.984375\n",
      "Train loss and acc of batch 51: 49.29546356201172, 0.96875\n",
      "Train loss and acc of batch 52: 49.20236587524414, 0.953125\n",
      "Train loss and acc of batch 53: 47.9465217590332, 1.0\n",
      "Train loss and acc of batch 54: 48.16328430175781, 0.984375\n",
      "Train loss and acc of batch 55: 47.946502685546875, 1.0\n",
      "Train loss and acc of batch 56: 47.94649124145508, 1.0\n",
      "Train loss and acc of batch 57: 48.54218292236328, 0.984375\n",
      "Train loss and acc of batch 58: 47.94647216796875, 1.0\n",
      "Train loss and acc of batch 59: 47.946468353271484, 1.0\n",
      "Train loss and acc of batch 60: 47.94645690917969, 1.0\n",
      "Train loss and acc of batch 61: 47.946449279785156, 1.0\n",
      "Train loss and acc of batch 62: 48.1632080078125, 0.984375\n",
      "Train loss and acc of batch 63: 49.13783264160156, 0.96875\n",
      "Train loss and acc of batch 64: 48.163185119628906, 0.984375\n",
      "Train loss and acc of batch 65: 47.94641876220703, 1.0\n",
      "Train loss and acc of batch 66: 47.9463996887207, 1.0\n",
      "Train loss and acc of batch 67: 48.75886154174805, 0.96875\n",
      "Train loss and acc of batch 68: 48.542083740234375, 0.984375\n",
      "Train loss and acc of batch 69: 48.16313934326172, 0.984375\n",
      "Train loss and acc of batch 70: 47.946372985839844, 1.0\n",
      "Training accuracy and loss of epoch #177: 0.9890, 48.2777\n",
      "Saved model by train loss 48.277696743817394\n",
      "Train loss and acc of batch 0: 47.946353912353516, 1.0\n",
      "Train loss and acc of batch 1: 47.94635009765625, 1.0\n",
      "Train loss and acc of batch 2: 48.232200622558594, 0.984375\n",
      "Train loss and acc of batch 3: 48.16309356689453, 0.984375\n",
      "Train loss and acc of batch 4: 47.94632339477539, 1.0\n",
      "Train loss and acc of batch 5: 49.29524230957031, 0.96875\n",
      "Train loss and acc of batch 6: 48.44892501831055, 0.96875\n",
      "Train loss and acc of batch 7: 47.9463005065918, 1.0\n",
      "Train loss and acc of batch 8: 48.5419921875, 0.984375\n",
      "Train loss and acc of batch 9: 48.23213195800781, 0.984375\n",
      "Train loss and acc of batch 10: 47.94626998901367, 1.0\n",
      "Train loss and acc of batch 11: 47.946258544921875, 1.0\n",
      "Train loss and acc of batch 12: 48.6994743347168, 0.984375\n",
      "Train loss and acc of batch 13: 48.16300964355469, 0.984375\n",
      "Train loss and acc of batch 14: 48.163002014160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.54192352294922, 0.984375\n",
      "Train loss and acc of batch 16: 48.54191589355469, 0.984375\n",
      "Train loss and acc of batch 17: 48.699432373046875, 0.984375\n",
      "Train loss and acc of batch 18: 48.82775115966797, 0.96875\n",
      "Train loss and acc of batch 19: 47.94619369506836, 1.0\n",
      "Train loss and acc of batch 20: 47.9461784362793, 1.0\n",
      "Train loss and acc of batch 21: 48.54187774658203, 0.984375\n",
      "Train loss and acc of batch 22: 48.5418701171875, 0.984375\n",
      "Train loss and acc of batch 23: 48.16291809082031, 0.984375\n",
      "Train loss and acc of batch 24: 48.541847229003906, 0.984375\n",
      "Train loss and acc of batch 25: 47.946136474609375, 1.0\n",
      "Train loss and acc of batch 26: 47.94612503051758, 1.0\n",
      "Train loss and acc of batch 27: 47.94612121582031, 1.0\n",
      "Train loss and acc of batch 28: 47.946109771728516, 1.0\n",
      "Train loss and acc of batch 29: 48.54180145263672, 0.984375\n",
      "Train loss and acc of batch 30: 47.94609069824219, 1.0\n",
      "Train loss and acc of batch 31: 48.162841796875, 0.984375\n",
      "Train loss and acc of batch 32: 47.946075439453125, 1.0\n",
      "Train loss and acc of batch 33: 47.946067810058594, 1.0\n",
      "Train loss and acc of batch 34: 48.54175567626953, 0.984375\n",
      "Train loss and acc of batch 35: 48.379581451416016, 0.96875\n",
      "Train loss and acc of batch 36: 47.946041107177734, 1.0\n",
      "Train loss and acc of batch 37: 48.699249267578125, 0.984375\n",
      "Train loss and acc of batch 38: 49.294944763183594, 0.96875\n",
      "Train loss and acc of batch 39: 48.16278076171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.94600296020508, 1.0\n",
      "Train loss and acc of batch 41: 49.294921875, 0.96875\n",
      "Train loss and acc of batch 42: 47.945987701416016, 1.0\n",
      "Train loss and acc of batch 43: 48.54167938232422, 0.984375\n",
      "Train loss and acc of batch 44: 47.94597244262695, 1.0\n",
      "Train loss and acc of batch 45: 48.541656494140625, 0.984375\n",
      "Train loss and acc of batch 46: 48.23180389404297, 0.984375\n",
      "Train loss and acc of batch 47: 47.94594192504883, 1.0\n",
      "Train loss and acc of batch 48: 47.94593048095703, 1.0\n",
      "Train loss and acc of batch 49: 47.945926666259766, 1.0\n",
      "Train loss and acc of batch 50: 48.54161834716797, 0.984375\n",
      "Train loss and acc of batch 51: 49.294830322265625, 0.96875\n",
      "Train loss and acc of batch 52: 49.20173645019531, 0.953125\n",
      "Train loss and acc of batch 53: 47.94588851928711, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 54: 48.16264343261719, 0.984375\n",
      "Train loss and acc of batch 55: 47.94586944580078, 1.0\n",
      "Train loss and acc of batch 56: 47.945858001708984, 1.0\n",
      "Train loss and acc of batch 57: 48.54154968261719, 0.984375\n",
      "Train loss and acc of batch 58: 47.94584274291992, 1.0\n",
      "Train loss and acc of batch 59: 47.945831298828125, 1.0\n",
      "Train loss and acc of batch 60: 47.945823669433594, 1.0\n",
      "Train loss and acc of batch 61: 47.94581604003906, 1.0\n",
      "Train loss and acc of batch 62: 48.162574768066406, 0.984375\n",
      "Train loss and acc of batch 63: 49.137203216552734, 0.96875\n",
      "Train loss and acc of batch 64: 48.162559509277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.94578170776367, 1.0\n",
      "Train loss and acc of batch 66: 47.945770263671875, 1.0\n",
      "Train loss and acc of batch 67: 48.75822448730469, 0.96875\n",
      "Train loss and acc of batch 68: 48.54145050048828, 0.984375\n",
      "Train loss and acc of batch 69: 48.162513732910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.945735931396484, 1.0\n",
      "Training accuracy and loss of epoch #178: 0.9890, 48.2771\n",
      "Saved model by train loss 48.27706345034317\n",
      "Train loss and acc of batch 0: 47.94572830200195, 1.0\n",
      "Train loss and acc of batch 1: 47.94572448730469, 1.0\n",
      "Train loss and acc of batch 2: 48.23155975341797, 0.984375\n",
      "Train loss and acc of batch 3: 48.16246032714844, 0.984375\n",
      "Train loss and acc of batch 4: 47.94569396972656, 1.0\n",
      "Train loss and acc of batch 5: 49.29460144042969, 0.96875\n",
      "Train loss and acc of batch 6: 48.44829559326172, 0.96875\n",
      "Train loss and acc of batch 7: 47.94566345214844, 1.0\n",
      "Train loss and acc of batch 8: 48.541358947753906, 0.984375\n",
      "Train loss and acc of batch 9: 48.23149871826172, 0.984375\n",
      "Train loss and acc of batch 10: 47.94563674926758, 1.0\n",
      "Train loss and acc of batch 11: 47.94562911987305, 1.0\n",
      "Train loss and acc of batch 12: 48.69884490966797, 0.984375\n",
      "Train loss and acc of batch 13: 48.162376403808594, 0.984375\n",
      "Train loss and acc of batch 14: 48.16236877441406, 0.984375\n",
      "Train loss and acc of batch 15: 48.541297912597656, 0.984375\n",
      "Train loss and acc of batch 16: 48.541290283203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.698795318603516, 0.984375\n",
      "Train loss and acc of batch 18: 48.82712173461914, 0.96875\n",
      "Train loss and acc of batch 19: 47.945556640625, 1.0\n",
      "Train loss and acc of batch 20: 47.94554901123047, 1.0\n",
      "Train loss and acc of batch 21: 48.54124450683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.541229248046875, 0.984375\n",
      "Train loss and acc of batch 23: 48.16228485107422, 0.984375\n",
      "Train loss and acc of batch 24: 48.54121398925781, 0.984375\n",
      "Train loss and acc of batch 25: 47.945499420166016, 1.0\n",
      "Train loss and acc of batch 26: 47.94549560546875, 1.0\n",
      "Train loss and acc of batch 27: 47.94548797607422, 1.0\n",
      "Train loss and acc of batch 28: 47.94547653198242, 1.0\n",
      "Train loss and acc of batch 29: 48.541168212890625, 0.984375\n",
      "Train loss and acc of batch 30: 47.94546127319336, 1.0\n",
      "Train loss and acc of batch 31: 48.16221618652344, 0.984375\n",
      "Train loss and acc of batch 32: 47.94544219970703, 1.0\n",
      "Train loss and acc of batch 33: 47.9454345703125, 1.0\n",
      "Train loss and acc of batch 34: 48.54113006591797, 0.984375\n",
      "Train loss and acc of batch 35: 48.378944396972656, 0.96875\n",
      "Train loss and acc of batch 36: 47.945404052734375, 1.0\n",
      "Train loss and acc of batch 37: 48.69862365722656, 0.984375\n",
      "Train loss and acc of batch 38: 49.2943115234375, 0.96875\n",
      "Train loss and acc of batch 39: 48.162139892578125, 0.984375\n",
      "Train loss and acc of batch 40: 47.945369720458984, 1.0\n",
      "Train loss and acc of batch 41: 49.29428482055664, 0.96875\n",
      "Train loss and acc of batch 42: 47.945350646972656, 1.0\n",
      "Train loss and acc of batch 43: 48.541046142578125, 0.984375\n",
      "Train loss and acc of batch 44: 47.945335388183594, 1.0\n",
      "Train loss and acc of batch 45: 48.54102325439453, 0.984375\n",
      "Train loss and acc of batch 46: 48.231170654296875, 0.984375\n",
      "Train loss and acc of batch 47: 47.945308685302734, 1.0\n",
      "Train loss and acc of batch 48: 47.9453010559082, 1.0\n",
      "Train loss and acc of batch 49: 47.945289611816406, 1.0\n",
      "Train loss and acc of batch 50: 48.540977478027344, 0.984375\n",
      "Train loss and acc of batch 51: 49.29420471191406, 0.96875\n",
      "Train loss and acc of batch 52: 49.20110321044922, 0.953125\n",
      "Train loss and acc of batch 53: 47.945247650146484, 1.0\n",
      "Train loss and acc of batch 54: 48.162010192871094, 0.984375\n",
      "Train loss and acc of batch 55: 47.94523239135742, 1.0\n",
      "Train loss and acc of batch 56: 47.945228576660156, 1.0\n",
      "Train loss and acc of batch 57: 48.540924072265625, 0.984375\n",
      "Train loss and acc of batch 58: 47.94520950317383, 1.0\n",
      "Train loss and acc of batch 59: 47.94519805908203, 1.0\n",
      "Train loss and acc of batch 60: 47.945194244384766, 1.0\n",
      "Train loss and acc of batch 61: 47.9451789855957, 1.0\n",
      "Train loss and acc of batch 62: 48.16194152832031, 0.984375\n",
      "Train loss and acc of batch 63: 49.136566162109375, 0.96875\n",
      "Train loss and acc of batch 64: 48.16192626953125, 0.984375\n",
      "Train loss and acc of batch 65: 47.94514846801758, 1.0\n",
      "Train loss and acc of batch 66: 47.94513702392578, 1.0\n",
      "Train loss and acc of batch 67: 48.757591247558594, 0.96875\n",
      "Train loss and acc of batch 68: 48.54081726074219, 0.984375\n",
      "Train loss and acc of batch 69: 48.16187286376953, 0.984375\n",
      "Train loss and acc of batch 70: 47.94510269165039, 1.0\n",
      "Training accuracy and loss of epoch #179: 0.9890, 48.2764\n",
      "Saved model by train loss 48.276430318053336\n",
      "Train loss and acc of batch 0: 47.94509506225586, 1.0\n",
      "Train loss and acc of batch 1: 47.94508743286133, 1.0\n",
      "Train loss and acc of batch 2: 48.230926513671875, 0.984375\n",
      "Train loss and acc of batch 3: 48.161834716796875, 0.984375\n",
      "Train loss and acc of batch 4: 47.9450569152832, 1.0\n",
      "Train loss and acc of batch 5: 49.293975830078125, 0.96875\n",
      "Train loss and acc of batch 6: 48.447654724121094, 0.96875\n",
      "Train loss and acc of batch 7: 47.945030212402344, 1.0\n",
      "Train loss and acc of batch 8: 48.54072570800781, 0.984375\n",
      "Train loss and acc of batch 9: 48.230865478515625, 0.984375\n",
      "Train loss and acc of batch 10: 47.945003509521484, 1.0\n",
      "Train loss and acc of batch 11: 47.94499206542969, 1.0\n",
      "Train loss and acc of batch 12: 48.69820785522461, 0.984375\n",
      "Train loss and acc of batch 13: 48.1617431640625, 0.984375\n",
      "Train loss and acc of batch 14: 48.16173553466797, 0.984375\n",
      "Train loss and acc of batch 15: 48.54066467285156, 0.984375\n",
      "Train loss and acc of batch 16: 48.5406494140625, 0.984375\n",
      "Train loss and acc of batch 17: 48.69816589355469, 0.984375\n",
      "Train loss and acc of batch 18: 48.82648468017578, 0.96875\n",
      "Train loss and acc of batch 19: 47.94492721557617, 1.0\n",
      "Train loss and acc of batch 20: 47.944915771484375, 1.0\n",
      "Train loss and acc of batch 21: 48.540611267089844, 0.984375\n",
      "Train loss and acc of batch 22: 48.54060363769531, 0.984375\n",
      "Train loss and acc of batch 23: 48.161651611328125, 0.984375\n",
      "Train loss and acc of batch 24: 48.54058074951172, 0.984375\n",
      "Train loss and acc of batch 25: 47.94486618041992, 1.0\n",
      "Train loss and acc of batch 26: 47.94485855102539, 1.0\n",
      "Train loss and acc of batch 27: 47.94485092163086, 1.0\n",
      "Train loss and acc of batch 28: 47.944847106933594, 1.0\n",
      "Train loss and acc of batch 29: 48.54053497314453, 0.984375\n",
      "Train loss and acc of batch 30: 47.944828033447266, 1.0\n",
      "Train loss and acc of batch 31: 48.161582946777344, 0.984375\n",
      "Train loss and acc of batch 32: 47.94480895996094, 1.0\n",
      "Train loss and acc of batch 33: 47.944801330566406, 1.0\n",
      "Train loss and acc of batch 34: 48.540489196777344, 0.984375\n",
      "Train loss and acc of batch 35: 48.3783073425293, 0.96875\n",
      "Train loss and acc of batch 36: 47.94477081298828, 1.0\n",
      "Train loss and acc of batch 37: 48.6979866027832, 0.984375\n",
      "Train loss and acc of batch 38: 49.293678283691406, 0.96875\n",
      "Train loss and acc of batch 39: 48.16150665283203, 0.984375\n",
      "Train loss and acc of batch 40: 47.944732666015625, 1.0\n",
      "Train loss and acc of batch 41: 49.29365158081055, 0.96875\n",
      "Train loss and acc of batch 42: 47.94471740722656, 1.0\n",
      "Train loss and acc of batch 43: 48.54041290283203, 0.984375\n",
      "Train loss and acc of batch 44: 47.9447021484375, 1.0\n",
      "Train loss and acc of batch 45: 48.54039001464844, 0.984375\n",
      "Train loss and acc of batch 46: 48.23052978515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.94467544555664, 1.0\n",
      "Train loss and acc of batch 48: 47.944664001464844, 1.0\n",
      "Train loss and acc of batch 49: 47.94465637207031, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 50: 48.54035186767578, 0.984375\n",
      "Train loss and acc of batch 51: 49.29356384277344, 0.96875\n",
      "Train loss and acc of batch 52: 49.20046615600586, 0.953125\n",
      "Train loss and acc of batch 53: 47.944618225097656, 1.0\n",
      "Train loss and acc of batch 54: 48.16136932373047, 0.984375\n",
      "Train loss and acc of batch 55: 47.944602966308594, 1.0\n",
      "Train loss and acc of batch 56: 47.94459533691406, 1.0\n",
      "Train loss and acc of batch 57: 48.54029083251953, 0.984375\n",
      "Train loss and acc of batch 58: 47.944576263427734, 1.0\n",
      "Train loss and acc of batch 59: 47.9445686340332, 1.0\n",
      "Train loss and acc of batch 60: 47.94456100463867, 1.0\n",
      "Train loss and acc of batch 61: 47.94455337524414, 1.0\n",
      "Train loss and acc of batch 62: 48.16130065917969, 0.984375\n",
      "Train loss and acc of batch 63: 49.13593292236328, 0.96875\n",
      "Train loss and acc of batch 64: 48.161293029785156, 0.984375\n",
      "Train loss and acc of batch 65: 47.94451141357422, 1.0\n",
      "Train loss and acc of batch 66: 47.94450759887695, 1.0\n",
      "Train loss and acc of batch 67: 48.7569694519043, 0.96875\n",
      "Train loss and acc of batch 68: 48.540184020996094, 0.984375\n",
      "Train loss and acc of batch 69: 48.16123962402344, 0.984375\n",
      "Train loss and acc of batch 70: 47.94446563720703, 1.0\n",
      "Training accuracy and loss of epoch #180: 0.9890, 48.2758\n",
      "Saved model by train loss 48.2757966484822\n",
      "Train loss and acc of batch 0: 47.9444580078125, 1.0\n",
      "Train loss and acc of batch 1: 47.94445037841797, 1.0\n",
      "Train loss and acc of batch 2: 48.23030090332031, 0.984375\n",
      "Train loss and acc of batch 3: 48.16119384765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.94443130493164, 1.0\n",
      "Train loss and acc of batch 5: 49.2933349609375, 0.96875\n",
      "Train loss and acc of batch 6: 48.447025299072266, 0.96875\n",
      "Train loss and acc of batch 7: 47.944400787353516, 1.0\n",
      "Train loss and acc of batch 8: 48.54009246826172, 0.984375\n",
      "Train loss and acc of batch 9: 48.23023223876953, 0.984375\n",
      "Train loss and acc of batch 10: 47.944366455078125, 1.0\n",
      "Train loss and acc of batch 11: 47.94436264038086, 1.0\n",
      "Train loss and acc of batch 12: 48.697574615478516, 0.984375\n",
      "Train loss and acc of batch 13: 48.161109924316406, 0.984375\n",
      "Train loss and acc of batch 14: 48.161094665527344, 0.984375\n",
      "Train loss and acc of batch 15: 48.54003143310547, 0.984375\n",
      "Train loss and acc of batch 16: 48.540016174316406, 0.984375\n",
      "Train loss and acc of batch 17: 48.69753646850586, 0.984375\n",
      "Train loss and acc of batch 18: 48.82585906982422, 0.96875\n",
      "Train loss and acc of batch 19: 47.94428634643555, 1.0\n",
      "Train loss and acc of batch 20: 47.944278717041016, 1.0\n",
      "Train loss and acc of batch 21: 48.53997802734375, 0.984375\n",
      "Train loss and acc of batch 22: 48.53996276855469, 0.984375\n",
      "Train loss and acc of batch 23: 48.16102600097656, 0.984375\n",
      "Train loss and acc of batch 24: 48.539947509765625, 0.984375\n",
      "Train loss and acc of batch 25: 47.944236755371094, 1.0\n",
      "Train loss and acc of batch 26: 47.94422912597656, 1.0\n",
      "Train loss and acc of batch 27: 47.944217681884766, 1.0\n",
      "Train loss and acc of batch 28: 47.944210052490234, 1.0\n",
      "Train loss and acc of batch 29: 48.53990173339844, 0.984375\n",
      "Train loss and acc of batch 30: 47.944190979003906, 1.0\n",
      "Train loss and acc of batch 31: 48.16094970703125, 0.984375\n",
      "Train loss and acc of batch 32: 47.94417953491211, 1.0\n",
      "Train loss and acc of batch 33: 47.94416046142578, 1.0\n",
      "Train loss and acc of batch 34: 48.53985595703125, 0.984375\n",
      "Train loss and acc of batch 35: 48.377681732177734, 0.96875\n",
      "Train loss and acc of batch 36: 47.94413757324219, 1.0\n",
      "Train loss and acc of batch 37: 48.69735336303711, 0.984375\n",
      "Train loss and acc of batch 38: 49.29304504394531, 0.96875\n",
      "Train loss and acc of batch 39: 48.16087341308594, 0.984375\n",
      "Train loss and acc of batch 40: 47.9441032409668, 1.0\n",
      "Train loss and acc of batch 41: 49.29301834106445, 0.96875\n",
      "Train loss and acc of batch 42: 47.94408416748047, 1.0\n",
      "Train loss and acc of batch 43: 48.53977966308594, 0.984375\n",
      "Train loss and acc of batch 44: 47.94406509399414, 1.0\n",
      "Train loss and acc of batch 45: 48.539764404296875, 0.984375\n",
      "Train loss and acc of batch 46: 48.22990417480469, 0.984375\n",
      "Train loss and acc of batch 47: 47.94403839111328, 1.0\n",
      "Train loss and acc of batch 48: 47.944034576416016, 1.0\n",
      "Train loss and acc of batch 49: 47.94402313232422, 1.0\n",
      "Train loss and acc of batch 50: 48.53971862792969, 0.984375\n",
      "Train loss and acc of batch 51: 49.29292297363281, 0.96875\n",
      "Train loss and acc of batch 52: 49.1998405456543, 0.953125\n",
      "Train loss and acc of batch 53: 47.94398498535156, 1.0\n",
      "Train loss and acc of batch 54: 48.16075134277344, 0.984375\n",
      "Train loss and acc of batch 55: 47.943965911865234, 1.0\n",
      "Train loss and acc of batch 56: 47.9439582824707, 1.0\n",
      "Train loss and acc of batch 57: 48.539649963378906, 0.984375\n",
      "Train loss and acc of batch 58: 47.943939208984375, 1.0\n",
      "Train loss and acc of batch 59: 47.94393539428711, 1.0\n",
      "Train loss and acc of batch 60: 47.94392776489258, 1.0\n",
      "Train loss and acc of batch 61: 47.94391632080078, 1.0\n",
      "Train loss and acc of batch 62: 48.160675048828125, 0.984375\n",
      "Train loss and acc of batch 63: 49.13530349731445, 0.96875\n",
      "Train loss and acc of batch 64: 48.16065216064453, 0.984375\n",
      "Train loss and acc of batch 65: 47.943878173828125, 1.0\n",
      "Train loss and acc of batch 66: 47.94387435913086, 1.0\n",
      "Train loss and acc of batch 67: 48.75632858276367, 0.96875\n",
      "Train loss and acc of batch 68: 48.53955841064453, 0.984375\n",
      "Train loss and acc of batch 69: 48.160606384277344, 0.984375\n",
      "Train loss and acc of batch 70: 47.94383239746094, 1.0\n",
      "Training accuracy and loss of epoch #181: 0.9890, 48.2752\n",
      "Saved model by train loss 48.27516351619237\n",
      "Train loss and acc of batch 0: 47.94382858276367, 1.0\n",
      "Train loss and acc of batch 1: 47.943817138671875, 1.0\n",
      "Train loss and acc of batch 2: 48.22966003417969, 0.984375\n",
      "Train loss and acc of batch 3: 48.16056823730469, 0.984375\n",
      "Train loss and acc of batch 4: 47.943790435791016, 1.0\n",
      "Train loss and acc of batch 5: 49.29270935058594, 0.96875\n",
      "Train loss and acc of batch 6: 48.44639205932617, 0.96875\n",
      "Train loss and acc of batch 7: 47.943763732910156, 1.0\n",
      "Train loss and acc of batch 8: 48.539451599121094, 0.984375\n",
      "Train loss and acc of batch 9: 48.22960662841797, 0.984375\n",
      "Train loss and acc of batch 10: 47.9437370300293, 1.0\n",
      "Train loss and acc of batch 11: 47.94373321533203, 1.0\n",
      "Train loss and acc of batch 12: 48.69694519042969, 0.984375\n",
      "Train loss and acc of batch 13: 48.16046905517578, 0.984375\n",
      "Train loss and acc of batch 14: 48.16046905517578, 0.984375\n",
      "Train loss and acc of batch 15: 48.539390563964844, 0.984375\n",
      "Train loss and acc of batch 16: 48.539390563964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.696895599365234, 0.984375\n",
      "Train loss and acc of batch 18: 48.825218200683594, 0.96875\n",
      "Train loss and acc of batch 19: 47.943660736083984, 1.0\n",
      "Train loss and acc of batch 20: 47.94365692138672, 1.0\n",
      "Train loss and acc of batch 21: 48.539337158203125, 0.984375\n",
      "Train loss and acc of batch 22: 48.539329528808594, 0.984375\n",
      "Train loss and acc of batch 23: 48.16038513183594, 0.984375\n",
      "Train loss and acc of batch 24: 48.53931427001953, 0.984375\n",
      "Train loss and acc of batch 25: 47.943603515625, 1.0\n",
      "Train loss and acc of batch 26: 47.94359588623047, 1.0\n",
      "Train loss and acc of batch 27: 47.94358444213867, 1.0\n",
      "Train loss and acc of batch 28: 47.94357681274414, 1.0\n",
      "Train loss and acc of batch 29: 48.539268493652344, 0.984375\n",
      "Train loss and acc of batch 30: 47.94356155395508, 1.0\n",
      "Train loss and acc of batch 31: 48.160316467285156, 0.984375\n",
      "Train loss and acc of batch 32: 47.943538665771484, 1.0\n",
      "Train loss and acc of batch 33: 47.94353485107422, 1.0\n",
      "Train loss and acc of batch 34: 48.539222717285156, 0.984375\n",
      "Train loss and acc of batch 35: 48.377044677734375, 0.96875\n",
      "Train loss and acc of batch 36: 47.94350051879883, 1.0\n",
      "Train loss and acc of batch 37: 48.69672393798828, 0.984375\n",
      "Train loss and acc of batch 38: 49.29241180419922, 0.96875\n",
      "Train loss and acc of batch 39: 48.160247802734375, 0.984375\n",
      "Train loss and acc of batch 40: 47.9434700012207, 1.0\n",
      "Train loss and acc of batch 41: 49.292388916015625, 0.96875\n",
      "Train loss and acc of batch 42: 47.94345474243164, 1.0\n",
      "Train loss and acc of batch 43: 48.53913879394531, 0.984375\n",
      "Train loss and acc of batch 44: 47.94343566894531, 1.0\n",
      "Train loss and acc of batch 45: 48.53912353515625, 0.984375\n",
      "Train loss and acc of batch 46: 48.22926330566406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 47.94341278076172, 1.0\n",
      "Train loss and acc of batch 48: 47.94340515136719, 1.0\n",
      "Train loss and acc of batch 49: 47.94339370727539, 1.0\n",
      "Train loss and acc of batch 50: 48.53907775878906, 0.984375\n",
      "Train loss and acc of batch 51: 49.29229736328125, 0.96875\n",
      "Train loss and acc of batch 52: 49.19920349121094, 0.953125\n",
      "Train loss and acc of batch 53: 47.943355560302734, 1.0\n",
      "Train loss and acc of batch 54: 48.16011047363281, 0.984375\n",
      "Train loss and acc of batch 55: 47.943336486816406, 1.0\n",
      "Train loss and acc of batch 56: 47.943328857421875, 1.0\n",
      "Train loss and acc of batch 57: 48.53901672363281, 0.984375\n",
      "Train loss and acc of batch 58: 47.94330978393555, 1.0\n",
      "Train loss and acc of batch 59: 47.943302154541016, 1.0\n",
      "Train loss and acc of batch 60: 47.94329071044922, 1.0\n",
      "Train loss and acc of batch 61: 47.94328689575195, 1.0\n",
      "Train loss and acc of batch 62: 48.16004180908203, 0.984375\n",
      "Train loss and acc of batch 63: 49.13467025756836, 0.96875\n",
      "Train loss and acc of batch 64: 48.16001892089844, 0.984375\n",
      "Train loss and acc of batch 65: 47.943241119384766, 1.0\n",
      "Train loss and acc of batch 66: 47.9432373046875, 1.0\n",
      "Train loss and acc of batch 67: 48.755699157714844, 0.96875\n",
      "Train loss and acc of batch 68: 48.538917541503906, 0.984375\n",
      "Train loss and acc of batch 69: 48.15997314453125, 0.984375\n",
      "Train loss and acc of batch 70: 47.943206787109375, 1.0\n",
      "Training accuracy and loss of epoch #182: 0.9890, 48.2745\n",
      "Saved model by train loss 48.274530437630666\n",
      "Train loss and acc of batch 0: 47.94318771362305, 1.0\n",
      "Train loss and acc of batch 1: 47.94318771362305, 1.0\n",
      "Train loss and acc of batch 2: 48.229026794433594, 0.984375\n",
      "Train loss and acc of batch 3: 48.15992736816406, 0.984375\n",
      "Train loss and acc of batch 4: 47.94316101074219, 1.0\n",
      "Train loss and acc of batch 5: 49.292076110839844, 0.96875\n",
      "Train loss and acc of batch 6: 48.44575881958008, 0.96875\n",
      "Train loss and acc of batch 7: 47.94313049316406, 1.0\n",
      "Train loss and acc of batch 8: 48.538818359375, 0.984375\n",
      "Train loss and acc of batch 9: 48.228965759277344, 0.984375\n",
      "Train loss and acc of batch 10: 47.9431037902832, 1.0\n",
      "Train loss and acc of batch 11: 47.943092346191406, 1.0\n",
      "Train loss and acc of batch 12: 48.69630813598633, 0.984375\n",
      "Train loss and acc of batch 13: 48.15984344482422, 0.984375\n",
      "Train loss and acc of batch 14: 48.159828186035156, 0.984375\n",
      "Train loss and acc of batch 15: 48.53876495361328, 0.984375\n",
      "Train loss and acc of batch 16: 48.53874969482422, 0.984375\n",
      "Train loss and acc of batch 17: 48.69626235961914, 0.984375\n",
      "Train loss and acc of batch 18: 48.824588775634766, 0.96875\n",
      "Train loss and acc of batch 19: 47.94302749633789, 1.0\n",
      "Train loss and acc of batch 20: 47.943016052246094, 1.0\n",
      "Train loss and acc of batch 21: 48.53871154785156, 0.984375\n",
      "Train loss and acc of batch 22: 48.5386962890625, 0.984375\n",
      "Train loss and acc of batch 23: 48.159751892089844, 0.984375\n",
      "Train loss and acc of batch 24: 48.53868103027344, 0.984375\n",
      "Train loss and acc of batch 25: 47.94296646118164, 1.0\n",
      "Train loss and acc of batch 26: 47.942962646484375, 1.0\n",
      "Train loss and acc of batch 27: 47.942955017089844, 1.0\n",
      "Train loss and acc of batch 28: 47.94294738769531, 1.0\n",
      "Train loss and acc of batch 29: 48.53863525390625, 0.984375\n",
      "Train loss and acc of batch 30: 47.94292449951172, 1.0\n",
      "Train loss and acc of batch 31: 48.15967559814453, 0.984375\n",
      "Train loss and acc of batch 32: 47.94291305541992, 1.0\n",
      "Train loss and acc of batch 33: 47.94290542602539, 1.0\n",
      "Train loss and acc of batch 34: 48.538597106933594, 0.984375\n",
      "Train loss and acc of batch 35: 48.37641525268555, 0.96875\n",
      "Train loss and acc of batch 36: 47.942874908447266, 1.0\n",
      "Train loss and acc of batch 37: 48.69608688354492, 0.984375\n",
      "Train loss and acc of batch 38: 49.291786193847656, 0.96875\n",
      "Train loss and acc of batch 39: 48.15960693359375, 0.984375\n",
      "Train loss and acc of batch 40: 47.94283676147461, 1.0\n",
      "Train loss and acc of batch 41: 49.291751861572266, 0.96875\n",
      "Train loss and acc of batch 42: 47.94282150268555, 1.0\n",
      "Train loss and acc of batch 43: 48.53851318359375, 0.984375\n",
      "Train loss and acc of batch 44: 47.94280242919922, 1.0\n",
      "Train loss and acc of batch 45: 48.538490295410156, 0.984375\n",
      "Train loss and acc of batch 46: 48.2286376953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.942771911621094, 1.0\n",
      "Train loss and acc of batch 48: 47.94276809692383, 1.0\n",
      "Train loss and acc of batch 49: 47.9427604675293, 1.0\n",
      "Train loss and acc of batch 50: 48.5384521484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.291664123535156, 0.96875\n",
      "Train loss and acc of batch 52: 49.19857406616211, 0.953125\n",
      "Train loss and acc of batch 53: 47.942718505859375, 1.0\n",
      "Train loss and acc of batch 54: 48.15947723388672, 0.984375\n",
      "Train loss and acc of batch 55: 47.94270324707031, 1.0\n",
      "Train loss and acc of batch 56: 47.94269561767578, 1.0\n",
      "Train loss and acc of batch 57: 48.53839111328125, 0.984375\n",
      "Train loss and acc of batch 58: 47.94267272949219, 1.0\n",
      "Train loss and acc of batch 59: 47.942665100097656, 1.0\n",
      "Train loss and acc of batch 60: 47.94266128540039, 1.0\n",
      "Train loss and acc of batch 61: 47.94265365600586, 1.0\n",
      "Train loss and acc of batch 62: 48.15940856933594, 0.984375\n",
      "Train loss and acc of batch 63: 49.134037017822266, 0.96875\n",
      "Train loss and acc of batch 64: 48.159385681152344, 0.984375\n",
      "Train loss and acc of batch 65: 47.9426155090332, 1.0\n",
      "Train loss and acc of batch 66: 47.94260025024414, 1.0\n",
      "Train loss and acc of batch 67: 48.75505828857422, 0.96875\n",
      "Train loss and acc of batch 68: 48.53828430175781, 0.984375\n",
      "Train loss and acc of batch 69: 48.15934753417969, 0.984375\n",
      "Train loss and acc of batch 70: 47.942569732666016, 1.0\n",
      "Training accuracy and loss of epoch #183: 0.9890, 48.2739\n",
      "Saved model by train loss 48.27389730534083\n",
      "Train loss and acc of batch 0: 47.94256591796875, 1.0\n",
      "Train loss and acc of batch 1: 47.94255065917969, 1.0\n",
      "Train loss and acc of batch 2: 48.2283935546875, 0.984375\n",
      "Train loss and acc of batch 3: 48.1593017578125, 0.984375\n",
      "Train loss and acc of batch 4: 47.94252395629883, 1.0\n",
      "Train loss and acc of batch 5: 49.29144287109375, 0.96875\n",
      "Train loss and acc of batch 6: 48.44512939453125, 0.96875\n",
      "Train loss and acc of batch 7: 47.94249725341797, 1.0\n",
      "Train loss and acc of batch 8: 48.53819274902344, 0.984375\n",
      "Train loss and acc of batch 9: 48.22833251953125, 0.984375\n",
      "Train loss and acc of batch 10: 47.94247055053711, 1.0\n",
      "Train loss and acc of batch 11: 47.94246292114258, 1.0\n",
      "Train loss and acc of batch 12: 48.6956787109375, 0.984375\n",
      "Train loss and acc of batch 13: 48.159210205078125, 0.984375\n",
      "Train loss and acc of batch 14: 48.159202575683594, 0.984375\n",
      "Train loss and acc of batch 15: 48.53813171386719, 0.984375\n",
      "Train loss and acc of batch 16: 48.538116455078125, 0.984375\n",
      "Train loss and acc of batch 17: 48.69563293457031, 0.984375\n",
      "Train loss and acc of batch 18: 48.823951721191406, 0.96875\n",
      "Train loss and acc of batch 19: 47.9423942565918, 1.0\n",
      "Train loss and acc of batch 20: 47.9423828125, 1.0\n",
      "Train loss and acc of batch 21: 48.53807830810547, 0.984375\n",
      "Train loss and acc of batch 22: 48.53807067871094, 0.984375\n",
      "Train loss and acc of batch 23: 48.15912628173828, 0.984375\n",
      "Train loss and acc of batch 24: 48.538047790527344, 0.984375\n",
      "Train loss and acc of batch 25: 47.94233703613281, 1.0\n",
      "Train loss and acc of batch 26: 47.942325592041016, 1.0\n",
      "Train loss and acc of batch 27: 47.94232177734375, 1.0\n",
      "Train loss and acc of batch 28: 47.94231414794922, 1.0\n",
      "Train loss and acc of batch 29: 48.538002014160156, 0.984375\n",
      "Train loss and acc of batch 30: 47.942291259765625, 1.0\n",
      "Train loss and acc of batch 31: 48.15904998779297, 0.984375\n",
      "Train loss and acc of batch 32: 47.94227600097656, 1.0\n",
      "Train loss and acc of batch 33: 47.94226837158203, 1.0\n",
      "Train loss and acc of batch 34: 48.5379638671875, 0.984375\n",
      "Train loss and acc of batch 35: 48.37577438354492, 0.96875\n",
      "Train loss and acc of batch 36: 47.94224166870117, 1.0\n",
      "Train loss and acc of batch 37: 48.69545364379883, 0.984375\n",
      "Train loss and acc of batch 38: 49.29114532470703, 0.96875\n",
      "Train loss and acc of batch 39: 48.15898132324219, 0.984375\n",
      "Train loss and acc of batch 40: 47.942203521728516, 1.0\n",
      "Train loss and acc of batch 41: 49.29111862182617, 0.96875\n",
      "Train loss and acc of batch 42: 47.94218826293945, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 43: 48.537879943847656, 0.984375\n",
      "Train loss and acc of batch 44: 47.942169189453125, 1.0\n",
      "Train loss and acc of batch 45: 48.537864685058594, 0.984375\n",
      "Train loss and acc of batch 46: 48.228004455566406, 0.984375\n",
      "Train loss and acc of batch 47: 47.942142486572266, 1.0\n",
      "Train loss and acc of batch 48: 47.942134857177734, 1.0\n",
      "Train loss and acc of batch 49: 47.94212341308594, 1.0\n",
      "Train loss and acc of batch 50: 48.537818908691406, 0.984375\n",
      "Train loss and acc of batch 51: 49.29103088378906, 0.96875\n",
      "Train loss and acc of batch 52: 49.197933197021484, 0.953125\n",
      "Train loss and acc of batch 53: 47.94208908081055, 1.0\n",
      "Train loss and acc of batch 54: 48.158843994140625, 0.984375\n",
      "Train loss and acc of batch 55: 47.94207000732422, 1.0\n",
      "Train loss and acc of batch 56: 47.94206619262695, 1.0\n",
      "Train loss and acc of batch 57: 48.537750244140625, 0.984375\n",
      "Train loss and acc of batch 58: 47.94204330444336, 1.0\n",
      "Train loss and acc of batch 59: 47.94203567504883, 1.0\n",
      "Train loss and acc of batch 60: 47.94202423095703, 1.0\n",
      "Train loss and acc of batch 61: 47.9420166015625, 1.0\n",
      "Train loss and acc of batch 62: 48.158775329589844, 0.984375\n",
      "Train loss and acc of batch 63: 49.133399963378906, 0.96875\n",
      "Train loss and acc of batch 64: 48.15876007080078, 0.984375\n",
      "Train loss and acc of batch 65: 47.941986083984375, 1.0\n",
      "Train loss and acc of batch 66: 47.94197463989258, 1.0\n",
      "Train loss and acc of batch 67: 48.75442886352539, 0.96875\n",
      "Train loss and acc of batch 68: 48.53765106201172, 0.984375\n",
      "Train loss and acc of batch 69: 48.15870666503906, 0.984375\n",
      "Train loss and acc of batch 70: 47.94194030761719, 1.0\n",
      "Training accuracy and loss of epoch #184: 0.9890, 48.2733\n",
      "Saved model by train loss 48.27326492524483\n",
      "Train loss and acc of batch 0: 47.941925048828125, 1.0\n",
      "Train loss and acc of batch 1: 47.941917419433594, 1.0\n",
      "Train loss and acc of batch 2: 48.22776794433594, 0.984375\n",
      "Train loss and acc of batch 3: 48.158660888671875, 0.984375\n",
      "Train loss and acc of batch 4: 47.941890716552734, 1.0\n",
      "Train loss and acc of batch 5: 49.290809631347656, 0.96875\n",
      "Train loss and acc of batch 6: 48.44449234008789, 0.96875\n",
      "Train loss and acc of batch 7: 47.94186782836914, 1.0\n",
      "Train loss and acc of batch 8: 48.537559509277344, 0.984375\n",
      "Train loss and acc of batch 9: 48.227699279785156, 0.984375\n",
      "Train loss and acc of batch 10: 47.94184112548828, 1.0\n",
      "Train loss and acc of batch 11: 47.94182586669922, 1.0\n",
      "Train loss and acc of batch 12: 48.695045471191406, 0.984375\n",
      "Train loss and acc of batch 13: 48.15857696533203, 0.984375\n",
      "Train loss and acc of batch 14: 48.15856170654297, 0.984375\n",
      "Train loss and acc of batch 15: 48.53749084472656, 0.984375\n",
      "Train loss and acc of batch 16: 48.53749084472656, 0.984375\n",
      "Train loss and acc of batch 17: 48.69499588012695, 0.984375\n",
      "Train loss and acc of batch 18: 48.82332229614258, 0.96875\n",
      "Train loss and acc of batch 19: 47.94175338745117, 1.0\n",
      "Train loss and acc of batch 20: 47.941749572753906, 1.0\n",
      "Train loss and acc of batch 21: 48.537445068359375, 0.984375\n",
      "Train loss and acc of batch 22: 48.53742980957031, 0.984375\n",
      "Train loss and acc of batch 23: 48.158485412597656, 0.984375\n",
      "Train loss and acc of batch 24: 48.53742218017578, 0.984375\n",
      "Train loss and acc of batch 25: 47.94170379638672, 1.0\n",
      "Train loss and acc of batch 26: 47.94169616699219, 1.0\n",
      "Train loss and acc of batch 27: 47.941688537597656, 1.0\n",
      "Train loss and acc of batch 28: 47.94167709350586, 1.0\n",
      "Train loss and acc of batch 29: 48.53736877441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.94166564941406, 1.0\n",
      "Train loss and acc of batch 31: 48.158416748046875, 0.984375\n",
      "Train loss and acc of batch 32: 47.94164276123047, 1.0\n",
      "Train loss and acc of batch 33: 47.941627502441406, 1.0\n",
      "Train loss and acc of batch 34: 48.537322998046875, 0.984375\n",
      "Train loss and acc of batch 35: 48.375144958496094, 0.96875\n",
      "Train loss and acc of batch 36: 47.94160842895508, 1.0\n",
      "Train loss and acc of batch 37: 48.694820404052734, 0.984375\n",
      "Train loss and acc of batch 38: 49.29051971435547, 0.96875\n",
      "Train loss and acc of batch 39: 48.158348083496094, 0.984375\n",
      "Train loss and acc of batch 40: 47.94157028198242, 1.0\n",
      "Train loss and acc of batch 41: 49.290489196777344, 0.96875\n",
      "Train loss and acc of batch 42: 47.941551208496094, 1.0\n",
      "Train loss and acc of batch 43: 48.53724670410156, 0.984375\n",
      "Train loss and acc of batch 44: 47.94153594970703, 1.0\n",
      "Train loss and acc of batch 45: 48.5372314453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.22737121582031, 0.984375\n",
      "Train loss and acc of batch 47: 47.94150924682617, 1.0\n",
      "Train loss and acc of batch 48: 47.94149398803711, 1.0\n",
      "Train loss and acc of batch 49: 47.941490173339844, 1.0\n",
      "Train loss and acc of batch 50: 48.53717803955078, 0.984375\n",
      "Train loss and acc of batch 51: 49.29039001464844, 0.96875\n",
      "Train loss and acc of batch 52: 49.197303771972656, 0.953125\n",
      "Train loss and acc of batch 53: 47.94145202636719, 1.0\n",
      "Train loss and acc of batch 54: 48.158203125, 0.984375\n",
      "Train loss and acc of batch 55: 47.941429138183594, 1.0\n",
      "Train loss and acc of batch 56: 47.94142532348633, 1.0\n",
      "Train loss and acc of batch 57: 48.53711700439453, 0.984375\n",
      "Train loss and acc of batch 58: 47.941410064697266, 1.0\n",
      "Train loss and acc of batch 59: 47.94139862060547, 1.0\n",
      "Train loss and acc of batch 60: 47.94139099121094, 1.0\n",
      "Train loss and acc of batch 61: 47.941383361816406, 1.0\n",
      "Train loss and acc of batch 62: 48.15813446044922, 0.984375\n",
      "Train loss and acc of batch 63: 49.13276672363281, 0.96875\n",
      "Train loss and acc of batch 64: 48.158119201660156, 0.984375\n",
      "Train loss and acc of batch 65: 47.941341400146484, 1.0\n",
      "Train loss and acc of batch 66: 47.94133758544922, 1.0\n",
      "Train loss and acc of batch 67: 48.75379180908203, 0.96875\n",
      "Train loss and acc of batch 68: 48.537025451660156, 0.984375\n",
      "Train loss and acc of batch 69: 48.15807342529297, 0.984375\n",
      "Train loss and acc of batch 70: 47.94129943847656, 1.0\n",
      "Training accuracy and loss of epoch #185: 0.9890, 48.2726\n",
      "Saved model by train loss 48.27263012738295\n",
      "Train loss and acc of batch 0: 47.941287994384766, 1.0\n",
      "Train loss and acc of batch 1: 47.9412841796875, 1.0\n",
      "Train loss and acc of batch 2: 48.22712707519531, 0.984375\n",
      "Train loss and acc of batch 3: 48.15802764892578, 0.984375\n",
      "Train loss and acc of batch 4: 47.94125747680664, 1.0\n",
      "Train loss and acc of batch 5: 49.29016876220703, 0.96875\n",
      "Train loss and acc of batch 6: 48.44385528564453, 0.96875\n",
      "Train loss and acc of batch 7: 47.941226959228516, 1.0\n",
      "Train loss and acc of batch 8: 48.53691864013672, 0.984375\n",
      "Train loss and acc of batch 9: 48.22706604003906, 0.984375\n",
      "Train loss and acc of batch 10: 47.941200256347656, 1.0\n",
      "Train loss and acc of batch 11: 47.94119644165039, 1.0\n",
      "Train loss and acc of batch 12: 48.69440460205078, 0.984375\n",
      "Train loss and acc of batch 13: 48.157936096191406, 0.984375\n",
      "Train loss and acc of batch 14: 48.157928466796875, 0.984375\n",
      "Train loss and acc of batch 15: 48.536865234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.53684997558594, 0.984375\n",
      "Train loss and acc of batch 17: 48.69436264038086, 0.984375\n",
      "Train loss and acc of batch 18: 48.82268142700195, 0.96875\n",
      "Train loss and acc of batch 19: 47.94112014770508, 1.0\n",
      "Train loss and acc of batch 20: 47.94111251831055, 1.0\n",
      "Train loss and acc of batch 21: 48.53680419921875, 0.984375\n",
      "Train loss and acc of batch 22: 48.53679656982422, 0.984375\n",
      "Train loss and acc of batch 23: 48.15785217285156, 0.984375\n",
      "Train loss and acc of batch 24: 48.536781311035156, 0.984375\n",
      "Train loss and acc of batch 25: 47.941070556640625, 1.0\n",
      "Train loss and acc of batch 26: 47.941062927246094, 1.0\n",
      "Train loss and acc of batch 27: 47.941043853759766, 1.0\n",
      "Train loss and acc of batch 28: 47.9410400390625, 1.0\n",
      "Train loss and acc of batch 29: 48.53673553466797, 0.984375\n",
      "Train loss and acc of batch 30: 47.94102478027344, 1.0\n",
      "Train loss and acc of batch 31: 48.15778350830078, 0.984375\n",
      "Train loss and acc of batch 32: 47.941009521484375, 1.0\n",
      "Train loss and acc of batch 33: 47.94099426269531, 1.0\n",
      "Train loss and acc of batch 34: 48.53668975830078, 0.984375\n",
      "Train loss and acc of batch 35: 48.37450408935547, 0.96875\n",
      "Train loss and acc of batch 36: 47.94096755981445, 1.0\n",
      "Train loss and acc of batch 37: 48.69418716430664, 0.984375\n",
      "Train loss and acc of batch 38: 49.289878845214844, 0.96875\n",
      "Train loss and acc of batch 39: 48.15770721435547, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 40: 47.94093322753906, 1.0\n",
      "Train loss and acc of batch 41: 49.28984832763672, 0.96875\n",
      "Train loss and acc of batch 42: 47.94091796875, 1.0\n",
      "Train loss and acc of batch 43: 48.53661346435547, 0.984375\n",
      "Train loss and acc of batch 44: 47.94089889526367, 1.0\n",
      "Train loss and acc of batch 45: 48.536590576171875, 0.984375\n",
      "Train loss and acc of batch 46: 48.22673034667969, 0.984375\n",
      "Train loss and acc of batch 47: 47.94087219238281, 1.0\n",
      "Train loss and acc of batch 48: 47.940860748291016, 1.0\n",
      "Train loss and acc of batch 49: 47.940853118896484, 1.0\n",
      "Train loss and acc of batch 50: 48.53654479980469, 0.984375\n",
      "Train loss and acc of batch 51: 49.289764404296875, 0.96875\n",
      "Train loss and acc of batch 52: 49.1966667175293, 0.953125\n",
      "Train loss and acc of batch 53: 47.940818786621094, 1.0\n",
      "Train loss and acc of batch 54: 48.15757751464844, 0.984375\n",
      "Train loss and acc of batch 55: 47.9407958984375, 1.0\n",
      "Train loss and acc of batch 56: 47.94078826904297, 1.0\n",
      "Train loss and acc of batch 57: 48.53648376464844, 0.984375\n",
      "Train loss and acc of batch 58: 47.940773010253906, 1.0\n",
      "Train loss and acc of batch 59: 47.94076919555664, 1.0\n",
      "Train loss and acc of batch 60: 47.940757751464844, 1.0\n",
      "Train loss and acc of batch 61: 47.94075012207031, 1.0\n",
      "Train loss and acc of batch 62: 48.157501220703125, 0.984375\n",
      "Train loss and acc of batch 63: 49.13212966918945, 0.96875\n",
      "Train loss and acc of batch 64: 48.15747833251953, 0.984375\n",
      "Train loss and acc of batch 65: 47.940711975097656, 1.0\n",
      "Train loss and acc of batch 66: 47.94070053100586, 1.0\n",
      "Train loss and acc of batch 67: 48.7531623840332, 0.96875\n",
      "Train loss and acc of batch 68: 48.53638458251953, 0.984375\n",
      "Train loss and acc of batch 69: 48.157432556152344, 0.984375\n",
      "Train loss and acc of batch 70: 47.94066619873047, 1.0\n",
      "Training accuracy and loss of epoch #186: 0.9890, 48.2720\n",
      "Saved model by train loss 48.27199420123033\n",
      "Train loss and acc of batch 0: 47.94065856933594, 1.0\n",
      "Train loss and acc of batch 1: 47.94064712524414, 1.0\n",
      "Train loss and acc of batch 2: 48.22649383544922, 0.984375\n",
      "Train loss and acc of batch 3: 48.15739440917969, 0.984375\n",
      "Train loss and acc of batch 4: 47.94062042236328, 1.0\n",
      "Train loss and acc of batch 5: 49.28954315185547, 0.96875\n",
      "Train loss and acc of batch 6: 48.4432258605957, 0.96875\n",
      "Train loss and acc of batch 7: 47.94059371948242, 1.0\n",
      "Train loss and acc of batch 8: 48.536293029785156, 0.984375\n",
      "Train loss and acc of batch 9: 48.22643280029297, 0.984375\n",
      "Train loss and acc of batch 10: 47.94057083129883, 1.0\n",
      "Train loss and acc of batch 11: 47.9405632019043, 1.0\n",
      "Train loss and acc of batch 12: 48.69377136230469, 0.984375\n",
      "Train loss and acc of batch 13: 48.15730285644531, 0.984375\n",
      "Train loss and acc of batch 14: 48.15729522705078, 0.984375\n",
      "Train loss and acc of batch 15: 48.536224365234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.536216735839844, 0.984375\n",
      "Train loss and acc of batch 17: 48.69373321533203, 0.984375\n",
      "Train loss and acc of batch 18: 48.822052001953125, 0.96875\n",
      "Train loss and acc of batch 19: 47.94049072265625, 1.0\n",
      "Train loss and acc of batch 20: 47.94047546386719, 1.0\n",
      "Train loss and acc of batch 21: 48.536170959472656, 0.984375\n",
      "Train loss and acc of batch 22: 48.536163330078125, 0.984375\n",
      "Train loss and acc of batch 23: 48.15721893310547, 0.984375\n",
      "Train loss and acc of batch 24: 48.53614807128906, 0.984375\n",
      "Train loss and acc of batch 25: 47.940433502197266, 1.0\n",
      "Train loss and acc of batch 26: 47.940425872802734, 1.0\n",
      "Train loss and acc of batch 27: 47.94042205810547, 1.0\n",
      "Train loss and acc of batch 28: 47.940406799316406, 1.0\n",
      "Train loss and acc of batch 29: 48.536102294921875, 0.984375\n",
      "Train loss and acc of batch 30: 47.94038772583008, 1.0\n",
      "Train loss and acc of batch 31: 48.157142639160156, 0.984375\n",
      "Train loss and acc of batch 32: 47.940372467041016, 1.0\n",
      "Train loss and acc of batch 33: 47.940364837646484, 1.0\n",
      "Train loss and acc of batch 34: 48.53605651855469, 0.984375\n",
      "Train loss and acc of batch 35: 48.37387466430664, 0.96875\n",
      "Train loss and acc of batch 36: 47.940338134765625, 1.0\n",
      "Train loss and acc of batch 37: 48.69355010986328, 0.984375\n",
      "Train loss and acc of batch 38: 49.28924560546875, 0.96875\n",
      "Train loss and acc of batch 39: 48.157073974609375, 0.984375\n",
      "Train loss and acc of batch 40: 47.94029998779297, 1.0\n",
      "Train loss and acc of batch 41: 49.28921890258789, 0.96875\n",
      "Train loss and acc of batch 42: 47.940284729003906, 1.0\n",
      "Train loss and acc of batch 43: 48.535972595214844, 0.984375\n",
      "Train loss and acc of batch 44: 47.94026565551758, 1.0\n",
      "Train loss and acc of batch 45: 48.53595733642578, 0.984375\n",
      "Train loss and acc of batch 46: 48.226104736328125, 0.984375\n",
      "Train loss and acc of batch 47: 47.940242767333984, 1.0\n",
      "Train loss and acc of batch 48: 47.94022750854492, 1.0\n",
      "Train loss and acc of batch 49: 47.940223693847656, 1.0\n",
      "Train loss and acc of batch 50: 48.535911560058594, 0.984375\n",
      "Train loss and acc of batch 51: 49.28913116455078, 0.96875\n",
      "Train loss and acc of batch 52: 49.19603729248047, 0.953125\n",
      "Train loss and acc of batch 53: 47.940181732177734, 1.0\n",
      "Train loss and acc of batch 54: 48.156944274902344, 0.984375\n",
      "Train loss and acc of batch 55: 47.94017028808594, 1.0\n",
      "Train loss and acc of batch 56: 47.94015884399414, 1.0\n",
      "Train loss and acc of batch 57: 48.535850524902344, 0.984375\n",
      "Train loss and acc of batch 58: 47.94013977050781, 1.0\n",
      "Train loss and acc of batch 59: 47.940128326416016, 1.0\n",
      "Train loss and acc of batch 60: 47.94012451171875, 1.0\n",
      "Train loss and acc of batch 61: 47.94011306762695, 1.0\n",
      "Train loss and acc of batch 62: 48.15686798095703, 0.984375\n",
      "Train loss and acc of batch 63: 49.131500244140625, 0.96875\n",
      "Train loss and acc of batch 64: 48.15684509277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.94007873535156, 1.0\n",
      "Train loss and acc of batch 66: 47.94007110595703, 1.0\n",
      "Train loss and acc of batch 67: 48.752525329589844, 0.96875\n",
      "Train loss and acc of batch 68: 48.53575134277344, 0.984375\n",
      "Train loss and acc of batch 69: 48.15680694580078, 0.984375\n",
      "Train loss and acc of batch 70: 47.94003677368164, 1.0\n",
      "Training accuracy and loss of epoch #187: 0.9890, 48.2714\n",
      "Saved model by train loss 48.27136155249367\n",
      "Train loss and acc of batch 0: 47.940025329589844, 1.0\n",
      "Train loss and acc of batch 1: 47.94001770019531, 1.0\n",
      "Train loss and acc of batch 2: 48.225860595703125, 0.984375\n",
      "Train loss and acc of batch 3: 48.156761169433594, 0.984375\n",
      "Train loss and acc of batch 4: 47.93999099731445, 1.0\n",
      "Train loss and acc of batch 5: 49.288902282714844, 0.96875\n",
      "Train loss and acc of batch 6: 48.442588806152344, 0.96875\n",
      "Train loss and acc of batch 7: 47.939964294433594, 1.0\n",
      "Train loss and acc of batch 8: 48.53565979003906, 0.984375\n",
      "Train loss and acc of batch 9: 48.225799560546875, 0.984375\n",
      "Train loss and acc of batch 10: 47.93993377685547, 1.0\n",
      "Train loss and acc of batch 11: 47.93992614746094, 1.0\n",
      "Train loss and acc of batch 12: 48.693145751953125, 0.984375\n",
      "Train loss and acc of batch 13: 48.15666961669922, 0.984375\n",
      "Train loss and acc of batch 14: 48.15666961669922, 0.984375\n",
      "Train loss and acc of batch 15: 48.53559112548828, 0.984375\n",
      "Train loss and acc of batch 16: 48.53558349609375, 0.984375\n",
      "Train loss and acc of batch 17: 48.69309616088867, 0.984375\n",
      "Train loss and acc of batch 18: 48.821414947509766, 0.96875\n",
      "Train loss and acc of batch 19: 47.93985366821289, 1.0\n",
      "Train loss and acc of batch 20: 47.939849853515625, 1.0\n",
      "Train loss and acc of batch 21: 48.53553771972656, 0.984375\n",
      "Train loss and acc of batch 22: 48.53553009033203, 0.984375\n",
      "Train loss and acc of batch 23: 47.9398193359375, 1.0\n",
      "Train loss and acc of batch 24: 48.53550720214844, 0.984375\n",
      "Train loss and acc of batch 25: 47.93980026245117, 1.0\n",
      "Train loss and acc of batch 26: 47.93979263305664, 1.0\n",
      "Train loss and acc of batch 27: 47.93978500366211, 1.0\n",
      "Train loss and acc of batch 28: 47.93977737426758, 1.0\n",
      "Train loss and acc of batch 29: 48.53546905517578, 0.984375\n",
      "Train loss and acc of batch 30: 47.939754486083984, 1.0\n",
      "Train loss and acc of batch 31: 48.156517028808594, 0.984375\n",
      "Train loss and acc of batch 32: 47.93974304199219, 1.0\n",
      "Train loss and acc of batch 33: 47.93973159790039, 1.0\n",
      "Train loss and acc of batch 34: 48.535423278808594, 0.984375\n",
      "Train loss and acc of batch 35: 48.37324142456055, 0.96875\n",
      "Train loss and acc of batch 36: 47.939701080322266, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 37: 48.69291305541992, 0.984375\n",
      "Train loss and acc of batch 38: 49.288604736328125, 0.96875\n",
      "Train loss and acc of batch 39: 48.15644073486328, 0.984375\n",
      "Train loss and acc of batch 40: 47.93967056274414, 1.0\n",
      "Train loss and acc of batch 41: 49.2885856628418, 0.96875\n",
      "Train loss and acc of batch 42: 47.93964767456055, 1.0\n",
      "Train loss and acc of batch 43: 48.53534698486328, 0.984375\n",
      "Train loss and acc of batch 44: 47.939632415771484, 1.0\n",
      "Train loss and acc of batch 45: 48.53533172607422, 0.984375\n",
      "Train loss and acc of batch 46: 48.22547149658203, 0.984375\n",
      "Train loss and acc of batch 47: 47.939605712890625, 1.0\n",
      "Train loss and acc of batch 48: 47.939598083496094, 1.0\n",
      "Train loss and acc of batch 49: 47.9395866394043, 1.0\n",
      "Train loss and acc of batch 50: 48.5352783203125, 0.984375\n",
      "Train loss and acc of batch 51: 49.28849792480469, 0.96875\n",
      "Train loss and acc of batch 52: 49.19540023803711, 0.953125\n",
      "Train loss and acc of batch 53: 47.939552307128906, 1.0\n",
      "Train loss and acc of batch 54: 48.15631103515625, 0.984375\n",
      "Train loss and acc of batch 55: 47.93953323364258, 1.0\n",
      "Train loss and acc of batch 56: 47.93952560424805, 1.0\n",
      "Train loss and acc of batch 57: 48.53522491455078, 0.984375\n",
      "Train loss and acc of batch 58: 47.93950653076172, 1.0\n",
      "Train loss and acc of batch 59: 47.93949890136719, 1.0\n",
      "Train loss and acc of batch 60: 47.939491271972656, 1.0\n",
      "Train loss and acc of batch 61: 47.93947982788086, 1.0\n",
      "Train loss and acc of batch 62: 48.15624237060547, 0.984375\n",
      "Train loss and acc of batch 63: 49.130863189697266, 0.96875\n",
      "Train loss and acc of batch 64: 48.156219482421875, 0.984375\n",
      "Train loss and acc of batch 65: 47.93944549560547, 1.0\n",
      "Train loss and acc of batch 66: 47.939430236816406, 1.0\n",
      "Train loss and acc of batch 67: 48.75189208984375, 0.96875\n",
      "Train loss and acc of batch 68: 48.535118103027344, 0.984375\n",
      "Train loss and acc of batch 69: 48.15617370605469, 0.984375\n",
      "Train loss and acc of batch 70: 47.93940353393555, 1.0\n",
      "Training accuracy and loss of epoch #188: 0.9892, 48.2677\n",
      "Saved model by train loss 48.26767548037247\n",
      "Train loss and acc of batch 0: 47.93939208984375, 1.0\n",
      "Train loss and acc of batch 1: 47.93938446044922, 1.0\n",
      "Train loss and acc of batch 2: 48.22522735595703, 0.984375\n",
      "Train loss and acc of batch 3: 48.1561279296875, 0.984375\n",
      "Train loss and acc of batch 4: 47.939353942871094, 1.0\n",
      "Train loss and acc of batch 5: 49.28826904296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.441951751708984, 0.96875\n",
      "Train loss and acc of batch 7: 47.9393310546875, 1.0\n",
      "Train loss and acc of batch 8: 48.53502655029297, 0.984375\n",
      "Train loss and acc of batch 9: 48.22516632080078, 0.984375\n",
      "Train loss and acc of batch 10: 47.939300537109375, 1.0\n",
      "Train loss and acc of batch 11: 47.939292907714844, 1.0\n",
      "Train loss and acc of batch 12: 48.692508697509766, 0.984375\n",
      "Train loss and acc of batch 13: 48.156044006347656, 0.984375\n",
      "Train loss and acc of batch 14: 48.156028747558594, 0.984375\n",
      "Train loss and acc of batch 15: 48.53495788574219, 0.984375\n",
      "Train loss and acc of batch 16: 48.534950256347656, 0.984375\n",
      "Train loss and acc of batch 17: 48.69246292114258, 0.984375\n",
      "Train loss and acc of batch 18: 48.82078552246094, 0.96875\n",
      "Train loss and acc of batch 19: 47.93922424316406, 1.0\n",
      "Train loss and acc of batch 20: 47.939212799072266, 1.0\n",
      "Train loss and acc of batch 21: 48.53490447998047, 0.984375\n",
      "Train loss and acc of batch 22: 48.53489685058594, 0.984375\n",
      "Train loss and acc of batch 23: 47.939186096191406, 1.0\n",
      "Train loss and acc of batch 24: 48.534881591796875, 0.984375\n",
      "Train loss and acc of batch 25: 47.93916320800781, 1.0\n",
      "Train loss and acc of batch 26: 47.93915939331055, 1.0\n",
      "Train loss and acc of batch 27: 47.939151763916016, 1.0\n",
      "Train loss and acc of batch 28: 47.939144134521484, 1.0\n",
      "Train loss and acc of batch 29: 48.53483581542969, 0.984375\n",
      "Train loss and acc of batch 30: 47.93912887573242, 1.0\n",
      "Train loss and acc of batch 31: 48.15587615966797, 0.984375\n",
      "Train loss and acc of batch 32: 47.93910598754883, 1.0\n",
      "Train loss and acc of batch 33: 47.93909454345703, 1.0\n",
      "Train loss and acc of batch 34: 48.5347900390625, 0.984375\n",
      "Train loss and acc of batch 35: 48.37260818481445, 0.96875\n",
      "Train loss and acc of batch 36: 47.9390754699707, 1.0\n",
      "Train loss and acc of batch 37: 48.692283630371094, 0.984375\n",
      "Train loss and acc of batch 38: 49.28797912597656, 0.96875\n",
      "Train loss and acc of batch 39: 48.15580749511719, 0.984375\n",
      "Train loss and acc of batch 40: 47.93903732299805, 1.0\n",
      "Train loss and acc of batch 41: 49.2879524230957, 0.96875\n",
      "Train loss and acc of batch 42: 47.93901443481445, 1.0\n",
      "Train loss and acc of batch 43: 48.534706115722656, 0.984375\n",
      "Train loss and acc of batch 44: 47.93899917602539, 1.0\n",
      "Train loss and acc of batch 45: 48.534690856933594, 0.984375\n",
      "Train loss and acc of batch 46: 48.22483825683594, 0.984375\n",
      "Train loss and acc of batch 47: 47.9389762878418, 1.0\n",
      "Train loss and acc of batch 48: 47.938961029052734, 1.0\n",
      "Train loss and acc of batch 49: 47.9389533996582, 1.0\n",
      "Train loss and acc of batch 50: 48.534645080566406, 0.984375\n",
      "Train loss and acc of batch 51: 49.287864685058594, 0.96875\n",
      "Train loss and acc of batch 52: 49.19477081298828, 0.953125\n",
      "Train loss and acc of batch 53: 47.93891906738281, 1.0\n",
      "Train loss and acc of batch 54: 48.155670166015625, 0.984375\n",
      "Train loss and acc of batch 55: 47.93890380859375, 1.0\n",
      "Train loss and acc of batch 56: 47.93888854980469, 1.0\n",
      "Train loss and acc of batch 57: 48.534584045410156, 0.984375\n",
      "Train loss and acc of batch 58: 47.938880920410156, 1.0\n",
      "Train loss and acc of batch 59: 47.938865661621094, 1.0\n",
      "Train loss and acc of batch 60: 47.93885803222656, 1.0\n",
      "Train loss and acc of batch 61: 47.938846588134766, 1.0\n",
      "Train loss and acc of batch 62: 48.155601501464844, 0.984375\n",
      "Train loss and acc of batch 63: 49.13023376464844, 0.96875\n",
      "Train loss and acc of batch 64: 48.15558624267578, 0.984375\n",
      "Train loss and acc of batch 65: 47.93880844116211, 1.0\n",
      "Train loss and acc of batch 66: 47.938804626464844, 1.0\n",
      "Train loss and acc of batch 67: 48.75126266479492, 0.96875\n",
      "Train loss and acc of batch 68: 48.53448486328125, 0.984375\n",
      "Train loss and acc of batch 69: 48.155540466308594, 0.984375\n",
      "Train loss and acc of batch 70: 47.93876266479492, 1.0\n",
      "Training accuracy and loss of epoch #189: 0.9892, 48.2670\n",
      "Saved model by train loss 48.267042025713856\n",
      "Train loss and acc of batch 0: 47.938758850097656, 1.0\n",
      "Train loss and acc of batch 1: 47.93875503540039, 1.0\n",
      "Train loss and acc of batch 2: 48.22459411621094, 0.984375\n",
      "Train loss and acc of batch 3: 48.155494689941406, 0.984375\n",
      "Train loss and acc of batch 4: 47.93872833251953, 1.0\n",
      "Train loss and acc of batch 5: 49.287635803222656, 0.96875\n",
      "Train loss and acc of batch 6: 48.441322326660156, 0.96875\n",
      "Train loss and acc of batch 7: 47.93869400024414, 1.0\n",
      "Train loss and acc of batch 8: 48.534385681152344, 0.984375\n",
      "Train loss and acc of batch 9: 48.22453308105469, 0.984375\n",
      "Train loss and acc of batch 10: 47.93867111206055, 1.0\n",
      "Train loss and acc of batch 11: 47.93865966796875, 1.0\n",
      "Train loss and acc of batch 12: 48.69187545776367, 0.984375\n",
      "Train loss and acc of batch 13: 48.15540313720703, 0.984375\n",
      "Train loss and acc of batch 14: 48.1553955078125, 0.984375\n",
      "Train loss and acc of batch 15: 48.534332275390625, 0.984375\n",
      "Train loss and acc of batch 16: 48.53431701660156, 0.984375\n",
      "Train loss and acc of batch 17: 48.691829681396484, 0.984375\n",
      "Train loss and acc of batch 18: 48.82014846801758, 0.96875\n",
      "Train loss and acc of batch 19: 47.93859100341797, 1.0\n",
      "Train loss and acc of batch 20: 47.93858337402344, 1.0\n",
      "Train loss and acc of batch 21: 48.534271240234375, 0.984375\n",
      "Train loss and acc of batch 22: 48.534263610839844, 0.984375\n",
      "Train loss and acc of batch 23: 47.93855667114258, 1.0\n",
      "Train loss and acc of batch 24: 48.53424835205078, 0.984375\n",
      "Train loss and acc of batch 25: 47.93853759765625, 1.0\n",
      "Train loss and acc of batch 26: 47.93852615356445, 1.0\n",
      "Train loss and acc of batch 27: 47.938514709472656, 1.0\n",
      "Train loss and acc of batch 28: 47.938507080078125, 1.0\n",
      "Train loss and acc of batch 29: 48.534202575683594, 0.984375\n",
      "Train loss and acc of batch 30: 47.9384880065918, 1.0\n",
      "Train loss and acc of batch 31: 48.155250549316406, 0.984375\n",
      "Train loss and acc of batch 32: 47.938480377197266, 1.0\n",
      "Train loss and acc of batch 33: 47.9384651184082, 1.0\n",
      "Train loss and acc of batch 34: 48.534156799316406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 35: 48.371971130371094, 0.96875\n",
      "Train loss and acc of batch 36: 47.93843460083008, 1.0\n",
      "Train loss and acc of batch 37: 48.691654205322266, 0.984375\n",
      "Train loss and acc of batch 38: 49.28734588623047, 0.96875\n",
      "Train loss and acc of batch 39: 48.155174255371094, 0.984375\n",
      "Train loss and acc of batch 40: 47.93840026855469, 1.0\n",
      "Train loss and acc of batch 41: 49.28731155395508, 0.96875\n",
      "Train loss and acc of batch 42: 47.938385009765625, 1.0\n",
      "Train loss and acc of batch 43: 48.534080505371094, 0.984375\n",
      "Train loss and acc of batch 44: 47.9383659362793, 1.0\n",
      "Train loss and acc of batch 45: 48.5340576171875, 0.984375\n",
      "Train loss and acc of batch 46: 48.22419738769531, 0.984375\n",
      "Train loss and acc of batch 47: 47.93833923339844, 1.0\n",
      "Train loss and acc of batch 48: 47.938331604003906, 1.0\n",
      "Train loss and acc of batch 49: 47.93832015991211, 1.0\n",
      "Train loss and acc of batch 50: 48.53401184082031, 0.984375\n",
      "Train loss and acc of batch 51: 49.2872314453125, 0.96875\n",
      "Train loss and acc of batch 52: 49.19413757324219, 0.953125\n",
      "Train loss and acc of batch 53: 47.93828582763672, 1.0\n",
      "Train loss and acc of batch 54: 48.15504455566406, 0.984375\n",
      "Train loss and acc of batch 55: 47.938262939453125, 1.0\n",
      "Train loss and acc of batch 56: 47.93825912475586, 1.0\n",
      "Train loss and acc of batch 57: 48.53395080566406, 0.984375\n",
      "Train loss and acc of batch 58: 47.93824005126953, 1.0\n",
      "Train loss and acc of batch 59: 47.938232421875, 1.0\n",
      "Train loss and acc of batch 60: 47.93822479248047, 1.0\n",
      "Train loss and acc of batch 61: 47.93821716308594, 1.0\n",
      "Train loss and acc of batch 62: 48.15497589111328, 0.984375\n",
      "Train loss and acc of batch 63: 49.12959671020508, 0.96875\n",
      "Train loss and acc of batch 64: 48.15495300292969, 0.984375\n",
      "Train loss and acc of batch 65: 47.93817901611328, 1.0\n",
      "Train loss and acc of batch 66: 47.93817138671875, 1.0\n",
      "Train loss and acc of batch 67: 48.75062561035156, 0.96875\n",
      "Train loss and acc of batch 68: 48.53385925292969, 0.984375\n",
      "Train loss and acc of batch 69: 48.1549072265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.938133239746094, 1.0\n",
      "Training accuracy and loss of epoch #190: 0.9892, 48.2664\n",
      "Saved model by train loss 48.26640910833654\n",
      "Train loss and acc of batch 0: 47.93812561035156, 1.0\n",
      "Train loss and acc of batch 1: 47.938114166259766, 1.0\n",
      "Train loss and acc of batch 2: 48.223960876464844, 0.984375\n",
      "Train loss and acc of batch 3: 48.15486145019531, 0.984375\n",
      "Train loss and acc of batch 4: 47.93809127807617, 1.0\n",
      "Train loss and acc of batch 5: 49.287010192871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.44068908691406, 0.96875\n",
      "Train loss and acc of batch 7: 47.93806076049805, 1.0\n",
      "Train loss and acc of batch 8: 48.53376007080078, 0.984375\n",
      "Train loss and acc of batch 9: 48.223899841308594, 0.984375\n",
      "Train loss and acc of batch 10: 47.93803787231445, 1.0\n",
      "Train loss and acc of batch 11: 47.93803024291992, 1.0\n",
      "Train loss and acc of batch 12: 48.69124221801758, 0.984375\n",
      "Train loss and acc of batch 13: 48.15476989746094, 0.984375\n",
      "Train loss and acc of batch 14: 48.15476989746094, 0.984375\n",
      "Train loss and acc of batch 15: 48.53369140625, 0.984375\n",
      "Train loss and acc of batch 16: 48.53368377685547, 0.984375\n",
      "Train loss and acc of batch 17: 48.69119644165039, 0.984375\n",
      "Train loss and acc of batch 18: 48.819522857666016, 0.96875\n",
      "Train loss and acc of batch 19: 47.937957763671875, 1.0\n",
      "Train loss and acc of batch 20: 47.93794250488281, 1.0\n",
      "Train loss and acc of batch 21: 48.53363800048828, 0.984375\n",
      "Train loss and acc of batch 22: 48.53363037109375, 0.984375\n",
      "Train loss and acc of batch 23: 47.93791961669922, 1.0\n",
      "Train loss and acc of batch 24: 48.53361511230469, 0.984375\n",
      "Train loss and acc of batch 25: 47.93790054321289, 1.0\n",
      "Train loss and acc of batch 26: 47.93789291381836, 1.0\n",
      "Train loss and acc of batch 27: 47.93788146972656, 1.0\n",
      "Train loss and acc of batch 28: 47.93788146972656, 1.0\n",
      "Train loss and acc of batch 29: 48.5335693359375, 0.984375\n",
      "Train loss and acc of batch 30: 47.93785858154297, 1.0\n",
      "Train loss and acc of batch 31: 48.15460968017578, 0.984375\n",
      "Train loss and acc of batch 32: 47.93783950805664, 1.0\n",
      "Train loss and acc of batch 33: 47.93783187866211, 1.0\n",
      "Train loss and acc of batch 34: 48.53352355957031, 0.984375\n",
      "Train loss and acc of batch 35: 48.371341705322266, 0.96875\n",
      "Train loss and acc of batch 36: 47.937808990478516, 1.0\n",
      "Train loss and acc of batch 37: 48.69102096557617, 0.984375\n",
      "Train loss and acc of batch 38: 49.286712646484375, 0.96875\n",
      "Train loss and acc of batch 39: 48.154541015625, 0.984375\n",
      "Train loss and acc of batch 40: 47.937767028808594, 1.0\n",
      "Train loss and acc of batch 41: 49.286685943603516, 0.96875\n",
      "Train loss and acc of batch 42: 47.93775177001953, 1.0\n",
      "Train loss and acc of batch 43: 48.53343963623047, 0.984375\n",
      "Train loss and acc of batch 44: 47.9377326965332, 1.0\n",
      "Train loss and acc of batch 45: 48.533424377441406, 0.984375\n",
      "Train loss and acc of batch 46: 48.22357177734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.93770980834961, 1.0\n",
      "Train loss and acc of batch 48: 47.93769454956055, 1.0\n",
      "Train loss and acc of batch 49: 47.93769073486328, 1.0\n",
      "Train loss and acc of batch 50: 48.53337860107422, 0.984375\n",
      "Train loss and acc of batch 51: 49.286598205566406, 0.96875\n",
      "Train loss and acc of batch 52: 49.19350051879883, 0.953125\n",
      "Train loss and acc of batch 53: 47.937652587890625, 1.0\n",
      "Train loss and acc of batch 54: 48.15440368652344, 0.984375\n",
      "Train loss and acc of batch 55: 47.93763732910156, 1.0\n",
      "Train loss and acc of batch 56: 47.9376220703125, 1.0\n",
      "Train loss and acc of batch 57: 48.53331756591797, 0.984375\n",
      "Train loss and acc of batch 58: 47.93760681152344, 1.0\n",
      "Train loss and acc of batch 59: 47.93759536743164, 1.0\n",
      "Train loss and acc of batch 60: 47.93758773803711, 1.0\n",
      "Train loss and acc of batch 61: 47.937583923339844, 1.0\n",
      "Train loss and acc of batch 62: 48.154335021972656, 0.984375\n",
      "Train loss and acc of batch 63: 49.12896728515625, 0.96875\n",
      "Train loss and acc of batch 64: 48.154319763183594, 0.984375\n",
      "Train loss and acc of batch 65: 47.93754577636719, 1.0\n",
      "Train loss and acc of batch 66: 47.937538146972656, 1.0\n",
      "Train loss and acc of batch 67: 48.749996185302734, 0.96875\n",
      "Train loss and acc of batch 68: 48.53321838378906, 0.984375\n",
      "Train loss and acc of batch 69: 48.154273986816406, 0.984375\n",
      "Train loss and acc of batch 70: 47.9375, 1.0\n",
      "Training accuracy and loss of epoch #191: 0.9892, 48.2658\n",
      "Saved model by train loss 48.265775814862316\n",
      "Train loss and acc of batch 0: 47.9374885559082, 1.0\n",
      "Train loss and acc of batch 1: 47.93748474121094, 1.0\n",
      "Train loss and acc of batch 2: 48.22332763671875, 0.984375\n",
      "Train loss and acc of batch 3: 48.15422821044922, 0.984375\n",
      "Train loss and acc of batch 4: 47.93745803833008, 1.0\n",
      "Train loss and acc of batch 5: 49.28636932373047, 0.96875\n",
      "Train loss and acc of batch 6: 48.44005584716797, 0.96875\n",
      "Train loss and acc of batch 7: 47.93743133544922, 1.0\n",
      "Train loss and acc of batch 8: 48.533119201660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.22325897216797, 0.984375\n",
      "Train loss and acc of batch 10: 47.937400817871094, 1.0\n",
      "Train loss and acc of batch 11: 47.93739318847656, 1.0\n",
      "Train loss and acc of batch 12: 48.690608978271484, 0.984375\n",
      "Train loss and acc of batch 13: 48.154144287109375, 0.984375\n",
      "Train loss and acc of batch 14: 48.15412902832031, 0.984375\n",
      "Train loss and acc of batch 15: 48.533058166503906, 0.984375\n",
      "Train loss and acc of batch 16: 48.533050537109375, 0.984375\n",
      "Train loss and acc of batch 17: 48.6905632019043, 0.984375\n",
      "Train loss and acc of batch 18: 48.818885803222656, 0.96875\n",
      "Train loss and acc of batch 19: 47.937320709228516, 1.0\n",
      "Train loss and acc of batch 20: 47.937313079833984, 1.0\n",
      "Train loss and acc of batch 21: 48.53301239013672, 0.984375\n",
      "Train loss and acc of batch 22: 48.532997131347656, 0.984375\n",
      "Train loss and acc of batch 23: 47.937286376953125, 1.0\n",
      "Train loss and acc of batch 24: 48.532981872558594, 0.984375\n",
      "Train loss and acc of batch 25: 47.9372673034668, 1.0\n",
      "Train loss and acc of batch 26: 47.93726348876953, 1.0\n",
      "Train loss and acc of batch 27: 47.93724822998047, 1.0\n",
      "Train loss and acc of batch 28: 47.93724060058594, 1.0\n",
      "Train loss and acc of batch 29: 48.532936096191406, 0.984375\n",
      "Train loss and acc of batch 30: 47.93722152709961, 1.0\n",
      "Train loss and acc of batch 31: 48.15398406982422, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 32: 47.93720626831055, 1.0\n",
      "Train loss and acc of batch 33: 47.93719482421875, 1.0\n",
      "Train loss and acc of batch 34: 48.53289031982422, 0.984375\n",
      "Train loss and acc of batch 35: 48.37071228027344, 0.96875\n",
      "Train loss and acc of batch 36: 47.93716812133789, 1.0\n",
      "Train loss and acc of batch 37: 48.69038391113281, 0.984375\n",
      "Train loss and acc of batch 38: 49.28607940673828, 0.96875\n",
      "Train loss and acc of batch 39: 48.153907775878906, 0.984375\n",
      "Train loss and acc of batch 40: 47.937137603759766, 1.0\n",
      "Train loss and acc of batch 41: 49.28605651855469, 0.96875\n",
      "Train loss and acc of batch 42: 47.93711853027344, 1.0\n",
      "Train loss and acc of batch 43: 48.532806396484375, 0.984375\n",
      "Train loss and acc of batch 44: 47.937095642089844, 1.0\n",
      "Train loss and acc of batch 45: 48.53279113769531, 0.984375\n",
      "Train loss and acc of batch 46: 48.222938537597656, 0.984375\n",
      "Train loss and acc of batch 47: 47.937068939208984, 1.0\n",
      "Train loss and acc of batch 48: 47.93706512451172, 1.0\n",
      "Train loss and acc of batch 49: 47.93705749511719, 1.0\n",
      "Train loss and acc of batch 50: 48.532745361328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.28595733642578, 0.96875\n",
      "Train loss and acc of batch 52: 49.19287109375, 0.953125\n",
      "Train loss and acc of batch 53: 47.93701934814453, 1.0\n",
      "Train loss and acc of batch 54: 48.153778076171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.9370002746582, 1.0\n",
      "Train loss and acc of batch 56: 47.936988830566406, 1.0\n",
      "Train loss and acc of batch 57: 48.532684326171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.93696975708008, 1.0\n",
      "Train loss and acc of batch 59: 47.93696594238281, 1.0\n",
      "Train loss and acc of batch 60: 47.93695831298828, 1.0\n",
      "Train loss and acc of batch 61: 47.936946868896484, 1.0\n",
      "Train loss and acc of batch 62: 48.15370178222656, 0.984375\n",
      "Train loss and acc of batch 63: 49.128334045410156, 0.96875\n",
      "Train loss and acc of batch 64: 48.1536865234375, 0.984375\n",
      "Train loss and acc of batch 65: 47.936912536621094, 1.0\n",
      "Train loss and acc of batch 66: 47.9369010925293, 1.0\n",
      "Train loss and acc of batch 67: 48.749359130859375, 0.96875\n",
      "Train loss and acc of batch 68: 48.53258514404297, 0.984375\n",
      "Train loss and acc of batch 69: 48.15364074707031, 0.984375\n",
      "Train loss and acc of batch 70: 47.936866760253906, 1.0\n",
      "Training accuracy and loss of epoch #192: 0.9892, 48.2651\n",
      "Saved model by train loss 48.26514198410679\n",
      "Train loss and acc of batch 0: 47.93686294555664, 1.0\n",
      "Train loss and acc of batch 1: 47.93684387207031, 1.0\n",
      "Train loss and acc of batch 2: 48.222694396972656, 0.984375\n",
      "Train loss and acc of batch 3: 48.153594970703125, 0.984375\n",
      "Train loss and acc of batch 4: 47.93682098388672, 1.0\n",
      "Train loss and acc of batch 5: 49.285736083984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.439422607421875, 0.96875\n",
      "Train loss and acc of batch 7: 47.936798095703125, 1.0\n",
      "Train loss and acc of batch 8: 48.532493591308594, 0.984375\n",
      "Train loss and acc of batch 9: 48.222633361816406, 0.984375\n",
      "Train loss and acc of batch 10: 47.936767578125, 1.0\n",
      "Train loss and acc of batch 11: 47.93675994873047, 1.0\n",
      "Train loss and acc of batch 12: 48.689979553222656, 0.984375\n",
      "Train loss and acc of batch 13: 48.15350341796875, 0.984375\n",
      "Train loss and acc of batch 14: 48.15350341796875, 0.984375\n",
      "Train loss and acc of batch 15: 48.53242492675781, 0.984375\n",
      "Train loss and acc of batch 16: 48.53241729736328, 0.984375\n",
      "Train loss and acc of batch 17: 48.6899299621582, 0.984375\n",
      "Train loss and acc of batch 18: 48.8182487487793, 0.96875\n",
      "Train loss and acc of batch 19: 47.93669128417969, 1.0\n",
      "Train loss and acc of batch 20: 47.936683654785156, 1.0\n",
      "Train loss and acc of batch 21: 48.532371520996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.53236389160156, 0.984375\n",
      "Train loss and acc of batch 23: 47.93665313720703, 1.0\n",
      "Train loss and acc of batch 24: 48.53234100341797, 0.984375\n",
      "Train loss and acc of batch 25: 47.93663787841797, 1.0\n",
      "Train loss and acc of batch 26: 47.93663024902344, 1.0\n",
      "Train loss and acc of batch 27: 47.93661880493164, 1.0\n",
      "Train loss and acc of batch 28: 47.93661117553711, 1.0\n",
      "Train loss and acc of batch 29: 48.53230285644531, 0.984375\n",
      "Train loss and acc of batch 30: 47.936588287353516, 1.0\n",
      "Train loss and acc of batch 31: 48.153350830078125, 0.984375\n",
      "Train loss and acc of batch 32: 47.93656921386719, 1.0\n",
      "Train loss and acc of batch 33: 47.93656921386719, 1.0\n",
      "Train loss and acc of batch 34: 48.532264709472656, 0.984375\n",
      "Train loss and acc of batch 35: 48.37007522583008, 0.96875\n",
      "Train loss and acc of batch 36: 47.93653869628906, 1.0\n",
      "Train loss and acc of batch 37: 48.68975067138672, 0.984375\n",
      "Train loss and acc of batch 38: 49.28544616699219, 0.96875\n",
      "Train loss and acc of batch 39: 48.15327453613281, 0.984375\n",
      "Train loss and acc of batch 40: 47.936500549316406, 1.0\n",
      "Train loss and acc of batch 41: 49.28541946411133, 0.96875\n",
      "Train loss and acc of batch 42: 47.936485290527344, 1.0\n",
      "Train loss and acc of batch 43: 48.53217315673828, 0.984375\n",
      "Train loss and acc of batch 44: 47.93647003173828, 1.0\n",
      "Train loss and acc of batch 45: 48.53215789794922, 0.984375\n",
      "Train loss and acc of batch 46: 48.22229766845703, 0.984375\n",
      "Train loss and acc of batch 47: 47.936439514160156, 1.0\n",
      "Train loss and acc of batch 48: 47.936431884765625, 1.0\n",
      "Train loss and acc of batch 49: 47.93642044067383, 1.0\n",
      "Train loss and acc of batch 50: 48.53211212158203, 0.984375\n",
      "Train loss and acc of batch 51: 49.28532409667969, 0.96875\n",
      "Train loss and acc of batch 52: 49.192237854003906, 0.953125\n",
      "Train loss and acc of batch 53: 47.93638610839844, 1.0\n",
      "Train loss and acc of batch 54: 48.15313720703125, 0.984375\n",
      "Train loss and acc of batch 55: 47.93636703491211, 1.0\n",
      "Train loss and acc of batch 56: 47.93635940551758, 1.0\n",
      "Train loss and acc of batch 57: 48.53205108642578, 0.984375\n",
      "Train loss and acc of batch 58: 47.936344146728516, 1.0\n",
      "Train loss and acc of batch 59: 47.93633270263672, 1.0\n",
      "Train loss and acc of batch 60: 47.93632125854492, 1.0\n",
      "Train loss and acc of batch 61: 47.93631362915039, 1.0\n",
      "Train loss and acc of batch 62: 48.153076171875, 0.984375\n",
      "Train loss and acc of batch 63: 49.1276969909668, 0.96875\n",
      "Train loss and acc of batch 64: 48.153053283691406, 0.984375\n",
      "Train loss and acc of batch 65: 47.936275482177734, 1.0\n",
      "Train loss and acc of batch 66: 47.93627166748047, 1.0\n",
      "Train loss and acc of batch 67: 48.74872970581055, 0.96875\n",
      "Train loss and acc of batch 68: 48.531944274902344, 0.984375\n",
      "Train loss and acc of batch 69: 48.15300750732422, 0.984375\n",
      "Train loss and acc of batch 70: 47.93623352050781, 1.0\n",
      "Training accuracy and loss of epoch #193: 0.9892, 48.2645\n",
      "Saved model by train loss 48.26450901300135\n",
      "Train loss and acc of batch 0: 47.936222076416016, 1.0\n",
      "Train loss and acc of batch 1: 47.93621826171875, 1.0\n",
      "Train loss and acc of batch 2: 48.22206115722656, 0.984375\n",
      "Train loss and acc of batch 3: 48.15296173095703, 0.984375\n",
      "Train loss and acc of batch 4: 47.936187744140625, 1.0\n",
      "Train loss and acc of batch 5: 49.28511047363281, 0.96875\n",
      "Train loss and acc of batch 6: 48.43878936767578, 0.96875\n",
      "Train loss and acc of batch 7: 47.93616485595703, 1.0\n",
      "Train loss and acc of batch 8: 48.53185272216797, 0.984375\n",
      "Train loss and acc of batch 9: 48.22200012207031, 0.984375\n",
      "Train loss and acc of batch 10: 47.93613815307617, 1.0\n",
      "Train loss and acc of batch 11: 47.936119079589844, 1.0\n",
      "Train loss and acc of batch 12: 48.6893424987793, 0.984375\n",
      "Train loss and acc of batch 13: 48.15287780761719, 0.984375\n",
      "Train loss and acc of batch 14: 48.152862548828125, 0.984375\n",
      "Train loss and acc of batch 15: 48.53179168701172, 0.984375\n",
      "Train loss and acc of batch 16: 48.53178405761719, 0.984375\n",
      "Train loss and acc of batch 17: 48.689292907714844, 0.984375\n",
      "Train loss and acc of batch 18: 48.81761932373047, 0.96875\n",
      "Train loss and acc of batch 19: 47.93605422973633, 1.0\n",
      "Train loss and acc of batch 20: 47.9360466003418, 1.0\n",
      "Train loss and acc of batch 21: 48.53173828125, 0.984375\n",
      "Train loss and acc of batch 22: 48.53173065185547, 0.984375\n",
      "Train loss and acc of batch 23: 47.9360237121582, 1.0\n",
      "Train loss and acc of batch 24: 48.531715393066406, 0.984375\n",
      "Train loss and acc of batch 25: 47.935997009277344, 1.0\n",
      "Train loss and acc of batch 26: 47.935997009277344, 1.0\n",
      "Train loss and acc of batch 27: 47.93598175048828, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 28: 47.935977935791016, 1.0\n",
      "Train loss and acc of batch 29: 48.53166961669922, 0.984375\n",
      "Train loss and acc of batch 30: 47.93595886230469, 1.0\n",
      "Train loss and acc of batch 31: 48.1527099609375, 0.984375\n",
      "Train loss and acc of batch 32: 47.93593978881836, 1.0\n",
      "Train loss and acc of batch 33: 47.93592834472656, 1.0\n",
      "Train loss and acc of batch 34: 48.53162384033203, 0.984375\n",
      "Train loss and acc of batch 35: 48.369441986083984, 0.96875\n",
      "Train loss and acc of batch 36: 47.93590545654297, 1.0\n",
      "Train loss and acc of batch 37: 48.68912124633789, 0.984375\n",
      "Train loss and acc of batch 38: 49.284812927246094, 0.96875\n",
      "Train loss and acc of batch 39: 48.15264129638672, 0.984375\n",
      "Train loss and acc of batch 40: 47.93586730957031, 1.0\n",
      "Train loss and acc of batch 41: 49.284786224365234, 0.96875\n",
      "Train loss and acc of batch 42: 47.935848236083984, 1.0\n",
      "Train loss and acc of batch 43: 48.53154754638672, 0.984375\n",
      "Train loss and acc of batch 44: 47.93583297729492, 1.0\n",
      "Train loss and acc of batch 45: 48.531524658203125, 0.984375\n",
      "Train loss and acc of batch 46: 48.22166442871094, 0.984375\n",
      "Train loss and acc of batch 47: 47.93580627441406, 1.0\n",
      "Train loss and acc of batch 48: 47.935794830322266, 1.0\n",
      "Train loss and acc of batch 49: 47.935791015625, 1.0\n",
      "Train loss and acc of batch 50: 48.53147888183594, 0.984375\n",
      "Train loss and acc of batch 51: 49.284698486328125, 0.96875\n",
      "Train loss and acc of batch 52: 49.19159698486328, 0.953125\n",
      "Train loss and acc of batch 53: 47.93575668334961, 1.0\n",
      "Train loss and acc of batch 54: 48.152503967285156, 0.984375\n",
      "Train loss and acc of batch 55: 47.935733795166016, 1.0\n",
      "Train loss and acc of batch 56: 47.935726165771484, 1.0\n",
      "Train loss and acc of batch 57: 48.53141784667969, 0.984375\n",
      "Train loss and acc of batch 58: 47.935707092285156, 1.0\n",
      "Train loss and acc of batch 59: 47.935699462890625, 1.0\n",
      "Train loss and acc of batch 60: 47.935691833496094, 1.0\n",
      "Train loss and acc of batch 61: 47.9356803894043, 1.0\n",
      "Train loss and acc of batch 62: 48.152435302734375, 0.984375\n",
      "Train loss and acc of batch 63: 49.12706756591797, 0.96875\n",
      "Train loss and acc of batch 64: 48.15242004394531, 0.984375\n",
      "Train loss and acc of batch 65: 47.93564987182617, 1.0\n",
      "Train loss and acc of batch 66: 47.935638427734375, 1.0\n",
      "Train loss and acc of batch 67: 48.74809265136719, 0.96875\n",
      "Train loss and acc of batch 68: 48.53131866455078, 0.984375\n",
      "Train loss and acc of batch 69: 48.152374267578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.93560028076172, 1.0\n",
      "Training accuracy and loss of epoch #194: 0.9892, 48.2639\n",
      "Saved model by train loss 48.26387555834273\n",
      "Train loss and acc of batch 0: 47.93559265136719, 1.0\n",
      "Train loss and acc of batch 1: 47.935585021972656, 1.0\n",
      "Train loss and acc of batch 2: 48.22142791748047, 0.984375\n",
      "Train loss and acc of batch 3: 48.15232849121094, 0.984375\n",
      "Train loss and acc of batch 4: 47.9355583190918, 1.0\n",
      "Train loss and acc of batch 5: 49.28446960449219, 0.96875\n",
      "Train loss and acc of batch 6: 48.43815612792969, 0.96875\n",
      "Train loss and acc of batch 7: 47.93552780151367, 1.0\n",
      "Train loss and acc of batch 8: 48.531219482421875, 0.984375\n",
      "Train loss and acc of batch 9: 48.22136688232422, 0.984375\n",
      "Train loss and acc of batch 10: 47.93550491333008, 1.0\n",
      "Train loss and acc of batch 11: 47.93549728393555, 1.0\n",
      "Train loss and acc of batch 12: 48.6887092590332, 0.984375\n",
      "Train loss and acc of batch 13: 48.152244567871094, 0.984375\n",
      "Train loss and acc of batch 14: 48.15222930908203, 0.984375\n",
      "Train loss and acc of batch 15: 48.531158447265625, 0.984375\n",
      "Train loss and acc of batch 16: 48.531150817871094, 0.984375\n",
      "Train loss and acc of batch 17: 48.68866729736328, 0.984375\n",
      "Train loss and acc of batch 18: 48.816986083984375, 0.96875\n",
      "Train loss and acc of batch 19: 47.935420989990234, 1.0\n",
      "Train loss and acc of batch 20: 47.9354133605957, 1.0\n",
      "Train loss and acc of batch 21: 48.531105041503906, 0.984375\n",
      "Train loss and acc of batch 22: 48.531097412109375, 0.984375\n",
      "Train loss and acc of batch 23: 47.93539047241211, 1.0\n",
      "Train loss and acc of batch 24: 48.53107452392578, 0.984375\n",
      "Train loss and acc of batch 25: 47.93537139892578, 1.0\n",
      "Train loss and acc of batch 26: 47.935359954833984, 1.0\n",
      "Train loss and acc of batch 27: 47.93534851074219, 1.0\n",
      "Train loss and acc of batch 28: 47.935340881347656, 1.0\n",
      "Train loss and acc of batch 29: 48.531036376953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.935325622558594, 1.0\n",
      "Train loss and acc of batch 31: 48.15208435058594, 0.984375\n",
      "Train loss and acc of batch 32: 47.93531036376953, 1.0\n",
      "Train loss and acc of batch 33: 47.93529510498047, 1.0\n",
      "Train loss and acc of batch 34: 48.53099060058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.368804931640625, 0.96875\n",
      "Train loss and acc of batch 36: 47.935272216796875, 1.0\n",
      "Train loss and acc of batch 37: 48.6884880065918, 0.984375\n",
      "Train loss and acc of batch 38: 49.2841796875, 0.96875\n",
      "Train loss and acc of batch 39: 48.152015686035156, 0.984375\n",
      "Train loss and acc of batch 40: 47.93523406982422, 1.0\n",
      "Train loss and acc of batch 41: 49.284149169921875, 0.96875\n",
      "Train loss and acc of batch 42: 47.935218811035156, 1.0\n",
      "Train loss and acc of batch 43: 48.530906677246094, 0.984375\n",
      "Train loss and acc of batch 44: 47.93519973754883, 1.0\n",
      "Train loss and acc of batch 45: 48.53089141845703, 0.984375\n",
      "Train loss and acc of batch 46: 48.221031188964844, 0.984375\n",
      "Train loss and acc of batch 47: 47.9351692199707, 1.0\n",
      "Train loss and acc of batch 48: 47.93516540527344, 1.0\n",
      "Train loss and acc of batch 49: 47.93515396118164, 1.0\n",
      "Train loss and acc of batch 50: 48.530853271484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.28406524658203, 0.96875\n",
      "Train loss and acc of batch 52: 49.19096755981445, 0.953125\n",
      "Train loss and acc of batch 53: 47.93511962890625, 1.0\n",
      "Train loss and acc of batch 54: 48.151878356933594, 0.984375\n",
      "Train loss and acc of batch 55: 47.93510055541992, 1.0\n",
      "Train loss and acc of batch 56: 47.935089111328125, 1.0\n",
      "Train loss and acc of batch 57: 48.530784606933594, 0.984375\n",
      "Train loss and acc of batch 58: 47.93507385253906, 1.0\n",
      "Train loss and acc of batch 59: 47.93506622314453, 1.0\n",
      "Train loss and acc of batch 60: 47.935062408447266, 1.0\n",
      "Train loss and acc of batch 61: 47.9350471496582, 1.0\n",
      "Train loss and acc of batch 62: 48.15180206298828, 0.984375\n",
      "Train loss and acc of batch 63: 49.12643051147461, 0.96875\n",
      "Train loss and acc of batch 64: 48.15178680419922, 0.984375\n",
      "Train loss and acc of batch 65: 47.93501281738281, 1.0\n",
      "Train loss and acc of batch 66: 47.93500518798828, 1.0\n",
      "Train loss and acc of batch 67: 48.74746322631836, 0.96875\n",
      "Train loss and acc of batch 68: 48.53069305419922, 0.984375\n",
      "Train loss and acc of batch 69: 48.15174102783203, 0.984375\n",
      "Train loss and acc of batch 70: 47.93496322631836, 1.0\n",
      "Training accuracy and loss of epoch #195: 0.9892, 48.2632\n",
      "Saved model by train loss 48.26324269469355\n",
      "Train loss and acc of batch 0: 47.934959411621094, 1.0\n",
      "Train loss and acc of batch 1: 47.9349479675293, 1.0\n",
      "Train loss and acc of batch 2: 48.220794677734375, 0.984375\n",
      "Train loss and acc of batch 3: 48.151695251464844, 0.984375\n",
      "Train loss and acc of batch 4: 47.9349250793457, 1.0\n",
      "Train loss and acc of batch 5: 49.283836364746094, 0.96875\n",
      "Train loss and acc of batch 6: 48.437522888183594, 0.96875\n",
      "Train loss and acc of batch 7: 47.934898376464844, 1.0\n",
      "Train loss and acc of batch 8: 48.53059387207031, 0.984375\n",
      "Train loss and acc of batch 9: 48.220726013183594, 0.984375\n",
      "Train loss and acc of batch 10: 47.934871673583984, 1.0\n",
      "Train loss and acc of batch 11: 47.93486404418945, 1.0\n",
      "Train loss and acc of batch 12: 48.68807601928711, 0.984375\n",
      "Train loss and acc of batch 13: 48.15160369873047, 0.984375\n",
      "Train loss and acc of batch 14: 48.15159606933594, 0.984375\n",
      "Train loss and acc of batch 15: 48.53052520751953, 0.984375\n",
      "Train loss and acc of batch 16: 48.530517578125, 0.984375\n",
      "Train loss and acc of batch 17: 48.68803405761719, 0.984375\n",
      "Train loss and acc of batch 18: 48.81635284423828, 0.96875\n",
      "Train loss and acc of batch 19: 47.93478775024414, 1.0\n",
      "Train loss and acc of batch 20: 47.934776306152344, 1.0\n",
      "Train loss and acc of batch 21: 48.53047180175781, 0.984375\n",
      "Train loss and acc of batch 22: 48.53046417236328, 0.984375\n",
      "Train loss and acc of batch 23: 47.93475341796875, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 24: 48.53044891357422, 0.984375\n",
      "Train loss and acc of batch 25: 47.93473815917969, 1.0\n",
      "Train loss and acc of batch 26: 47.93472671508789, 1.0\n",
      "Train loss and acc of batch 27: 47.934715270996094, 1.0\n",
      "Train loss and acc of batch 28: 47.93470764160156, 1.0\n",
      "Train loss and acc of batch 29: 48.53040313720703, 0.984375\n",
      "Train loss and acc of batch 30: 47.9346923828125, 1.0\n",
      "Train loss and acc of batch 31: 48.151451110839844, 0.984375\n",
      "Train loss and acc of batch 32: 47.93467330932617, 1.0\n",
      "Train loss and acc of batch 33: 47.93466567993164, 1.0\n",
      "Train loss and acc of batch 34: 48.530357360839844, 0.984375\n",
      "Train loss and acc of batch 35: 48.36817932128906, 0.96875\n",
      "Train loss and acc of batch 36: 47.93463897705078, 1.0\n",
      "Train loss and acc of batch 37: 48.68785095214844, 0.984375\n",
      "Train loss and acc of batch 38: 49.283546447753906, 0.96875\n",
      "Train loss and acc of batch 39: 48.15138244628906, 0.984375\n",
      "Train loss and acc of batch 40: 47.934600830078125, 1.0\n",
      "Train loss and acc of batch 41: 49.28351974487305, 0.96875\n",
      "Train loss and acc of batch 42: 47.9345817565918, 1.0\n",
      "Train loss and acc of batch 43: 48.5302734375, 0.984375\n",
      "Train loss and acc of batch 44: 47.934566497802734, 1.0\n",
      "Train loss and acc of batch 45: 48.53025817871094, 0.984375\n",
      "Train loss and acc of batch 46: 48.22039794921875, 0.984375\n",
      "Train loss and acc of batch 47: 47.934539794921875, 1.0\n",
      "Train loss and acc of batch 48: 47.93452835083008, 1.0\n",
      "Train loss and acc of batch 49: 47.93452072143555, 1.0\n",
      "Train loss and acc of batch 50: 48.53021240234375, 0.984375\n",
      "Train loss and acc of batch 51: 49.28343200683594, 0.96875\n",
      "Train loss and acc of batch 52: 49.190338134765625, 0.953125\n",
      "Train loss and acc of batch 53: 47.93449020385742, 1.0\n",
      "Train loss and acc of batch 54: 48.1512451171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.93446731567383, 1.0\n",
      "Train loss and acc of batch 56: 47.9344596862793, 1.0\n",
      "Train loss and acc of batch 57: 48.5301513671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.934444427490234, 1.0\n",
      "Train loss and acc of batch 59: 47.93442916870117, 1.0\n",
      "Train loss and acc of batch 60: 47.934425354003906, 1.0\n",
      "Train loss and acc of batch 61: 47.93441390991211, 1.0\n",
      "Train loss and acc of batch 62: 48.15116882324219, 0.984375\n",
      "Train loss and acc of batch 63: 49.12580108642578, 0.96875\n",
      "Train loss and acc of batch 64: 48.151153564453125, 0.984375\n",
      "Train loss and acc of batch 65: 47.93437576293945, 1.0\n",
      "Train loss and acc of batch 66: 47.93437194824219, 1.0\n",
      "Train loss and acc of batch 67: 48.746829986572266, 0.96875\n",
      "Train loss and acc of batch 68: 48.530052185058594, 0.984375\n",
      "Train loss and acc of batch 69: 48.15110778808594, 0.984375\n",
      "Train loss and acc of batch 70: 47.9343376159668, 1.0\n",
      "Training accuracy and loss of epoch #196: 0.9892, 48.2626\n",
      "Saved model by train loss 48.26260940121933\n",
      "Train loss and acc of batch 0: 47.934322357177734, 1.0\n",
      "Train loss and acc of batch 1: 47.93431854248047, 1.0\n",
      "Train loss and acc of batch 2: 48.22015380859375, 0.984375\n",
      "Train loss and acc of batch 3: 48.15106201171875, 0.984375\n",
      "Train loss and acc of batch 4: 47.93429183959961, 1.0\n",
      "Train loss and acc of batch 5: 49.283203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.4368896484375, 0.96875\n",
      "Train loss and acc of batch 7: 47.934261322021484, 1.0\n",
      "Train loss and acc of batch 8: 48.52995300292969, 0.984375\n",
      "Train loss and acc of batch 9: 48.22010040283203, 0.984375\n",
      "Train loss and acc of batch 10: 47.93423843383789, 1.0\n",
      "Train loss and acc of batch 11: 47.934226989746094, 1.0\n",
      "Train loss and acc of batch 12: 48.687442779541016, 0.984375\n",
      "Train loss and acc of batch 13: 48.150978088378906, 0.984375\n",
      "Train loss and acc of batch 14: 48.150962829589844, 0.984375\n",
      "Train loss and acc of batch 15: 48.52989196777344, 0.984375\n",
      "Train loss and acc of batch 16: 48.529876708984375, 0.984375\n",
      "Train loss and acc of batch 17: 48.68739700317383, 0.984375\n",
      "Train loss and acc of batch 18: 48.81571960449219, 0.96875\n",
      "Train loss and acc of batch 19: 47.93415832519531, 1.0\n",
      "Train loss and acc of batch 20: 47.93415069580078, 1.0\n",
      "Train loss and acc of batch 21: 48.52983856201172, 0.984375\n",
      "Train loss and acc of batch 22: 48.52983093261719, 0.984375\n",
      "Train loss and acc of batch 23: 47.93411636352539, 1.0\n",
      "Train loss and acc of batch 24: 48.529815673828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.93410110473633, 1.0\n",
      "Train loss and acc of batch 26: 47.9340934753418, 1.0\n",
      "Train loss and acc of batch 27: 47.934085845947266, 1.0\n",
      "Train loss and acc of batch 28: 47.934078216552734, 1.0\n",
      "Train loss and acc of batch 29: 48.52976989746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.93405532836914, 1.0\n",
      "Train loss and acc of batch 31: 48.15081024169922, 0.984375\n",
      "Train loss and acc of batch 32: 47.934043884277344, 1.0\n",
      "Train loss and acc of batch 33: 47.93402862548828, 1.0\n",
      "Train loss and acc of batch 34: 48.52972412109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.3675422668457, 0.96875\n",
      "Train loss and acc of batch 36: 47.93400192260742, 1.0\n",
      "Train loss and acc of batch 37: 48.68722152709961, 0.984375\n",
      "Train loss and acc of batch 38: 49.28291320800781, 0.96875\n",
      "Train loss and acc of batch 39: 48.15074157714844, 0.984375\n",
      "Train loss and acc of batch 40: 47.93396759033203, 1.0\n",
      "Train loss and acc of batch 41: 49.28288650512695, 0.96875\n",
      "Train loss and acc of batch 42: 47.93395233154297, 1.0\n",
      "Train loss and acc of batch 43: 48.52964782714844, 0.984375\n",
      "Train loss and acc of batch 44: 47.933929443359375, 1.0\n",
      "Train loss and acc of batch 45: 48.529624938964844, 0.984375\n",
      "Train loss and acc of batch 46: 48.21977233886719, 0.984375\n",
      "Train loss and acc of batch 47: 47.93390655517578, 1.0\n",
      "Train loss and acc of batch 48: 47.93389892578125, 1.0\n",
      "Train loss and acc of batch 49: 47.93389129638672, 1.0\n",
      "Train loss and acc of batch 50: 48.529579162597656, 0.984375\n",
      "Train loss and acc of batch 51: 49.282798767089844, 0.96875\n",
      "Train loss and acc of batch 52: 49.18970489501953, 0.953125\n",
      "Train loss and acc of batch 53: 47.93385314941406, 1.0\n",
      "Train loss and acc of batch 54: 48.150611877441406, 0.984375\n",
      "Train loss and acc of batch 55: 47.933837890625, 1.0\n",
      "Train loss and acc of batch 56: 47.93383026123047, 1.0\n",
      "Train loss and acc of batch 57: 48.529518127441406, 0.984375\n",
      "Train loss and acc of batch 58: 47.93380355834961, 1.0\n",
      "Train loss and acc of batch 59: 47.933799743652344, 1.0\n",
      "Train loss and acc of batch 60: 47.93379211425781, 1.0\n",
      "Train loss and acc of batch 61: 47.933780670166016, 1.0\n",
      "Train loss and acc of batch 62: 48.150535583496094, 0.984375\n",
      "Train loss and acc of batch 63: 49.12516784667969, 0.96875\n",
      "Train loss and acc of batch 64: 48.15052032470703, 0.984375\n",
      "Train loss and acc of batch 65: 47.93375015258789, 1.0\n",
      "Train loss and acc of batch 66: 47.93373489379883, 1.0\n",
      "Train loss and acc of batch 67: 48.74618911743164, 0.96875\n",
      "Train loss and acc of batch 68: 48.5294189453125, 0.984375\n",
      "Train loss and acc of batch 69: 48.15046691894531, 0.984375\n",
      "Train loss and acc of batch 70: 47.93370056152344, 1.0\n",
      "Training accuracy and loss of epoch #197: 0.9892, 48.2620\n",
      "Saved model by train loss 48.26197583910445\n",
      "Train loss and acc of batch 0: 47.933692932128906, 1.0\n",
      "Train loss and acc of batch 1: 47.93368148803711, 1.0\n",
      "Train loss and acc of batch 2: 48.219520568847656, 0.984375\n",
      "Train loss and acc of batch 3: 48.150428771972656, 0.984375\n",
      "Train loss and acc of batch 4: 47.933650970458984, 1.0\n",
      "Train loss and acc of batch 5: 49.282569885253906, 0.96875\n",
      "Train loss and acc of batch 6: 48.43625259399414, 0.96875\n",
      "Train loss and acc of batch 7: 47.93362808227539, 1.0\n",
      "Train loss and acc of batch 8: 48.529319763183594, 0.984375\n",
      "Train loss and acc of batch 9: 48.21946716308594, 0.984375\n",
      "Train loss and acc of batch 10: 47.933597564697266, 1.0\n",
      "Train loss and acc of batch 11: 47.933597564697266, 1.0\n",
      "Train loss and acc of batch 12: 48.686805725097656, 0.984375\n",
      "Train loss and acc of batch 13: 48.15033721923828, 0.984375\n",
      "Train loss and acc of batch 14: 48.15032958984375, 0.984375\n",
      "Train loss and acc of batch 15: 48.529258728027344, 0.984375\n",
      "Train loss and acc of batch 16: 48.52924346923828, 0.984375\n",
      "Train loss and acc of batch 17: 48.686763763427734, 0.984375\n",
      "Train loss and acc of batch 18: 48.81507873535156, 0.96875\n",
      "Train loss and acc of batch 19: 47.93352127075195, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 20: 47.933509826660156, 1.0\n",
      "Train loss and acc of batch 21: 48.529205322265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.529197692871094, 0.984375\n",
      "Train loss and acc of batch 23: 47.93347930908203, 1.0\n",
      "Train loss and acc of batch 24: 48.5291748046875, 0.984375\n",
      "Train loss and acc of batch 25: 47.93346405029297, 1.0\n",
      "Train loss and acc of batch 26: 47.93345642089844, 1.0\n",
      "Train loss and acc of batch 27: 47.93345260620117, 1.0\n",
      "Train loss and acc of batch 28: 47.933441162109375, 1.0\n",
      "Train loss and acc of batch 29: 48.52912902832031, 0.984375\n",
      "Train loss and acc of batch 30: 47.93342208862305, 1.0\n",
      "Train loss and acc of batch 31: 48.150177001953125, 0.984375\n",
      "Train loss and acc of batch 32: 47.93340301513672, 1.0\n",
      "Train loss and acc of batch 33: 47.93339538574219, 1.0\n",
      "Train loss and acc of batch 34: 48.529083251953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.366905212402344, 0.96875\n",
      "Train loss and acc of batch 36: 47.93336868286133, 1.0\n",
      "Train loss and acc of batch 37: 48.68658447265625, 0.984375\n",
      "Train loss and acc of batch 38: 49.28227233886719, 0.96875\n",
      "Train loss and acc of batch 39: 48.15010070800781, 0.984375\n",
      "Train loss and acc of batch 40: 47.93333435058594, 1.0\n",
      "Train loss and acc of batch 41: 49.282249450683594, 0.96875\n",
      "Train loss and acc of batch 42: 47.933319091796875, 1.0\n",
      "Train loss and acc of batch 43: 48.52900695800781, 0.984375\n",
      "Train loss and acc of batch 44: 47.93330001831055, 1.0\n",
      "Train loss and acc of batch 45: 48.52899169921875, 0.984375\n",
      "Train loss and acc of batch 46: 48.21913146972656, 0.984375\n",
      "Train loss and acc of batch 47: 47.93326950073242, 1.0\n",
      "Train loss and acc of batch 48: 47.93326187133789, 1.0\n",
      "Train loss and acc of batch 49: 47.933250427246094, 1.0\n",
      "Train loss and acc of batch 50: 48.528953552246094, 0.984375\n",
      "Train loss and acc of batch 51: 49.28215789794922, 0.96875\n",
      "Train loss and acc of batch 52: 49.189064025878906, 0.953125\n",
      "Train loss and acc of batch 53: 47.9332160949707, 1.0\n",
      "Train loss and acc of batch 54: 48.14997100830078, 0.984375\n",
      "Train loss and acc of batch 55: 47.93320083618164, 1.0\n",
      "Train loss and acc of batch 56: 47.93319320678711, 1.0\n",
      "Train loss and acc of batch 57: 48.52888488769531, 0.984375\n",
      "Train loss and acc of batch 58: 47.93317794799805, 1.0\n",
      "Train loss and acc of batch 59: 47.933162689208984, 1.0\n",
      "Train loss and acc of batch 60: 47.93315505981445, 1.0\n",
      "Train loss and acc of batch 61: 47.93314743041992, 1.0\n",
      "Train loss and acc of batch 62: 48.14989471435547, 0.984375\n",
      "Train loss and acc of batch 63: 49.12453079223633, 0.96875\n",
      "Train loss and acc of batch 64: 48.149879455566406, 0.984375\n",
      "Train loss and acc of batch 65: 47.93311309814453, 1.0\n",
      "Train loss and acc of batch 66: 47.93309783935547, 1.0\n",
      "Train loss and acc of batch 67: 48.74555587768555, 0.96875\n",
      "Train loss and acc of batch 68: 48.528785705566406, 0.984375\n",
      "Train loss and acc of batch 69: 48.14984130859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.933067321777344, 1.0\n",
      "Training accuracy and loss of epoch #198: 0.9892, 48.2613\n",
      "Saved model by train loss 48.26133991295183\n",
      "Train loss and acc of batch 0: 47.93305587768555, 1.0\n",
      "Train loss and acc of batch 1: 47.933048248291016, 1.0\n",
      "Train loss and acc of batch 2: 48.218894958496094, 0.984375\n",
      "Train loss and acc of batch 3: 48.14978790283203, 0.984375\n",
      "Train loss and acc of batch 4: 47.933021545410156, 1.0\n",
      "Train loss and acc of batch 5: 49.28193664550781, 0.96875\n",
      "Train loss and acc of batch 6: 48.43561935424805, 0.96875\n",
      "Train loss and acc of batch 7: 47.93299865722656, 1.0\n",
      "Train loss and acc of batch 8: 48.5286865234375, 0.984375\n",
      "Train loss and acc of batch 9: 48.21882629394531, 0.984375\n",
      "Train loss and acc of batch 10: 47.93296432495117, 1.0\n",
      "Train loss and acc of batch 11: 47.93295669555664, 1.0\n",
      "Train loss and acc of batch 12: 48.68617630004883, 0.984375\n",
      "Train loss and acc of batch 13: 48.14970397949219, 0.984375\n",
      "Train loss and acc of batch 14: 48.149696350097656, 0.984375\n",
      "Train loss and acc of batch 15: 48.52862548828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.52861785888672, 0.984375\n",
      "Train loss and acc of batch 17: 48.686126708984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.814449310302734, 0.96875\n",
      "Train loss and acc of batch 19: 47.93288803100586, 1.0\n",
      "Train loss and acc of batch 20: 47.93287658691406, 1.0\n",
      "Train loss and acc of batch 21: 48.52857208251953, 0.984375\n",
      "Train loss and acc of batch 22: 48.528564453125, 0.984375\n",
      "Train loss and acc of batch 23: 47.93285369873047, 1.0\n",
      "Train loss and acc of batch 24: 48.52854919433594, 0.984375\n",
      "Train loss and acc of batch 25: 47.93283462524414, 1.0\n",
      "Train loss and acc of batch 26: 47.93282699584961, 1.0\n",
      "Train loss and acc of batch 27: 47.93281173706055, 1.0\n",
      "Train loss and acc of batch 28: 47.93280792236328, 1.0\n",
      "Train loss and acc of batch 29: 48.52850341796875, 0.984375\n",
      "Train loss and acc of batch 30: 47.93279266357422, 1.0\n",
      "Train loss and acc of batch 31: 48.14954376220703, 0.984375\n",
      "Train loss and acc of batch 32: 47.932769775390625, 1.0\n",
      "Train loss and acc of batch 33: 47.932762145996094, 1.0\n",
      "Train loss and acc of batch 34: 48.52845001220703, 0.984375\n",
      "Train loss and acc of batch 35: 48.366275787353516, 0.96875\n",
      "Train loss and acc of batch 36: 47.93273162841797, 1.0\n",
      "Train loss and acc of batch 37: 48.685951232910156, 0.984375\n",
      "Train loss and acc of batch 38: 49.281639099121094, 0.96875\n",
      "Train loss and acc of batch 39: 48.14947509765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.932701110839844, 1.0\n",
      "Train loss and acc of batch 41: 49.2816162109375, 0.96875\n",
      "Train loss and acc of batch 42: 47.932682037353516, 1.0\n",
      "Train loss and acc of batch 43: 48.52838134765625, 0.984375\n",
      "Train loss and acc of batch 44: 47.93266296386719, 1.0\n",
      "Train loss and acc of batch 45: 48.528358459472656, 0.984375\n",
      "Train loss and acc of batch 46: 48.21849822998047, 0.984375\n",
      "Train loss and acc of batch 47: 47.932640075683594, 1.0\n",
      "Train loss and acc of batch 48: 47.9326286315918, 1.0\n",
      "Train loss and acc of batch 49: 47.93262481689453, 1.0\n",
      "Train loss and acc of batch 50: 48.52831268310547, 0.984375\n",
      "Train loss and acc of batch 51: 49.281524658203125, 0.96875\n",
      "Train loss and acc of batch 52: 49.188438415527344, 0.953125\n",
      "Train loss and acc of batch 53: 47.932586669921875, 1.0\n",
      "Train loss and acc of batch 54: 48.14933776855469, 0.984375\n",
      "Train loss and acc of batch 55: 47.932559967041016, 1.0\n",
      "Train loss and acc of batch 56: 47.93255615234375, 1.0\n",
      "Train loss and acc of batch 57: 48.52825164794922, 0.984375\n",
      "Train loss and acc of batch 58: 47.93254089355469, 1.0\n",
      "Train loss and acc of batch 59: 47.93252944946289, 1.0\n",
      "Train loss and acc of batch 60: 47.932525634765625, 1.0\n",
      "Train loss and acc of batch 61: 47.93251037597656, 1.0\n",
      "Train loss and acc of batch 62: 48.149269104003906, 0.984375\n",
      "Train loss and acc of batch 63: 49.1239013671875, 0.96875\n",
      "Train loss and acc of batch 64: 48.14924621582031, 0.984375\n",
      "Train loss and acc of batch 65: 47.93247604370117, 1.0\n",
      "Train loss and acc of batch 66: 47.932464599609375, 1.0\n",
      "Train loss and acc of batch 67: 48.74492263793945, 0.96875\n",
      "Train loss and acc of batch 68: 48.52815246582031, 0.984375\n",
      "Train loss and acc of batch 69: 48.149200439453125, 0.984375\n",
      "Train loss and acc of batch 70: 47.932430267333984, 1.0\n",
      "Training accuracy and loss of epoch #199: 0.9892, 48.2607\n",
      "Saved model by train loss 48.26070710303078\n",
      "Train loss and acc of batch 0: 47.93242263793945, 1.0\n",
      "Train loss and acc of batch 1: 47.93241500854492, 1.0\n",
      "Train loss and acc of batch 2: 48.21826171875, 0.984375\n",
      "Train loss and acc of batch 3: 48.14916229248047, 0.984375\n",
      "Train loss and acc of batch 4: 47.9323844909668, 1.0\n",
      "Train loss and acc of batch 5: 49.28130340576172, 0.96875\n",
      "Train loss and acc of batch 6: 48.43498992919922, 0.96875\n",
      "Train loss and acc of batch 7: 47.93235778808594, 1.0\n",
      "Train loss and acc of batch 8: 48.528053283691406, 0.984375\n",
      "Train loss and acc of batch 9: 48.21820068359375, 0.984375\n",
      "Train loss and acc of batch 10: 47.932334899902344, 1.0\n",
      "Train loss and acc of batch 11: 47.93233108520508, 1.0\n",
      "Train loss and acc of batch 12: 48.6855354309082, 0.984375\n",
      "Train loss and acc of batch 13: 48.149070739746094, 0.984375\n",
      "Train loss and acc of batch 14: 48.14906311035156, 0.984375\n",
      "Train loss and acc of batch 15: 48.527992248535156, 0.984375\n",
      "Train loss and acc of batch 16: 48.527984619140625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 17: 48.68549728393555, 0.984375\n",
      "Train loss and acc of batch 18: 48.81381607055664, 0.96875\n",
      "Train loss and acc of batch 19: 47.932254791259766, 1.0\n",
      "Train loss and acc of batch 20: 47.932247161865234, 1.0\n",
      "Train loss and acc of batch 21: 48.527931213378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.527931213378906, 0.984375\n",
      "Train loss and acc of batch 23: 47.932212829589844, 1.0\n",
      "Train loss and acc of batch 24: 48.527915954589844, 0.984375\n",
      "Train loss and acc of batch 25: 47.93219757080078, 1.0\n",
      "Train loss and acc of batch 26: 47.93218994140625, 1.0\n",
      "Train loss and acc of batch 27: 47.93217849731445, 1.0\n",
      "Train loss and acc of batch 28: 47.93217849731445, 1.0\n",
      "Train loss and acc of batch 29: 48.527862548828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.93215560913086, 1.0\n",
      "Train loss and acc of batch 31: 48.14891052246094, 0.984375\n",
      "Train loss and acc of batch 32: 47.93213653564453, 1.0\n",
      "Train loss and acc of batch 33: 47.932125091552734, 1.0\n",
      "Train loss and acc of batch 34: 48.52781677246094, 0.984375\n",
      "Train loss and acc of batch 35: 48.365638732910156, 0.96875\n",
      "Train loss and acc of batch 36: 47.93210220336914, 1.0\n",
      "Train loss and acc of batch 37: 48.68532180786133, 0.984375\n",
      "Train loss and acc of batch 38: 49.28101348876953, 0.96875\n",
      "Train loss and acc of batch 39: 48.148841857910156, 0.984375\n",
      "Train loss and acc of batch 40: 47.93206024169922, 1.0\n",
      "Train loss and acc of batch 41: 49.280982971191406, 0.96875\n",
      "Train loss and acc of batch 42: 47.93204879760742, 1.0\n",
      "Train loss and acc of batch 43: 48.527740478515625, 0.984375\n",
      "Train loss and acc of batch 44: 47.932029724121094, 1.0\n",
      "Train loss and acc of batch 45: 48.52772521972656, 0.984375\n",
      "Train loss and acc of batch 46: 48.217864990234375, 0.984375\n",
      "Train loss and acc of batch 47: 47.9320068359375, 1.0\n",
      "Train loss and acc of batch 48: 47.93199920654297, 1.0\n",
      "Train loss and acc of batch 49: 47.931983947753906, 1.0\n",
      "Train loss and acc of batch 50: 48.527679443359375, 0.984375\n",
      "Train loss and acc of batch 51: 49.28089141845703, 0.96875\n",
      "Train loss and acc of batch 52: 49.187801361083984, 0.953125\n",
      "Train loss and acc of batch 53: 47.93195343017578, 1.0\n",
      "Train loss and acc of batch 54: 48.148704528808594, 0.984375\n",
      "Train loss and acc of batch 55: 47.93193435668945, 1.0\n",
      "Train loss and acc of batch 56: 47.931922912597656, 1.0\n",
      "Train loss and acc of batch 57: 48.527618408203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.93190383911133, 1.0\n",
      "Train loss and acc of batch 59: 47.93190002441406, 1.0\n",
      "Train loss and acc of batch 60: 47.931884765625, 1.0\n",
      "Train loss and acc of batch 61: 47.931880950927734, 1.0\n",
      "Train loss and acc of batch 62: 48.14862823486328, 0.984375\n",
      "Train loss and acc of batch 63: 49.123260498046875, 0.96875\n",
      "Train loss and acc of batch 64: 48.14862060546875, 0.984375\n",
      "Train loss and acc of batch 65: 47.93185043334961, 1.0\n",
      "Train loss and acc of batch 66: 47.93183517456055, 1.0\n",
      "Train loss and acc of batch 67: 48.744293212890625, 0.96875\n",
      "Train loss and acc of batch 68: 48.52751922607422, 0.984375\n",
      "Train loss and acc of batch 69: 48.14857482910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.93179702758789, 1.0\n",
      "Training accuracy and loss of epoch #200: 0.9892, 48.2601\n",
      "Saved model by train loss 48.26007375582843\n",
      "Train loss and acc of batch 0: 47.93178939819336, 1.0\n",
      "Train loss and acc of batch 1: 47.93178176879883, 1.0\n",
      "Train loss and acc of batch 2: 48.217628479003906, 0.984375\n",
      "Train loss and acc of batch 3: 48.148529052734375, 0.984375\n",
      "Train loss and acc of batch 4: 47.931758880615234, 1.0\n",
      "Train loss and acc of batch 5: 49.280670166015625, 0.96875\n",
      "Train loss and acc of batch 6: 48.434349060058594, 0.96875\n",
      "Train loss and acc of batch 7: 47.93172836303711, 1.0\n",
      "Train loss and acc of batch 8: 48.52741241455078, 0.984375\n",
      "Train loss and acc of batch 9: 48.217567443847656, 0.984375\n",
      "Train loss and acc of batch 10: 47.93170166015625, 1.0\n",
      "Train loss and acc of batch 11: 47.93169021606445, 1.0\n",
      "Train loss and acc of batch 12: 48.68490982055664, 0.984375\n",
      "Train loss and acc of batch 13: 48.1484375, 0.984375\n",
      "Train loss and acc of batch 14: 48.14842987060547, 0.984375\n",
      "Train loss and acc of batch 15: 48.52735900878906, 0.984375\n",
      "Train loss and acc of batch 16: 48.52735137939453, 0.984375\n",
      "Train loss and acc of batch 17: 48.68486404418945, 0.984375\n",
      "Train loss and acc of batch 18: 48.81318283081055, 0.96875\n",
      "Train loss and acc of batch 19: 47.93162536621094, 1.0\n",
      "Train loss and acc of batch 20: 47.93160629272461, 1.0\n",
      "Train loss and acc of batch 21: 48.527305603027344, 0.984375\n",
      "Train loss and acc of batch 22: 48.52729034423828, 0.984375\n",
      "Train loss and acc of batch 23: 47.93158721923828, 1.0\n",
      "Train loss and acc of batch 24: 48.52727508544922, 0.984375\n",
      "Train loss and acc of batch 25: 47.93156433105469, 1.0\n",
      "Train loss and acc of batch 26: 47.93156051635742, 1.0\n",
      "Train loss and acc of batch 27: 47.931549072265625, 1.0\n",
      "Train loss and acc of batch 28: 47.93153762817383, 1.0\n",
      "Train loss and acc of batch 29: 48.52723693847656, 0.984375\n",
      "Train loss and acc of batch 30: 47.931522369384766, 1.0\n",
      "Train loss and acc of batch 31: 48.148277282714844, 0.984375\n",
      "Train loss and acc of batch 32: 47.9315071105957, 1.0\n",
      "Train loss and acc of batch 33: 47.93150329589844, 1.0\n",
      "Train loss and acc of batch 34: 48.527191162109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.36500549316406, 0.96875\n",
      "Train loss and acc of batch 36: 47.93146896362305, 1.0\n",
      "Train loss and acc of batch 37: 48.68468475341797, 0.984375\n",
      "Train loss and acc of batch 38: 49.28038024902344, 0.96875\n",
      "Train loss and acc of batch 39: 48.14820098876953, 0.984375\n",
      "Train loss and acc of batch 40: 47.931434631347656, 1.0\n",
      "Train loss and acc of batch 41: 49.28034973144531, 0.96875\n",
      "Train loss and acc of batch 42: 47.93141555786133, 1.0\n",
      "Train loss and acc of batch 43: 48.52710723876953, 0.984375\n",
      "Train loss and acc of batch 44: 47.931400299072266, 1.0\n",
      "Train loss and acc of batch 45: 48.52708435058594, 0.984375\n",
      "Train loss and acc of batch 46: 48.21723175048828, 0.984375\n",
      "Train loss and acc of batch 47: 47.931373596191406, 1.0\n",
      "Train loss and acc of batch 48: 47.93136215209961, 1.0\n",
      "Train loss and acc of batch 49: 47.93135452270508, 1.0\n",
      "Train loss and acc of batch 50: 48.52704620361328, 0.984375\n",
      "Train loss and acc of batch 51: 49.28025817871094, 0.96875\n",
      "Train loss and acc of batch 52: 49.18716812133789, 0.953125\n",
      "Train loss and acc of batch 53: 47.931312561035156, 1.0\n",
      "Train loss and acc of batch 54: 48.14807891845703, 0.984375\n",
      "Train loss and acc of batch 55: 47.93130111694336, 1.0\n",
      "Train loss and acc of batch 56: 47.93128967285156, 1.0\n",
      "Train loss and acc of batch 57: 48.52698516845703, 0.984375\n",
      "Train loss and acc of batch 58: 47.931270599365234, 1.0\n",
      "Train loss and acc of batch 59: 47.9312629699707, 1.0\n",
      "Train loss and acc of batch 60: 47.93125915527344, 1.0\n",
      "Train loss and acc of batch 61: 47.93124771118164, 1.0\n",
      "Train loss and acc of batch 62: 48.14800262451172, 0.984375\n",
      "Train loss and acc of batch 63: 49.12263107299805, 0.96875\n",
      "Train loss and acc of batch 64: 48.147987365722656, 0.984375\n",
      "Train loss and acc of batch 65: 47.931209564208984, 1.0\n",
      "Train loss and acc of batch 66: 47.931209564208984, 1.0\n",
      "Train loss and acc of batch 67: 48.743656158447266, 0.96875\n",
      "Train loss and acc of batch 68: 48.526885986328125, 0.984375\n",
      "Train loss and acc of batch 69: 48.14794158935547, 0.984375\n",
      "Train loss and acc of batch 70: 47.93116760253906, 1.0\n",
      "Training accuracy and loss of epoch #201: 0.9892, 48.2594\n",
      "Saved model by train loss 48.25944094590738\n",
      "Train loss and acc of batch 0: 47.93115997314453, 1.0\n",
      "Train loss and acc of batch 1: 47.931148529052734, 1.0\n",
      "Train loss and acc of batch 2: 48.21699523925781, 0.984375\n",
      "Train loss and acc of batch 3: 48.14790344238281, 0.984375\n",
      "Train loss and acc of batch 4: 47.93112564086914, 1.0\n",
      "Train loss and acc of batch 5: 49.28003692626953, 0.96875\n",
      "Train loss and acc of batch 6: 48.43372344970703, 0.96875\n",
      "Train loss and acc of batch 7: 47.93109130859375, 1.0\n",
      "Train loss and acc of batch 8: 48.52678680419922, 0.984375\n",
      "Train loss and acc of batch 9: 48.21692657470703, 0.984375\n",
      "Train loss and acc of batch 10: 47.93106460571289, 1.0\n",
      "Train loss and acc of batch 11: 47.931060791015625, 1.0\n",
      "Train loss and acc of batch 12: 48.68427658081055, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 13: 48.147804260253906, 0.984375\n",
      "Train loss and acc of batch 14: 48.147796630859375, 0.984375\n",
      "Train loss and acc of batch 15: 48.52671813964844, 0.984375\n",
      "Train loss and acc of batch 16: 48.52671813964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.68423080444336, 0.984375\n",
      "Train loss and acc of batch 18: 48.81255340576172, 0.96875\n",
      "Train loss and acc of batch 19: 47.93098449707031, 1.0\n",
      "Train loss and acc of batch 20: 47.93098068237305, 1.0\n",
      "Train loss and acc of batch 21: 48.52666473388672, 0.984375\n",
      "Train loss and acc of batch 22: 48.52666473388672, 0.984375\n",
      "Train loss and acc of batch 23: 47.93095779418945, 1.0\n",
      "Train loss and acc of batch 24: 48.526641845703125, 0.984375\n",
      "Train loss and acc of batch 25: 47.93093490600586, 1.0\n",
      "Train loss and acc of batch 26: 47.93092346191406, 1.0\n",
      "Train loss and acc of batch 27: 47.93091583251953, 1.0\n",
      "Train loss and acc of batch 28: 47.930912017822266, 1.0\n",
      "Train loss and acc of batch 29: 48.52660369873047, 0.984375\n",
      "Train loss and acc of batch 30: 47.93088912963867, 1.0\n",
      "Train loss and acc of batch 31: 48.14764404296875, 0.984375\n",
      "Train loss and acc of batch 32: 47.93087387084961, 1.0\n",
      "Train loss and acc of batch 33: 47.93086242675781, 1.0\n",
      "Train loss and acc of batch 34: 48.52655792236328, 0.984375\n",
      "Train loss and acc of batch 35: 48.36437225341797, 0.96875\n",
      "Train loss and acc of batch 36: 47.93083572387695, 1.0\n",
      "Train loss and acc of batch 37: 48.684051513671875, 0.984375\n",
      "Train loss and acc of batch 38: 49.27973937988281, 0.96875\n",
      "Train loss and acc of batch 39: 48.14757537841797, 0.984375\n",
      "Train loss and acc of batch 40: 47.93080139160156, 1.0\n",
      "Train loss and acc of batch 41: 49.27971649169922, 0.96875\n",
      "Train loss and acc of batch 42: 47.9307861328125, 1.0\n",
      "Train loss and acc of batch 43: 48.52647399902344, 0.984375\n",
      "Train loss and acc of batch 44: 47.930763244628906, 1.0\n",
      "Train loss and acc of batch 45: 48.526458740234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.21659851074219, 0.984375\n",
      "Train loss and acc of batch 47: 47.93074035644531, 1.0\n",
      "Train loss and acc of batch 48: 47.93072509765625, 1.0\n",
      "Train loss and acc of batch 49: 47.930721282958984, 1.0\n",
      "Train loss and acc of batch 50: 48.52641296386719, 0.984375\n",
      "Train loss and acc of batch 51: 49.279632568359375, 0.96875\n",
      "Train loss and acc of batch 52: 49.18653106689453, 0.953125\n",
      "Train loss and acc of batch 53: 47.930686950683594, 1.0\n",
      "Train loss and acc of batch 54: 48.147438049316406, 0.984375\n",
      "Train loss and acc of batch 55: 47.930667877197266, 1.0\n",
      "Train loss and acc of batch 56: 47.930660247802734, 1.0\n",
      "Train loss and acc of batch 57: 48.52635192871094, 0.984375\n",
      "Train loss and acc of batch 58: 47.930641174316406, 1.0\n",
      "Train loss and acc of batch 59: 47.93063735961914, 1.0\n",
      "Train loss and acc of batch 60: 47.93062210083008, 1.0\n",
      "Train loss and acc of batch 61: 47.93061065673828, 1.0\n",
      "Train loss and acc of batch 62: 48.147369384765625, 0.984375\n",
      "Train loss and acc of batch 63: 49.12199783325195, 0.96875\n",
      "Train loss and acc of batch 64: 48.14735412597656, 0.984375\n",
      "Train loss and acc of batch 65: 47.930572509765625, 1.0\n",
      "Train loss and acc of batch 66: 47.93056869506836, 1.0\n",
      "Train loss and acc of batch 67: 48.74302673339844, 0.96875\n",
      "Train loss and acc of batch 68: 48.52625274658203, 0.984375\n",
      "Train loss and acc of batch 69: 48.147308349609375, 0.984375\n",
      "Train loss and acc of batch 70: 47.930538177490234, 1.0\n",
      "Training accuracy and loss of epoch #202: 0.9892, 48.2588\n",
      "Saved model by train loss 48.2588080822582\n",
      "Train loss and acc of batch 0: 47.93052291870117, 1.0\n",
      "Train loss and acc of batch 1: 47.93051528930664, 1.0\n",
      "Train loss and acc of batch 2: 48.21636199951172, 0.984375\n",
      "Train loss and acc of batch 3: 48.147254943847656, 0.984375\n",
      "Train loss and acc of batch 4: 47.930484771728516, 1.0\n",
      "Train loss and acc of batch 5: 49.27940368652344, 0.96875\n",
      "Train loss and acc of batch 6: 48.43308639526367, 0.96875\n",
      "Train loss and acc of batch 7: 47.93046569824219, 1.0\n",
      "Train loss and acc of batch 8: 48.526153564453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.21629333496094, 0.984375\n",
      "Train loss and acc of batch 10: 47.93043518066406, 1.0\n",
      "Train loss and acc of batch 11: 47.930423736572266, 1.0\n",
      "Train loss and acc of batch 12: 48.68363952636719, 0.984375\n",
      "Train loss and acc of batch 13: 48.147178649902344, 0.984375\n",
      "Train loss and acc of batch 14: 48.14716339111328, 0.984375\n",
      "Train loss and acc of batch 15: 48.526092529296875, 0.984375\n",
      "Train loss and acc of batch 16: 48.526084899902344, 0.984375\n",
      "Train loss and acc of batch 17: 48.683589935302734, 0.984375\n",
      "Train loss and acc of batch 18: 48.81191635131836, 0.96875\n",
      "Train loss and acc of batch 19: 47.93035888671875, 1.0\n",
      "Train loss and acc of batch 20: 47.93034744262695, 1.0\n",
      "Train loss and acc of batch 21: 48.526039123535156, 0.984375\n",
      "Train loss and acc of batch 22: 48.526023864746094, 0.984375\n",
      "Train loss and acc of batch 23: 47.93031692504883, 1.0\n",
      "Train loss and acc of batch 24: 48.52601623535156, 0.984375\n",
      "Train loss and acc of batch 25: 47.930301666259766, 1.0\n",
      "Train loss and acc of batch 26: 47.93029022216797, 1.0\n",
      "Train loss and acc of batch 27: 47.9302864074707, 1.0\n",
      "Train loss and acc of batch 28: 47.930274963378906, 1.0\n",
      "Train loss and acc of batch 29: 48.525970458984375, 0.984375\n",
      "Train loss and acc of batch 30: 47.930259704589844, 1.0\n",
      "Train loss and acc of batch 31: 48.147010803222656, 0.984375\n",
      "Train loss and acc of batch 32: 47.930240631103516, 1.0\n",
      "Train loss and acc of batch 33: 47.93022537231445, 1.0\n",
      "Train loss and acc of batch 34: 48.52592468261719, 0.984375\n",
      "Train loss and acc of batch 35: 48.36374282836914, 0.96875\n",
      "Train loss and acc of batch 36: 47.93021011352539, 1.0\n",
      "Train loss and acc of batch 37: 48.683414459228516, 0.984375\n",
      "Train loss and acc of batch 38: 49.27911376953125, 0.96875\n",
      "Train loss and acc of batch 39: 48.146934509277344, 0.984375\n",
      "Train loss and acc of batch 40: 47.9301643371582, 1.0\n",
      "Train loss and acc of batch 41: 49.27908706665039, 0.96875\n",
      "Train loss and acc of batch 42: 47.93014907836914, 1.0\n",
      "Train loss and acc of batch 43: 48.525840759277344, 0.984375\n",
      "Train loss and acc of batch 44: 47.930137634277344, 1.0\n",
      "Train loss and acc of batch 45: 48.52582550048828, 0.984375\n",
      "Train loss and acc of batch 46: 48.215965270996094, 0.984375\n",
      "Train loss and acc of batch 47: 47.93010711669922, 1.0\n",
      "Train loss and acc of batch 48: 47.93009948730469, 1.0\n",
      "Train loss and acc of batch 49: 47.93008804321289, 1.0\n",
      "Train loss and acc of batch 50: 48.52577209472656, 0.984375\n",
      "Train loss and acc of batch 51: 49.27899169921875, 0.96875\n",
      "Train loss and acc of batch 52: 49.1859016418457, 0.953125\n",
      "Train loss and acc of batch 53: 47.930049896240234, 1.0\n",
      "Train loss and acc of batch 54: 48.14680480957031, 0.984375\n",
      "Train loss and acc of batch 55: 47.93003463745117, 1.0\n",
      "Train loss and acc of batch 56: 47.930023193359375, 1.0\n",
      "Train loss and acc of batch 57: 48.525718688964844, 0.984375\n",
      "Train loss and acc of batch 58: 47.93001174926758, 1.0\n",
      "Train loss and acc of batch 59: 47.93000030517578, 1.0\n",
      "Train loss and acc of batch 60: 47.929988861083984, 1.0\n",
      "Train loss and acc of batch 61: 47.92998123168945, 1.0\n",
      "Train loss and acc of batch 62: 48.14673614501953, 0.984375\n",
      "Train loss and acc of batch 63: 49.121368408203125, 0.96875\n",
      "Train loss and acc of batch 64: 48.14671325683594, 0.984375\n",
      "Train loss and acc of batch 65: 47.92994689941406, 1.0\n",
      "Train loss and acc of batch 66: 47.929935455322266, 1.0\n",
      "Train loss and acc of batch 67: 48.74238967895508, 0.96875\n",
      "Train loss and acc of batch 68: 48.525611877441406, 0.984375\n",
      "Train loss and acc of batch 69: 48.14667510986328, 0.984375\n",
      "Train loss and acc of batch 70: 47.92989730834961, 1.0\n",
      "Training accuracy and loss of epoch #203: 0.9892, 48.2582\n",
      "Saved model by train loss 48.25817446641519\n",
      "Train loss and acc of batch 0: 47.929893493652344, 1.0\n",
      "Train loss and acc of batch 1: 47.92988586425781, 1.0\n",
      "Train loss and acc of batch 2: 48.215728759765625, 0.984375\n",
      "Train loss and acc of batch 3: 48.146629333496094, 0.984375\n",
      "Train loss and acc of batch 4: 47.92985916137695, 1.0\n",
      "Train loss and acc of batch 5: 49.278770446777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.432456970214844, 0.96875\n",
      "Train loss and acc of batch 7: 47.92982482910156, 1.0\n",
      "Train loss and acc of batch 8: 48.52552032470703, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 9: 48.215660095214844, 0.984375\n",
      "Train loss and acc of batch 10: 47.9297981262207, 1.0\n",
      "Train loss and acc of batch 11: 47.92979049682617, 1.0\n",
      "Train loss and acc of batch 12: 48.68301010131836, 0.984375\n",
      "Train loss and acc of batch 13: 48.14653778076172, 0.984375\n",
      "Train loss and acc of batch 14: 48.14653015136719, 0.984375\n",
      "Train loss and acc of batch 15: 48.52545928955078, 0.984375\n",
      "Train loss and acc of batch 16: 48.52545166015625, 0.984375\n",
      "Train loss and acc of batch 17: 48.682960510253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.811279296875, 0.96875\n",
      "Train loss and acc of batch 19: 47.929725646972656, 1.0\n",
      "Train loss and acc of batch 20: 47.92971420288086, 1.0\n",
      "Train loss and acc of batch 21: 48.52540588378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.52539825439453, 0.984375\n",
      "Train loss and acc of batch 23: 47.929691314697266, 1.0\n",
      "Train loss and acc of batch 24: 48.52537536621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.929664611816406, 1.0\n",
      "Train loss and acc of batch 26: 47.92966079711914, 1.0\n",
      "Train loss and acc of batch 27: 47.929649353027344, 1.0\n",
      "Train loss and acc of batch 28: 47.92964172363281, 1.0\n",
      "Train loss and acc of batch 29: 48.52533721923828, 0.984375\n",
      "Train loss and acc of batch 30: 47.92962646484375, 1.0\n",
      "Train loss and acc of batch 31: 48.14637756347656, 0.984375\n",
      "Train loss and acc of batch 32: 47.92960739135742, 1.0\n",
      "Train loss and acc of batch 33: 47.92959976196289, 1.0\n",
      "Train loss and acc of batch 34: 48.525291442871094, 0.984375\n",
      "Train loss and acc of batch 35: 48.363101959228516, 0.96875\n",
      "Train loss and acc of batch 36: 47.929569244384766, 1.0\n",
      "Train loss and acc of batch 37: 48.68278884887695, 0.984375\n",
      "Train loss and acc of batch 38: 49.278472900390625, 0.96875\n",
      "Train loss and acc of batch 39: 48.14630126953125, 0.984375\n",
      "Train loss and acc of batch 40: 47.929534912109375, 1.0\n",
      "Train loss and acc of batch 41: 49.27845001220703, 0.96875\n",
      "Train loss and acc of batch 42: 47.92951583862305, 1.0\n",
      "Train loss and acc of batch 43: 48.52521514892578, 0.984375\n",
      "Train loss and acc of batch 44: 47.929500579833984, 1.0\n",
      "Train loss and acc of batch 45: 48.52519226074219, 0.984375\n",
      "Train loss and acc of batch 46: 48.21532440185547, 0.984375\n",
      "Train loss and acc of batch 47: 47.929473876953125, 1.0\n",
      "Train loss and acc of batch 48: 47.929466247558594, 1.0\n",
      "Train loss and acc of batch 49: 47.92945098876953, 1.0\n",
      "Train loss and acc of batch 50: 48.525146484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.27836608886719, 0.96875\n",
      "Train loss and acc of batch 52: 49.18526840209961, 0.953125\n",
      "Train loss and acc of batch 53: 47.929412841796875, 1.0\n",
      "Train loss and acc of batch 54: 48.14617919921875, 0.984375\n",
      "Train loss and acc of batch 55: 47.929405212402344, 1.0\n",
      "Train loss and acc of batch 56: 47.92939376831055, 1.0\n",
      "Train loss and acc of batch 57: 48.52508544921875, 0.984375\n",
      "Train loss and acc of batch 58: 47.92937469482422, 1.0\n",
      "Train loss and acc of batch 59: 47.92936325073242, 1.0\n",
      "Train loss and acc of batch 60: 47.929359436035156, 1.0\n",
      "Train loss and acc of batch 61: 47.92934799194336, 1.0\n",
      "Train loss and acc of batch 62: 48.14610290527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.120731353759766, 0.96875\n",
      "Train loss and acc of batch 64: 48.146087646484375, 0.984375\n",
      "Train loss and acc of batch 65: 47.92931365966797, 1.0\n",
      "Train loss and acc of batch 66: 47.92930603027344, 1.0\n",
      "Train loss and acc of batch 67: 48.741756439208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.524986267089844, 0.984375\n",
      "Train loss and acc of batch 69: 48.14604187011719, 0.984375\n",
      "Train loss and acc of batch 70: 47.92927169799805, 1.0\n",
      "Training accuracy and loss of epoch #204: 0.9892, 48.2575\n",
      "Saved model by train loss 48.257541871406666\n",
      "Train loss and acc of batch 0: 47.929256439208984, 1.0\n",
      "Train loss and acc of batch 1: 47.92924499511719, 1.0\n",
      "Train loss and acc of batch 2: 48.21509552001953, 0.984375\n",
      "Train loss and acc of batch 3: 48.14599609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.92922592163086, 1.0\n",
      "Train loss and acc of batch 5: 49.27813720703125, 0.96875\n",
      "Train loss and acc of batch 6: 48.43182373046875, 0.96875\n",
      "Train loss and acc of batch 7: 47.929195404052734, 1.0\n",
      "Train loss and acc of batch 8: 48.52488708496094, 0.984375\n",
      "Train loss and acc of batch 9: 48.21503448486328, 0.984375\n",
      "Train loss and acc of batch 10: 47.929168701171875, 1.0\n",
      "Train loss and acc of batch 11: 47.92916488647461, 1.0\n",
      "Train loss and acc of batch 12: 48.682376861572266, 0.984375\n",
      "Train loss and acc of batch 13: 48.145912170410156, 0.984375\n",
      "Train loss and acc of batch 14: 48.145904541015625, 0.984375\n",
      "Train loss and acc of batch 15: 48.52482604980469, 0.984375\n",
      "Train loss and acc of batch 16: 48.524818420410156, 0.984375\n",
      "Train loss and acc of batch 17: 48.68232727050781, 0.984375\n",
      "Train loss and acc of batch 18: 48.81064987182617, 0.96875\n",
      "Train loss and acc of batch 19: 47.9290885925293, 1.0\n",
      "Train loss and acc of batch 20: 47.929080963134766, 1.0\n",
      "Train loss and acc of batch 21: 48.52476501464844, 0.984375\n",
      "Train loss and acc of batch 22: 48.52476501464844, 0.984375\n",
      "Train loss and acc of batch 23: 47.929054260253906, 1.0\n",
      "Train loss and acc of batch 24: 48.524742126464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.92903518676758, 1.0\n",
      "Train loss and acc of batch 26: 47.92902755737305, 1.0\n",
      "Train loss and acc of batch 27: 47.929019927978516, 1.0\n",
      "Train loss and acc of batch 28: 47.929012298583984, 1.0\n",
      "Train loss and acc of batch 29: 48.524696350097656, 0.984375\n",
      "Train loss and acc of batch 30: 47.928993225097656, 1.0\n",
      "Train loss and acc of batch 31: 48.14574432373047, 0.984375\n",
      "Train loss and acc of batch 32: 47.928977966308594, 1.0\n",
      "Train loss and acc of batch 33: 47.92896270751953, 1.0\n",
      "Train loss and acc of batch 34: 48.524658203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.36247634887695, 0.96875\n",
      "Train loss and acc of batch 36: 47.92893981933594, 1.0\n",
      "Train loss and acc of batch 37: 48.682151794433594, 0.984375\n",
      "Train loss and acc of batch 38: 49.27783966064453, 0.96875\n",
      "Train loss and acc of batch 39: 48.14567565917969, 0.984375\n",
      "Train loss and acc of batch 40: 47.928897857666016, 1.0\n",
      "Train loss and acc of batch 41: 49.2778205871582, 0.96875\n",
      "Train loss and acc of batch 42: 47.92888641357422, 1.0\n",
      "Train loss and acc of batch 43: 48.524574279785156, 0.984375\n",
      "Train loss and acc of batch 44: 47.92886734008789, 1.0\n",
      "Train loss and acc of batch 45: 48.524559020996094, 0.984375\n",
      "Train loss and acc of batch 46: 48.214698791503906, 0.984375\n",
      "Train loss and acc of batch 47: 47.92884063720703, 1.0\n",
      "Train loss and acc of batch 48: 47.928829193115234, 1.0\n",
      "Train loss and acc of batch 49: 47.92882537841797, 1.0\n",
      "Train loss and acc of batch 50: 48.52452087402344, 0.984375\n",
      "Train loss and acc of batch 51: 49.277732849121094, 0.96875\n",
      "Train loss and acc of batch 52: 49.18463134765625, 0.953125\n",
      "Train loss and acc of batch 53: 47.92878723144531, 1.0\n",
      "Train loss and acc of batch 54: 48.145538330078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.92877197265625, 1.0\n",
      "Train loss and acc of batch 56: 47.928768157958984, 1.0\n",
      "Train loss and acc of batch 57: 48.524452209472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.928741455078125, 1.0\n",
      "Train loss and acc of batch 59: 47.92873764038086, 1.0\n",
      "Train loss and acc of batch 60: 47.92872619628906, 1.0\n",
      "Train loss and acc of batch 61: 47.928714752197266, 1.0\n",
      "Train loss and acc of batch 62: 48.145469665527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.12009811401367, 0.96875\n",
      "Train loss and acc of batch 64: 48.14545440673828, 0.984375\n",
      "Train loss and acc of batch 65: 47.92867660522461, 1.0\n",
      "Train loss and acc of batch 66: 47.92866897583008, 1.0\n",
      "Train loss and acc of batch 67: 48.741127014160156, 0.96875\n",
      "Train loss and acc of batch 68: 48.52435302734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.145408630371094, 0.984375\n",
      "Train loss and acc of batch 70: 47.92863464355469, 1.0\n",
      "Training accuracy and loss of epoch #205: 0.9892, 48.2569\n",
      "Saved model by train loss 48.2569093838544\n",
      "Train loss and acc of batch 0: 47.928627014160156, 1.0\n",
      "Train loss and acc of batch 1: 47.928619384765625, 1.0\n",
      "Train loss and acc of batch 2: 48.21446990966797, 0.984375\n",
      "Train loss and acc of batch 3: 48.145362854003906, 0.984375\n",
      "Train loss and acc of batch 4: 47.9285888671875, 1.0\n",
      "Train loss and acc of batch 5: 49.27751159667969, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 6: 48.431190490722656, 0.96875\n",
      "Train loss and acc of batch 7: 47.928565979003906, 1.0\n",
      "Train loss and acc of batch 8: 48.524261474609375, 0.984375\n",
      "Train loss and acc of batch 9: 48.21440124511719, 0.984375\n",
      "Train loss and acc of batch 10: 47.92853927612305, 1.0\n",
      "Train loss and acc of batch 11: 47.92852783203125, 1.0\n",
      "Train loss and acc of batch 12: 48.68174362182617, 0.984375\n",
      "Train loss and acc of batch 13: 48.14527893066406, 0.984375\n",
      "Train loss and acc of batch 14: 48.14527130126953, 0.984375\n",
      "Train loss and acc of batch 15: 48.524200439453125, 0.984375\n",
      "Train loss and acc of batch 16: 48.52418518066406, 0.984375\n",
      "Train loss and acc of batch 17: 48.681697845458984, 0.984375\n",
      "Train loss and acc of batch 18: 48.81001663208008, 0.96875\n",
      "Train loss and acc of batch 19: 47.9284553527832, 1.0\n",
      "Train loss and acc of batch 20: 47.928443908691406, 1.0\n",
      "Train loss and acc of batch 21: 48.524147033691406, 0.984375\n",
      "Train loss and acc of batch 22: 48.524131774902344, 0.984375\n",
      "Train loss and acc of batch 23: 47.92842102050781, 1.0\n",
      "Train loss and acc of batch 24: 48.52411651611328, 0.984375\n",
      "Train loss and acc of batch 25: 47.92840576171875, 1.0\n",
      "Train loss and acc of batch 26: 47.92839431762695, 1.0\n",
      "Train loss and acc of batch 27: 47.92838668823242, 1.0\n",
      "Train loss and acc of batch 28: 47.928375244140625, 1.0\n",
      "Train loss and acc of batch 29: 48.524070739746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.92836380004883, 1.0\n",
      "Train loss and acc of batch 31: 48.145111083984375, 0.984375\n",
      "Train loss and acc of batch 32: 47.928340911865234, 1.0\n",
      "Train loss and acc of batch 33: 47.92832565307617, 1.0\n",
      "Train loss and acc of batch 34: 48.524024963378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.361846923828125, 0.96875\n",
      "Train loss and acc of batch 36: 47.928306579589844, 1.0\n",
      "Train loss and acc of batch 37: 48.6815185546875, 0.984375\n",
      "Train loss and acc of batch 38: 49.27721405029297, 0.96875\n",
      "Train loss and acc of batch 39: 48.145042419433594, 0.984375\n",
      "Train loss and acc of batch 40: 47.92827224731445, 1.0\n",
      "Train loss and acc of batch 41: 49.277191162109375, 0.96875\n",
      "Train loss and acc of batch 42: 47.92824935913086, 1.0\n",
      "Train loss and acc of batch 43: 48.523948669433594, 0.984375\n",
      "Train loss and acc of batch 44: 47.92823791503906, 1.0\n",
      "Train loss and acc of batch 45: 48.52392578125, 0.984375\n",
      "Train loss and acc of batch 46: 48.214073181152344, 0.984375\n",
      "Train loss and acc of batch 47: 47.92820358276367, 1.0\n",
      "Train loss and acc of batch 48: 47.92819595336914, 1.0\n",
      "Train loss and acc of batch 49: 47.928192138671875, 1.0\n",
      "Train loss and acc of batch 50: 48.52388000488281, 0.984375\n",
      "Train loss and acc of batch 51: 49.277099609375, 0.96875\n",
      "Train loss and acc of batch 52: 49.18400955200195, 0.953125\n",
      "Train loss and acc of batch 53: 47.92815399169922, 1.0\n",
      "Train loss and acc of batch 54: 48.14491271972656, 0.984375\n",
      "Train loss and acc of batch 55: 47.92813491821289, 1.0\n",
      "Train loss and acc of batch 56: 47.928123474121094, 1.0\n",
      "Train loss and acc of batch 57: 48.52381896972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.92811584472656, 1.0\n",
      "Train loss and acc of batch 59: 47.9281005859375, 1.0\n",
      "Train loss and acc of batch 60: 47.92809295654297, 1.0\n",
      "Train loss and acc of batch 61: 47.928077697753906, 1.0\n",
      "Train loss and acc of batch 62: 48.14483642578125, 0.984375\n",
      "Train loss and acc of batch 63: 49.119468688964844, 0.96875\n",
      "Train loss and acc of batch 64: 48.14482116699219, 0.984375\n",
      "Train loss and acc of batch 65: 47.92804718017578, 1.0\n",
      "Train loss and acc of batch 66: 47.928043365478516, 1.0\n",
      "Train loss and acc of batch 67: 48.74049758911133, 0.96875\n",
      "Train loss and acc of batch 68: 48.523719787597656, 0.984375\n",
      "Train loss and acc of batch 69: 48.144775390625, 0.984375\n",
      "Train loss and acc of batch 70: 47.92799758911133, 1.0\n",
      "Training accuracy and loss of epoch #206: 0.9892, 48.2563\n",
      "Saved model by train loss 48.25627775595222\n",
      "Train loss and acc of batch 0: 47.92799377441406, 1.0\n",
      "Train loss and acc of batch 1: 47.9279899597168, 1.0\n",
      "Train loss and acc of batch 2: 48.213829040527344, 0.984375\n",
      "Train loss and acc of batch 3: 48.14472961425781, 0.984375\n",
      "Train loss and acc of batch 4: 47.92795944213867, 1.0\n",
      "Train loss and acc of batch 5: 49.27687072753906, 0.96875\n",
      "Train loss and acc of batch 6: 48.43056106567383, 0.96875\n",
      "Train loss and acc of batch 7: 47.92792510986328, 1.0\n",
      "Train loss and acc of batch 8: 48.52362823486328, 0.984375\n",
      "Train loss and acc of batch 9: 48.213768005371094, 0.984375\n",
      "Train loss and acc of batch 10: 47.92790603637695, 1.0\n",
      "Train loss and acc of batch 11: 47.92789077758789, 1.0\n",
      "Train loss and acc of batch 12: 48.68111038208008, 0.984375\n",
      "Train loss and acc of batch 13: 48.14463806152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.144630432128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.52356719970703, 0.984375\n",
      "Train loss and acc of batch 16: 48.52355194091797, 0.984375\n",
      "Train loss and acc of batch 17: 48.68106460571289, 0.984375\n",
      "Train loss and acc of batch 18: 48.809391021728516, 0.96875\n",
      "Train loss and acc of batch 19: 47.92782211303711, 1.0\n",
      "Train loss and acc of batch 20: 47.927818298339844, 1.0\n",
      "Train loss and acc of batch 21: 48.52350616455078, 0.984375\n",
      "Train loss and acc of batch 22: 48.52349853515625, 0.984375\n",
      "Train loss and acc of batch 23: 47.92778778076172, 1.0\n",
      "Train loss and acc of batch 24: 48.52348327636719, 0.984375\n",
      "Train loss and acc of batch 25: 47.927772521972656, 1.0\n",
      "Train loss and acc of batch 26: 47.92776107788086, 1.0\n",
      "Train loss and acc of batch 27: 47.92775344848633, 1.0\n",
      "Train loss and acc of batch 28: 47.92774200439453, 1.0\n",
      "Train loss and acc of batch 29: 48.5234375, 0.984375\n",
      "Train loss and acc of batch 30: 47.927730560302734, 1.0\n",
      "Train loss and acc of batch 31: 48.14448547363281, 0.984375\n",
      "Train loss and acc of batch 32: 47.92770767211914, 1.0\n",
      "Train loss and acc of batch 33: 47.92770004272461, 1.0\n",
      "Train loss and acc of batch 34: 48.52339172363281, 0.984375\n",
      "Train loss and acc of batch 35: 48.3612060546875, 0.96875\n",
      "Train loss and acc of batch 36: 47.927669525146484, 1.0\n",
      "Train loss and acc of batch 37: 48.68088912963867, 0.984375\n",
      "Train loss and acc of batch 38: 49.276580810546875, 0.96875\n",
      "Train loss and acc of batch 39: 48.1444091796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.927635192871094, 1.0\n",
      "Train loss and acc of batch 41: 49.27655792236328, 0.96875\n",
      "Train loss and acc of batch 42: 47.92761993408203, 1.0\n",
      "Train loss and acc of batch 43: 48.5233154296875, 0.984375\n",
      "Train loss and acc of batch 44: 47.92759704589844, 1.0\n",
      "Train loss and acc of batch 45: 48.523292541503906, 0.984375\n",
      "Train loss and acc of batch 46: 48.21343994140625, 0.984375\n",
      "Train loss and acc of batch 47: 47.92757797241211, 1.0\n",
      "Train loss and acc of batch 48: 47.92756652832031, 1.0\n",
      "Train loss and acc of batch 49: 47.927555084228516, 1.0\n",
      "Train loss and acc of batch 50: 48.52324676513672, 0.984375\n",
      "Train loss and acc of batch 51: 49.276466369628906, 0.96875\n",
      "Train loss and acc of batch 52: 49.18336868286133, 0.953125\n",
      "Train loss and acc of batch 53: 47.92752456665039, 1.0\n",
      "Train loss and acc of batch 54: 48.14427947998047, 0.984375\n",
      "Train loss and acc of batch 55: 47.92750549316406, 1.0\n",
      "Train loss and acc of batch 56: 47.927494049072266, 1.0\n",
      "Train loss and acc of batch 57: 48.52318572998047, 0.984375\n",
      "Train loss and acc of batch 58: 47.92747497558594, 1.0\n",
      "Train loss and acc of batch 59: 47.927467346191406, 1.0\n",
      "Train loss and acc of batch 60: 47.927459716796875, 1.0\n",
      "Train loss and acc of batch 61: 47.927452087402344, 1.0\n",
      "Train loss and acc of batch 62: 48.144203186035156, 0.984375\n",
      "Train loss and acc of batch 63: 49.118839263916016, 0.96875\n",
      "Train loss and acc of batch 64: 48.144187927246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.92741394042969, 1.0\n",
      "Train loss and acc of batch 66: 47.927406311035156, 1.0\n",
      "Train loss and acc of batch 67: 48.73986053466797, 0.96875\n",
      "Train loss and acc of batch 68: 48.52308654785156, 0.984375\n",
      "Train loss and acc of batch 69: 48.144142150878906, 0.984375\n",
      "Train loss and acc of batch 70: 47.927371978759766, 1.0\n",
      "Training accuracy and loss of epoch #207: 0.9892, 48.2556\n",
      "Saved model by train loss 48.25564440874986\n",
      "Train loss and acc of batch 0: 47.92736053466797, 1.0\n",
      "Train loss and acc of batch 1: 47.92734909057617, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 2: 48.21319580078125, 0.984375\n",
      "Train loss and acc of batch 3: 48.14410400390625, 0.984375\n",
      "Train loss and acc of batch 4: 47.92732238769531, 1.0\n",
      "Train loss and acc of batch 5: 49.2762451171875, 0.96875\n",
      "Train loss and acc of batch 6: 48.4299201965332, 0.96875\n",
      "Train loss and acc of batch 7: 47.92729568481445, 1.0\n",
      "Train loss and acc of batch 8: 48.522987365722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.213134765625, 0.984375\n",
      "Train loss and acc of batch 10: 47.927268981933594, 1.0\n",
      "Train loss and acc of batch 11: 47.92726516723633, 1.0\n",
      "Train loss and acc of batch 12: 48.680477142333984, 0.984375\n",
      "Train loss and acc of batch 13: 48.144012451171875, 0.984375\n",
      "Train loss and acc of batch 14: 48.14399719238281, 0.984375\n",
      "Train loss and acc of batch 15: 48.522926330566406, 0.984375\n",
      "Train loss and acc of batch 16: 48.522918701171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.68043518066406, 0.984375\n",
      "Train loss and acc of batch 18: 48.808753967285156, 0.96875\n",
      "Train loss and acc of batch 19: 47.92719268798828, 1.0\n",
      "Train loss and acc of batch 20: 47.92718505859375, 1.0\n",
      "Train loss and acc of batch 21: 48.52287292480469, 0.984375\n",
      "Train loss and acc of batch 22: 48.522865295410156, 0.984375\n",
      "Train loss and acc of batch 23: 47.927154541015625, 1.0\n",
      "Train loss and acc of batch 24: 48.522850036621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.9271354675293, 1.0\n",
      "Train loss and acc of batch 26: 47.92713165283203, 1.0\n",
      "Train loss and acc of batch 27: 47.9271240234375, 1.0\n",
      "Train loss and acc of batch 28: 47.92711639404297, 1.0\n",
      "Train loss and acc of batch 29: 48.522796630859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.927093505859375, 1.0\n",
      "Train loss and acc of batch 31: 48.14385223388672, 0.984375\n",
      "Train loss and acc of batch 32: 47.92707824707031, 1.0\n",
      "Train loss and acc of batch 33: 47.92707061767578, 1.0\n",
      "Train loss and acc of batch 34: 48.52275848388672, 0.984375\n",
      "Train loss and acc of batch 35: 48.36057662963867, 0.96875\n",
      "Train loss and acc of batch 36: 47.92703628540039, 1.0\n",
      "Train loss and acc of batch 37: 48.68025207519531, 0.984375\n",
      "Train loss and acc of batch 38: 49.27594757080078, 0.96875\n",
      "Train loss and acc of batch 39: 48.143775939941406, 0.984375\n",
      "Train loss and acc of batch 40: 47.927005767822266, 1.0\n",
      "Train loss and acc of batch 41: 49.27592468261719, 0.96875\n",
      "Train loss and acc of batch 42: 47.92698669433594, 1.0\n",
      "Train loss and acc of batch 43: 48.522682189941406, 0.984375\n",
      "Train loss and acc of batch 44: 47.92696762084961, 1.0\n",
      "Train loss and acc of batch 45: 48.52265930175781, 0.984375\n",
      "Train loss and acc of batch 46: 48.212806701660156, 0.984375\n",
      "Train loss and acc of batch 47: 47.926944732666016, 1.0\n",
      "Train loss and acc of batch 48: 47.926937103271484, 1.0\n",
      "Train loss and acc of batch 49: 47.92692565917969, 1.0\n",
      "Train loss and acc of batch 50: 48.522613525390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.27583312988281, 0.96875\n",
      "Train loss and acc of batch 52: 49.182735443115234, 0.953125\n",
      "Train loss and acc of batch 53: 47.92688751220703, 1.0\n",
      "Train loss and acc of batch 54: 48.143646240234375, 0.984375\n",
      "Train loss and acc of batch 55: 47.92687225341797, 1.0\n",
      "Train loss and acc of batch 56: 47.9268684387207, 1.0\n",
      "Train loss and acc of batch 57: 48.522552490234375, 0.984375\n",
      "Train loss and acc of batch 58: 47.926841735839844, 1.0\n",
      "Train loss and acc of batch 59: 47.92683792114258, 1.0\n",
      "Train loss and acc of batch 60: 47.92682647705078, 1.0\n",
      "Train loss and acc of batch 61: 47.92681884765625, 1.0\n",
      "Train loss and acc of batch 62: 48.14356994628906, 0.984375\n",
      "Train loss and acc of batch 63: 49.118202209472656, 0.96875\n",
      "Train loss and acc of batch 64: 48.14354705810547, 0.984375\n",
      "Train loss and acc of batch 65: 47.926780700683594, 1.0\n",
      "Train loss and acc of batch 66: 47.9267692565918, 1.0\n",
      "Train loss and acc of batch 67: 48.739227294921875, 0.96875\n",
      "Train loss and acc of batch 68: 48.52245330810547, 0.984375\n",
      "Train loss and acc of batch 69: 48.14350891113281, 0.984375\n",
      "Train loss and acc of batch 70: 47.92673873901367, 1.0\n",
      "Training accuracy and loss of epoch #208: 0.9892, 48.2550\n",
      "Saved model by train loss 48.25501138391629\n",
      "Train loss and acc of batch 0: 47.926734924316406, 1.0\n",
      "Train loss and acc of batch 1: 47.92671585083008, 1.0\n",
      "Train loss and acc of batch 2: 48.212562561035156, 0.984375\n",
      "Train loss and acc of batch 3: 48.143463134765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.92669677734375, 1.0\n",
      "Train loss and acc of batch 5: 49.275604248046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.429290771484375, 0.96875\n",
      "Train loss and acc of batch 7: 47.926666259765625, 1.0\n",
      "Train loss and acc of batch 8: 48.522361755371094, 0.984375\n",
      "Train loss and acc of batch 9: 48.212501525878906, 0.984375\n",
      "Train loss and acc of batch 10: 47.9266357421875, 1.0\n",
      "Train loss and acc of batch 11: 47.926631927490234, 1.0\n",
      "Train loss and acc of batch 12: 48.67984390258789, 0.984375\n",
      "Train loss and acc of batch 13: 48.14337921142578, 0.984375\n",
      "Train loss and acc of batch 14: 48.14336395263672, 0.984375\n",
      "Train loss and acc of batch 15: 48.52229309082031, 0.984375\n",
      "Train loss and acc of batch 16: 48.52228546142578, 0.984375\n",
      "Train loss and acc of batch 17: 48.6797981262207, 0.984375\n",
      "Train loss and acc of batch 18: 48.80812072753906, 0.96875\n",
      "Train loss and acc of batch 19: 47.92655563354492, 1.0\n",
      "Train loss and acc of batch 20: 47.92654800415039, 1.0\n",
      "Train loss and acc of batch 21: 48.522239685058594, 0.984375\n",
      "Train loss and acc of batch 22: 48.52223205566406, 0.984375\n",
      "Train loss and acc of batch 23: 47.92652130126953, 1.0\n",
      "Train loss and acc of batch 24: 48.522216796875, 0.984375\n",
      "Train loss and acc of batch 25: 47.92650604248047, 1.0\n",
      "Train loss and acc of batch 26: 47.92649459838867, 1.0\n",
      "Train loss and acc of batch 27: 47.926490783691406, 1.0\n",
      "Train loss and acc of batch 28: 47.926475524902344, 1.0\n",
      "Train loss and acc of batch 29: 48.52217102050781, 0.984375\n",
      "Train loss and acc of batch 30: 47.926456451416016, 1.0\n",
      "Train loss and acc of batch 31: 48.143211364746094, 0.984375\n",
      "Train loss and acc of batch 32: 47.92644119262695, 1.0\n",
      "Train loss and acc of batch 33: 47.926429748535156, 1.0\n",
      "Train loss and acc of batch 34: 48.522125244140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.359947204589844, 0.96875\n",
      "Train loss and acc of batch 36: 47.92640686035156, 1.0\n",
      "Train loss and acc of batch 37: 48.67961883544922, 0.984375\n",
      "Train loss and acc of batch 38: 49.27531433105469, 0.96875\n",
      "Train loss and acc of batch 39: 48.14314270019531, 0.984375\n",
      "Train loss and acc of batch 40: 47.92637252807617, 1.0\n",
      "Train loss and acc of batch 41: 49.27529525756836, 0.96875\n",
      "Train loss and acc of batch 42: 47.926353454589844, 1.0\n",
      "Train loss and acc of batch 43: 48.52204895019531, 0.984375\n",
      "Train loss and acc of batch 44: 47.92633819580078, 1.0\n",
      "Train loss and acc of batch 45: 48.52202606201172, 0.984375\n",
      "Train loss and acc of batch 46: 48.21217346191406, 0.984375\n",
      "Train loss and acc of batch 47: 47.92630386352539, 1.0\n",
      "Train loss and acc of batch 48: 47.926300048828125, 1.0\n",
      "Train loss and acc of batch 49: 47.92628860473633, 1.0\n",
      "Train loss and acc of batch 50: 48.52198791503906, 0.984375\n",
      "Train loss and acc of batch 51: 49.27519989013672, 0.96875\n",
      "Train loss and acc of batch 52: 49.182106018066406, 0.953125\n",
      "Train loss and acc of batch 53: 47.92625427246094, 1.0\n",
      "Train loss and acc of batch 54: 48.14301300048828, 0.984375\n",
      "Train loss and acc of batch 55: 47.926239013671875, 1.0\n",
      "Train loss and acc of batch 56: 47.92622756958008, 1.0\n",
      "Train loss and acc of batch 57: 48.52191925048828, 0.984375\n",
      "Train loss and acc of batch 58: 47.926212310791016, 1.0\n",
      "Train loss and acc of batch 59: 47.926204681396484, 1.0\n",
      "Train loss and acc of batch 60: 47.92619705200195, 1.0\n",
      "Train loss and acc of batch 61: 47.92618179321289, 1.0\n",
      "Train loss and acc of batch 62: 48.14293670654297, 0.984375\n",
      "Train loss and acc of batch 63: 49.11756896972656, 0.96875\n",
      "Train loss and acc of batch 64: 48.142921447753906, 0.984375\n",
      "Train loss and acc of batch 65: 47.926151275634766, 1.0\n",
      "Train loss and acc of batch 66: 47.926143646240234, 1.0\n",
      "Train loss and acc of batch 67: 48.73859405517578, 0.96875\n",
      "Train loss and acc of batch 68: 48.521820068359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.14288330078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.92610168457031, 1.0\n",
      "Training accuracy and loss of epoch #209: 0.9892, 48.2544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.254378305354585\n",
      "Train loss and acc of batch 0: 47.92609405517578, 1.0\n",
      "Train loss and acc of batch 1: 47.92607879638672, 1.0\n",
      "Train loss and acc of batch 2: 48.21192932128906, 0.984375\n",
      "Train loss and acc of batch 3: 48.14283752441406, 0.984375\n",
      "Train loss and acc of batch 4: 47.92605972290039, 1.0\n",
      "Train loss and acc of batch 5: 49.27497100830078, 0.96875\n",
      "Train loss and acc of batch 6: 48.42865753173828, 0.96875\n",
      "Train loss and acc of batch 7: 47.926025390625, 1.0\n",
      "Train loss and acc of batch 8: 48.521728515625, 0.984375\n",
      "Train loss and acc of batch 9: 48.21186828613281, 0.984375\n",
      "Train loss and acc of batch 10: 47.926002502441406, 1.0\n",
      "Train loss and acc of batch 11: 47.92599105834961, 1.0\n",
      "Train loss and acc of batch 12: 48.6792106628418, 0.984375\n",
      "Train loss and acc of batch 13: 48.142738342285156, 0.984375\n",
      "Train loss and acc of batch 14: 48.142730712890625, 0.984375\n",
      "Train loss and acc of batch 15: 48.52165985107422, 0.984375\n",
      "Train loss and acc of batch 16: 48.52165222167969, 0.984375\n",
      "Train loss and acc of batch 17: 48.67916488647461, 0.984375\n",
      "Train loss and acc of batch 18: 48.80747985839844, 0.96875\n",
      "Train loss and acc of batch 19: 47.92592239379883, 1.0\n",
      "Train loss and acc of batch 20: 47.9259147644043, 1.0\n",
      "Train loss and acc of batch 21: 48.5216064453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.52159881591797, 0.984375\n",
      "Train loss and acc of batch 23: 47.92588806152344, 1.0\n",
      "Train loss and acc of batch 24: 48.521575927734375, 0.984375\n",
      "Train loss and acc of batch 25: 47.92586898803711, 1.0\n",
      "Train loss and acc of batch 26: 47.925865173339844, 1.0\n",
      "Train loss and acc of batch 27: 47.92584991455078, 1.0\n",
      "Train loss and acc of batch 28: 47.92584228515625, 1.0\n",
      "Train loss and acc of batch 29: 48.52153778076172, 0.984375\n",
      "Train loss and acc of batch 30: 47.92582321166992, 1.0\n",
      "Train loss and acc of batch 31: 48.14258575439453, 0.984375\n",
      "Train loss and acc of batch 32: 47.92580795288086, 1.0\n",
      "Train loss and acc of batch 33: 47.92579650878906, 1.0\n",
      "Train loss and acc of batch 34: 48.52149200439453, 0.984375\n",
      "Train loss and acc of batch 35: 48.35930633544922, 0.96875\n",
      "Train loss and acc of batch 36: 47.92577362060547, 1.0\n",
      "Train loss and acc of batch 37: 48.67898941040039, 0.984375\n",
      "Train loss and acc of batch 38: 49.27467346191406, 0.96875\n",
      "Train loss and acc of batch 39: 48.14250946044922, 0.984375\n",
      "Train loss and acc of batch 40: 47.92573547363281, 1.0\n",
      "Train loss and acc of batch 41: 49.27465057373047, 0.96875\n",
      "Train loss and acc of batch 42: 47.925716400146484, 1.0\n",
      "Train loss and acc of batch 43: 48.52140808105469, 0.984375\n",
      "Train loss and acc of batch 44: 47.925697326660156, 1.0\n",
      "Train loss and acc of batch 45: 48.521400451660156, 0.984375\n",
      "Train loss and acc of batch 46: 48.21153259277344, 0.984375\n",
      "Train loss and acc of batch 47: 47.9256706237793, 1.0\n",
      "Train loss and acc of batch 48: 47.925662994384766, 1.0\n",
      "Train loss and acc of batch 49: 47.925655364990234, 1.0\n",
      "Train loss and acc of batch 50: 48.52134704589844, 0.984375\n",
      "Train loss and acc of batch 51: 49.274559020996094, 0.96875\n",
      "Train loss and acc of batch 52: 49.18146896362305, 0.953125\n",
      "Train loss and acc of batch 53: 47.92562484741211, 1.0\n",
      "Train loss and acc of batch 54: 48.14237976074219, 0.984375\n",
      "Train loss and acc of batch 55: 47.92559814453125, 1.0\n",
      "Train loss and acc of batch 56: 47.925594329833984, 1.0\n",
      "Train loss and acc of batch 57: 48.52128601074219, 0.984375\n",
      "Train loss and acc of batch 58: 47.925575256347656, 1.0\n",
      "Train loss and acc of batch 59: 47.92557144165039, 1.0\n",
      "Train loss and acc of batch 60: 47.925559997558594, 1.0\n",
      "Train loss and acc of batch 61: 47.92554473876953, 1.0\n",
      "Train loss and acc of batch 62: 48.142303466796875, 0.984375\n",
      "Train loss and acc of batch 63: 49.11692810058594, 0.96875\n",
      "Train loss and acc of batch 64: 48.14228820800781, 0.984375\n",
      "Train loss and acc of batch 65: 47.925514221191406, 1.0\n",
      "Train loss and acc of batch 66: 47.92550277709961, 1.0\n",
      "Train loss and acc of batch 67: 48.73796463012695, 0.96875\n",
      "Train loss and acc of batch 68: 48.52118682861328, 0.984375\n",
      "Train loss and acc of batch 69: 48.142234802246094, 0.984375\n",
      "Train loss and acc of batch 70: 47.92546844482422, 1.0\n",
      "Training accuracy and loss of epoch #210: 0.9892, 48.2537\n",
      "Saved model by train loss 48.25374280902702\n",
      "Train loss and acc of batch 0: 47.92545700073242, 1.0\n",
      "Train loss and acc of batch 1: 47.925453186035156, 1.0\n",
      "Train loss and acc of batch 2: 48.21129608154297, 0.984375\n",
      "Train loss and acc of batch 3: 48.142189025878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.92542266845703, 1.0\n",
      "Train loss and acc of batch 5: 49.27433776855469, 0.96875\n",
      "Train loss and acc of batch 6: 48.42802047729492, 0.96875\n",
      "Train loss and acc of batch 7: 47.92539596557617, 1.0\n",
      "Train loss and acc of batch 8: 48.521087646484375, 0.984375\n",
      "Train loss and acc of batch 9: 48.21122741699219, 0.984375\n",
      "Train loss and acc of batch 10: 47.92537307739258, 1.0\n",
      "Train loss and acc of batch 11: 47.92536926269531, 1.0\n",
      "Train loss and acc of batch 12: 48.67857360839844, 0.984375\n",
      "Train loss and acc of batch 13: 48.14210510253906, 0.984375\n",
      "Train loss and acc of batch 14: 48.14209747314453, 0.984375\n",
      "Train loss and acc of batch 15: 48.521026611328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.521018981933594, 0.984375\n",
      "Train loss and acc of batch 17: 48.67852783203125, 0.984375\n",
      "Train loss and acc of batch 18: 48.806854248046875, 0.96875\n",
      "Train loss and acc of batch 19: 47.925289154052734, 1.0\n",
      "Train loss and acc of batch 20: 47.92527770996094, 1.0\n",
      "Train loss and acc of batch 21: 48.520973205566406, 0.984375\n",
      "Train loss and acc of batch 22: 48.520965576171875, 0.984375\n",
      "Train loss and acc of batch 23: 47.925254821777344, 1.0\n",
      "Train loss and acc of batch 24: 48.52095031738281, 0.984375\n",
      "Train loss and acc of batch 25: 47.92523956298828, 1.0\n",
      "Train loss and acc of batch 26: 47.925228118896484, 1.0\n",
      "Train loss and acc of batch 27: 47.92522048950195, 1.0\n",
      "Train loss and acc of batch 28: 47.925209045410156, 1.0\n",
      "Train loss and acc of batch 29: 48.520904541015625, 0.984375\n",
      "Train loss and acc of batch 30: 47.925193786621094, 1.0\n",
      "Train loss and acc of batch 31: 48.141944885253906, 0.984375\n",
      "Train loss and acc of batch 32: 47.925174713134766, 1.0\n",
      "Train loss and acc of batch 33: 47.925167083740234, 1.0\n",
      "Train loss and acc of batch 34: 48.52085876464844, 0.984375\n",
      "Train loss and acc of batch 35: 48.358673095703125, 0.96875\n",
      "Train loss and acc of batch 36: 47.92513656616211, 1.0\n",
      "Train loss and acc of batch 37: 48.678348541259766, 0.984375\n",
      "Train loss and acc of batch 38: 49.2740478515625, 0.96875\n",
      "Train loss and acc of batch 39: 48.141883850097656, 0.984375\n",
      "Train loss and acc of batch 40: 47.92510223388672, 1.0\n",
      "Train loss and acc of batch 41: 49.27402114868164, 0.96875\n",
      "Train loss and acc of batch 42: 47.92508316040039, 1.0\n",
      "Train loss and acc of batch 43: 48.520774841308594, 0.984375\n",
      "Train loss and acc of batch 44: 47.92506790161133, 1.0\n",
      "Train loss and acc of batch 45: 48.52075958251953, 0.984375\n",
      "Train loss and acc of batch 46: 48.210899353027344, 0.984375\n",
      "Train loss and acc of batch 47: 47.92504119873047, 1.0\n",
      "Train loss and acc of batch 48: 47.92503356933594, 1.0\n",
      "Train loss and acc of batch 49: 47.92502212524414, 1.0\n",
      "Train loss and acc of batch 50: 48.520713806152344, 0.984375\n",
      "Train loss and acc of batch 51: 49.27392578125, 0.96875\n",
      "Train loss and acc of batch 52: 49.18083953857422, 0.953125\n",
      "Train loss and acc of batch 53: 47.92498779296875, 1.0\n",
      "Train loss and acc of batch 54: 48.14173889160156, 0.984375\n",
      "Train loss and acc of batch 55: 47.92497253417969, 1.0\n",
      "Train loss and acc of batch 56: 47.924957275390625, 1.0\n",
      "Train loss and acc of batch 57: 48.520652770996094, 0.984375\n",
      "Train loss and acc of batch 58: 47.92494201660156, 1.0\n",
      "Train loss and acc of batch 59: 47.92493438720703, 1.0\n",
      "Train loss and acc of batch 60: 47.9249267578125, 1.0\n",
      "Train loss and acc of batch 61: 47.92491912841797, 1.0\n",
      "Train loss and acc of batch 62: 48.14167022705078, 0.984375\n",
      "Train loss and acc of batch 63: 49.11629867553711, 0.96875\n",
      "Train loss and acc of batch 64: 48.14164733886719, 0.984375\n",
      "Train loss and acc of batch 65: 47.92487716674805, 1.0\n",
      "Train loss and acc of batch 66: 47.92487335205078, 1.0\n",
      "Train loss and acc of batch 67: 48.737327575683594, 0.96875\n",
      "Train loss and acc of batch 68: 48.52055358886719, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 48.14161682128906, 0.984375\n",
      "Train loss and acc of batch 70: 47.92483139038086, 1.0\n",
      "Training accuracy and loss of epoch #211: 0.9892, 48.2531\n",
      "Saved model by train loss 48.25310967673718\n",
      "Train loss and acc of batch 0: 47.924827575683594, 1.0\n",
      "Train loss and acc of batch 1: 47.9248161315918, 1.0\n",
      "Train loss and acc of batch 2: 48.210655212402344, 0.984375\n",
      "Train loss and acc of batch 3: 48.141563415527344, 0.984375\n",
      "Train loss and acc of batch 4: 47.9247932434082, 1.0\n",
      "Train loss and acc of batch 5: 49.273704528808594, 0.96875\n",
      "Train loss and acc of batch 6: 48.42738723754883, 0.96875\n",
      "Train loss and acc of batch 7: 47.92476272583008, 1.0\n",
      "Train loss and acc of batch 8: 48.52045440673828, 0.984375\n",
      "Train loss and acc of batch 9: 48.210601806640625, 0.984375\n",
      "Train loss and acc of batch 10: 47.92473602294922, 1.0\n",
      "Train loss and acc of batch 11: 47.92472839355469, 1.0\n",
      "Train loss and acc of batch 12: 48.677947998046875, 0.984375\n",
      "Train loss and acc of batch 13: 48.14147186279297, 0.984375\n",
      "Train loss and acc of batch 14: 48.14146423339844, 0.984375\n",
      "Train loss and acc of batch 15: 48.52039337158203, 0.984375\n",
      "Train loss and acc of batch 16: 48.5203857421875, 0.984375\n",
      "Train loss and acc of batch 17: 48.67790222167969, 0.984375\n",
      "Train loss and acc of batch 18: 48.80622100830078, 0.96875\n",
      "Train loss and acc of batch 19: 47.924659729003906, 1.0\n",
      "Train loss and acc of batch 20: 47.924644470214844, 1.0\n",
      "Train loss and acc of batch 21: 48.52033996582031, 0.984375\n",
      "Train loss and acc of batch 22: 48.52032470703125, 0.984375\n",
      "Train loss and acc of batch 23: 47.924625396728516, 1.0\n",
      "Train loss and acc of batch 24: 48.52030944824219, 0.984375\n",
      "Train loss and acc of batch 25: 47.92460250854492, 1.0\n",
      "Train loss and acc of batch 26: 47.924598693847656, 1.0\n",
      "Train loss and acc of batch 27: 47.92458724975586, 1.0\n",
      "Train loss and acc of batch 28: 47.92457580566406, 1.0\n",
      "Train loss and acc of batch 29: 48.52027130126953, 0.984375\n",
      "Train loss and acc of batch 30: 47.924556732177734, 1.0\n",
      "Train loss and acc of batch 31: 48.141319274902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.924537658691406, 1.0\n",
      "Train loss and acc of batch 33: 47.92453384399414, 1.0\n",
      "Train loss and acc of batch 34: 48.520225524902344, 0.984375\n",
      "Train loss and acc of batch 35: 48.3580436706543, 0.96875\n",
      "Train loss and acc of batch 36: 47.924503326416016, 1.0\n",
      "Train loss and acc of batch 37: 48.6777229309082, 0.984375\n",
      "Train loss and acc of batch 38: 49.273414611816406, 0.96875\n",
      "Train loss and acc of batch 39: 48.14124298095703, 0.984375\n",
      "Train loss and acc of batch 40: 47.92447280883789, 1.0\n",
      "Train loss and acc of batch 41: 49.27338790893555, 0.96875\n",
      "Train loss and acc of batch 42: 47.92445373535156, 1.0\n",
      "Train loss and acc of batch 43: 48.52014923095703, 0.984375\n",
      "Train loss and acc of batch 44: 47.924434661865234, 1.0\n",
      "Train loss and acc of batch 45: 48.52012634277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.21027374267578, 0.984375\n",
      "Train loss and acc of batch 47: 47.924407958984375, 1.0\n",
      "Train loss and acc of batch 48: 47.924400329589844, 1.0\n",
      "Train loss and acc of batch 49: 47.92438888549805, 1.0\n",
      "Train loss and acc of batch 50: 48.52008056640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.27330017089844, 0.96875\n",
      "Train loss and acc of batch 52: 49.180198669433594, 0.953125\n",
      "Train loss and acc of batch 53: 47.92435073852539, 1.0\n",
      "Train loss and acc of batch 54: 48.14111328125, 0.984375\n",
      "Train loss and acc of batch 55: 47.92433547973633, 1.0\n",
      "Train loss and acc of batch 56: 47.92433166503906, 1.0\n",
      "Train loss and acc of batch 57: 48.52001953125, 0.984375\n",
      "Train loss and acc of batch 58: 47.9243049621582, 1.0\n",
      "Train loss and acc of batch 59: 47.92430114746094, 1.0\n",
      "Train loss and acc of batch 60: 47.92428970336914, 1.0\n",
      "Train loss and acc of batch 61: 47.92428207397461, 1.0\n",
      "Train loss and acc of batch 62: 48.14103698730469, 0.984375\n",
      "Train loss and acc of batch 63: 49.11566925048828, 0.96875\n",
      "Train loss and acc of batch 64: 48.141021728515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.92424774169922, 1.0\n",
      "Train loss and acc of batch 66: 47.924232482910156, 1.0\n",
      "Train loss and acc of batch 67: 48.7366943359375, 0.96875\n",
      "Train loss and acc of batch 68: 48.519927978515625, 0.984375\n",
      "Train loss and acc of batch 69: 48.14097595214844, 0.984375\n",
      "Train loss and acc of batch 70: 47.9242057800293, 1.0\n",
      "Training accuracy and loss of epoch #212: 0.9892, 48.2525\n",
      "Saved model by train loss 48.25247708172866\n",
      "Train loss and acc of batch 0: 47.9241943359375, 1.0\n",
      "Train loss and acc of batch 1: 47.9241828918457, 1.0\n",
      "Train loss and acc of batch 2: 48.21002960205078, 0.984375\n",
      "Train loss and acc of batch 3: 48.14093017578125, 0.984375\n",
      "Train loss and acc of batch 4: 47.92416000366211, 1.0\n",
      "Train loss and acc of batch 5: 49.27307891845703, 0.96875\n",
      "Train loss and acc of batch 6: 48.4267578125, 0.96875\n",
      "Train loss and acc of batch 7: 47.92412567138672, 1.0\n",
      "Train loss and acc of batch 8: 48.51982879638672, 0.984375\n",
      "Train loss and acc of batch 9: 48.2099609375, 0.984375\n",
      "Train loss and acc of batch 10: 47.924102783203125, 1.0\n",
      "Train loss and acc of batch 11: 47.92409896850586, 1.0\n",
      "Train loss and acc of batch 12: 48.677310943603516, 0.984375\n",
      "Train loss and acc of batch 13: 48.140846252441406, 0.984375\n",
      "Train loss and acc of batch 14: 48.140838623046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.519752502441406, 0.984375\n",
      "Train loss and acc of batch 16: 48.519752502441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.67726135253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.80558395385742, 0.96875\n",
      "Train loss and acc of batch 19: 47.92402267456055, 1.0\n",
      "Train loss and acc of batch 20: 47.92401123046875, 1.0\n",
      "Train loss and acc of batch 21: 48.51970672607422, 0.984375\n",
      "Train loss and acc of batch 22: 48.51970672607422, 0.984375\n",
      "Train loss and acc of batch 23: 47.92398452758789, 1.0\n",
      "Train loss and acc of batch 24: 48.519676208496094, 0.984375\n",
      "Train loss and acc of batch 25: 47.92396926879883, 1.0\n",
      "Train loss and acc of batch 26: 47.92395782470703, 1.0\n",
      "Train loss and acc of batch 27: 47.923954010009766, 1.0\n",
      "Train loss and acc of batch 28: 47.92394256591797, 1.0\n",
      "Train loss and acc of batch 29: 48.51963806152344, 0.984375\n",
      "Train loss and acc of batch 30: 47.923927307128906, 1.0\n",
      "Train loss and acc of batch 31: 48.14067840576172, 0.984375\n",
      "Train loss and acc of batch 32: 47.92390441894531, 1.0\n",
      "Train loss and acc of batch 33: 47.92390060424805, 1.0\n",
      "Train loss and acc of batch 34: 48.51958465576172, 0.984375\n",
      "Train loss and acc of batch 35: 48.3574104309082, 0.96875\n",
      "Train loss and acc of batch 36: 47.92387008666992, 1.0\n",
      "Train loss and acc of batch 37: 48.67708206176758, 0.984375\n",
      "Train loss and acc of batch 38: 49.27277374267578, 0.96875\n",
      "Train loss and acc of batch 39: 48.14060974121094, 0.984375\n",
      "Train loss and acc of batch 40: 47.92383575439453, 1.0\n",
      "Train loss and acc of batch 41: 49.27275848388672, 0.96875\n",
      "Train loss and acc of batch 42: 47.9238166809082, 1.0\n",
      "Train loss and acc of batch 43: 48.519508361816406, 0.984375\n",
      "Train loss and acc of batch 44: 47.92380142211914, 1.0\n",
      "Train loss and acc of batch 45: 48.519493103027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.209632873535156, 0.984375\n",
      "Train loss and acc of batch 47: 47.92377853393555, 1.0\n",
      "Train loss and acc of batch 48: 47.92375946044922, 1.0\n",
      "Train loss and acc of batch 49: 47.92375946044922, 1.0\n",
      "Train loss and acc of batch 50: 48.51945495605469, 0.984375\n",
      "Train loss and acc of batch 51: 49.27265930175781, 0.96875\n",
      "Train loss and acc of batch 52: 49.1795654296875, 0.953125\n",
      "Train loss and acc of batch 53: 47.9237174987793, 1.0\n",
      "Train loss and acc of batch 54: 48.140472412109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.9237060546875, 1.0\n",
      "Train loss and acc of batch 56: 47.92369079589844, 1.0\n",
      "Train loss and acc of batch 57: 48.519386291503906, 0.984375\n",
      "Train loss and acc of batch 58: 47.923675537109375, 1.0\n",
      "Train loss and acc of batch 59: 47.923667907714844, 1.0\n",
      "Train loss and acc of batch 60: 47.92365646362305, 1.0\n",
      "Train loss and acc of batch 61: 47.92365264892578, 1.0\n",
      "Train loss and acc of batch 62: 48.140403747558594, 0.984375\n",
      "Train loss and acc of batch 63: 49.11503219604492, 0.96875\n",
      "Train loss and acc of batch 64: 48.14038848876953, 0.984375\n",
      "Train loss and acc of batch 65: 47.923614501953125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 66: 47.92360305786133, 1.0\n",
      "Train loss and acc of batch 67: 48.73606491088867, 0.96875\n",
      "Train loss and acc of batch 68: 48.519287109375, 0.984375\n",
      "Train loss and acc of batch 69: 48.140342712402344, 0.984375\n",
      "Train loss and acc of batch 70: 47.92356872558594, 1.0\n",
      "Training accuracy and loss of epoch #213: 0.9892, 48.2518\n",
      "Saved model by train loss 48.251843143516865\n",
      "Train loss and acc of batch 0: 47.92355728149414, 1.0\n",
      "Train loss and acc of batch 1: 47.923553466796875, 1.0\n",
      "Train loss and acc of batch 2: 48.209388732910156, 0.984375\n",
      "Train loss and acc of batch 3: 48.140296936035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.923526763916016, 1.0\n",
      "Train loss and acc of batch 5: 49.27244567871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.426124572753906, 0.96875\n",
      "Train loss and acc of batch 7: 47.923500061035156, 1.0\n",
      "Train loss and acc of batch 8: 48.519187927246094, 0.984375\n",
      "Train loss and acc of batch 9: 48.209327697753906, 0.984375\n",
      "Train loss and acc of batch 10: 47.9234733581543, 1.0\n",
      "Train loss and acc of batch 11: 47.9234619140625, 1.0\n",
      "Train loss and acc of batch 12: 48.676673889160156, 0.984375\n",
      "Train loss and acc of batch 13: 48.14020538330078, 0.984375\n",
      "Train loss and acc of batch 14: 48.14019775390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.519134521484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.51911926269531, 0.984375\n",
      "Train loss and acc of batch 17: 48.67662811279297, 0.984375\n",
      "Train loss and acc of batch 18: 48.80495071411133, 0.96875\n",
      "Train loss and acc of batch 19: 47.92338943481445, 1.0\n",
      "Train loss and acc of batch 20: 47.92338562011719, 1.0\n",
      "Train loss and acc of batch 21: 48.519081115722656, 0.984375\n",
      "Train loss and acc of batch 22: 48.519065856933594, 0.984375\n",
      "Train loss and acc of batch 23: 47.9233512878418, 1.0\n",
      "Train loss and acc of batch 24: 48.51905059814453, 0.984375\n",
      "Train loss and acc of batch 25: 47.923336029052734, 1.0\n",
      "Train loss and acc of batch 26: 47.9233283996582, 1.0\n",
      "Train loss and acc of batch 27: 47.923316955566406, 1.0\n",
      "Train loss and acc of batch 28: 47.923309326171875, 1.0\n",
      "Train loss and acc of batch 29: 48.519004821777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.92329406738281, 1.0\n",
      "Train loss and acc of batch 31: 48.140052795410156, 0.984375\n",
      "Train loss and acc of batch 32: 47.923274993896484, 1.0\n",
      "Train loss and acc of batch 33: 47.92326354980469, 1.0\n",
      "Train loss and acc of batch 34: 48.518959045410156, 0.984375\n",
      "Train loss and acc of batch 35: 48.356781005859375, 0.96875\n",
      "Train loss and acc of batch 36: 47.923240661621094, 1.0\n",
      "Train loss and acc of batch 37: 48.67645263671875, 0.984375\n",
      "Train loss and acc of batch 38: 49.27214813232422, 0.96875\n",
      "Train loss and acc of batch 39: 48.139976501464844, 0.984375\n",
      "Train loss and acc of batch 40: 47.9232063293457, 1.0\n",
      "Train loss and acc of batch 41: 49.27212142944336, 0.96875\n",
      "Train loss and acc of batch 42: 47.923187255859375, 1.0\n",
      "Train loss and acc of batch 43: 48.51887512207031, 0.984375\n",
      "Train loss and acc of batch 44: 47.92317199707031, 1.0\n",
      "Train loss and acc of batch 45: 48.51885986328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.209007263183594, 0.984375\n",
      "Train loss and acc of batch 47: 47.92314147949219, 1.0\n",
      "Train loss and acc of batch 48: 47.92313766479492, 1.0\n",
      "Train loss and acc of batch 49: 47.923126220703125, 1.0\n",
      "Train loss and acc of batch 50: 48.51881408691406, 0.984375\n",
      "Train loss and acc of batch 51: 49.27202606201172, 0.96875\n",
      "Train loss and acc of batch 52: 49.1789436340332, 0.953125\n",
      "Train loss and acc of batch 53: 47.92308807373047, 1.0\n",
      "Train loss and acc of batch 54: 48.13984680175781, 0.984375\n",
      "Train loss and acc of batch 55: 47.923072814941406, 1.0\n",
      "Train loss and acc of batch 56: 47.923057556152344, 1.0\n",
      "Train loss and acc of batch 57: 48.51875305175781, 0.984375\n",
      "Train loss and acc of batch 58: 47.92304229736328, 1.0\n",
      "Train loss and acc of batch 59: 47.92303466796875, 1.0\n",
      "Train loss and acc of batch 60: 47.92302703857422, 1.0\n",
      "Train loss and acc of batch 61: 47.92301940917969, 1.0\n",
      "Train loss and acc of batch 62: 48.13977813720703, 0.984375\n",
      "Train loss and acc of batch 63: 49.114402770996094, 0.96875\n",
      "Train loss and acc of batch 64: 48.13975524902344, 0.984375\n",
      "Train loss and acc of batch 65: 47.92298126220703, 1.0\n",
      "Train loss and acc of batch 66: 47.922969818115234, 1.0\n",
      "Train loss and acc of batch 67: 48.73543167114258, 0.96875\n",
      "Train loss and acc of batch 68: 48.51866149902344, 0.984375\n",
      "Train loss and acc of batch 69: 48.13970947265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.922935485839844, 1.0\n",
      "Training accuracy and loss of epoch #214: 0.9892, 48.2512\n",
      "Saved model by train loss 48.25121130070216\n",
      "Train loss and acc of batch 0: 47.92292785644531, 1.0\n",
      "Train loss and acc of batch 1: 47.92292022705078, 1.0\n",
      "Train loss and acc of batch 2: 48.208763122558594, 0.984375\n",
      "Train loss and acc of batch 3: 48.13966369628906, 0.984375\n",
      "Train loss and acc of batch 4: 47.92289352416992, 1.0\n",
      "Train loss and acc of batch 5: 49.27180480957031, 0.96875\n",
      "Train loss and acc of batch 6: 48.42549514770508, 0.96875\n",
      "Train loss and acc of batch 7: 47.92286682128906, 1.0\n",
      "Train loss and acc of batch 8: 48.5185546875, 0.984375\n",
      "Train loss and acc of batch 9: 48.208702087402344, 0.984375\n",
      "Train loss and acc of batch 10: 47.9228401184082, 1.0\n",
      "Train loss and acc of batch 11: 47.92283248901367, 1.0\n",
      "Train loss and acc of batch 12: 48.676048278808594, 0.984375\n",
      "Train loss and acc of batch 13: 48.13957977294922, 0.984375\n",
      "Train loss and acc of batch 14: 48.139564514160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.51849365234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.51848602294922, 0.984375\n",
      "Train loss and acc of batch 17: 48.67599868774414, 0.984375\n",
      "Train loss and acc of batch 18: 48.804325103759766, 0.96875\n",
      "Train loss and acc of batch 19: 47.922760009765625, 1.0\n",
      "Train loss and acc of batch 20: 47.92275619506836, 1.0\n",
      "Train loss and acc of batch 21: 48.51844787597656, 0.984375\n",
      "Train loss and acc of batch 22: 48.5184326171875, 0.984375\n",
      "Train loss and acc of batch 23: 47.92272186279297, 1.0\n",
      "Train loss and acc of batch 24: 48.51841735839844, 0.984375\n",
      "Train loss and acc of batch 25: 47.922706604003906, 1.0\n",
      "Train loss and acc of batch 26: 47.922698974609375, 1.0\n",
      "Train loss and acc of batch 27: 47.92268753051758, 1.0\n",
      "Train loss and acc of batch 28: 47.92268371582031, 1.0\n",
      "Train loss and acc of batch 29: 48.51837158203125, 0.984375\n",
      "Train loss and acc of batch 30: 47.92266082763672, 1.0\n",
      "Train loss and acc of batch 31: 48.13941955566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.92264175415039, 1.0\n",
      "Train loss and acc of batch 33: 47.922637939453125, 1.0\n",
      "Train loss and acc of batch 34: 48.518333435058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.35614776611328, 0.96875\n",
      "Train loss and acc of batch 36: 47.922603607177734, 1.0\n",
      "Train loss and acc of batch 37: 48.67582702636719, 0.984375\n",
      "Train loss and acc of batch 38: 49.271514892578125, 0.96875\n",
      "Train loss and acc of batch 39: 48.13935089111328, 0.984375\n",
      "Train loss and acc of batch 40: 47.92258071899414, 1.0\n",
      "Train loss and acc of batch 41: 49.271488189697266, 0.96875\n",
      "Train loss and acc of batch 42: 47.92255783081055, 1.0\n",
      "Train loss and acc of batch 43: 48.51824951171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.92253494262695, 1.0\n",
      "Train loss and acc of batch 45: 48.518226623535156, 0.984375\n",
      "Train loss and acc of batch 46: 48.20836639404297, 0.984375\n",
      "Train loss and acc of batch 47: 47.92251205444336, 1.0\n",
      "Train loss and acc of batch 48: 47.92250442504883, 1.0\n",
      "Train loss and acc of batch 49: 47.9224967956543, 1.0\n",
      "Train loss and acc of batch 50: 48.51818084716797, 0.984375\n",
      "Train loss and acc of batch 51: 49.271400451660156, 0.96875\n",
      "Train loss and acc of batch 52: 49.178306579589844, 0.953125\n",
      "Train loss and acc of batch 53: 47.92245864868164, 1.0\n",
      "Train loss and acc of batch 54: 48.13921356201172, 0.984375\n",
      "Train loss and acc of batch 55: 47.92243957519531, 1.0\n",
      "Train loss and acc of batch 56: 47.92243194580078, 1.0\n",
      "Train loss and acc of batch 57: 48.51811981201172, 0.984375\n",
      "Train loss and acc of batch 58: 47.92241287231445, 1.0\n",
      "Train loss and acc of batch 59: 47.92240524291992, 1.0\n",
      "Train loss and acc of batch 60: 47.922393798828125, 1.0\n",
      "Train loss and acc of batch 61: 47.922386169433594, 1.0\n",
      "Train loss and acc of batch 62: 48.13914489746094, 0.984375\n",
      "Train loss and acc of batch 63: 49.113773345947266, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 64: 48.139122009277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.9223518371582, 1.0\n",
      "Train loss and acc of batch 66: 47.922340393066406, 1.0\n",
      "Train loss and acc of batch 67: 48.734798431396484, 0.96875\n",
      "Train loss and acc of batch 68: 48.518028259277344, 0.984375\n",
      "Train loss and acc of batch 69: 48.139076232910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.92230987548828, 1.0\n",
      "Training accuracy and loss of epoch #215: 0.9892, 48.2506\n",
      "Saved model by train loss 48.25058021008129\n",
      "Train loss and acc of batch 0: 47.92229461669922, 1.0\n",
      "Train loss and acc of batch 1: 47.92228317260742, 1.0\n",
      "Train loss and acc of batch 2: 48.2081298828125, 0.984375\n",
      "Train loss and acc of batch 3: 48.13903045654297, 0.984375\n",
      "Train loss and acc of batch 4: 47.92226028442383, 1.0\n",
      "Train loss and acc of batch 5: 49.27117919921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.424861907958984, 0.96875\n",
      "Train loss and acc of batch 7: 47.922237396240234, 1.0\n",
      "Train loss and acc of batch 8: 48.517921447753906, 0.984375\n",
      "Train loss and acc of batch 9: 48.20806884765625, 0.984375\n",
      "Train loss and acc of batch 10: 47.92220687866211, 1.0\n",
      "Train loss and acc of batch 11: 47.92219924926758, 1.0\n",
      "Train loss and acc of batch 12: 48.6754150390625, 0.984375\n",
      "Train loss and acc of batch 13: 48.138946533203125, 0.984375\n",
      "Train loss and acc of batch 14: 48.138938903808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.51786804199219, 0.984375\n",
      "Train loss and acc of batch 16: 48.517852783203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.67536926269531, 0.984375\n",
      "Train loss and acc of batch 18: 48.803688049316406, 0.96875\n",
      "Train loss and acc of batch 19: 47.9221305847168, 1.0\n",
      "Train loss and acc of batch 20: 47.922119140625, 1.0\n",
      "Train loss and acc of batch 21: 48.51780700683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.517799377441406, 0.984375\n",
      "Train loss and acc of batch 23: 47.922096252441406, 1.0\n",
      "Train loss and acc of batch 24: 48.517784118652344, 0.984375\n",
      "Train loss and acc of batch 25: 47.92207336425781, 1.0\n",
      "Train loss and acc of batch 26: 47.922061920166016, 1.0\n",
      "Train loss and acc of batch 27: 47.92205047607422, 1.0\n",
      "Train loss and acc of batch 28: 47.92205047607422, 1.0\n",
      "Train loss and acc of batch 29: 48.51774597167969, 0.984375\n",
      "Train loss and acc of batch 30: 47.92203140258789, 1.0\n",
      "Train loss and acc of batch 31: 48.13878631591797, 0.984375\n",
      "Train loss and acc of batch 32: 47.92201232910156, 1.0\n",
      "Train loss and acc of batch 33: 47.922000885009766, 1.0\n",
      "Train loss and acc of batch 34: 48.5177001953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.35551452636719, 0.96875\n",
      "Train loss and acc of batch 36: 47.921974182128906, 1.0\n",
      "Train loss and acc of batch 37: 48.675193786621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.27088165283203, 0.96875\n",
      "Train loss and acc of batch 39: 48.138710021972656, 0.984375\n",
      "Train loss and acc of batch 40: 47.92194366455078, 1.0\n",
      "Train loss and acc of batch 41: 49.27085494995117, 0.96875\n",
      "Train loss and acc of batch 42: 47.92192459106445, 1.0\n",
      "Train loss and acc of batch 43: 48.517616271972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.92190170288086, 1.0\n",
      "Train loss and acc of batch 45: 48.517601013183594, 0.984375\n",
      "Train loss and acc of batch 46: 48.207740783691406, 0.984375\n",
      "Train loss and acc of batch 47: 47.921878814697266, 1.0\n",
      "Train loss and acc of batch 48: 47.921871185302734, 1.0\n",
      "Train loss and acc of batch 49: 47.92185974121094, 1.0\n",
      "Train loss and acc of batch 50: 48.517555236816406, 0.984375\n",
      "Train loss and acc of batch 51: 49.27076721191406, 0.96875\n",
      "Train loss and acc of batch 52: 49.177677154541016, 0.953125\n",
      "Train loss and acc of batch 53: 47.92182540893555, 1.0\n",
      "Train loss and acc of batch 54: 48.138572692871094, 0.984375\n",
      "Train loss and acc of batch 55: 47.92180633544922, 1.0\n",
      "Train loss and acc of batch 56: 47.92179870605469, 1.0\n",
      "Train loss and acc of batch 57: 48.517494201660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.92177963256836, 1.0\n",
      "Train loss and acc of batch 59: 47.92177200317383, 1.0\n",
      "Train loss and acc of batch 60: 47.9217643737793, 1.0\n",
      "Train loss and acc of batch 61: 47.9217529296875, 1.0\n",
      "Train loss and acc of batch 62: 48.13850402832031, 0.984375\n",
      "Train loss and acc of batch 63: 49.11314010620117, 0.96875\n",
      "Train loss and acc of batch 64: 48.13848876953125, 0.984375\n",
      "Train loss and acc of batch 65: 47.921714782714844, 1.0\n",
      "Train loss and acc of batch 66: 47.921714782714844, 1.0\n",
      "Train loss and acc of batch 67: 48.734169006347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.51738739013672, 0.984375\n",
      "Train loss and acc of batch 69: 48.13844299316406, 0.984375\n",
      "Train loss and acc of batch 70: 47.92167282104492, 1.0\n",
      "Training accuracy and loss of epoch #216: 0.9892, 48.2499\n",
      "Saved model by train loss 48.24994745388837\n",
      "Train loss and acc of batch 0: 47.921661376953125, 1.0\n",
      "Train loss and acc of batch 1: 47.921653747558594, 1.0\n",
      "Train loss and acc of batch 2: 48.207496643066406, 0.984375\n",
      "Train loss and acc of batch 3: 48.138404846191406, 0.984375\n",
      "Train loss and acc of batch 4: 47.921627044677734, 1.0\n",
      "Train loss and acc of batch 5: 49.270545959472656, 0.96875\n",
      "Train loss and acc of batch 6: 48.42422866821289, 0.96875\n",
      "Train loss and acc of batch 7: 47.921600341796875, 1.0\n",
      "Train loss and acc of batch 8: 48.517295837402344, 0.984375\n",
      "Train loss and acc of batch 9: 48.20744323730469, 0.984375\n",
      "Train loss and acc of batch 10: 47.921573638916016, 1.0\n",
      "Train loss and acc of batch 11: 47.921566009521484, 1.0\n",
      "Train loss and acc of batch 12: 48.674781799316406, 0.984375\n",
      "Train loss and acc of batch 13: 48.13831329345703, 0.984375\n",
      "Train loss and acc of batch 14: 48.1383056640625, 0.984375\n",
      "Train loss and acc of batch 15: 48.517234802246094, 0.984375\n",
      "Train loss and acc of batch 16: 48.51721954345703, 0.984375\n",
      "Train loss and acc of batch 17: 48.67473602294922, 0.984375\n",
      "Train loss and acc of batch 18: 48.80305480957031, 0.96875\n",
      "Train loss and acc of batch 19: 47.92149353027344, 1.0\n",
      "Train loss and acc of batch 20: 47.921485900878906, 1.0\n",
      "Train loss and acc of batch 21: 48.517181396484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.517173767089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.92146301269531, 1.0\n",
      "Train loss and acc of batch 24: 48.51715087890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.921443939208984, 1.0\n",
      "Train loss and acc of batch 26: 47.92143630981445, 1.0\n",
      "Train loss and acc of batch 27: 47.921424865722656, 1.0\n",
      "Train loss and acc of batch 28: 47.921409606933594, 1.0\n",
      "Train loss and acc of batch 29: 48.517112731933594, 0.984375\n",
      "Train loss and acc of batch 30: 47.92139434814453, 1.0\n",
      "Train loss and acc of batch 31: 48.138153076171875, 0.984375\n",
      "Train loss and acc of batch 32: 47.92137908935547, 1.0\n",
      "Train loss and acc of batch 33: 47.92136764526367, 1.0\n",
      "Train loss and acc of batch 34: 48.517059326171875, 0.984375\n",
      "Train loss and acc of batch 35: 48.354881286621094, 0.96875\n",
      "Train loss and acc of batch 36: 47.92134475708008, 1.0\n",
      "Train loss and acc of batch 37: 48.674564361572266, 0.984375\n",
      "Train loss and acc of batch 38: 49.27024841308594, 0.96875\n",
      "Train loss and acc of batch 39: 48.13807678222656, 0.984375\n",
      "Train loss and acc of batch 40: 47.92130661010742, 1.0\n",
      "Train loss and acc of batch 41: 49.270225524902344, 0.96875\n",
      "Train loss and acc of batch 42: 47.92129135131836, 1.0\n",
      "Train loss and acc of batch 43: 48.51698303222656, 0.984375\n",
      "Train loss and acc of batch 44: 47.92127227783203, 1.0\n",
      "Train loss and acc of batch 45: 48.5169677734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.20710754394531, 0.984375\n",
      "Train loss and acc of batch 47: 47.92124557495117, 1.0\n",
      "Train loss and acc of batch 48: 47.92123794555664, 1.0\n",
      "Train loss and acc of batch 49: 47.921226501464844, 1.0\n",
      "Train loss and acc of batch 50: 48.51692199707031, 0.984375\n",
      "Train loss and acc of batch 51: 49.27013397216797, 0.96875\n",
      "Train loss and acc of batch 52: 49.177040100097656, 0.953125\n",
      "Train loss and acc of batch 53: 47.92119216918945, 1.0\n",
      "Train loss and acc of batch 54: 48.13794708251953, 0.984375\n",
      "Train loss and acc of batch 55: 47.92116928100586, 1.0\n",
      "Train loss and acc of batch 56: 47.92116165161133, 1.0\n",
      "Train loss and acc of batch 57: 48.51686096191406, 0.984375\n",
      "Train loss and acc of batch 58: 47.921146392822266, 1.0\n",
      "Train loss and acc of batch 59: 47.921138763427734, 1.0\n",
      "Train loss and acc of batch 60: 47.9211311340332, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 61: 47.921119689941406, 1.0\n",
      "Train loss and acc of batch 62: 48.13787078857422, 0.984375\n",
      "Train loss and acc of batch 63: 49.11250305175781, 0.96875\n",
      "Train loss and acc of batch 64: 48.13786315917969, 0.984375\n",
      "Train loss and acc of batch 65: 47.921085357666016, 1.0\n",
      "Train loss and acc of batch 66: 47.921077728271484, 1.0\n",
      "Train loss and acc of batch 67: 48.73353576660156, 0.96875\n",
      "Train loss and acc of batch 68: 48.516761779785156, 0.984375\n",
      "Train loss and acc of batch 69: 48.13780975341797, 0.984375\n",
      "Train loss and acc of batch 70: 47.92103958129883, 1.0\n",
      "Training accuracy and loss of epoch #217: 0.9892, 48.2493\n",
      "Saved model by train loss 48.2493149663361\n",
      "Train loss and acc of batch 0: 47.92102813720703, 1.0\n",
      "Train loss and acc of batch 1: 47.9210205078125, 1.0\n",
      "Train loss and acc of batch 2: 48.20686340332031, 0.984375\n",
      "Train loss and acc of batch 3: 48.13777160644531, 0.984375\n",
      "Train loss and acc of batch 4: 47.92099380493164, 1.0\n",
      "Train loss and acc of batch 5: 49.26991271972656, 0.96875\n",
      "Train loss and acc of batch 6: 48.4235954284668, 0.96875\n",
      "Train loss and acc of batch 7: 47.92097091674805, 1.0\n",
      "Train loss and acc of batch 8: 48.51666259765625, 0.984375\n",
      "Train loss and acc of batch 9: 48.20680236816406, 0.984375\n",
      "Train loss and acc of batch 10: 47.92094421386719, 1.0\n",
      "Train loss and acc of batch 11: 47.92093276977539, 1.0\n",
      "Train loss and acc of batch 12: 48.67414474487305, 0.984375\n",
      "Train loss and acc of batch 13: 48.137672424316406, 0.984375\n",
      "Train loss and acc of batch 14: 48.137672424316406, 0.984375\n",
      "Train loss and acc of batch 15: 48.51659393310547, 0.984375\n",
      "Train loss and acc of batch 16: 48.51659393310547, 0.984375\n",
      "Train loss and acc of batch 17: 48.674102783203125, 0.984375\n",
      "Train loss and acc of batch 18: 48.802425384521484, 0.96875\n",
      "Train loss and acc of batch 19: 47.92085647583008, 1.0\n",
      "Train loss and acc of batch 20: 47.92085266113281, 1.0\n",
      "Train loss and acc of batch 21: 48.51654815673828, 0.984375\n",
      "Train loss and acc of batch 22: 48.51653289794922, 0.984375\n",
      "Train loss and acc of batch 23: 47.92082595825195, 1.0\n",
      "Train loss and acc of batch 24: 48.516517639160156, 0.984375\n",
      "Train loss and acc of batch 25: 47.92081069946289, 1.0\n",
      "Train loss and acc of batch 26: 47.92080307006836, 1.0\n",
      "Train loss and acc of batch 27: 47.9207878112793, 1.0\n",
      "Train loss and acc of batch 28: 47.920780181884766, 1.0\n",
      "Train loss and acc of batch 29: 48.51647186279297, 0.984375\n",
      "Train loss and acc of batch 30: 47.9207649230957, 1.0\n",
      "Train loss and acc of batch 31: 48.13751983642578, 0.984375\n",
      "Train loss and acc of batch 32: 47.920745849609375, 1.0\n",
      "Train loss and acc of batch 33: 47.920738220214844, 1.0\n",
      "Train loss and acc of batch 34: 48.51642608642578, 0.984375\n",
      "Train loss and acc of batch 35: 48.354248046875, 0.96875\n",
      "Train loss and acc of batch 36: 47.92070770263672, 1.0\n",
      "Train loss and acc of batch 37: 48.67392349243164, 0.984375\n",
      "Train loss and acc of batch 38: 49.269615173339844, 0.96875\n",
      "Train loss and acc of batch 39: 48.137451171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.920677185058594, 1.0\n",
      "Train loss and acc of batch 41: 49.26959228515625, 0.96875\n",
      "Train loss and acc of batch 42: 47.920654296875, 1.0\n",
      "Train loss and acc of batch 43: 48.51634979248047, 0.984375\n",
      "Train loss and acc of batch 44: 47.9206428527832, 1.0\n",
      "Train loss and acc of batch 45: 48.516334533691406, 0.984375\n",
      "Train loss and acc of batch 46: 48.20647430419922, 0.984375\n",
      "Train loss and acc of batch 47: 47.92061233520508, 1.0\n",
      "Train loss and acc of batch 48: 47.92060089111328, 1.0\n",
      "Train loss and acc of batch 49: 47.920597076416016, 1.0\n",
      "Train loss and acc of batch 50: 48.51628112792969, 0.984375\n",
      "Train loss and acc of batch 51: 49.269500732421875, 0.96875\n",
      "Train loss and acc of batch 52: 49.17641067504883, 0.953125\n",
      "Train loss and acc of batch 53: 47.920562744140625, 1.0\n",
      "Train loss and acc of batch 54: 48.13731384277344, 0.984375\n",
      "Train loss and acc of batch 55: 47.92053985595703, 1.0\n",
      "Train loss and acc of batch 56: 47.920528411865234, 1.0\n",
      "Train loss and acc of batch 57: 48.51622009277344, 0.984375\n",
      "Train loss and acc of batch 58: 47.92051315307617, 1.0\n",
      "Train loss and acc of batch 59: 47.92050552368164, 1.0\n",
      "Train loss and acc of batch 60: 47.920494079589844, 1.0\n",
      "Train loss and acc of batch 61: 47.92049026489258, 1.0\n",
      "Train loss and acc of batch 62: 48.137245178222656, 0.984375\n",
      "Train loss and acc of batch 63: 49.111873626708984, 0.96875\n",
      "Train loss and acc of batch 64: 48.13722229003906, 0.984375\n",
      "Train loss and acc of batch 65: 47.92045211791992, 1.0\n",
      "Train loss and acc of batch 66: 47.92044448852539, 1.0\n",
      "Train loss and acc of batch 67: 48.7328987121582, 0.96875\n",
      "Train loss and acc of batch 68: 48.51612854003906, 0.984375\n",
      "Train loss and acc of batch 69: 48.137176513671875, 0.984375\n",
      "Train loss and acc of batch 70: 47.920406341552734, 1.0\n",
      "Training accuracy and loss of epoch #218: 0.9892, 48.2487\n",
      "Saved model by train loss 48.248681350493094\n",
      "Train loss and acc of batch 0: 47.92039489746094, 1.0\n",
      "Train loss and acc of batch 1: 47.92039108276367, 1.0\n",
      "Train loss and acc of batch 2: 48.20623016357422, 0.984375\n",
      "Train loss and acc of batch 3: 48.13713836669922, 0.984375\n",
      "Train loss and acc of batch 4: 47.92036056518555, 1.0\n",
      "Train loss and acc of batch 5: 49.26927947998047, 0.96875\n",
      "Train loss and acc of batch 6: 48.4229621887207, 0.96875\n",
      "Train loss and acc of batch 7: 47.92033767700195, 1.0\n",
      "Train loss and acc of batch 8: 48.516021728515625, 0.984375\n",
      "Train loss and acc of batch 9: 48.2061767578125, 0.984375\n",
      "Train loss and acc of batch 10: 47.92030715942383, 1.0\n",
      "Train loss and acc of batch 11: 47.92030334472656, 1.0\n",
      "Train loss and acc of batch 12: 48.67351531982422, 0.984375\n",
      "Train loss and acc of batch 13: 48.137046813964844, 0.984375\n",
      "Train loss and acc of batch 14: 48.13703155517578, 0.984375\n",
      "Train loss and acc of batch 15: 48.515968322753906, 0.984375\n",
      "Train loss and acc of batch 16: 48.515953063964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.67346954345703, 0.984375\n",
      "Train loss and acc of batch 18: 48.80179214477539, 0.96875\n",
      "Train loss and acc of batch 19: 47.920230865478516, 1.0\n",
      "Train loss and acc of batch 20: 47.920223236083984, 1.0\n",
      "Train loss and acc of batch 21: 48.515907287597656, 0.984375\n",
      "Train loss and acc of batch 22: 48.515899658203125, 0.984375\n",
      "Train loss and acc of batch 23: 47.92019271850586, 1.0\n",
      "Train loss and acc of batch 24: 48.51588439941406, 0.984375\n",
      "Train loss and acc of batch 25: 47.9201774597168, 1.0\n",
      "Train loss and acc of batch 26: 47.920166015625, 1.0\n",
      "Train loss and acc of batch 27: 47.92015838623047, 1.0\n",
      "Train loss and acc of batch 28: 47.92014694213867, 1.0\n",
      "Train loss and acc of batch 29: 48.515838623046875, 0.984375\n",
      "Train loss and acc of batch 30: 47.92013168334961, 1.0\n",
      "Train loss and acc of batch 31: 48.13688659667969, 0.984375\n",
      "Train loss and acc of batch 32: 47.92011260986328, 1.0\n",
      "Train loss and acc of batch 33: 47.92010498046875, 1.0\n",
      "Train loss and acc of batch 34: 48.51580047607422, 0.984375\n",
      "Train loss and acc of batch 35: 48.35361862182617, 0.96875\n",
      "Train loss and acc of batch 36: 47.92007827758789, 1.0\n",
      "Train loss and acc of batch 37: 48.67329025268555, 0.984375\n",
      "Train loss and acc of batch 38: 49.26898956298828, 0.96875\n",
      "Train loss and acc of batch 39: 48.136817932128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.920040130615234, 1.0\n",
      "Train loss and acc of batch 41: 49.268959045410156, 0.96875\n",
      "Train loss and acc of batch 42: 47.92002487182617, 1.0\n",
      "Train loss and acc of batch 43: 48.515716552734375, 0.984375\n",
      "Train loss and acc of batch 44: 47.920005798339844, 1.0\n",
      "Train loss and acc of batch 45: 48.51569366455078, 0.984375\n",
      "Train loss and acc of batch 46: 48.205841064453125, 0.984375\n",
      "Train loss and acc of batch 47: 47.919979095458984, 1.0\n",
      "Train loss and acc of batch 48: 47.91997528076172, 1.0\n",
      "Train loss and acc of batch 49: 47.919960021972656, 1.0\n",
      "Train loss and acc of batch 50: 48.515655517578125, 0.984375\n",
      "Train loss and acc of batch 51: 49.26886749267578, 0.96875\n",
      "Train loss and acc of batch 52: 49.17577362060547, 0.953125\n",
      "Train loss and acc of batch 53: 47.919921875, 1.0\n",
      "Train loss and acc of batch 54: 48.136680603027344, 0.984375\n",
      "Train loss and acc of batch 55: 47.91990661621094, 1.0\n",
      "Train loss and acc of batch 56: 47.91990280151367, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 57: 48.515586853027344, 0.984375\n",
      "Train loss and acc of batch 58: 47.91987609863281, 1.0\n",
      "Train loss and acc of batch 59: 47.91987228393555, 1.0\n",
      "Train loss and acc of batch 60: 47.91986083984375, 1.0\n",
      "Train loss and acc of batch 61: 47.91985321044922, 1.0\n",
      "Train loss and acc of batch 62: 48.13661193847656, 0.984375\n",
      "Train loss and acc of batch 63: 49.11124038696289, 0.96875\n",
      "Train loss and acc of batch 64: 48.1365966796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.91981506347656, 1.0\n",
      "Train loss and acc of batch 66: 47.91980743408203, 1.0\n",
      "Train loss and acc of batch 67: 48.73226547241211, 0.96875\n",
      "Train loss and acc of batch 68: 48.51549530029297, 0.984375\n",
      "Train loss and acc of batch 69: 48.13655090332031, 0.984375\n",
      "Train loss and acc of batch 70: 47.919776916503906, 1.0\n",
      "Training accuracy and loss of epoch #219: 0.9892, 48.2480\n",
      "Saved model by train loss 48.24804859430018\n",
      "Train loss and acc of batch 0: 47.919769287109375, 1.0\n",
      "Train loss and acc of batch 1: 47.91975021362305, 1.0\n",
      "Train loss and acc of batch 2: 48.205596923828125, 0.984375\n",
      "Train loss and acc of batch 3: 48.136505126953125, 0.984375\n",
      "Train loss and acc of batch 4: 47.91973114013672, 1.0\n",
      "Train loss and acc of batch 5: 49.268646240234375, 0.96875\n",
      "Train loss and acc of batch 6: 48.42232894897461, 0.96875\n",
      "Train loss and acc of batch 7: 47.91970443725586, 1.0\n",
      "Train loss and acc of batch 8: 48.51539611816406, 0.984375\n",
      "Train loss and acc of batch 9: 48.205535888671875, 0.984375\n",
      "Train loss and acc of batch 10: 47.919673919677734, 1.0\n",
      "Train loss and acc of batch 11: 47.9196662902832, 1.0\n",
      "Train loss and acc of batch 12: 48.672882080078125, 0.984375\n",
      "Train loss and acc of batch 13: 48.13641357421875, 0.984375\n",
      "Train loss and acc of batch 14: 48.13641357421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.51532745361328, 0.984375\n",
      "Train loss and acc of batch 16: 48.51531982421875, 0.984375\n",
      "Train loss and acc of batch 17: 48.67283630371094, 0.984375\n",
      "Train loss and acc of batch 18: 48.8011589050293, 0.96875\n",
      "Train loss and acc of batch 19: 47.91959762573242, 1.0\n",
      "Train loss and acc of batch 20: 47.91958999633789, 1.0\n",
      "Train loss and acc of batch 21: 48.515281677246094, 0.984375\n",
      "Train loss and acc of batch 22: 48.51527404785156, 0.984375\n",
      "Train loss and acc of batch 23: 47.919559478759766, 1.0\n",
      "Train loss and acc of batch 24: 48.51525115966797, 0.984375\n",
      "Train loss and acc of batch 25: 47.9195442199707, 1.0\n",
      "Train loss and acc of batch 26: 47.919532775878906, 1.0\n",
      "Train loss and acc of batch 27: 47.919525146484375, 1.0\n",
      "Train loss and acc of batch 28: 47.91951370239258, 1.0\n",
      "Train loss and acc of batch 29: 48.51520538330078, 0.984375\n",
      "Train loss and acc of batch 30: 47.91949462890625, 1.0\n",
      "Train loss and acc of batch 31: 48.136253356933594, 0.984375\n",
      "Train loss and acc of batch 32: 47.91947937011719, 1.0\n",
      "Train loss and acc of batch 33: 47.91947555541992, 1.0\n",
      "Train loss and acc of batch 34: 48.515159606933594, 0.984375\n",
      "Train loss and acc of batch 35: 48.35298538208008, 0.96875\n",
      "Train loss and acc of batch 36: 47.9194450378418, 1.0\n",
      "Train loss and acc of batch 37: 48.67265701293945, 0.984375\n",
      "Train loss and acc of batch 38: 49.268348693847656, 0.96875\n",
      "Train loss and acc of batch 39: 48.13617706298828, 0.984375\n",
      "Train loss and acc of batch 40: 47.91940689086914, 1.0\n",
      "Train loss and acc of batch 41: 49.26832962036133, 0.96875\n",
      "Train loss and acc of batch 42: 47.91938781738281, 1.0\n",
      "Train loss and acc of batch 43: 48.51508331298828, 0.984375\n",
      "Train loss and acc of batch 44: 47.91937255859375, 1.0\n",
      "Train loss and acc of batch 45: 48.51506042480469, 0.984375\n",
      "Train loss and acc of batch 46: 48.20520782470703, 0.984375\n",
      "Train loss and acc of batch 47: 47.919349670410156, 1.0\n",
      "Train loss and acc of batch 48: 47.919334411621094, 1.0\n",
      "Train loss and acc of batch 49: 47.91933059692383, 1.0\n",
      "Train loss and acc of batch 50: 48.51502227783203, 0.984375\n",
      "Train loss and acc of batch 51: 49.26823425292969, 0.96875\n",
      "Train loss and acc of batch 52: 49.175140380859375, 0.953125\n",
      "Train loss and acc of batch 53: 47.91929244995117, 1.0\n",
      "Train loss and acc of batch 54: 48.13604736328125, 0.984375\n",
      "Train loss and acc of batch 55: 47.91927719116211, 1.0\n",
      "Train loss and acc of batch 56: 47.91926574707031, 1.0\n",
      "Train loss and acc of batch 57: 48.51496124267578, 0.984375\n",
      "Train loss and acc of batch 58: 47.91925048828125, 1.0\n",
      "Train loss and acc of batch 59: 47.91923904418945, 1.0\n",
      "Train loss and acc of batch 60: 47.91923141479492, 1.0\n",
      "Train loss and acc of batch 61: 47.919219970703125, 1.0\n",
      "Train loss and acc of batch 62: 48.13597869873047, 0.984375\n",
      "Train loss and acc of batch 63: 49.1106071472168, 0.96875\n",
      "Train loss and acc of batch 64: 48.135963439941406, 0.984375\n",
      "Train loss and acc of batch 65: 47.919185638427734, 1.0\n",
      "Train loss and acc of batch 66: 47.91918182373047, 1.0\n",
      "Train loss and acc of batch 67: 48.73162841796875, 0.96875\n",
      "Train loss and acc of batch 68: 48.514862060546875, 0.984375\n",
      "Train loss and acc of batch 69: 48.13591766357422, 0.984375\n",
      "Train loss and acc of batch 70: 47.91913986206055, 1.0\n",
      "Training accuracy and loss of epoch #220: 0.9892, 48.2474\n",
      "Saved model by train loss 48.24741573065099\n",
      "Train loss and acc of batch 0: 47.919132232666016, 1.0\n",
      "Train loss and acc of batch 1: 47.919124603271484, 1.0\n",
      "Train loss and acc of batch 2: 48.20496368408203, 0.984375\n",
      "Train loss and acc of batch 3: 48.13587188720703, 0.984375\n",
      "Train loss and acc of batch 4: 47.919097900390625, 1.0\n",
      "Train loss and acc of batch 5: 49.26801300048828, 0.96875\n",
      "Train loss and acc of batch 6: 48.421695709228516, 0.96875\n",
      "Train loss and acc of batch 7: 47.91907501220703, 1.0\n",
      "Train loss and acc of batch 8: 48.51476287841797, 0.984375\n",
      "Train loss and acc of batch 9: 48.20491027832031, 0.984375\n",
      "Train loss and acc of batch 10: 47.91904067993164, 1.0\n",
      "Train loss and acc of batch 11: 47.91903305053711, 1.0\n",
      "Train loss and acc of batch 12: 48.67224884033203, 0.984375\n",
      "Train loss and acc of batch 13: 48.135780334472656, 0.984375\n",
      "Train loss and acc of batch 14: 48.135772705078125, 0.984375\n",
      "Train loss and acc of batch 15: 48.51470184326172, 0.984375\n",
      "Train loss and acc of batch 16: 48.51469421386719, 0.984375\n",
      "Train loss and acc of batch 17: 48.67220687866211, 0.984375\n",
      "Train loss and acc of batch 18: 48.8005256652832, 0.96875\n",
      "Train loss and acc of batch 19: 47.91896057128906, 1.0\n",
      "Train loss and acc of batch 20: 47.9189567565918, 1.0\n",
      "Train loss and acc of batch 21: 48.5146484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.51464080810547, 0.984375\n",
      "Train loss and acc of batch 23: 47.91892623901367, 1.0\n",
      "Train loss and acc of batch 24: 48.514625549316406, 0.984375\n",
      "Train loss and acc of batch 25: 47.918907165527344, 1.0\n",
      "Train loss and acc of batch 26: 47.91890335083008, 1.0\n",
      "Train loss and acc of batch 27: 47.918888092041016, 1.0\n",
      "Train loss and acc of batch 28: 47.91888427734375, 1.0\n",
      "Train loss and acc of batch 29: 48.51457214355469, 0.984375\n",
      "Train loss and acc of batch 30: 47.91886520385742, 1.0\n",
      "Train loss and acc of batch 31: 48.13562774658203, 0.984375\n",
      "Train loss and acc of batch 32: 47.91884994506836, 1.0\n",
      "Train loss and acc of batch 33: 47.9188346862793, 1.0\n",
      "Train loss and acc of batch 34: 48.51453399658203, 0.984375\n",
      "Train loss and acc of batch 35: 48.352352142333984, 0.96875\n",
      "Train loss and acc of batch 36: 47.9188117980957, 1.0\n",
      "Train loss and acc of batch 37: 48.672027587890625, 0.984375\n",
      "Train loss and acc of batch 38: 49.267723083496094, 0.96875\n",
      "Train loss and acc of batch 39: 48.13554382324219, 0.984375\n",
      "Train loss and acc of batch 40: 47.91877365112305, 1.0\n",
      "Train loss and acc of batch 41: 49.26769256591797, 0.96875\n",
      "Train loss and acc of batch 42: 47.918758392333984, 1.0\n",
      "Train loss and acc of batch 43: 48.51445007324219, 0.984375\n",
      "Train loss and acc of batch 44: 47.918739318847656, 1.0\n",
      "Train loss and acc of batch 45: 48.514434814453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.20457458496094, 0.984375\n",
      "Train loss and acc of batch 47: 47.9187126159668, 1.0\n",
      "Train loss and acc of batch 48: 47.918704986572266, 1.0\n",
      "Train loss and acc of batch 49: 47.91869354248047, 1.0\n",
      "Train loss and acc of batch 50: 48.51438903808594, 0.984375\n",
      "Train loss and acc of batch 51: 49.267601013183594, 0.96875\n",
      "Train loss and acc of batch 52: 49.174503326416016, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.91865921020508, 1.0\n",
      "Train loss and acc of batch 54: 48.135414123535156, 0.984375\n",
      "Train loss and acc of batch 55: 47.91864013671875, 1.0\n",
      "Train loss and acc of batch 56: 47.91863250732422, 1.0\n",
      "Train loss and acc of batch 57: 48.51432800292969, 0.984375\n",
      "Train loss and acc of batch 58: 47.91861343383789, 1.0\n",
      "Train loss and acc of batch 59: 47.918609619140625, 1.0\n",
      "Train loss and acc of batch 60: 47.91859436035156, 1.0\n",
      "Train loss and acc of batch 61: 47.91858673095703, 1.0\n",
      "Train loss and acc of batch 62: 48.135345458984375, 0.984375\n",
      "Train loss and acc of batch 63: 49.1099739074707, 0.96875\n",
      "Train loss and acc of batch 64: 48.13533020019531, 0.984375\n",
      "Train loss and acc of batch 65: 47.91855239868164, 1.0\n",
      "Train loss and acc of batch 66: 47.918540954589844, 1.0\n",
      "Train loss and acc of batch 67: 48.73100662231445, 0.96875\n",
      "Train loss and acc of batch 68: 48.51422882080078, 0.984375\n",
      "Train loss and acc of batch 69: 48.135276794433594, 0.984375\n",
      "Train loss and acc of batch 70: 47.91850662231445, 1.0\n",
      "Training accuracy and loss of epoch #221: 0.9892, 48.2468\n",
      "Saved model by train loss 48.24678313564247\n",
      "Train loss and acc of batch 0: 47.91849899291992, 1.0\n",
      "Train loss and acc of batch 1: 47.918487548828125, 1.0\n",
      "Train loss and acc of batch 2: 48.20433807373047, 0.984375\n",
      "Train loss and acc of batch 3: 48.13523864746094, 0.984375\n",
      "Train loss and acc of batch 4: 47.918460845947266, 1.0\n",
      "Train loss and acc of batch 5: 49.26737976074219, 0.96875\n",
      "Train loss and acc of batch 6: 48.42106628417969, 0.96875\n",
      "Train loss and acc of batch 7: 47.91843795776367, 1.0\n",
      "Train loss and acc of batch 8: 48.514129638671875, 0.984375\n",
      "Train loss and acc of batch 9: 48.20426940917969, 0.984375\n",
      "Train loss and acc of batch 10: 47.91841506958008, 1.0\n",
      "Train loss and acc of batch 11: 47.91840362548828, 1.0\n",
      "Train loss and acc of batch 12: 48.67161178588867, 0.984375\n",
      "Train loss and acc of batch 13: 48.13514709472656, 0.984375\n",
      "Train loss and acc of batch 14: 48.13513946533203, 0.984375\n",
      "Train loss and acc of batch 15: 48.514068603515625, 0.984375\n",
      "Train loss and acc of batch 16: 48.514060974121094, 0.984375\n",
      "Train loss and acc of batch 17: 48.671573638916016, 0.984375\n",
      "Train loss and acc of batch 18: 48.799888610839844, 0.96875\n",
      "Train loss and acc of batch 19: 47.91832733154297, 1.0\n",
      "Train loss and acc of batch 20: 47.91831970214844, 1.0\n",
      "Train loss and acc of batch 21: 48.514007568359375, 0.984375\n",
      "Train loss and acc of batch 22: 48.513999938964844, 0.984375\n",
      "Train loss and acc of batch 23: 47.918296813964844, 1.0\n",
      "Train loss and acc of batch 24: 48.51398468017578, 0.984375\n",
      "Train loss and acc of batch 25: 47.91827392578125, 1.0\n",
      "Train loss and acc of batch 26: 47.91826248168945, 1.0\n",
      "Train loss and acc of batch 27: 47.91825485229492, 1.0\n",
      "Train loss and acc of batch 28: 47.91824722290039, 1.0\n",
      "Train loss and acc of batch 29: 48.513938903808594, 0.984375\n",
      "Train loss and acc of batch 30: 47.91822814941406, 1.0\n",
      "Train loss and acc of batch 31: 48.134986877441406, 0.984375\n",
      "Train loss and acc of batch 32: 47.918212890625, 1.0\n",
      "Train loss and acc of batch 33: 47.9182014465332, 1.0\n",
      "Train loss and acc of batch 34: 48.513893127441406, 0.984375\n",
      "Train loss and acc of batch 35: 48.35171127319336, 0.96875\n",
      "Train loss and acc of batch 36: 47.91817855834961, 1.0\n",
      "Train loss and acc of batch 37: 48.671390533447266, 0.984375\n",
      "Train loss and acc of batch 38: 49.26708221435547, 0.96875\n",
      "Train loss and acc of batch 39: 48.134918212890625, 0.984375\n",
      "Train loss and acc of batch 40: 47.91813659667969, 1.0\n",
      "Train loss and acc of batch 41: 49.26705551147461, 0.96875\n",
      "Train loss and acc of batch 42: 47.918121337890625, 1.0\n",
      "Train loss and acc of batch 43: 48.51380920410156, 0.984375\n",
      "Train loss and acc of batch 44: 47.91810607910156, 1.0\n",
      "Train loss and acc of batch 45: 48.5137939453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.203941345214844, 0.984375\n",
      "Train loss and acc of batch 47: 47.9180793762207, 1.0\n",
      "Train loss and acc of batch 48: 47.91807174682617, 1.0\n",
      "Train loss and acc of batch 49: 47.91805648803711, 1.0\n",
      "Train loss and acc of batch 50: 48.513755798339844, 0.984375\n",
      "Train loss and acc of batch 51: 49.2669677734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.17387771606445, 0.953125\n",
      "Train loss and acc of batch 53: 47.91802978515625, 1.0\n",
      "Train loss and acc of batch 54: 48.13477325439453, 0.984375\n",
      "Train loss and acc of batch 55: 47.918006896972656, 1.0\n",
      "Train loss and acc of batch 56: 47.91799545288086, 1.0\n",
      "Train loss and acc of batch 57: 48.51368713378906, 0.984375\n",
      "Train loss and acc of batch 58: 47.9179801940918, 1.0\n",
      "Train loss and acc of batch 59: 47.917972564697266, 1.0\n",
      "Train loss and acc of batch 60: 47.91796112060547, 1.0\n",
      "Train loss and acc of batch 61: 47.91795349121094, 1.0\n",
      "Train loss and acc of batch 62: 48.13471221923828, 0.984375\n",
      "Train loss and acc of batch 63: 49.109336853027344, 0.96875\n",
      "Train loss and acc of batch 64: 48.13468933105469, 0.984375\n",
      "Train loss and acc of batch 65: 47.91791915893555, 1.0\n",
      "Train loss and acc of batch 66: 47.917911529541016, 1.0\n",
      "Train loss and acc of batch 67: 48.730369567871094, 0.96875\n",
      "Train loss and acc of batch 68: 48.513587951660156, 0.984375\n",
      "Train loss and acc of batch 69: 48.1346435546875, 0.984375\n",
      "Train loss and acc of batch 70: 47.917869567871094, 1.0\n",
      "Training accuracy and loss of epoch #222: 0.9892, 48.2461\n",
      "Saved model by train loss 48.246147961683675\n",
      "Train loss and acc of batch 0: 47.91786193847656, 1.0\n",
      "Train loss and acc of batch 1: 47.91785430908203, 1.0\n",
      "Train loss and acc of batch 2: 48.203697204589844, 0.984375\n",
      "Train loss and acc of batch 3: 48.13459777832031, 0.984375\n",
      "Train loss and acc of batch 4: 47.91783142089844, 1.0\n",
      "Train loss and acc of batch 5: 49.266746520996094, 0.96875\n",
      "Train loss and acc of batch 6: 48.42042541503906, 0.96875\n",
      "Train loss and acc of batch 7: 47.91780090332031, 1.0\n",
      "Train loss and acc of batch 8: 48.51349639892578, 0.984375\n",
      "Train loss and acc of batch 9: 48.203636169433594, 0.984375\n",
      "Train loss and acc of batch 10: 47.917781829833984, 1.0\n",
      "Train loss and acc of batch 11: 47.91776657104492, 1.0\n",
      "Train loss and acc of batch 12: 48.67097854614258, 0.984375\n",
      "Train loss and acc of batch 13: 48.13451385498047, 0.984375\n",
      "Train loss and acc of batch 14: 48.134498596191406, 0.984375\n",
      "Train loss and acc of batch 15: 48.513427734375, 0.984375\n",
      "Train loss and acc of batch 16: 48.51342010498047, 0.984375\n",
      "Train loss and acc of batch 17: 48.670936584472656, 0.984375\n",
      "Train loss and acc of batch 18: 48.799259185791016, 0.96875\n",
      "Train loss and acc of batch 19: 47.91769790649414, 1.0\n",
      "Train loss and acc of batch 20: 47.917686462402344, 1.0\n",
      "Train loss and acc of batch 21: 48.51337432861328, 0.984375\n",
      "Train loss and acc of batch 22: 48.51336669921875, 0.984375\n",
      "Train loss and acc of batch 23: 47.917659759521484, 1.0\n",
      "Train loss and acc of batch 24: 48.51335906982422, 0.984375\n",
      "Train loss and acc of batch 25: 47.917640686035156, 1.0\n",
      "Train loss and acc of batch 26: 47.917633056640625, 1.0\n",
      "Train loss and acc of batch 27: 47.917625427246094, 1.0\n",
      "Train loss and acc of batch 28: 47.91761016845703, 1.0\n",
      "Train loss and acc of batch 29: 48.5133056640625, 0.984375\n",
      "Train loss and acc of batch 30: 47.91759490966797, 1.0\n",
      "Train loss and acc of batch 31: 48.13435363769531, 0.984375\n",
      "Train loss and acc of batch 32: 47.91758346557617, 1.0\n",
      "Train loss and acc of batch 33: 47.917572021484375, 1.0\n",
      "Train loss and acc of batch 34: 48.51325988769531, 0.984375\n",
      "Train loss and acc of batch 35: 48.35108184814453, 0.96875\n",
      "Train loss and acc of batch 36: 47.917537689208984, 1.0\n",
      "Train loss and acc of batch 37: 48.67076110839844, 0.984375\n",
      "Train loss and acc of batch 38: 49.266456604003906, 0.96875\n",
      "Train loss and acc of batch 39: 48.13428497314453, 0.984375\n",
      "Train loss and acc of batch 40: 47.917510986328125, 1.0\n",
      "Train loss and acc of batch 41: 49.26642608642578, 0.96875\n",
      "Train loss and acc of batch 42: 47.91748809814453, 1.0\n",
      "Train loss and acc of batch 43: 48.51318359375, 0.984375\n",
      "Train loss and acc of batch 44: 47.9174690246582, 1.0\n",
      "Train loss and acc of batch 45: 48.513160705566406, 0.984375\n",
      "Train loss and acc of batch 46: 48.20330810546875, 0.984375\n",
      "Train loss and acc of batch 47: 47.917449951171875, 1.0\n",
      "Train loss and acc of batch 48: 47.91743469238281, 1.0\n",
      "Train loss and acc of batch 49: 47.91742706298828, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 50: 48.51312255859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.266334533691406, 0.96875\n",
      "Train loss and acc of batch 52: 49.173240661621094, 0.953125\n",
      "Train loss and acc of batch 53: 47.917388916015625, 1.0\n",
      "Train loss and acc of batch 54: 48.13414764404297, 0.984375\n",
      "Train loss and acc of batch 55: 47.91737365722656, 1.0\n",
      "Train loss and acc of batch 56: 47.917362213134766, 1.0\n",
      "Train loss and acc of batch 57: 48.51305389404297, 0.984375\n",
      "Train loss and acc of batch 58: 47.9173469543457, 1.0\n",
      "Train loss and acc of batch 59: 47.917335510253906, 1.0\n",
      "Train loss and acc of batch 60: 47.91733169555664, 1.0\n",
      "Train loss and acc of batch 61: 47.917320251464844, 1.0\n",
      "Train loss and acc of batch 62: 48.13407897949219, 0.984375\n",
      "Train loss and acc of batch 63: 49.108707427978516, 0.96875\n",
      "Train loss and acc of batch 64: 48.134056091308594, 0.984375\n",
      "Train loss and acc of batch 65: 47.91728591918945, 1.0\n",
      "Train loss and acc of batch 66: 47.91727828979492, 1.0\n",
      "Train loss and acc of batch 67: 48.729732513427734, 0.96875\n",
      "Train loss and acc of batch 68: 48.512962341308594, 0.984375\n",
      "Train loss and acc of batch 69: 48.13401794433594, 0.984375\n",
      "Train loss and acc of batch 70: 47.91724395751953, 1.0\n",
      "Training accuracy and loss of epoch #223: 0.9892, 48.2455\n",
      "Saved model by train loss 48.24551488312198\n",
      "Train loss and acc of batch 0: 47.91722869873047, 1.0\n",
      "Train loss and acc of batch 1: 47.91722106933594, 1.0\n",
      "Train loss and acc of batch 2: 48.20306396484375, 0.984375\n",
      "Train loss and acc of batch 3: 48.13397216796875, 0.984375\n",
      "Train loss and acc of batch 4: 47.917198181152344, 1.0\n",
      "Train loss and acc of batch 5: 49.26611328125, 0.96875\n",
      "Train loss and acc of batch 6: 48.419795989990234, 0.96875\n",
      "Train loss and acc of batch 7: 47.91716766357422, 1.0\n",
      "Train loss and acc of batch 8: 48.51286315917969, 0.984375\n",
      "Train loss and acc of batch 9: 48.2030029296875, 0.984375\n",
      "Train loss and acc of batch 10: 47.91714096069336, 1.0\n",
      "Train loss and acc of batch 11: 47.917137145996094, 1.0\n",
      "Train loss and acc of batch 12: 48.67034912109375, 0.984375\n",
      "Train loss and acc of batch 13: 48.133888244628906, 0.984375\n",
      "Train loss and acc of batch 14: 48.133872985839844, 0.984375\n",
      "Train loss and acc of batch 15: 48.512794494628906, 0.984375\n",
      "Train loss and acc of batch 16: 48.512786865234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.67030715942383, 0.984375\n",
      "Train loss and acc of batch 18: 48.79862594604492, 0.96875\n",
      "Train loss and acc of batch 19: 47.91706085205078, 1.0\n",
      "Train loss and acc of batch 20: 47.91705322265625, 1.0\n",
      "Train loss and acc of batch 21: 48.51274871826172, 0.984375\n",
      "Train loss and acc of batch 22: 48.51274108886719, 0.984375\n",
      "Train loss and acc of batch 23: 47.91702651977539, 1.0\n",
      "Train loss and acc of batch 24: 48.512718200683594, 0.984375\n",
      "Train loss and acc of batch 25: 47.91701126098633, 1.0\n",
      "Train loss and acc of batch 26: 47.9170036315918, 1.0\n",
      "Train loss and acc of batch 27: 47.9169921875, 1.0\n",
      "Train loss and acc of batch 28: 47.91698455810547, 1.0\n",
      "Train loss and acc of batch 29: 48.512672424316406, 0.984375\n",
      "Train loss and acc of batch 30: 47.916961669921875, 1.0\n",
      "Train loss and acc of batch 31: 48.13372039794922, 0.984375\n",
      "Train loss and acc of batch 32: 47.91695022583008, 1.0\n",
      "Train loss and acc of batch 33: 47.916934967041016, 1.0\n",
      "Train loss and acc of batch 34: 48.51263427734375, 0.984375\n",
      "Train loss and acc of batch 35: 48.35044860839844, 0.96875\n",
      "Train loss and acc of batch 36: 47.91691207885742, 1.0\n",
      "Train loss and acc of batch 37: 48.67012405395508, 0.984375\n",
      "Train loss and acc of batch 38: 49.26581573486328, 0.96875\n",
      "Train loss and acc of batch 39: 48.13365173339844, 0.984375\n",
      "Train loss and acc of batch 40: 47.91687774658203, 1.0\n",
      "Train loss and acc of batch 41: 49.26579666137695, 0.96875\n",
      "Train loss and acc of batch 42: 47.9168586730957, 1.0\n",
      "Train loss and acc of batch 43: 48.512550354003906, 0.984375\n",
      "Train loss and acc of batch 44: 47.91683578491211, 1.0\n",
      "Train loss and acc of batch 45: 48.512535095214844, 0.984375\n",
      "Train loss and acc of batch 46: 48.202674865722656, 0.984375\n",
      "Train loss and acc of batch 47: 47.916812896728516, 1.0\n",
      "Train loss and acc of batch 48: 47.916805267333984, 1.0\n",
      "Train loss and acc of batch 49: 47.91679382324219, 1.0\n",
      "Train loss and acc of batch 50: 48.512489318847656, 0.984375\n",
      "Train loss and acc of batch 51: 49.26570129394531, 0.96875\n",
      "Train loss and acc of batch 52: 49.172607421875, 0.953125\n",
      "Train loss and acc of batch 53: 47.9167594909668, 1.0\n",
      "Train loss and acc of batch 54: 48.133514404296875, 0.984375\n",
      "Train loss and acc of batch 55: 47.916744232177734, 1.0\n",
      "Train loss and acc of batch 56: 47.91673278808594, 1.0\n",
      "Train loss and acc of batch 57: 48.512428283691406, 0.984375\n",
      "Train loss and acc of batch 58: 47.916709899902344, 1.0\n",
      "Train loss and acc of batch 59: 47.91670608520508, 1.0\n",
      "Train loss and acc of batch 60: 47.91669845581055, 1.0\n",
      "Train loss and acc of batch 61: 47.91668701171875, 1.0\n",
      "Train loss and acc of batch 62: 48.133445739746094, 0.984375\n",
      "Train loss and acc of batch 63: 49.10807418823242, 0.96875\n",
      "Train loss and acc of batch 64: 48.1334228515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.91665267944336, 1.0\n",
      "Train loss and acc of batch 66: 47.91664123535156, 1.0\n",
      "Train loss and acc of batch 67: 48.729103088378906, 0.96875\n",
      "Train loss and acc of batch 68: 48.5123291015625, 0.984375\n",
      "Train loss and acc of batch 69: 48.133384704589844, 0.984375\n",
      "Train loss and acc of batch 70: 47.91660690307617, 1.0\n",
      "Training accuracy and loss of epoch #224: 0.9892, 48.2449\n",
      "Saved model by train loss 48.24488277166662\n",
      "Train loss and acc of batch 0: 47.91659927368164, 1.0\n",
      "Train loss and acc of batch 1: 47.916587829589844, 1.0\n",
      "Train loss and acc of batch 2: 48.202430725097656, 0.984375\n",
      "Train loss and acc of batch 3: 48.133331298828125, 0.984375\n",
      "Train loss and acc of batch 4: 47.916561126708984, 1.0\n",
      "Train loss and acc of batch 5: 49.265480041503906, 0.96875\n",
      "Train loss and acc of batch 6: 48.41916275024414, 0.96875\n",
      "Train loss and acc of batch 7: 47.91653823852539, 1.0\n",
      "Train loss and acc of batch 8: 48.512229919433594, 0.984375\n",
      "Train loss and acc of batch 9: 48.202369689941406, 0.984375\n",
      "Train loss and acc of batch 10: 47.91651153564453, 1.0\n",
      "Train loss and acc of batch 11: 47.916500091552734, 1.0\n",
      "Train loss and acc of batch 12: 48.669715881347656, 0.984375\n",
      "Train loss and acc of batch 13: 48.13324737548828, 0.984375\n",
      "Train loss and acc of batch 14: 48.13323211669922, 0.984375\n",
      "Train loss and acc of batch 15: 48.51216125488281, 0.984375\n",
      "Train loss and acc of batch 16: 48.51215362548828, 0.984375\n",
      "Train loss and acc of batch 17: 48.6696662902832, 0.984375\n",
      "Train loss and acc of batch 18: 48.79798889160156, 0.96875\n",
      "Train loss and acc of batch 19: 47.91643142700195, 1.0\n",
      "Train loss and acc of batch 20: 47.916419982910156, 1.0\n",
      "Train loss and acc of batch 21: 48.512115478515625, 0.984375\n",
      "Train loss and acc of batch 22: 48.512107849121094, 0.984375\n",
      "Train loss and acc of batch 23: 47.91638946533203, 1.0\n",
      "Train loss and acc of batch 24: 48.5120849609375, 0.984375\n",
      "Train loss and acc of batch 25: 47.916378021240234, 1.0\n",
      "Train loss and acc of batch 26: 47.9163703918457, 1.0\n",
      "Train loss and acc of batch 27: 47.916358947753906, 1.0\n",
      "Train loss and acc of batch 28: 47.91634750366211, 1.0\n",
      "Train loss and acc of batch 29: 48.51203918457031, 0.984375\n",
      "Train loss and acc of batch 30: 47.91632843017578, 1.0\n",
      "Train loss and acc of batch 31: 48.133087158203125, 0.984375\n",
      "Train loss and acc of batch 32: 47.91631317138672, 1.0\n",
      "Train loss and acc of batch 33: 47.91630554199219, 1.0\n",
      "Train loss and acc of batch 34: 48.511993408203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.34981918334961, 0.96875\n",
      "Train loss and acc of batch 36: 47.91627883911133, 1.0\n",
      "Train loss and acc of batch 37: 48.669490814208984, 0.984375\n",
      "Train loss and acc of batch 38: 49.26518249511719, 0.96875\n",
      "Train loss and acc of batch 39: 48.13301086425781, 0.984375\n",
      "Train loss and acc of batch 40: 47.91624069213867, 1.0\n",
      "Train loss and acc of batch 41: 49.265159606933594, 0.96875\n",
      "Train loss and acc of batch 42: 47.916221618652344, 1.0\n",
      "Train loss and acc of batch 43: 48.51191711425781, 0.984375\n",
      "Train loss and acc of batch 44: 47.91620635986328, 1.0\n",
      "Train loss and acc of batch 45: 48.51189422607422, 0.984375\n",
      "Train loss and acc of batch 46: 48.20204162597656, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 47.916175842285156, 1.0\n",
      "Train loss and acc of batch 48: 47.91617202758789, 1.0\n",
      "Train loss and acc of batch 49: 47.91616439819336, 1.0\n",
      "Train loss and acc of batch 50: 48.51184844970703, 0.984375\n",
      "Train loss and acc of batch 51: 49.26506805419922, 0.96875\n",
      "Train loss and acc of batch 52: 49.17197799682617, 0.953125\n",
      "Train loss and acc of batch 53: 47.91612243652344, 1.0\n",
      "Train loss and acc of batch 54: 48.13288879394531, 0.984375\n",
      "Train loss and acc of batch 55: 47.916107177734375, 1.0\n",
      "Train loss and acc of batch 56: 47.916099548339844, 1.0\n",
      "Train loss and acc of batch 57: 48.51179504394531, 0.984375\n",
      "Train loss and acc of batch 58: 47.916080474853516, 1.0\n",
      "Train loss and acc of batch 59: 47.91606903076172, 1.0\n",
      "Train loss and acc of batch 60: 47.91606140136719, 1.0\n",
      "Train loss and acc of batch 61: 47.916053771972656, 1.0\n",
      "Train loss and acc of batch 62: 48.1328125, 0.984375\n",
      "Train loss and acc of batch 63: 49.10744094848633, 0.96875\n",
      "Train loss and acc of batch 64: 48.13279724121094, 0.984375\n",
      "Train loss and acc of batch 65: 47.916019439697266, 1.0\n",
      "Train loss and acc of batch 66: 47.916011810302734, 1.0\n",
      "Train loss and acc of batch 67: 48.72846603393555, 0.96875\n",
      "Train loss and acc of batch 68: 48.511695861816406, 0.984375\n",
      "Train loss and acc of batch 69: 48.13275146484375, 0.984375\n",
      "Train loss and acc of batch 70: 47.91597366333008, 1.0\n",
      "Training accuracy and loss of epoch #225: 0.9892, 48.2442\n",
      "Saved model by train loss 48.24424867227044\n",
      "Train loss and acc of batch 0: 47.91596603393555, 1.0\n",
      "Train loss and acc of batch 1: 47.91596603393555, 1.0\n",
      "Train loss and acc of batch 2: 48.20179748535156, 0.984375\n",
      "Train loss and acc of batch 3: 48.13269805908203, 0.984375\n",
      "Train loss and acc of batch 4: 47.91592788696289, 1.0\n",
      "Train loss and acc of batch 5: 49.26484680175781, 0.96875\n",
      "Train loss and acc of batch 6: 48.41852951049805, 0.96875\n",
      "Train loss and acc of batch 7: 47.9159049987793, 1.0\n",
      "Train loss and acc of batch 8: 48.5115966796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.20173645019531, 0.984375\n",
      "Train loss and acc of batch 10: 47.91587448120117, 1.0\n",
      "Train loss and acc of batch 11: 47.915870666503906, 1.0\n",
      "Train loss and acc of batch 12: 48.66908645629883, 0.984375\n",
      "Train loss and acc of batch 13: 48.13261413574219, 0.984375\n",
      "Train loss and acc of batch 14: 48.132606506347656, 0.984375\n",
      "Train loss and acc of batch 15: 48.51152801513672, 0.984375\n",
      "Train loss and acc of batch 16: 48.51152038574219, 0.984375\n",
      "Train loss and acc of batch 17: 48.66903305053711, 0.984375\n",
      "Train loss and acc of batch 18: 48.797359466552734, 0.96875\n",
      "Train loss and acc of batch 19: 47.915794372558594, 1.0\n",
      "Train loss and acc of batch 20: 47.91579055786133, 1.0\n",
      "Train loss and acc of batch 21: 48.511474609375, 0.984375\n",
      "Train loss and acc of batch 22: 48.511474609375, 0.984375\n",
      "Train loss and acc of batch 23: 47.91576385498047, 1.0\n",
      "Train loss and acc of batch 24: 48.511451721191406, 0.984375\n",
      "Train loss and acc of batch 25: 47.915740966796875, 1.0\n",
      "Train loss and acc of batch 26: 47.91572570800781, 1.0\n",
      "Train loss and acc of batch 27: 47.91572189331055, 1.0\n",
      "Train loss and acc of batch 28: 47.915714263916016, 1.0\n",
      "Train loss and acc of batch 29: 48.51141357421875, 0.984375\n",
      "Train loss and acc of batch 30: 47.91570281982422, 1.0\n",
      "Train loss and acc of batch 31: 48.13245391845703, 0.984375\n",
      "Train loss and acc of batch 32: 47.91567611694336, 1.0\n",
      "Train loss and acc of batch 33: 47.915672302246094, 1.0\n",
      "Train loss and acc of batch 34: 48.51136779785156, 0.984375\n",
      "Train loss and acc of batch 35: 48.34918212890625, 0.96875\n",
      "Train loss and acc of batch 36: 47.91564178466797, 1.0\n",
      "Train loss and acc of batch 37: 48.668861389160156, 0.984375\n",
      "Train loss and acc of batch 38: 49.264549255371094, 0.96875\n",
      "Train loss and acc of batch 39: 48.13238525390625, 0.984375\n",
      "Train loss and acc of batch 40: 47.915611267089844, 1.0\n",
      "Train loss and acc of batch 41: 49.2645263671875, 0.96875\n",
      "Train loss and acc of batch 42: 47.91558837890625, 1.0\n",
      "Train loss and acc of batch 43: 48.51128387451172, 0.984375\n",
      "Train loss and acc of batch 44: 47.91556930541992, 1.0\n",
      "Train loss and acc of batch 45: 48.511260986328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.20140075683594, 0.984375\n",
      "Train loss and acc of batch 47: 47.91554641723633, 1.0\n",
      "Train loss and acc of batch 48: 47.9155387878418, 1.0\n",
      "Train loss and acc of batch 49: 47.915531158447266, 1.0\n",
      "Train loss and acc of batch 50: 48.51122283935547, 0.984375\n",
      "Train loss and acc of batch 51: 49.264442443847656, 0.96875\n",
      "Train loss and acc of batch 52: 49.17134094238281, 0.953125\n",
      "Train loss and acc of batch 53: 47.91549301147461, 1.0\n",
      "Train loss and acc of batch 54: 48.13224792480469, 0.984375\n",
      "Train loss and acc of batch 55: 47.91547393798828, 1.0\n",
      "Train loss and acc of batch 56: 47.91546630859375, 1.0\n",
      "Train loss and acc of batch 57: 48.51116943359375, 0.984375\n",
      "Train loss and acc of batch 58: 47.91545104980469, 1.0\n",
      "Train loss and acc of batch 59: 47.91543960571289, 1.0\n",
      "Train loss and acc of batch 60: 47.915428161621094, 1.0\n",
      "Train loss and acc of batch 61: 47.91542053222656, 1.0\n",
      "Train loss and acc of batch 62: 47.91541290283203, 1.0\n",
      "Train loss and acc of batch 63: 49.1068000793457, 0.96875\n",
      "Train loss and acc of batch 64: 48.13215637207031, 0.984375\n",
      "Train loss and acc of batch 65: 47.91538619995117, 1.0\n",
      "Train loss and acc of batch 66: 47.91537857055664, 1.0\n",
      "Train loss and acc of batch 67: 48.727840423583984, 0.96875\n",
      "Train loss and acc of batch 68: 48.51106262207031, 0.984375\n",
      "Train loss and acc of batch 69: 48.132110595703125, 0.984375\n",
      "Train loss and acc of batch 70: 47.91534423828125, 1.0\n",
      "Training accuracy and loss of epoch #226: 0.9894, 48.2406\n",
      "Saved model by train acc 0.9894366197183099\n",
      "Saved model by train loss 48.240562922518016\n",
      "Train loss and acc of batch 0: 47.91532897949219, 1.0\n",
      "Train loss and acc of batch 1: 47.91532516479492, 1.0\n",
      "Train loss and acc of batch 2: 48.201171875, 0.984375\n",
      "Train loss and acc of batch 3: 48.13207244873047, 0.984375\n",
      "Train loss and acc of batch 4: 47.9152946472168, 1.0\n",
      "Train loss and acc of batch 5: 49.26421356201172, 0.96875\n",
      "Train loss and acc of batch 6: 48.41789245605469, 0.96875\n",
      "Train loss and acc of batch 7: 47.9152717590332, 1.0\n",
      "Train loss and acc of batch 8: 48.510963439941406, 0.984375\n",
      "Train loss and acc of batch 9: 48.20110321044922, 0.984375\n",
      "Train loss and acc of batch 10: 47.91524124145508, 1.0\n",
      "Train loss and acc of batch 11: 47.91523361206055, 1.0\n",
      "Train loss and acc of batch 12: 48.6684455871582, 0.984375\n",
      "Train loss and acc of batch 13: 48.131980895996094, 0.984375\n",
      "Train loss and acc of batch 14: 48.13197326660156, 0.984375\n",
      "Train loss and acc of batch 15: 48.510902404785156, 0.984375\n",
      "Train loss and acc of batch 16: 48.510894775390625, 0.984375\n",
      "Train loss and acc of batch 17: 48.66840362548828, 0.984375\n",
      "Train loss and acc of batch 18: 48.79672622680664, 0.96875\n",
      "Train loss and acc of batch 19: 47.915164947509766, 1.0\n",
      "Train loss and acc of batch 20: 47.9151496887207, 1.0\n",
      "Train loss and acc of batch 21: 48.51084899902344, 0.984375\n",
      "Train loss and acc of batch 22: 48.510833740234375, 0.984375\n",
      "Train loss and acc of batch 23: 47.91512680053711, 1.0\n",
      "Train loss and acc of batch 24: 48.510826110839844, 0.984375\n",
      "Train loss and acc of batch 25: 47.91511154174805, 1.0\n",
      "Train loss and acc of batch 26: 47.91510009765625, 1.0\n",
      "Train loss and acc of batch 27: 47.91509246826172, 1.0\n",
      "Train loss and acc of batch 28: 47.91508102416992, 1.0\n",
      "Train loss and acc of batch 29: 48.510772705078125, 0.984375\n",
      "Train loss and acc of batch 30: 47.91506576538086, 1.0\n",
      "Train loss and acc of batch 31: 48.13182067871094, 0.984375\n",
      "Train loss and acc of batch 32: 47.9150505065918, 1.0\n",
      "Train loss and acc of batch 33: 47.9150390625, 1.0\n",
      "Train loss and acc of batch 34: 48.51073455810547, 0.984375\n",
      "Train loss and acc of batch 35: 48.348548889160156, 0.96875\n",
      "Train loss and acc of batch 36: 47.915016174316406, 1.0\n",
      "Train loss and acc of batch 37: 48.6682243347168, 0.984375\n",
      "Train loss and acc of batch 38: 49.26392364501953, 0.96875\n",
      "Train loss and acc of batch 39: 48.131744384765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.914974212646484, 1.0\n",
      "Train loss and acc of batch 41: 49.263893127441406, 0.96875\n",
      "Train loss and acc of batch 42: 47.91495895385742, 1.0\n",
      "Train loss and acc of batch 43: 48.510650634765625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 44: 47.91494369506836, 1.0\n",
      "Train loss and acc of batch 45: 48.51062774658203, 0.984375\n",
      "Train loss and acc of batch 46: 48.200775146484375, 0.984375\n",
      "Train loss and acc of batch 47: 47.9149169921875, 1.0\n",
      "Train loss and acc of batch 48: 47.91489791870117, 1.0\n",
      "Train loss and acc of batch 49: 47.914894104003906, 1.0\n",
      "Train loss and acc of batch 50: 48.510589599609375, 0.984375\n",
      "Train loss and acc of batch 51: 49.26380157470703, 0.96875\n",
      "Train loss and acc of batch 52: 49.170711517333984, 0.953125\n",
      "Train loss and acc of batch 53: 47.914859771728516, 1.0\n",
      "Train loss and acc of batch 54: 48.131614685058594, 0.984375\n",
      "Train loss and acc of batch 55: 47.91484069824219, 1.0\n",
      "Train loss and acc of batch 56: 47.91482925415039, 1.0\n",
      "Train loss and acc of batch 57: 48.510528564453125, 0.984375\n",
      "Train loss and acc of batch 58: 47.914817810058594, 1.0\n",
      "Train loss and acc of batch 59: 47.9148063659668, 1.0\n",
      "Train loss and acc of batch 60: 47.914798736572266, 1.0\n",
      "Train loss and acc of batch 61: 47.914791107177734, 1.0\n",
      "Train loss and acc of batch 62: 47.91477966308594, 1.0\n",
      "Train loss and acc of batch 63: 49.10617446899414, 0.96875\n",
      "Train loss and acc of batch 64: 48.13152313232422, 0.984375\n",
      "Train loss and acc of batch 65: 47.91475296020508, 1.0\n",
      "Train loss and acc of batch 66: 47.91474533081055, 1.0\n",
      "Train loss and acc of batch 67: 48.727203369140625, 0.96875\n",
      "Train loss and acc of batch 68: 48.51042938232422, 0.984375\n",
      "Train loss and acc of batch 69: 48.13148498535156, 0.984375\n",
      "Train loss and acc of batch 70: 47.91470718383789, 1.0\n",
      "Training accuracy and loss of epoch #227: 0.9894, 48.2399\n",
      "Saved model by train loss 48.239930112596966\n",
      "Train loss and acc of batch 0: 47.914703369140625, 1.0\n",
      "Train loss and acc of batch 1: 47.91468811035156, 1.0\n",
      "Train loss and acc of batch 2: 48.200531005859375, 0.984375\n",
      "Train loss and acc of batch 3: 48.131439208984375, 0.984375\n",
      "Train loss and acc of batch 4: 47.914669036865234, 1.0\n",
      "Train loss and acc of batch 5: 49.263580322265625, 0.96875\n",
      "Train loss and acc of batch 6: 48.417259216308594, 0.96875\n",
      "Train loss and acc of batch 7: 47.914634704589844, 1.0\n",
      "Train loss and acc of batch 8: 48.51033020019531, 0.984375\n",
      "Train loss and acc of batch 9: 48.200477600097656, 0.984375\n",
      "Train loss and acc of batch 10: 47.914608001708984, 1.0\n",
      "Train loss and acc of batch 11: 47.91460037231445, 1.0\n",
      "Train loss and acc of batch 12: 48.667816162109375, 0.984375\n",
      "Train loss and acc of batch 13: 48.13134765625, 0.984375\n",
      "Train loss and acc of batch 14: 48.13134002685547, 0.984375\n",
      "Train loss and acc of batch 15: 48.51026916503906, 0.984375\n",
      "Train loss and acc of batch 16: 48.51026153564453, 0.984375\n",
      "Train loss and acc of batch 17: 48.66777420043945, 0.984375\n",
      "Train loss and acc of batch 18: 48.79609298706055, 0.96875\n",
      "Train loss and acc of batch 19: 47.91453170776367, 1.0\n",
      "Train loss and acc of batch 20: 47.914520263671875, 1.0\n",
      "Train loss and acc of batch 21: 48.510215759277344, 0.984375\n",
      "Train loss and acc of batch 22: 48.51020050048828, 0.984375\n",
      "Train loss and acc of batch 23: 47.91449737548828, 1.0\n",
      "Train loss and acc of batch 24: 48.51018524169922, 0.984375\n",
      "Train loss and acc of batch 25: 47.91447830200195, 1.0\n",
      "Train loss and acc of batch 26: 47.91447448730469, 1.0\n",
      "Train loss and acc of batch 27: 47.914459228515625, 1.0\n",
      "Train loss and acc of batch 28: 47.914451599121094, 1.0\n",
      "Train loss and acc of batch 29: 48.51013946533203, 0.984375\n",
      "Train loss and acc of batch 30: 47.9144287109375, 1.0\n",
      "Train loss and acc of batch 31: 48.131187438964844, 0.984375\n",
      "Train loss and acc of batch 32: 47.9144172668457, 1.0\n",
      "Train loss and acc of batch 33: 47.914405822753906, 1.0\n",
      "Train loss and acc of batch 34: 48.510093688964844, 0.984375\n",
      "Train loss and acc of batch 35: 48.34791564941406, 0.96875\n",
      "Train loss and acc of batch 36: 47.91437530517578, 1.0\n",
      "Train loss and acc of batch 37: 48.667598724365234, 0.984375\n",
      "Train loss and acc of batch 38: 49.263282775878906, 0.96875\n",
      "Train loss and acc of batch 39: 48.13111877441406, 0.984375\n",
      "Train loss and acc of batch 40: 47.914344787597656, 1.0\n",
      "Train loss and acc of batch 41: 49.26325607299805, 0.96875\n",
      "Train loss and acc of batch 42: 47.91432571411133, 1.0\n",
      "Train loss and acc of batch 43: 48.51001739501953, 0.984375\n",
      "Train loss and acc of batch 44: 47.914306640625, 1.0\n",
      "Train loss and acc of batch 45: 48.51000213623047, 0.984375\n",
      "Train loss and acc of batch 46: 48.20014190673828, 0.984375\n",
      "Train loss and acc of batch 47: 47.91427993774414, 1.0\n",
      "Train loss and acc of batch 48: 47.91427230834961, 1.0\n",
      "Train loss and acc of batch 49: 47.91425704956055, 1.0\n",
      "Train loss and acc of batch 50: 48.50995635986328, 0.984375\n",
      "Train loss and acc of batch 51: 49.26317596435547, 0.96875\n",
      "Train loss and acc of batch 52: 49.170074462890625, 0.953125\n",
      "Train loss and acc of batch 53: 47.91422653198242, 1.0\n",
      "Train loss and acc of batch 54: 48.1309814453125, 0.984375\n",
      "Train loss and acc of batch 55: 47.91421127319336, 1.0\n",
      "Train loss and acc of batch 56: 47.91420364379883, 1.0\n",
      "Train loss and acc of batch 57: 48.5098876953125, 0.984375\n",
      "Train loss and acc of batch 58: 47.914180755615234, 1.0\n",
      "Train loss and acc of batch 59: 47.9141731262207, 1.0\n",
      "Train loss and acc of batch 60: 47.91416931152344, 1.0\n",
      "Train loss and acc of batch 61: 47.914154052734375, 1.0\n",
      "Train loss and acc of batch 62: 47.91415023803711, 1.0\n",
      "Train loss and acc of batch 63: 49.10553741455078, 0.96875\n",
      "Train loss and acc of batch 64: 48.130889892578125, 0.984375\n",
      "Train loss and acc of batch 65: 47.91412353515625, 1.0\n",
      "Train loss and acc of batch 66: 47.91410827636719, 1.0\n",
      "Train loss and acc of batch 67: 48.726566314697266, 0.96875\n",
      "Train loss and acc of batch 68: 48.509796142578125, 0.984375\n",
      "Train loss and acc of batch 69: 48.13084411621094, 0.984375\n",
      "Train loss and acc of batch 70: 47.9140739440918, 1.0\n",
      "Training accuracy and loss of epoch #228: 0.9894, 48.2393\n",
      "Saved model by train loss 48.23929703403527\n",
      "Train loss and acc of batch 0: 47.914066314697266, 1.0\n",
      "Train loss and acc of batch 1: 47.914058685302734, 1.0\n",
      "Train loss and acc of batch 2: 48.19990539550781, 0.984375\n",
      "Train loss and acc of batch 3: 48.13080596923828, 0.984375\n",
      "Train loss and acc of batch 4: 47.91402816772461, 1.0\n",
      "Train loss and acc of batch 5: 49.26294708251953, 0.96875\n",
      "Train loss and acc of batch 6: 48.416629791259766, 0.96875\n",
      "Train loss and acc of batch 7: 47.91400146484375, 1.0\n",
      "Train loss and acc of batch 8: 48.50969696044922, 0.984375\n",
      "Train loss and acc of batch 9: 48.19983673095703, 0.984375\n",
      "Train loss and acc of batch 10: 47.913978576660156, 1.0\n",
      "Train loss and acc of batch 11: 47.91397476196289, 1.0\n",
      "Train loss and acc of batch 12: 48.66718292236328, 0.984375\n",
      "Train loss and acc of batch 13: 48.130714416503906, 0.984375\n",
      "Train loss and acc of batch 14: 48.130706787109375, 0.984375\n",
      "Train loss and acc of batch 15: 48.50962829589844, 0.984375\n",
      "Train loss and acc of batch 16: 48.50962829589844, 0.984375\n",
      "Train loss and acc of batch 17: 48.66714096069336, 0.984375\n",
      "Train loss and acc of batch 18: 48.79545974731445, 0.96875\n",
      "Train loss and acc of batch 19: 47.913902282714844, 1.0\n",
      "Train loss and acc of batch 20: 47.91388702392578, 1.0\n",
      "Train loss and acc of batch 21: 48.50958251953125, 0.984375\n",
      "Train loss and acc of batch 22: 48.50957489013672, 0.984375\n",
      "Train loss and acc of batch 23: 47.913856506347656, 1.0\n",
      "Train loss and acc of batch 24: 48.509552001953125, 0.984375\n",
      "Train loss and acc of batch 25: 47.91384506225586, 1.0\n",
      "Train loss and acc of batch 26: 47.91383361816406, 1.0\n",
      "Train loss and acc of batch 27: 47.9138298034668, 1.0\n",
      "Train loss and acc of batch 28: 47.913818359375, 1.0\n",
      "Train loss and acc of batch 29: 48.50950622558594, 0.984375\n",
      "Train loss and acc of batch 30: 47.91380310058594, 1.0\n",
      "Train loss and acc of batch 31: 48.13054656982422, 0.984375\n",
      "Train loss and acc of batch 32: 47.913780212402344, 1.0\n",
      "Train loss and acc of batch 33: 47.91377258300781, 1.0\n",
      "Train loss and acc of batch 34: 48.50946044921875, 0.984375\n",
      "Train loss and acc of batch 35: 48.34728240966797, 0.96875\n",
      "Train loss and acc of batch 36: 47.91374969482422, 1.0\n",
      "Train loss and acc of batch 37: 48.66695785522461, 0.984375\n",
      "Train loss and acc of batch 38: 49.262657165527344, 0.96875\n",
      "Train loss and acc of batch 39: 48.13048553466797, 0.984375\n",
      "Train loss and acc of batch 40: 47.91371154785156, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.26262664794922, 0.96875\n",
      "Train loss and acc of batch 42: 47.9136848449707, 1.0\n",
      "Train loss and acc of batch 43: 48.50938415527344, 0.984375\n",
      "Train loss and acc of batch 44: 47.91367721557617, 1.0\n",
      "Train loss and acc of batch 45: 48.509368896484375, 0.984375\n",
      "Train loss and acc of batch 46: 48.19950866699219, 0.984375\n",
      "Train loss and acc of batch 47: 47.91365051269531, 1.0\n",
      "Train loss and acc of batch 48: 47.913639068603516, 1.0\n",
      "Train loss and acc of batch 49: 47.913631439208984, 1.0\n",
      "Train loss and acc of batch 50: 48.50932312011719, 0.984375\n",
      "Train loss and acc of batch 51: 49.262535095214844, 0.96875\n",
      "Train loss and acc of batch 52: 49.16944122314453, 0.953125\n",
      "Train loss and acc of batch 53: 47.913597106933594, 1.0\n",
      "Train loss and acc of batch 54: 48.130348205566406, 0.984375\n",
      "Train loss and acc of batch 55: 47.913578033447266, 1.0\n",
      "Train loss and acc of batch 56: 47.91356658935547, 1.0\n",
      "Train loss and acc of batch 57: 48.50926208496094, 0.984375\n",
      "Train loss and acc of batch 58: 47.913551330566406, 1.0\n",
      "Train loss and acc of batch 59: 47.91353988647461, 1.0\n",
      "Train loss and acc of batch 60: 47.91352844238281, 1.0\n",
      "Train loss and acc of batch 61: 47.91352462768555, 1.0\n",
      "Train loss and acc of batch 62: 47.91351318359375, 1.0\n",
      "Train loss and acc of batch 63: 49.10491180419922, 0.96875\n",
      "Train loss and acc of batch 64: 48.13026428222656, 0.984375\n",
      "Train loss and acc of batch 65: 47.913482666015625, 1.0\n",
      "Train loss and acc of batch 66: 47.91347885131836, 1.0\n",
      "Train loss and acc of batch 67: 48.72593307495117, 0.96875\n",
      "Train loss and acc of batch 68: 48.50916290283203, 0.984375\n",
      "Train loss and acc of batch 69: 48.130218505859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.9134407043457, 1.0\n",
      "Training accuracy and loss of epoch #229: 0.9894, 48.2387\n",
      "Saved model by train loss 48.23866422411422\n",
      "Train loss and acc of batch 0: 47.913429260253906, 1.0\n",
      "Train loss and acc of batch 1: 47.91342544555664, 1.0\n",
      "Train loss and acc of batch 2: 48.19926452636719, 0.984375\n",
      "Train loss and acc of batch 3: 48.13017272949219, 0.984375\n",
      "Train loss and acc of batch 4: 47.91339874267578, 1.0\n",
      "Train loss and acc of batch 5: 49.26231384277344, 0.96875\n",
      "Train loss and acc of batch 6: 48.41600036621094, 0.96875\n",
      "Train loss and acc of batch 7: 47.91337585449219, 1.0\n",
      "Train loss and acc of batch 8: 48.509063720703125, 0.984375\n",
      "Train loss and acc of batch 9: 48.19921112060547, 0.984375\n",
      "Train loss and acc of batch 10: 47.9133415222168, 1.0\n",
      "Train loss and acc of batch 11: 47.91333770751953, 1.0\n",
      "Train loss and acc of batch 12: 48.66655349731445, 0.984375\n",
      "Train loss and acc of batch 13: 48.130088806152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.13007354736328, 0.984375\n",
      "Train loss and acc of batch 15: 48.509002685546875, 0.984375\n",
      "Train loss and acc of batch 16: 48.50898742675781, 0.984375\n",
      "Train loss and acc of batch 17: 48.66650390625, 0.984375\n",
      "Train loss and acc of batch 18: 48.79482650756836, 0.96875\n",
      "Train loss and acc of batch 19: 47.913265228271484, 1.0\n",
      "Train loss and acc of batch 20: 47.91325759887695, 1.0\n",
      "Train loss and acc of batch 21: 48.50895690917969, 0.984375\n",
      "Train loss and acc of batch 22: 48.508934020996094, 0.984375\n",
      "Train loss and acc of batch 23: 47.913230895996094, 1.0\n",
      "Train loss and acc of batch 24: 48.50892639160156, 0.984375\n",
      "Train loss and acc of batch 25: 47.913211822509766, 1.0\n",
      "Train loss and acc of batch 26: 47.913204193115234, 1.0\n",
      "Train loss and acc of batch 27: 47.91318893432617, 1.0\n",
      "Train loss and acc of batch 28: 47.91318130493164, 1.0\n",
      "Train loss and acc of batch 29: 48.508880615234375, 0.984375\n",
      "Train loss and acc of batch 30: 47.91316604614258, 1.0\n",
      "Train loss and acc of batch 31: 48.129920959472656, 0.984375\n",
      "Train loss and acc of batch 32: 47.913150787353516, 1.0\n",
      "Train loss and acc of batch 33: 47.91313934326172, 1.0\n",
      "Train loss and acc of batch 34: 48.50883483886719, 0.984375\n",
      "Train loss and acc of batch 35: 48.346656799316406, 0.96875\n",
      "Train loss and acc of batch 36: 47.91311264038086, 1.0\n",
      "Train loss and acc of batch 37: 48.66632843017578, 0.984375\n",
      "Train loss and acc of batch 38: 49.26202392578125, 0.96875\n",
      "Train loss and acc of batch 39: 48.129852294921875, 0.984375\n",
      "Train loss and acc of batch 40: 47.91307830810547, 1.0\n",
      "Train loss and acc of batch 41: 49.262001037597656, 0.96875\n",
      "Train loss and acc of batch 42: 47.913063049316406, 1.0\n",
      "Train loss and acc of batch 43: 48.508758544921875, 0.984375\n",
      "Train loss and acc of batch 44: 47.91304016113281, 1.0\n",
      "Train loss and acc of batch 45: 48.50872802734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.198883056640625, 0.984375\n",
      "Train loss and acc of batch 47: 47.91301345825195, 1.0\n",
      "Train loss and acc of batch 48: 47.91300964355469, 1.0\n",
      "Train loss and acc of batch 49: 47.913002014160156, 1.0\n",
      "Train loss and acc of batch 50: 48.508689880371094, 0.984375\n",
      "Train loss and acc of batch 51: 49.26190185546875, 0.96875\n",
      "Train loss and acc of batch 52: 49.16881561279297, 0.953125\n",
      "Train loss and acc of batch 53: 47.912960052490234, 1.0\n",
      "Train loss and acc of batch 54: 48.12971496582031, 0.984375\n",
      "Train loss and acc of batch 55: 47.91294479370117, 1.0\n",
      "Train loss and acc of batch 56: 47.912933349609375, 1.0\n",
      "Train loss and acc of batch 57: 48.508628845214844, 0.984375\n",
      "Train loss and acc of batch 58: 47.91291809082031, 1.0\n",
      "Train loss and acc of batch 59: 47.912906646728516, 1.0\n",
      "Train loss and acc of batch 60: 47.91290283203125, 1.0\n",
      "Train loss and acc of batch 61: 47.91288757324219, 1.0\n",
      "Train loss and acc of batch 62: 47.91288375854492, 1.0\n",
      "Train loss and acc of batch 63: 49.10427474975586, 0.96875\n",
      "Train loss and acc of batch 64: 48.12963104248047, 0.984375\n",
      "Train loss and acc of batch 65: 47.9128532409668, 1.0\n",
      "Train loss and acc of batch 66: 47.912845611572266, 1.0\n",
      "Train loss and acc of batch 67: 48.725303649902344, 0.96875\n",
      "Train loss and acc of batch 68: 48.50852966308594, 0.984375\n",
      "Train loss and acc of batch 69: 48.12958526611328, 0.984375\n",
      "Train loss and acc of batch 70: 47.912811279296875, 1.0\n",
      "Training accuracy and loss of epoch #230: 0.9894, 48.2380\n",
      "Saved model by train loss 48.23803232757138\n",
      "Train loss and acc of batch 0: 47.912803649902344, 1.0\n",
      "Train loss and acc of batch 1: 47.91279220581055, 1.0\n",
      "Train loss and acc of batch 2: 48.198631286621094, 0.984375\n",
      "Train loss and acc of batch 3: 48.129539489746094, 0.984375\n",
      "Train loss and acc of batch 4: 47.91276550292969, 1.0\n",
      "Train loss and acc of batch 5: 49.261688232421875, 0.96875\n",
      "Train loss and acc of batch 6: 48.41536331176758, 0.96875\n",
      "Train loss and acc of batch 7: 47.91273880004883, 1.0\n",
      "Train loss and acc of batch 8: 48.50843811035156, 0.984375\n",
      "Train loss and acc of batch 9: 48.198577880859375, 0.984375\n",
      "Train loss and acc of batch 10: 47.91271209716797, 1.0\n",
      "Train loss and acc of batch 11: 47.91270065307617, 1.0\n",
      "Train loss and acc of batch 12: 48.66591262817383, 0.984375\n",
      "Train loss and acc of batch 13: 48.12944793701172, 0.984375\n",
      "Train loss and acc of batch 14: 48.12944793701172, 0.984375\n",
      "Train loss and acc of batch 15: 48.50836944580078, 0.984375\n",
      "Train loss and acc of batch 16: 48.50836181640625, 0.984375\n",
      "Train loss and acc of batch 17: 48.66587448120117, 0.984375\n",
      "Train loss and acc of batch 18: 48.794193267822266, 0.96875\n",
      "Train loss and acc of batch 19: 47.91263198852539, 1.0\n",
      "Train loss and acc of batch 20: 47.91262435913086, 1.0\n",
      "Train loss and acc of batch 21: 48.50831604003906, 0.984375\n",
      "Train loss and acc of batch 22: 48.50830841064453, 0.984375\n",
      "Train loss and acc of batch 23: 47.91259765625, 1.0\n",
      "Train loss and acc of batch 24: 48.50828552246094, 0.984375\n",
      "Train loss and acc of batch 25: 47.91257858276367, 1.0\n",
      "Train loss and acc of batch 26: 47.912574768066406, 1.0\n",
      "Train loss and acc of batch 27: 47.912559509277344, 1.0\n",
      "Train loss and acc of batch 28: 47.91255569458008, 1.0\n",
      "Train loss and acc of batch 29: 48.50824737548828, 0.984375\n",
      "Train loss and acc of batch 30: 47.912532806396484, 1.0\n",
      "Train loss and acc of batch 31: 48.12928771972656, 0.984375\n",
      "Train loss and acc of batch 32: 47.912513732910156, 1.0\n",
      "Train loss and acc of batch 33: 47.91250991821289, 1.0\n",
      "Train loss and acc of batch 34: 48.50819396972656, 0.984375\n",
      "Train loss and acc of batch 35: 48.34601593017578, 0.96875\n",
      "Train loss and acc of batch 36: 47.91248321533203, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 37: 48.66569900512695, 0.984375\n",
      "Train loss and acc of batch 38: 49.261383056640625, 0.96875\n",
      "Train loss and acc of batch 39: 48.12921905517578, 0.984375\n",
      "Train loss and acc of batch 40: 47.912445068359375, 1.0\n",
      "Train loss and acc of batch 41: 49.2613639831543, 0.96875\n",
      "Train loss and acc of batch 42: 47.91242980957031, 1.0\n",
      "Train loss and acc of batch 43: 48.50811767578125, 0.984375\n",
      "Train loss and acc of batch 44: 47.912410736083984, 1.0\n",
      "Train loss and acc of batch 45: 48.50811004638672, 0.984375\n",
      "Train loss and acc of batch 46: 48.1982421875, 0.984375\n",
      "Train loss and acc of batch 47: 47.912384033203125, 1.0\n",
      "Train loss and acc of batch 48: 47.91237258911133, 1.0\n",
      "Train loss and acc of batch 49: 47.91236114501953, 1.0\n",
      "Train loss and acc of batch 50: 48.508056640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.26127624511719, 0.96875\n",
      "Train loss and acc of batch 52: 49.168174743652344, 0.953125\n",
      "Train loss and acc of batch 53: 47.912330627441406, 1.0\n",
      "Train loss and acc of batch 54: 48.12908172607422, 0.984375\n",
      "Train loss and acc of batch 55: 47.91231155395508, 1.0\n",
      "Train loss and acc of batch 56: 47.91230392456055, 1.0\n",
      "Train loss and acc of batch 57: 48.50799560546875, 0.984375\n",
      "Train loss and acc of batch 58: 47.91228485107422, 1.0\n",
      "Train loss and acc of batch 59: 47.91228103637695, 1.0\n",
      "Train loss and acc of batch 60: 47.91226577758789, 1.0\n",
      "Train loss and acc of batch 61: 47.912261962890625, 1.0\n",
      "Train loss and acc of batch 62: 47.91224670410156, 1.0\n",
      "Train loss and acc of batch 63: 49.103641510009766, 0.96875\n",
      "Train loss and acc of batch 64: 48.128997802734375, 0.984375\n",
      "Train loss and acc of batch 65: 47.912227630615234, 1.0\n",
      "Train loss and acc of batch 66: 47.91221618652344, 1.0\n",
      "Train loss and acc of batch 67: 48.72467041015625, 0.96875\n",
      "Train loss and acc of batch 68: 48.507896423339844, 0.984375\n",
      "Train loss and acc of batch 69: 48.12895202636719, 0.984375\n",
      "Train loss and acc of batch 70: 47.91218185424805, 1.0\n",
      "Training accuracy and loss of epoch #231: 0.9894, 48.2374\n",
      "Saved model by train loss 48.23739957137847\n",
      "Train loss and acc of batch 0: 47.912166595458984, 1.0\n",
      "Train loss and acc of batch 1: 47.91216278076172, 1.0\n",
      "Train loss and acc of batch 2: 48.19800567626953, 0.984375\n",
      "Train loss and acc of batch 3: 48.12890625, 0.984375\n",
      "Train loss and acc of batch 4: 47.912132263183594, 1.0\n",
      "Train loss and acc of batch 5: 49.26104736328125, 0.96875\n",
      "Train loss and acc of batch 6: 48.414730072021484, 0.96875\n",
      "Train loss and acc of batch 7: 47.912113189697266, 1.0\n",
      "Train loss and acc of batch 8: 48.50779724121094, 0.984375\n",
      "Train loss and acc of batch 9: 48.19794464111328, 0.984375\n",
      "Train loss and acc of batch 10: 47.912078857421875, 1.0\n",
      "Train loss and acc of batch 11: 47.91206741333008, 1.0\n",
      "Train loss and acc of batch 12: 48.665283203125, 0.984375\n",
      "Train loss and acc of batch 13: 48.128822326660156, 0.984375\n",
      "Train loss and acc of batch 14: 48.128807067871094, 0.984375\n",
      "Train loss and acc of batch 15: 48.50773620605469, 0.984375\n",
      "Train loss and acc of batch 16: 48.507728576660156, 0.984375\n",
      "Train loss and acc of batch 17: 48.66524124145508, 0.984375\n",
      "Train loss and acc of batch 18: 48.79356002807617, 0.96875\n",
      "Train loss and acc of batch 19: 47.91199493408203, 1.0\n",
      "Train loss and acc of batch 20: 47.911991119384766, 1.0\n",
      "Train loss and acc of batch 21: 48.50768280029297, 0.984375\n",
      "Train loss and acc of batch 22: 48.50767517089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.911964416503906, 1.0\n",
      "Train loss and acc of batch 24: 48.507659912109375, 0.984375\n",
      "Train loss and acc of batch 25: 47.91194152832031, 1.0\n",
      "Train loss and acc of batch 26: 47.91193771362305, 1.0\n",
      "Train loss and acc of batch 27: 47.911930084228516, 1.0\n",
      "Train loss and acc of batch 28: 47.91191864013672, 1.0\n",
      "Train loss and acc of batch 29: 48.50761413574219, 0.984375\n",
      "Train loss and acc of batch 30: 47.91189956665039, 1.0\n",
      "Train loss and acc of batch 31: 48.12865447998047, 0.984375\n",
      "Train loss and acc of batch 32: 47.911888122558594, 1.0\n",
      "Train loss and acc of batch 33: 47.91187286376953, 1.0\n",
      "Train loss and acc of batch 34: 48.507568359375, 0.984375\n",
      "Train loss and acc of batch 35: 48.34539031982422, 0.96875\n",
      "Train loss and acc of batch 36: 47.91184997558594, 1.0\n",
      "Train loss and acc of batch 37: 48.665061950683594, 0.984375\n",
      "Train loss and acc of batch 38: 49.26075744628906, 0.96875\n",
      "Train loss and acc of batch 39: 48.128578186035156, 0.984375\n",
      "Train loss and acc of batch 40: 47.91181182861328, 1.0\n",
      "Train loss and acc of batch 41: 49.26072692871094, 0.96875\n",
      "Train loss and acc of batch 42: 47.91178894042969, 1.0\n",
      "Train loss and acc of batch 43: 48.507484436035156, 0.984375\n",
      "Train loss and acc of batch 44: 47.91177749633789, 1.0\n",
      "Train loss and acc of batch 45: 48.507469177246094, 0.984375\n",
      "Train loss and acc of batch 46: 48.19761657714844, 0.984375\n",
      "Train loss and acc of batch 47: 47.911746978759766, 1.0\n",
      "Train loss and acc of batch 48: 47.911739349365234, 1.0\n",
      "Train loss and acc of batch 49: 47.9117317199707, 1.0\n",
      "Train loss and acc of batch 50: 48.507423400878906, 0.984375\n",
      "Train loss and acc of batch 51: 49.26063537597656, 0.96875\n",
      "Train loss and acc of batch 52: 49.167545318603516, 0.953125\n",
      "Train loss and acc of batch 53: 47.91169738769531, 1.0\n",
      "Train loss and acc of batch 54: 48.128456115722656, 0.984375\n",
      "Train loss and acc of batch 55: 47.911678314208984, 1.0\n",
      "Train loss and acc of batch 56: 47.91166687011719, 1.0\n",
      "Train loss and acc of batch 57: 48.507362365722656, 0.984375\n",
      "Train loss and acc of batch 58: 47.91165542602539, 1.0\n",
      "Train loss and acc of batch 59: 47.911643981933594, 1.0\n",
      "Train loss and acc of batch 60: 47.9116325378418, 1.0\n",
      "Train loss and acc of batch 61: 47.911624908447266, 1.0\n",
      "Train loss and acc of batch 62: 47.91161346435547, 1.0\n",
      "Train loss and acc of batch 63: 49.10301208496094, 0.96875\n",
      "Train loss and acc of batch 64: 48.12836456298828, 0.984375\n",
      "Train loss and acc of batch 65: 47.911590576171875, 1.0\n",
      "Train loss and acc of batch 66: 47.911582946777344, 1.0\n",
      "Train loss and acc of batch 67: 48.724037170410156, 0.96875\n",
      "Train loss and acc of batch 68: 48.50726318359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.128318786621094, 0.984375\n",
      "Train loss and acc of batch 70: 47.91154098510742, 1.0\n",
      "Training accuracy and loss of epoch #232: 0.9894, 48.2368\n",
      "Saved model by train loss 48.23676622417611\n",
      "Train loss and acc of batch 0: 47.911537170410156, 1.0\n",
      "Train loss and acc of batch 1: 47.91152572631836, 1.0\n",
      "Train loss and acc of batch 2: 48.19737243652344, 0.984375\n",
      "Train loss and acc of batch 3: 48.128273010253906, 0.984375\n",
      "Train loss and acc of batch 4: 47.9114990234375, 1.0\n",
      "Train loss and acc of batch 5: 49.260414123535156, 0.96875\n",
      "Train loss and acc of batch 6: 48.414100646972656, 0.96875\n",
      "Train loss and acc of batch 7: 47.911476135253906, 1.0\n",
      "Train loss and acc of batch 8: 48.507164001464844, 0.984375\n",
      "Train loss and acc of batch 9: 48.19731140136719, 0.984375\n",
      "Train loss and acc of batch 10: 47.91144943237305, 1.0\n",
      "Train loss and acc of batch 11: 47.91143798828125, 1.0\n",
      "Train loss and acc of batch 12: 48.66465377807617, 0.984375\n",
      "Train loss and acc of batch 13: 48.12818145751953, 0.984375\n",
      "Train loss and acc of batch 14: 48.128173828125, 0.984375\n",
      "Train loss and acc of batch 15: 48.507102966308594, 0.984375\n",
      "Train loss and acc of batch 16: 48.50709533691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.664608001708984, 0.984375\n",
      "Train loss and acc of batch 18: 48.792930603027344, 0.96875\n",
      "Train loss and acc of batch 19: 47.91136932373047, 1.0\n",
      "Train loss and acc of batch 20: 47.91135787963867, 1.0\n",
      "Train loss and acc of batch 21: 48.507049560546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.507041931152344, 0.984375\n",
      "Train loss and acc of batch 23: 47.91133117675781, 1.0\n",
      "Train loss and acc of batch 24: 48.50701904296875, 0.984375\n",
      "Train loss and acc of batch 25: 47.91131591796875, 1.0\n",
      "Train loss and acc of batch 26: 47.91130447387695, 1.0\n",
      "Train loss and acc of batch 27: 47.911293029785156, 1.0\n",
      "Train loss and acc of batch 28: 47.911285400390625, 1.0\n",
      "Train loss and acc of batch 29: 48.506980895996094, 0.984375\n",
      "Train loss and acc of batch 30: 47.9112663269043, 1.0\n",
      "Train loss and acc of batch 31: 48.128021240234375, 0.984375\n",
      "Train loss and acc of batch 32: 47.9112548828125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.9112434387207, 1.0\n",
      "Train loss and acc of batch 34: 48.506935119628906, 0.984375\n",
      "Train loss and acc of batch 35: 48.344749450683594, 0.96875\n",
      "Train loss and acc of batch 36: 47.91121292114258, 1.0\n",
      "Train loss and acc of batch 37: 48.6644287109375, 0.984375\n",
      "Train loss and acc of batch 38: 49.26012420654297, 0.96875\n",
      "Train loss and acc of batch 39: 48.127960205078125, 0.984375\n",
      "Train loss and acc of batch 40: 47.91117858886719, 1.0\n",
      "Train loss and acc of batch 41: 49.260093688964844, 0.96875\n",
      "Train loss and acc of batch 42: 47.91115951538086, 1.0\n",
      "Train loss and acc of batch 43: 48.506858825683594, 0.984375\n",
      "Train loss and acc of batch 44: 47.9111442565918, 1.0\n",
      "Train loss and acc of batch 45: 48.5068359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.19697570800781, 0.984375\n",
      "Train loss and acc of batch 47: 47.91111755371094, 1.0\n",
      "Train loss and acc of batch 48: 47.911109924316406, 1.0\n",
      "Train loss and acc of batch 49: 47.911094665527344, 1.0\n",
      "Train loss and acc of batch 50: 48.50679016113281, 0.984375\n",
      "Train loss and acc of batch 51: 49.26000213623047, 0.96875\n",
      "Train loss and acc of batch 52: 49.16691207885742, 0.953125\n",
      "Train loss and acc of batch 53: 47.911067962646484, 1.0\n",
      "Train loss and acc of batch 54: 48.12782287597656, 0.984375\n",
      "Train loss and acc of batch 55: 47.91104507446289, 1.0\n",
      "Train loss and acc of batch 56: 47.91103744506836, 1.0\n",
      "Train loss and acc of batch 57: 48.50672912597656, 0.984375\n",
      "Train loss and acc of batch 58: 47.91101837158203, 1.0\n",
      "Train loss and acc of batch 59: 47.911006927490234, 1.0\n",
      "Train loss and acc of batch 60: 47.9109992980957, 1.0\n",
      "Train loss and acc of batch 61: 47.91099166870117, 1.0\n",
      "Train loss and acc of batch 62: 47.910987854003906, 1.0\n",
      "Train loss and acc of batch 63: 49.10237503051758, 0.96875\n",
      "Train loss and acc of batch 64: 48.12773132324219, 0.984375\n",
      "Train loss and acc of batch 65: 47.910953521728516, 1.0\n",
      "Train loss and acc of batch 66: 47.91094970703125, 1.0\n",
      "Train loss and acc of batch 67: 48.72340774536133, 0.96875\n",
      "Train loss and acc of batch 68: 48.506629943847656, 0.984375\n",
      "Train loss and acc of batch 69: 48.127685546875, 0.984375\n",
      "Train loss and acc of batch 70: 47.910911560058594, 1.0\n",
      "Training accuracy and loss of epoch #233: 0.9894, 48.2361\n",
      "Saved model by train loss 48.236133467983194\n",
      "Train loss and acc of batch 0: 47.91090393066406, 1.0\n",
      "Train loss and acc of batch 1: 47.910892486572266, 1.0\n",
      "Train loss and acc of batch 2: 48.196739196777344, 0.984375\n",
      "Train loss and acc of batch 3: 48.12763977050781, 0.984375\n",
      "Train loss and acc of batch 4: 47.910865783691406, 1.0\n",
      "Train loss and acc of batch 5: 49.259788513183594, 0.96875\n",
      "Train loss and acc of batch 6: 48.41346740722656, 0.96875\n",
      "Train loss and acc of batch 7: 47.91083908081055, 1.0\n",
      "Train loss and acc of batch 8: 48.50653076171875, 0.984375\n",
      "Train loss and acc of batch 9: 48.196678161621094, 0.984375\n",
      "Train loss and acc of batch 10: 47.91081619262695, 1.0\n",
      "Train loss and acc of batch 11: 47.910804748535156, 1.0\n",
      "Train loss and acc of batch 12: 48.66402053833008, 0.984375\n",
      "Train loss and acc of batch 13: 48.12755584716797, 0.984375\n",
      "Train loss and acc of batch 14: 48.127540588378906, 0.984375\n",
      "Train loss and acc of batch 15: 48.5064697265625, 0.984375\n",
      "Train loss and acc of batch 16: 48.50646209716797, 0.984375\n",
      "Train loss and acc of batch 17: 48.66397476196289, 0.984375\n",
      "Train loss and acc of batch 18: 48.79229736328125, 0.96875\n",
      "Train loss and acc of batch 19: 47.91073226928711, 1.0\n",
      "Train loss and acc of batch 20: 47.910728454589844, 1.0\n",
      "Train loss and acc of batch 21: 48.50641632080078, 0.984375\n",
      "Train loss and acc of batch 22: 48.50640869140625, 0.984375\n",
      "Train loss and acc of batch 23: 47.91069793701172, 1.0\n",
      "Train loss and acc of batch 24: 48.50639343261719, 0.984375\n",
      "Train loss and acc of batch 25: 47.910675048828125, 1.0\n",
      "Train loss and acc of batch 26: 47.91067123413086, 1.0\n",
      "Train loss and acc of batch 27: 47.910667419433594, 1.0\n",
      "Train loss and acc of batch 28: 47.9106559753418, 1.0\n",
      "Train loss and acc of batch 29: 48.50634002685547, 0.984375\n",
      "Train loss and acc of batch 30: 47.9106330871582, 1.0\n",
      "Train loss and acc of batch 31: 48.12738800048828, 0.984375\n",
      "Train loss and acc of batch 32: 47.910621643066406, 1.0\n",
      "Train loss and acc of batch 33: 47.91061019897461, 1.0\n",
      "Train loss and acc of batch 34: 48.50630187988281, 0.984375\n",
      "Train loss and acc of batch 35: 48.344120025634766, 0.96875\n",
      "Train loss and acc of batch 36: 47.910579681396484, 1.0\n",
      "Train loss and acc of batch 37: 48.663795471191406, 0.984375\n",
      "Train loss and acc of batch 38: 49.259490966796875, 0.96875\n",
      "Train loss and acc of batch 39: 48.1273193359375, 0.984375\n",
      "Train loss and acc of batch 40: 47.91054916381836, 1.0\n",
      "Train loss and acc of batch 41: 49.259464263916016, 0.96875\n",
      "Train loss and acc of batch 42: 47.910526275634766, 1.0\n",
      "Train loss and acc of batch 43: 48.50621795654297, 0.984375\n",
      "Train loss and acc of batch 44: 47.91050338745117, 1.0\n",
      "Train loss and acc of batch 45: 48.506202697753906, 0.984375\n",
      "Train loss and acc of batch 46: 48.19634246826172, 0.984375\n",
      "Train loss and acc of batch 47: 47.910484313964844, 1.0\n",
      "Train loss and acc of batch 48: 47.91046905517578, 1.0\n",
      "Train loss and acc of batch 49: 47.910465240478516, 1.0\n",
      "Train loss and acc of batch 50: 48.50615692138672, 0.984375\n",
      "Train loss and acc of batch 51: 49.259368896484375, 0.96875\n",
      "Train loss and acc of batch 52: 49.16627502441406, 0.953125\n",
      "Train loss and acc of batch 53: 47.910423278808594, 1.0\n",
      "Train loss and acc of batch 54: 48.12718200683594, 0.984375\n",
      "Train loss and acc of batch 55: 47.91041564941406, 1.0\n",
      "Train loss and acc of batch 56: 47.910400390625, 1.0\n",
      "Train loss and acc of batch 57: 48.50609588623047, 0.984375\n",
      "Train loss and acc of batch 58: 47.91038131713867, 1.0\n",
      "Train loss and acc of batch 59: 47.91037368774414, 1.0\n",
      "Train loss and acc of batch 60: 47.91036605834961, 1.0\n",
      "Train loss and acc of batch 61: 47.91035842895508, 1.0\n",
      "Train loss and acc of batch 62: 47.91034698486328, 1.0\n",
      "Train loss and acc of batch 63: 49.101741790771484, 0.96875\n",
      "Train loss and acc of batch 64: 48.12709045410156, 0.984375\n",
      "Train loss and acc of batch 65: 47.910316467285156, 1.0\n",
      "Train loss and acc of batch 66: 47.91031265258789, 1.0\n",
      "Train loss and acc of batch 67: 48.7227668762207, 0.96875\n",
      "Train loss and acc of batch 68: 48.50599670410156, 0.984375\n",
      "Train loss and acc of batch 69: 48.127052307128906, 0.984375\n",
      "Train loss and acc of batch 70: 47.9102783203125, 1.0\n",
      "Training accuracy and loss of epoch #234: 0.9894, 48.2355\n",
      "Saved model by train loss 48.235499422315144\n",
      "Train loss and acc of batch 0: 47.9102668762207, 1.0\n",
      "Train loss and acc of batch 1: 47.910255432128906, 1.0\n",
      "Train loss and acc of batch 2: 48.19609832763672, 0.984375\n",
      "Train loss and acc of batch 3: 48.12700653076172, 0.984375\n",
      "Train loss and acc of batch 4: 47.91023254394531, 1.0\n",
      "Train loss and acc of batch 5: 49.25914764404297, 0.96875\n",
      "Train loss and acc of batch 6: 48.41283416748047, 0.96875\n",
      "Train loss and acc of batch 7: 47.91020584106445, 1.0\n",
      "Train loss and acc of batch 8: 48.505897521972656, 0.984375\n",
      "Train loss and acc of batch 9: 48.19603729248047, 0.984375\n",
      "Train loss and acc of batch 10: 47.91017532348633, 1.0\n",
      "Train loss and acc of batch 11: 47.9101676940918, 1.0\n",
      "Train loss and acc of batch 12: 48.663387298583984, 0.984375\n",
      "Train loss and acc of batch 13: 48.126914978027344, 0.984375\n",
      "Train loss and acc of batch 14: 48.12690734863281, 0.984375\n",
      "Train loss and acc of batch 15: 48.505836486816406, 0.984375\n",
      "Train loss and acc of batch 16: 48.505821228027344, 0.984375\n",
      "Train loss and acc of batch 17: 48.6633415222168, 0.984375\n",
      "Train loss and acc of batch 18: 48.79166030883789, 0.96875\n",
      "Train loss and acc of batch 19: 47.91009521484375, 1.0\n",
      "Train loss and acc of batch 20: 47.910091400146484, 1.0\n",
      "Train loss and acc of batch 21: 48.505775451660156, 0.984375\n",
      "Train loss and acc of batch 22: 48.505775451660156, 0.984375\n",
      "Train loss and acc of batch 23: 47.91006088256836, 1.0\n",
      "Train loss and acc of batch 24: 48.50575256347656, 0.984375\n",
      "Train loss and acc of batch 25: 47.9100456237793, 1.0\n",
      "Train loss and acc of batch 26: 47.910037994384766, 1.0\n",
      "Train loss and acc of batch 27: 47.91002655029297, 1.0\n",
      "Train loss and acc of batch 28: 47.91001892089844, 1.0\n",
      "Train loss and acc of batch 29: 48.505706787109375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 30: 47.90999984741211, 1.0\n",
      "Train loss and acc of batch 31: 48.12675476074219, 0.984375\n",
      "Train loss and acc of batch 32: 47.90998458862305, 1.0\n",
      "Train loss and acc of batch 33: 47.909969329833984, 1.0\n",
      "Train loss and acc of batch 34: 48.50566864013672, 0.984375\n",
      "Train loss and acc of batch 35: 48.343482971191406, 0.96875\n",
      "Train loss and acc of batch 36: 47.909950256347656, 1.0\n",
      "Train loss and acc of batch 37: 48.66315841674805, 0.984375\n",
      "Train loss and acc of batch 38: 49.25885009765625, 0.96875\n",
      "Train loss and acc of batch 39: 48.126678466796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.909915924072266, 1.0\n",
      "Train loss and acc of batch 41: 49.258827209472656, 0.96875\n",
      "Train loss and acc of batch 42: 47.90989303588867, 1.0\n",
      "Train loss and acc of batch 43: 48.505592346191406, 0.984375\n",
      "Train loss and acc of batch 44: 47.90987777709961, 1.0\n",
      "Train loss and acc of batch 45: 48.50556945800781, 0.984375\n",
      "Train loss and acc of batch 46: 48.195709228515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.909847259521484, 1.0\n",
      "Train loss and acc of batch 48: 47.90983963012695, 1.0\n",
      "Train loss and acc of batch 49: 47.909828186035156, 1.0\n",
      "Train loss and acc of batch 50: 48.505523681640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.25873565673828, 0.96875\n",
      "Train loss and acc of batch 52: 49.16564178466797, 0.953125\n",
      "Train loss and acc of batch 53: 47.909793853759766, 1.0\n",
      "Train loss and acc of batch 54: 48.126556396484375, 0.984375\n",
      "Train loss and acc of batch 55: 47.9097785949707, 1.0\n",
      "Train loss and acc of batch 56: 47.909767150878906, 1.0\n",
      "Train loss and acc of batch 57: 48.505462646484375, 0.984375\n",
      "Train loss and acc of batch 58: 47.909751892089844, 1.0\n",
      "Train loss and acc of batch 59: 47.90974426269531, 1.0\n",
      "Train loss and acc of batch 60: 47.909732818603516, 1.0\n",
      "Train loss and acc of batch 61: 47.909725189208984, 1.0\n",
      "Train loss and acc of batch 62: 47.90971374511719, 1.0\n",
      "Train loss and acc of batch 63: 49.10110855102539, 0.96875\n",
      "Train loss and acc of batch 64: 48.12646484375, 0.984375\n",
      "Train loss and acc of batch 65: 47.909690856933594, 1.0\n",
      "Train loss and acc of batch 66: 47.90967559814453, 1.0\n",
      "Train loss and acc of batch 67: 48.72213363647461, 0.96875\n",
      "Train loss and acc of batch 68: 48.50536346435547, 0.984375\n",
      "Train loss and acc of batch 69: 48.12641906738281, 0.984375\n",
      "Train loss and acc of batch 70: 47.909645080566406, 1.0\n",
      "Training accuracy and loss of epoch #235: 0.9894, 48.2349\n",
      "Saved model by train loss 48.23486489309391\n",
      "Train loss and acc of batch 0: 47.90963363647461, 1.0\n",
      "Train loss and acc of batch 1: 47.90962600708008, 1.0\n",
      "Train loss and acc of batch 2: 48.195472717285156, 0.984375\n",
      "Train loss and acc of batch 3: 48.126373291015625, 0.984375\n",
      "Train loss and acc of batch 4: 47.90959930419922, 1.0\n",
      "Train loss and acc of batch 5: 49.258514404296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.412200927734375, 0.96875\n",
      "Train loss and acc of batch 7: 47.90957260131836, 1.0\n",
      "Train loss and acc of batch 8: 48.50526428222656, 0.984375\n",
      "Train loss and acc of batch 9: 48.195404052734375, 0.984375\n",
      "Train loss and acc of batch 10: 47.9095458984375, 1.0\n",
      "Train loss and acc of batch 11: 47.90953826904297, 1.0\n",
      "Train loss and acc of batch 12: 48.662750244140625, 0.984375\n",
      "Train loss and acc of batch 13: 48.12628173828125, 0.984375\n",
      "Train loss and acc of batch 14: 48.12627410888672, 0.984375\n",
      "Train loss and acc of batch 15: 48.50520324707031, 0.984375\n",
      "Train loss and acc of batch 16: 48.50519561767578, 0.984375\n",
      "Train loss and acc of batch 17: 48.66270446777344, 0.984375\n",
      "Train loss and acc of batch 18: 48.79102325439453, 0.96875\n",
      "Train loss and acc of batch 19: 47.90946578979492, 1.0\n",
      "Train loss and acc of batch 20: 47.909454345703125, 1.0\n",
      "Train loss and acc of batch 21: 48.505149841308594, 0.984375\n",
      "Train loss and acc of batch 22: 48.50514221191406, 0.984375\n",
      "Train loss and acc of batch 23: 47.90943145751953, 1.0\n",
      "Train loss and acc of batch 24: 48.50511932373047, 0.984375\n",
      "Train loss and acc of batch 25: 47.90941619873047, 1.0\n",
      "Train loss and acc of batch 26: 47.90940475463867, 1.0\n",
      "Train loss and acc of batch 27: 47.909393310546875, 1.0\n",
      "Train loss and acc of batch 28: 47.90938949584961, 1.0\n",
      "Train loss and acc of batch 29: 48.50508117675781, 0.984375\n",
      "Train loss and acc of batch 30: 47.90937042236328, 1.0\n",
      "Train loss and acc of batch 31: 48.126121520996094, 0.984375\n",
      "Train loss and acc of batch 32: 47.90934753417969, 1.0\n",
      "Train loss and acc of batch 33: 47.909339904785156, 1.0\n",
      "Train loss and acc of batch 34: 48.505035400390625, 0.984375\n",
      "Train loss and acc of batch 35: 48.34284973144531, 0.96875\n",
      "Train loss and acc of batch 36: 47.9093132019043, 1.0\n",
      "Train loss and acc of batch 37: 48.662532806396484, 0.984375\n",
      "Train loss and acc of batch 38: 49.25822448730469, 0.96875\n",
      "Train loss and acc of batch 39: 48.12605285644531, 0.984375\n",
      "Train loss and acc of batch 40: 47.909278869628906, 1.0\n",
      "Train loss and acc of batch 41: 49.25819396972656, 0.96875\n",
      "Train loss and acc of batch 42: 47.90925979614258, 1.0\n",
      "Train loss and acc of batch 43: 48.50495910644531, 0.984375\n",
      "Train loss and acc of batch 44: 47.909244537353516, 1.0\n",
      "Train loss and acc of batch 45: 48.50493621826172, 0.984375\n",
      "Train loss and acc of batch 46: 48.19507598876953, 0.984375\n",
      "Train loss and acc of batch 47: 47.90921401977539, 1.0\n",
      "Train loss and acc of batch 48: 47.90920639038086, 1.0\n",
      "Train loss and acc of batch 49: 47.90919876098633, 1.0\n",
      "Train loss and acc of batch 50: 48.50489044189453, 0.984375\n",
      "Train loss and acc of batch 51: 49.25811004638672, 0.96875\n",
      "Train loss and acc of batch 52: 49.16501235961914, 0.953125\n",
      "Train loss and acc of batch 53: 47.90916442871094, 1.0\n",
      "Train loss and acc of batch 54: 48.12592315673828, 0.984375\n",
      "Train loss and acc of batch 55: 47.90914535522461, 1.0\n",
      "Train loss and acc of batch 56: 47.90913772583008, 1.0\n",
      "Train loss and acc of batch 57: 48.50482940673828, 0.984375\n",
      "Train loss and acc of batch 58: 47.909122467041016, 1.0\n",
      "Train loss and acc of batch 59: 47.90911102294922, 1.0\n",
      "Train loss and acc of batch 60: 47.909095764160156, 1.0\n",
      "Train loss and acc of batch 61: 47.909088134765625, 1.0\n",
      "Train loss and acc of batch 62: 48.12584686279297, 0.984375\n",
      "Train loss and acc of batch 63: 49.10047149658203, 0.96875\n",
      "Train loss and acc of batch 64: 48.125831604003906, 0.984375\n",
      "Train loss and acc of batch 65: 47.909053802490234, 1.0\n",
      "Train loss and acc of batch 66: 47.90904998779297, 1.0\n",
      "Train loss and acc of batch 67: 48.72150421142578, 0.96875\n",
      "Train loss and acc of batch 68: 48.504730224609375, 0.984375\n",
      "Train loss and acc of batch 69: 48.12578582763672, 0.984375\n",
      "Train loss and acc of batch 70: 47.90900802612305, 1.0\n",
      "Training accuracy and loss of epoch #236: 0.9892, 48.2373\n",
      "Train loss and acc of batch 0: 47.909000396728516, 1.0\n",
      "Train loss and acc of batch 1: 47.90899658203125, 1.0\n",
      "Train loss and acc of batch 2: 48.19483947753906, 0.984375\n",
      "Train loss and acc of batch 3: 48.12574005126953, 0.984375\n",
      "Train loss and acc of batch 4: 47.908966064453125, 1.0\n",
      "Train loss and acc of batch 5: 49.25788116455078, 0.96875\n",
      "Train loss and acc of batch 6: 48.411563873291016, 0.96875\n",
      "Train loss and acc of batch 7: 47.908939361572266, 1.0\n",
      "Train loss and acc of batch 8: 48.50463104248047, 0.984375\n",
      "Train loss and acc of batch 9: 48.19477844238281, 0.984375\n",
      "Train loss and acc of batch 10: 47.90891647338867, 1.0\n",
      "Train loss and acc of batch 11: 47.90890884399414, 1.0\n",
      "Train loss and acc of batch 12: 48.6621208190918, 0.984375\n",
      "Train loss and acc of batch 13: 48.12565612792969, 0.984375\n",
      "Train loss and acc of batch 14: 48.125640869140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.50457000732422, 0.984375\n",
      "Train loss and acc of batch 16: 48.50456237792969, 0.984375\n",
      "Train loss and acc of batch 17: 48.662071228027344, 0.984375\n",
      "Train loss and acc of batch 18: 48.79039764404297, 0.96875\n",
      "Train loss and acc of batch 19: 47.908836364746094, 1.0\n",
      "Train loss and acc of batch 20: 47.90882110595703, 1.0\n",
      "Train loss and acc of batch 21: 48.5045166015625, 0.984375\n",
      "Train loss and acc of batch 22: 48.50450897216797, 0.984375\n",
      "Train loss and acc of batch 23: 47.90879821777344, 1.0\n",
      "Train loss and acc of batch 24: 48.504493713378906, 0.984375\n",
      "Train loss and acc of batch 25: 47.908775329589844, 1.0\n",
      "Train loss and acc of batch 26: 47.908775329589844, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 27: 47.90876388549805, 1.0\n",
      "Train loss and acc of batch 28: 47.908748626708984, 1.0\n",
      "Train loss and acc of batch 29: 48.50444793701172, 0.984375\n",
      "Train loss and acc of batch 30: 47.90873336791992, 1.0\n",
      "Train loss and acc of batch 31: 48.12548828125, 0.984375\n",
      "Train loss and acc of batch 32: 47.908721923828125, 1.0\n",
      "Train loss and acc of batch 33: 47.90870666503906, 1.0\n",
      "Train loss and acc of batch 34: 48.50440216064453, 0.984375\n",
      "Train loss and acc of batch 35: 48.34221649169922, 0.96875\n",
      "Train loss and acc of batch 36: 47.90867614746094, 1.0\n",
      "Train loss and acc of batch 37: 48.661895751953125, 0.984375\n",
      "Train loss and acc of batch 38: 49.257591247558594, 0.96875\n",
      "Train loss and acc of batch 39: 48.12541961669922, 0.984375\n",
      "Train loss and acc of batch 40: 47.90864944458008, 1.0\n",
      "Train loss and acc of batch 41: 49.257568359375, 0.96875\n",
      "Train loss and acc of batch 42: 47.908626556396484, 1.0\n",
      "Train loss and acc of batch 43: 48.50431823730469, 0.984375\n",
      "Train loss and acc of batch 44: 47.90860366821289, 1.0\n",
      "Train loss and acc of batch 45: 48.504302978515625, 0.984375\n",
      "Train loss and acc of batch 46: 48.19445037841797, 0.984375\n",
      "Train loss and acc of batch 47: 47.90858459472656, 1.0\n",
      "Train loss and acc of batch 48: 47.908573150634766, 1.0\n",
      "Train loss and acc of batch 49: 47.9085693359375, 1.0\n",
      "Train loss and acc of batch 50: 48.50425720214844, 0.984375\n",
      "Train loss and acc of batch 51: 49.257476806640625, 0.96875\n",
      "Train loss and acc of batch 52: 49.16438293457031, 0.953125\n",
      "Train loss and acc of batch 53: 47.90852737426758, 1.0\n",
      "Train loss and acc of batch 54: 48.12528991699219, 0.984375\n",
      "Train loss and acc of batch 55: 47.90851593017578, 1.0\n",
      "Train loss and acc of batch 56: 47.90850830078125, 1.0\n",
      "Train loss and acc of batch 57: 48.50420379638672, 0.984375\n",
      "Train loss and acc of batch 58: 47.90848159790039, 1.0\n",
      "Train loss and acc of batch 59: 47.908477783203125, 1.0\n",
      "Train loss and acc of batch 60: 47.908470153808594, 1.0\n",
      "Train loss and acc of batch 61: 47.9084587097168, 1.0\n",
      "Train loss and acc of batch 62: 48.125213623046875, 0.984375\n",
      "Train loss and acc of batch 63: 49.099849700927734, 0.96875\n",
      "Train loss and acc of batch 64: 48.12519073486328, 0.984375\n",
      "Train loss and acc of batch 65: 47.908424377441406, 1.0\n",
      "Train loss and acc of batch 66: 47.908416748046875, 1.0\n",
      "Train loss and acc of batch 67: 48.72087097167969, 0.96875\n",
      "Train loss and acc of batch 68: 48.50409698486328, 0.984375\n",
      "Train loss and acc of batch 69: 48.125160217285156, 0.984375\n",
      "Train loss and acc of batch 70: 47.90837860107422, 1.0\n",
      "Training accuracy and loss of epoch #237: 0.9892, 48.2367\n",
      "Train loss and acc of batch 0: 47.90837097167969, 1.0\n",
      "Train loss and acc of batch 1: 47.90835952758789, 1.0\n",
      "Train loss and acc of batch 2: 48.19420623779297, 0.984375\n",
      "Train loss and acc of batch 3: 48.12510681152344, 0.984375\n",
      "Train loss and acc of batch 4: 47.9083366394043, 1.0\n",
      "Train loss and acc of batch 5: 49.25724792480469, 0.96875\n",
      "Train loss and acc of batch 6: 48.41093826293945, 0.96875\n",
      "Train loss and acc of batch 7: 47.90830612182617, 1.0\n",
      "Train loss and acc of batch 8: 48.503997802734375, 0.984375\n",
      "Train loss and acc of batch 9: 48.19414520263672, 0.984375\n",
      "Train loss and acc of batch 10: 47.90827560424805, 1.0\n",
      "Train loss and acc of batch 11: 47.90827560424805, 1.0\n",
      "Train loss and acc of batch 12: 48.66149139404297, 0.984375\n",
      "Train loss and acc of batch 13: 48.125022888183594, 0.984375\n",
      "Train loss and acc of batch 14: 48.12501525878906, 0.984375\n",
      "Train loss and acc of batch 15: 48.503936767578125, 0.984375\n",
      "Train loss and acc of batch 16: 48.50392150878906, 0.984375\n",
      "Train loss and acc of batch 17: 48.66144561767578, 0.984375\n",
      "Train loss and acc of batch 18: 48.78976058959961, 0.96875\n",
      "Train loss and acc of batch 19: 47.908199310302734, 1.0\n",
      "Train loss and acc of batch 20: 47.90819549560547, 1.0\n",
      "Train loss and acc of batch 21: 48.503875732421875, 0.984375\n",
      "Train loss and acc of batch 22: 48.503875732421875, 0.984375\n",
      "Train loss and acc of batch 23: 47.908164978027344, 1.0\n",
      "Train loss and acc of batch 24: 48.50385284423828, 0.984375\n",
      "Train loss and acc of batch 25: 47.90814971923828, 1.0\n",
      "Train loss and acc of batch 26: 47.90814208984375, 1.0\n",
      "Train loss and acc of batch 27: 47.90813064575195, 1.0\n",
      "Train loss and acc of batch 28: 47.90812683105469, 1.0\n",
      "Train loss and acc of batch 29: 48.503814697265625, 0.984375\n",
      "Train loss and acc of batch 30: 47.90810012817383, 1.0\n",
      "Train loss and acc of batch 31: 48.12486267089844, 0.984375\n",
      "Train loss and acc of batch 32: 47.908084869384766, 1.0\n",
      "Train loss and acc of batch 33: 47.90807342529297, 1.0\n",
      "Train loss and acc of batch 34: 48.50376892089844, 0.984375\n",
      "Train loss and acc of batch 35: 48.34158706665039, 0.96875\n",
      "Train loss and acc of batch 36: 47.908050537109375, 1.0\n",
      "Train loss and acc of batch 37: 48.66126251220703, 0.984375\n",
      "Train loss and acc of batch 38: 49.25695037841797, 0.96875\n",
      "Train loss and acc of batch 39: 48.124786376953125, 0.984375\n",
      "Train loss and acc of batch 40: 47.908016204833984, 1.0\n",
      "Train loss and acc of batch 41: 49.256935119628906, 0.96875\n",
      "Train loss and acc of batch 42: 47.90800094604492, 1.0\n",
      "Train loss and acc of batch 43: 48.503692626953125, 0.984375\n",
      "Train loss and acc of batch 44: 47.90797805786133, 1.0\n",
      "Train loss and acc of batch 45: 48.50366973876953, 0.984375\n",
      "Train loss and acc of batch 46: 48.193809509277344, 0.984375\n",
      "Train loss and acc of batch 47: 47.9079475402832, 1.0\n",
      "Train loss and acc of batch 48: 47.90794372558594, 1.0\n",
      "Train loss and acc of batch 49: 47.90793228149414, 1.0\n",
      "Train loss and acc of batch 50: 48.503631591796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.2568359375, 0.96875\n",
      "Train loss and acc of batch 52: 49.16374588012695, 0.953125\n",
      "Train loss and acc of batch 53: 47.90789794921875, 1.0\n",
      "Train loss and acc of batch 54: 48.12464904785156, 0.984375\n",
      "Train loss and acc of batch 55: 47.90787887573242, 1.0\n",
      "Train loss and acc of batch 56: 47.907875061035156, 1.0\n",
      "Train loss and acc of batch 57: 48.503562927246094, 0.984375\n",
      "Train loss and acc of batch 58: 47.90785598754883, 1.0\n",
      "Train loss and acc of batch 59: 47.9078483581543, 1.0\n",
      "Train loss and acc of batch 60: 47.907833099365234, 1.0\n",
      "Train loss and acc of batch 61: 47.90782928466797, 1.0\n",
      "Train loss and acc of batch 62: 48.12458801269531, 0.984375\n",
      "Train loss and acc of batch 63: 49.09920883178711, 0.96875\n",
      "Train loss and acc of batch 64: 48.12456512451172, 0.984375\n",
      "Train loss and acc of batch 65: 47.90779113769531, 1.0\n",
      "Train loss and acc of batch 66: 47.907779693603516, 1.0\n",
      "Train loss and acc of batch 67: 48.720237731933594, 0.96875\n",
      "Train loss and acc of batch 68: 48.50346374511719, 0.984375\n",
      "Train loss and acc of batch 69: 48.12451934814453, 0.984375\n",
      "Train loss and acc of batch 70: 47.907752990722656, 1.0\n",
      "Training accuracy and loss of epoch #238: 0.9892, 48.2360\n",
      "Train loss and acc of batch 0: 47.907737731933594, 1.0\n",
      "Train loss and acc of batch 1: 47.9077262878418, 1.0\n",
      "Train loss and acc of batch 2: 48.193572998046875, 0.984375\n",
      "Train loss and acc of batch 3: 48.124473571777344, 0.984375\n",
      "Train loss and acc of batch 4: 47.9077033996582, 1.0\n",
      "Train loss and acc of batch 5: 49.256614685058594, 0.96875\n",
      "Train loss and acc of batch 6: 48.410301208496094, 0.96875\n",
      "Train loss and acc of batch 7: 47.907676696777344, 1.0\n",
      "Train loss and acc of batch 8: 48.50336456298828, 0.984375\n",
      "Train loss and acc of batch 9: 48.193504333496094, 0.984375\n",
      "Train loss and acc of batch 10: 47.907649993896484, 1.0\n",
      "Train loss and acc of batch 11: 47.90764236450195, 1.0\n",
      "Train loss and acc of batch 12: 48.66085433959961, 0.984375\n",
      "Train loss and acc of batch 13: 48.1243896484375, 0.984375\n",
      "Train loss and acc of batch 14: 48.12438201904297, 0.984375\n",
      "Train loss and acc of batch 15: 48.50330352783203, 0.984375\n",
      "Train loss and acc of batch 16: 48.50330352783203, 0.984375\n",
      "Train loss and acc of batch 17: 48.66080856323242, 0.984375\n",
      "Train loss and acc of batch 18: 48.78913116455078, 0.96875\n",
      "Train loss and acc of batch 19: 47.90756607055664, 1.0\n",
      "Train loss and acc of batch 20: 47.90755844116211, 1.0\n",
      "Train loss and acc of batch 21: 48.50325012207031, 0.984375\n",
      "Train loss and acc of batch 22: 48.50324249267578, 0.984375\n",
      "Train loss and acc of batch 23: 47.90753173828125, 1.0\n",
      "Train loss and acc of batch 24: 48.50322723388672, 0.984375\n",
      "Train loss and acc of batch 25: 47.90751266479492, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 26: 47.907508850097656, 1.0\n",
      "Train loss and acc of batch 27: 47.907501220703125, 1.0\n",
      "Train loss and acc of batch 28: 47.90748596191406, 1.0\n",
      "Train loss and acc of batch 29: 48.50318145751953, 0.984375\n",
      "Train loss and acc of batch 30: 47.907470703125, 1.0\n",
      "Train loss and acc of batch 31: 48.124229431152344, 0.984375\n",
      "Train loss and acc of batch 32: 47.907447814941406, 1.0\n",
      "Train loss and acc of batch 33: 47.90744400024414, 1.0\n",
      "Train loss and acc of batch 34: 48.503135681152344, 0.984375\n",
      "Train loss and acc of batch 35: 48.34095764160156, 0.96875\n",
      "Train loss and acc of batch 36: 47.90741729736328, 1.0\n",
      "Train loss and acc of batch 37: 48.6606330871582, 0.984375\n",
      "Train loss and acc of batch 38: 49.256324768066406, 0.96875\n",
      "Train loss and acc of batch 39: 48.12415313720703, 0.984375\n",
      "Train loss and acc of batch 40: 47.907379150390625, 1.0\n",
      "Train loss and acc of batch 41: 49.25630187988281, 0.96875\n",
      "Train loss and acc of batch 42: 47.9073600769043, 1.0\n",
      "Train loss and acc of batch 43: 48.50305938720703, 0.984375\n",
      "Train loss and acc of batch 44: 47.907352447509766, 1.0\n",
      "Train loss and acc of batch 45: 48.50303649902344, 0.984375\n",
      "Train loss and acc of batch 46: 48.19317626953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.90731430053711, 1.0\n",
      "Train loss and acc of batch 48: 47.90730667114258, 1.0\n",
      "Train loss and acc of batch 49: 47.90730285644531, 1.0\n",
      "Train loss and acc of batch 50: 48.50299072265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.25621032714844, 0.96875\n",
      "Train loss and acc of batch 52: 49.16311264038086, 0.953125\n",
      "Train loss and acc of batch 53: 47.907264709472656, 1.0\n",
      "Train loss and acc of batch 54: 48.1240234375, 0.984375\n",
      "Train loss and acc of batch 55: 47.907249450683594, 1.0\n",
      "Train loss and acc of batch 56: 47.9072380065918, 1.0\n",
      "Train loss and acc of batch 57: 48.5029296875, 0.984375\n",
      "Train loss and acc of batch 58: 47.907222747802734, 1.0\n",
      "Train loss and acc of batch 59: 47.9072151184082, 1.0\n",
      "Train loss and acc of batch 60: 47.907203674316406, 1.0\n",
      "Train loss and acc of batch 61: 47.90719223022461, 1.0\n",
      "Train loss and acc of batch 62: 48.12394714355469, 0.984375\n",
      "Train loss and acc of batch 63: 49.09858322143555, 0.96875\n",
      "Train loss and acc of batch 64: 48.123931884765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.90715789794922, 1.0\n",
      "Train loss and acc of batch 66: 47.90715026855469, 1.0\n",
      "Train loss and acc of batch 67: 48.719600677490234, 0.96875\n",
      "Train loss and acc of batch 68: 48.502838134765625, 0.984375\n",
      "Train loss and acc of batch 69: 48.12389373779297, 0.984375\n",
      "Train loss and acc of batch 70: 47.90711212158203, 1.0\n",
      "Training accuracy and loss of epoch #239: 0.9892, 48.2354\n",
      "Train loss and acc of batch 0: 47.907108306884766, 1.0\n",
      "Train loss and acc of batch 1: 47.907100677490234, 1.0\n",
      "Train loss and acc of batch 2: 48.19293975830078, 0.984375\n",
      "Train loss and acc of batch 3: 48.12384033203125, 0.984375\n",
      "Train loss and acc of batch 4: 47.90706253051758, 1.0\n",
      "Train loss and acc of batch 5: 49.25598907470703, 0.96875\n",
      "Train loss and acc of batch 6: 48.40966796875, 0.96875\n",
      "Train loss and acc of batch 7: 47.90704345703125, 1.0\n",
      "Train loss and acc of batch 8: 48.50273132324219, 0.984375\n",
      "Train loss and acc of batch 9: 48.19287872314453, 0.984375\n",
      "Train loss and acc of batch 10: 47.907012939453125, 1.0\n",
      "Train loss and acc of batch 11: 47.90700912475586, 1.0\n",
      "Train loss and acc of batch 12: 48.660221099853516, 0.984375\n",
      "Train loss and acc of batch 13: 48.123748779296875, 0.984375\n",
      "Train loss and acc of batch 14: 48.123741149902344, 0.984375\n",
      "Train loss and acc of batch 15: 48.50267791748047, 0.984375\n",
      "Train loss and acc of batch 16: 48.502662658691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.66017532348633, 0.984375\n",
      "Train loss and acc of batch 18: 48.78850173950195, 0.96875\n",
      "Train loss and acc of batch 19: 47.90693283081055, 1.0\n",
      "Train loss and acc of batch 20: 47.906925201416016, 1.0\n",
      "Train loss and acc of batch 21: 48.50261688232422, 0.984375\n",
      "Train loss and acc of batch 22: 48.50260925292969, 0.984375\n",
      "Train loss and acc of batch 23: 47.90690231323242, 1.0\n",
      "Train loss and acc of batch 24: 48.502593994140625, 0.984375\n",
      "Train loss and acc of batch 25: 47.90687942504883, 1.0\n",
      "Train loss and acc of batch 26: 47.90687561035156, 1.0\n",
      "Train loss and acc of batch 27: 47.906864166259766, 1.0\n",
      "Train loss and acc of batch 28: 47.906856536865234, 1.0\n",
      "Train loss and acc of batch 29: 48.50255584716797, 0.984375\n",
      "Train loss and acc of batch 30: 47.90684127807617, 1.0\n",
      "Train loss and acc of batch 31: 48.12359619140625, 0.984375\n",
      "Train loss and acc of batch 32: 47.90681457519531, 1.0\n",
      "Train loss and acc of batch 33: 47.90681076049805, 1.0\n",
      "Train loss and acc of batch 34: 48.50250244140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.3403205871582, 0.96875\n",
      "Train loss and acc of batch 36: 47.90678405761719, 1.0\n",
      "Train loss and acc of batch 37: 48.65999984741211, 0.984375\n",
      "Train loss and acc of batch 38: 49.25569152832031, 0.96875\n",
      "Train loss and acc of batch 39: 48.12351989746094, 0.984375\n",
      "Train loss and acc of batch 40: 47.9067497253418, 1.0\n",
      "Train loss and acc of batch 41: 49.25566101074219, 0.96875\n",
      "Train loss and acc of batch 42: 47.90673065185547, 1.0\n",
      "Train loss and acc of batch 43: 48.50242614746094, 0.984375\n",
      "Train loss and acc of batch 44: 47.90671157836914, 1.0\n",
      "Train loss and acc of batch 45: 48.502403259277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.19255065917969, 0.984375\n",
      "Train loss and acc of batch 47: 47.90668487548828, 1.0\n",
      "Train loss and acc of batch 48: 47.90667724609375, 1.0\n",
      "Train loss and acc of batch 49: 47.90666580200195, 1.0\n",
      "Train loss and acc of batch 50: 48.502357482910156, 0.984375\n",
      "Train loss and acc of batch 51: 49.255577087402344, 0.96875\n",
      "Train loss and acc of batch 52: 49.1624870300293, 0.953125\n",
      "Train loss and acc of batch 53: 47.90663528442383, 1.0\n",
      "Train loss and acc of batch 54: 48.123390197753906, 0.984375\n",
      "Train loss and acc of batch 55: 47.906612396240234, 1.0\n",
      "Train loss and acc of batch 56: 47.90660858154297, 1.0\n",
      "Train loss and acc of batch 57: 48.50230407714844, 0.984375\n",
      "Train loss and acc of batch 58: 47.90658950805664, 1.0\n",
      "Train loss and acc of batch 59: 47.90658187866211, 1.0\n",
      "Train loss and acc of batch 60: 47.90657424926758, 1.0\n",
      "Train loss and acc of batch 61: 47.90656280517578, 1.0\n",
      "Train loss and acc of batch 62: 48.123321533203125, 0.984375\n",
      "Train loss and acc of batch 63: 49.09794616699219, 0.96875\n",
      "Train loss and acc of batch 64: 48.12329864501953, 0.984375\n",
      "Train loss and acc of batch 65: 47.90652847290039, 1.0\n",
      "Train loss and acc of batch 66: 47.906517028808594, 1.0\n",
      "Train loss and acc of batch 67: 48.71897506713867, 0.96875\n",
      "Train loss and acc of batch 68: 48.50220489501953, 0.984375\n",
      "Train loss and acc of batch 69: 48.123252868652344, 0.984375\n",
      "Train loss and acc of batch 70: 47.90647888183594, 1.0\n",
      "Training accuracy and loss of epoch #240: 0.9892, 48.2348\n",
      "Saved model by train loss 48.23475593244526\n",
      "Train loss and acc of batch 0: 47.90647506713867, 1.0\n",
      "Train loss and acc of batch 1: 47.90645980834961, 1.0\n",
      "Train loss and acc of batch 2: 48.19231414794922, 0.984375\n",
      "Train loss and acc of batch 3: 48.123207092285156, 0.984375\n",
      "Train loss and acc of batch 4: 47.90644073486328, 1.0\n",
      "Train loss and acc of batch 5: 49.25535583496094, 0.96875\n",
      "Train loss and acc of batch 6: 48.40903091430664, 0.96875\n",
      "Train loss and acc of batch 7: 47.90640640258789, 1.0\n",
      "Train loss and acc of batch 8: 48.502105712890625, 0.984375\n",
      "Train loss and acc of batch 9: 48.19224548339844, 0.984375\n",
      "Train loss and acc of batch 10: 47.90638732910156, 1.0\n",
      "Train loss and acc of batch 11: 47.906375885009766, 1.0\n",
      "Train loss and acc of batch 12: 48.65958786010742, 0.984375\n",
      "Train loss and acc of batch 13: 48.12312316894531, 0.984375\n",
      "Train loss and acc of batch 14: 48.12311553955078, 0.984375\n",
      "Train loss and acc of batch 15: 48.502037048339844, 0.984375\n",
      "Train loss and acc of batch 16: 48.50202941894531, 0.984375\n",
      "Train loss and acc of batch 17: 48.6595458984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.78786849975586, 0.96875\n",
      "Train loss and acc of batch 19: 47.90630340576172, 1.0\n",
      "Train loss and acc of batch 20: 47.90629959106445, 1.0\n",
      "Train loss and acc of batch 21: 48.501983642578125, 0.984375\n",
      "Train loss and acc of batch 22: 48.501976013183594, 0.984375\n",
      "Train loss and acc of batch 23: 47.90626907348633, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 24: 48.50196075439453, 0.984375\n",
      "Train loss and acc of batch 25: 47.906253814697266, 1.0\n",
      "Train loss and acc of batch 26: 47.9062385559082, 1.0\n",
      "Train loss and acc of batch 27: 47.90623474121094, 1.0\n",
      "Train loss and acc of batch 28: 47.906227111816406, 1.0\n",
      "Train loss and acc of batch 29: 48.501914978027344, 0.984375\n",
      "Train loss and acc of batch 30: 47.90620803833008, 1.0\n",
      "Train loss and acc of batch 31: 48.122962951660156, 0.984375\n",
      "Train loss and acc of batch 32: 47.90618896484375, 1.0\n",
      "Train loss and acc of batch 33: 47.90617752075195, 1.0\n",
      "Train loss and acc of batch 34: 48.501869201660156, 0.984375\n",
      "Train loss and acc of batch 35: 48.33969497680664, 0.96875\n",
      "Train loss and acc of batch 36: 47.906150817871094, 1.0\n",
      "Train loss and acc of batch 37: 48.659366607666016, 0.984375\n",
      "Train loss and acc of batch 38: 49.25505828857422, 0.96875\n",
      "Train loss and acc of batch 39: 48.122894287109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.9061164855957, 1.0\n",
      "Train loss and acc of batch 41: 49.25503921508789, 0.96875\n",
      "Train loss and acc of batch 42: 47.90610122680664, 1.0\n",
      "Train loss and acc of batch 43: 48.501792907714844, 0.984375\n",
      "Train loss and acc of batch 44: 47.90608215332031, 1.0\n",
      "Train loss and acc of batch 45: 48.50177764892578, 0.984375\n",
      "Train loss and acc of batch 46: 48.191917419433594, 0.984375\n",
      "Train loss and acc of batch 47: 47.90605545043945, 1.0\n",
      "Train loss and acc of batch 48: 47.906044006347656, 1.0\n",
      "Train loss and acc of batch 49: 47.90604019165039, 1.0\n",
      "Train loss and acc of batch 50: 48.501731872558594, 0.984375\n",
      "Train loss and acc of batch 51: 49.25494384765625, 0.96875\n",
      "Train loss and acc of batch 52: 49.16184997558594, 0.953125\n",
      "Train loss and acc of batch 53: 47.906002044677734, 1.0\n",
      "Train loss and acc of batch 54: 48.12275695800781, 0.984375\n",
      "Train loss and acc of batch 55: 47.90598678588867, 1.0\n",
      "Train loss and acc of batch 56: 47.905975341796875, 1.0\n",
      "Train loss and acc of batch 57: 48.501670837402344, 0.984375\n",
      "Train loss and acc of batch 58: 47.90595626831055, 1.0\n",
      "Train loss and acc of batch 59: 47.90594482421875, 1.0\n",
      "Train loss and acc of batch 60: 47.905941009521484, 1.0\n",
      "Train loss and acc of batch 61: 47.90592575073242, 1.0\n",
      "Train loss and acc of batch 62: 48.12268829345703, 0.984375\n",
      "Train loss and acc of batch 63: 49.09731674194336, 0.96875\n",
      "Train loss and acc of batch 64: 48.12267303466797, 0.984375\n",
      "Train loss and acc of batch 65: 47.9058952331543, 1.0\n",
      "Train loss and acc of batch 66: 47.905887603759766, 1.0\n",
      "Train loss and acc of batch 67: 48.71833801269531, 0.96875\n",
      "Train loss and acc of batch 68: 48.50157165527344, 0.984375\n",
      "Train loss and acc of batch 69: 48.12262725830078, 0.984375\n",
      "Train loss and acc of batch 70: 47.905853271484375, 1.0\n",
      "Training accuracy and loss of epoch #241: 0.9892, 48.2341\n",
      "Saved model by train loss 48.234124626911864\n",
      "Train loss and acc of batch 0: 47.90584182739258, 1.0\n",
      "Train loss and acc of batch 1: 47.905826568603516, 1.0\n",
      "Train loss and acc of batch 2: 48.191673278808594, 0.984375\n",
      "Train loss and acc of batch 3: 48.122581481933594, 0.984375\n",
      "Train loss and acc of batch 4: 47.90580749511719, 1.0\n",
      "Train loss and acc of batch 5: 49.254722595214844, 0.96875\n",
      "Train loss and acc of batch 6: 48.40840530395508, 0.96875\n",
      "Train loss and acc of batch 7: 47.90578079223633, 1.0\n",
      "Train loss and acc of batch 8: 48.50147247314453, 0.984375\n",
      "Train loss and acc of batch 9: 48.191612243652344, 0.984375\n",
      "Train loss and acc of batch 10: 47.9057502746582, 1.0\n",
      "Train loss and acc of batch 11: 47.90574264526367, 1.0\n",
      "Train loss and acc of batch 12: 48.658958435058594, 0.984375\n",
      "Train loss and acc of batch 13: 48.12248992919922, 0.984375\n",
      "Train loss and acc of batch 14: 48.12248229980469, 0.984375\n",
      "Train loss and acc of batch 15: 48.50141143798828, 0.984375\n",
      "Train loss and acc of batch 16: 48.50139617919922, 0.984375\n",
      "Train loss and acc of batch 17: 48.658912658691406, 0.984375\n",
      "Train loss and acc of batch 18: 48.787235260009766, 0.96875\n",
      "Train loss and acc of batch 19: 47.905670166015625, 1.0\n",
      "Train loss and acc of batch 20: 47.905662536621094, 1.0\n",
      "Train loss and acc of batch 21: 48.50135803222656, 0.984375\n",
      "Train loss and acc of batch 22: 48.50135040283203, 0.984375\n",
      "Train loss and acc of batch 23: 47.9056396484375, 1.0\n",
      "Train loss and acc of batch 24: 48.50132751464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.905616760253906, 1.0\n",
      "Train loss and acc of batch 26: 47.90561294555664, 1.0\n",
      "Train loss and acc of batch 27: 47.905601501464844, 1.0\n",
      "Train loss and acc of batch 28: 47.90559387207031, 1.0\n",
      "Train loss and acc of batch 29: 48.50128936767578, 0.984375\n",
      "Train loss and acc of batch 30: 47.90557861328125, 1.0\n",
      "Train loss and acc of batch 31: 48.12232971191406, 0.984375\n",
      "Train loss and acc of batch 32: 47.905555725097656, 1.0\n",
      "Train loss and acc of batch 33: 47.90554428100586, 1.0\n",
      "Train loss and acc of batch 34: 48.501243591308594, 0.984375\n",
      "Train loss and acc of batch 35: 48.33905792236328, 0.96875\n",
      "Train loss and acc of batch 36: 47.905521392822266, 1.0\n",
      "Train loss and acc of batch 37: 48.65873336791992, 0.984375\n",
      "Train loss and acc of batch 38: 49.254425048828125, 0.96875\n",
      "Train loss and acc of batch 39: 48.12225341796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.905487060546875, 1.0\n",
      "Train loss and acc of batch 41: 49.25440216064453, 0.96875\n",
      "Train loss and acc of batch 42: 47.90546798706055, 1.0\n",
      "Train loss and acc of batch 43: 48.50115966796875, 0.984375\n",
      "Train loss and acc of batch 44: 47.90545654296875, 1.0\n",
      "Train loss and acc of batch 45: 48.50114440917969, 0.984375\n",
      "Train loss and acc of batch 46: 48.19127655029297, 0.984375\n",
      "Train loss and acc of batch 47: 47.905418395996094, 1.0\n",
      "Train loss and acc of batch 48: 47.90541458129883, 1.0\n",
      "Train loss and acc of batch 49: 47.90540313720703, 1.0\n",
      "Train loss and acc of batch 50: 48.5010986328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.254310607910156, 0.96875\n",
      "Train loss and acc of batch 52: 49.161216735839844, 0.953125\n",
      "Train loss and acc of batch 53: 47.90536880493164, 1.0\n",
      "Train loss and acc of batch 54: 48.12212371826172, 0.984375\n",
      "Train loss and acc of batch 55: 47.90535354614258, 1.0\n",
      "Train loss and acc of batch 56: 47.90534210205078, 1.0\n",
      "Train loss and acc of batch 57: 48.50103759765625, 0.984375\n",
      "Train loss and acc of batch 58: 47.90532684326172, 1.0\n",
      "Train loss and acc of batch 59: 47.90531539916992, 1.0\n",
      "Train loss and acc of batch 60: 47.905303955078125, 1.0\n",
      "Train loss and acc of batch 61: 47.905296325683594, 1.0\n",
      "Train loss and acc of batch 62: 48.12205505371094, 0.984375\n",
      "Train loss and acc of batch 63: 49.096683502197266, 0.96875\n",
      "Train loss and acc of batch 64: 48.122032165527344, 0.984375\n",
      "Train loss and acc of batch 65: 47.90526580810547, 1.0\n",
      "Train loss and acc of batch 66: 47.90525436401367, 1.0\n",
      "Train loss and acc of batch 67: 48.71771240234375, 0.96875\n",
      "Train loss and acc of batch 68: 48.500938415527344, 0.984375\n",
      "Train loss and acc of batch 69: 48.121986389160156, 0.984375\n",
      "Train loss and acc of batch 70: 47.905216217041016, 1.0\n",
      "Training accuracy and loss of epoch #242: 0.9892, 48.2335\n",
      "Saved model by train loss 48.23349208563146\n",
      "Train loss and acc of batch 0: 47.90521240234375, 1.0\n",
      "Train loss and acc of batch 1: 47.90520095825195, 1.0\n",
      "Train loss and acc of batch 2: 48.19104766845703, 0.984375\n",
      "Train loss and acc of batch 3: 48.1219482421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.90517044067383, 1.0\n",
      "Train loss and acc of batch 5: 49.25408935546875, 0.96875\n",
      "Train loss and acc of batch 6: 48.40777587890625, 0.96875\n",
      "Train loss and acc of batch 7: 47.905147552490234, 1.0\n",
      "Train loss and acc of batch 8: 48.50083923339844, 0.984375\n",
      "Train loss and acc of batch 9: 48.19097900390625, 0.984375\n",
      "Train loss and acc of batch 10: 47.905120849609375, 1.0\n",
      "Train loss and acc of batch 11: 47.90510940551758, 1.0\n",
      "Train loss and acc of batch 12: 48.6583251953125, 0.984375\n",
      "Train loss and acc of batch 13: 48.121856689453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.121849060058594, 0.984375\n",
      "Train loss and acc of batch 15: 48.50077819824219, 0.984375\n",
      "Train loss and acc of batch 16: 48.500770568847656, 0.984375\n",
      "Train loss and acc of batch 17: 48.65828323364258, 0.984375\n",
      "Train loss and acc of batch 18: 48.786598205566406, 0.96875\n",
      "Train loss and acc of batch 19: 47.9050407409668, 1.0\n",
      "Train loss and acc of batch 20: 47.905029296875, 1.0\n",
      "Train loss and acc of batch 21: 48.50071716308594, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 22: 48.50071716308594, 0.984375\n",
      "Train loss and acc of batch 23: 47.905006408691406, 1.0\n",
      "Train loss and acc of batch 24: 48.500694274902344, 0.984375\n",
      "Train loss and acc of batch 25: 47.90498733520508, 1.0\n",
      "Train loss and acc of batch 26: 47.904972076416016, 1.0\n",
      "Train loss and acc of batch 27: 47.90496826171875, 1.0\n",
      "Train loss and acc of batch 28: 47.90496063232422, 1.0\n",
      "Train loss and acc of batch 29: 48.50065612792969, 0.984375\n",
      "Train loss and acc of batch 30: 47.90494155883789, 1.0\n",
      "Train loss and acc of batch 31: 48.1217041015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.90492248535156, 1.0\n",
      "Train loss and acc of batch 33: 47.90491485595703, 1.0\n",
      "Train loss and acc of batch 34: 48.50060272216797, 0.984375\n",
      "Train loss and acc of batch 35: 48.33842468261719, 0.96875\n",
      "Train loss and acc of batch 36: 47.90488815307617, 1.0\n",
      "Train loss and acc of batch 37: 48.65810012817383, 0.984375\n",
      "Train loss and acc of batch 38: 49.25379180908203, 0.96875\n",
      "Train loss and acc of batch 39: 48.12162780761719, 0.984375\n",
      "Train loss and acc of batch 40: 47.904850006103516, 1.0\n",
      "Train loss and acc of batch 41: 49.25376892089844, 0.96875\n",
      "Train loss and acc of batch 42: 47.90483474731445, 1.0\n",
      "Train loss and acc of batch 43: 48.500526428222656, 0.984375\n",
      "Train loss and acc of batch 44: 47.904815673828125, 1.0\n",
      "Train loss and acc of batch 45: 48.500511169433594, 0.984375\n",
      "Train loss and acc of batch 46: 48.190650939941406, 0.984375\n",
      "Train loss and acc of batch 47: 47.904788970947266, 1.0\n",
      "Train loss and acc of batch 48: 47.90477752685547, 1.0\n",
      "Train loss and acc of batch 49: 47.90476608276367, 1.0\n",
      "Train loss and acc of batch 50: 48.500465393066406, 0.984375\n",
      "Train loss and acc of batch 51: 49.25367736816406, 0.96875\n",
      "Train loss and acc of batch 52: 49.160587310791016, 0.953125\n",
      "Train loss and acc of batch 53: 47.90473937988281, 1.0\n",
      "Train loss and acc of batch 54: 48.121490478515625, 0.984375\n",
      "Train loss and acc of batch 55: 47.90471649169922, 1.0\n",
      "Train loss and acc of batch 56: 47.90471267700195, 1.0\n",
      "Train loss and acc of batch 57: 48.500404357910156, 0.984375\n",
      "Train loss and acc of batch 58: 47.904693603515625, 1.0\n",
      "Train loss and acc of batch 59: 47.90467834472656, 1.0\n",
      "Train loss and acc of batch 60: 47.90467834472656, 1.0\n",
      "Train loss and acc of batch 61: 47.90467071533203, 1.0\n",
      "Train loss and acc of batch 62: 48.121421813964844, 0.984375\n",
      "Train loss and acc of batch 63: 49.096046447753906, 0.96875\n",
      "Train loss and acc of batch 64: 48.12139892578125, 0.984375\n",
      "Train loss and acc of batch 65: 47.90462875366211, 1.0\n",
      "Train loss and acc of batch 66: 47.90462112426758, 1.0\n",
      "Train loss and acc of batch 67: 48.717079162597656, 0.96875\n",
      "Train loss and acc of batch 68: 48.50030517578125, 0.984375\n",
      "Train loss and acc of batch 69: 48.121360778808594, 0.984375\n",
      "Train loss and acc of batch 70: 47.90458297729492, 1.0\n",
      "Training accuracy and loss of epoch #243: 0.9892, 48.2329\n",
      "Saved model by train loss 48.232859436894806\n",
      "Train loss and acc of batch 0: 47.90457534790039, 1.0\n",
      "Train loss and acc of batch 1: 47.90456771850586, 1.0\n",
      "Train loss and acc of batch 2: 48.190406799316406, 0.984375\n",
      "Train loss and acc of batch 3: 48.121315002441406, 0.984375\n",
      "Train loss and acc of batch 4: 47.904541015625, 1.0\n",
      "Train loss and acc of batch 5: 49.253456115722656, 0.96875\n",
      "Train loss and acc of batch 6: 48.40713882446289, 0.96875\n",
      "Train loss and acc of batch 7: 47.904510498046875, 1.0\n",
      "Train loss and acc of batch 8: 48.500205993652344, 0.984375\n",
      "Train loss and acc of batch 9: 48.190345764160156, 0.984375\n",
      "Train loss and acc of batch 10: 47.90448760986328, 1.0\n",
      "Train loss and acc of batch 11: 47.904476165771484, 1.0\n",
      "Train loss and acc of batch 12: 48.65769577026367, 0.984375\n",
      "Train loss and acc of batch 13: 48.12122344970703, 0.984375\n",
      "Train loss and acc of batch 14: 48.1212158203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.500144958496094, 0.984375\n",
      "Train loss and acc of batch 16: 48.50013732910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.657649993896484, 0.984375\n",
      "Train loss and acc of batch 18: 48.785972595214844, 0.96875\n",
      "Train loss and acc of batch 19: 47.9044075012207, 1.0\n",
      "Train loss and acc of batch 20: 47.904396057128906, 1.0\n",
      "Train loss and acc of batch 21: 48.500083923339844, 0.984375\n",
      "Train loss and acc of batch 22: 48.500083923339844, 0.984375\n",
      "Train loss and acc of batch 23: 47.90436935424805, 1.0\n",
      "Train loss and acc of batch 24: 48.50006866455078, 0.984375\n",
      "Train loss and acc of batch 25: 47.90435791015625, 1.0\n",
      "Train loss and acc of batch 26: 47.90434646606445, 1.0\n",
      "Train loss and acc of batch 27: 47.90433883666992, 1.0\n",
      "Train loss and acc of batch 28: 47.904327392578125, 1.0\n",
      "Train loss and acc of batch 29: 48.500022888183594, 0.984375\n",
      "Train loss and acc of batch 30: 47.9043083190918, 1.0\n",
      "Train loss and acc of batch 31: 48.121070861816406, 0.984375\n",
      "Train loss and acc of batch 32: 47.90428924560547, 1.0\n",
      "Train loss and acc of batch 33: 47.90428161621094, 1.0\n",
      "Train loss and acc of batch 34: 48.499977111816406, 0.984375\n",
      "Train loss and acc of batch 35: 48.337791442871094, 0.96875\n",
      "Train loss and acc of batch 36: 47.904258728027344, 1.0\n",
      "Train loss and acc of batch 37: 48.657470703125, 0.984375\n",
      "Train loss and acc of batch 38: 49.25316619873047, 0.96875\n",
      "Train loss and acc of batch 39: 48.120994567871094, 0.984375\n",
      "Train loss and acc of batch 40: 47.90422058105469, 1.0\n",
      "Train loss and acc of batch 41: 49.25313949584961, 0.96875\n",
      "Train loss and acc of batch 42: 47.904205322265625, 1.0\n",
      "Train loss and acc of batch 43: 48.49989318847656, 0.984375\n",
      "Train loss and acc of batch 44: 47.90418243408203, 1.0\n",
      "Train loss and acc of batch 45: 48.4998779296875, 0.984375\n",
      "Train loss and acc of batch 46: 48.19001770019531, 0.984375\n",
      "Train loss and acc of batch 47: 47.90415954589844, 1.0\n",
      "Train loss and acc of batch 48: 47.90414810180664, 1.0\n",
      "Train loss and acc of batch 49: 47.90414047241211, 1.0\n",
      "Train loss and acc of batch 50: 48.49983215332031, 0.984375\n",
      "Train loss and acc of batch 51: 49.25304412841797, 0.96875\n",
      "Train loss and acc of batch 52: 49.15995407104492, 0.953125\n",
      "Train loss and acc of batch 53: 47.90410614013672, 1.0\n",
      "Train loss and acc of batch 54: 48.12085723876953, 0.984375\n",
      "Train loss and acc of batch 55: 47.904090881347656, 1.0\n",
      "Train loss and acc of batch 56: 47.904075622558594, 1.0\n",
      "Train loss and acc of batch 57: 48.49977111816406, 0.984375\n",
      "Train loss and acc of batch 58: 47.904056549072266, 1.0\n",
      "Train loss and acc of batch 59: 47.904052734375, 1.0\n",
      "Train loss and acc of batch 60: 47.9040412902832, 1.0\n",
      "Train loss and acc of batch 61: 47.90403366088867, 1.0\n",
      "Train loss and acc of batch 62: 48.12078857421875, 0.984375\n",
      "Train loss and acc of batch 63: 49.09541702270508, 0.96875\n",
      "Train loss and acc of batch 64: 48.12077331542969, 0.984375\n",
      "Train loss and acc of batch 65: 47.903995513916016, 1.0\n",
      "Train loss and acc of batch 66: 47.903987884521484, 1.0\n",
      "Train loss and acc of batch 67: 48.7164421081543, 0.96875\n",
      "Train loss and acc of batch 68: 48.499671936035156, 0.984375\n",
      "Train loss and acc of batch 69: 48.1207275390625, 0.984375\n",
      "Train loss and acc of batch 70: 47.90395736694336, 1.0\n",
      "Training accuracy and loss of epoch #244: 0.9892, 48.2322\n",
      "Saved model by train loss 48.23222732543945\n",
      "Train loss and acc of batch 0: 47.90394592285156, 1.0\n",
      "Train loss and acc of batch 1: 47.903934478759766, 1.0\n",
      "Train loss and acc of batch 2: 48.18977355957031, 0.984375\n",
      "Train loss and acc of batch 3: 48.12068176269531, 0.984375\n",
      "Train loss and acc of batch 4: 47.90391159057617, 1.0\n",
      "Train loss and acc of batch 5: 49.25282287597656, 0.96875\n",
      "Train loss and acc of batch 6: 48.4065055847168, 0.96875\n",
      "Train loss and acc of batch 7: 47.90388107299805, 1.0\n",
      "Train loss and acc of batch 8: 48.49957275390625, 0.984375\n",
      "Train loss and acc of batch 9: 48.189720153808594, 0.984375\n",
      "Train loss and acc of batch 10: 47.90385818481445, 1.0\n",
      "Train loss and acc of batch 11: 47.903846740722656, 1.0\n",
      "Train loss and acc of batch 12: 48.65706253051758, 0.984375\n",
      "Train loss and acc of batch 13: 48.12059783935547, 0.984375\n",
      "Train loss and acc of batch 14: 48.120582580566406, 0.984375\n",
      "Train loss and acc of batch 15: 48.49951171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.49950408935547, 0.984375\n",
      "Train loss and acc of batch 17: 48.657012939453125, 0.984375\n",
      "Train loss and acc of batch 18: 48.785335540771484, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 19: 47.90377426147461, 1.0\n",
      "Train loss and acc of batch 20: 47.90376281738281, 1.0\n",
      "Train loss and acc of batch 21: 48.49945831298828, 0.984375\n",
      "Train loss and acc of batch 22: 48.49945068359375, 0.984375\n",
      "Train loss and acc of batch 23: 47.90373992919922, 1.0\n",
      "Train loss and acc of batch 24: 48.499427795410156, 0.984375\n",
      "Train loss and acc of batch 25: 47.90372085571289, 1.0\n",
      "Train loss and acc of batch 26: 47.90371322631836, 1.0\n",
      "Train loss and acc of batch 27: 47.903709411621094, 1.0\n",
      "Train loss and acc of batch 28: 47.90369415283203, 1.0\n",
      "Train loss and acc of batch 29: 48.4993896484375, 0.984375\n",
      "Train loss and acc of batch 30: 47.9036750793457, 1.0\n",
      "Train loss and acc of batch 31: 48.12042999267578, 0.984375\n",
      "Train loss and acc of batch 32: 47.90365982055664, 1.0\n",
      "Train loss and acc of batch 33: 47.903648376464844, 1.0\n",
      "Train loss and acc of batch 34: 48.49934387207031, 0.984375\n",
      "Train loss and acc of batch 35: 48.33716583251953, 0.96875\n",
      "Train loss and acc of batch 36: 47.903621673583984, 1.0\n",
      "Train loss and acc of batch 37: 48.656837463378906, 0.984375\n",
      "Train loss and acc of batch 38: 49.252532958984375, 0.96875\n",
      "Train loss and acc of batch 39: 48.120361328125, 0.984375\n",
      "Train loss and acc of batch 40: 47.90359115600586, 1.0\n",
      "Train loss and acc of batch 41: 49.252506256103516, 0.96875\n",
      "Train loss and acc of batch 42: 47.90357208251953, 1.0\n",
      "Train loss and acc of batch 43: 48.49925994873047, 0.984375\n",
      "Train loss and acc of batch 44: 47.9035530090332, 1.0\n",
      "Train loss and acc of batch 45: 48.499244689941406, 0.984375\n",
      "Train loss and acc of batch 46: 48.18939208984375, 0.984375\n",
      "Train loss and acc of batch 47: 47.90352249145508, 1.0\n",
      "Train loss and acc of batch 48: 47.90351486206055, 1.0\n",
      "Train loss and acc of batch 49: 47.903507232666016, 1.0\n",
      "Train loss and acc of batch 50: 48.49919891357422, 0.984375\n",
      "Train loss and acc of batch 51: 49.252410888671875, 0.96875\n",
      "Train loss and acc of batch 52: 49.15931701660156, 0.953125\n",
      "Train loss and acc of batch 53: 47.90346908569336, 1.0\n",
      "Train loss and acc of batch 54: 48.12023162841797, 0.984375\n",
      "Train loss and acc of batch 55: 47.90345764160156, 1.0\n",
      "Train loss and acc of batch 56: 47.903446197509766, 1.0\n",
      "Train loss and acc of batch 57: 48.49913787841797, 0.984375\n",
      "Train loss and acc of batch 58: 47.90342712402344, 1.0\n",
      "Train loss and acc of batch 59: 47.90341567993164, 1.0\n",
      "Train loss and acc of batch 60: 47.90341567993164, 1.0\n",
      "Train loss and acc of batch 61: 47.90340042114258, 1.0\n",
      "Train loss and acc of batch 62: 48.120155334472656, 0.984375\n",
      "Train loss and acc of batch 63: 49.094783782958984, 0.96875\n",
      "Train loss and acc of batch 64: 48.12013244628906, 0.984375\n",
      "Train loss and acc of batch 65: 47.90336608886719, 1.0\n",
      "Train loss and acc of batch 66: 47.90335464477539, 1.0\n",
      "Train loss and acc of batch 67: 48.71581268310547, 0.96875\n",
      "Train loss and acc of batch 68: 48.49903869628906, 0.984375\n",
      "Train loss and acc of batch 69: 48.120094299316406, 0.984375\n",
      "Train loss and acc of batch 70: 47.9033203125, 1.0\n",
      "Training accuracy and loss of epoch #245: 0.9892, 48.2316\n",
      "Saved model by train loss 48.23159478415906\n",
      "Train loss and acc of batch 0: 47.90331268310547, 1.0\n",
      "Train loss and acc of batch 1: 47.90330123901367, 1.0\n",
      "Train loss and acc of batch 2: 48.18914794921875, 0.984375\n",
      "Train loss and acc of batch 3: 48.12004852294922, 0.984375\n",
      "Train loss and acc of batch 4: 47.90327453613281, 1.0\n",
      "Train loss and acc of batch 5: 49.25218963623047, 0.96875\n",
      "Train loss and acc of batch 6: 48.40587615966797, 0.96875\n",
      "Train loss and acc of batch 7: 47.90324783325195, 1.0\n",
      "Train loss and acc of batch 8: 48.498939514160156, 0.984375\n",
      "Train loss and acc of batch 9: 48.18907928466797, 0.984375\n",
      "Train loss and acc of batch 10: 47.903221130371094, 1.0\n",
      "Train loss and acc of batch 11: 47.90321350097656, 1.0\n",
      "Train loss and acc of batch 12: 48.656429290771484, 0.984375\n",
      "Train loss and acc of batch 13: 48.119956970214844, 0.984375\n",
      "Train loss and acc of batch 14: 48.119956970214844, 0.984375\n",
      "Train loss and acc of batch 15: 48.498878479003906, 0.984375\n",
      "Train loss and acc of batch 16: 48.498870849609375, 0.984375\n",
      "Train loss and acc of batch 17: 48.6563835144043, 0.984375\n",
      "Train loss and acc of batch 18: 48.78470230102539, 0.96875\n",
      "Train loss and acc of batch 19: 47.903141021728516, 1.0\n",
      "Train loss and acc of batch 20: 47.903133392333984, 1.0\n",
      "Train loss and acc of batch 21: 48.49882507324219, 0.984375\n",
      "Train loss and acc of batch 22: 48.498817443847656, 0.984375\n",
      "Train loss and acc of batch 23: 47.903106689453125, 1.0\n",
      "Train loss and acc of batch 24: 48.49879455566406, 0.984375\n",
      "Train loss and acc of batch 25: 47.9030876159668, 1.0\n",
      "Train loss and acc of batch 26: 47.903079986572266, 1.0\n",
      "Train loss and acc of batch 27: 47.903072357177734, 1.0\n",
      "Train loss and acc of batch 28: 47.9030647277832, 1.0\n",
      "Train loss and acc of batch 29: 48.498756408691406, 0.984375\n",
      "Train loss and acc of batch 30: 47.90304183959961, 1.0\n",
      "Train loss and acc of batch 31: 48.11980438232422, 0.984375\n",
      "Train loss and acc of batch 32: 47.903018951416016, 1.0\n",
      "Train loss and acc of batch 33: 47.90301513671875, 1.0\n",
      "Train loss and acc of batch 34: 48.49871063232422, 0.984375\n",
      "Train loss and acc of batch 35: 48.33652877807617, 0.96875\n",
      "Train loss and acc of batch 36: 47.902992248535156, 1.0\n",
      "Train loss and acc of batch 37: 48.65620040893555, 0.984375\n",
      "Train loss and acc of batch 38: 49.25189208984375, 0.96875\n",
      "Train loss and acc of batch 39: 48.119728088378906, 0.984375\n",
      "Train loss and acc of batch 40: 47.9029541015625, 1.0\n",
      "Train loss and acc of batch 41: 49.25187301635742, 0.96875\n",
      "Train loss and acc of batch 42: 47.90293884277344, 1.0\n",
      "Train loss and acc of batch 43: 48.498634338378906, 0.984375\n",
      "Train loss and acc of batch 44: 47.90291976928711, 1.0\n",
      "Train loss and acc of batch 45: 48.498619079589844, 0.984375\n",
      "Train loss and acc of batch 46: 48.188751220703125, 0.984375\n",
      "Train loss and acc of batch 47: 47.90288543701172, 1.0\n",
      "Train loss and acc of batch 48: 47.90288162231445, 1.0\n",
      "Train loss and acc of batch 49: 47.902870178222656, 1.0\n",
      "Train loss and acc of batch 50: 48.498565673828125, 0.984375\n",
      "Train loss and acc of batch 51: 49.25177764892578, 0.96875\n",
      "Train loss and acc of batch 52: 49.1586799621582, 0.953125\n",
      "Train loss and acc of batch 53: 47.902835845947266, 1.0\n",
      "Train loss and acc of batch 54: 48.119590759277344, 0.984375\n",
      "Train loss and acc of batch 55: 47.90281677246094, 1.0\n",
      "Train loss and acc of batch 56: 47.90281295776367, 1.0\n",
      "Train loss and acc of batch 57: 48.498504638671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.902793884277344, 1.0\n",
      "Train loss and acc of batch 59: 47.90278625488281, 1.0\n",
      "Train loss and acc of batch 60: 47.902767181396484, 1.0\n",
      "Train loss and acc of batch 61: 47.90275955200195, 1.0\n",
      "Train loss and acc of batch 62: 48.11952209472656, 0.984375\n",
      "Train loss and acc of batch 63: 49.094146728515625, 0.96875\n",
      "Train loss and acc of batch 64: 48.1195068359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.902732849121094, 1.0\n",
      "Train loss and acc of batch 66: 47.90271759033203, 1.0\n",
      "Train loss and acc of batch 67: 48.71517562866211, 0.96875\n",
      "Train loss and acc of batch 68: 48.49840545654297, 0.984375\n",
      "Train loss and acc of batch 69: 48.11945343017578, 0.984375\n",
      "Train loss and acc of batch 70: 47.902687072753906, 1.0\n",
      "Training accuracy and loss of epoch #246: 0.9892, 48.2310\n",
      "Saved model by train loss 48.23096068476288\n",
      "Train loss and acc of batch 0: 47.90267562866211, 1.0\n",
      "Train loss and acc of batch 1: 47.90266799926758, 1.0\n",
      "Train loss and acc of batch 2: 48.188514709472656, 0.984375\n",
      "Train loss and acc of batch 3: 48.119415283203125, 0.984375\n",
      "Train loss and acc of batch 4: 47.90263748168945, 1.0\n",
      "Train loss and acc of batch 5: 49.251556396484375, 0.96875\n",
      "Train loss and acc of batch 6: 48.40523910522461, 0.96875\n",
      "Train loss and acc of batch 7: 47.90261459350586, 1.0\n",
      "Train loss and acc of batch 8: 48.49830627441406, 0.984375\n",
      "Train loss and acc of batch 9: 48.188446044921875, 0.984375\n",
      "Train loss and acc of batch 10: 47.902587890625, 1.0\n",
      "Train loss and acc of batch 11: 47.9025764465332, 1.0\n",
      "Train loss and acc of batch 12: 48.655792236328125, 0.984375\n",
      "Train loss and acc of batch 13: 48.11932373046875, 0.984375\n",
      "Train loss and acc of batch 14: 48.11931610107422, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 15: 48.49824523925781, 0.984375\n",
      "Train loss and acc of batch 16: 48.49823760986328, 0.984375\n",
      "Train loss and acc of batch 17: 48.65574645996094, 0.984375\n",
      "Train loss and acc of batch 18: 48.7840690612793, 0.96875\n",
      "Train loss and acc of batch 19: 47.902503967285156, 1.0\n",
      "Train loss and acc of batch 20: 47.902496337890625, 1.0\n",
      "Train loss and acc of batch 21: 48.498191833496094, 0.984375\n",
      "Train loss and acc of batch 22: 48.49817657470703, 0.984375\n",
      "Train loss and acc of batch 23: 47.902469635009766, 1.0\n",
      "Train loss and acc of batch 24: 48.49816131591797, 0.984375\n",
      "Train loss and acc of batch 25: 47.90245056152344, 1.0\n",
      "Train loss and acc of batch 26: 47.902442932128906, 1.0\n",
      "Train loss and acc of batch 27: 47.902435302734375, 1.0\n",
      "Train loss and acc of batch 28: 47.902427673339844, 1.0\n",
      "Train loss and acc of batch 29: 48.49811553955078, 0.984375\n",
      "Train loss and acc of batch 30: 47.90241622924805, 1.0\n",
      "Train loss and acc of batch 31: 48.119163513183594, 0.984375\n",
      "Train loss and acc of batch 32: 47.90238571166992, 1.0\n",
      "Train loss and acc of batch 33: 47.902381896972656, 1.0\n",
      "Train loss and acc of batch 34: 48.498069763183594, 0.984375\n",
      "Train loss and acc of batch 35: 48.33589172363281, 0.96875\n",
      "Train loss and acc of batch 36: 47.9023551940918, 1.0\n",
      "Train loss and acc of batch 37: 48.65557098388672, 0.984375\n",
      "Train loss and acc of batch 38: 49.251258850097656, 0.96875\n",
      "Train loss and acc of batch 39: 48.11909484863281, 0.984375\n",
      "Train loss and acc of batch 40: 47.90231704711914, 1.0\n",
      "Train loss and acc of batch 41: 49.25123596191406, 0.96875\n",
      "Train loss and acc of batch 42: 47.90230178833008, 1.0\n",
      "Train loss and acc of batch 43: 48.49799346923828, 0.984375\n",
      "Train loss and acc of batch 44: 47.90229034423828, 1.0\n",
      "Train loss and acc of batch 45: 48.49797821044922, 0.984375\n",
      "Train loss and acc of batch 46: 48.18811798095703, 0.984375\n",
      "Train loss and acc of batch 47: 47.90225601196289, 1.0\n",
      "Train loss and acc of batch 48: 47.902244567871094, 1.0\n",
      "Train loss and acc of batch 49: 47.90224075317383, 1.0\n",
      "Train loss and acc of batch 50: 48.4979248046875, 0.984375\n",
      "Train loss and acc of batch 51: 49.25114440917969, 0.96875\n",
      "Train loss and acc of batch 52: 49.15805435180664, 0.953125\n",
      "Train loss and acc of batch 53: 47.90220642089844, 1.0\n",
      "Train loss and acc of batch 54: 48.11895751953125, 0.984375\n",
      "Train loss and acc of batch 55: 47.90218734741211, 1.0\n",
      "Train loss and acc of batch 56: 47.90217590332031, 1.0\n",
      "Train loss and acc of batch 57: 48.49787139892578, 0.984375\n",
      "Train loss and acc of batch 58: 47.90216064453125, 1.0\n",
      "Train loss and acc of batch 59: 47.90215301513672, 1.0\n",
      "Train loss and acc of batch 60: 47.90214157104492, 1.0\n",
      "Train loss and acc of batch 61: 47.90213394165039, 1.0\n",
      "Train loss and acc of batch 62: 48.11888885498047, 0.984375\n",
      "Train loss and acc of batch 63: 49.0935173034668, 0.96875\n",
      "Train loss and acc of batch 64: 48.118865966796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.902095794677734, 1.0\n",
      "Train loss and acc of batch 66: 47.9020881652832, 1.0\n",
      "Train loss and acc of batch 67: 48.71454620361328, 0.96875\n",
      "Train loss and acc of batch 68: 48.497764587402344, 0.984375\n",
      "Train loss and acc of batch 69: 48.11882781982422, 0.984375\n",
      "Train loss and acc of batch 70: 47.90205001831055, 1.0\n",
      "Training accuracy and loss of epoch #247: 0.9892, 48.2303\n",
      "Saved model by train loss 48.230326209269776\n",
      "Train loss and acc of batch 0: 47.902042388916016, 1.0\n",
      "Train loss and acc of batch 1: 47.902034759521484, 1.0\n",
      "Train loss and acc of batch 2: 48.18788146972656, 0.984375\n",
      "Train loss and acc of batch 3: 48.11878204345703, 0.984375\n",
      "Train loss and acc of batch 4: 47.90201187133789, 1.0\n",
      "Train loss and acc of batch 5: 49.25092315673828, 0.96875\n",
      "Train loss and acc of batch 6: 48.404605865478516, 0.96875\n",
      "Train loss and acc of batch 7: 47.9019775390625, 1.0\n",
      "Train loss and acc of batch 8: 48.49767303466797, 0.984375\n",
      "Train loss and acc of batch 9: 48.18782043457031, 0.984375\n",
      "Train loss and acc of batch 10: 47.901954650878906, 1.0\n",
      "Train loss and acc of batch 11: 47.901939392089844, 1.0\n",
      "Train loss and acc of batch 12: 48.655155181884766, 0.984375\n",
      "Train loss and acc of batch 13: 48.118690490722656, 0.984375\n",
      "Train loss and acc of batch 14: 48.118682861328125, 0.984375\n",
      "Train loss and acc of batch 15: 48.49761199951172, 0.984375\n",
      "Train loss and acc of batch 16: 48.49760437011719, 0.984375\n",
      "Train loss and acc of batch 17: 48.65511703491211, 0.984375\n",
      "Train loss and acc of batch 18: 48.78343963623047, 0.96875\n",
      "Train loss and acc of batch 19: 47.90187454223633, 1.0\n",
      "Train loss and acc of batch 20: 47.90186309814453, 1.0\n",
      "Train loss and acc of batch 21: 48.49755859375, 0.984375\n",
      "Train loss and acc of batch 22: 48.49754333496094, 0.984375\n",
      "Train loss and acc of batch 23: 47.90184020996094, 1.0\n",
      "Train loss and acc of batch 24: 48.497528076171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.901817321777344, 1.0\n",
      "Train loss and acc of batch 26: 47.90180969238281, 1.0\n",
      "Train loss and acc of batch 27: 47.90180206298828, 1.0\n",
      "Train loss and acc of batch 28: 47.90179443359375, 1.0\n",
      "Train loss and acc of batch 29: 48.49748992919922, 0.984375\n",
      "Train loss and acc of batch 30: 47.90177536010742, 1.0\n",
      "Train loss and acc of batch 31: 48.1185302734375, 0.984375\n",
      "Train loss and acc of batch 32: 47.90176010131836, 1.0\n",
      "Train loss and acc of batch 33: 47.90174865722656, 1.0\n",
      "Train loss and acc of batch 34: 48.49744415283203, 0.984375\n",
      "Train loss and acc of batch 35: 48.33525466918945, 0.96875\n",
      "Train loss and acc of batch 36: 47.9017219543457, 1.0\n",
      "Train loss and acc of batch 37: 48.65494155883789, 0.984375\n",
      "Train loss and acc of batch 38: 49.250633239746094, 0.96875\n",
      "Train loss and acc of batch 39: 48.11846160888672, 0.984375\n",
      "Train loss and acc of batch 40: 47.90168762207031, 1.0\n",
      "Train loss and acc of batch 41: 49.25060272216797, 0.96875\n",
      "Train loss and acc of batch 42: 47.90167236328125, 1.0\n",
      "Train loss and acc of batch 43: 48.497352600097656, 0.984375\n",
      "Train loss and acc of batch 44: 47.90165328979492, 1.0\n",
      "Train loss and acc of batch 45: 48.497344970703125, 0.984375\n",
      "Train loss and acc of batch 46: 48.18749237060547, 0.984375\n",
      "Train loss and acc of batch 47: 47.9016227722168, 1.0\n",
      "Train loss and acc of batch 48: 47.901615142822266, 1.0\n",
      "Train loss and acc of batch 49: 47.90160369873047, 1.0\n",
      "Train loss and acc of batch 50: 48.49729919433594, 0.984375\n",
      "Train loss and acc of batch 51: 49.250518798828125, 0.96875\n",
      "Train loss and acc of batch 52: 49.15741729736328, 0.953125\n",
      "Train loss and acc of batch 53: 47.90156936645508, 1.0\n",
      "Train loss and acc of batch 54: 48.118324279785156, 0.984375\n",
      "Train loss and acc of batch 55: 47.90155029296875, 1.0\n",
      "Train loss and acc of batch 56: 47.90154266357422, 1.0\n",
      "Train loss and acc of batch 57: 48.49723815917969, 0.984375\n",
      "Train loss and acc of batch 58: 47.901527404785156, 1.0\n",
      "Train loss and acc of batch 59: 47.90151596069336, 1.0\n",
      "Train loss and acc of batch 60: 47.90150833129883, 1.0\n",
      "Train loss and acc of batch 61: 47.90149688720703, 1.0\n",
      "Train loss and acc of batch 62: 48.118255615234375, 0.984375\n",
      "Train loss and acc of batch 63: 49.0928840637207, 0.96875\n",
      "Train loss and acc of batch 64: 48.11823272705078, 0.984375\n",
      "Train loss and acc of batch 65: 47.90146255493164, 1.0\n",
      "Train loss and acc of batch 66: 47.901458740234375, 1.0\n",
      "Train loss and acc of batch 67: 48.71391296386719, 0.96875\n",
      "Train loss and acc of batch 68: 48.49713897705078, 0.984375\n",
      "Train loss and acc of batch 69: 48.118194580078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.90141677856445, 1.0\n",
      "Training accuracy and loss of epoch #248: 0.9892, 48.2297\n",
      "Saved model by train loss 48.22969372171751\n",
      "Train loss and acc of batch 0: 47.90141296386719, 1.0\n",
      "Train loss and acc of batch 1: 47.90140151977539, 1.0\n",
      "Train loss and acc of batch 2: 48.18724822998047, 0.984375\n",
      "Train loss and acc of batch 3: 48.11814880371094, 0.984375\n",
      "Train loss and acc of batch 4: 47.90137481689453, 1.0\n",
      "Train loss and acc of batch 5: 49.25028991699219, 0.96875\n",
      "Train loss and acc of batch 6: 48.40397262573242, 0.96875\n",
      "Train loss and acc of batch 7: 47.901344299316406, 1.0\n",
      "Train loss and acc of batch 8: 48.497047424316406, 0.984375\n",
      "Train loss and acc of batch 9: 48.18717956542969, 0.984375\n",
      "Train loss and acc of batch 10: 47.90132141113281, 1.0\n",
      "Train loss and acc of batch 11: 47.90131378173828, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 12: 48.6545295715332, 0.984375\n",
      "Train loss and acc of batch 13: 48.11805725097656, 0.984375\n",
      "Train loss and acc of batch 14: 48.11804962158203, 0.984375\n",
      "Train loss and acc of batch 15: 48.496978759765625, 0.984375\n",
      "Train loss and acc of batch 16: 48.496971130371094, 0.984375\n",
      "Train loss and acc of batch 17: 48.65448760986328, 0.984375\n",
      "Train loss and acc of batch 18: 48.78280258178711, 0.96875\n",
      "Train loss and acc of batch 19: 47.901241302490234, 1.0\n",
      "Train loss and acc of batch 20: 47.90122985839844, 1.0\n",
      "Train loss and acc of batch 21: 48.496925354003906, 0.984375\n",
      "Train loss and acc of batch 22: 48.496917724609375, 0.984375\n",
      "Train loss and acc of batch 23: 47.90120315551758, 1.0\n",
      "Train loss and acc of batch 24: 48.49689483642578, 0.984375\n",
      "Train loss and acc of batch 25: 47.90119171142578, 1.0\n",
      "Train loss and acc of batch 26: 47.901180267333984, 1.0\n",
      "Train loss and acc of batch 27: 47.90116882324219, 1.0\n",
      "Train loss and acc of batch 28: 47.901161193847656, 1.0\n",
      "Train loss and acc of batch 29: 48.496849060058594, 0.984375\n",
      "Train loss and acc of batch 30: 47.901145935058594, 1.0\n",
      "Train loss and acc of batch 31: 48.117897033691406, 0.984375\n",
      "Train loss and acc of batch 32: 47.901123046875, 1.0\n",
      "Train loss and acc of batch 33: 47.901119232177734, 1.0\n",
      "Train loss and acc of batch 34: 48.496803283691406, 0.984375\n",
      "Train loss and acc of batch 35: 48.334625244140625, 0.96875\n",
      "Train loss and acc of batch 36: 47.901092529296875, 1.0\n",
      "Train loss and acc of batch 37: 48.654300689697266, 0.984375\n",
      "Train loss and acc of batch 38: 49.24999237060547, 0.96875\n",
      "Train loss and acc of batch 39: 48.117828369140625, 0.984375\n",
      "Train loss and acc of batch 40: 47.90105438232422, 1.0\n",
      "Train loss and acc of batch 41: 49.249977111816406, 0.96875\n",
      "Train loss and acc of batch 42: 47.901031494140625, 1.0\n",
      "Train loss and acc of batch 43: 48.496726989746094, 0.984375\n",
      "Train loss and acc of batch 44: 47.90102005004883, 1.0\n",
      "Train loss and acc of batch 45: 48.49671173095703, 0.984375\n",
      "Train loss and acc of batch 46: 48.186851501464844, 0.984375\n",
      "Train loss and acc of batch 47: 47.90099334716797, 1.0\n",
      "Train loss and acc of batch 48: 47.90098190307617, 1.0\n",
      "Train loss and acc of batch 49: 47.900970458984375, 1.0\n",
      "Train loss and acc of batch 50: 48.496665954589844, 0.984375\n",
      "Train loss and acc of batch 51: 49.2498779296875, 0.96875\n",
      "Train loss and acc of batch 52: 49.15678787231445, 0.953125\n",
      "Train loss and acc of batch 53: 47.900943756103516, 1.0\n",
      "Train loss and acc of batch 54: 48.11769104003906, 0.984375\n",
      "Train loss and acc of batch 55: 47.90092468261719, 1.0\n",
      "Train loss and acc of batch 56: 47.900909423828125, 1.0\n",
      "Train loss and acc of batch 57: 48.49659729003906, 0.984375\n",
      "Train loss and acc of batch 58: 47.90089416503906, 1.0\n",
      "Train loss and acc of batch 59: 47.900882720947266, 1.0\n",
      "Train loss and acc of batch 60: 47.900875091552734, 1.0\n",
      "Train loss and acc of batch 61: 47.9008674621582, 1.0\n",
      "Train loss and acc of batch 62: 48.11762237548828, 0.984375\n",
      "Train loss and acc of batch 63: 49.09225082397461, 0.96875\n",
      "Train loss and acc of batch 64: 48.11760711669922, 0.984375\n",
      "Train loss and acc of batch 65: 47.90082550048828, 1.0\n",
      "Train loss and acc of batch 66: 47.900821685791016, 1.0\n",
      "Train loss and acc of batch 67: 48.713279724121094, 0.96875\n",
      "Train loss and acc of batch 68: 48.49650573730469, 0.984375\n",
      "Train loss and acc of batch 69: 48.11756134033203, 0.984375\n",
      "Train loss and acc of batch 70: 47.900787353515625, 1.0\n",
      "Training accuracy and loss of epoch #249: 0.9892, 48.2291\n",
      "Saved model by train loss 48.22906085806833\n",
      "Train loss and acc of batch 0: 47.90077590942383, 1.0\n",
      "Train loss and acc of batch 1: 47.90077209472656, 1.0\n",
      "Train loss and acc of batch 2: 48.186607360839844, 0.984375\n",
      "Train loss and acc of batch 3: 48.117515563964844, 0.984375\n",
      "Train loss and acc of batch 4: 47.90074157714844, 1.0\n",
      "Train loss and acc of batch 5: 49.249656677246094, 0.96875\n",
      "Train loss and acc of batch 6: 48.40333938598633, 0.96875\n",
      "Train loss and acc of batch 7: 47.900718688964844, 1.0\n",
      "Train loss and acc of batch 8: 48.49640655517578, 0.984375\n",
      "Train loss and acc of batch 9: 48.186546325683594, 0.984375\n",
      "Train loss and acc of batch 10: 47.900691986083984, 1.0\n",
      "Train loss and acc of batch 11: 47.90068054199219, 1.0\n",
      "Train loss and acc of batch 12: 48.65389633178711, 0.984375\n",
      "Train loss and acc of batch 13: 48.11742401123047, 0.984375\n",
      "Train loss and acc of batch 14: 48.11741638183594, 0.984375\n",
      "Train loss and acc of batch 15: 48.49634552001953, 0.984375\n",
      "Train loss and acc of batch 16: 48.496337890625, 0.984375\n",
      "Train loss and acc of batch 17: 48.653846740722656, 0.984375\n",
      "Train loss and acc of batch 18: 48.782169342041016, 0.96875\n",
      "Train loss and acc of batch 19: 47.90060806274414, 1.0\n",
      "Train loss and acc of batch 20: 47.90060043334961, 1.0\n",
      "Train loss and acc of batch 21: 48.49629211425781, 0.984375\n",
      "Train loss and acc of batch 22: 48.49627685546875, 0.984375\n",
      "Train loss and acc of batch 23: 47.900569915771484, 1.0\n",
      "Train loss and acc of batch 24: 48.49626922607422, 0.984375\n",
      "Train loss and acc of batch 25: 47.90055465698242, 1.0\n",
      "Train loss and acc of batch 26: 47.90054702758789, 1.0\n",
      "Train loss and acc of batch 27: 47.900535583496094, 1.0\n",
      "Train loss and acc of batch 28: 47.90053176879883, 1.0\n",
      "Train loss and acc of batch 29: 48.49622344970703, 0.984375\n",
      "Train loss and acc of batch 30: 47.9005126953125, 1.0\n",
      "Train loss and acc of batch 31: 48.11726379394531, 0.984375\n",
      "Train loss and acc of batch 32: 47.90049362182617, 1.0\n",
      "Train loss and acc of batch 33: 47.900482177734375, 1.0\n",
      "Train loss and acc of batch 34: 48.496177673339844, 0.984375\n",
      "Train loss and acc of batch 35: 48.33399963378906, 0.96875\n",
      "Train loss and acc of batch 36: 47.90045166015625, 1.0\n",
      "Train loss and acc of batch 37: 48.65366744995117, 0.984375\n",
      "Train loss and acc of batch 38: 49.249359130859375, 0.96875\n",
      "Train loss and acc of batch 39: 48.11719512939453, 0.984375\n",
      "Train loss and acc of batch 40: 47.900421142578125, 1.0\n",
      "Train loss and acc of batch 41: 49.24934005737305, 0.96875\n",
      "Train loss and acc of batch 42: 47.90040588378906, 1.0\n",
      "Train loss and acc of batch 43: 48.49609375, 0.984375\n",
      "Train loss and acc of batch 44: 47.900386810302734, 1.0\n",
      "Train loss and acc of batch 45: 48.49607849121094, 0.984375\n",
      "Train loss and acc of batch 46: 48.18621826171875, 0.984375\n",
      "Train loss and acc of batch 47: 47.90035629272461, 1.0\n",
      "Train loss and acc of batch 48: 47.90034866333008, 1.0\n",
      "Train loss and acc of batch 49: 47.90034484863281, 1.0\n",
      "Train loss and acc of batch 50: 48.49603271484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.249244689941406, 0.96875\n",
      "Train loss and acc of batch 52: 49.15615463256836, 0.953125\n",
      "Train loss and acc of batch 53: 47.900306701660156, 1.0\n",
      "Train loss and acc of batch 54: 48.11705780029297, 0.984375\n",
      "Train loss and acc of batch 55: 47.90028762817383, 1.0\n",
      "Train loss and acc of batch 56: 47.90027618408203, 1.0\n",
      "Train loss and acc of batch 57: 48.4959716796875, 0.984375\n",
      "Train loss and acc of batch 58: 47.90026092529297, 1.0\n",
      "Train loss and acc of batch 59: 47.90024948120117, 1.0\n",
      "Train loss and acc of batch 60: 47.90024185180664, 1.0\n",
      "Train loss and acc of batch 61: 47.900238037109375, 1.0\n",
      "Train loss and acc of batch 62: 48.11698913574219, 0.984375\n",
      "Train loss and acc of batch 63: 49.09162139892578, 0.96875\n",
      "Train loss and acc of batch 64: 48.116966247558594, 0.984375\n",
      "Train loss and acc of batch 65: 47.90019607543945, 1.0\n",
      "Train loss and acc of batch 66: 47.90018844604492, 1.0\n",
      "Train loss and acc of batch 67: 48.712646484375, 0.96875\n",
      "Train loss and acc of batch 68: 48.495872497558594, 0.984375\n",
      "Train loss and acc of batch 69: 48.11692810058594, 0.984375\n",
      "Train loss and acc of batch 70: 47.90015411376953, 1.0\n",
      "Training accuracy and loss of epoch #250: 0.9892, 48.2284\n",
      "Saved model by train loss 48.22842788696289\n",
      "Train loss and acc of batch 0: 47.900150299072266, 1.0\n",
      "Train loss and acc of batch 1: 47.9001350402832, 1.0\n",
      "Train loss and acc of batch 2: 48.18597412109375, 0.984375\n",
      "Train loss and acc of batch 3: 48.11688232421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.90011215209961, 1.0\n",
      "Train loss and acc of batch 5: 49.2490234375, 0.96875\n",
      "Train loss and acc of batch 6: 48.402713775634766, 0.96875\n",
      "Train loss and acc of batch 7: 47.900081634521484, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 8: 48.49577331542969, 0.984375\n",
      "Train loss and acc of batch 9: 48.1859130859375, 0.984375\n",
      "Train loss and acc of batch 10: 47.900054931640625, 1.0\n",
      "Train loss and acc of batch 11: 47.900047302246094, 1.0\n",
      "Train loss and acc of batch 12: 48.653263092041016, 0.984375\n",
      "Train loss and acc of batch 13: 48.116790771484375, 0.984375\n",
      "Train loss and acc of batch 14: 48.116790771484375, 0.984375\n",
      "Train loss and acc of batch 15: 48.49571228027344, 0.984375\n",
      "Train loss and acc of batch 16: 48.495704650878906, 0.984375\n",
      "Train loss and acc of batch 17: 48.65321731567383, 0.984375\n",
      "Train loss and acc of batch 18: 48.78153610229492, 0.96875\n",
      "Train loss and acc of batch 19: 47.89997863769531, 1.0\n",
      "Train loss and acc of batch 20: 47.899967193603516, 1.0\n",
      "Train loss and acc of batch 21: 48.49565887451172, 0.984375\n",
      "Train loss and acc of batch 22: 48.49565124511719, 0.984375\n",
      "Train loss and acc of batch 23: 47.89994430541992, 1.0\n",
      "Train loss and acc of batch 24: 48.495628356933594, 0.984375\n",
      "Train loss and acc of batch 25: 47.899925231933594, 1.0\n",
      "Train loss and acc of batch 26: 47.89990997314453, 1.0\n",
      "Train loss and acc of batch 27: 47.899906158447266, 1.0\n",
      "Train loss and acc of batch 28: 47.89989471435547, 1.0\n",
      "Train loss and acc of batch 29: 48.49559020996094, 0.984375\n",
      "Train loss and acc of batch 30: 47.89987564086914, 1.0\n",
      "Train loss and acc of batch 31: 48.11663818359375, 0.984375\n",
      "Train loss and acc of batch 32: 47.89985656738281, 1.0\n",
      "Train loss and acc of batch 33: 47.89985656738281, 1.0\n",
      "Train loss and acc of batch 34: 48.49554443359375, 0.984375\n",
      "Train loss and acc of batch 35: 48.33335876464844, 0.96875\n",
      "Train loss and acc of batch 36: 47.89982223510742, 1.0\n",
      "Train loss and acc of batch 37: 48.653038024902344, 0.984375\n",
      "Train loss and acc of batch 38: 49.24872589111328, 0.96875\n",
      "Train loss and acc of batch 39: 48.11656188964844, 0.984375\n",
      "Train loss and acc of batch 40: 47.89978790283203, 1.0\n",
      "Train loss and acc of batch 41: 49.24870681762695, 0.96875\n",
      "Train loss and acc of batch 42: 47.89977264404297, 1.0\n",
      "Train loss and acc of batch 43: 48.49546813964844, 0.984375\n",
      "Train loss and acc of batch 44: 47.89975357055664, 1.0\n",
      "Train loss and acc of batch 45: 48.495445251464844, 0.984375\n",
      "Train loss and acc of batch 46: 48.185585021972656, 0.984375\n",
      "Train loss and acc of batch 47: 47.89972686767578, 1.0\n",
      "Train loss and acc of batch 48: 47.89971923828125, 1.0\n",
      "Train loss and acc of batch 49: 47.89970397949219, 1.0\n",
      "Train loss and acc of batch 50: 48.495399475097656, 0.984375\n",
      "Train loss and acc of batch 51: 49.248619079589844, 0.96875\n",
      "Train loss and acc of batch 52: 49.155521392822266, 0.953125\n",
      "Train loss and acc of batch 53: 47.89967346191406, 1.0\n",
      "Train loss and acc of batch 54: 48.116432189941406, 0.984375\n",
      "Train loss and acc of batch 55: 47.899654388427734, 1.0\n",
      "Train loss and acc of batch 56: 47.89965057373047, 1.0\n",
      "Train loss and acc of batch 57: 48.495338439941406, 0.984375\n",
      "Train loss and acc of batch 58: 47.899627685546875, 1.0\n",
      "Train loss and acc of batch 59: 47.899620056152344, 1.0\n",
      "Train loss and acc of batch 60: 47.89960861206055, 1.0\n",
      "Train loss and acc of batch 61: 47.89960479736328, 1.0\n",
      "Train loss and acc of batch 62: 48.116355895996094, 0.984375\n",
      "Train loss and acc of batch 63: 49.09098434448242, 0.96875\n",
      "Train loss and acc of batch 64: 48.11634063720703, 0.984375\n",
      "Train loss and acc of batch 65: 47.899566650390625, 1.0\n",
      "Train loss and acc of batch 66: 47.89955520629883, 1.0\n",
      "Train loss and acc of batch 67: 48.71200942993164, 0.96875\n",
      "Train loss and acc of batch 68: 48.4952392578125, 0.984375\n",
      "Train loss and acc of batch 69: 48.116294860839844, 0.984375\n",
      "Train loss and acc of batch 70: 47.8995246887207, 1.0\n",
      "Training accuracy and loss of epoch #251: 0.9892, 48.2278\n",
      "Saved model by train loss 48.22779577550754\n",
      "Train loss and acc of batch 0: 47.899513244628906, 1.0\n",
      "Train loss and acc of batch 1: 47.89950942993164, 1.0\n",
      "Train loss and acc of batch 2: 48.18534851074219, 0.984375\n",
      "Train loss and acc of batch 3: 48.116241455078125, 0.984375\n",
      "Train loss and acc of batch 4: 47.89947509765625, 1.0\n",
      "Train loss and acc of batch 5: 49.248390197753906, 0.96875\n",
      "Train loss and acc of batch 6: 48.40207290649414, 0.96875\n",
      "Train loss and acc of batch 7: 47.89944839477539, 1.0\n",
      "Train loss and acc of batch 8: 48.495140075683594, 0.984375\n",
      "Train loss and acc of batch 9: 48.185279846191406, 0.984375\n",
      "Train loss and acc of batch 10: 47.89942169189453, 1.0\n",
      "Train loss and acc of batch 11: 47.8994140625, 1.0\n",
      "Train loss and acc of batch 12: 48.65262985229492, 0.984375\n",
      "Train loss and acc of batch 13: 48.11616516113281, 0.984375\n",
      "Train loss and acc of batch 14: 48.11615753173828, 0.984375\n",
      "Train loss and acc of batch 15: 48.495086669921875, 0.984375\n",
      "Train loss and acc of batch 16: 48.49507141113281, 0.984375\n",
      "Train loss and acc of batch 17: 48.652584075927734, 0.984375\n",
      "Train loss and acc of batch 18: 48.78091049194336, 0.96875\n",
      "Train loss and acc of batch 19: 47.89934539794922, 1.0\n",
      "Train loss and acc of batch 20: 47.899330139160156, 1.0\n",
      "Train loss and acc of batch 21: 48.495033264160156, 0.984375\n",
      "Train loss and acc of batch 22: 48.495018005371094, 0.984375\n",
      "Train loss and acc of batch 23: 47.89931106567383, 1.0\n",
      "Train loss and acc of batch 24: 48.49500274658203, 0.984375\n",
      "Train loss and acc of batch 25: 47.899288177490234, 1.0\n",
      "Train loss and acc of batch 26: 47.89928436279297, 1.0\n",
      "Train loss and acc of batch 27: 47.89927291870117, 1.0\n",
      "Train loss and acc of batch 28: 47.89926528930664, 1.0\n",
      "Train loss and acc of batch 29: 48.494956970214844, 0.984375\n",
      "Train loss and acc of batch 30: 47.89924621582031, 1.0\n",
      "Train loss and acc of batch 31: 48.116004943847656, 0.984375\n",
      "Train loss and acc of batch 32: 47.899234771728516, 1.0\n",
      "Train loss and acc of batch 33: 47.89921569824219, 1.0\n",
      "Train loss and acc of batch 34: 48.494911193847656, 0.984375\n",
      "Train loss and acc of batch 35: 48.33272933959961, 0.96875\n",
      "Train loss and acc of batch 36: 47.89919662475586, 1.0\n",
      "Train loss and acc of batch 37: 48.652408599853516, 0.984375\n",
      "Train loss and acc of batch 38: 49.24810028076172, 0.96875\n",
      "Train loss and acc of batch 39: 48.115928649902344, 0.984375\n",
      "Train loss and acc of batch 40: 47.89916229248047, 1.0\n",
      "Train loss and acc of batch 41: 49.24807357788086, 0.96875\n",
      "Train loss and acc of batch 42: 47.899139404296875, 1.0\n",
      "Train loss and acc of batch 43: 48.494834899902344, 0.984375\n",
      "Train loss and acc of batch 44: 47.89912033081055, 1.0\n",
      "Train loss and acc of batch 45: 48.49481201171875, 0.984375\n",
      "Train loss and acc of batch 46: 48.184959411621094, 0.984375\n",
      "Train loss and acc of batch 47: 47.89909362792969, 1.0\n",
      "Train loss and acc of batch 48: 47.89908218383789, 1.0\n",
      "Train loss and acc of batch 49: 47.899078369140625, 1.0\n",
      "Train loss and acc of batch 50: 48.49476623535156, 0.984375\n",
      "Train loss and acc of batch 51: 49.24798583984375, 0.96875\n",
      "Train loss and acc of batch 52: 49.15488815307617, 0.953125\n",
      "Train loss and acc of batch 53: 47.89904022216797, 1.0\n",
      "Train loss and acc of batch 54: 48.11579895019531, 0.984375\n",
      "Train loss and acc of batch 55: 47.899024963378906, 1.0\n",
      "Train loss and acc of batch 56: 47.89901351928711, 1.0\n",
      "Train loss and acc of batch 57: 48.494712829589844, 0.984375\n",
      "Train loss and acc of batch 58: 47.89899444580078, 1.0\n",
      "Train loss and acc of batch 59: 47.89898681640625, 1.0\n",
      "Train loss and acc of batch 60: 47.898983001708984, 1.0\n",
      "Train loss and acc of batch 61: 47.89897155761719, 1.0\n",
      "Train loss and acc of batch 62: 48.11572265625, 0.984375\n",
      "Train loss and acc of batch 63: 49.09035110473633, 0.96875\n",
      "Train loss and acc of batch 64: 48.11570739746094, 0.984375\n",
      "Train loss and acc of batch 65: 47.8989372253418, 1.0\n",
      "Train loss and acc of batch 66: 47.898921966552734, 1.0\n",
      "Train loss and acc of batch 67: 48.71138000488281, 0.96875\n",
      "Train loss and acc of batch 68: 48.49461364746094, 0.984375\n",
      "Train loss and acc of batch 69: 48.11566162109375, 0.984375\n",
      "Train loss and acc of batch 70: 47.898887634277344, 1.0\n",
      "Training accuracy and loss of epoch #252: 0.9892, 48.2272\n",
      "Saved model by train loss 48.22716409387723\n",
      "Train loss and acc of batch 0: 47.89888000488281, 1.0\n",
      "Train loss and acc of batch 1: 47.89887237548828, 1.0\n",
      "Train loss and acc of batch 2: 48.184715270996094, 0.984375\n",
      "Train loss and acc of batch 3: 48.115623474121094, 0.984375\n",
      "Train loss and acc of batch 4: 47.89884567260742, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 5: 49.247764587402344, 0.96875\n",
      "Train loss and acc of batch 6: 48.40143966674805, 0.96875\n",
      "Train loss and acc of batch 7: 47.89881896972656, 1.0\n",
      "Train loss and acc of batch 8: 48.49451446533203, 0.984375\n",
      "Train loss and acc of batch 9: 48.184654235839844, 0.984375\n",
      "Train loss and acc of batch 10: 47.89878845214844, 1.0\n",
      "Train loss and acc of batch 11: 47.89878463745117, 1.0\n",
      "Train loss and acc of batch 12: 48.652000427246094, 0.984375\n",
      "Train loss and acc of batch 13: 48.11553192138672, 0.984375\n",
      "Train loss and acc of batch 14: 48.11552429199219, 0.984375\n",
      "Train loss and acc of batch 15: 48.49444580078125, 0.984375\n",
      "Train loss and acc of batch 16: 48.49443817138672, 0.984375\n",
      "Train loss and acc of batch 17: 48.65195846557617, 0.984375\n",
      "Train loss and acc of batch 18: 48.7802734375, 0.96875\n",
      "Train loss and acc of batch 19: 47.898712158203125, 1.0\n",
      "Train loss and acc of batch 20: 47.89869689941406, 1.0\n",
      "Train loss and acc of batch 21: 48.49439239501953, 0.984375\n",
      "Train loss and acc of batch 22: 48.494384765625, 0.984375\n",
      "Train loss and acc of batch 23: 47.89867401123047, 1.0\n",
      "Train loss and acc of batch 24: 48.49436950683594, 0.984375\n",
      "Train loss and acc of batch 25: 47.89866256713867, 1.0\n",
      "Train loss and acc of batch 26: 47.898651123046875, 1.0\n",
      "Train loss and acc of batch 27: 47.898643493652344, 1.0\n",
      "Train loss and acc of batch 28: 47.89862823486328, 1.0\n",
      "Train loss and acc of batch 29: 48.49432373046875, 0.984375\n",
      "Train loss and acc of batch 30: 47.89861297607422, 1.0\n",
      "Train loss and acc of batch 31: 48.11537170410156, 0.984375\n",
      "Train loss and acc of batch 32: 47.89859390258789, 1.0\n",
      "Train loss and acc of batch 33: 47.89858627319336, 1.0\n",
      "Train loss and acc of batch 34: 48.49427795410156, 0.984375\n",
      "Train loss and acc of batch 35: 48.332096099853516, 0.96875\n",
      "Train loss and acc of batch 36: 47.8985595703125, 1.0\n",
      "Train loss and acc of batch 37: 48.651771545410156, 0.984375\n",
      "Train loss and acc of batch 38: 49.247467041015625, 0.96875\n",
      "Train loss and acc of batch 39: 48.11530303955078, 0.984375\n",
      "Train loss and acc of batch 40: 47.89852523803711, 1.0\n",
      "Train loss and acc of batch 41: 49.24744415283203, 0.96875\n",
      "Train loss and acc of batch 42: 47.89850997924805, 1.0\n",
      "Train loss and acc of batch 43: 48.49419403076172, 0.984375\n",
      "Train loss and acc of batch 44: 47.89849090576172, 1.0\n",
      "Train loss and acc of batch 45: 48.49418640136719, 0.984375\n",
      "Train loss and acc of batch 46: 48.184326171875, 0.984375\n",
      "Train loss and acc of batch 47: 47.898460388183594, 1.0\n",
      "Train loss and acc of batch 48: 47.89845275878906, 1.0\n",
      "Train loss and acc of batch 49: 47.898441314697266, 1.0\n",
      "Train loss and acc of batch 50: 48.494140625, 0.984375\n",
      "Train loss and acc of batch 51: 49.247344970703125, 0.96875\n",
      "Train loss and acc of batch 52: 49.154258728027344, 0.953125\n",
      "Train loss and acc of batch 53: 47.89841079711914, 1.0\n",
      "Train loss and acc of batch 54: 48.11516571044922, 0.984375\n",
      "Train loss and acc of batch 55: 47.89839172363281, 1.0\n",
      "Train loss and acc of batch 56: 47.898380279541016, 1.0\n",
      "Train loss and acc of batch 57: 48.49407196044922, 0.984375\n",
      "Train loss and acc of batch 58: 47.89836120605469, 1.0\n",
      "Train loss and acc of batch 59: 47.89835739135742, 1.0\n",
      "Train loss and acc of batch 60: 47.898345947265625, 1.0\n",
      "Train loss and acc of batch 61: 47.89833450317383, 1.0\n",
      "Train loss and acc of batch 62: 48.11509704589844, 0.984375\n",
      "Train loss and acc of batch 63: 49.0897216796875, 0.96875\n",
      "Train loss and acc of batch 64: 48.115074157714844, 0.984375\n",
      "Train loss and acc of batch 65: 47.89830017089844, 1.0\n",
      "Train loss and acc of batch 66: 47.898292541503906, 1.0\n",
      "Train loss and acc of batch 67: 48.710750579833984, 0.96875\n",
      "Train loss and acc of batch 68: 48.493980407714844, 0.984375\n",
      "Train loss and acc of batch 69: 48.115028381347656, 0.984375\n",
      "Train loss and acc of batch 70: 47.89826202392578, 1.0\n",
      "Training accuracy and loss of epoch #253: 0.9892, 48.2265\n",
      "Saved model by train loss 48.22653176750935\n",
      "Train loss and acc of batch 0: 47.89824676513672, 1.0\n",
      "Train loss and acc of batch 1: 47.89823913574219, 1.0\n",
      "Train loss and acc of batch 2: 48.18408203125, 0.984375\n",
      "Train loss and acc of batch 3: 48.11498260498047, 0.984375\n",
      "Train loss and acc of batch 4: 47.89821243286133, 1.0\n",
      "Train loss and acc of batch 5: 49.24712371826172, 0.96875\n",
      "Train loss and acc of batch 6: 48.400814056396484, 0.96875\n",
      "Train loss and acc of batch 7: 47.89818572998047, 1.0\n",
      "Train loss and acc of batch 8: 48.493873596191406, 0.984375\n",
      "Train loss and acc of batch 9: 48.18402099609375, 0.984375\n",
      "Train loss and acc of batch 10: 47.898162841796875, 1.0\n",
      "Train loss and acc of batch 11: 47.89815139770508, 1.0\n",
      "Train loss and acc of batch 12: 48.6513671875, 0.984375\n",
      "Train loss and acc of batch 13: 48.114898681640625, 0.984375\n",
      "Train loss and acc of batch 14: 48.114891052246094, 0.984375\n",
      "Train loss and acc of batch 15: 48.493812561035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.493812561035156, 0.984375\n",
      "Train loss and acc of batch 17: 48.65131759643555, 0.984375\n",
      "Train loss and acc of batch 18: 48.779640197753906, 0.96875\n",
      "Train loss and acc of batch 19: 47.8980827331543, 1.0\n",
      "Train loss and acc of batch 20: 47.8980712890625, 1.0\n",
      "Train loss and acc of batch 21: 48.49375915527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.493751525878906, 0.984375\n",
      "Train loss and acc of batch 23: 47.898040771484375, 1.0\n",
      "Train loss and acc of batch 24: 48.493736267089844, 0.984375\n",
      "Train loss and acc of batch 25: 47.89802551269531, 1.0\n",
      "Train loss and acc of batch 26: 47.89801788330078, 1.0\n",
      "Train loss and acc of batch 27: 47.898006439208984, 1.0\n",
      "Train loss and acc of batch 28: 47.89799880981445, 1.0\n",
      "Train loss and acc of batch 29: 48.493690490722656, 0.984375\n",
      "Train loss and acc of batch 30: 47.89798355102539, 1.0\n",
      "Train loss and acc of batch 31: 48.11473846435547, 0.984375\n",
      "Train loss and acc of batch 32: 47.8979606628418, 1.0\n",
      "Train loss and acc of batch 33: 47.89795684814453, 1.0\n",
      "Train loss and acc of batch 34: 48.49364471435547, 0.984375\n",
      "Train loss and acc of batch 35: 48.33146667480469, 0.96875\n",
      "Train loss and acc of batch 36: 47.89792251586914, 1.0\n",
      "Train loss and acc of batch 37: 48.65114212036133, 0.984375\n",
      "Train loss and acc of batch 38: 49.24683380126953, 0.96875\n",
      "Train loss and acc of batch 39: 48.114662170410156, 0.984375\n",
      "Train loss and acc of batch 40: 47.897891998291016, 1.0\n",
      "Train loss and acc of batch 41: 49.24681091308594, 0.96875\n",
      "Train loss and acc of batch 42: 47.89787673950195, 1.0\n",
      "Train loss and acc of batch 43: 48.493568420410156, 0.984375\n",
      "Train loss and acc of batch 44: 47.897857666015625, 1.0\n",
      "Train loss and acc of batch 45: 48.49354553222656, 0.984375\n",
      "Train loss and acc of batch 46: 48.183685302734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.89783477783203, 1.0\n",
      "Train loss and acc of batch 48: 47.89781951904297, 1.0\n",
      "Train loss and acc of batch 49: 47.8978157043457, 1.0\n",
      "Train loss and acc of batch 50: 48.493499755859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.24671936035156, 0.96875\n",
      "Train loss and acc of batch 52: 49.15362548828125, 0.953125\n",
      "Train loss and acc of batch 53: 47.89777755737305, 1.0\n",
      "Train loss and acc of batch 54: 48.114532470703125, 0.984375\n",
      "Train loss and acc of batch 55: 47.89775848388672, 1.0\n",
      "Train loss and acc of batch 56: 47.89774703979492, 1.0\n",
      "Train loss and acc of batch 57: 48.493446350097656, 0.984375\n",
      "Train loss and acc of batch 58: 47.89773178100586, 1.0\n",
      "Train loss and acc of batch 59: 47.89772033691406, 1.0\n",
      "Train loss and acc of batch 60: 47.89771270751953, 1.0\n",
      "Train loss and acc of batch 61: 47.89769744873047, 1.0\n",
      "Train loss and acc of batch 62: 48.114463806152344, 0.984375\n",
      "Train loss and acc of batch 63: 49.08909225463867, 0.96875\n",
      "Train loss and acc of batch 64: 48.11444091796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.897666931152344, 1.0\n",
      "Train loss and acc of batch 66: 47.89766311645508, 1.0\n",
      "Train loss and acc of batch 67: 48.710113525390625, 0.96875\n",
      "Train loss and acc of batch 68: 48.49334716796875, 0.984375\n",
      "Train loss and acc of batch 69: 48.11439514160156, 0.984375\n",
      "Train loss and acc of batch 70: 47.89762496948242, 1.0\n",
      "Training accuracy and loss of epoch #254: 0.9892, 48.2259\n",
      "Saved model by train loss 48.22589874267578\n",
      "Train loss and acc of batch 0: 47.897621154785156, 1.0\n",
      "Train loss and acc of batch 1: 47.89760971069336, 1.0\n",
      "Train loss and acc of batch 2: 48.183448791503906, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 3: 48.114356994628906, 0.984375\n",
      "Train loss and acc of batch 4: 47.8975830078125, 1.0\n",
      "Train loss and acc of batch 5: 49.246498107910156, 0.96875\n",
      "Train loss and acc of batch 6: 48.40018081665039, 0.96875\n",
      "Train loss and acc of batch 7: 47.89754867553711, 1.0\n",
      "Train loss and acc of batch 8: 48.49324035644531, 0.984375\n",
      "Train loss and acc of batch 9: 48.183387756347656, 0.984375\n",
      "Train loss and acc of batch 10: 47.897525787353516, 1.0\n",
      "Train loss and acc of batch 11: 47.897518157958984, 1.0\n",
      "Train loss and acc of batch 12: 48.65073013305664, 0.984375\n",
      "Train loss and acc of batch 13: 48.11426544189453, 0.984375\n",
      "Train loss and acc of batch 14: 48.1142578125, 0.984375\n",
      "Train loss and acc of batch 15: 48.493186950683594, 0.984375\n",
      "Train loss and acc of batch 16: 48.49317169189453, 0.984375\n",
      "Train loss and acc of batch 17: 48.65068817138672, 0.984375\n",
      "Train loss and acc of batch 18: 48.77901077270508, 0.96875\n",
      "Train loss and acc of batch 19: 47.8974494934082, 1.0\n",
      "Train loss and acc of batch 20: 47.897438049316406, 1.0\n",
      "Train loss and acc of batch 21: 48.493125915527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.49311828613281, 0.984375\n",
      "Train loss and acc of batch 23: 47.89741134643555, 1.0\n",
      "Train loss and acc of batch 24: 48.49310302734375, 0.984375\n",
      "Train loss and acc of batch 25: 47.89739227294922, 1.0\n",
      "Train loss and acc of batch 26: 47.89738464355469, 1.0\n",
      "Train loss and acc of batch 27: 47.89737319946289, 1.0\n",
      "Train loss and acc of batch 28: 47.897369384765625, 1.0\n",
      "Train loss and acc of batch 29: 48.493064880371094, 0.984375\n",
      "Train loss and acc of batch 30: 47.8973503112793, 1.0\n",
      "Train loss and acc of batch 31: 48.114105224609375, 0.984375\n",
      "Train loss and acc of batch 32: 47.897335052490234, 1.0\n",
      "Train loss and acc of batch 33: 47.89731979370117, 1.0\n",
      "Train loss and acc of batch 34: 48.493019104003906, 0.984375\n",
      "Train loss and acc of batch 35: 48.330833435058594, 0.96875\n",
      "Train loss and acc of batch 36: 47.89729690551758, 1.0\n",
      "Train loss and acc of batch 37: 48.650516510009766, 0.984375\n",
      "Train loss and acc of batch 38: 49.24620056152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.11402893066406, 0.984375\n",
      "Train loss and acc of batch 40: 47.89725875854492, 1.0\n",
      "Train loss and acc of batch 41: 49.24617385864258, 0.96875\n",
      "Train loss and acc of batch 42: 47.897247314453125, 1.0\n",
      "Train loss and acc of batch 43: 48.49293518066406, 0.984375\n",
      "Train loss and acc of batch 44: 47.89722442626953, 1.0\n",
      "Train loss and acc of batch 45: 48.49291229248047, 0.984375\n",
      "Train loss and acc of batch 46: 48.18305969238281, 0.984375\n",
      "Train loss and acc of batch 47: 47.89719772338867, 1.0\n",
      "Train loss and acc of batch 48: 47.89719009399414, 1.0\n",
      "Train loss and acc of batch 49: 47.897178649902344, 1.0\n",
      "Train loss and acc of batch 50: 48.49287414550781, 0.984375\n",
      "Train loss and acc of batch 51: 49.24609375, 0.96875\n",
      "Train loss and acc of batch 52: 49.15298843383789, 0.953125\n",
      "Train loss and acc of batch 53: 47.89714431762695, 1.0\n",
      "Train loss and acc of batch 54: 48.11389923095703, 0.984375\n",
      "Train loss and acc of batch 55: 47.897125244140625, 1.0\n",
      "Train loss and acc of batch 56: 47.89712142944336, 1.0\n",
      "Train loss and acc of batch 57: 48.49281311035156, 0.984375\n",
      "Train loss and acc of batch 58: 47.897098541259766, 1.0\n",
      "Train loss and acc of batch 59: 47.897090911865234, 1.0\n",
      "Train loss and acc of batch 60: 47.89707565307617, 1.0\n",
      "Train loss and acc of batch 61: 47.897071838378906, 1.0\n",
      "Train loss and acc of batch 62: 48.11383056640625, 0.984375\n",
      "Train loss and acc of batch 63: 49.08845901489258, 0.96875\n",
      "Train loss and acc of batch 64: 48.11381530761719, 0.984375\n",
      "Train loss and acc of batch 65: 47.89704132080078, 1.0\n",
      "Train loss and acc of batch 66: 47.897029876708984, 1.0\n",
      "Train loss and acc of batch 67: 48.7094841003418, 0.96875\n",
      "Train loss and acc of batch 68: 48.492706298828125, 0.984375\n",
      "Train loss and acc of batch 69: 48.11376190185547, 0.984375\n",
      "Train loss and acc of batch 70: 47.896995544433594, 1.0\n",
      "Training accuracy and loss of epoch #255: 0.9892, 48.2253\n",
      "Saved model by train loss 48.2252671147736\n",
      "Train loss and acc of batch 0: 47.89698791503906, 1.0\n",
      "Train loss and acc of batch 1: 47.89697265625, 1.0\n",
      "Train loss and acc of batch 2: 48.182823181152344, 0.984375\n",
      "Train loss and acc of batch 3: 48.11371612548828, 0.984375\n",
      "Train loss and acc of batch 4: 47.896949768066406, 1.0\n",
      "Train loss and acc of batch 5: 49.24586486816406, 0.96875\n",
      "Train loss and acc of batch 6: 48.39954376220703, 0.96875\n",
      "Train loss and acc of batch 7: 47.89691925048828, 1.0\n",
      "Train loss and acc of batch 8: 48.49262237548828, 0.984375\n",
      "Train loss and acc of batch 9: 48.18275451660156, 0.984375\n",
      "Train loss and acc of batch 10: 47.89689254760742, 1.0\n",
      "Train loss and acc of batch 11: 47.89688491821289, 1.0\n",
      "Train loss and acc of batch 12: 48.65009689331055, 0.984375\n",
      "Train loss and acc of batch 13: 48.11363220214844, 0.984375\n",
      "Train loss and acc of batch 14: 48.113624572753906, 0.984375\n",
      "Train loss and acc of batch 15: 48.4925537109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.49254608154297, 0.984375\n",
      "Train loss and acc of batch 17: 48.65005111694336, 0.984375\n",
      "Train loss and acc of batch 18: 48.778377532958984, 0.96875\n",
      "Train loss and acc of batch 19: 47.89681625366211, 1.0\n",
      "Train loss and acc of batch 20: 47.89680480957031, 1.0\n",
      "Train loss and acc of batch 21: 48.49250030517578, 0.984375\n",
      "Train loss and acc of batch 22: 48.49249267578125, 0.984375\n",
      "Train loss and acc of batch 23: 47.89678192138672, 1.0\n",
      "Train loss and acc of batch 24: 48.492469787597656, 0.984375\n",
      "Train loss and acc of batch 25: 47.89676284790039, 1.0\n",
      "Train loss and acc of batch 26: 47.89674758911133, 1.0\n",
      "Train loss and acc of batch 27: 47.89674377441406, 1.0\n",
      "Train loss and acc of batch 28: 47.89673614501953, 1.0\n",
      "Train loss and acc of batch 29: 48.49242401123047, 0.984375\n",
      "Train loss and acc of batch 30: 47.89672088623047, 1.0\n",
      "Train loss and acc of batch 31: 48.11347198486328, 0.984375\n",
      "Train loss and acc of batch 32: 47.896697998046875, 1.0\n",
      "Train loss and acc of batch 33: 47.896690368652344, 1.0\n",
      "Train loss and acc of batch 34: 48.49237823486328, 0.984375\n",
      "Train loss and acc of batch 35: 48.330204010009766, 0.96875\n",
      "Train loss and acc of batch 36: 47.89666748046875, 1.0\n",
      "Train loss and acc of batch 37: 48.649879455566406, 0.984375\n",
      "Train loss and acc of batch 38: 49.245567321777344, 0.96875\n",
      "Train loss and acc of batch 39: 48.1134033203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.89662551879883, 1.0\n",
      "Train loss and acc of batch 41: 49.245548248291016, 0.96875\n",
      "Train loss and acc of batch 42: 47.8966064453125, 1.0\n",
      "Train loss and acc of batch 43: 48.49230194091797, 0.984375\n",
      "Train loss and acc of batch 44: 47.8965950012207, 1.0\n",
      "Train loss and acc of batch 45: 48.492279052734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.18242645263672, 0.984375\n",
      "Train loss and acc of batch 47: 47.89656448364258, 1.0\n",
      "Train loss and acc of batch 48: 47.89655685424805, 1.0\n",
      "Train loss and acc of batch 49: 47.896549224853516, 1.0\n",
      "Train loss and acc of batch 50: 48.49224090576172, 0.984375\n",
      "Train loss and acc of batch 51: 49.245452880859375, 0.96875\n",
      "Train loss and acc of batch 52: 49.15236282348633, 0.953125\n",
      "Train loss and acc of batch 53: 47.89651107788086, 1.0\n",
      "Train loss and acc of batch 54: 48.11326599121094, 0.984375\n",
      "Train loss and acc of batch 55: 47.8964958190918, 1.0\n",
      "Train loss and acc of batch 56: 47.896488189697266, 1.0\n",
      "Train loss and acc of batch 57: 48.49217224121094, 0.984375\n",
      "Train loss and acc of batch 58: 47.89646911621094, 1.0\n",
      "Train loss and acc of batch 59: 47.89645767211914, 1.0\n",
      "Train loss and acc of batch 60: 47.89645004272461, 1.0\n",
      "Train loss and acc of batch 61: 47.89643859863281, 1.0\n",
      "Train loss and acc of batch 62: 48.113189697265625, 0.984375\n",
      "Train loss and acc of batch 63: 49.087825775146484, 0.96875\n",
      "Train loss and acc of batch 64: 48.113182067871094, 0.984375\n",
      "Train loss and acc of batch 65: 47.896400451660156, 1.0\n",
      "Train loss and acc of batch 66: 47.896400451660156, 1.0\n",
      "Train loss and acc of batch 67: 48.7088508605957, 0.96875\n",
      "Train loss and acc of batch 68: 48.49207305908203, 0.984375\n",
      "Train loss and acc of batch 69: 48.113136291503906, 0.984375\n",
      "Train loss and acc of batch 70: 47.89635467529297, 1.0\n",
      "Training accuracy and loss of epoch #256: 0.9892, 48.2246\n",
      "Saved model by train loss 48.224634466036946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.89634704589844, 1.0\n",
      "Train loss and acc of batch 1: 47.89634323120117, 1.0\n",
      "Train loss and acc of batch 2: 48.18218994140625, 0.984375\n",
      "Train loss and acc of batch 3: 48.11309051513672, 0.984375\n",
      "Train loss and acc of batch 4: 47.89631271362305, 1.0\n",
      "Train loss and acc of batch 5: 49.24523162841797, 0.96875\n",
      "Train loss and acc of batch 6: 48.3989143371582, 0.96875\n",
      "Train loss and acc of batch 7: 47.89629364013672, 1.0\n",
      "Train loss and acc of batch 8: 48.491981506347656, 0.984375\n",
      "Train loss and acc of batch 9: 48.18212890625, 0.984375\n",
      "Train loss and acc of batch 10: 47.896263122558594, 1.0\n",
      "Train loss and acc of batch 11: 47.89625549316406, 1.0\n",
      "Train loss and acc of batch 12: 48.64946746826172, 0.984375\n",
      "Train loss and acc of batch 13: 48.112998962402344, 0.984375\n",
      "Train loss and acc of batch 14: 48.11299133300781, 0.984375\n",
      "Train loss and acc of batch 15: 48.491920471191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.491912841796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.6494255065918, 0.984375\n",
      "Train loss and acc of batch 18: 48.77774429321289, 0.96875\n",
      "Train loss and acc of batch 19: 47.896183013916016, 1.0\n",
      "Train loss and acc of batch 20: 47.896175384521484, 1.0\n",
      "Train loss and acc of batch 21: 48.49186706542969, 0.984375\n",
      "Train loss and acc of batch 22: 48.491859436035156, 0.984375\n",
      "Train loss and acc of batch 23: 47.896148681640625, 1.0\n",
      "Train loss and acc of batch 24: 48.491844177246094, 0.984375\n",
      "Train loss and acc of batch 25: 47.8961296081543, 1.0\n",
      "Train loss and acc of batch 26: 47.896121978759766, 1.0\n",
      "Train loss and acc of batch 27: 47.8961067199707, 1.0\n",
      "Train loss and acc of batch 28: 47.89610290527344, 1.0\n",
      "Train loss and acc of batch 29: 48.491798400878906, 0.984375\n",
      "Train loss and acc of batch 30: 47.896087646484375, 1.0\n",
      "Train loss and acc of batch 31: 48.11283874511719, 0.984375\n",
      "Train loss and acc of batch 32: 47.89606857299805, 1.0\n",
      "Train loss and acc of batch 33: 47.896053314208984, 1.0\n",
      "Train loss and acc of batch 34: 48.49175262451172, 0.984375\n",
      "Train loss and acc of batch 35: 48.32957077026367, 0.96875\n",
      "Train loss and acc of batch 36: 47.896026611328125, 1.0\n",
      "Train loss and acc of batch 37: 48.64924621582031, 0.984375\n",
      "Train loss and acc of batch 38: 49.24494171142578, 0.96875\n",
      "Train loss and acc of batch 39: 48.112770080566406, 0.984375\n",
      "Train loss and acc of batch 40: 47.895999908447266, 1.0\n",
      "Train loss and acc of batch 41: 49.244911193847656, 0.96875\n",
      "Train loss and acc of batch 42: 47.89597702026367, 1.0\n",
      "Train loss and acc of batch 43: 48.491668701171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.895957946777344, 1.0\n",
      "Train loss and acc of batch 45: 48.49165344238281, 0.984375\n",
      "Train loss and acc of batch 46: 48.181793212890625, 0.984375\n",
      "Train loss and acc of batch 47: 47.895931243896484, 1.0\n",
      "Train loss and acc of batch 48: 47.89592361450195, 1.0\n",
      "Train loss and acc of batch 49: 47.89591598510742, 1.0\n",
      "Train loss and acc of batch 50: 48.491600036621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.24481964111328, 0.96875\n",
      "Train loss and acc of batch 52: 49.151729583740234, 0.953125\n",
      "Train loss and acc of batch 53: 47.89588165283203, 1.0\n",
      "Train loss and acc of batch 54: 48.112640380859375, 0.984375\n",
      "Train loss and acc of batch 55: 47.89585494995117, 1.0\n",
      "Train loss and acc of batch 56: 47.89584732055664, 1.0\n",
      "Train loss and acc of batch 57: 48.491546630859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.895835876464844, 1.0\n",
      "Train loss and acc of batch 59: 47.89582824707031, 1.0\n",
      "Train loss and acc of batch 60: 47.895816802978516, 1.0\n",
      "Train loss and acc of batch 61: 47.89580535888672, 1.0\n",
      "Train loss and acc of batch 62: 48.11256408691406, 0.984375\n",
      "Train loss and acc of batch 63: 49.087196350097656, 0.96875\n",
      "Train loss and acc of batch 64: 48.11254119873047, 0.984375\n",
      "Train loss and acc of batch 65: 47.895774841308594, 1.0\n",
      "Train loss and acc of batch 66: 47.8957633972168, 1.0\n",
      "Train loss and acc of batch 67: 48.708221435546875, 0.96875\n",
      "Train loss and acc of batch 68: 48.491455078125, 0.984375\n",
      "Train loss and acc of batch 69: 48.11250305175781, 0.984375\n",
      "Train loss and acc of batch 70: 47.89572525024414, 1.0\n",
      "Training accuracy and loss of epoch #257: 0.9892, 48.2240\n",
      "Saved model by train loss 48.22400267695038\n",
      "Train loss and acc of batch 0: 47.89571762084961, 1.0\n",
      "Train loss and acc of batch 1: 47.89570999145508, 1.0\n",
      "Train loss and acc of batch 2: 48.181556701660156, 0.984375\n",
      "Train loss and acc of batch 3: 48.112457275390625, 0.984375\n",
      "Train loss and acc of batch 4: 47.89568328857422, 1.0\n",
      "Train loss and acc of batch 5: 49.244598388671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.39828109741211, 0.96875\n",
      "Train loss and acc of batch 7: 47.89565658569336, 1.0\n",
      "Train loss and acc of batch 8: 48.49134826660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.181488037109375, 0.984375\n",
      "Train loss and acc of batch 10: 47.8956298828125, 1.0\n",
      "Train loss and acc of batch 11: 47.89562225341797, 1.0\n",
      "Train loss and acc of batch 12: 48.648834228515625, 0.984375\n",
      "Train loss and acc of batch 13: 48.11236572265625, 0.984375\n",
      "Train loss and acc of batch 14: 48.11235809326172, 0.984375\n",
      "Train loss and acc of batch 15: 48.49128723144531, 0.984375\n",
      "Train loss and acc of batch 16: 48.49127960205078, 0.984375\n",
      "Train loss and acc of batch 17: 48.6487922668457, 0.984375\n",
      "Train loss and acc of batch 18: 48.7771110534668, 0.96875\n",
      "Train loss and acc of batch 19: 47.89555358886719, 1.0\n",
      "Train loss and acc of batch 20: 47.89554214477539, 1.0\n",
      "Train loss and acc of batch 21: 48.491233825683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.49121856689453, 0.984375\n",
      "Train loss and acc of batch 23: 47.895511627197266, 1.0\n",
      "Train loss and acc of batch 24: 48.49120330810547, 0.984375\n",
      "Train loss and acc of batch 25: 47.8954963684082, 1.0\n",
      "Train loss and acc of batch 26: 47.89548873901367, 1.0\n",
      "Train loss and acc of batch 27: 47.89547348022461, 1.0\n",
      "Train loss and acc of batch 28: 47.89546585083008, 1.0\n",
      "Train loss and acc of batch 29: 48.49115753173828, 0.984375\n",
      "Train loss and acc of batch 30: 47.895450592041016, 1.0\n",
      "Train loss and acc of batch 31: 48.112213134765625, 0.984375\n",
      "Train loss and acc of batch 32: 47.89543151855469, 1.0\n",
      "Train loss and acc of batch 33: 47.89542770385742, 1.0\n",
      "Train loss and acc of batch 34: 48.491119384765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.32893753051758, 0.96875\n",
      "Train loss and acc of batch 36: 47.8953971862793, 1.0\n",
      "Train loss and acc of batch 37: 48.64860916137695, 0.984375\n",
      "Train loss and acc of batch 38: 49.244300842285156, 0.96875\n",
      "Train loss and acc of batch 39: 48.11213684082031, 0.984375\n",
      "Train loss and acc of batch 40: 47.895362854003906, 1.0\n",
      "Train loss and acc of batch 41: 49.24427795410156, 0.96875\n",
      "Train loss and acc of batch 42: 47.89534378051758, 1.0\n",
      "Train loss and acc of batch 43: 48.49103546142578, 0.984375\n",
      "Train loss and acc of batch 44: 47.895328521728516, 1.0\n",
      "Train loss and acc of batch 45: 48.49102020263672, 0.984375\n",
      "Train loss and acc of batch 46: 48.18115997314453, 0.984375\n",
      "Train loss and acc of batch 47: 47.895301818847656, 1.0\n",
      "Train loss and acc of batch 48: 47.895294189453125, 1.0\n",
      "Train loss and acc of batch 49: 47.89527893066406, 1.0\n",
      "Train loss and acc of batch 50: 48.49097442626953, 0.984375\n",
      "Train loss and acc of batch 51: 49.24418640136719, 0.96875\n",
      "Train loss and acc of batch 52: 49.151092529296875, 0.953125\n",
      "Train loss and acc of batch 53: 47.89524459838867, 1.0\n",
      "Train loss and acc of batch 54: 48.11200714111328, 0.984375\n",
      "Train loss and acc of batch 55: 47.895225524902344, 1.0\n",
      "Train loss and acc of batch 56: 47.89522171020508, 1.0\n",
      "Train loss and acc of batch 57: 48.49090576171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.89520263671875, 1.0\n",
      "Train loss and acc of batch 59: 47.89519500732422, 1.0\n",
      "Train loss and acc of batch 60: 47.89518737792969, 1.0\n",
      "Train loss and acc of batch 61: 47.89517593383789, 1.0\n",
      "Train loss and acc of batch 62: 48.11193084716797, 0.984375\n",
      "Train loss and acc of batch 63: 49.08656311035156, 0.96875\n",
      "Train loss and acc of batch 64: 48.111907958984375, 0.984375\n",
      "Train loss and acc of batch 65: 47.895137786865234, 1.0\n",
      "Train loss and acc of batch 66: 47.89512252807617, 1.0\n",
      "Train loss and acc of batch 67: 48.707584381103516, 0.96875\n",
      "Train loss and acc of batch 68: 48.490814208984375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 48.11186218261719, 0.984375\n",
      "Train loss and acc of batch 70: 47.89509201049805, 1.0\n",
      "Training accuracy and loss of epoch #258: 0.9892, 48.2234\n",
      "Saved model by train loss 48.223368792466715\n",
      "Train loss and acc of batch 0: 47.895084381103516, 1.0\n",
      "Train loss and acc of batch 1: 47.89507293701172, 1.0\n",
      "Train loss and acc of batch 2: 48.18092346191406, 0.984375\n",
      "Train loss and acc of batch 3: 48.11181640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.895050048828125, 1.0\n",
      "Train loss and acc of batch 5: 49.24396514892578, 0.96875\n",
      "Train loss and acc of batch 6: 48.397647857666016, 0.96875\n",
      "Train loss and acc of batch 7: 47.89502716064453, 1.0\n",
      "Train loss and acc of batch 8: 48.49071502685547, 0.984375\n",
      "Train loss and acc of batch 9: 48.18085479736328, 0.984375\n",
      "Train loss and acc of batch 10: 47.89499282836914, 1.0\n",
      "Train loss and acc of batch 11: 47.89498519897461, 1.0\n",
      "Train loss and acc of batch 12: 48.648197174072266, 0.984375\n",
      "Train loss and acc of batch 13: 48.111732482910156, 0.984375\n",
      "Train loss and acc of batch 14: 48.111724853515625, 0.984375\n",
      "Train loss and acc of batch 15: 48.49064636230469, 0.984375\n",
      "Train loss and acc of batch 16: 48.490638732910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.648155212402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.7764778137207, 0.96875\n",
      "Train loss and acc of batch 19: 47.89491271972656, 1.0\n",
      "Train loss and acc of batch 20: 47.8949089050293, 1.0\n",
      "Train loss and acc of batch 21: 48.4906005859375, 0.984375\n",
      "Train loss and acc of batch 22: 48.49058532714844, 0.984375\n",
      "Train loss and acc of batch 23: 47.89487838745117, 1.0\n",
      "Train loss and acc of batch 24: 48.490570068359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.89485549926758, 1.0\n",
      "Train loss and acc of batch 26: 47.89484786987305, 1.0\n",
      "Train loss and acc of batch 27: 47.89484405517578, 1.0\n",
      "Train loss and acc of batch 28: 47.89483642578125, 1.0\n",
      "Train loss and acc of batch 29: 48.49052429199219, 0.984375\n",
      "Train loss and acc of batch 30: 47.894813537597656, 1.0\n",
      "Train loss and acc of batch 31: 48.111572265625, 0.984375\n",
      "Train loss and acc of batch 32: 47.894798278808594, 1.0\n",
      "Train loss and acc of batch 33: 47.89479064941406, 1.0\n",
      "Train loss and acc of batch 34: 48.490478515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.32830047607422, 0.96875\n",
      "Train loss and acc of batch 36: 47.8947639465332, 1.0\n",
      "Train loss and acc of batch 37: 48.647979736328125, 0.984375\n",
      "Train loss and acc of batch 38: 49.24366760253906, 0.96875\n",
      "Train loss and acc of batch 39: 48.11150360107422, 0.984375\n",
      "Train loss and acc of batch 40: 47.89472579956055, 1.0\n",
      "Train loss and acc of batch 41: 49.24364471435547, 0.96875\n",
      "Train loss and acc of batch 42: 47.89470672607422, 1.0\n",
      "Train loss and acc of batch 43: 48.49040222167969, 0.984375\n",
      "Train loss and acc of batch 44: 47.89468765258789, 1.0\n",
      "Train loss and acc of batch 45: 48.490379333496094, 0.984375\n",
      "Train loss and acc of batch 46: 48.18052673339844, 0.984375\n",
      "Train loss and acc of batch 47: 47.89466857910156, 1.0\n",
      "Train loss and acc of batch 48: 47.894657135009766, 1.0\n",
      "Train loss and acc of batch 49: 47.8946533203125, 1.0\n",
      "Train loss and acc of batch 50: 48.49034118652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.243553161621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.15045928955078, 0.953125\n",
      "Train loss and acc of batch 53: 47.894615173339844, 1.0\n",
      "Train loss and acc of batch 54: 48.111366271972656, 0.984375\n",
      "Train loss and acc of batch 55: 47.89459228515625, 1.0\n",
      "Train loss and acc of batch 56: 47.89458465576172, 1.0\n",
      "Train loss and acc of batch 57: 48.49028015136719, 0.984375\n",
      "Train loss and acc of batch 58: 47.89456558227539, 1.0\n",
      "Train loss and acc of batch 59: 47.894554138183594, 1.0\n",
      "Train loss and acc of batch 60: 47.89455032348633, 1.0\n",
      "Train loss and acc of batch 61: 47.8945426940918, 1.0\n",
      "Train loss and acc of batch 62: 48.111297607421875, 0.984375\n",
      "Train loss and acc of batch 63: 49.08592987060547, 0.96875\n",
      "Train loss and acc of batch 64: 48.11128234863281, 0.984375\n",
      "Train loss and acc of batch 65: 47.894508361816406, 1.0\n",
      "Train loss and acc of batch 66: 47.89449691772461, 1.0\n",
      "Train loss and acc of batch 67: 48.70695114135742, 0.96875\n",
      "Train loss and acc of batch 68: 48.49018096923828, 0.984375\n",
      "Train loss and acc of batch 69: 48.111228942871094, 0.984375\n",
      "Train loss and acc of batch 70: 47.89445877075195, 1.0\n",
      "Training accuracy and loss of epoch #259: 0.9892, 48.2227\n",
      "Saved model by train loss 48.22273426324549\n",
      "Train loss and acc of batch 0: 47.89445114135742, 1.0\n",
      "Train loss and acc of batch 1: 47.894439697265625, 1.0\n",
      "Train loss and acc of batch 2: 48.18028259277344, 0.984375\n",
      "Train loss and acc of batch 3: 48.11119079589844, 0.984375\n",
      "Train loss and acc of batch 4: 47.89441680908203, 1.0\n",
      "Train loss and acc of batch 5: 49.24333190917969, 0.96875\n",
      "Train loss and acc of batch 6: 48.39701843261719, 0.96875\n",
      "Train loss and acc of batch 7: 47.89439010620117, 1.0\n",
      "Train loss and acc of batch 8: 48.490081787109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.18022155761719, 0.984375\n",
      "Train loss and acc of batch 10: 47.89435958862305, 1.0\n",
      "Train loss and acc of batch 11: 47.89435577392578, 1.0\n",
      "Train loss and acc of batch 12: 48.64756774902344, 0.984375\n",
      "Train loss and acc of batch 13: 48.11109924316406, 0.984375\n",
      "Train loss and acc of batch 14: 48.11109161376953, 0.984375\n",
      "Train loss and acc of batch 15: 48.490020751953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.49000549316406, 0.984375\n",
      "Train loss and acc of batch 17: 48.64752197265625, 0.984375\n",
      "Train loss and acc of batch 18: 48.77584457397461, 0.96875\n",
      "Train loss and acc of batch 19: 47.894283294677734, 1.0\n",
      "Train loss and acc of batch 20: 47.8942756652832, 1.0\n",
      "Train loss and acc of batch 21: 48.489967346191406, 0.984375\n",
      "Train loss and acc of batch 22: 48.489959716796875, 0.984375\n",
      "Train loss and acc of batch 23: 47.89425277709961, 1.0\n",
      "Train loss and acc of batch 24: 48.48993682861328, 0.984375\n",
      "Train loss and acc of batch 25: 47.89422607421875, 1.0\n",
      "Train loss and acc of batch 26: 47.89421844482422, 1.0\n",
      "Train loss and acc of batch 27: 47.89420700073242, 1.0\n",
      "Train loss and acc of batch 28: 47.894203186035156, 1.0\n",
      "Train loss and acc of batch 29: 48.489891052246094, 0.984375\n",
      "Train loss and acc of batch 30: 47.89418411254883, 1.0\n",
      "Train loss and acc of batch 31: 48.110939025878906, 0.984375\n",
      "Train loss and acc of batch 32: 47.894168853759766, 1.0\n",
      "Train loss and acc of batch 33: 47.89415740966797, 1.0\n",
      "Train loss and acc of batch 34: 48.48985290527344, 0.984375\n",
      "Train loss and acc of batch 35: 48.327667236328125, 0.96875\n",
      "Train loss and acc of batch 36: 47.89413070678711, 1.0\n",
      "Train loss and acc of batch 37: 48.6473503112793, 0.984375\n",
      "Train loss and acc of batch 38: 49.24303436279297, 0.96875\n",
      "Train loss and acc of batch 39: 48.110870361328125, 0.984375\n",
      "Train loss and acc of batch 40: 47.89409255981445, 1.0\n",
      "Train loss and acc of batch 41: 49.243011474609375, 0.96875\n",
      "Train loss and acc of batch 42: 47.894081115722656, 1.0\n",
      "Train loss and acc of batch 43: 48.489768981933594, 0.984375\n",
      "Train loss and acc of batch 44: 47.89405822753906, 1.0\n",
      "Train loss and acc of batch 45: 48.48975372314453, 0.984375\n",
      "Train loss and acc of batch 46: 48.179893493652344, 0.984375\n",
      "Train loss and acc of batch 47: 47.8940315246582, 1.0\n",
      "Train loss and acc of batch 48: 47.89402770996094, 1.0\n",
      "Train loss and acc of batch 49: 47.894012451171875, 1.0\n",
      "Train loss and acc of batch 50: 48.489707946777344, 0.984375\n",
      "Train loss and acc of batch 51: 49.242919921875, 0.96875\n",
      "Train loss and acc of batch 52: 49.14982986450195, 0.953125\n",
      "Train loss and acc of batch 53: 47.89398193359375, 1.0\n",
      "Train loss and acc of batch 54: 48.11073303222656, 0.984375\n",
      "Train loss and acc of batch 55: 47.89396286010742, 1.0\n",
      "Train loss and acc of batch 56: 47.89395523071289, 1.0\n",
      "Train loss and acc of batch 57: 48.489646911621094, 0.984375\n",
      "Train loss and acc of batch 58: 47.89393615722656, 1.0\n",
      "Train loss and acc of batch 59: 47.89392852783203, 1.0\n",
      "Train loss and acc of batch 60: 47.893917083740234, 1.0\n",
      "Train loss and acc of batch 61: 47.8939094543457, 1.0\n",
      "Train loss and acc of batch 62: 48.11066436767578, 0.984375\n",
      "Train loss and acc of batch 63: 49.085289001464844, 0.96875\n",
      "Train loss and acc of batch 64: 48.11064910888672, 0.984375\n",
      "Train loss and acc of batch 65: 47.89387512207031, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 66: 47.893863677978516, 1.0\n",
      "Train loss and acc of batch 67: 48.70632553100586, 0.96875\n",
      "Train loss and acc of batch 68: 48.48954772949219, 0.984375\n",
      "Train loss and acc of batch 69: 48.11060333251953, 0.984375\n",
      "Train loss and acc of batch 70: 47.89383316040039, 1.0\n",
      "Training accuracy and loss of epoch #260: 0.9892, 48.2221\n",
      "Saved model by train loss 48.222102527887046\n",
      "Train loss and acc of batch 0: 47.89381790161133, 1.0\n",
      "Train loss and acc of batch 1: 47.89380645751953, 1.0\n",
      "Train loss and acc of batch 2: 48.179656982421875, 0.984375\n",
      "Train loss and acc of batch 3: 48.110557556152344, 0.984375\n",
      "Train loss and acc of batch 4: 47.8937873840332, 1.0\n",
      "Train loss and acc of batch 5: 49.242698669433594, 0.96875\n",
      "Train loss and acc of batch 6: 48.39638137817383, 0.96875\n",
      "Train loss and acc of batch 7: 47.89375686645508, 1.0\n",
      "Train loss and acc of batch 8: 48.48944854736328, 0.984375\n",
      "Train loss and acc of batch 9: 48.179588317871094, 0.984375\n",
      "Train loss and acc of batch 10: 47.893733978271484, 1.0\n",
      "Train loss and acc of batch 11: 47.89372253417969, 1.0\n",
      "Train loss and acc of batch 12: 48.64693832397461, 0.984375\n",
      "Train loss and acc of batch 13: 48.1104736328125, 0.984375\n",
      "Train loss and acc of batch 14: 48.11045837402344, 0.984375\n",
      "Train loss and acc of batch 15: 48.48938751220703, 0.984375\n",
      "Train loss and acc of batch 16: 48.4893798828125, 0.984375\n",
      "Train loss and acc of batch 17: 48.64689254760742, 0.984375\n",
      "Train loss and acc of batch 18: 48.77521896362305, 0.96875\n",
      "Train loss and acc of batch 19: 47.89365005493164, 1.0\n",
      "Train loss and acc of batch 20: 47.893638610839844, 1.0\n",
      "Train loss and acc of batch 21: 48.48933410644531, 0.984375\n",
      "Train loss and acc of batch 22: 48.48932647705078, 0.984375\n",
      "Train loss and acc of batch 23: 47.89361572265625, 1.0\n",
      "Train loss and acc of batch 24: 48.48931121826172, 0.984375\n",
      "Train loss and acc of batch 25: 47.89359664916992, 1.0\n",
      "Train loss and acc of batch 26: 47.89358901977539, 1.0\n",
      "Train loss and acc of batch 27: 47.89358139038086, 1.0\n",
      "Train loss and acc of batch 28: 47.8935661315918, 1.0\n",
      "Train loss and acc of batch 29: 48.48926544189453, 0.984375\n",
      "Train loss and acc of batch 30: 47.893550872802734, 1.0\n",
      "Train loss and acc of batch 31: 48.11030578613281, 0.984375\n",
      "Train loss and acc of batch 32: 47.89353942871094, 1.0\n",
      "Train loss and acc of batch 33: 47.89352798461914, 1.0\n",
      "Train loss and acc of batch 34: 48.48921203613281, 0.984375\n",
      "Train loss and acc of batch 35: 48.3270378112793, 0.96875\n",
      "Train loss and acc of batch 36: 47.893497467041016, 1.0\n",
      "Train loss and acc of batch 37: 48.64671325683594, 0.984375\n",
      "Train loss and acc of batch 38: 49.242408752441406, 0.96875\n",
      "Train loss and acc of batch 39: 48.11023712158203, 0.984375\n",
      "Train loss and acc of batch 40: 47.893463134765625, 1.0\n",
      "Train loss and acc of batch 41: 49.24238586425781, 0.96875\n",
      "Train loss and acc of batch 42: 47.8934440612793, 1.0\n",
      "Train loss and acc of batch 43: 48.4891357421875, 0.984375\n",
      "Train loss and acc of batch 44: 47.893428802490234, 1.0\n",
      "Train loss and acc of batch 45: 48.48912048339844, 0.984375\n",
      "Train loss and acc of batch 46: 48.17926025390625, 0.984375\n",
      "Train loss and acc of batch 47: 47.89339828491211, 1.0\n",
      "Train loss and acc of batch 48: 47.89339065551758, 1.0\n",
      "Train loss and acc of batch 49: 47.89338302612305, 1.0\n",
      "Train loss and acc of batch 50: 48.48907470703125, 0.984375\n",
      "Train loss and acc of batch 51: 49.242286682128906, 0.96875\n",
      "Train loss and acc of batch 52: 49.14919662475586, 0.953125\n",
      "Train loss and acc of batch 53: 47.89334487915039, 1.0\n",
      "Train loss and acc of batch 54: 48.110107421875, 0.984375\n",
      "Train loss and acc of batch 55: 47.89333724975586, 1.0\n",
      "Train loss and acc of batch 56: 47.8933219909668, 1.0\n",
      "Train loss and acc of batch 57: 48.489013671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.893306732177734, 1.0\n",
      "Train loss and acc of batch 59: 47.89329147338867, 1.0\n",
      "Train loss and acc of batch 60: 47.893287658691406, 1.0\n",
      "Train loss and acc of batch 61: 47.89327621459961, 1.0\n",
      "Train loss and acc of batch 62: 48.11003112792969, 0.984375\n",
      "Train loss and acc of batch 63: 49.084659576416016, 0.96875\n",
      "Train loss and acc of batch 64: 48.110008239746094, 0.984375\n",
      "Train loss and acc of batch 65: 47.89323806762695, 1.0\n",
      "Train loss and acc of batch 66: 47.89323425292969, 1.0\n",
      "Train loss and acc of batch 67: 48.7056884765625, 0.96875\n",
      "Train loss and acc of batch 68: 48.488914489746094, 0.984375\n",
      "Train loss and acc of batch 69: 48.10997772216797, 0.984375\n",
      "Train loss and acc of batch 70: 47.89319610595703, 1.0\n",
      "Training accuracy and loss of epoch #261: 0.9892, 48.2215\n",
      "Saved model by train loss 48.22147063134422\n",
      "Train loss and acc of batch 0: 47.893184661865234, 1.0\n",
      "Train loss and acc of batch 1: 47.893184661865234, 1.0\n",
      "Train loss and acc of batch 2: 48.17902374267578, 0.984375\n",
      "Train loss and acc of batch 3: 48.10992431640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.893157958984375, 1.0\n",
      "Train loss and acc of batch 5: 49.2420654296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.395751953125, 0.96875\n",
      "Train loss and acc of batch 7: 47.893123626708984, 1.0\n",
      "Train loss and acc of batch 8: 48.48881530761719, 0.984375\n",
      "Train loss and acc of batch 9: 48.17896270751953, 0.984375\n",
      "Train loss and acc of batch 10: 47.893096923828125, 1.0\n",
      "Train loss and acc of batch 11: 47.893089294433594, 1.0\n",
      "Train loss and acc of batch 12: 48.64630889892578, 0.984375\n",
      "Train loss and acc of batch 13: 48.109832763671875, 0.984375\n",
      "Train loss and acc of batch 14: 48.109825134277344, 0.984375\n",
      "Train loss and acc of batch 15: 48.48876190185547, 0.984375\n",
      "Train loss and acc of batch 16: 48.488746643066406, 0.984375\n",
      "Train loss and acc of batch 17: 48.64625930786133, 0.984375\n",
      "Train loss and acc of batch 18: 48.77458190917969, 0.96875\n",
      "Train loss and acc of batch 19: 47.89301681518555, 1.0\n",
      "Train loss and acc of batch 20: 47.89301300048828, 1.0\n",
      "Train loss and acc of batch 21: 48.48869323730469, 0.984375\n",
      "Train loss and acc of batch 22: 48.48869323730469, 0.984375\n",
      "Train loss and acc of batch 23: 47.892982482910156, 1.0\n",
      "Train loss and acc of batch 24: 48.488670349121094, 0.984375\n",
      "Train loss and acc of batch 25: 47.89296340942383, 1.0\n",
      "Train loss and acc of batch 26: 47.89295959472656, 1.0\n",
      "Train loss and acc of batch 27: 47.8929443359375, 1.0\n",
      "Train loss and acc of batch 28: 47.892940521240234, 1.0\n",
      "Train loss and acc of batch 29: 48.48863220214844, 0.984375\n",
      "Train loss and acc of batch 30: 47.892921447753906, 1.0\n",
      "Train loss and acc of batch 31: 48.10967254638672, 0.984375\n",
      "Train loss and acc of batch 32: 47.89290237426758, 1.0\n",
      "Train loss and acc of batch 33: 47.89289093017578, 1.0\n",
      "Train loss and acc of batch 34: 48.48858642578125, 0.984375\n",
      "Train loss and acc of batch 35: 48.3264045715332, 0.96875\n",
      "Train loss and acc of batch 36: 47.89286422729492, 1.0\n",
      "Train loss and acc of batch 37: 48.646080017089844, 0.984375\n",
      "Train loss and acc of batch 38: 49.24176788330078, 0.96875\n",
      "Train loss and acc of batch 39: 48.10960388183594, 0.984375\n",
      "Train loss and acc of batch 40: 47.89283752441406, 1.0\n",
      "Train loss and acc of batch 41: 49.24174880981445, 0.96875\n",
      "Train loss and acc of batch 42: 47.89281463623047, 1.0\n",
      "Train loss and acc of batch 43: 48.48851013183594, 0.984375\n",
      "Train loss and acc of batch 44: 47.89279556274414, 1.0\n",
      "Train loss and acc of batch 45: 48.488487243652344, 0.984375\n",
      "Train loss and acc of batch 46: 48.178627014160156, 0.984375\n",
      "Train loss and acc of batch 47: 47.89276885986328, 1.0\n",
      "Train loss and acc of batch 48: 47.892765045166016, 1.0\n",
      "Train loss and acc of batch 49: 47.89275360107422, 1.0\n",
      "Train loss and acc of batch 50: 48.488441467285156, 0.984375\n",
      "Train loss and acc of batch 51: 49.241661071777344, 0.96875\n",
      "Train loss and acc of batch 52: 49.148563385009766, 0.953125\n",
      "Train loss and acc of batch 53: 47.89271545410156, 1.0\n",
      "Train loss and acc of batch 54: 48.109474182128906, 0.984375\n",
      "Train loss and acc of batch 55: 47.892696380615234, 1.0\n",
      "Train loss and acc of batch 56: 47.8926887512207, 1.0\n",
      "Train loss and acc of batch 57: 48.48838806152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.89266586303711, 1.0\n",
      "Train loss and acc of batch 59: 47.892662048339844, 1.0\n",
      "Train loss and acc of batch 60: 47.89265823364258, 1.0\n",
      "Train loss and acc of batch 61: 47.892642974853516, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 62: 48.109405517578125, 0.984375\n",
      "Train loss and acc of batch 63: 49.08403015136719, 0.96875\n",
      "Train loss and acc of batch 64: 48.10938262939453, 0.984375\n",
      "Train loss and acc of batch 65: 47.892608642578125, 1.0\n",
      "Train loss and acc of batch 66: 47.89259719848633, 1.0\n",
      "Train loss and acc of batch 67: 48.705055236816406, 0.96875\n",
      "Train loss and acc of batch 68: 48.48828887939453, 0.984375\n",
      "Train loss and acc of batch 69: 48.109336853027344, 0.984375\n",
      "Train loss and acc of batch 70: 47.89256286621094, 1.0\n",
      "Training accuracy and loss of epoch #262: 0.9892, 48.2208\n",
      "Saved model by train loss 48.220838519888865\n",
      "Train loss and acc of batch 0: 47.89256286621094, 1.0\n",
      "Train loss and acc of batch 1: 47.89254379272461, 1.0\n",
      "Train loss and acc of batch 2: 48.17839050292969, 0.984375\n",
      "Train loss and acc of batch 3: 48.109291076660156, 0.984375\n",
      "Train loss and acc of batch 4: 47.89251708984375, 1.0\n",
      "Train loss and acc of batch 5: 49.24143981933594, 0.96875\n",
      "Train loss and acc of batch 6: 48.39512252807617, 0.96875\n",
      "Train loss and acc of batch 7: 47.892494201660156, 1.0\n",
      "Train loss and acc of batch 8: 48.488182067871094, 0.984375\n",
      "Train loss and acc of batch 9: 48.17832946777344, 0.984375\n",
      "Train loss and acc of batch 10: 47.8924674987793, 1.0\n",
      "Train loss and acc of batch 11: 47.892459869384766, 1.0\n",
      "Train loss and acc of batch 12: 48.645668029785156, 0.984375\n",
      "Train loss and acc of batch 13: 48.10920715332031, 0.984375\n",
      "Train loss and acc of batch 14: 48.10919952392578, 0.984375\n",
      "Train loss and acc of batch 15: 48.488121032714844, 0.984375\n",
      "Train loss and acc of batch 16: 48.48811340332031, 0.984375\n",
      "Train loss and acc of batch 17: 48.6456298828125, 0.984375\n",
      "Train loss and acc of batch 18: 48.773948669433594, 0.96875\n",
      "Train loss and acc of batch 19: 47.892391204833984, 1.0\n",
      "Train loss and acc of batch 20: 47.89237594604492, 1.0\n",
      "Train loss and acc of batch 21: 48.488067626953125, 0.984375\n",
      "Train loss and acc of batch 22: 48.488059997558594, 0.984375\n",
      "Train loss and acc of batch 23: 47.8923454284668, 1.0\n",
      "Train loss and acc of batch 24: 48.48804473876953, 0.984375\n",
      "Train loss and acc of batch 25: 47.892337799072266, 1.0\n",
      "Train loss and acc of batch 26: 47.8923225402832, 1.0\n",
      "Train loss and acc of batch 27: 47.89231491088867, 1.0\n",
      "Train loss and acc of batch 28: 47.892311096191406, 1.0\n",
      "Train loss and acc of batch 29: 48.487998962402344, 0.984375\n",
      "Train loss and acc of batch 30: 47.89228439331055, 1.0\n",
      "Train loss and acc of batch 31: 48.109046936035156, 0.984375\n",
      "Train loss and acc of batch 32: 47.892269134521484, 1.0\n",
      "Train loss and acc of batch 33: 47.89226150512695, 1.0\n",
      "Train loss and acc of batch 34: 48.487953186035156, 0.984375\n",
      "Train loss and acc of batch 35: 48.32577133178711, 0.96875\n",
      "Train loss and acc of batch 36: 47.892234802246094, 1.0\n",
      "Train loss and acc of batch 37: 48.64544677734375, 0.984375\n",
      "Train loss and acc of batch 38: 49.24114227294922, 0.96875\n",
      "Train loss and acc of batch 39: 48.108978271484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.89219665527344, 1.0\n",
      "Train loss and acc of batch 41: 49.24111557006836, 0.96875\n",
      "Train loss and acc of batch 42: 47.892181396484375, 1.0\n",
      "Train loss and acc of batch 43: 48.487876892089844, 0.984375\n",
      "Train loss and acc of batch 44: 47.89216613769531, 1.0\n",
      "Train loss and acc of batch 45: 48.48785400390625, 0.984375\n",
      "Train loss and acc of batch 46: 48.178001403808594, 0.984375\n",
      "Train loss and acc of batch 47: 47.89213943481445, 1.0\n",
      "Train loss and acc of batch 48: 47.892127990722656, 1.0\n",
      "Train loss and acc of batch 49: 47.89211654663086, 1.0\n",
      "Train loss and acc of batch 50: 48.487815856933594, 0.984375\n",
      "Train loss and acc of batch 51: 49.24102783203125, 0.96875\n",
      "Train loss and acc of batch 52: 49.14793395996094, 0.953125\n",
      "Train loss and acc of batch 53: 47.89208221435547, 1.0\n",
      "Train loss and acc of batch 54: 48.10884094238281, 0.984375\n",
      "Train loss and acc of batch 55: 47.89206314086914, 1.0\n",
      "Train loss and acc of batch 56: 47.89205551147461, 1.0\n",
      "Train loss and acc of batch 57: 48.48774719238281, 0.984375\n",
      "Train loss and acc of batch 58: 47.89204025268555, 1.0\n",
      "Train loss and acc of batch 59: 47.89202880859375, 1.0\n",
      "Train loss and acc of batch 60: 47.89202117919922, 1.0\n",
      "Train loss and acc of batch 61: 47.89201354980469, 1.0\n",
      "Train loss and acc of batch 62: 48.10877227783203, 0.984375\n",
      "Train loss and acc of batch 63: 49.08339309692383, 0.96875\n",
      "Train loss and acc of batch 64: 48.10874938964844, 0.984375\n",
      "Train loss and acc of batch 65: 47.8919792175293, 1.0\n",
      "Train loss and acc of batch 66: 47.891971588134766, 1.0\n",
      "Train loss and acc of batch 67: 48.70442199707031, 0.96875\n",
      "Train loss and acc of batch 68: 48.487648010253906, 0.984375\n",
      "Train loss and acc of batch 69: 48.10870361328125, 0.984375\n",
      "Train loss and acc of batch 70: 47.89193344116211, 1.0\n",
      "Training accuracy and loss of epoch #263: 0.9892, 48.2202\n",
      "Saved model by train loss 48.2202065696179\n",
      "Train loss and acc of batch 0: 47.89192199707031, 1.0\n",
      "Train loss and acc of batch 1: 47.89191436767578, 1.0\n",
      "Train loss and acc of batch 2: 48.177757263183594, 0.984375\n",
      "Train loss and acc of batch 3: 48.10865783691406, 0.984375\n",
      "Train loss and acc of batch 4: 47.89188766479492, 1.0\n",
      "Train loss and acc of batch 5: 49.240806579589844, 0.96875\n",
      "Train loss and acc of batch 6: 48.39448547363281, 0.96875\n",
      "Train loss and acc of batch 7: 47.89186096191406, 1.0\n",
      "Train loss and acc of batch 8: 48.487548828125, 0.984375\n",
      "Train loss and acc of batch 9: 48.177696228027344, 0.984375\n",
      "Train loss and acc of batch 10: 47.8918342590332, 1.0\n",
      "Train loss and acc of batch 11: 47.891822814941406, 1.0\n",
      "Train loss and acc of batch 12: 48.645042419433594, 0.984375\n",
      "Train loss and acc of batch 13: 48.10856628417969, 0.984375\n",
      "Train loss and acc of batch 14: 48.10856628417969, 0.984375\n",
      "Train loss and acc of batch 15: 48.48748779296875, 0.984375\n",
      "Train loss and acc of batch 16: 48.48748016357422, 0.984375\n",
      "Train loss and acc of batch 17: 48.64499282836914, 0.984375\n",
      "Train loss and acc of batch 18: 48.7733154296875, 0.96875\n",
      "Train loss and acc of batch 19: 47.891754150390625, 1.0\n",
      "Train loss and acc of batch 20: 47.89174270629883, 1.0\n",
      "Train loss and acc of batch 21: 48.48743438720703, 0.984375\n",
      "Train loss and acc of batch 22: 48.48743438720703, 0.984375\n",
      "Train loss and acc of batch 23: 47.891719818115234, 1.0\n",
      "Train loss and acc of batch 24: 48.48741149902344, 0.984375\n",
      "Train loss and acc of batch 25: 47.89169692993164, 1.0\n",
      "Train loss and acc of batch 26: 47.891693115234375, 1.0\n",
      "Train loss and acc of batch 27: 47.89168167114258, 1.0\n",
      "Train loss and acc of batch 28: 47.89167785644531, 1.0\n",
      "Train loss and acc of batch 29: 48.48736572265625, 0.984375\n",
      "Train loss and acc of batch 30: 47.89165496826172, 1.0\n",
      "Train loss and acc of batch 31: 48.10841369628906, 0.984375\n",
      "Train loss and acc of batch 32: 47.891639709472656, 1.0\n",
      "Train loss and acc of batch 33: 47.89162826538086, 1.0\n",
      "Train loss and acc of batch 34: 48.48731994628906, 0.984375\n",
      "Train loss and acc of batch 35: 48.32514190673828, 0.96875\n",
      "Train loss and acc of batch 36: 47.8916015625, 1.0\n",
      "Train loss and acc of batch 37: 48.64481735229492, 0.984375\n",
      "Train loss and acc of batch 38: 49.240509033203125, 0.96875\n",
      "Train loss and acc of batch 39: 48.10833740234375, 0.984375\n",
      "Train loss and acc of batch 40: 47.89156723022461, 1.0\n",
      "Train loss and acc of batch 41: 49.240482330322266, 0.96875\n",
      "Train loss and acc of batch 42: 47.89154815673828, 1.0\n",
      "Train loss and acc of batch 43: 48.48724365234375, 0.984375\n",
      "Train loss and acc of batch 44: 47.89152908325195, 1.0\n",
      "Train loss and acc of batch 45: 48.487220764160156, 0.984375\n",
      "Train loss and acc of batch 46: 48.17736053466797, 0.984375\n",
      "Train loss and acc of batch 47: 47.89150619506836, 1.0\n",
      "Train loss and acc of batch 48: 47.8914909362793, 1.0\n",
      "Train loss and acc of batch 49: 47.891483306884766, 1.0\n",
      "Train loss and acc of batch 50: 48.48717498779297, 0.984375\n",
      "Train loss and acc of batch 51: 49.240394592285156, 0.96875\n",
      "Train loss and acc of batch 52: 49.147300720214844, 0.953125\n",
      "Train loss and acc of batch 53: 47.891448974609375, 1.0\n",
      "Train loss and acc of batch 54: 48.10820770263672, 0.984375\n",
      "Train loss and acc of batch 55: 47.89143371582031, 1.0\n",
      "Train loss and acc of batch 56: 47.89142608642578, 1.0\n",
      "Train loss and acc of batch 57: 48.48712158203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.89140319824219, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 59: 47.89139938354492, 1.0\n",
      "Train loss and acc of batch 60: 47.89138412475586, 1.0\n",
      "Train loss and acc of batch 61: 47.891380310058594, 1.0\n",
      "Train loss and acc of batch 62: 48.108131408691406, 0.984375\n",
      "Train loss and acc of batch 63: 49.082763671875, 0.96875\n",
      "Train loss and acc of batch 64: 48.108116149902344, 0.984375\n",
      "Train loss and acc of batch 65: 47.8913459777832, 1.0\n",
      "Train loss and acc of batch 66: 47.891334533691406, 1.0\n",
      "Train loss and acc of batch 67: 48.703792572021484, 0.96875\n",
      "Train loss and acc of batch 68: 48.487022399902344, 0.984375\n",
      "Train loss and acc of batch 69: 48.108070373535156, 0.984375\n",
      "Train loss and acc of batch 70: 47.891300201416016, 1.0\n",
      "Training accuracy and loss of epoch #264: 0.9892, 48.2196\n",
      "Saved model by train loss 48.21957332987181\n",
      "Train loss and acc of batch 0: 47.89128875732422, 1.0\n",
      "Train loss and acc of batch 1: 47.89128112792969, 1.0\n",
      "Train loss and acc of batch 2: 48.17713165283203, 0.984375\n",
      "Train loss and acc of batch 3: 48.1080322265625, 0.984375\n",
      "Train loss and acc of batch 4: 47.89125442504883, 1.0\n",
      "Train loss and acc of batch 5: 49.24017333984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.39384841918945, 0.96875\n",
      "Train loss and acc of batch 7: 47.89122772216797, 1.0\n",
      "Train loss and acc of batch 8: 48.48692321777344, 0.984375\n",
      "Train loss and acc of batch 9: 48.17705535888672, 0.984375\n",
      "Train loss and acc of batch 10: 47.89120101928711, 1.0\n",
      "Train loss and acc of batch 11: 47.89119338989258, 1.0\n",
      "Train loss and acc of batch 12: 48.644405364990234, 0.984375\n",
      "Train loss and acc of batch 13: 48.107940673828125, 0.984375\n",
      "Train loss and acc of batch 14: 48.10792541503906, 0.984375\n",
      "Train loss and acc of batch 15: 48.486854553222656, 0.984375\n",
      "Train loss and acc of batch 16: 48.486846923828125, 0.984375\n",
      "Train loss and acc of batch 17: 48.64435958862305, 0.984375\n",
      "Train loss and acc of batch 18: 48.772682189941406, 0.96875\n",
      "Train loss and acc of batch 19: 47.891117095947266, 1.0\n",
      "Train loss and acc of batch 20: 47.891109466552734, 1.0\n",
      "Train loss and acc of batch 21: 48.48680877685547, 0.984375\n",
      "Train loss and acc of batch 22: 48.486793518066406, 0.984375\n",
      "Train loss and acc of batch 23: 47.89108657836914, 1.0\n",
      "Train loss and acc of batch 24: 48.486778259277344, 0.984375\n",
      "Train loss and acc of batch 25: 47.89107131958008, 1.0\n",
      "Train loss and acc of batch 26: 47.891056060791016, 1.0\n",
      "Train loss and acc of batch 27: 47.89105224609375, 1.0\n",
      "Train loss and acc of batch 28: 47.89104461669922, 1.0\n",
      "Train loss and acc of batch 29: 48.486732482910156, 0.984375\n",
      "Train loss and acc of batch 30: 47.89102554321289, 1.0\n",
      "Train loss and acc of batch 31: 48.10778045654297, 0.984375\n",
      "Train loss and acc of batch 32: 47.89100646972656, 1.0\n",
      "Train loss and acc of batch 33: 47.890995025634766, 1.0\n",
      "Train loss and acc of batch 34: 48.48668670654297, 0.984375\n",
      "Train loss and acc of batch 35: 48.32450866699219, 0.96875\n",
      "Train loss and acc of batch 36: 47.89097213745117, 1.0\n",
      "Train loss and acc of batch 37: 48.64418411254883, 0.984375\n",
      "Train loss and acc of batch 38: 49.23988342285156, 0.96875\n",
      "Train loss and acc of batch 39: 48.10771179199219, 0.984375\n",
      "Train loss and acc of batch 40: 47.89093017578125, 1.0\n",
      "Train loss and acc of batch 41: 49.23985290527344, 0.96875\n",
      "Train loss and acc of batch 42: 47.89092254638672, 1.0\n",
      "Train loss and acc of batch 43: 48.486602783203125, 0.984375\n",
      "Train loss and acc of batch 44: 47.890899658203125, 1.0\n",
      "Train loss and acc of batch 45: 48.486595153808594, 0.984375\n",
      "Train loss and acc of batch 46: 48.176734924316406, 0.984375\n",
      "Train loss and acc of batch 47: 47.890869140625, 1.0\n",
      "Train loss and acc of batch 48: 47.89086151123047, 1.0\n",
      "Train loss and acc of batch 49: 47.89085388183594, 1.0\n",
      "Train loss and acc of batch 50: 48.486549377441406, 0.984375\n",
      "Train loss and acc of batch 51: 49.23976135253906, 0.96875\n",
      "Train loss and acc of batch 52: 49.146671295166016, 0.953125\n",
      "Train loss and acc of batch 53: 47.89081954956055, 1.0\n",
      "Train loss and acc of batch 54: 48.107574462890625, 0.984375\n",
      "Train loss and acc of batch 55: 47.89080047607422, 1.0\n",
      "Train loss and acc of batch 56: 47.89079284667969, 1.0\n",
      "Train loss and acc of batch 57: 48.486480712890625, 0.984375\n",
      "Train loss and acc of batch 58: 47.890777587890625, 1.0\n",
      "Train loss and acc of batch 59: 47.89076614379883, 1.0\n",
      "Train loss and acc of batch 60: 47.8907585144043, 1.0\n",
      "Train loss and acc of batch 61: 47.8907470703125, 1.0\n",
      "Train loss and acc of batch 62: 48.10749816894531, 0.984375\n",
      "Train loss and acc of batch 63: 49.08213424682617, 0.96875\n",
      "Train loss and acc of batch 64: 48.10749053955078, 0.984375\n",
      "Train loss and acc of batch 65: 47.89071273803711, 1.0\n",
      "Train loss and acc of batch 66: 47.89070510864258, 1.0\n",
      "Train loss and acc of batch 67: 48.703163146972656, 0.96875\n",
      "Train loss and acc of batch 68: 48.48638153076172, 0.984375\n",
      "Train loss and acc of batch 69: 48.107444763183594, 0.984375\n",
      "Train loss and acc of batch 70: 47.89066696166992, 1.0\n",
      "Training accuracy and loss of epoch #265: 0.9892, 48.2189\n",
      "Saved model by train loss 48.21894154078524\n",
      "Train loss and acc of batch 0: 47.890655517578125, 1.0\n",
      "Train loss and acc of batch 1: 47.890647888183594, 1.0\n",
      "Train loss and acc of batch 2: 48.176490783691406, 0.984375\n",
      "Train loss and acc of batch 3: 48.107398986816406, 0.984375\n",
      "Train loss and acc of batch 4: 47.890625, 1.0\n",
      "Train loss and acc of batch 5: 49.239540100097656, 0.96875\n",
      "Train loss and acc of batch 6: 48.39322280883789, 0.96875\n",
      "Train loss and acc of batch 7: 47.89059829711914, 1.0\n",
      "Train loss and acc of batch 8: 48.486289978027344, 0.984375\n",
      "Train loss and acc of batch 9: 48.176429748535156, 0.984375\n",
      "Train loss and acc of batch 10: 47.89057540893555, 1.0\n",
      "Train loss and acc of batch 11: 47.890560150146484, 1.0\n",
      "Train loss and acc of batch 12: 48.643775939941406, 0.984375\n",
      "Train loss and acc of batch 13: 48.10730743408203, 0.984375\n",
      "Train loss and acc of batch 14: 48.10729217529297, 0.984375\n",
      "Train loss and acc of batch 15: 48.486228942871094, 0.984375\n",
      "Train loss and acc of batch 16: 48.48621368408203, 0.984375\n",
      "Train loss and acc of batch 17: 48.64373016357422, 0.984375\n",
      "Train loss and acc of batch 18: 48.77205276489258, 0.96875\n",
      "Train loss and acc of batch 19: 47.89048385620117, 1.0\n",
      "Train loss and acc of batch 20: 47.890480041503906, 1.0\n",
      "Train loss and acc of batch 21: 48.486175537109375, 0.984375\n",
      "Train loss and acc of batch 22: 48.48616027832031, 0.984375\n",
      "Train loss and acc of batch 23: 47.89045333862305, 1.0\n",
      "Train loss and acc of batch 24: 48.48615264892578, 0.984375\n",
      "Train loss and acc of batch 25: 47.890438079833984, 1.0\n",
      "Train loss and acc of batch 26: 47.89043045043945, 1.0\n",
      "Train loss and acc of batch 27: 47.890419006347656, 1.0\n",
      "Train loss and acc of batch 28: 47.890403747558594, 1.0\n",
      "Train loss and acc of batch 29: 48.48609924316406, 0.984375\n",
      "Train loss and acc of batch 30: 47.8903923034668, 1.0\n",
      "Train loss and acc of batch 31: 48.107147216796875, 0.984375\n",
      "Train loss and acc of batch 32: 47.89037322998047, 1.0\n",
      "Train loss and acc of batch 33: 47.89036560058594, 1.0\n",
      "Train loss and acc of batch 34: 48.486061096191406, 0.984375\n",
      "Train loss and acc of batch 35: 48.32387924194336, 0.96875\n",
      "Train loss and acc of batch 36: 47.89033508300781, 1.0\n",
      "Train loss and acc of batch 37: 48.6435546875, 0.984375\n",
      "Train loss and acc of batch 38: 49.23925018310547, 0.96875\n",
      "Train loss and acc of batch 39: 48.107078552246094, 0.984375\n",
      "Train loss and acc of batch 40: 47.89030456542969, 1.0\n",
      "Train loss and acc of batch 41: 49.23921585083008, 0.96875\n",
      "Train loss and acc of batch 42: 47.890281677246094, 1.0\n",
      "Train loss and acc of batch 43: 48.48597717285156, 0.984375\n",
      "Train loss and acc of batch 44: 47.8902702331543, 1.0\n",
      "Train loss and acc of batch 45: 48.4859619140625, 0.984375\n",
      "Train loss and acc of batch 46: 48.17610168457031, 0.984375\n",
      "Train loss and acc of batch 47: 47.890235900878906, 1.0\n",
      "Train loss and acc of batch 48: 47.89023208618164, 1.0\n",
      "Train loss and acc of batch 49: 47.89022445678711, 1.0\n",
      "Train loss and acc of batch 50: 48.48591613769531, 0.984375\n",
      "Train loss and acc of batch 51: 49.23912811279297, 0.96875\n",
      "Train loss and acc of batch 52: 49.146034240722656, 0.953125\n",
      "Train loss and acc of batch 53: 47.89018630981445, 1.0\n",
      "Train loss and acc of batch 54: 48.10694122314453, 0.984375\n",
      "Train loss and acc of batch 55: 47.89017105102539, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 56: 47.89015579223633, 1.0\n",
      "Train loss and acc of batch 57: 48.48585510253906, 0.984375\n",
      "Train loss and acc of batch 58: 47.89014434814453, 1.0\n",
      "Train loss and acc of batch 59: 47.890132904052734, 1.0\n",
      "Train loss and acc of batch 60: 47.8901252746582, 1.0\n",
      "Train loss and acc of batch 61: 47.89012145996094, 1.0\n",
      "Train loss and acc of batch 62: 48.10687255859375, 0.984375\n",
      "Train loss and acc of batch 63: 49.08150100708008, 0.96875\n",
      "Train loss and acc of batch 64: 48.106849670410156, 0.984375\n",
      "Train loss and acc of batch 65: 47.890079498291016, 1.0\n",
      "Train loss and acc of batch 66: 47.89007568359375, 1.0\n",
      "Train loss and acc of batch 67: 48.7025260925293, 0.96875\n",
      "Train loss and acc of batch 68: 48.485755920410156, 0.984375\n",
      "Train loss and acc of batch 69: 48.1068115234375, 0.984375\n",
      "Train loss and acc of batch 70: 47.89003372192383, 1.0\n",
      "Training accuracy and loss of epoch #266: 0.9892, 48.2183\n",
      "Saved model by train loss 48.21830975169867\n",
      "Train loss and acc of batch 0: 47.8900260925293, 1.0\n",
      "Train loss and acc of batch 1: 47.89002227783203, 1.0\n",
      "Train loss and acc of batch 2: 48.17585754394531, 0.984375\n",
      "Train loss and acc of batch 3: 48.10676574707031, 0.984375\n",
      "Train loss and acc of batch 4: 47.88998794555664, 1.0\n",
      "Train loss and acc of batch 5: 49.23890686035156, 0.96875\n",
      "Train loss and acc of batch 6: 48.39259338378906, 0.96875\n",
      "Train loss and acc of batch 7: 47.88996124267578, 1.0\n",
      "Train loss and acc of batch 8: 48.48565673828125, 0.984375\n",
      "Train loss and acc of batch 9: 48.175804138183594, 0.984375\n",
      "Train loss and acc of batch 10: 47.88993453979492, 1.0\n",
      "Train loss and acc of batch 11: 47.88993453979492, 1.0\n",
      "Train loss and acc of batch 12: 48.64314651489258, 0.984375\n",
      "Train loss and acc of batch 13: 48.10667419433594, 0.984375\n",
      "Train loss and acc of batch 14: 48.106666564941406, 0.984375\n",
      "Train loss and acc of batch 15: 48.485595703125, 0.984375\n",
      "Train loss and acc of batch 16: 48.48558807373047, 0.984375\n",
      "Train loss and acc of batch 17: 48.64310073852539, 0.984375\n",
      "Train loss and acc of batch 18: 48.771419525146484, 0.96875\n",
      "Train loss and acc of batch 19: 47.88985824584961, 1.0\n",
      "Train loss and acc of batch 20: 47.88985061645508, 1.0\n",
      "Train loss and acc of batch 21: 48.48553466796875, 0.984375\n",
      "Train loss and acc of batch 22: 48.48553466796875, 0.984375\n",
      "Train loss and acc of batch 23: 47.88982009887695, 1.0\n",
      "Train loss and acc of batch 24: 48.485511779785156, 0.984375\n",
      "Train loss and acc of batch 25: 47.889808654785156, 1.0\n",
      "Train loss and acc of batch 26: 47.889793395996094, 1.0\n",
      "Train loss and acc of batch 27: 47.88978576660156, 1.0\n",
      "Train loss and acc of batch 28: 47.8897819519043, 1.0\n",
      "Train loss and acc of batch 29: 48.48546600341797, 0.984375\n",
      "Train loss and acc of batch 30: 47.8897590637207, 1.0\n",
      "Train loss and acc of batch 31: 48.10651397705078, 0.984375\n",
      "Train loss and acc of batch 32: 47.889739990234375, 1.0\n",
      "Train loss and acc of batch 33: 47.88973617553711, 1.0\n",
      "Train loss and acc of batch 34: 48.48542785644531, 0.984375\n",
      "Train loss and acc of batch 35: 48.3232421875, 0.96875\n",
      "Train loss and acc of batch 36: 47.88970947265625, 1.0\n",
      "Train loss and acc of batch 37: 48.642921447753906, 0.984375\n",
      "Train loss and acc of batch 38: 49.238609313964844, 0.96875\n",
      "Train loss and acc of batch 39: 48.1064453125, 0.984375\n",
      "Train loss and acc of batch 40: 47.889671325683594, 1.0\n",
      "Train loss and acc of batch 41: 49.23858642578125, 0.96875\n",
      "Train loss and acc of batch 42: 47.8896598815918, 1.0\n",
      "Train loss and acc of batch 43: 48.48534393310547, 0.984375\n",
      "Train loss and acc of batch 44: 47.88963317871094, 1.0\n",
      "Train loss and acc of batch 45: 48.485328674316406, 0.984375\n",
      "Train loss and acc of batch 46: 48.17546844482422, 0.984375\n",
      "Train loss and acc of batch 47: 47.88960647583008, 1.0\n",
      "Train loss and acc of batch 48: 47.88959884643555, 1.0\n",
      "Train loss and acc of batch 49: 47.88958740234375, 1.0\n",
      "Train loss and acc of batch 50: 48.48528289794922, 0.984375\n",
      "Train loss and acc of batch 51: 49.238494873046875, 0.96875\n",
      "Train loss and acc of batch 52: 49.14540100097656, 0.953125\n",
      "Train loss and acc of batch 53: 47.889556884765625, 1.0\n",
      "Train loss and acc of batch 54: 48.10630798339844, 0.984375\n",
      "Train loss and acc of batch 55: 47.8895378112793, 1.0\n",
      "Train loss and acc of batch 56: 47.88953399658203, 1.0\n",
      "Train loss and acc of batch 57: 48.48521423339844, 0.984375\n",
      "Train loss and acc of batch 58: 47.88950729370117, 1.0\n",
      "Train loss and acc of batch 59: 47.889503479003906, 1.0\n",
      "Train loss and acc of batch 60: 47.889488220214844, 1.0\n",
      "Train loss and acc of batch 61: 47.88948440551758, 1.0\n",
      "Train loss and acc of batch 62: 48.106239318847656, 0.984375\n",
      "Train loss and acc of batch 63: 49.080867767333984, 0.96875\n",
      "Train loss and acc of batch 64: 48.106224060058594, 0.984375\n",
      "Train loss and acc of batch 65: 47.88944625854492, 1.0\n",
      "Train loss and acc of batch 66: 47.889434814453125, 1.0\n",
      "Train loss and acc of batch 67: 48.70189666748047, 0.96875\n",
      "Train loss and acc of batch 68: 48.48511505126953, 0.984375\n",
      "Train loss and acc of batch 69: 48.106178283691406, 0.984375\n",
      "Train loss and acc of batch 70: 47.889408111572266, 1.0\n",
      "Training accuracy and loss of epoch #267: 0.9892, 48.2177\n",
      "Saved model by train loss 48.21767747905892\n",
      "Train loss and acc of batch 0: 47.8893928527832, 1.0\n",
      "Train loss and acc of batch 1: 47.889381408691406, 1.0\n",
      "Train loss and acc of batch 2: 48.17523193359375, 0.984375\n",
      "Train loss and acc of batch 3: 48.10613250732422, 0.984375\n",
      "Train loss and acc of batch 4: 47.88935852050781, 1.0\n",
      "Train loss and acc of batch 5: 49.23827362060547, 0.96875\n",
      "Train loss and acc of batch 6: 48.3919563293457, 0.96875\n",
      "Train loss and acc of batch 7: 47.88933181762695, 1.0\n",
      "Train loss and acc of batch 8: 48.485023498535156, 0.984375\n",
      "Train loss and acc of batch 9: 48.17516326904297, 0.984375\n",
      "Train loss and acc of batch 10: 47.889305114746094, 1.0\n",
      "Train loss and acc of batch 11: 47.8892936706543, 1.0\n",
      "Train loss and acc of batch 12: 48.64250946044922, 0.984375\n",
      "Train loss and acc of batch 13: 48.106048583984375, 0.984375\n",
      "Train loss and acc of batch 14: 48.10603332519531, 0.984375\n",
      "Train loss and acc of batch 15: 48.484962463378906, 0.984375\n",
      "Train loss and acc of batch 16: 48.484954833984375, 0.984375\n",
      "Train loss and acc of batch 17: 48.6424674987793, 0.984375\n",
      "Train loss and acc of batch 18: 48.77078628540039, 0.96875\n",
      "Train loss and acc of batch 19: 47.88922882080078, 1.0\n",
      "Train loss and acc of batch 20: 47.88920974731445, 1.0\n",
      "Train loss and acc of batch 21: 48.48490905761719, 0.984375\n",
      "Train loss and acc of batch 22: 48.484901428222656, 0.984375\n",
      "Train loss and acc of batch 23: 47.88918685913086, 1.0\n",
      "Train loss and acc of batch 24: 48.48487854003906, 0.984375\n",
      "Train loss and acc of batch 25: 47.8891716003418, 1.0\n",
      "Train loss and acc of batch 26: 47.88916015625, 1.0\n",
      "Train loss and acc of batch 27: 47.889156341552734, 1.0\n",
      "Train loss and acc of batch 28: 47.88914108276367, 1.0\n",
      "Train loss and acc of batch 29: 48.484840393066406, 0.984375\n",
      "Train loss and acc of batch 30: 47.88913345336914, 1.0\n",
      "Train loss and acc of batch 31: 48.10588073730469, 0.984375\n",
      "Train loss and acc of batch 32: 47.88910675048828, 1.0\n",
      "Train loss and acc of batch 33: 47.88909912109375, 1.0\n",
      "Train loss and acc of batch 34: 48.48478698730469, 0.984375\n",
      "Train loss and acc of batch 35: 48.32261276245117, 0.96875\n",
      "Train loss and acc of batch 36: 47.88908004760742, 1.0\n",
      "Train loss and acc of batch 37: 48.64228820800781, 0.984375\n",
      "Train loss and acc of batch 38: 49.23797607421875, 0.96875\n",
      "Train loss and acc of batch 39: 48.105804443359375, 0.984375\n",
      "Train loss and acc of batch 40: 47.8890380859375, 1.0\n",
      "Train loss and acc of batch 41: 49.23796081542969, 0.96875\n",
      "Train loss and acc of batch 42: 47.88901901245117, 1.0\n",
      "Train loss and acc of batch 43: 48.484710693359375, 0.984375\n",
      "Train loss and acc of batch 44: 47.88900375366211, 1.0\n",
      "Train loss and acc of batch 45: 48.48469543457031, 0.984375\n",
      "Train loss and acc of batch 46: 48.174835205078125, 0.984375\n",
      "Train loss and acc of batch 47: 47.88897705078125, 1.0\n",
      "Train loss and acc of batch 48: 47.88896560668945, 1.0\n",
      "Train loss and acc of batch 49: 47.88895797729492, 1.0\n",
      "Train loss and acc of batch 50: 48.484649658203125, 0.984375\n",
      "Train loss and acc of batch 51: 49.23786163330078, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 52: 49.144771575927734, 0.953125\n",
      "Train loss and acc of batch 53: 47.888916015625, 1.0\n",
      "Train loss and acc of batch 54: 48.105674743652344, 0.984375\n",
      "Train loss and acc of batch 55: 47.88890838623047, 1.0\n",
      "Train loss and acc of batch 56: 47.888893127441406, 1.0\n",
      "Train loss and acc of batch 57: 48.484588623046875, 0.984375\n",
      "Train loss and acc of batch 58: 47.88888168334961, 1.0\n",
      "Train loss and acc of batch 59: 47.88886260986328, 1.0\n",
      "Train loss and acc of batch 60: 47.88886260986328, 1.0\n",
      "Train loss and acc of batch 61: 47.88884735107422, 1.0\n",
      "Train loss and acc of batch 62: 48.10560607910156, 0.984375\n",
      "Train loss and acc of batch 63: 49.080238342285156, 0.96875\n",
      "Train loss and acc of batch 64: 48.1055908203125, 0.984375\n",
      "Train loss and acc of batch 65: 47.88881301879883, 1.0\n",
      "Train loss and acc of batch 66: 47.88880920410156, 1.0\n",
      "Train loss and acc of batch 67: 48.70125961303711, 0.96875\n",
      "Train loss and acc of batch 68: 48.48448944091797, 0.984375\n",
      "Train loss and acc of batch 69: 48.10554504394531, 0.984375\n",
      "Train loss and acc of batch 70: 47.88876724243164, 1.0\n",
      "Training accuracy and loss of epoch #268: 0.9892, 48.2170\n",
      "Saved model by train loss 48.21704450795348\n",
      "Train loss and acc of batch 0: 47.88875961303711, 1.0\n",
      "Train loss and acc of batch 1: 47.88875961303711, 1.0\n",
      "Train loss and acc of batch 2: 48.174598693847656, 0.984375\n",
      "Train loss and acc of batch 3: 48.105506896972656, 0.984375\n",
      "Train loss and acc of batch 4: 47.88872528076172, 1.0\n",
      "Train loss and acc of batch 5: 49.237640380859375, 0.96875\n",
      "Train loss and acc of batch 6: 48.391326904296875, 0.96875\n",
      "Train loss and acc of batch 7: 47.888702392578125, 1.0\n",
      "Train loss and acc of batch 8: 48.48439025878906, 0.984375\n",
      "Train loss and acc of batch 9: 48.174537658691406, 0.984375\n",
      "Train loss and acc of batch 10: 47.888675689697266, 1.0\n",
      "Train loss and acc of batch 11: 47.88866424560547, 1.0\n",
      "Train loss and acc of batch 12: 48.64188003540039, 0.984375\n",
      "Train loss and acc of batch 13: 48.10540771484375, 0.984375\n",
      "Train loss and acc of batch 14: 48.10540008544922, 0.984375\n",
      "Train loss and acc of batch 15: 48.48432922363281, 0.984375\n",
      "Train loss and acc of batch 16: 48.48432159423828, 0.984375\n",
      "Train loss and acc of batch 17: 48.64183807373047, 0.984375\n",
      "Train loss and acc of batch 18: 48.7701530456543, 0.96875\n",
      "Train loss and acc of batch 19: 47.88859176635742, 1.0\n",
      "Train loss and acc of batch 20: 47.888587951660156, 1.0\n",
      "Train loss and acc of batch 21: 48.484283447265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.48426818847656, 0.984375\n",
      "Train loss and acc of batch 23: 47.88855743408203, 1.0\n",
      "Train loss and acc of batch 24: 48.48424530029297, 0.984375\n",
      "Train loss and acc of batch 25: 47.8885383605957, 1.0\n",
      "Train loss and acc of batch 26: 47.88853454589844, 1.0\n",
      "Train loss and acc of batch 27: 47.888519287109375, 1.0\n",
      "Train loss and acc of batch 28: 47.888511657714844, 1.0\n",
      "Train loss and acc of batch 29: 48.48420715332031, 0.984375\n",
      "Train loss and acc of batch 30: 47.88849639892578, 1.0\n",
      "Train loss and acc of batch 31: 48.105255126953125, 0.984375\n",
      "Train loss and acc of batch 32: 47.88847732543945, 1.0\n",
      "Train loss and acc of batch 33: 47.888465881347656, 1.0\n",
      "Train loss and acc of batch 34: 48.484161376953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.32197952270508, 0.96875\n",
      "Train loss and acc of batch 36: 47.88844680786133, 1.0\n",
      "Train loss and acc of batch 37: 48.641658782958984, 0.984375\n",
      "Train loss and acc of batch 38: 49.237342834472656, 0.96875\n",
      "Train loss and acc of batch 39: 48.10517883300781, 0.984375\n",
      "Train loss and acc of batch 40: 47.88840866088867, 1.0\n",
      "Train loss and acc of batch 41: 49.23731994628906, 0.96875\n",
      "Train loss and acc of batch 42: 47.888389587402344, 1.0\n",
      "Train loss and acc of batch 43: 48.48407745361328, 0.984375\n",
      "Train loss and acc of batch 44: 47.888370513916016, 1.0\n",
      "Train loss and acc of batch 45: 48.48406219482422, 0.984375\n",
      "Train loss and acc of batch 46: 48.17420196533203, 0.984375\n",
      "Train loss and acc of batch 47: 47.888343811035156, 1.0\n",
      "Train loss and acc of batch 48: 47.888336181640625, 1.0\n",
      "Train loss and acc of batch 49: 47.888328552246094, 1.0\n",
      "Train loss and acc of batch 50: 48.48401641845703, 0.984375\n",
      "Train loss and acc of batch 51: 49.23723602294922, 0.96875\n",
      "Train loss and acc of batch 52: 49.144142150878906, 0.953125\n",
      "Train loss and acc of batch 53: 47.88829040527344, 1.0\n",
      "Train loss and acc of batch 54: 48.10504150390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.888267517089844, 1.0\n",
      "Train loss and acc of batch 56: 47.88825988769531, 1.0\n",
      "Train loss and acc of batch 57: 48.48396301269531, 0.984375\n",
      "Train loss and acc of batch 58: 47.88824462890625, 1.0\n",
      "Train loss and acc of batch 59: 47.88823699951172, 1.0\n",
      "Train loss and acc of batch 60: 47.88822555541992, 1.0\n",
      "Train loss and acc of batch 61: 47.88821792602539, 1.0\n",
      "Train loss and acc of batch 62: 48.10497283935547, 0.984375\n",
      "Train loss and acc of batch 63: 49.07960510253906, 0.96875\n",
      "Train loss and acc of batch 64: 48.104957580566406, 0.984375\n",
      "Train loss and acc of batch 65: 47.888179779052734, 1.0\n",
      "Train loss and acc of batch 66: 47.88817596435547, 1.0\n",
      "Train loss and acc of batch 67: 48.70063400268555, 0.96875\n",
      "Train loss and acc of batch 68: 48.483856201171875, 0.984375\n",
      "Train loss and acc of batch 69: 48.10491943359375, 0.984375\n",
      "Train loss and acc of batch 70: 47.88813781738281, 1.0\n",
      "Training accuracy and loss of epoch #269: 0.9892, 48.2164\n",
      "Saved model by train loss 48.21641330987635\n",
      "Train loss and acc of batch 0: 47.88813018798828, 1.0\n",
      "Train loss and acc of batch 1: 47.88812255859375, 1.0\n",
      "Train loss and acc of batch 2: 48.17396545410156, 0.984375\n",
      "Train loss and acc of batch 3: 48.10486602783203, 0.984375\n",
      "Train loss and acc of batch 4: 47.88809585571289, 1.0\n",
      "Train loss and acc of batch 5: 49.23701477050781, 0.96875\n",
      "Train loss and acc of batch 6: 48.39069747924805, 0.96875\n",
      "Train loss and acc of batch 7: 47.88806915283203, 1.0\n",
      "Train loss and acc of batch 8: 48.48375701904297, 0.984375\n",
      "Train loss and acc of batch 9: 48.17390441894531, 0.984375\n",
      "Train loss and acc of batch 10: 47.88804244995117, 1.0\n",
      "Train loss and acc of batch 11: 47.88803482055664, 1.0\n",
      "Train loss and acc of batch 12: 48.64124298095703, 0.984375\n",
      "Train loss and acc of batch 13: 48.10478210449219, 0.984375\n",
      "Train loss and acc of batch 14: 48.104774475097656, 0.984375\n",
      "Train loss and acc of batch 15: 48.48369598388672, 0.984375\n",
      "Train loss and acc of batch 16: 48.48368835449219, 0.984375\n",
      "Train loss and acc of batch 17: 48.64120101928711, 0.984375\n",
      "Train loss and acc of batch 18: 48.76952362060547, 0.96875\n",
      "Train loss and acc of batch 19: 47.887962341308594, 1.0\n",
      "Train loss and acc of batch 20: 47.88795471191406, 1.0\n",
      "Train loss and acc of batch 21: 48.48365020751953, 0.984375\n",
      "Train loss and acc of batch 22: 48.48363494873047, 0.984375\n",
      "Train loss and acc of batch 23: 47.8879280090332, 1.0\n",
      "Train loss and acc of batch 24: 48.483619689941406, 0.984375\n",
      "Train loss and acc of batch 25: 47.887908935546875, 1.0\n",
      "Train loss and acc of batch 26: 47.887901306152344, 1.0\n",
      "Train loss and acc of batch 27: 47.88789367675781, 1.0\n",
      "Train loss and acc of batch 28: 47.887882232666016, 1.0\n",
      "Train loss and acc of batch 29: 48.48358154296875, 0.984375\n",
      "Train loss and acc of batch 30: 47.88786315917969, 1.0\n",
      "Train loss and acc of batch 31: 48.1046142578125, 0.984375\n",
      "Train loss and acc of batch 32: 47.887847900390625, 1.0\n",
      "Train loss and acc of batch 33: 47.887840270996094, 1.0\n",
      "Train loss and acc of batch 34: 48.48352813720703, 0.984375\n",
      "Train loss and acc of batch 35: 48.321353912353516, 0.96875\n",
      "Train loss and acc of batch 36: 47.88780975341797, 1.0\n",
      "Train loss and acc of batch 37: 48.64102554321289, 0.984375\n",
      "Train loss and acc of batch 38: 49.236717224121094, 0.96875\n",
      "Train loss and acc of batch 39: 48.10454559326172, 0.984375\n",
      "Train loss and acc of batch 40: 47.88777542114258, 1.0\n",
      "Train loss and acc of batch 41: 49.2366943359375, 0.96875\n",
      "Train loss and acc of batch 42: 47.88775634765625, 1.0\n",
      "Train loss and acc of batch 43: 48.48345184326172, 0.984375\n",
      "Train loss and acc of batch 44: 47.88773727416992, 1.0\n",
      "Train loss and acc of batch 45: 48.483428955078125, 0.984375\n",
      "Train loss and acc of batch 46: 48.17357635498047, 0.984375\n",
      "Train loss and acc of batch 47: 47.88771057128906, 1.0\n",
      "Train loss and acc of batch 48: 47.8877067565918, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 49: 47.887699127197266, 1.0\n",
      "Train loss and acc of batch 50: 48.48338317871094, 0.984375\n",
      "Train loss and acc of batch 51: 49.236602783203125, 0.96875\n",
      "Train loss and acc of batch 52: 49.14350891113281, 0.953125\n",
      "Train loss and acc of batch 53: 47.887657165527344, 1.0\n",
      "Train loss and acc of batch 54: 48.10441589355469, 0.984375\n",
      "Train loss and acc of batch 55: 47.887638092041016, 1.0\n",
      "Train loss and acc of batch 56: 47.88763427734375, 1.0\n",
      "Train loss and acc of batch 57: 48.48332977294922, 0.984375\n",
      "Train loss and acc of batch 58: 47.887611389160156, 1.0\n",
      "Train loss and acc of batch 59: 47.887603759765625, 1.0\n",
      "Train loss and acc of batch 60: 47.88759994506836, 1.0\n",
      "Train loss and acc of batch 61: 47.8875846862793, 1.0\n",
      "Train loss and acc of batch 62: 48.104347229003906, 0.984375\n",
      "Train loss and acc of batch 63: 49.078975677490234, 0.96875\n",
      "Train loss and acc of batch 64: 48.10432434082031, 0.984375\n",
      "Train loss and acc of batch 65: 47.887550354003906, 1.0\n",
      "Train loss and acc of batch 66: 47.887542724609375, 1.0\n",
      "Train loss and acc of batch 67: 48.69999694824219, 0.96875\n",
      "Train loss and acc of batch 68: 48.48323059082031, 0.984375\n",
      "Train loss and acc of batch 69: 48.104278564453125, 0.984375\n",
      "Train loss and acc of batch 70: 47.887508392333984, 1.0\n",
      "Training accuracy and loss of epoch #270: 0.9892, 48.2158\n",
      "Saved model by train loss 48.215782165527344\n",
      "Train loss and acc of batch 0: 47.88750076293945, 1.0\n",
      "Train loss and acc of batch 1: 47.88748550415039, 1.0\n",
      "Train loss and acc of batch 2: 48.17333221435547, 0.984375\n",
      "Train loss and acc of batch 3: 48.10423278808594, 0.984375\n",
      "Train loss and acc of batch 4: 47.8874626159668, 1.0\n",
      "Train loss and acc of batch 5: 49.23638153076172, 0.96875\n",
      "Train loss and acc of batch 6: 48.39006042480469, 0.96875\n",
      "Train loss and acc of batch 7: 47.88743209838867, 1.0\n",
      "Train loss and acc of batch 8: 48.483123779296875, 0.984375\n",
      "Train loss and acc of batch 9: 48.17326354980469, 0.984375\n",
      "Train loss and acc of batch 10: 47.88740539550781, 1.0\n",
      "Train loss and acc of batch 11: 47.88739776611328, 1.0\n",
      "Train loss and acc of batch 12: 48.64060974121094, 0.984375\n",
      "Train loss and acc of batch 13: 48.10414123535156, 0.984375\n",
      "Train loss and acc of batch 14: 48.10413360595703, 0.984375\n",
      "Train loss and acc of batch 15: 48.483062744140625, 0.984375\n",
      "Train loss and acc of batch 16: 48.483055114746094, 0.984375\n",
      "Train loss and acc of batch 17: 48.640567779541016, 0.984375\n",
      "Train loss and acc of batch 18: 48.76888656616211, 0.96875\n",
      "Train loss and acc of batch 19: 47.887325286865234, 1.0\n",
      "Train loss and acc of batch 20: 47.8873176574707, 1.0\n",
      "Train loss and acc of batch 21: 48.483009338378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.483001708984375, 0.984375\n",
      "Train loss and acc of batch 23: 47.88728713989258, 1.0\n",
      "Train loss and acc of batch 24: 48.48297882080078, 0.984375\n",
      "Train loss and acc of batch 25: 47.88727569580078, 1.0\n",
      "Train loss and acc of batch 26: 47.88725662231445, 1.0\n",
      "Train loss and acc of batch 27: 47.88725662231445, 1.0\n",
      "Train loss and acc of batch 28: 47.887245178222656, 1.0\n",
      "Train loss and acc of batch 29: 48.482940673828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.88722610473633, 1.0\n",
      "Train loss and acc of batch 31: 48.103981018066406, 0.984375\n",
      "Train loss and acc of batch 32: 47.88720703125, 1.0\n",
      "Train loss and acc of batch 33: 47.887203216552734, 1.0\n",
      "Train loss and acc of batch 34: 48.48289489746094, 0.984375\n",
      "Train loss and acc of batch 35: 48.32071304321289, 0.96875\n",
      "Train loss and acc of batch 36: 47.887176513671875, 1.0\n",
      "Train loss and acc of batch 37: 48.6403923034668, 0.984375\n",
      "Train loss and acc of batch 38: 49.23607635498047, 0.96875\n",
      "Train loss and acc of batch 39: 48.103912353515625, 0.984375\n",
      "Train loss and acc of batch 40: 47.88713455200195, 1.0\n",
      "Train loss and acc of batch 41: 49.23605728149414, 0.96875\n",
      "Train loss and acc of batch 42: 47.88712692260742, 1.0\n",
      "Train loss and acc of batch 43: 48.482810974121094, 0.984375\n",
      "Train loss and acc of batch 44: 47.88710403442383, 1.0\n",
      "Train loss and acc of batch 45: 48.48279571533203, 0.984375\n",
      "Train loss and acc of batch 46: 48.172935485839844, 0.984375\n",
      "Train loss and acc of batch 47: 47.88707733154297, 1.0\n",
      "Train loss and acc of batch 48: 47.88706588745117, 1.0\n",
      "Train loss and acc of batch 49: 47.887054443359375, 1.0\n",
      "Train loss and acc of batch 50: 48.482749938964844, 0.984375\n",
      "Train loss and acc of batch 51: 49.23596954345703, 0.96875\n",
      "Train loss and acc of batch 52: 49.14287185668945, 0.953125\n",
      "Train loss and acc of batch 53: 47.88702392578125, 1.0\n",
      "Train loss and acc of batch 54: 48.103782653808594, 0.984375\n",
      "Train loss and acc of batch 55: 47.88700485229492, 1.0\n",
      "Train loss and acc of batch 56: 47.887001037597656, 1.0\n",
      "Train loss and acc of batch 57: 48.482688903808594, 0.984375\n",
      "Train loss and acc of batch 58: 47.88697814941406, 1.0\n",
      "Train loss and acc of batch 59: 47.88697052001953, 1.0\n",
      "Train loss and acc of batch 60: 47.886959075927734, 1.0\n",
      "Train loss and acc of batch 61: 47.88695526123047, 1.0\n",
      "Train loss and acc of batch 62: 48.10370635986328, 0.984375\n",
      "Train loss and acc of batch 63: 49.078330993652344, 0.96875\n",
      "Train loss and acc of batch 64: 48.10369110107422, 0.984375\n",
      "Train loss and acc of batch 65: 47.88691711425781, 1.0\n",
      "Train loss and acc of batch 66: 47.886905670166016, 1.0\n",
      "Train loss and acc of batch 67: 48.699363708496094, 0.96875\n",
      "Train loss and acc of batch 68: 48.48258972167969, 0.984375\n",
      "Train loss and acc of batch 69: 48.10364532470703, 0.984375\n",
      "Train loss and acc of batch 70: 47.88687515258789, 1.0\n",
      "Training accuracy and loss of epoch #271: 0.9892, 48.2151\n",
      "Saved model by train loss 48.21514586327781\n",
      "Train loss and acc of batch 0: 47.88686752319336, 1.0\n",
      "Train loss and acc of batch 1: 47.88685607910156, 1.0\n",
      "Train loss and acc of batch 2: 48.172691345214844, 0.984375\n",
      "Train loss and acc of batch 3: 48.103599548339844, 0.984375\n",
      "Train loss and acc of batch 4: 47.88682556152344, 1.0\n",
      "Train loss and acc of batch 5: 49.235748291015625, 0.96875\n",
      "Train loss and acc of batch 6: 48.38942337036133, 0.96875\n",
      "Train loss and acc of batch 7: 47.886802673339844, 1.0\n",
      "Train loss and acc of batch 8: 48.48249053955078, 0.984375\n",
      "Train loss and acc of batch 9: 48.172637939453125, 0.984375\n",
      "Train loss and acc of batch 10: 47.88677215576172, 1.0\n",
      "Train loss and acc of batch 11: 47.88676452636719, 1.0\n",
      "Train loss and acc of batch 12: 48.63998031616211, 0.984375\n",
      "Train loss and acc of batch 13: 48.103515625, 0.984375\n",
      "Train loss and acc of batch 14: 48.10350036621094, 0.984375\n",
      "Train loss and acc of batch 15: 48.48242950439453, 0.984375\n",
      "Train loss and acc of batch 16: 48.482421875, 0.984375\n",
      "Train loss and acc of batch 17: 48.63993453979492, 0.984375\n",
      "Train loss and acc of batch 18: 48.76825714111328, 0.96875\n",
      "Train loss and acc of batch 19: 47.886695861816406, 1.0\n",
      "Train loss and acc of batch 20: 47.886680603027344, 1.0\n",
      "Train loss and acc of batch 21: 48.48237609863281, 0.984375\n",
      "Train loss and acc of batch 22: 48.48236846923828, 0.984375\n",
      "Train loss and acc of batch 23: 47.88665771484375, 1.0\n",
      "Train loss and acc of batch 24: 48.48235321044922, 0.984375\n",
      "Train loss and acc of batch 25: 47.886634826660156, 1.0\n",
      "Train loss and acc of batch 26: 47.88663101196289, 1.0\n",
      "Train loss and acc of batch 27: 47.886627197265625, 1.0\n",
      "Train loss and acc of batch 28: 47.88661193847656, 1.0\n",
      "Train loss and acc of batch 29: 48.48230743408203, 0.984375\n",
      "Train loss and acc of batch 30: 47.886600494384766, 1.0\n",
      "Train loss and acc of batch 31: 48.10334777832031, 0.984375\n",
      "Train loss and acc of batch 32: 47.88657760620117, 1.0\n",
      "Train loss and acc of batch 33: 47.88656997680664, 1.0\n",
      "Train loss and acc of batch 34: 48.482261657714844, 0.984375\n",
      "Train loss and acc of batch 35: 48.3200798034668, 0.96875\n",
      "Train loss and acc of batch 36: 47.88654708862305, 1.0\n",
      "Train loss and acc of batch 37: 48.63975524902344, 0.984375\n",
      "Train loss and acc of batch 38: 49.235450744628906, 0.96875\n",
      "Train loss and acc of batch 39: 48.10327911376953, 0.984375\n",
      "Train loss and acc of batch 40: 47.88650894165039, 1.0\n",
      "Train loss and acc of batch 41: 49.23542404174805, 0.96875\n",
      "Train loss and acc of batch 42: 47.8864860534668, 1.0\n",
      "Train loss and acc of batch 43: 48.482177734375, 0.984375\n",
      "Train loss and acc of batch 44: 47.886470794677734, 1.0\n",
      "Train loss and acc of batch 45: 48.48216247558594, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 46: 48.17230987548828, 0.984375\n",
      "Train loss and acc of batch 47: 47.886444091796875, 1.0\n",
      "Train loss and acc of batch 48: 47.88643264770508, 1.0\n",
      "Train loss and acc of batch 49: 47.88642501831055, 1.0\n",
      "Train loss and acc of batch 50: 48.48211669921875, 0.984375\n",
      "Train loss and acc of batch 51: 49.23533630371094, 0.96875\n",
      "Train loss and acc of batch 52: 49.142242431640625, 0.953125\n",
      "Train loss and acc of batch 53: 47.886390686035156, 1.0\n",
      "Train loss and acc of batch 54: 48.1031494140625, 0.984375\n",
      "Train loss and acc of batch 55: 47.88637161254883, 1.0\n",
      "Train loss and acc of batch 56: 47.8863639831543, 1.0\n",
      "Train loss and acc of batch 57: 48.4820556640625, 0.984375\n",
      "Train loss and acc of batch 58: 47.88634490966797, 1.0\n",
      "Train loss and acc of batch 59: 47.88633728027344, 1.0\n",
      "Train loss and acc of batch 60: 47.88633346557617, 1.0\n",
      "Train loss and acc of batch 61: 47.88631820678711, 1.0\n",
      "Train loss and acc of batch 62: 48.10307312011719, 0.984375\n",
      "Train loss and acc of batch 63: 49.07770919799805, 0.96875\n",
      "Train loss and acc of batch 64: 48.103057861328125, 0.984375\n",
      "Train loss and acc of batch 65: 47.88628387451172, 1.0\n",
      "Train loss and acc of batch 66: 47.88627624511719, 1.0\n",
      "Train loss and acc of batch 67: 48.698734283447266, 0.96875\n",
      "Train loss and acc of batch 68: 48.481964111328125, 0.984375\n",
      "Train loss and acc of batch 69: 48.10301208496094, 0.984375\n",
      "Train loss and acc of batch 70: 47.88623809814453, 1.0\n",
      "Training accuracy and loss of epoch #272: 0.9892, 48.2145\n",
      "Saved model by train loss 48.21451385927872\n",
      "Train loss and acc of batch 0: 47.886234283447266, 1.0\n",
      "Train loss and acc of batch 1: 47.8862190246582, 1.0\n",
      "Train loss and acc of batch 2: 48.17207336425781, 0.984375\n",
      "Train loss and acc of batch 3: 48.10296630859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.886192321777344, 1.0\n",
      "Train loss and acc of batch 5: 49.235107421875, 0.96875\n",
      "Train loss and acc of batch 6: 48.3887939453125, 0.96875\n",
      "Train loss and acc of batch 7: 47.88616943359375, 1.0\n",
      "Train loss and acc of batch 8: 48.48185729980469, 0.984375\n",
      "Train loss and acc of batch 9: 48.17200469970703, 0.984375\n",
      "Train loss and acc of batch 10: 47.886138916015625, 1.0\n",
      "Train loss and acc of batch 11: 47.88613510131836, 1.0\n",
      "Train loss and acc of batch 12: 48.63935089111328, 0.984375\n",
      "Train loss and acc of batch 13: 48.102882385253906, 0.984375\n",
      "Train loss and acc of batch 14: 48.102867126464844, 0.984375\n",
      "Train loss and acc of batch 15: 48.48179626464844, 0.984375\n",
      "Train loss and acc of batch 16: 48.481788635253906, 0.984375\n",
      "Train loss and acc of batch 17: 48.639305114746094, 0.984375\n",
      "Train loss and acc of batch 18: 48.76762390136719, 0.96875\n",
      "Train loss and acc of batch 19: 47.88606262207031, 1.0\n",
      "Train loss and acc of batch 20: 47.88605499267578, 1.0\n",
      "Train loss and acc of batch 21: 48.48175048828125, 0.984375\n",
      "Train loss and acc of batch 22: 48.48173522949219, 0.984375\n",
      "Train loss and acc of batch 23: 47.88602828979492, 1.0\n",
      "Train loss and acc of batch 24: 48.481719970703125, 0.984375\n",
      "Train loss and acc of batch 25: 47.88601303100586, 1.0\n",
      "Train loss and acc of batch 26: 47.8859977722168, 1.0\n",
      "Train loss and acc of batch 27: 47.885982513427734, 1.0\n",
      "Train loss and acc of batch 28: 47.88597869873047, 1.0\n",
      "Train loss and acc of batch 29: 48.48167419433594, 0.984375\n",
      "Train loss and acc of batch 30: 47.885963439941406, 1.0\n",
      "Train loss and acc of batch 31: 48.10272216796875, 0.984375\n",
      "Train loss and acc of batch 32: 47.88594436645508, 1.0\n",
      "Train loss and acc of batch 33: 47.88593673706055, 1.0\n",
      "Train loss and acc of batch 34: 48.48162841796875, 0.984375\n",
      "Train loss and acc of batch 35: 48.3194465637207, 0.96875\n",
      "Train loss and acc of batch 36: 47.88591003417969, 1.0\n",
      "Train loss and acc of batch 37: 48.63912582397461, 0.984375\n",
      "Train loss and acc of batch 38: 49.23481750488281, 0.96875\n",
      "Train loss and acc of batch 39: 48.10265350341797, 0.984375\n",
      "Train loss and acc of batch 40: 47.88587188720703, 1.0\n",
      "Train loss and acc of batch 41: 49.23479080200195, 0.96875\n",
      "Train loss and acc of batch 42: 47.88585662841797, 1.0\n",
      "Train loss and acc of batch 43: 48.481544494628906, 0.984375\n",
      "Train loss and acc of batch 44: 47.88583755493164, 1.0\n",
      "Train loss and acc of batch 45: 48.481529235839844, 0.984375\n",
      "Train loss and acc of batch 46: 48.17167663574219, 0.984375\n",
      "Train loss and acc of batch 47: 47.88581085205078, 1.0\n",
      "Train loss and acc of batch 48: 47.88580322265625, 1.0\n",
      "Train loss and acc of batch 49: 47.88579559326172, 1.0\n",
      "Train loss and acc of batch 50: 48.481483459472656, 0.984375\n",
      "Train loss and acc of batch 51: 49.234703063964844, 0.96875\n",
      "Train loss and acc of batch 52: 49.14160919189453, 0.953125\n",
      "Train loss and acc of batch 53: 47.88576126098633, 1.0\n",
      "Train loss and acc of batch 54: 48.102516174316406, 0.984375\n",
      "Train loss and acc of batch 55: 47.8857421875, 1.0\n",
      "Train loss and acc of batch 56: 47.8857307434082, 1.0\n",
      "Train loss and acc of batch 57: 48.48143005371094, 0.984375\n",
      "Train loss and acc of batch 58: 47.88571548461914, 1.0\n",
      "Train loss and acc of batch 59: 47.885704040527344, 1.0\n",
      "Train loss and acc of batch 60: 47.88569641113281, 1.0\n",
      "Train loss and acc of batch 61: 47.885684967041016, 1.0\n",
      "Train loss and acc of batch 62: 48.102447509765625, 0.984375\n",
      "Train loss and acc of batch 63: 49.07706832885742, 0.96875\n",
      "Train loss and acc of batch 64: 48.10242462158203, 0.984375\n",
      "Train loss and acc of batch 65: 47.885650634765625, 1.0\n",
      "Train loss and acc of batch 66: 47.88564682006836, 1.0\n",
      "Train loss and acc of batch 67: 48.69810104370117, 0.96875\n",
      "Train loss and acc of batch 68: 48.48133087158203, 0.984375\n",
      "Train loss and acc of batch 69: 48.102378845214844, 0.984375\n",
      "Train loss and acc of batch 70: 47.88560485839844, 1.0\n",
      "Training accuracy and loss of epoch #273: 0.9892, 48.2139\n",
      "Saved model by train loss 48.213881694095235\n",
      "Train loss and acc of batch 0: 47.885597229003906, 1.0\n",
      "Train loss and acc of batch 1: 47.885589599609375, 1.0\n",
      "Train loss and acc of batch 2: 48.17143249511719, 0.984375\n",
      "Train loss and acc of batch 3: 48.102333068847656, 0.984375\n",
      "Train loss and acc of batch 4: 47.885562896728516, 1.0\n",
      "Train loss and acc of batch 5: 49.23448181152344, 0.96875\n",
      "Train loss and acc of batch 6: 48.38816452026367, 0.96875\n",
      "Train loss and acc of batch 7: 47.88553237915039, 1.0\n",
      "Train loss and acc of batch 8: 48.481231689453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.17137145996094, 0.984375\n",
      "Train loss and acc of batch 10: 47.8855094909668, 1.0\n",
      "Train loss and acc of batch 11: 47.885501861572266, 1.0\n",
      "Train loss and acc of batch 12: 48.63871765136719, 0.984375\n",
      "Train loss and acc of batch 13: 48.10224151611328, 0.984375\n",
      "Train loss and acc of batch 14: 48.10224151611328, 0.984375\n",
      "Train loss and acc of batch 15: 48.481163024902344, 0.984375\n",
      "Train loss and acc of batch 16: 48.48115539550781, 0.984375\n",
      "Train loss and acc of batch 17: 48.638668060302734, 0.984375\n",
      "Train loss and acc of batch 18: 48.766990661621094, 0.96875\n",
      "Train loss and acc of batch 19: 47.885433197021484, 1.0\n",
      "Train loss and acc of batch 20: 47.88541793823242, 1.0\n",
      "Train loss and acc of batch 21: 48.481109619140625, 0.984375\n",
      "Train loss and acc of batch 22: 48.481109619140625, 0.984375\n",
      "Train loss and acc of batch 23: 47.88539123535156, 1.0\n",
      "Train loss and acc of batch 24: 48.48108673095703, 0.984375\n",
      "Train loss and acc of batch 25: 47.885379791259766, 1.0\n",
      "Train loss and acc of batch 26: 47.8853645324707, 1.0\n",
      "Train loss and acc of batch 27: 47.88536071777344, 1.0\n",
      "Train loss and acc of batch 28: 47.88535690307617, 1.0\n",
      "Train loss and acc of batch 29: 48.481040954589844, 0.984375\n",
      "Train loss and acc of batch 30: 47.88533020019531, 1.0\n",
      "Train loss and acc of batch 31: 48.102081298828125, 0.984375\n",
      "Train loss and acc of batch 32: 47.88531494140625, 1.0\n",
      "Train loss and acc of batch 33: 47.88530731201172, 1.0\n",
      "Train loss and acc of batch 34: 48.480995178222656, 0.984375\n",
      "Train loss and acc of batch 35: 48.31881332397461, 0.96875\n",
      "Train loss and acc of batch 36: 47.88528060913086, 1.0\n",
      "Train loss and acc of batch 37: 48.638492584228516, 0.984375\n",
      "Train loss and acc of batch 38: 49.23418426513672, 0.96875\n",
      "Train loss and acc of batch 39: 48.102020263671875, 0.984375\n",
      "Train loss and acc of batch 40: 47.8852424621582, 1.0\n",
      "Train loss and acc of batch 41: 49.234161376953125, 0.96875\n",
      "Train loss and acc of batch 42: 47.885231018066406, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 43: 48.480918884277344, 0.984375\n",
      "Train loss and acc of batch 44: 47.88520431518555, 1.0\n",
      "Train loss and acc of batch 45: 48.48089599609375, 0.984375\n",
      "Train loss and acc of batch 46: 48.17103576660156, 0.984375\n",
      "Train loss and acc of batch 47: 47.88518142700195, 1.0\n",
      "Train loss and acc of batch 48: 47.885169982910156, 1.0\n",
      "Train loss and acc of batch 49: 47.88516616821289, 1.0\n",
      "Train loss and acc of batch 50: 48.480857849121094, 0.984375\n",
      "Train loss and acc of batch 51: 49.23406982421875, 0.96875\n",
      "Train loss and acc of batch 52: 49.14097595214844, 0.953125\n",
      "Train loss and acc of batch 53: 47.885128021240234, 1.0\n",
      "Train loss and acc of batch 54: 48.10187530517578, 0.984375\n",
      "Train loss and acc of batch 55: 47.88511276245117, 1.0\n",
      "Train loss and acc of batch 56: 47.88510513305664, 1.0\n",
      "Train loss and acc of batch 57: 48.480796813964844, 0.984375\n",
      "Train loss and acc of batch 58: 47.88507843017578, 1.0\n",
      "Train loss and acc of batch 59: 47.885074615478516, 1.0\n",
      "Train loss and acc of batch 60: 47.88506317138672, 1.0\n",
      "Train loss and acc of batch 61: 47.88505935668945, 1.0\n",
      "Train loss and acc of batch 62: 48.10181427001953, 0.984375\n",
      "Train loss and acc of batch 63: 49.076438903808594, 0.96875\n",
      "Train loss and acc of batch 64: 48.10179138183594, 0.984375\n",
      "Train loss and acc of batch 65: 47.88501739501953, 1.0\n",
      "Train loss and acc of batch 66: 47.885009765625, 1.0\n",
      "Train loss and acc of batch 67: 48.69746780395508, 0.96875\n",
      "Train loss and acc of batch 68: 48.480690002441406, 0.984375\n",
      "Train loss and acc of batch 69: 48.10174560546875, 0.984375\n",
      "Train loss and acc of batch 70: 47.88497543334961, 1.0\n",
      "Training accuracy and loss of epoch #274: 0.9892, 48.2132\n",
      "Saved model by train loss 48.21324947518362\n",
      "Train loss and acc of batch 0: 47.88496780395508, 1.0\n",
      "Train loss and acc of batch 1: 47.88495635986328, 1.0\n",
      "Train loss and acc of batch 2: 48.17079162597656, 0.984375\n",
      "Train loss and acc of batch 3: 48.10169982910156, 0.984375\n",
      "Train loss and acc of batch 4: 47.88493347167969, 1.0\n",
      "Train loss and acc of batch 5: 49.233848571777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.38753128051758, 0.96875\n",
      "Train loss and acc of batch 7: 47.88490676879883, 1.0\n",
      "Train loss and acc of batch 8: 48.4805908203125, 0.984375\n",
      "Train loss and acc of batch 9: 48.170738220214844, 0.984375\n",
      "Train loss and acc of batch 10: 47.8848762512207, 1.0\n",
      "Train loss and acc of batch 11: 47.88486862182617, 1.0\n",
      "Train loss and acc of batch 12: 48.638084411621094, 0.984375\n",
      "Train loss and acc of batch 13: 48.10161590576172, 0.984375\n",
      "Train loss and acc of batch 14: 48.10160827636719, 0.984375\n",
      "Train loss and acc of batch 15: 48.48052978515625, 0.984375\n",
      "Train loss and acc of batch 16: 48.48052215576172, 0.984375\n",
      "Train loss and acc of batch 17: 48.638038635253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.766361236572266, 0.96875\n",
      "Train loss and acc of batch 19: 47.884796142578125, 1.0\n",
      "Train loss and acc of batch 20: 47.88478469848633, 1.0\n",
      "Train loss and acc of batch 21: 48.48048400878906, 0.984375\n",
      "Train loss and acc of batch 22: 48.48046875, 0.984375\n",
      "Train loss and acc of batch 23: 47.884765625, 1.0\n",
      "Train loss and acc of batch 24: 48.48045349121094, 0.984375\n",
      "Train loss and acc of batch 25: 47.884742736816406, 1.0\n",
      "Train loss and acc of batch 26: 47.884735107421875, 1.0\n",
      "Train loss and acc of batch 27: 47.884727478027344, 1.0\n",
      "Train loss and acc of batch 28: 47.88471603393555, 1.0\n",
      "Train loss and acc of batch 29: 48.48041534423828, 0.984375\n",
      "Train loss and acc of batch 30: 47.88469314575195, 1.0\n",
      "Train loss and acc of batch 31: 48.10145568847656, 0.984375\n",
      "Train loss and acc of batch 32: 47.88468551635742, 1.0\n",
      "Train loss and acc of batch 33: 47.884674072265625, 1.0\n",
      "Train loss and acc of batch 34: 48.48036193847656, 0.984375\n",
      "Train loss and acc of batch 35: 48.31818771362305, 0.96875\n",
      "Train loss and acc of batch 36: 47.8846435546875, 1.0\n",
      "Train loss and acc of batch 37: 48.63785934448242, 0.984375\n",
      "Train loss and acc of batch 38: 49.233558654785156, 0.96875\n",
      "Train loss and acc of batch 39: 48.10137939453125, 0.984375\n",
      "Train loss and acc of batch 40: 47.884613037109375, 1.0\n",
      "Train loss and acc of batch 41: 49.2335319519043, 0.96875\n",
      "Train loss and acc of batch 42: 47.88459396362305, 1.0\n",
      "Train loss and acc of batch 43: 48.48029327392578, 0.984375\n",
      "Train loss and acc of batch 44: 47.88457489013672, 1.0\n",
      "Train loss and acc of batch 45: 48.480262756347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.17041015625, 0.984375\n",
      "Train loss and acc of batch 47: 47.884544372558594, 1.0\n",
      "Train loss and acc of batch 48: 47.88454055786133, 1.0\n",
      "Train loss and acc of batch 49: 47.8845329284668, 1.0\n",
      "Train loss and acc of batch 50: 48.480224609375, 0.984375\n",
      "Train loss and acc of batch 51: 49.23344421386719, 0.96875\n",
      "Train loss and acc of batch 52: 49.140342712402344, 0.953125\n",
      "Train loss and acc of batch 53: 47.884490966796875, 1.0\n",
      "Train loss and acc of batch 54: 48.10124969482422, 0.984375\n",
      "Train loss and acc of batch 55: 47.88447570800781, 1.0\n",
      "Train loss and acc of batch 56: 47.88447189331055, 1.0\n",
      "Train loss and acc of batch 57: 48.48016357421875, 0.984375\n",
      "Train loss and acc of batch 58: 47.88444900512695, 1.0\n",
      "Train loss and acc of batch 59: 47.884437561035156, 1.0\n",
      "Train loss and acc of batch 60: 47.884437561035156, 1.0\n",
      "Train loss and acc of batch 61: 47.88441848754883, 1.0\n",
      "Train loss and acc of batch 62: 48.10118103027344, 0.984375\n",
      "Train loss and acc of batch 63: 49.075809478759766, 0.96875\n",
      "Train loss and acc of batch 64: 48.101158142089844, 0.984375\n",
      "Train loss and acc of batch 65: 47.8843879699707, 1.0\n",
      "Train loss and acc of batch 66: 47.884376525878906, 1.0\n",
      "Train loss and acc of batch 67: 48.696834564208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.480064392089844, 0.984375\n",
      "Train loss and acc of batch 69: 48.10111999511719, 0.984375\n",
      "Train loss and acc of batch 70: 47.88434600830078, 1.0\n",
      "Training accuracy and loss of epoch #275: 0.9892, 48.2126\n",
      "Saved model by train loss 48.21261747118453\n",
      "Train loss and acc of batch 0: 47.88433837890625, 1.0\n",
      "Train loss and acc of batch 1: 47.88432312011719, 1.0\n",
      "Train loss and acc of batch 2: 48.17017364501953, 0.984375\n",
      "Train loss and acc of batch 3: 48.10107421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.88429260253906, 1.0\n",
      "Train loss and acc of batch 5: 49.23320770263672, 0.96875\n",
      "Train loss and acc of batch 6: 48.38690185546875, 0.96875\n",
      "Train loss and acc of batch 7: 47.88426971435547, 1.0\n",
      "Train loss and acc of batch 8: 48.47996520996094, 0.984375\n",
      "Train loss and acc of batch 9: 48.17010498046875, 0.984375\n",
      "Train loss and acc of batch 10: 47.88424301147461, 1.0\n",
      "Train loss and acc of batch 11: 47.88423538208008, 1.0\n",
      "Train loss and acc of batch 12: 48.637451171875, 0.984375\n",
      "Train loss and acc of batch 13: 48.100982666015625, 0.984375\n",
      "Train loss and acc of batch 14: 48.100982666015625, 0.984375\n",
      "Train loss and acc of batch 15: 48.479896545410156, 0.984375\n",
      "Train loss and acc of batch 16: 48.479896545410156, 0.984375\n",
      "Train loss and acc of batch 17: 48.63740921020508, 0.984375\n",
      "Train loss and acc of batch 18: 48.76572799682617, 0.96875\n",
      "Train loss and acc of batch 19: 47.88416290283203, 1.0\n",
      "Train loss and acc of batch 20: 47.884159088134766, 1.0\n",
      "Train loss and acc of batch 21: 48.47984313964844, 0.984375\n",
      "Train loss and acc of batch 22: 48.47984313964844, 0.984375\n",
      "Train loss and acc of batch 23: 47.88412857055664, 1.0\n",
      "Train loss and acc of batch 24: 48.479820251464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.88411331176758, 1.0\n",
      "Train loss and acc of batch 26: 47.88410568237305, 1.0\n",
      "Train loss and acc of batch 27: 47.88409423828125, 1.0\n",
      "Train loss and acc of batch 28: 47.884090423583984, 1.0\n",
      "Train loss and acc of batch 29: 48.479774475097656, 0.984375\n",
      "Train loss and acc of batch 30: 47.884071350097656, 1.0\n",
      "Train loss and acc of batch 31: 48.10082244873047, 0.984375\n",
      "Train loss and acc of batch 32: 47.88404846191406, 1.0\n",
      "Train loss and acc of batch 33: 47.88404083251953, 1.0\n",
      "Train loss and acc of batch 34: 48.479736328125, 0.984375\n",
      "Train loss and acc of batch 35: 48.31755447387695, 0.96875\n",
      "Train loss and acc of batch 36: 47.88401794433594, 1.0\n",
      "Train loss and acc of batch 37: 48.637229919433594, 0.984375\n",
      "Train loss and acc of batch 38: 49.23291778564453, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 39: 48.10075378417969, 0.984375\n",
      "Train loss and acc of batch 40: 47.883975982666016, 1.0\n",
      "Train loss and acc of batch 41: 49.2328987121582, 0.96875\n",
      "Train loss and acc of batch 42: 47.88396072387695, 1.0\n",
      "Train loss and acc of batch 43: 48.479652404785156, 0.984375\n",
      "Train loss and acc of batch 44: 47.88394546508789, 1.0\n",
      "Train loss and acc of batch 45: 48.479637145996094, 0.984375\n",
      "Train loss and acc of batch 46: 48.169776916503906, 0.984375\n",
      "Train loss and acc of batch 47: 47.883914947509766, 1.0\n",
      "Train loss and acc of batch 48: 47.88390350341797, 1.0\n",
      "Train loss and acc of batch 49: 47.88389587402344, 1.0\n",
      "Train loss and acc of batch 50: 48.479591369628906, 0.984375\n",
      "Train loss and acc of batch 51: 49.23280334472656, 0.96875\n",
      "Train loss and acc of batch 52: 49.13970947265625, 0.953125\n",
      "Train loss and acc of batch 53: 47.88386154174805, 1.0\n",
      "Train loss and acc of batch 54: 48.100616455078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.883846282958984, 1.0\n",
      "Train loss and acc of batch 56: 47.88383483886719, 1.0\n",
      "Train loss and acc of batch 57: 48.479530334472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.883819580078125, 1.0\n",
      "Train loss and acc of batch 59: 47.88381576538086, 1.0\n",
      "Train loss and acc of batch 60: 47.8838005065918, 1.0\n",
      "Train loss and acc of batch 61: 47.883792877197266, 1.0\n",
      "Train loss and acc of batch 62: 48.100547790527344, 0.984375\n",
      "Train loss and acc of batch 63: 49.075172424316406, 0.96875\n",
      "Train loss and acc of batch 64: 48.10053253173828, 0.984375\n",
      "Train loss and acc of batch 65: 47.88375473022461, 1.0\n",
      "Train loss and acc of batch 66: 47.88374710083008, 1.0\n",
      "Train loss and acc of batch 67: 48.69620132446289, 0.96875\n",
      "Train loss and acc of batch 68: 48.47943115234375, 0.984375\n",
      "Train loss and acc of batch 69: 48.100486755371094, 0.984375\n",
      "Train loss and acc of batch 70: 47.88371276855469, 1.0\n",
      "Training accuracy and loss of epoch #276: 0.9892, 48.2120\n",
      "Saved model by train loss 48.211985574641695\n",
      "Train loss and acc of batch 0: 47.883697509765625, 1.0\n",
      "Train loss and acc of batch 1: 47.883697509765625, 1.0\n",
      "Train loss and acc of batch 2: 48.16954040527344, 0.984375\n",
      "Train loss and acc of batch 3: 48.100440979003906, 0.984375\n",
      "Train loss and acc of batch 4: 47.8836669921875, 1.0\n",
      "Train loss and acc of batch 5: 49.232582092285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.386260986328125, 0.96875\n",
      "Train loss and acc of batch 7: 47.88364028930664, 1.0\n",
      "Train loss and acc of batch 8: 48.479331970214844, 0.984375\n",
      "Train loss and acc of batch 9: 48.169471740722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.88361740112305, 1.0\n",
      "Train loss and acc of batch 11: 47.883602142333984, 1.0\n",
      "Train loss and acc of batch 12: 48.636817932128906, 0.984375\n",
      "Train loss and acc of batch 13: 48.10034942626953, 0.984375\n",
      "Train loss and acc of batch 14: 48.100341796875, 0.984375\n",
      "Train loss and acc of batch 15: 48.479270935058594, 0.984375\n",
      "Train loss and acc of batch 16: 48.47926330566406, 0.984375\n",
      "Train loss and acc of batch 17: 48.63676834106445, 0.984375\n",
      "Train loss and acc of batch 18: 48.76509475708008, 0.96875\n",
      "Train loss and acc of batch 19: 47.8835334777832, 1.0\n",
      "Train loss and acc of batch 20: 47.883522033691406, 1.0\n",
      "Train loss and acc of batch 21: 48.479217529296875, 0.984375\n",
      "Train loss and acc of batch 22: 48.479209899902344, 0.984375\n",
      "Train loss and acc of batch 23: 47.88349533081055, 1.0\n",
      "Train loss and acc of batch 24: 48.47918701171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.883480072021484, 1.0\n",
      "Train loss and acc of batch 26: 47.88347244262695, 1.0\n",
      "Train loss and acc of batch 27: 47.883460998535156, 1.0\n",
      "Train loss and acc of batch 28: 47.883453369140625, 1.0\n",
      "Train loss and acc of batch 29: 48.479148864746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.88343811035156, 1.0\n",
      "Train loss and acc of batch 31: 48.100189208984375, 0.984375\n",
      "Train loss and acc of batch 32: 47.883419036865234, 1.0\n",
      "Train loss and acc of batch 33: 47.8834114074707, 1.0\n",
      "Train loss and acc of batch 34: 48.479095458984375, 0.984375\n",
      "Train loss and acc of batch 35: 48.316925048828125, 0.96875\n",
      "Train loss and acc of batch 36: 47.88338088989258, 1.0\n",
      "Train loss and acc of batch 37: 48.636592864990234, 0.984375\n",
      "Train loss and acc of batch 38: 49.23229217529297, 0.96875\n",
      "Train loss and acc of batch 39: 48.100120544433594, 0.984375\n",
      "Train loss and acc of batch 40: 47.88334655761719, 1.0\n",
      "Train loss and acc of batch 41: 49.232261657714844, 0.96875\n",
      "Train loss and acc of batch 42: 47.88332748413086, 1.0\n",
      "Train loss and acc of batch 43: 48.47901916503906, 0.984375\n",
      "Train loss and acc of batch 44: 47.88331604003906, 1.0\n",
      "Train loss and acc of batch 45: 48.47900390625, 0.984375\n",
      "Train loss and acc of batch 46: 48.169151306152344, 0.984375\n",
      "Train loss and acc of batch 47: 47.88328552246094, 1.0\n",
      "Train loss and acc of batch 48: 47.883270263671875, 1.0\n",
      "Train loss and acc of batch 49: 47.883270263671875, 1.0\n",
      "Train loss and acc of batch 50: 48.47895812988281, 0.984375\n",
      "Train loss and acc of batch 51: 49.23217010498047, 0.96875\n",
      "Train loss and acc of batch 52: 49.13908004760742, 0.953125\n",
      "Train loss and acc of batch 53: 47.88322830200195, 1.0\n",
      "Train loss and acc of batch 54: 48.09999084472656, 0.984375\n",
      "Train loss and acc of batch 55: 47.88321304321289, 1.0\n",
      "Train loss and acc of batch 56: 47.883201599121094, 1.0\n",
      "Train loss and acc of batch 57: 48.47889709472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.88318634033203, 1.0\n",
      "Train loss and acc of batch 59: 47.8831787109375, 1.0\n",
      "Train loss and acc of batch 60: 47.88317108154297, 1.0\n",
      "Train loss and acc of batch 61: 47.88315963745117, 1.0\n",
      "Train loss and acc of batch 62: 48.09991455078125, 0.984375\n",
      "Train loss and acc of batch 63: 49.074546813964844, 0.96875\n",
      "Train loss and acc of batch 64: 48.099891662597656, 0.984375\n",
      "Train loss and acc of batch 65: 47.883121490478516, 1.0\n",
      "Train loss and acc of batch 66: 47.88311767578125, 1.0\n",
      "Train loss and acc of batch 67: 48.69557189941406, 0.96875\n",
      "Train loss and acc of batch 68: 48.478797912597656, 0.984375\n",
      "Train loss and acc of batch 69: 48.09984588623047, 0.984375\n",
      "Train loss and acc of batch 70: 47.88307571411133, 1.0\n",
      "Training accuracy and loss of epoch #277: 0.9892, 48.2114\n",
      "Saved model by train loss 48.211353140817565\n",
      "Train loss and acc of batch 0: 47.88307189941406, 1.0\n",
      "Train loss and acc of batch 1: 47.88306427001953, 1.0\n",
      "Train loss and acc of batch 2: 48.168907165527344, 0.984375\n",
      "Train loss and acc of batch 3: 48.09980773925781, 0.984375\n",
      "Train loss and acc of batch 4: 47.88303756713867, 1.0\n",
      "Train loss and acc of batch 5: 49.23194885253906, 0.96875\n",
      "Train loss and acc of batch 6: 48.38563537597656, 0.96875\n",
      "Train loss and acc of batch 7: 47.88300323486328, 1.0\n",
      "Train loss and acc of batch 8: 48.47869873046875, 0.984375\n",
      "Train loss and acc of batch 9: 48.16883850097656, 0.984375\n",
      "Train loss and acc of batch 10: 47.88298034667969, 1.0\n",
      "Train loss and acc of batch 11: 47.882972717285156, 1.0\n",
      "Train loss and acc of batch 12: 48.63618469238281, 0.984375\n",
      "Train loss and acc of batch 13: 48.09971618652344, 0.984375\n",
      "Train loss and acc of batch 14: 48.099708557128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.4786376953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.47863006591797, 0.984375\n",
      "Train loss and acc of batch 17: 48.63614273071289, 0.984375\n",
      "Train loss and acc of batch 18: 48.764469146728516, 0.96875\n",
      "Train loss and acc of batch 19: 47.88290023803711, 1.0\n",
      "Train loss and acc of batch 20: 47.882896423339844, 1.0\n",
      "Train loss and acc of batch 21: 48.47858428955078, 0.984375\n",
      "Train loss and acc of batch 22: 48.47856903076172, 0.984375\n",
      "Train loss and acc of batch 23: 47.88286590576172, 1.0\n",
      "Train loss and acc of batch 24: 48.478553771972656, 0.984375\n",
      "Train loss and acc of batch 25: 47.882850646972656, 1.0\n",
      "Train loss and acc of batch 26: 47.882835388183594, 1.0\n",
      "Train loss and acc of batch 27: 47.88282775878906, 1.0\n",
      "Train loss and acc of batch 28: 47.88282012939453, 1.0\n",
      "Train loss and acc of batch 29: 48.478515625, 0.984375\n",
      "Train loss and acc of batch 30: 47.8828010559082, 1.0\n",
      "Train loss and acc of batch 31: 48.09956359863281, 0.984375\n",
      "Train loss and acc of batch 32: 47.88278579711914, 1.0\n",
      "Train loss and acc of batch 33: 47.88277816772461, 1.0\n",
      "Train loss and acc of batch 34: 48.47846984863281, 0.984375\n",
      "Train loss and acc of batch 35: 48.3162841796875, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 36: 47.882747650146484, 1.0\n",
      "Train loss and acc of batch 37: 48.635963439941406, 0.984375\n",
      "Train loss and acc of batch 38: 49.231651306152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.0994873046875, 0.984375\n",
      "Train loss and acc of batch 40: 47.882713317871094, 1.0\n",
      "Train loss and acc of batch 41: 49.231632232666016, 0.96875\n",
      "Train loss and acc of batch 42: 47.882694244384766, 1.0\n",
      "Train loss and acc of batch 43: 48.47838592529297, 0.984375\n",
      "Train loss and acc of batch 44: 47.88267517089844, 1.0\n",
      "Train loss and acc of batch 45: 48.478370666503906, 0.984375\n",
      "Train loss and acc of batch 46: 48.16851806640625, 0.984375\n",
      "Train loss and acc of batch 47: 47.882652282714844, 1.0\n",
      "Train loss and acc of batch 48: 47.88264846801758, 1.0\n",
      "Train loss and acc of batch 49: 47.882633209228516, 1.0\n",
      "Train loss and acc of batch 50: 48.47832489013672, 0.984375\n",
      "Train loss and acc of batch 51: 49.231544494628906, 0.96875\n",
      "Train loss and acc of batch 52: 49.138450622558594, 0.953125\n",
      "Train loss and acc of batch 53: 47.882598876953125, 1.0\n",
      "Train loss and acc of batch 54: 48.09935760498047, 0.984375\n",
      "Train loss and acc of batch 55: 47.8825798034668, 1.0\n",
      "Train loss and acc of batch 56: 47.882572174072266, 1.0\n",
      "Train loss and acc of batch 57: 48.47826385498047, 0.984375\n",
      "Train loss and acc of batch 58: 47.88255310058594, 1.0\n",
      "Train loss and acc of batch 59: 47.882545471191406, 1.0\n",
      "Train loss and acc of batch 60: 47.882537841796875, 1.0\n",
      "Train loss and acc of batch 61: 47.88252639770508, 1.0\n",
      "Train loss and acc of batch 62: 48.09928894042969, 0.984375\n",
      "Train loss and acc of batch 63: 49.07391357421875, 0.96875\n",
      "Train loss and acc of batch 64: 48.099266052246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.88249206542969, 1.0\n",
      "Train loss and acc of batch 66: 47.882484436035156, 1.0\n",
      "Train loss and acc of batch 67: 48.69493865966797, 0.96875\n",
      "Train loss and acc of batch 68: 48.478172302246094, 0.984375\n",
      "Train loss and acc of batch 69: 48.099220275878906, 0.984375\n",
      "Train loss and acc of batch 70: 47.882450103759766, 1.0\n",
      "Training accuracy and loss of epoch #278: 0.9892, 48.2107\n",
      "Saved model by train loss 48.21072129800286\n",
      "Train loss and acc of batch 0: 47.8824348449707, 1.0\n",
      "Train loss and acc of batch 1: 47.88242721557617, 1.0\n",
      "Train loss and acc of batch 2: 48.16827392578125, 0.984375\n",
      "Train loss and acc of batch 3: 48.09918212890625, 0.984375\n",
      "Train loss and acc of batch 4: 47.88240432739258, 1.0\n",
      "Train loss and acc of batch 5: 49.2313232421875, 0.96875\n",
      "Train loss and acc of batch 6: 48.38500213623047, 0.96875\n",
      "Train loss and acc of batch 7: 47.88237380981445, 1.0\n",
      "Train loss and acc of batch 8: 48.478065490722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.168212890625, 0.984375\n",
      "Train loss and acc of batch 10: 47.882347106933594, 1.0\n",
      "Train loss and acc of batch 11: 47.8823356628418, 1.0\n",
      "Train loss and acc of batch 12: 48.635555267333984, 0.984375\n",
      "Train loss and acc of batch 13: 48.099090576171875, 0.984375\n",
      "Train loss and acc of batch 14: 48.09907531738281, 0.984375\n",
      "Train loss and acc of batch 15: 48.478004455566406, 0.984375\n",
      "Train loss and acc of batch 16: 48.477996826171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.6355094909668, 0.984375\n",
      "Train loss and acc of batch 18: 48.763832092285156, 0.96875\n",
      "Train loss and acc of batch 19: 47.88227462768555, 1.0\n",
      "Train loss and acc of batch 20: 47.88226318359375, 1.0\n",
      "Train loss and acc of batch 21: 48.47795104980469, 0.984375\n",
      "Train loss and acc of batch 22: 48.477943420410156, 0.984375\n",
      "Train loss and acc of batch 23: 47.88223648071289, 1.0\n",
      "Train loss and acc of batch 24: 48.477928161621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.8822135925293, 1.0\n",
      "Train loss and acc of batch 26: 47.882205963134766, 1.0\n",
      "Train loss and acc of batch 27: 47.882198333740234, 1.0\n",
      "Train loss and acc of batch 28: 47.88218688964844, 1.0\n",
      "Train loss and acc of batch 29: 48.477874755859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.882171630859375, 1.0\n",
      "Train loss and acc of batch 31: 48.09892272949219, 0.984375\n",
      "Train loss and acc of batch 32: 47.88215255737305, 1.0\n",
      "Train loss and acc of batch 33: 47.882144927978516, 1.0\n",
      "Train loss and acc of batch 34: 48.47783660888672, 0.984375\n",
      "Train loss and acc of batch 35: 48.31565475463867, 0.96875\n",
      "Train loss and acc of batch 36: 47.88211441040039, 1.0\n",
      "Train loss and acc of batch 37: 48.63533401489258, 0.984375\n",
      "Train loss and acc of batch 38: 49.23102569580078, 0.96875\n",
      "Train loss and acc of batch 39: 48.098854064941406, 0.984375\n",
      "Train loss and acc of batch 40: 47.882080078125, 1.0\n",
      "Train loss and acc of batch 41: 49.23099899291992, 0.96875\n",
      "Train loss and acc of batch 42: 47.8820686340332, 1.0\n",
      "Train loss and acc of batch 43: 48.477752685546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.88204574584961, 1.0\n",
      "Train loss and acc of batch 45: 48.47773742675781, 0.984375\n",
      "Train loss and acc of batch 46: 48.167877197265625, 0.984375\n",
      "Train loss and acc of batch 47: 47.88201904296875, 1.0\n",
      "Train loss and acc of batch 48: 47.88201141357422, 1.0\n",
      "Train loss and acc of batch 49: 47.88200378417969, 1.0\n",
      "Train loss and acc of batch 50: 48.477691650390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.23090362548828, 0.96875\n",
      "Train loss and acc of batch 52: 49.137813568115234, 0.953125\n",
      "Train loss and acc of batch 53: 47.88196563720703, 1.0\n",
      "Train loss and acc of batch 54: 48.098716735839844, 0.984375\n",
      "Train loss and acc of batch 55: 47.88195037841797, 1.0\n",
      "Train loss and acc of batch 56: 47.88193893432617, 1.0\n",
      "Train loss and acc of batch 57: 48.477630615234375, 0.984375\n",
      "Train loss and acc of batch 58: 47.881919860839844, 1.0\n",
      "Train loss and acc of batch 59: 47.88191604614258, 1.0\n",
      "Train loss and acc of batch 60: 47.881900787353516, 1.0\n",
      "Train loss and acc of batch 61: 47.88189697265625, 1.0\n",
      "Train loss and acc of batch 62: 48.09864807128906, 0.984375\n",
      "Train loss and acc of batch 63: 49.073280334472656, 0.96875\n",
      "Train loss and acc of batch 64: 48.09864044189453, 0.984375\n",
      "Train loss and acc of batch 65: 47.88185501098633, 1.0\n",
      "Train loss and acc of batch 66: 47.8818473815918, 1.0\n",
      "Train loss and acc of batch 67: 48.69430923461914, 0.96875\n",
      "Train loss and acc of batch 68: 48.47753143310547, 0.984375\n",
      "Train loss and acc of batch 69: 48.098594665527344, 0.984375\n",
      "Train loss and acc of batch 70: 47.88181686401367, 1.0\n",
      "Training accuracy and loss of epoch #279: 0.9892, 48.2101\n",
      "Saved model by train loss 48.210088702994334\n",
      "Train loss and acc of batch 0: 47.881805419921875, 1.0\n",
      "Train loss and acc of batch 1: 47.88179397583008, 1.0\n",
      "Train loss and acc of batch 2: 48.167640686035156, 0.984375\n",
      "Train loss and acc of batch 3: 48.098541259765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.881771087646484, 1.0\n",
      "Train loss and acc of batch 5: 49.230682373046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.384368896484375, 0.96875\n",
      "Train loss and acc of batch 7: 47.881744384765625, 1.0\n",
      "Train loss and acc of batch 8: 48.477439880371094, 0.984375\n",
      "Train loss and acc of batch 9: 48.167579650878906, 0.984375\n",
      "Train loss and acc of batch 10: 47.88172149658203, 1.0\n",
      "Train loss and acc of batch 11: 47.88170623779297, 1.0\n",
      "Train loss and acc of batch 12: 48.634925842285156, 0.984375\n",
      "Train loss and acc of batch 13: 48.09845733642578, 0.984375\n",
      "Train loss and acc of batch 14: 48.09844207763672, 0.984375\n",
      "Train loss and acc of batch 15: 48.47737121582031, 0.984375\n",
      "Train loss and acc of batch 16: 48.47736358642578, 0.984375\n",
      "Train loss and acc of batch 17: 48.63488006591797, 0.984375\n",
      "Train loss and acc of batch 18: 48.76320266723633, 0.96875\n",
      "Train loss and acc of batch 19: 47.88163757324219, 1.0\n",
      "Train loss and acc of batch 20: 47.88162612915039, 1.0\n",
      "Train loss and acc of batch 21: 48.477325439453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.47731018066406, 0.984375\n",
      "Train loss and acc of batch 23: 47.88159942626953, 1.0\n",
      "Train loss and acc of batch 24: 48.477294921875, 0.984375\n",
      "Train loss and acc of batch 25: 47.8815803527832, 1.0\n",
      "Train loss and acc of batch 26: 47.88157653808594, 1.0\n",
      "Train loss and acc of batch 27: 47.881568908691406, 1.0\n",
      "Train loss and acc of batch 28: 47.881553649902344, 1.0\n",
      "Train loss and acc of batch 29: 48.47724914550781, 0.984375\n",
      "Train loss and acc of batch 30: 47.881534576416016, 1.0\n",
      "Train loss and acc of batch 31: 48.098297119140625, 0.984375\n",
      "Train loss and acc of batch 32: 47.88151931762695, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.88151168823242, 1.0\n",
      "Train loss and acc of batch 34: 48.477203369140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.31502914428711, 0.96875\n",
      "Train loss and acc of batch 36: 47.88148880004883, 1.0\n",
      "Train loss and acc of batch 37: 48.63469696044922, 0.984375\n",
      "Train loss and acc of batch 38: 49.23039245605469, 0.96875\n",
      "Train loss and acc of batch 39: 48.098228454589844, 0.984375\n",
      "Train loss and acc of batch 40: 47.88145065307617, 1.0\n",
      "Train loss and acc of batch 41: 49.23037338256836, 0.96875\n",
      "Train loss and acc of batch 42: 47.881431579589844, 1.0\n",
      "Train loss and acc of batch 43: 48.47712707519531, 0.984375\n",
      "Train loss and acc of batch 44: 47.88141632080078, 1.0\n",
      "Train loss and acc of batch 45: 48.47710418701172, 0.984375\n",
      "Train loss and acc of batch 46: 48.16725158691406, 0.984375\n",
      "Train loss and acc of batch 47: 47.881385803222656, 1.0\n",
      "Train loss and acc of batch 48: 47.881378173828125, 1.0\n",
      "Train loss and acc of batch 49: 47.88137435913086, 1.0\n",
      "Train loss and acc of batch 50: 48.47706604003906, 0.984375\n",
      "Train loss and acc of batch 51: 49.23027038574219, 0.96875\n",
      "Train loss and acc of batch 52: 49.137184143066406, 0.953125\n",
      "Train loss and acc of batch 53: 47.88133239746094, 1.0\n",
      "Train loss and acc of batch 54: 48.09809112548828, 0.984375\n",
      "Train loss and acc of batch 55: 47.881317138671875, 1.0\n",
      "Train loss and acc of batch 56: 47.881309509277344, 1.0\n",
      "Train loss and acc of batch 57: 48.47699737548828, 0.984375\n",
      "Train loss and acc of batch 58: 47.88128662109375, 1.0\n",
      "Train loss and acc of batch 59: 47.88127899169922, 1.0\n",
      "Train loss and acc of batch 60: 47.88127136230469, 1.0\n",
      "Train loss and acc of batch 61: 47.88125991821289, 1.0\n",
      "Train loss and acc of batch 62: 48.0980224609375, 0.984375\n",
      "Train loss and acc of batch 63: 49.07264709472656, 0.96875\n",
      "Train loss and acc of batch 64: 48.09800720214844, 0.984375\n",
      "Train loss and acc of batch 65: 47.8812255859375, 1.0\n",
      "Train loss and acc of batch 66: 47.881221771240234, 1.0\n",
      "Train loss and acc of batch 67: 48.69367218017578, 0.96875\n",
      "Train loss and acc of batch 68: 48.476905822753906, 0.984375\n",
      "Train loss and acc of batch 69: 48.09796142578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.88118362426758, 1.0\n",
      "Training accuracy and loss of epoch #280: 0.9892, 48.2095\n",
      "Saved model by train loss 48.20945729000468\n",
      "Train loss and acc of batch 0: 47.88117599487305, 1.0\n",
      "Train loss and acc of batch 1: 47.88116455078125, 1.0\n",
      "Train loss and acc of batch 2: 48.16700744628906, 0.984375\n",
      "Train loss and acc of batch 3: 48.09790802001953, 0.984375\n",
      "Train loss and acc of batch 4: 47.88113784790039, 1.0\n",
      "Train loss and acc of batch 5: 49.23005676269531, 0.96875\n",
      "Train loss and acc of batch 6: 48.38373947143555, 0.96875\n",
      "Train loss and acc of batch 7: 47.8811149597168, 1.0\n",
      "Train loss and acc of batch 8: 48.476806640625, 0.984375\n",
      "Train loss and acc of batch 9: 48.16694641113281, 0.984375\n",
      "Train loss and acc of batch 10: 47.88108444213867, 1.0\n",
      "Train loss and acc of batch 11: 47.88107681274414, 1.0\n",
      "Train loss and acc of batch 12: 48.63429641723633, 0.984375\n",
      "Train loss and acc of batch 13: 48.09782409667969, 0.984375\n",
      "Train loss and acc of batch 14: 48.097816467285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.47673797607422, 0.984375\n",
      "Train loss and acc of batch 16: 48.47673034667969, 0.984375\n",
      "Train loss and acc of batch 17: 48.63424301147461, 0.984375\n",
      "Train loss and acc of batch 18: 48.76256561279297, 0.96875\n",
      "Train loss and acc of batch 19: 47.881004333496094, 1.0\n",
      "Train loss and acc of batch 20: 47.88099670410156, 1.0\n",
      "Train loss and acc of batch 21: 48.47669219970703, 0.984375\n",
      "Train loss and acc of batch 22: 48.47667694091797, 0.984375\n",
      "Train loss and acc of batch 23: 47.88097381591797, 1.0\n",
      "Train loss and acc of batch 24: 48.476661682128906, 0.984375\n",
      "Train loss and acc of batch 25: 47.880950927734375, 1.0\n",
      "Train loss and acc of batch 26: 47.880943298339844, 1.0\n",
      "Train loss and acc of batch 27: 47.88093185424805, 1.0\n",
      "Train loss and acc of batch 28: 47.88092803955078, 1.0\n",
      "Train loss and acc of batch 29: 48.47661590576172, 0.984375\n",
      "Train loss and acc of batch 30: 47.88090896606445, 1.0\n",
      "Train loss and acc of batch 31: 48.09766387939453, 0.984375\n",
      "Train loss and acc of batch 32: 47.88088607788086, 1.0\n",
      "Train loss and acc of batch 33: 47.88087844848633, 1.0\n",
      "Train loss and acc of batch 34: 48.47657775878906, 0.984375\n",
      "Train loss and acc of batch 35: 48.31439208984375, 0.96875\n",
      "Train loss and acc of batch 36: 47.88085174560547, 1.0\n",
      "Train loss and acc of batch 37: 48.63406753540039, 0.984375\n",
      "Train loss and acc of batch 38: 49.229759216308594, 0.96875\n",
      "Train loss and acc of batch 39: 48.09758758544922, 0.984375\n",
      "Train loss and acc of batch 40: 47.88081741333008, 1.0\n",
      "Train loss and acc of batch 41: 49.229736328125, 0.96875\n",
      "Train loss and acc of batch 42: 47.88079833984375, 1.0\n",
      "Train loss and acc of batch 43: 48.47649383544922, 0.984375\n",
      "Train loss and acc of batch 44: 47.88078308105469, 1.0\n",
      "Train loss and acc of batch 45: 48.476478576660156, 0.984375\n",
      "Train loss and acc of batch 46: 48.16661071777344, 0.984375\n",
      "Train loss and acc of batch 47: 47.88075637817383, 1.0\n",
      "Train loss and acc of batch 48: 47.88074493408203, 1.0\n",
      "Train loss and acc of batch 49: 47.880741119384766, 1.0\n",
      "Train loss and acc of batch 50: 48.47643280029297, 0.984375\n",
      "Train loss and acc of batch 51: 49.229644775390625, 0.96875\n",
      "Train loss and acc of batch 52: 49.13655090332031, 0.953125\n",
      "Train loss and acc of batch 53: 47.880706787109375, 1.0\n",
      "Train loss and acc of batch 54: 48.09745788574219, 0.984375\n",
      "Train loss and acc of batch 55: 47.88068389892578, 1.0\n",
      "Train loss and acc of batch 56: 47.88067626953125, 1.0\n",
      "Train loss and acc of batch 57: 48.47636413574219, 0.984375\n",
      "Train loss and acc of batch 58: 47.88065719604492, 1.0\n",
      "Train loss and acc of batch 59: 47.88064956665039, 1.0\n",
      "Train loss and acc of batch 60: 47.880638122558594, 1.0\n",
      "Train loss and acc of batch 61: 47.88063049316406, 1.0\n",
      "Train loss and acc of batch 62: 48.097389221191406, 0.984375\n",
      "Train loss and acc of batch 63: 49.072017669677734, 0.96875\n",
      "Train loss and acc of batch 64: 48.097373962402344, 0.984375\n",
      "Train loss and acc of batch 65: 47.88059616088867, 1.0\n",
      "Train loss and acc of batch 66: 47.88058853149414, 1.0\n",
      "Train loss and acc of batch 67: 48.69304656982422, 0.96875\n",
      "Train loss and acc of batch 68: 48.47626495361328, 0.984375\n",
      "Train loss and acc of batch 69: 48.097320556640625, 0.984375\n",
      "Train loss and acc of batch 70: 47.880550384521484, 1.0\n",
      "Training accuracy and loss of epoch #281: 0.9892, 48.2088\n",
      "Saved model by train loss 48.208825124821196\n",
      "Train loss and acc of batch 0: 47.88054656982422, 1.0\n",
      "Train loss and acc of batch 1: 47.88053512573242, 1.0\n",
      "Train loss and acc of batch 2: 48.16637420654297, 0.984375\n",
      "Train loss and acc of batch 3: 48.09727478027344, 0.984375\n",
      "Train loss and acc of batch 4: 47.8805046081543, 1.0\n",
      "Train loss and acc of batch 5: 49.22942352294922, 0.96875\n",
      "Train loss and acc of batch 6: 48.38310241699219, 0.96875\n",
      "Train loss and acc of batch 7: 47.8804817199707, 1.0\n",
      "Train loss and acc of batch 8: 48.476173400878906, 0.984375\n",
      "Train loss and acc of batch 9: 48.16631317138672, 0.984375\n",
      "Train loss and acc of batch 10: 47.88045883178711, 1.0\n",
      "Train loss and acc of batch 11: 47.88044357299805, 1.0\n",
      "Train loss and acc of batch 12: 48.6336555480957, 0.984375\n",
      "Train loss and acc of batch 13: 48.097190856933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.09718322753906, 0.984375\n",
      "Train loss and acc of batch 15: 48.476112365722656, 0.984375\n",
      "Train loss and acc of batch 16: 48.476097106933594, 0.984375\n",
      "Train loss and acc of batch 17: 48.63361740112305, 0.984375\n",
      "Train loss and acc of batch 18: 48.761932373046875, 0.96875\n",
      "Train loss and acc of batch 19: 47.880374908447266, 1.0\n",
      "Train loss and acc of batch 20: 47.88036346435547, 1.0\n",
      "Train loss and acc of batch 21: 48.47605895996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.476043701171875, 0.984375\n",
      "Train loss and acc of batch 23: 47.88033676147461, 1.0\n",
      "Train loss and acc of batch 24: 48.47602844238281, 0.984375\n",
      "Train loss and acc of batch 25: 47.88031768798828, 1.0\n",
      "Train loss and acc of batch 26: 47.88031005859375, 1.0\n",
      "Train loss and acc of batch 27: 47.88030242919922, 1.0\n",
      "Train loss and acc of batch 28: 47.88029479980469, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 29: 48.475990295410156, 0.984375\n",
      "Train loss and acc of batch 30: 47.880271911621094, 1.0\n",
      "Train loss and acc of batch 31: 48.09703063964844, 0.984375\n",
      "Train loss and acc of batch 32: 47.8802604675293, 1.0\n",
      "Train loss and acc of batch 33: 47.880252838134766, 1.0\n",
      "Train loss and acc of batch 34: 48.47593688964844, 0.984375\n",
      "Train loss and acc of batch 35: 48.313758850097656, 0.96875\n",
      "Train loss and acc of batch 36: 47.88022232055664, 1.0\n",
      "Train loss and acc of batch 37: 48.63343811035156, 0.984375\n",
      "Train loss and acc of batch 38: 49.2291259765625, 0.96875\n",
      "Train loss and acc of batch 39: 48.096954345703125, 0.984375\n",
      "Train loss and acc of batch 40: 47.880184173583984, 1.0\n",
      "Train loss and acc of batch 41: 49.22909927368164, 0.96875\n",
      "Train loss and acc of batch 42: 47.88016891479492, 1.0\n",
      "Train loss and acc of batch 43: 48.475860595703125, 0.984375\n",
      "Train loss and acc of batch 44: 47.88015365600586, 1.0\n",
      "Train loss and acc of batch 45: 48.47583770751953, 0.984375\n",
      "Train loss and acc of batch 46: 48.165985107421875, 0.984375\n",
      "Train loss and acc of batch 47: 47.880123138427734, 1.0\n",
      "Train loss and acc of batch 48: 47.8801155090332, 1.0\n",
      "Train loss and acc of batch 49: 47.880104064941406, 1.0\n",
      "Train loss and acc of batch 50: 48.475799560546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.22901153564453, 0.96875\n",
      "Train loss and acc of batch 52: 49.135921478271484, 0.953125\n",
      "Train loss and acc of batch 53: 47.880069732666016, 1.0\n",
      "Train loss and acc of batch 54: 48.096824645996094, 0.984375\n",
      "Train loss and acc of batch 55: 47.88005065917969, 1.0\n",
      "Train loss and acc of batch 56: 47.88004684448242, 1.0\n",
      "Train loss and acc of batch 57: 48.475738525390625, 0.984375\n",
      "Train loss and acc of batch 58: 47.88002395629883, 1.0\n",
      "Train loss and acc of batch 59: 47.88001251220703, 1.0\n",
      "Train loss and acc of batch 60: 47.880008697509766, 1.0\n",
      "Train loss and acc of batch 61: 47.87999725341797, 1.0\n",
      "Train loss and acc of batch 62: 48.09675598144531, 0.984375\n",
      "Train loss and acc of batch 63: 49.071380615234375, 0.96875\n",
      "Train loss and acc of batch 64: 48.09673309326172, 0.984375\n",
      "Train loss and acc of batch 65: 47.87996292114258, 1.0\n",
      "Train loss and acc of batch 66: 47.87995529174805, 1.0\n",
      "Train loss and acc of batch 67: 48.69240951538086, 0.96875\n",
      "Train loss and acc of batch 68: 48.47563934326172, 0.984375\n",
      "Train loss and acc of batch 69: 48.09669494628906, 0.984375\n",
      "Train loss and acc of batch 70: 47.879920959472656, 1.0\n",
      "Training accuracy and loss of epoch #282: 0.9892, 48.2082\n",
      "Saved model by train loss 48.20819274472519\n",
      "Train loss and acc of batch 0: 47.87990951538086, 1.0\n",
      "Train loss and acc of batch 1: 47.87990188598633, 1.0\n",
      "Train loss and acc of batch 2: 48.165748596191406, 0.984375\n",
      "Train loss and acc of batch 3: 48.096649169921875, 0.984375\n",
      "Train loss and acc of batch 4: 47.87987518310547, 1.0\n",
      "Train loss and acc of batch 5: 49.228790283203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.38247299194336, 0.96875\n",
      "Train loss and acc of batch 7: 47.879844665527344, 1.0\n",
      "Train loss and acc of batch 8: 48.47554016113281, 0.984375\n",
      "Train loss and acc of batch 9: 48.165687561035156, 0.984375\n",
      "Train loss and acc of batch 10: 47.87982177734375, 1.0\n",
      "Train loss and acc of batch 11: 47.87981033325195, 1.0\n",
      "Train loss and acc of batch 12: 48.63302993774414, 0.984375\n",
      "Train loss and acc of batch 13: 48.0965576171875, 0.984375\n",
      "Train loss and acc of batch 14: 48.09654998779297, 0.984375\n",
      "Train loss and acc of batch 15: 48.47547149658203, 0.984375\n",
      "Train loss and acc of batch 16: 48.47547149658203, 0.984375\n",
      "Train loss and acc of batch 17: 48.63298034667969, 0.984375\n",
      "Train loss and acc of batch 18: 48.76130294799805, 0.96875\n",
      "Train loss and acc of batch 19: 47.87974166870117, 1.0\n",
      "Train loss and acc of batch 20: 47.87972640991211, 1.0\n",
      "Train loss and acc of batch 21: 48.47541809082031, 0.984375\n",
      "Train loss and acc of batch 22: 48.47541046142578, 0.984375\n",
      "Train loss and acc of batch 23: 47.879703521728516, 1.0\n",
      "Train loss and acc of batch 24: 48.47539520263672, 0.984375\n",
      "Train loss and acc of batch 25: 47.87968444824219, 1.0\n",
      "Train loss and acc of batch 26: 47.87967300415039, 1.0\n",
      "Train loss and acc of batch 27: 47.879669189453125, 1.0\n",
      "Train loss and acc of batch 28: 47.87965774536133, 1.0\n",
      "Train loss and acc of batch 29: 48.47534942626953, 0.984375\n",
      "Train loss and acc of batch 30: 47.879642486572266, 1.0\n",
      "Train loss and acc of batch 31: 48.096397399902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.87961959838867, 1.0\n",
      "Train loss and acc of batch 33: 47.879615783691406, 1.0\n",
      "Train loss and acc of batch 34: 48.475303649902344, 0.984375\n",
      "Train loss and acc of batch 35: 48.3131217956543, 0.96875\n",
      "Train loss and acc of batch 36: 47.879581451416016, 1.0\n",
      "Train loss and acc of batch 37: 48.63280487060547, 0.984375\n",
      "Train loss and acc of batch 38: 49.228492736816406, 0.96875\n",
      "Train loss and acc of batch 39: 48.09632110595703, 0.984375\n",
      "Train loss and acc of batch 40: 47.87955093383789, 1.0\n",
      "Train loss and acc of batch 41: 49.22847366333008, 0.96875\n",
      "Train loss and acc of batch 42: 47.87953186035156, 1.0\n",
      "Train loss and acc of batch 43: 48.47522735595703, 0.984375\n",
      "Train loss and acc of batch 44: 47.8795166015625, 1.0\n",
      "Train loss and acc of batch 45: 48.47521209716797, 0.984375\n",
      "Train loss and acc of batch 46: 48.16535186767578, 0.984375\n",
      "Train loss and acc of batch 47: 47.87949752807617, 1.0\n",
      "Train loss and acc of batch 48: 47.87948226928711, 1.0\n",
      "Train loss and acc of batch 49: 47.87946701049805, 1.0\n",
      "Train loss and acc of batch 50: 48.47516632080078, 0.984375\n",
      "Train loss and acc of batch 51: 49.22837829589844, 0.96875\n",
      "Train loss and acc of batch 52: 49.135284423828125, 0.953125\n",
      "Train loss and acc of batch 53: 47.879432678222656, 1.0\n",
      "Train loss and acc of batch 54: 48.09619140625, 0.984375\n",
      "Train loss and acc of batch 55: 47.87942123413086, 1.0\n",
      "Train loss and acc of batch 56: 47.87940979003906, 1.0\n",
      "Train loss and acc of batch 57: 48.47509765625, 0.984375\n",
      "Train loss and acc of batch 58: 47.879390716552734, 1.0\n",
      "Train loss and acc of batch 59: 47.8793830871582, 1.0\n",
      "Train loss and acc of batch 60: 47.87937545776367, 1.0\n",
      "Train loss and acc of batch 61: 47.879364013671875, 1.0\n",
      "Train loss and acc of batch 62: 48.09612274169922, 0.984375\n",
      "Train loss and acc of batch 63: 49.07074737548828, 0.96875\n",
      "Train loss and acc of batch 64: 48.096099853515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.879329681396484, 1.0\n",
      "Train loss and acc of batch 66: 47.87931823730469, 1.0\n",
      "Train loss and acc of batch 67: 48.6917724609375, 0.96875\n",
      "Train loss and acc of batch 68: 48.475006103515625, 0.984375\n",
      "Train loss and acc of batch 69: 48.09606170654297, 0.984375\n",
      "Train loss and acc of batch 70: 47.8792839050293, 1.0\n",
      "Training accuracy and loss of epoch #283: 0.9892, 48.2076\n",
      "Saved model by train loss 48.20755907515405\n",
      "Train loss and acc of batch 0: 47.879276275634766, 1.0\n",
      "Train loss and acc of batch 1: 47.879268646240234, 1.0\n",
      "Train loss and acc of batch 2: 48.16510772705078, 0.984375\n",
      "Train loss and acc of batch 3: 48.09601593017578, 0.984375\n",
      "Train loss and acc of batch 4: 47.87923812866211, 1.0\n",
      "Train loss and acc of batch 5: 49.22815704345703, 0.96875\n",
      "Train loss and acc of batch 6: 48.3818359375, 0.96875\n",
      "Train loss and acc of batch 7: 47.87921142578125, 1.0\n",
      "Train loss and acc of batch 8: 48.47490692138672, 0.984375\n",
      "Train loss and acc of batch 9: 48.16504669189453, 0.984375\n",
      "Train loss and acc of batch 10: 47.87918472290039, 1.0\n",
      "Train loss and acc of batch 11: 47.879180908203125, 1.0\n",
      "Train loss and acc of batch 12: 48.63239288330078, 0.984375\n",
      "Train loss and acc of batch 13: 48.095924377441406, 0.984375\n",
      "Train loss and acc of batch 14: 48.095916748046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.47484588623047, 0.984375\n",
      "Train loss and acc of batch 16: 48.474830627441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.632347106933594, 0.984375\n",
      "Train loss and acc of batch 18: 48.76066970825195, 0.96875\n",
      "Train loss and acc of batch 19: 47.87910461425781, 1.0\n",
      "Train loss and acc of batch 20: 47.87909698486328, 1.0\n",
      "Train loss and acc of batch 21: 48.47479248046875, 0.984375\n",
      "Train loss and acc of batch 22: 48.47478485107422, 0.984375\n",
      "Train loss and acc of batch 23: 47.879066467285156, 1.0\n",
      "Train loss and acc of batch 24: 48.474761962890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.879051208496094, 1.0\n",
      "Train loss and acc of batch 26: 47.87904739379883, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 27: 47.87903594970703, 1.0\n",
      "Train loss and acc of batch 28: 47.8790283203125, 1.0\n",
      "Train loss and acc of batch 29: 48.47471618652344, 0.984375\n",
      "Train loss and acc of batch 30: 47.87900924682617, 1.0\n",
      "Train loss and acc of batch 31: 48.09576416015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.87899398803711, 1.0\n",
      "Train loss and acc of batch 33: 47.87898254394531, 1.0\n",
      "Train loss and acc of batch 34: 48.47467803955078, 0.984375\n",
      "Train loss and acc of batch 35: 48.31249237060547, 0.96875\n",
      "Train loss and acc of batch 36: 47.87895202636719, 1.0\n",
      "Train loss and acc of batch 37: 48.63216781616211, 0.984375\n",
      "Train loss and acc of batch 38: 49.22785949707031, 0.96875\n",
      "Train loss and acc of batch 39: 48.09569549560547, 0.984375\n",
      "Train loss and acc of batch 40: 47.87892150878906, 1.0\n",
      "Train loss and acc of batch 41: 49.22783660888672, 0.96875\n",
      "Train loss and acc of batch 42: 47.878902435302734, 1.0\n",
      "Train loss and acc of batch 43: 48.47459411621094, 0.984375\n",
      "Train loss and acc of batch 44: 47.878883361816406, 1.0\n",
      "Train loss and acc of batch 45: 48.474571228027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.16471862792969, 0.984375\n",
      "Train loss and acc of batch 47: 47.87885665893555, 1.0\n",
      "Train loss and acc of batch 48: 47.878849029541016, 1.0\n",
      "Train loss and acc of batch 49: 47.878841400146484, 1.0\n",
      "Train loss and acc of batch 50: 48.47453308105469, 0.984375\n",
      "Train loss and acc of batch 51: 49.227745056152344, 0.96875\n",
      "Train loss and acc of batch 52: 49.13465118408203, 0.953125\n",
      "Train loss and acc of batch 53: 47.87880325317383, 1.0\n",
      "Train loss and acc of batch 54: 48.095558166503906, 0.984375\n",
      "Train loss and acc of batch 55: 47.878787994384766, 1.0\n",
      "Train loss and acc of batch 56: 47.87877655029297, 1.0\n",
      "Train loss and acc of batch 57: 48.47447204589844, 0.984375\n",
      "Train loss and acc of batch 58: 47.87875747680664, 1.0\n",
      "Train loss and acc of batch 59: 47.878753662109375, 1.0\n",
      "Train loss and acc of batch 60: 47.87874221801758, 1.0\n",
      "Train loss and acc of batch 61: 47.87873458862305, 1.0\n",
      "Train loss and acc of batch 62: 48.095489501953125, 0.984375\n",
      "Train loss and acc of batch 63: 49.07011795043945, 0.96875\n",
      "Train loss and acc of batch 64: 48.09547424316406, 0.984375\n",
      "Train loss and acc of batch 65: 47.878692626953125, 1.0\n",
      "Train loss and acc of batch 66: 47.878684997558594, 1.0\n",
      "Train loss and acc of batch 67: 48.69114685058594, 0.96875\n",
      "Train loss and acc of batch 68: 48.47437286376953, 0.984375\n",
      "Train loss and acc of batch 69: 48.095428466796875, 0.984375\n",
      "Train loss and acc of batch 70: 47.8786506652832, 1.0\n",
      "Training accuracy and loss of epoch #284: 0.9892, 48.2069\n",
      "Saved model by train loss 48.206926587601785\n",
      "Train loss and acc of batch 0: 47.87864685058594, 1.0\n",
      "Train loss and acc of batch 1: 47.878631591796875, 1.0\n",
      "Train loss and acc of batch 2: 48.16448211669922, 0.984375\n",
      "Train loss and acc of batch 3: 48.09538269042969, 0.984375\n",
      "Train loss and acc of batch 4: 47.87860870361328, 1.0\n",
      "Train loss and acc of batch 5: 49.22752380371094, 0.96875\n",
      "Train loss and acc of batch 6: 48.38121032714844, 0.96875\n",
      "Train loss and acc of batch 7: 47.87858200073242, 1.0\n",
      "Train loss and acc of batch 8: 48.474273681640625, 0.984375\n",
      "Train loss and acc of batch 9: 48.16441345214844, 0.984375\n",
      "Train loss and acc of batch 10: 47.8785514831543, 1.0\n",
      "Train loss and acc of batch 11: 47.878543853759766, 1.0\n",
      "Train loss and acc of batch 12: 48.63175964355469, 0.984375\n",
      "Train loss and acc of batch 13: 48.09529113769531, 0.984375\n",
      "Train loss and acc of batch 14: 48.09528350830078, 0.984375\n",
      "Train loss and acc of batch 15: 48.474212646484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.474205017089844, 0.984375\n",
      "Train loss and acc of batch 17: 48.631717681884766, 0.984375\n",
      "Train loss and acc of batch 18: 48.76003646850586, 0.96875\n",
      "Train loss and acc of batch 19: 47.878475189208984, 1.0\n",
      "Train loss and acc of batch 20: 47.87846374511719, 1.0\n",
      "Train loss and acc of batch 21: 48.474151611328125, 0.984375\n",
      "Train loss and acc of batch 22: 48.474143981933594, 0.984375\n",
      "Train loss and acc of batch 23: 47.87843704223633, 1.0\n",
      "Train loss and acc of batch 24: 48.47412872314453, 0.984375\n",
      "Train loss and acc of batch 25: 47.878421783447266, 1.0\n",
      "Train loss and acc of batch 26: 47.87841033935547, 1.0\n",
      "Train loss and acc of batch 27: 47.87840270996094, 1.0\n",
      "Train loss and acc of batch 28: 47.878395080566406, 1.0\n",
      "Train loss and acc of batch 29: 48.474082946777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.87837600708008, 1.0\n",
      "Train loss and acc of batch 31: 48.095130920410156, 0.984375\n",
      "Train loss and acc of batch 32: 47.87835693359375, 1.0\n",
      "Train loss and acc of batch 33: 47.87834930419922, 1.0\n",
      "Train loss and acc of batch 34: 48.47404479980469, 0.984375\n",
      "Train loss and acc of batch 35: 48.31186294555664, 0.96875\n",
      "Train loss and acc of batch 36: 47.87832260131836, 1.0\n",
      "Train loss and acc of batch 37: 48.631534576416016, 0.984375\n",
      "Train loss and acc of batch 38: 49.22722625732422, 0.96875\n",
      "Train loss and acc of batch 39: 48.095062255859375, 0.984375\n",
      "Train loss and acc of batch 40: 47.8782844543457, 1.0\n",
      "Train loss and acc of batch 41: 49.227203369140625, 0.96875\n",
      "Train loss and acc of batch 42: 47.87826919555664, 1.0\n",
      "Train loss and acc of batch 43: 48.473960876464844, 0.984375\n",
      "Train loss and acc of batch 44: 47.87825012207031, 1.0\n",
      "Train loss and acc of batch 45: 48.47394561767578, 0.984375\n",
      "Train loss and acc of batch 46: 48.164085388183594, 0.984375\n",
      "Train loss and acc of batch 47: 47.87822341918945, 1.0\n",
      "Train loss and acc of batch 48: 47.87821960449219, 1.0\n",
      "Train loss and acc of batch 49: 47.87820816040039, 1.0\n",
      "Train loss and acc of batch 50: 48.473899841308594, 0.984375\n",
      "Train loss and acc of batch 51: 49.22711181640625, 0.96875\n",
      "Train loss and acc of batch 52: 49.13401794433594, 0.953125\n",
      "Train loss and acc of batch 53: 47.878170013427734, 1.0\n",
      "Train loss and acc of batch 54: 48.09492492675781, 0.984375\n",
      "Train loss and acc of batch 55: 47.878150939941406, 1.0\n",
      "Train loss and acc of batch 56: 47.87814712524414, 1.0\n",
      "Train loss and acc of batch 57: 48.473838806152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.87813186645508, 1.0\n",
      "Train loss and acc of batch 59: 47.878116607666016, 1.0\n",
      "Train loss and acc of batch 60: 47.878108978271484, 1.0\n",
      "Train loss and acc of batch 61: 47.87809753417969, 1.0\n",
      "Train loss and acc of batch 62: 48.09486389160156, 0.984375\n",
      "Train loss and acc of batch 63: 49.06948471069336, 0.96875\n",
      "Train loss and acc of batch 64: 48.09484100341797, 0.984375\n",
      "Train loss and acc of batch 65: 47.8780632019043, 1.0\n",
      "Train loss and acc of batch 66: 47.8780517578125, 1.0\n",
      "Train loss and acc of batch 67: 48.69050979614258, 0.96875\n",
      "Train loss and acc of batch 68: 48.47373962402344, 0.984375\n",
      "Train loss and acc of batch 69: 48.09478759765625, 0.984375\n",
      "Train loss and acc of batch 70: 47.878021240234375, 1.0\n",
      "Training accuracy and loss of epoch #285: 0.9892, 48.2063\n",
      "Saved model by train loss 48.20629388513699\n",
      "Train loss and acc of batch 0: 47.878013610839844, 1.0\n",
      "Train loss and acc of batch 1: 47.87800598144531, 1.0\n",
      "Train loss and acc of batch 2: 48.163848876953125, 0.984375\n",
      "Train loss and acc of batch 3: 48.094749450683594, 0.984375\n",
      "Train loss and acc of batch 4: 47.87797546386719, 1.0\n",
      "Train loss and acc of batch 5: 49.226898193359375, 0.96875\n",
      "Train loss and acc of batch 6: 48.38056945800781, 0.96875\n",
      "Train loss and acc of batch 7: 47.87794876098633, 1.0\n",
      "Train loss and acc of batch 8: 48.47364044189453, 0.984375\n",
      "Train loss and acc of batch 9: 48.163787841796875, 0.984375\n",
      "Train loss and acc of batch 10: 47.87792205810547, 1.0\n",
      "Train loss and acc of batch 11: 47.87791061401367, 1.0\n",
      "Train loss and acc of batch 12: 48.631126403808594, 0.984375\n",
      "Train loss and acc of batch 13: 48.09465789794922, 0.984375\n",
      "Train loss and acc of batch 14: 48.09465026855469, 0.984375\n",
      "Train loss and acc of batch 15: 48.47357940673828, 0.984375\n",
      "Train loss and acc of batch 16: 48.47357177734375, 0.984375\n",
      "Train loss and acc of batch 17: 48.63108444213867, 0.984375\n",
      "Train loss and acc of batch 18: 48.759403228759766, 0.96875\n",
      "Train loss and acc of batch 19: 47.877845764160156, 1.0\n",
      "Train loss and acc of batch 20: 47.87783432006836, 1.0\n",
      "Train loss and acc of batch 21: 48.47352600097656, 0.984375\n",
      "Train loss and acc of batch 22: 48.47351837158203, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 23: 47.877803802490234, 1.0\n",
      "Train loss and acc of batch 24: 48.47349548339844, 0.984375\n",
      "Train loss and acc of batch 25: 47.877784729003906, 1.0\n",
      "Train loss and acc of batch 26: 47.87778091430664, 1.0\n",
      "Train loss and acc of batch 27: 47.877769470214844, 1.0\n",
      "Train loss and acc of batch 28: 47.87776565551758, 1.0\n",
      "Train loss and acc of batch 29: 48.47345733642578, 0.984375\n",
      "Train loss and acc of batch 30: 47.87774658203125, 1.0\n",
      "Train loss and acc of batch 31: 48.09449768066406, 0.984375\n",
      "Train loss and acc of batch 32: 47.877723693847656, 1.0\n",
      "Train loss and acc of batch 33: 47.877716064453125, 1.0\n",
      "Train loss and acc of batch 34: 48.473411560058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.31122589111328, 0.96875\n",
      "Train loss and acc of batch 36: 47.8776969909668, 1.0\n",
      "Train loss and acc of batch 37: 48.63090515136719, 0.984375\n",
      "Train loss and acc of batch 38: 49.226600646972656, 0.96875\n",
      "Train loss and acc of batch 39: 48.09442901611328, 0.984375\n",
      "Train loss and acc of batch 40: 47.87765121459961, 1.0\n",
      "Train loss and acc of batch 41: 49.2265739440918, 0.96875\n",
      "Train loss and acc of batch 42: 47.87763595581055, 1.0\n",
      "Train loss and acc of batch 43: 48.47332763671875, 0.984375\n",
      "Train loss and acc of batch 44: 47.877620697021484, 1.0\n",
      "Train loss and acc of batch 45: 48.47331237792969, 0.984375\n",
      "Train loss and acc of batch 46: 48.1634521484375, 0.984375\n",
      "Train loss and acc of batch 47: 47.877593994140625, 1.0\n",
      "Train loss and acc of batch 48: 47.87758255004883, 1.0\n",
      "Train loss and acc of batch 49: 47.8775749206543, 1.0\n",
      "Train loss and acc of batch 50: 48.4732666015625, 0.984375\n",
      "Train loss and acc of batch 51: 49.226478576660156, 0.96875\n",
      "Train loss and acc of batch 52: 49.133392333984375, 0.953125\n",
      "Train loss and acc of batch 53: 47.87754440307617, 1.0\n",
      "Train loss and acc of batch 54: 48.09429168701172, 0.984375\n",
      "Train loss and acc of batch 55: 47.87752151489258, 1.0\n",
      "Train loss and acc of batch 56: 47.87751388549805, 1.0\n",
      "Train loss and acc of batch 57: 48.47320556640625, 0.984375\n",
      "Train loss and acc of batch 58: 47.87749481201172, 1.0\n",
      "Train loss and acc of batch 59: 47.87748718261719, 1.0\n",
      "Train loss and acc of batch 60: 47.87747573852539, 1.0\n",
      "Train loss and acc of batch 61: 47.877471923828125, 1.0\n",
      "Train loss and acc of batch 62: 48.09422302246094, 0.984375\n",
      "Train loss and acc of batch 63: 49.06885528564453, 0.96875\n",
      "Train loss and acc of batch 64: 48.094207763671875, 0.984375\n",
      "Train loss and acc of batch 65: 47.87743377685547, 1.0\n",
      "Train loss and acc of batch 66: 47.87742614746094, 1.0\n",
      "Train loss and acc of batch 67: 48.68988037109375, 0.96875\n",
      "Train loss and acc of batch 68: 48.473106384277344, 0.984375\n",
      "Train loss and acc of batch 69: 48.09416198730469, 0.984375\n",
      "Train loss and acc of batch 70: 47.87738800048828, 1.0\n",
      "Training accuracy and loss of epoch #286: 0.9892, 48.2057\n",
      "Saved model by train loss 48.20566241841921\n",
      "Train loss and acc of batch 0: 47.87738037109375, 1.0\n",
      "Train loss and acc of batch 1: 47.87736892700195, 1.0\n",
      "Train loss and acc of batch 2: 48.16321563720703, 0.984375\n",
      "Train loss and acc of batch 3: 48.0941162109375, 0.984375\n",
      "Train loss and acc of batch 4: 47.87734603881836, 1.0\n",
      "Train loss and acc of batch 5: 49.22625732421875, 0.96875\n",
      "Train loss and acc of batch 6: 48.379940032958984, 0.96875\n",
      "Train loss and acc of batch 7: 47.8773193359375, 1.0\n",
      "Train loss and acc of batch 8: 48.47301483154297, 0.984375\n",
      "Train loss and acc of batch 9: 48.16315460205078, 0.984375\n",
      "Train loss and acc of batch 10: 47.877288818359375, 1.0\n",
      "Train loss and acc of batch 11: 47.87727737426758, 1.0\n",
      "Train loss and acc of batch 12: 48.6304931640625, 0.984375\n",
      "Train loss and acc of batch 13: 48.094032287597656, 0.984375\n",
      "Train loss and acc of batch 14: 48.094017028808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.47294616699219, 0.984375\n",
      "Train loss and acc of batch 16: 48.472930908203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.630455017089844, 0.984375\n",
      "Train loss and acc of batch 18: 48.75877380371094, 0.96875\n",
      "Train loss and acc of batch 19: 47.8772087097168, 1.0\n",
      "Train loss and acc of batch 20: 47.877197265625, 1.0\n",
      "Train loss and acc of batch 21: 48.472900390625, 0.984375\n",
      "Train loss and acc of batch 22: 48.47288513183594, 0.984375\n",
      "Train loss and acc of batch 23: 47.87717819213867, 1.0\n",
      "Train loss and acc of batch 24: 48.472862243652344, 0.984375\n",
      "Train loss and acc of batch 25: 47.87715148925781, 1.0\n",
      "Train loss and acc of batch 26: 47.87714385986328, 1.0\n",
      "Train loss and acc of batch 27: 47.87713623046875, 1.0\n",
      "Train loss and acc of batch 28: 47.87712860107422, 1.0\n",
      "Train loss and acc of batch 29: 48.47282409667969, 0.984375\n",
      "Train loss and acc of batch 30: 47.87710952758789, 1.0\n",
      "Train loss and acc of batch 31: 48.0938720703125, 0.984375\n",
      "Train loss and acc of batch 32: 47.87709426879883, 1.0\n",
      "Train loss and acc of batch 33: 47.877079010009766, 1.0\n",
      "Train loss and acc of batch 34: 48.4727783203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.31060028076172, 0.96875\n",
      "Train loss and acc of batch 36: 47.87705993652344, 1.0\n",
      "Train loss and acc of batch 37: 48.63027572631836, 0.984375\n",
      "Train loss and acc of batch 38: 49.22596740722656, 0.96875\n",
      "Train loss and acc of batch 39: 48.09379577636719, 0.984375\n",
      "Train loss and acc of batch 40: 47.87702560424805, 1.0\n",
      "Train loss and acc of batch 41: 49.2259407043457, 0.96875\n",
      "Train loss and acc of batch 42: 47.87700653076172, 1.0\n",
      "Train loss and acc of batch 43: 48.472694396972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.876983642578125, 1.0\n",
      "Train loss and acc of batch 45: 48.472679138183594, 0.984375\n",
      "Train loss and acc of batch 46: 48.16282653808594, 0.984375\n",
      "Train loss and acc of batch 47: 47.876956939697266, 1.0\n",
      "Train loss and acc of batch 48: 47.876949310302734, 1.0\n",
      "Train loss and acc of batch 49: 47.87694549560547, 1.0\n",
      "Train loss and acc of batch 50: 48.472633361816406, 0.984375\n",
      "Train loss and acc of batch 51: 49.225852966308594, 0.96875\n",
      "Train loss and acc of batch 52: 49.132755279541016, 0.953125\n",
      "Train loss and acc of batch 53: 47.87690353393555, 1.0\n",
      "Train loss and acc of batch 54: 48.093658447265625, 0.984375\n",
      "Train loss and acc of batch 55: 47.87689208984375, 1.0\n",
      "Train loss and acc of batch 56: 47.87688064575195, 1.0\n",
      "Train loss and acc of batch 57: 48.472572326660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.876861572265625, 1.0\n",
      "Train loss and acc of batch 59: 47.876853942871094, 1.0\n",
      "Train loss and acc of batch 60: 47.87685012817383, 1.0\n",
      "Train loss and acc of batch 61: 47.876834869384766, 1.0\n",
      "Train loss and acc of batch 62: 48.093589782714844, 0.984375\n",
      "Train loss and acc of batch 63: 49.06822204589844, 0.96875\n",
      "Train loss and acc of batch 64: 48.09357452392578, 0.984375\n",
      "Train loss and acc of batch 65: 47.876800537109375, 1.0\n",
      "Train loss and acc of batch 66: 47.87679672241211, 1.0\n",
      "Train loss and acc of batch 67: 48.689247131347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.47248077392578, 0.984375\n",
      "Train loss and acc of batch 69: 48.093528747558594, 0.984375\n",
      "Train loss and acc of batch 70: 47.87675476074219, 1.0\n",
      "Training accuracy and loss of epoch #287: 0.9892, 48.2050\n",
      "Saved model by train loss 48.20502998459507\n",
      "Train loss and acc of batch 0: 47.876747131347656, 1.0\n",
      "Train loss and acc of batch 1: 47.876731872558594, 1.0\n",
      "Train loss and acc of batch 2: 48.16258239746094, 0.984375\n",
      "Train loss and acc of batch 3: 48.09349060058594, 0.984375\n",
      "Train loss and acc of batch 4: 47.876712799072266, 1.0\n",
      "Train loss and acc of batch 5: 49.225624084472656, 0.96875\n",
      "Train loss and acc of batch 6: 48.37931442260742, 0.96875\n",
      "Train loss and acc of batch 7: 47.87668228149414, 1.0\n",
      "Train loss and acc of batch 8: 48.472381591796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.16252136230469, 0.984375\n",
      "Train loss and acc of batch 10: 47.87665939331055, 1.0\n",
      "Train loss and acc of batch 11: 47.876651763916016, 1.0\n",
      "Train loss and acc of batch 12: 48.62986755371094, 0.984375\n",
      "Train loss and acc of batch 13: 48.09339141845703, 0.984375\n",
      "Train loss and acc of batch 14: 48.0933837890625, 0.984375\n",
      "Train loss and acc of batch 15: 48.472312927246094, 0.984375\n",
      "Train loss and acc of batch 16: 48.47230529785156, 0.984375\n",
      "Train loss and acc of batch 17: 48.62982177734375, 0.984375\n",
      "Train loss and acc of batch 18: 48.75813674926758, 0.96875\n",
      "Train loss and acc of batch 19: 47.87657928466797, 1.0\n",
      "Train loss and acc of batch 20: 47.87657165527344, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 21: 48.472259521484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.472251892089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.87654495239258, 1.0\n",
      "Train loss and acc of batch 24: 48.47223663330078, 0.984375\n",
      "Train loss and acc of batch 25: 47.87652587890625, 1.0\n",
      "Train loss and acc of batch 26: 47.87651443481445, 1.0\n",
      "Train loss and acc of batch 27: 47.87650680541992, 1.0\n",
      "Train loss and acc of batch 28: 47.876495361328125, 1.0\n",
      "Train loss and acc of batch 29: 48.47218322753906, 0.984375\n",
      "Train loss and acc of batch 30: 47.87648010253906, 1.0\n",
      "Train loss and acc of batch 31: 48.093238830566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.876461029052734, 1.0\n",
      "Train loss and acc of batch 33: 47.8764533996582, 1.0\n",
      "Train loss and acc of batch 34: 48.472145080566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.30996322631836, 0.96875\n",
      "Train loss and acc of batch 36: 47.876426696777344, 1.0\n",
      "Train loss and acc of batch 37: 48.629642486572266, 0.984375\n",
      "Train loss and acc of batch 38: 49.22533416748047, 0.96875\n",
      "Train loss and acc of batch 39: 48.093170166015625, 0.984375\n",
      "Train loss and acc of batch 40: 47.87639236450195, 1.0\n",
      "Train loss and acc of batch 41: 49.225311279296875, 0.96875\n",
      "Train loss and acc of batch 42: 47.876373291015625, 1.0\n",
      "Train loss and acc of batch 43: 48.472068786621094, 0.984375\n",
      "Train loss and acc of batch 44: 47.8763542175293, 1.0\n",
      "Train loss and acc of batch 45: 48.47205352783203, 0.984375\n",
      "Train loss and acc of batch 46: 48.16218566894531, 0.984375\n",
      "Train loss and acc of batch 47: 47.8763313293457, 1.0\n",
      "Train loss and acc of batch 48: 47.876319885253906, 1.0\n",
      "Train loss and acc of batch 49: 47.876312255859375, 1.0\n",
      "Train loss and acc of batch 50: 48.47200012207031, 0.984375\n",
      "Train loss and acc of batch 51: 49.2252197265625, 0.96875\n",
      "Train loss and acc of batch 52: 49.13212203979492, 0.953125\n",
      "Train loss and acc of batch 53: 47.876277923583984, 1.0\n",
      "Train loss and acc of batch 54: 48.09303283691406, 0.984375\n",
      "Train loss and acc of batch 55: 47.876258850097656, 1.0\n",
      "Train loss and acc of batch 56: 47.876251220703125, 1.0\n",
      "Train loss and acc of batch 57: 48.47193145751953, 0.984375\n",
      "Train loss and acc of batch 58: 47.87622833251953, 1.0\n",
      "Train loss and acc of batch 59: 47.876224517822266, 1.0\n",
      "Train loss and acc of batch 60: 47.87621307373047, 1.0\n",
      "Train loss and acc of batch 61: 47.87620544433594, 1.0\n",
      "Train loss and acc of batch 62: 48.09296417236328, 0.984375\n",
      "Train loss and acc of batch 63: 49.06758499145508, 0.96875\n",
      "Train loss and acc of batch 64: 48.09294128417969, 0.984375\n",
      "Train loss and acc of batch 65: 47.87616729736328, 1.0\n",
      "Train loss and acc of batch 66: 47.87615966796875, 1.0\n",
      "Train loss and acc of batch 67: 48.68861770629883, 0.96875\n",
      "Train loss and acc of batch 68: 48.47184753417969, 0.984375\n",
      "Train loss and acc of batch 69: 48.0928955078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.876121520996094, 1.0\n",
      "Training accuracy and loss of epoch #288: 0.9892, 48.2044\n",
      "Saved model by train loss 48.2043981955085\n",
      "Train loss and acc of batch 0: 47.8761100769043, 1.0\n",
      "Train loss and acc of batch 1: 47.87610626220703, 1.0\n",
      "Train loss and acc of batch 2: 48.161949157714844, 0.984375\n",
      "Train loss and acc of batch 3: 48.09284973144531, 0.984375\n",
      "Train loss and acc of batch 4: 47.87607955932617, 1.0\n",
      "Train loss and acc of batch 5: 49.224998474121094, 0.96875\n",
      "Train loss and acc of batch 6: 48.37868118286133, 0.96875\n",
      "Train loss and acc of batch 7: 47.87605285644531, 1.0\n",
      "Train loss and acc of batch 8: 48.47174072265625, 0.984375\n",
      "Train loss and acc of batch 9: 48.161888122558594, 0.984375\n",
      "Train loss and acc of batch 10: 47.87602615356445, 1.0\n",
      "Train loss and acc of batch 11: 47.87602233886719, 1.0\n",
      "Train loss and acc of batch 12: 48.62923049926758, 0.984375\n",
      "Train loss and acc of batch 13: 48.09276580810547, 0.984375\n",
      "Train loss and acc of batch 14: 48.092750549316406, 0.984375\n",
      "Train loss and acc of batch 15: 48.4716796875, 0.984375\n",
      "Train loss and acc of batch 16: 48.47167205810547, 0.984375\n",
      "Train loss and acc of batch 17: 48.62918472290039, 0.984375\n",
      "Train loss and acc of batch 18: 48.75750732421875, 0.96875\n",
      "Train loss and acc of batch 19: 47.87594985961914, 1.0\n",
      "Train loss and acc of batch 20: 47.87593460083008, 1.0\n",
      "Train loss and acc of batch 21: 48.47162628173828, 0.984375\n",
      "Train loss and acc of batch 22: 48.47161865234375, 0.984375\n",
      "Train loss and acc of batch 23: 47.87590789794922, 1.0\n",
      "Train loss and acc of batch 24: 48.47160339355469, 0.984375\n",
      "Train loss and acc of batch 25: 47.875892639160156, 1.0\n",
      "Train loss and acc of batch 26: 47.875885009765625, 1.0\n",
      "Train loss and acc of batch 27: 47.875877380371094, 1.0\n",
      "Train loss and acc of batch 28: 47.87586975097656, 1.0\n",
      "Train loss and acc of batch 29: 48.4715576171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.875850677490234, 1.0\n",
      "Train loss and acc of batch 31: 48.09259796142578, 0.984375\n",
      "Train loss and acc of batch 32: 47.875831604003906, 1.0\n",
      "Train loss and acc of batch 33: 47.875823974609375, 1.0\n",
      "Train loss and acc of batch 34: 48.47151184082031, 0.984375\n",
      "Train loss and acc of batch 35: 48.30933380126953, 0.96875\n",
      "Train loss and acc of batch 36: 47.875797271728516, 1.0\n",
      "Train loss and acc of batch 37: 48.629005432128906, 0.984375\n",
      "Train loss and acc of batch 38: 49.224700927734375, 0.96875\n",
      "Train loss and acc of batch 39: 48.09253692626953, 0.984375\n",
      "Train loss and acc of batch 40: 47.87575912475586, 1.0\n",
      "Train loss and acc of batch 41: 49.22467803955078, 0.96875\n",
      "Train loss and acc of batch 42: 47.8757438659668, 1.0\n",
      "Train loss and acc of batch 43: 48.471435546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.87572479248047, 1.0\n",
      "Train loss and acc of batch 45: 48.471412658691406, 0.984375\n",
      "Train loss and acc of batch 46: 48.16156005859375, 0.984375\n",
      "Train loss and acc of batch 47: 47.87569808959961, 1.0\n",
      "Train loss and acc of batch 48: 47.87568664550781, 1.0\n",
      "Train loss and acc of batch 49: 47.87567901611328, 1.0\n",
      "Train loss and acc of batch 50: 48.47137451171875, 0.984375\n",
      "Train loss and acc of batch 51: 49.224586486816406, 0.96875\n",
      "Train loss and acc of batch 52: 49.13149642944336, 0.953125\n",
      "Train loss and acc of batch 53: 47.875640869140625, 1.0\n",
      "Train loss and acc of batch 54: 48.09239959716797, 0.984375\n",
      "Train loss and acc of batch 55: 47.87562561035156, 1.0\n",
      "Train loss and acc of batch 56: 47.8756217956543, 1.0\n",
      "Train loss and acc of batch 57: 48.47130584716797, 0.984375\n",
      "Train loss and acc of batch 58: 47.8755989074707, 1.0\n",
      "Train loss and acc of batch 59: 47.87559127807617, 1.0\n",
      "Train loss and acc of batch 60: 47.875579833984375, 1.0\n",
      "Train loss and acc of batch 61: 47.875572204589844, 1.0\n",
      "Train loss and acc of batch 62: 48.09233093261719, 0.984375\n",
      "Train loss and acc of batch 63: 49.066959381103516, 0.96875\n",
      "Train loss and acc of batch 64: 48.092315673828125, 0.984375\n",
      "Train loss and acc of batch 65: 47.87553405761719, 1.0\n",
      "Train loss and acc of batch 66: 47.87553024291992, 1.0\n",
      "Train loss and acc of batch 67: 48.687984466552734, 0.96875\n",
      "Train loss and acc of batch 68: 48.47120666503906, 0.984375\n",
      "Train loss and acc of batch 69: 48.09226989746094, 0.984375\n",
      "Train loss and acc of batch 70: 47.875492095947266, 1.0\n",
      "Training accuracy and loss of epoch #289: 0.9892, 48.2038\n",
      "Saved model by train loss 48.20376624523754\n",
      "Train loss and acc of batch 0: 47.875484466552734, 1.0\n",
      "Train loss and acc of batch 1: 47.87547302246094, 1.0\n",
      "Train loss and acc of batch 2: 48.16131591796875, 0.984375\n",
      "Train loss and acc of batch 3: 48.09221649169922, 0.984375\n",
      "Train loss and acc of batch 4: 47.875450134277344, 1.0\n",
      "Train loss and acc of batch 5: 49.22435760498047, 0.96875\n",
      "Train loss and acc of batch 6: 48.378047943115234, 0.96875\n",
      "Train loss and acc of batch 7: 47.87541961669922, 1.0\n",
      "Train loss and acc of batch 8: 48.47111511230469, 0.984375\n",
      "Train loss and acc of batch 9: 48.1612548828125, 0.984375\n",
      "Train loss and acc of batch 10: 47.87539291381836, 1.0\n",
      "Train loss and acc of batch 11: 47.87538146972656, 1.0\n",
      "Train loss and acc of batch 12: 48.62860107421875, 0.984375\n",
      "Train loss and acc of batch 13: 48.092132568359375, 0.984375\n",
      "Train loss and acc of batch 14: 48.092124938964844, 0.984375\n",
      "Train loss and acc of batch 15: 48.47105407714844, 0.984375\n",
      "Train loss and acc of batch 16: 48.471038818359375, 0.984375\n",
      "Train loss and acc of batch 17: 48.62855529785156, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 18: 48.75687789916992, 0.96875\n",
      "Train loss and acc of batch 19: 47.87531280517578, 1.0\n",
      "Train loss and acc of batch 20: 47.87530517578125, 1.0\n",
      "Train loss and acc of batch 21: 48.47099304199219, 0.984375\n",
      "Train loss and acc of batch 22: 48.470985412597656, 0.984375\n",
      "Train loss and acc of batch 23: 47.87527847290039, 1.0\n",
      "Train loss and acc of batch 24: 48.470970153808594, 0.984375\n",
      "Train loss and acc of batch 25: 47.87525939941406, 1.0\n",
      "Train loss and acc of batch 26: 47.87525177001953, 1.0\n",
      "Train loss and acc of batch 27: 47.875244140625, 1.0\n",
      "Train loss and acc of batch 28: 47.87523651123047, 1.0\n",
      "Train loss and acc of batch 29: 48.470924377441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.87520980834961, 1.0\n",
      "Train loss and acc of batch 31: 48.09197235107422, 0.984375\n",
      "Train loss and acc of batch 32: 47.87519836425781, 1.0\n",
      "Train loss and acc of batch 33: 47.875186920166016, 1.0\n",
      "Train loss and acc of batch 34: 48.47087860107422, 0.984375\n",
      "Train loss and acc of batch 35: 48.30870056152344, 0.96875\n",
      "Train loss and acc of batch 36: 47.87516403198242, 1.0\n",
      "Train loss and acc of batch 37: 48.628379821777344, 0.984375\n",
      "Train loss and acc of batch 38: 49.22406768798828, 0.96875\n",
      "Train loss and acc of batch 39: 48.091896057128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.87512969970703, 1.0\n",
      "Train loss and acc of batch 41: 49.22404479980469, 0.96875\n",
      "Train loss and acc of batch 42: 47.8751106262207, 1.0\n",
      "Train loss and acc of batch 43: 48.470802307128906, 0.984375\n",
      "Train loss and acc of batch 44: 47.87508773803711, 1.0\n",
      "Train loss and acc of batch 45: 48.47077941894531, 0.984375\n",
      "Train loss and acc of batch 46: 48.160926818847656, 0.984375\n",
      "Train loss and acc of batch 47: 47.875064849853516, 1.0\n",
      "Train loss and acc of batch 48: 47.87505340576172, 1.0\n",
      "Train loss and acc of batch 49: 47.87504959106445, 1.0\n",
      "Train loss and acc of batch 50: 48.470741271972656, 0.984375\n",
      "Train loss and acc of batch 51: 49.223960876464844, 0.96875\n",
      "Train loss and acc of batch 52: 49.130859375, 0.953125\n",
      "Train loss and acc of batch 53: 47.87500762939453, 1.0\n",
      "Train loss and acc of batch 54: 48.091766357421875, 0.984375\n",
      "Train loss and acc of batch 55: 47.87499237060547, 1.0\n",
      "Train loss and acc of batch 56: 47.87498474121094, 1.0\n",
      "Train loss and acc of batch 57: 48.470680236816406, 0.984375\n",
      "Train loss and acc of batch 58: 47.87496566772461, 1.0\n",
      "Train loss and acc of batch 59: 47.87495422363281, 1.0\n",
      "Train loss and acc of batch 60: 47.87495040893555, 1.0\n",
      "Train loss and acc of batch 61: 47.874942779541016, 1.0\n",
      "Train loss and acc of batch 62: 48.091697692871094, 0.984375\n",
      "Train loss and acc of batch 63: 49.066322326660156, 0.96875\n",
      "Train loss and acc of batch 64: 48.09168243408203, 0.984375\n",
      "Train loss and acc of batch 65: 47.874908447265625, 1.0\n",
      "Train loss and acc of batch 66: 47.8748893737793, 1.0\n",
      "Train loss and acc of batch 67: 48.687347412109375, 0.96875\n",
      "Train loss and acc of batch 68: 48.4705810546875, 0.984375\n",
      "Train loss and acc of batch 69: 48.09162902832031, 0.984375\n",
      "Train loss and acc of batch 70: 47.87486267089844, 1.0\n",
      "Training accuracy and loss of epoch #290: 0.9892, 48.2031\n",
      "Saved model by train loss 48.203133596500884\n",
      "Train loss and acc of batch 0: 47.87485885620117, 1.0\n",
      "Train loss and acc of batch 1: 47.87484359741211, 1.0\n",
      "Train loss and acc of batch 2: 48.160682678222656, 0.984375\n",
      "Train loss and acc of batch 3: 48.091590881347656, 0.984375\n",
      "Train loss and acc of batch 4: 47.874813079833984, 1.0\n",
      "Train loss and acc of batch 5: 49.223731994628906, 0.96875\n",
      "Train loss and acc of batch 6: 48.377410888671875, 0.96875\n",
      "Train loss and acc of batch 7: 47.874786376953125, 1.0\n",
      "Train loss and acc of batch 8: 48.470481872558594, 0.984375\n",
      "Train loss and acc of batch 9: 48.160621643066406, 0.984375\n",
      "Train loss and acc of batch 10: 47.874759674072266, 1.0\n",
      "Train loss and acc of batch 11: 47.874755859375, 1.0\n",
      "Train loss and acc of batch 12: 48.627967834472656, 0.984375\n",
      "Train loss and acc of batch 13: 48.09149932861328, 0.984375\n",
      "Train loss and acc of batch 14: 48.09149932861328, 0.984375\n",
      "Train loss and acc of batch 15: 48.470420837402344, 0.984375\n",
      "Train loss and acc of batch 16: 48.47041320800781, 0.984375\n",
      "Train loss and acc of batch 17: 48.62792205810547, 0.984375\n",
      "Train loss and acc of batch 18: 48.75624465942383, 0.96875\n",
      "Train loss and acc of batch 19: 47.87468338012695, 1.0\n",
      "Train loss and acc of batch 20: 47.874671936035156, 1.0\n",
      "Train loss and acc of batch 21: 48.470367431640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.470359802246094, 0.984375\n",
      "Train loss and acc of batch 23: 47.87464141845703, 1.0\n",
      "Train loss and acc of batch 24: 48.4703369140625, 0.984375\n",
      "Train loss and acc of batch 25: 47.874629974365234, 1.0\n",
      "Train loss and acc of batch 26: 47.87461853027344, 1.0\n",
      "Train loss and acc of batch 27: 47.87461471557617, 1.0\n",
      "Train loss and acc of batch 28: 47.87460708618164, 1.0\n",
      "Train loss and acc of batch 29: 48.47029113769531, 0.984375\n",
      "Train loss and acc of batch 30: 47.87458801269531, 1.0\n",
      "Train loss and acc of batch 31: 48.091339111328125, 0.984375\n",
      "Train loss and acc of batch 32: 47.874568939208984, 1.0\n",
      "Train loss and acc of batch 33: 47.87455749511719, 1.0\n",
      "Train loss and acc of batch 34: 48.470252990722656, 0.984375\n",
      "Train loss and acc of batch 35: 48.30807113647461, 0.96875\n",
      "Train loss and acc of batch 36: 47.874534606933594, 1.0\n",
      "Train loss and acc of batch 37: 48.627742767333984, 0.984375\n",
      "Train loss and acc of batch 38: 49.22344207763672, 0.96875\n",
      "Train loss and acc of batch 39: 48.091270446777344, 0.984375\n",
      "Train loss and acc of batch 40: 47.87449264526367, 1.0\n",
      "Train loss and acc of batch 41: 49.223411560058594, 0.96875\n",
      "Train loss and acc of batch 42: 47.87448501586914, 1.0\n",
      "Train loss and acc of batch 43: 48.47016906738281, 0.984375\n",
      "Train loss and acc of batch 44: 47.87446212768555, 1.0\n",
      "Train loss and acc of batch 45: 48.47015380859375, 0.984375\n",
      "Train loss and acc of batch 46: 48.16029357910156, 0.984375\n",
      "Train loss and acc of batch 47: 47.87443161010742, 1.0\n",
      "Train loss and acc of batch 48: 47.874420166015625, 1.0\n",
      "Train loss and acc of batch 49: 47.87441635131836, 1.0\n",
      "Train loss and acc of batch 50: 48.470115661621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.22332000732422, 0.96875\n",
      "Train loss and acc of batch 52: 49.130226135253906, 0.953125\n",
      "Train loss and acc of batch 53: 47.8743782043457, 1.0\n",
      "Train loss and acc of batch 54: 48.09113311767578, 0.984375\n",
      "Train loss and acc of batch 55: 47.87436294555664, 1.0\n",
      "Train loss and acc of batch 56: 47.874359130859375, 1.0\n",
      "Train loss and acc of batch 57: 48.47004699707031, 0.984375\n",
      "Train loss and acc of batch 58: 47.87433624267578, 1.0\n",
      "Train loss and acc of batch 59: 47.874324798583984, 1.0\n",
      "Train loss and acc of batch 60: 47.87432098388672, 1.0\n",
      "Train loss and acc of batch 61: 47.87430953979492, 1.0\n",
      "Train loss and acc of batch 62: 48.091064453125, 0.984375\n",
      "Train loss and acc of batch 63: 49.06569290161133, 0.96875\n",
      "Train loss and acc of batch 64: 48.09104919433594, 0.984375\n",
      "Train loss and acc of batch 65: 47.87427520751953, 1.0\n",
      "Train loss and acc of batch 66: 47.874263763427734, 1.0\n",
      "Train loss and acc of batch 67: 48.68672561645508, 0.96875\n",
      "Train loss and acc of batch 68: 48.469947814941406, 0.984375\n",
      "Train loss and acc of batch 69: 48.09100341796875, 0.984375\n",
      "Train loss and acc of batch 70: 47.87423324584961, 1.0\n",
      "Training accuracy and loss of epoch #291: 0.9892, 48.2025\n",
      "Saved model by train loss 48.202503096889444\n",
      "Train loss and acc of batch 0: 47.87421798706055, 1.0\n",
      "Train loss and acc of batch 1: 47.874210357666016, 1.0\n",
      "Train loss and acc of batch 2: 48.160057067871094, 0.984375\n",
      "Train loss and acc of batch 3: 48.09095764160156, 0.984375\n",
      "Train loss and acc of batch 4: 47.87418746948242, 1.0\n",
      "Train loss and acc of batch 5: 49.22309875488281, 0.96875\n",
      "Train loss and acc of batch 6: 48.37678146362305, 0.96875\n",
      "Train loss and acc of batch 7: 47.87416076660156, 1.0\n",
      "Train loss and acc of batch 8: 48.46984100341797, 0.984375\n",
      "Train loss and acc of batch 9: 48.15998840332031, 0.984375\n",
      "Train loss and acc of batch 10: 47.8741340637207, 1.0\n",
      "Train loss and acc of batch 11: 47.87411880493164, 1.0\n",
      "Train loss and acc of batch 12: 48.62733459472656, 0.984375\n",
      "Train loss and acc of batch 13: 48.09087371826172, 0.984375\n",
      "Train loss and acc of batch 14: 48.090858459472656, 0.984375\n",
      "Train loss and acc of batch 15: 48.46978759765625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 16: 48.46977996826172, 0.984375\n",
      "Train loss and acc of batch 17: 48.62729263305664, 0.984375\n",
      "Train loss and acc of batch 18: 48.755615234375, 0.96875\n",
      "Train loss and acc of batch 19: 47.87405014038086, 1.0\n",
      "Train loss and acc of batch 20: 47.87403869628906, 1.0\n",
      "Train loss and acc of batch 21: 48.46973419189453, 0.984375\n",
      "Train loss and acc of batch 22: 48.4697265625, 0.984375\n",
      "Train loss and acc of batch 23: 47.87401580810547, 1.0\n",
      "Train loss and acc of batch 24: 48.46971130371094, 0.984375\n",
      "Train loss and acc of batch 25: 47.87399673461914, 1.0\n",
      "Train loss and acc of batch 26: 47.87398910522461, 1.0\n",
      "Train loss and acc of batch 27: 47.87397766113281, 1.0\n",
      "Train loss and acc of batch 28: 47.873966217041016, 1.0\n",
      "Train loss and acc of batch 29: 48.46966552734375, 0.984375\n",
      "Train loss and acc of batch 30: 47.873958587646484, 1.0\n",
      "Train loss and acc of batch 31: 48.09071350097656, 0.984375\n",
      "Train loss and acc of batch 32: 47.87393569946289, 1.0\n",
      "Train loss and acc of batch 33: 47.873924255371094, 1.0\n",
      "Train loss and acc of batch 34: 48.46961212158203, 0.984375\n",
      "Train loss and acc of batch 35: 48.30744171142578, 0.96875\n",
      "Train loss and acc of batch 36: 47.87389373779297, 1.0\n",
      "Train loss and acc of batch 37: 48.627113342285156, 0.984375\n",
      "Train loss and acc of batch 38: 49.222808837890625, 0.96875\n",
      "Train loss and acc of batch 39: 48.09063720703125, 0.984375\n",
      "Train loss and acc of batch 40: 47.873863220214844, 1.0\n",
      "Train loss and acc of batch 41: 49.22278594970703, 0.96875\n",
      "Train loss and acc of batch 42: 47.873844146728516, 1.0\n",
      "Train loss and acc of batch 43: 48.46953582763672, 0.984375\n",
      "Train loss and acc of batch 44: 47.87382888793945, 1.0\n",
      "Train loss and acc of batch 45: 48.469520568847656, 0.984375\n",
      "Train loss and acc of batch 46: 48.15966033935547, 0.984375\n",
      "Train loss and acc of batch 47: 47.873802185058594, 1.0\n",
      "Train loss and acc of batch 48: 47.87379455566406, 1.0\n",
      "Train loss and acc of batch 49: 47.87378692626953, 1.0\n",
      "Train loss and acc of batch 50: 48.46947479248047, 0.984375\n",
      "Train loss and acc of batch 51: 49.222694396972656, 0.96875\n",
      "Train loss and acc of batch 52: 49.12959671020508, 0.953125\n",
      "Train loss and acc of batch 53: 47.87374496459961, 1.0\n",
      "Train loss and acc of batch 54: 48.09050750732422, 0.984375\n",
      "Train loss and acc of batch 55: 47.87372589111328, 1.0\n",
      "Train loss and acc of batch 56: 47.87371826171875, 1.0\n",
      "Train loss and acc of batch 57: 48.46941375732422, 0.984375\n",
      "Train loss and acc of batch 58: 47.87370681762695, 1.0\n",
      "Train loss and acc of batch 59: 47.873695373535156, 1.0\n",
      "Train loss and acc of batch 60: 47.873687744140625, 1.0\n",
      "Train loss and acc of batch 61: 47.873680114746094, 1.0\n",
      "Train loss and acc of batch 62: 48.090431213378906, 0.984375\n",
      "Train loss and acc of batch 63: 49.0650634765625, 0.96875\n",
      "Train loss and acc of batch 64: 48.090415954589844, 0.984375\n",
      "Train loss and acc of batch 65: 47.87363815307617, 1.0\n",
      "Train loss and acc of batch 66: 47.873634338378906, 1.0\n",
      "Train loss and acc of batch 67: 48.68608474731445, 0.96875\n",
      "Train loss and acc of batch 68: 48.46931457519531, 0.984375\n",
      "Train loss and acc of batch 69: 48.09037780761719, 0.984375\n",
      "Train loss and acc of batch 70: 47.873592376708984, 1.0\n",
      "Training accuracy and loss of epoch #292: 0.9892, 48.2019\n",
      "Saved model by train loss 48.201870824249696\n",
      "Train loss and acc of batch 0: 47.87358474731445, 1.0\n",
      "Train loss and acc of batch 1: 47.87358093261719, 1.0\n",
      "Train loss and acc of batch 2: 48.159423828125, 0.984375\n",
      "Train loss and acc of batch 3: 48.09033203125, 0.984375\n",
      "Train loss and acc of batch 4: 47.873558044433594, 1.0\n",
      "Train loss and acc of batch 5: 49.22247314453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.376155853271484, 0.96875\n",
      "Train loss and acc of batch 7: 47.87352752685547, 1.0\n",
      "Train loss and acc of batch 8: 48.469215393066406, 0.984375\n",
      "Train loss and acc of batch 9: 48.15936279296875, 0.984375\n",
      "Train loss and acc of batch 10: 47.873497009277344, 1.0\n",
      "Train loss and acc of batch 11: 47.87348937988281, 1.0\n",
      "Train loss and acc of batch 12: 48.626705169677734, 0.984375\n",
      "Train loss and acc of batch 13: 48.090232849121094, 0.984375\n",
      "Train loss and acc of batch 14: 48.09022521972656, 0.984375\n",
      "Train loss and acc of batch 15: 48.46916198730469, 0.984375\n",
      "Train loss and acc of batch 16: 48.469146728515625, 0.984375\n",
      "Train loss and acc of batch 17: 48.62666320800781, 0.984375\n",
      "Train loss and acc of batch 18: 48.754981994628906, 0.96875\n",
      "Train loss and acc of batch 19: 47.87342071533203, 1.0\n",
      "Train loss and acc of batch 20: 47.8734130859375, 1.0\n",
      "Train loss and acc of batch 21: 48.46910095214844, 0.984375\n",
      "Train loss and acc of batch 22: 48.469093322753906, 0.984375\n",
      "Train loss and acc of batch 23: 47.87338638305664, 1.0\n",
      "Train loss and acc of batch 24: 48.469078063964844, 0.984375\n",
      "Train loss and acc of batch 25: 47.87336349487305, 1.0\n",
      "Train loss and acc of batch 26: 47.87335968017578, 1.0\n",
      "Train loss and acc of batch 27: 47.87334442138672, 1.0\n",
      "Train loss and acc of batch 28: 47.87334060668945, 1.0\n",
      "Train loss and acc of batch 29: 48.469032287597656, 0.984375\n",
      "Train loss and acc of batch 30: 47.873321533203125, 1.0\n",
      "Train loss and acc of batch 31: 48.09007263183594, 0.984375\n",
      "Train loss and acc of batch 32: 47.8733024597168, 1.0\n",
      "Train loss and acc of batch 33: 47.873294830322266, 1.0\n",
      "Train loss and acc of batch 34: 48.468994140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.30680465698242, 0.96875\n",
      "Train loss and acc of batch 36: 47.87326431274414, 1.0\n",
      "Train loss and acc of batch 37: 48.62648010253906, 0.984375\n",
      "Train loss and acc of batch 38: 49.22217559814453, 0.96875\n",
      "Train loss and acc of batch 39: 48.090003967285156, 0.984375\n",
      "Train loss and acc of batch 40: 47.87322998046875, 1.0\n",
      "Train loss and acc of batch 41: 49.22214889526367, 0.96875\n",
      "Train loss and acc of batch 42: 47.87321472167969, 1.0\n",
      "Train loss and acc of batch 43: 48.468902587890625, 0.984375\n",
      "Train loss and acc of batch 44: 47.87319564819336, 1.0\n",
      "Train loss and acc of batch 45: 48.46888732910156, 0.984375\n",
      "Train loss and acc of batch 46: 48.159027099609375, 0.984375\n",
      "Train loss and acc of batch 47: 47.8731689453125, 1.0\n",
      "Train loss and acc of batch 48: 47.873165130615234, 1.0\n",
      "Train loss and acc of batch 49: 47.87315368652344, 1.0\n",
      "Train loss and acc of batch 50: 48.468841552734375, 0.984375\n",
      "Train loss and acc of batch 51: 49.22206115722656, 0.96875\n",
      "Train loss and acc of batch 52: 49.128963470458984, 0.953125\n",
      "Train loss and acc of batch 53: 47.87311935424805, 1.0\n",
      "Train loss and acc of batch 54: 48.089874267578125, 0.984375\n",
      "Train loss and acc of batch 55: 47.87309646606445, 1.0\n",
      "Train loss and acc of batch 56: 47.87308883666992, 1.0\n",
      "Train loss and acc of batch 57: 48.468788146972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.873069763183594, 1.0\n",
      "Train loss and acc of batch 59: 47.87306213378906, 1.0\n",
      "Train loss and acc of batch 60: 47.87305450439453, 1.0\n",
      "Train loss and acc of batch 61: 47.873046875, 1.0\n",
      "Train loss and acc of batch 62: 48.089805603027344, 0.984375\n",
      "Train loss and acc of batch 63: 49.064430236816406, 0.96875\n",
      "Train loss and acc of batch 64: 48.08977508544922, 0.984375\n",
      "Train loss and acc of batch 65: 47.87301254272461, 1.0\n",
      "Train loss and acc of batch 66: 47.87299728393555, 1.0\n",
      "Train loss and acc of batch 67: 48.68545913696289, 0.96875\n",
      "Train loss and acc of batch 68: 48.46868133544922, 0.984375\n",
      "Train loss and acc of batch 69: 48.08973693847656, 0.984375\n",
      "Train loss and acc of batch 70: 47.872962951660156, 1.0\n",
      "Training accuracy and loss of epoch #293: 0.9892, 48.2012\n",
      "Saved model by train loss 48.20123925007565\n",
      "Train loss and acc of batch 0: 47.87295913696289, 1.0\n",
      "Train loss and acc of batch 1: 47.87294387817383, 1.0\n",
      "Train loss and acc of batch 2: 48.158790588378906, 0.984375\n",
      "Train loss and acc of batch 3: 48.089691162109375, 0.984375\n",
      "Train loss and acc of batch 4: 47.872920989990234, 1.0\n",
      "Train loss and acc of batch 5: 49.221839904785156, 0.96875\n",
      "Train loss and acc of batch 6: 48.37552261352539, 0.96875\n",
      "Train loss and acc of batch 7: 47.872894287109375, 1.0\n",
      "Train loss and acc of batch 8: 48.468589782714844, 0.984375\n",
      "Train loss and acc of batch 9: 48.158729553222656, 0.984375\n",
      "Train loss and acc of batch 10: 47.872867584228516, 1.0\n",
      "Train loss and acc of batch 11: 47.872859954833984, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 12: 48.626068115234375, 0.984375\n",
      "Train loss and acc of batch 13: 48.08960723876953, 0.984375\n",
      "Train loss and acc of batch 14: 48.089599609375, 0.984375\n",
      "Train loss and acc of batch 15: 48.46852111816406, 0.984375\n",
      "Train loss and acc of batch 16: 48.46851348876953, 0.984375\n",
      "Train loss and acc of batch 17: 48.62602615356445, 0.984375\n",
      "Train loss and acc of batch 18: 48.75434875488281, 0.96875\n",
      "Train loss and acc of batch 19: 47.87278747558594, 1.0\n",
      "Train loss and acc of batch 20: 47.87277603149414, 1.0\n",
      "Train loss and acc of batch 21: 48.468475341796875, 0.984375\n",
      "Train loss and acc of batch 22: 48.46846008300781, 0.984375\n",
      "Train loss and acc of batch 23: 47.87274932861328, 1.0\n",
      "Train loss and acc of batch 24: 48.46844482421875, 0.984375\n",
      "Train loss and acc of batch 25: 47.87273025512695, 1.0\n",
      "Train loss and acc of batch 26: 47.872718811035156, 1.0\n",
      "Train loss and acc of batch 27: 47.872718811035156, 1.0\n",
      "Train loss and acc of batch 28: 47.872703552246094, 1.0\n",
      "Train loss and acc of batch 29: 48.46839904785156, 0.984375\n",
      "Train loss and acc of batch 30: 47.872684478759766, 1.0\n",
      "Train loss and acc of batch 31: 48.089439392089844, 0.984375\n",
      "Train loss and acc of batch 32: 47.8726692199707, 1.0\n",
      "Train loss and acc of batch 33: 47.87266159057617, 1.0\n",
      "Train loss and acc of batch 34: 48.468353271484375, 0.984375\n",
      "Train loss and acc of batch 35: 48.306175231933594, 0.96875\n",
      "Train loss and acc of batch 36: 47.87263488769531, 1.0\n",
      "Train loss and acc of batch 37: 48.625850677490234, 0.984375\n",
      "Train loss and acc of batch 38: 49.22154235839844, 0.96875\n",
      "Train loss and acc of batch 39: 48.089378356933594, 0.984375\n",
      "Train loss and acc of batch 40: 47.87260055541992, 1.0\n",
      "Train loss and acc of batch 41: 49.22151565551758, 0.96875\n",
      "Train loss and acc of batch 42: 47.872581481933594, 1.0\n",
      "Train loss and acc of batch 43: 48.46827697753906, 0.984375\n",
      "Train loss and acc of batch 44: 47.87256622314453, 1.0\n",
      "Train loss and acc of batch 45: 48.46825408935547, 0.984375\n",
      "Train loss and acc of batch 46: 48.15840148925781, 0.984375\n",
      "Train loss and acc of batch 47: 47.87253952026367, 1.0\n",
      "Train loss and acc of batch 48: 47.872528076171875, 1.0\n",
      "Train loss and acc of batch 49: 47.872520446777344, 1.0\n",
      "Train loss and acc of batch 50: 48.46821594238281, 0.984375\n",
      "Train loss and acc of batch 51: 49.22142791748047, 0.96875\n",
      "Train loss and acc of batch 52: 49.12833786010742, 0.953125\n",
      "Train loss and acc of batch 53: 47.87247848510742, 1.0\n",
      "Train loss and acc of batch 54: 48.08924102783203, 0.984375\n",
      "Train loss and acc of batch 55: 47.872467041015625, 1.0\n",
      "Train loss and acc of batch 56: 47.872459411621094, 1.0\n",
      "Train loss and acc of batch 57: 48.46815490722656, 0.984375\n",
      "Train loss and acc of batch 58: 47.87244415283203, 1.0\n",
      "Train loss and acc of batch 59: 47.8724250793457, 1.0\n",
      "Train loss and acc of batch 60: 47.87242126464844, 1.0\n",
      "Train loss and acc of batch 61: 47.87240982055664, 1.0\n",
      "Train loss and acc of batch 62: 48.08916473388672, 0.984375\n",
      "Train loss and acc of batch 63: 49.06379699707031, 0.96875\n",
      "Train loss and acc of batch 64: 48.089149475097656, 0.984375\n",
      "Train loss and acc of batch 65: 47.87237548828125, 1.0\n",
      "Train loss and acc of batch 66: 47.872371673583984, 1.0\n",
      "Train loss and acc of batch 67: 48.6848258972168, 0.96875\n",
      "Train loss and acc of batch 68: 48.468048095703125, 0.984375\n",
      "Train loss and acc of batch 69: 48.08910369873047, 0.984375\n",
      "Train loss and acc of batch 70: 47.87233352661133, 1.0\n",
      "Training accuracy and loss of epoch #294: 0.9892, 48.2006\n",
      "Saved model by train loss 48.200606816251515\n",
      "Train loss and acc of batch 0: 47.87232208251953, 1.0\n",
      "Train loss and acc of batch 1: 47.872310638427734, 1.0\n",
      "Train loss and acc of batch 2: 48.15815734863281, 0.984375\n",
      "Train loss and acc of batch 3: 48.08905792236328, 0.984375\n",
      "Train loss and acc of batch 4: 47.87228775024414, 1.0\n",
      "Train loss and acc of batch 5: 49.22120666503906, 0.96875\n",
      "Train loss and acc of batch 6: 48.3748893737793, 0.96875\n",
      "Train loss and acc of batch 7: 47.87226104736328, 1.0\n",
      "Train loss and acc of batch 8: 48.46795654296875, 0.984375\n",
      "Train loss and acc of batch 9: 48.158103942871094, 0.984375\n",
      "Train loss and acc of batch 10: 47.87223815917969, 1.0\n",
      "Train loss and acc of batch 11: 47.872222900390625, 1.0\n",
      "Train loss and acc of batch 12: 48.62544250488281, 0.984375\n",
      "Train loss and acc of batch 13: 48.08897399902344, 0.984375\n",
      "Train loss and acc of batch 14: 48.088966369628906, 0.984375\n",
      "Train loss and acc of batch 15: 48.46788787841797, 0.984375\n",
      "Train loss and acc of batch 16: 48.46788787841797, 0.984375\n",
      "Train loss and acc of batch 17: 48.62539291381836, 0.984375\n",
      "Train loss and acc of batch 18: 48.75371551513672, 0.96875\n",
      "Train loss and acc of batch 19: 47.87215042114258, 1.0\n",
      "Train loss and acc of batch 20: 47.87214660644531, 1.0\n",
      "Train loss and acc of batch 21: 48.46783447265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.46782684326172, 0.984375\n",
      "Train loss and acc of batch 23: 47.87212371826172, 1.0\n",
      "Train loss and acc of batch 24: 48.46781921386719, 0.984375\n",
      "Train loss and acc of batch 25: 47.87209701538086, 1.0\n",
      "Train loss and acc of batch 26: 47.87209701538086, 1.0\n",
      "Train loss and acc of batch 27: 47.87208557128906, 1.0\n",
      "Train loss and acc of batch 28: 47.87207794189453, 1.0\n",
      "Train loss and acc of batch 29: 48.46776580810547, 0.984375\n",
      "Train loss and acc of batch 30: 47.87205505371094, 1.0\n",
      "Train loss and acc of batch 31: 48.08881378173828, 0.984375\n",
      "Train loss and acc of batch 32: 47.87203598022461, 1.0\n",
      "Train loss and acc of batch 33: 47.872032165527344, 1.0\n",
      "Train loss and acc of batch 34: 48.46772003173828, 0.984375\n",
      "Train loss and acc of batch 35: 48.3055419921875, 0.96875\n",
      "Train loss and acc of batch 36: 47.87200164794922, 1.0\n",
      "Train loss and acc of batch 37: 48.625221252441406, 0.984375\n",
      "Train loss and acc of batch 38: 49.220916748046875, 0.96875\n",
      "Train loss and acc of batch 39: 48.0887451171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.871971130371094, 1.0\n",
      "Train loss and acc of batch 41: 49.22088623046875, 0.96875\n",
      "Train loss and acc of batch 42: 47.871952056884766, 1.0\n",
      "Train loss and acc of batch 43: 48.46764373779297, 0.984375\n",
      "Train loss and acc of batch 44: 47.87193298339844, 1.0\n",
      "Train loss and acc of batch 45: 48.467628479003906, 0.984375\n",
      "Train loss and acc of batch 46: 48.15776824951172, 0.984375\n",
      "Train loss and acc of batch 47: 47.87190246582031, 1.0\n",
      "Train loss and acc of batch 48: 47.87189483642578, 1.0\n",
      "Train loss and acc of batch 49: 47.87188720703125, 1.0\n",
      "Train loss and acc of batch 50: 48.46757507324219, 0.984375\n",
      "Train loss and acc of batch 51: 49.220794677734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.12770462036133, 0.953125\n",
      "Train loss and acc of batch 53: 47.87185287475586, 1.0\n",
      "Train loss and acc of batch 54: 48.08860778808594, 0.984375\n",
      "Train loss and acc of batch 55: 47.8718376159668, 1.0\n",
      "Train loss and acc of batch 56: 47.871826171875, 1.0\n",
      "Train loss and acc of batch 57: 48.46751403808594, 0.984375\n",
      "Train loss and acc of batch 58: 47.871803283691406, 1.0\n",
      "Train loss and acc of batch 59: 47.87179946899414, 1.0\n",
      "Train loss and acc of batch 60: 47.871788024902344, 1.0\n",
      "Train loss and acc of batch 61: 47.87178039550781, 1.0\n",
      "Train loss and acc of batch 62: 48.088531494140625, 0.984375\n",
      "Train loss and acc of batch 63: 49.06315994262695, 0.96875\n",
      "Train loss and acc of batch 64: 48.08851623535156, 0.984375\n",
      "Train loss and acc of batch 65: 47.87174606323242, 1.0\n",
      "Train loss and acc of batch 66: 47.871734619140625, 1.0\n",
      "Train loss and acc of batch 67: 48.68418884277344, 0.96875\n",
      "Train loss and acc of batch 68: 48.46742248535156, 0.984375\n",
      "Train loss and acc of batch 69: 48.088470458984375, 0.984375\n",
      "Train loss and acc of batch 70: 47.871700286865234, 1.0\n",
      "Training accuracy and loss of epoch #295: 0.9892, 48.2000\n",
      "Saved model by train loss 48.19997481225242\n",
      "Train loss and acc of batch 0: 47.87168884277344, 1.0\n",
      "Train loss and acc of batch 1: 47.871681213378906, 1.0\n",
      "Train loss and acc of batch 2: 48.15752410888672, 0.984375\n",
      "Train loss and acc of batch 3: 48.08842468261719, 0.984375\n",
      "Train loss and acc of batch 4: 47.87165069580078, 1.0\n",
      "Train loss and acc of batch 5: 49.22056579589844, 0.96875\n",
      "Train loss and acc of batch 6: 48.37424850463867, 0.96875\n",
      "Train loss and acc of batch 7: 47.87162780761719, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 8: 48.467315673828125, 0.984375\n",
      "Train loss and acc of batch 9: 48.15746307373047, 0.984375\n",
      "Train loss and acc of batch 10: 47.87159729003906, 1.0\n",
      "Train loss and acc of batch 11: 47.8715934753418, 1.0\n",
      "Train loss and acc of batch 12: 48.62480163574219, 0.984375\n",
      "Train loss and acc of batch 13: 48.088340759277344, 0.984375\n",
      "Train loss and acc of batch 14: 48.08832550048828, 0.984375\n",
      "Train loss and acc of batch 15: 48.467262268066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.467247009277344, 0.984375\n",
      "Train loss and acc of batch 17: 48.6247673034668, 0.984375\n",
      "Train loss and acc of batch 18: 48.75308609008789, 0.96875\n",
      "Train loss and acc of batch 19: 47.871517181396484, 1.0\n",
      "Train loss and acc of batch 20: 47.87150955200195, 1.0\n",
      "Train loss and acc of batch 21: 48.467201232910156, 0.984375\n",
      "Train loss and acc of batch 22: 48.467193603515625, 0.984375\n",
      "Train loss and acc of batch 23: 47.87148666381836, 1.0\n",
      "Train loss and acc of batch 24: 48.46717834472656, 0.984375\n",
      "Train loss and acc of batch 25: 47.87146759033203, 1.0\n",
      "Train loss and acc of batch 26: 47.8714599609375, 1.0\n",
      "Train loss and acc of batch 27: 47.8714485168457, 1.0\n",
      "Train loss and acc of batch 28: 47.87144088745117, 1.0\n",
      "Train loss and acc of batch 29: 48.467132568359375, 0.984375\n",
      "Train loss and acc of batch 30: 47.87142562866211, 1.0\n",
      "Train loss and acc of batch 31: 48.08818054199219, 0.984375\n",
      "Train loss and acc of batch 32: 47.871402740478516, 1.0\n",
      "Train loss and acc of batch 33: 47.87139892578125, 1.0\n",
      "Train loss and acc of batch 34: 48.46708679199219, 0.984375\n",
      "Train loss and acc of batch 35: 48.30490493774414, 0.96875\n",
      "Train loss and acc of batch 36: 47.871368408203125, 1.0\n",
      "Train loss and acc of batch 37: 48.62458419799805, 0.984375\n",
      "Train loss and acc of batch 38: 49.22027587890625, 0.96875\n",
      "Train loss and acc of batch 39: 48.088104248046875, 0.984375\n",
      "Train loss and acc of batch 40: 47.871334075927734, 1.0\n",
      "Train loss and acc of batch 41: 49.22024917602539, 0.96875\n",
      "Train loss and acc of batch 42: 47.87131118774414, 1.0\n",
      "Train loss and acc of batch 43: 48.467010498046875, 0.984375\n",
      "Train loss and acc of batch 44: 47.871299743652344, 1.0\n",
      "Train loss and acc of batch 45: 48.46699523925781, 0.984375\n",
      "Train loss and acc of batch 46: 48.157127380371094, 0.984375\n",
      "Train loss and acc of batch 47: 47.871273040771484, 1.0\n",
      "Train loss and acc of batch 48: 47.87126159667969, 1.0\n",
      "Train loss and acc of batch 49: 47.87125015258789, 1.0\n",
      "Train loss and acc of batch 50: 48.466941833496094, 0.984375\n",
      "Train loss and acc of batch 51: 49.22015380859375, 0.96875\n",
      "Train loss and acc of batch 52: 49.12706756591797, 0.953125\n",
      "Train loss and acc of batch 53: 47.8712158203125, 1.0\n",
      "Train loss and acc of batch 54: 48.087974548339844, 0.984375\n",
      "Train loss and acc of batch 55: 47.87120056152344, 1.0\n",
      "Train loss and acc of batch 56: 47.87118911743164, 1.0\n",
      "Train loss and acc of batch 57: 48.466880798339844, 0.984375\n",
      "Train loss and acc of batch 58: 47.87117385864258, 1.0\n",
      "Train loss and acc of batch 59: 47.87116622924805, 1.0\n",
      "Train loss and acc of batch 60: 47.871150970458984, 1.0\n",
      "Train loss and acc of batch 61: 47.87114715576172, 1.0\n",
      "Train loss and acc of batch 62: 48.08789825439453, 0.984375\n",
      "Train loss and acc of batch 63: 49.062530517578125, 0.96875\n",
      "Train loss and acc of batch 64: 48.08788299560547, 0.984375\n",
      "Train loss and acc of batch 65: 47.87111282348633, 1.0\n",
      "Train loss and acc of batch 66: 47.87110137939453, 1.0\n",
      "Train loss and acc of batch 67: 48.68355941772461, 0.96875\n",
      "Train loss and acc of batch 68: 48.46678161621094, 0.984375\n",
      "Train loss and acc of batch 69: 48.08784484863281, 0.984375\n",
      "Train loss and acc of batch 70: 47.871063232421875, 1.0\n",
      "Training accuracy and loss of epoch #296: 0.9892, 48.1993\n",
      "Saved model by train loss 48.19933985320615\n",
      "Train loss and acc of batch 0: 47.87105941772461, 1.0\n",
      "Train loss and acc of batch 1: 47.87104797363281, 1.0\n",
      "Train loss and acc of batch 2: 48.156898498535156, 0.984375\n",
      "Train loss and acc of batch 3: 48.087799072265625, 0.984375\n",
      "Train loss and acc of batch 4: 47.87102508544922, 1.0\n",
      "Train loss and acc of batch 5: 49.219940185546875, 0.96875\n",
      "Train loss and acc of batch 6: 48.37362289428711, 0.96875\n",
      "Train loss and acc of batch 7: 47.87099075317383, 1.0\n",
      "Train loss and acc of batch 8: 48.46669006347656, 0.984375\n",
      "Train loss and acc of batch 9: 48.156829833984375, 0.984375\n",
      "Train loss and acc of batch 10: 47.870967864990234, 1.0\n",
      "Train loss and acc of batch 11: 47.8709602355957, 1.0\n",
      "Train loss and acc of batch 12: 48.624176025390625, 0.984375\n",
      "Train loss and acc of batch 13: 48.08770751953125, 0.984375\n",
      "Train loss and acc of batch 14: 48.08769226074219, 0.984375\n",
      "Train loss and acc of batch 15: 48.46662139892578, 0.984375\n",
      "Train loss and acc of batch 16: 48.46661376953125, 0.984375\n",
      "Train loss and acc of batch 17: 48.62413024902344, 0.984375\n",
      "Train loss and acc of batch 18: 48.7524528503418, 0.96875\n",
      "Train loss and acc of batch 19: 47.870887756347656, 1.0\n",
      "Train loss and acc of batch 20: 47.870880126953125, 1.0\n",
      "Train loss and acc of batch 21: 48.46656799316406, 0.984375\n",
      "Train loss and acc of batch 22: 48.46656036376953, 0.984375\n",
      "Train loss and acc of batch 23: 47.870849609375, 1.0\n",
      "Train loss and acc of batch 24: 48.46654510498047, 0.984375\n",
      "Train loss and acc of batch 25: 47.87083435058594, 1.0\n",
      "Train loss and acc of batch 26: 47.870826721191406, 1.0\n",
      "Train loss and acc of batch 27: 47.870819091796875, 1.0\n",
      "Train loss and acc of batch 28: 47.87080764770508, 1.0\n",
      "Train loss and acc of batch 29: 48.46649932861328, 0.984375\n",
      "Train loss and acc of batch 30: 47.870792388916016, 1.0\n",
      "Train loss and acc of batch 31: 48.087547302246094, 0.984375\n",
      "Train loss and acc of batch 32: 47.87077331542969, 1.0\n",
      "Train loss and acc of batch 33: 47.870765686035156, 1.0\n",
      "Train loss and acc of batch 34: 48.466453552246094, 0.984375\n",
      "Train loss and acc of batch 35: 48.30427169799805, 0.96875\n",
      "Train loss and acc of batch 36: 47.87073516845703, 1.0\n",
      "Train loss and acc of batch 37: 48.62394714355469, 0.984375\n",
      "Train loss and acc of batch 38: 49.219642639160156, 0.96875\n",
      "Train loss and acc of batch 39: 48.08747863769531, 0.984375\n",
      "Train loss and acc of batch 40: 47.870697021484375, 1.0\n",
      "Train loss and acc of batch 41: 49.21961975097656, 0.96875\n",
      "Train loss and acc of batch 42: 47.87068176269531, 1.0\n",
      "Train loss and acc of batch 43: 48.46637725830078, 0.984375\n",
      "Train loss and acc of batch 44: 47.870662689208984, 1.0\n",
      "Train loss and acc of batch 45: 48.46636199951172, 0.984375\n",
      "Train loss and acc of batch 46: 48.156494140625, 0.984375\n",
      "Train loss and acc of batch 47: 47.870643615722656, 1.0\n",
      "Train loss and acc of batch 48: 47.870628356933594, 1.0\n",
      "Train loss and acc of batch 49: 47.8706169128418, 1.0\n",
      "Train loss and acc of batch 50: 48.46631622314453, 0.984375\n",
      "Train loss and acc of batch 51: 49.21952819824219, 0.96875\n",
      "Train loss and acc of batch 52: 49.126434326171875, 0.953125\n",
      "Train loss and acc of batch 53: 47.870582580566406, 1.0\n",
      "Train loss and acc of batch 54: 48.08734130859375, 0.984375\n",
      "Train loss and acc of batch 55: 47.870567321777344, 1.0\n",
      "Train loss and acc of batch 56: 47.87055969238281, 1.0\n",
      "Train loss and acc of batch 57: 48.46624755859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.87054443359375, 1.0\n",
      "Train loss and acc of batch 59: 47.87053298950195, 1.0\n",
      "Train loss and acc of batch 60: 47.87052536010742, 1.0\n",
      "Train loss and acc of batch 61: 47.870513916015625, 1.0\n",
      "Train loss and acc of batch 62: 48.08727264404297, 0.984375\n",
      "Train loss and acc of batch 63: 49.06189727783203, 0.96875\n",
      "Train loss and acc of batch 64: 48.087257385253906, 0.984375\n",
      "Train loss and acc of batch 65: 47.87047576904297, 1.0\n",
      "Train loss and acc of batch 66: 47.87046813964844, 1.0\n",
      "Train loss and acc of batch 67: 48.682926177978516, 0.96875\n",
      "Train loss and acc of batch 68: 48.466156005859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.08720397949219, 0.984375\n",
      "Train loss and acc of batch 70: 47.87043380737305, 1.0\n",
      "Training accuracy and loss of epoch #297: 0.9892, 48.1987\n",
      "Saved model by train loss 48.198708171575845\n",
      "Train loss and acc of batch 0: 47.87042236328125, 1.0\n",
      "Train loss and acc of batch 1: 47.87041473388672, 1.0\n",
      "Train loss and acc of batch 2: 48.15625762939453, 0.984375\n",
      "Train loss and acc of batch 3: 48.08716583251953, 0.984375\n",
      "Train loss and acc of batch 4: 47.870391845703125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 5: 49.21930694580078, 0.96875\n",
      "Train loss and acc of batch 6: 48.37299346923828, 0.96875\n",
      "Train loss and acc of batch 7: 47.870361328125, 1.0\n",
      "Train loss and acc of batch 8: 48.46605682373047, 0.984375\n",
      "Train loss and acc of batch 9: 48.15619659423828, 0.984375\n",
      "Train loss and acc of batch 10: 47.87033462524414, 1.0\n",
      "Train loss and acc of batch 11: 47.87032699584961, 1.0\n",
      "Train loss and acc of batch 12: 48.62354278564453, 0.984375\n",
      "Train loss and acc of batch 13: 48.087074279785156, 0.984375\n",
      "Train loss and acc of batch 14: 48.087066650390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.46599578857422, 0.984375\n",
      "Train loss and acc of batch 16: 48.46598815917969, 0.984375\n",
      "Train loss and acc of batch 17: 48.623497009277344, 0.984375\n",
      "Train loss and acc of batch 18: 48.7518196105957, 0.96875\n",
      "Train loss and acc of batch 19: 47.87025833129883, 1.0\n",
      "Train loss and acc of batch 20: 47.87024688720703, 1.0\n",
      "Train loss and acc of batch 21: 48.4659423828125, 0.984375\n",
      "Train loss and acc of batch 22: 48.46593475341797, 0.984375\n",
      "Train loss and acc of batch 23: 47.870216369628906, 1.0\n",
      "Train loss and acc of batch 24: 48.465911865234375, 0.984375\n",
      "Train loss and acc of batch 25: 47.87020492553711, 1.0\n",
      "Train loss and acc of batch 26: 47.87019348144531, 1.0\n",
      "Train loss and acc of batch 27: 47.870182037353516, 1.0\n",
      "Train loss and acc of batch 28: 47.87017822265625, 1.0\n",
      "Train loss and acc of batch 29: 48.46586608886719, 0.984375\n",
      "Train loss and acc of batch 30: 47.87015914916992, 1.0\n",
      "Train loss and acc of batch 31: 48.0869140625, 0.984375\n",
      "Train loss and acc of batch 32: 47.87014389038086, 1.0\n",
      "Train loss and acc of batch 33: 47.87013244628906, 1.0\n",
      "Train loss and acc of batch 34: 48.4658203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.30364227294922, 0.96875\n",
      "Train loss and acc of batch 36: 47.87010955810547, 1.0\n",
      "Train loss and acc of batch 37: 48.62331771850586, 0.984375\n",
      "Train loss and acc of batch 38: 49.21900939941406, 0.96875\n",
      "Train loss and acc of batch 39: 48.08684539794922, 0.984375\n",
      "Train loss and acc of batch 40: 47.87006759643555, 1.0\n",
      "Train loss and acc of batch 41: 49.21898651123047, 0.96875\n",
      "Train loss and acc of batch 42: 47.870052337646484, 1.0\n",
      "Train loss and acc of batch 43: 48.46574401855469, 0.984375\n",
      "Train loss and acc of batch 44: 47.870033264160156, 1.0\n",
      "Train loss and acc of batch 45: 48.465728759765625, 0.984375\n",
      "Train loss and acc of batch 46: 48.15586853027344, 0.984375\n",
      "Train loss and acc of batch 47: 47.8700065612793, 1.0\n",
      "Train loss and acc of batch 48: 47.8699951171875, 1.0\n",
      "Train loss and acc of batch 49: 47.869991302490234, 1.0\n",
      "Train loss and acc of batch 50: 48.46568298339844, 0.984375\n",
      "Train loss and acc of batch 51: 49.218894958496094, 0.96875\n",
      "Train loss and acc of batch 52: 49.12580108642578, 0.953125\n",
      "Train loss and acc of batch 53: 47.86995315551758, 1.0\n",
      "Train loss and acc of batch 54: 48.086708068847656, 0.984375\n",
      "Train loss and acc of batch 55: 47.86993408203125, 1.0\n",
      "Train loss and acc of batch 56: 47.86992645263672, 1.0\n",
      "Train loss and acc of batch 57: 48.46562194824219, 0.984375\n",
      "Train loss and acc of batch 58: 47.869911193847656, 1.0\n",
      "Train loss and acc of batch 59: 47.86989974975586, 1.0\n",
      "Train loss and acc of batch 60: 47.86989212036133, 1.0\n",
      "Train loss and acc of batch 61: 47.8698844909668, 1.0\n",
      "Train loss and acc of batch 62: 48.086639404296875, 0.984375\n",
      "Train loss and acc of batch 63: 49.0612678527832, 0.96875\n",
      "Train loss and acc of batch 64: 48.08662414550781, 0.984375\n",
      "Train loss and acc of batch 65: 47.869842529296875, 1.0\n",
      "Train loss and acc of batch 66: 47.869834899902344, 1.0\n",
      "Train loss and acc of batch 67: 48.68229675292969, 0.96875\n",
      "Train loss and acc of batch 68: 48.46551513671875, 0.984375\n",
      "Train loss and acc of batch 69: 48.086578369140625, 0.984375\n",
      "Train loss and acc of batch 70: 47.86980438232422, 1.0\n",
      "Training accuracy and loss of epoch #298: 0.9892, 48.1981\n",
      "Saved model by train loss 48.198076489945535\n",
      "Train loss and acc of batch 0: 47.86979675292969, 1.0\n",
      "Train loss and acc of batch 1: 47.86978530883789, 1.0\n",
      "Train loss and acc of batch 2: 48.15562438964844, 0.984375\n",
      "Train loss and acc of batch 3: 48.08653259277344, 0.984375\n",
      "Train loss and acc of batch 4: 47.86975860595703, 1.0\n",
      "Train loss and acc of batch 5: 49.21867370605469, 0.96875\n",
      "Train loss and acc of batch 6: 48.37236022949219, 0.96875\n",
      "Train loss and acc of batch 7: 47.86973190307617, 1.0\n",
      "Train loss and acc of batch 8: 48.465423583984375, 0.984375\n",
      "Train loss and acc of batch 9: 48.15556335449219, 0.984375\n",
      "Train loss and acc of batch 10: 47.86970520019531, 1.0\n",
      "Train loss and acc of batch 11: 47.869693756103516, 1.0\n",
      "Train loss and acc of batch 12: 48.62290573120117, 0.984375\n",
      "Train loss and acc of batch 13: 48.08644104003906, 0.984375\n",
      "Train loss and acc of batch 14: 48.08643341064453, 0.984375\n",
      "Train loss and acc of batch 15: 48.465362548828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.46534729003906, 0.984375\n",
      "Train loss and acc of batch 17: 48.622867584228516, 0.984375\n",
      "Train loss and acc of batch 18: 48.75118637084961, 0.96875\n",
      "Train loss and acc of batch 19: 47.869625091552734, 1.0\n",
      "Train loss and acc of batch 20: 47.86961364746094, 1.0\n",
      "Train loss and acc of batch 21: 48.465309143066406, 0.984375\n",
      "Train loss and acc of batch 22: 48.465301513671875, 0.984375\n",
      "Train loss and acc of batch 23: 47.86958694458008, 1.0\n",
      "Train loss and acc of batch 24: 48.46527862548828, 0.984375\n",
      "Train loss and acc of batch 25: 47.86956787109375, 1.0\n",
      "Train loss and acc of batch 26: 47.86956024169922, 1.0\n",
      "Train loss and acc of batch 27: 47.86955642700195, 1.0\n",
      "Train loss and acc of batch 28: 47.869544982910156, 1.0\n",
      "Train loss and acc of batch 29: 48.465240478515625, 0.984375\n",
      "Train loss and acc of batch 30: 47.86952590942383, 1.0\n",
      "Train loss and acc of batch 31: 48.086280822753906, 0.984375\n",
      "Train loss and acc of batch 32: 47.8695068359375, 1.0\n",
      "Train loss and acc of batch 33: 47.869503021240234, 1.0\n",
      "Train loss and acc of batch 34: 48.465187072753906, 0.984375\n",
      "Train loss and acc of batch 35: 48.303009033203125, 0.96875\n",
      "Train loss and acc of batch 36: 47.869476318359375, 1.0\n",
      "Train loss and acc of batch 37: 48.62268829345703, 0.984375\n",
      "Train loss and acc of batch 38: 49.21837615966797, 0.96875\n",
      "Train loss and acc of batch 39: 48.086212158203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.86943435668945, 1.0\n",
      "Train loss and acc of batch 41: 49.21835708618164, 0.96875\n",
      "Train loss and acc of batch 42: 47.86941909790039, 1.0\n",
      "Train loss and acc of batch 43: 48.465110778808594, 0.984375\n",
      "Train loss and acc of batch 44: 47.86940002441406, 1.0\n",
      "Train loss and acc of batch 45: 48.46509552001953, 0.984375\n",
      "Train loss and acc of batch 46: 48.155235290527344, 0.984375\n",
      "Train loss and acc of batch 47: 47.86937713623047, 1.0\n",
      "Train loss and acc of batch 48: 47.86936569213867, 1.0\n",
      "Train loss and acc of batch 49: 47.869354248046875, 1.0\n",
      "Train loss and acc of batch 50: 48.465049743652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.21826934814453, 0.96875\n",
      "Train loss and acc of batch 52: 49.12517166137695, 0.953125\n",
      "Train loss and acc of batch 53: 47.869319915771484, 1.0\n",
      "Train loss and acc of batch 54: 48.08607482910156, 0.984375\n",
      "Train loss and acc of batch 55: 47.86930465698242, 1.0\n",
      "Train loss and acc of batch 56: 47.86929702758789, 1.0\n",
      "Train loss and acc of batch 57: 48.464988708496094, 0.984375\n",
      "Train loss and acc of batch 58: 47.86928176879883, 1.0\n",
      "Train loss and acc of batch 59: 47.86927032470703, 1.0\n",
      "Train loss and acc of batch 60: 47.869258880615234, 1.0\n",
      "Train loss and acc of batch 61: 47.8692512512207, 1.0\n",
      "Train loss and acc of batch 62: 48.08600616455078, 0.984375\n",
      "Train loss and acc of batch 63: 49.06063461303711, 0.96875\n",
      "Train loss and acc of batch 64: 48.08599090576172, 0.984375\n",
      "Train loss and acc of batch 65: 47.86921310424805, 1.0\n",
      "Train loss and acc of batch 66: 47.86920928955078, 1.0\n",
      "Train loss and acc of batch 67: 48.681663513183594, 0.96875\n",
      "Train loss and acc of batch 68: 48.464881896972656, 0.984375\n",
      "Train loss and acc of batch 69: 48.08594512939453, 0.984375\n",
      "Train loss and acc of batch 70: 47.869171142578125, 1.0\n",
      "Training accuracy and loss of epoch #299: 0.9892, 48.1974\n",
      "Saved model by train loss 48.197444324762046\n",
      "Train loss and acc of batch 0: 47.86915969848633, 1.0\n",
      "Train loss and acc of batch 1: 47.86915588378906, 1.0\n",
      "Train loss and acc of batch 2: 48.154998779296875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 3: 48.085899353027344, 0.984375\n",
      "Train loss and acc of batch 4: 47.86912536621094, 1.0\n",
      "Train loss and acc of batch 5: 49.218040466308594, 0.96875\n",
      "Train loss and acc of batch 6: 48.37172317504883, 0.96875\n",
      "Train loss and acc of batch 7: 47.869102478027344, 1.0\n",
      "Train loss and acc of batch 8: 48.46479034423828, 0.984375\n",
      "Train loss and acc of batch 9: 48.154937744140625, 0.984375\n",
      "Train loss and acc of batch 10: 47.86907196044922, 1.0\n",
      "Train loss and acc of batch 11: 47.86906051635742, 1.0\n",
      "Train loss and acc of batch 12: 48.62228012084961, 0.984375\n",
      "Train loss and acc of batch 13: 48.08580780029297, 0.984375\n",
      "Train loss and acc of batch 14: 48.08580017089844, 0.984375\n",
      "Train loss and acc of batch 15: 48.46472930908203, 0.984375\n",
      "Train loss and acc of batch 16: 48.4647216796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.62223434448242, 0.984375\n",
      "Train loss and acc of batch 18: 48.75055694580078, 0.96875\n",
      "Train loss and acc of batch 19: 47.86899185180664, 1.0\n",
      "Train loss and acc of batch 20: 47.86898422241211, 1.0\n",
      "Train loss and acc of batch 21: 48.46467590332031, 0.984375\n",
      "Train loss and acc of batch 22: 48.46466827392578, 0.984375\n",
      "Train loss and acc of batch 23: 47.86895751953125, 1.0\n",
      "Train loss and acc of batch 24: 48.46465301513672, 0.984375\n",
      "Train loss and acc of batch 25: 47.86894226074219, 1.0\n",
      "Train loss and acc of batch 26: 47.868934631347656, 1.0\n",
      "Train loss and acc of batch 27: 47.868919372558594, 1.0\n",
      "Train loss and acc of batch 28: 47.86891174316406, 1.0\n",
      "Train loss and acc of batch 29: 48.46460723876953, 0.984375\n",
      "Train loss and acc of batch 30: 47.868892669677734, 1.0\n",
      "Train loss and acc of batch 31: 48.08564758300781, 0.984375\n",
      "Train loss and acc of batch 32: 47.86888122558594, 1.0\n",
      "Train loss and acc of batch 33: 47.868865966796875, 1.0\n",
      "Train loss and acc of batch 34: 48.464561462402344, 0.984375\n",
      "Train loss and acc of batch 35: 48.30237579345703, 0.96875\n",
      "Train loss and acc of batch 36: 47.86884307861328, 1.0\n",
      "Train loss and acc of batch 37: 48.6220588684082, 0.984375\n",
      "Train loss and acc of batch 38: 49.217750549316406, 0.96875\n",
      "Train loss and acc of batch 39: 48.08557891845703, 0.984375\n",
      "Train loss and acc of batch 40: 47.868804931640625, 1.0\n",
      "Train loss and acc of batch 41: 49.21772384643555, 0.96875\n",
      "Train loss and acc of batch 42: 47.8687858581543, 1.0\n",
      "Train loss and acc of batch 43: 48.4644775390625, 0.984375\n",
      "Train loss and acc of batch 44: 47.868770599365234, 1.0\n",
      "Train loss and acc of batch 45: 48.46446228027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.15460968017578, 0.984375\n",
      "Train loss and acc of batch 47: 47.86874008178711, 1.0\n",
      "Train loss and acc of batch 48: 47.86873245239258, 1.0\n",
      "Train loss and acc of batch 49: 47.86872482299805, 1.0\n",
      "Train loss and acc of batch 50: 48.46441650390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.21763610839844, 0.96875\n",
      "Train loss and acc of batch 52: 49.12453842163086, 0.953125\n",
      "Train loss and acc of batch 53: 47.86869430541992, 1.0\n",
      "Train loss and acc of batch 54: 48.08544158935547, 0.984375\n",
      "Train loss and acc of batch 55: 47.868675231933594, 1.0\n",
      "Train loss and acc of batch 56: 47.86865997314453, 1.0\n",
      "Train loss and acc of batch 57: 48.46435546875, 0.984375\n",
      "Train loss and acc of batch 58: 47.86864471435547, 1.0\n",
      "Train loss and acc of batch 59: 47.86863708496094, 1.0\n",
      "Train loss and acc of batch 60: 47.868629455566406, 1.0\n",
      "Train loss and acc of batch 61: 47.86862564086914, 1.0\n",
      "Train loss and acc of batch 62: 48.08537292480469, 0.984375\n",
      "Train loss and acc of batch 63: 49.06000518798828, 0.96875\n",
      "Train loss and acc of batch 64: 48.085357666015625, 0.984375\n",
      "Train loss and acc of batch 65: 47.86858367919922, 1.0\n",
      "Train loss and acc of batch 66: 47.86857223510742, 1.0\n",
      "Train loss and acc of batch 67: 48.6810302734375, 0.96875\n",
      "Train loss and acc of batch 68: 48.464256286621094, 0.984375\n",
      "Train loss and acc of batch 69: 48.08531188964844, 0.984375\n",
      "Train loss and acc of batch 70: 47.86853790283203, 1.0\n",
      "Training accuracy and loss of epoch #300: 0.9892, 48.1968\n",
      "Saved model by train loss 48.19681285804426\n",
      "Train loss and acc of batch 0: 47.8685302734375, 1.0\n",
      "Train loss and acc of batch 1: 47.8685188293457, 1.0\n",
      "Train loss and acc of batch 2: 48.15436553955078, 0.984375\n",
      "Train loss and acc of batch 3: 48.08527374267578, 0.984375\n",
      "Train loss and acc of batch 4: 47.868492126464844, 1.0\n",
      "Train loss and acc of batch 5: 49.2174072265625, 0.96875\n",
      "Train loss and acc of batch 6: 48.371089935302734, 0.96875\n",
      "Train loss and acc of batch 7: 47.86846923828125, 1.0\n",
      "Train loss and acc of batch 8: 48.46416473388672, 0.984375\n",
      "Train loss and acc of batch 9: 48.15430450439453, 0.984375\n",
      "Train loss and acc of batch 10: 47.868438720703125, 1.0\n",
      "Train loss and acc of batch 11: 47.868431091308594, 1.0\n",
      "Train loss and acc of batch 12: 48.62165069580078, 0.984375\n",
      "Train loss and acc of batch 13: 48.085182189941406, 0.984375\n",
      "Train loss and acc of batch 14: 48.085166931152344, 0.984375\n",
      "Train loss and acc of batch 15: 48.46409606933594, 0.984375\n",
      "Train loss and acc of batch 16: 48.464088439941406, 0.984375\n",
      "Train loss and acc of batch 17: 48.62160110473633, 0.984375\n",
      "Train loss and acc of batch 18: 48.74992752075195, 0.96875\n",
      "Train loss and acc of batch 19: 47.86836624145508, 1.0\n",
      "Train loss and acc of batch 20: 47.86834716796875, 1.0\n",
      "Train loss and acc of batch 21: 48.46404266357422, 0.984375\n",
      "Train loss and acc of batch 22: 48.46403503417969, 0.984375\n",
      "Train loss and acc of batch 23: 47.86832809448242, 1.0\n",
      "Train loss and acc of batch 24: 48.464012145996094, 0.984375\n",
      "Train loss and acc of batch 25: 47.86831283569336, 1.0\n",
      "Train loss and acc of batch 26: 47.86830139160156, 1.0\n",
      "Train loss and acc of batch 27: 47.86829376220703, 1.0\n",
      "Train loss and acc of batch 28: 47.86827850341797, 1.0\n",
      "Train loss and acc of batch 29: 48.46397399902344, 0.984375\n",
      "Train loss and acc of batch 30: 47.868263244628906, 1.0\n",
      "Train loss and acc of batch 31: 48.08502197265625, 0.984375\n",
      "Train loss and acc of batch 32: 47.86824417114258, 1.0\n",
      "Train loss and acc of batch 33: 47.86823654174805, 1.0\n",
      "Train loss and acc of batch 34: 48.46392822265625, 0.984375\n",
      "Train loss and acc of batch 35: 48.3017463684082, 0.96875\n",
      "Train loss and acc of batch 36: 47.86820983886719, 1.0\n",
      "Train loss and acc of batch 37: 48.62142562866211, 0.984375\n",
      "Train loss and acc of batch 38: 49.21711730957031, 0.96875\n",
      "Train loss and acc of batch 39: 48.08495330810547, 0.984375\n",
      "Train loss and acc of batch 40: 47.8681755065918, 1.0\n",
      "Train loss and acc of batch 41: 49.21709442138672, 0.96875\n",
      "Train loss and acc of batch 42: 47.868160247802734, 1.0\n",
      "Train loss and acc of batch 43: 48.46385192871094, 0.984375\n",
      "Train loss and acc of batch 44: 47.86813735961914, 1.0\n",
      "Train loss and acc of batch 45: 48.463829040527344, 0.984375\n",
      "Train loss and acc of batch 46: 48.15397644042969, 0.984375\n",
      "Train loss and acc of batch 47: 47.86811065673828, 1.0\n",
      "Train loss and acc of batch 48: 47.868106842041016, 1.0\n",
      "Train loss and acc of batch 49: 47.86809539794922, 1.0\n",
      "Train loss and acc of batch 50: 48.46379089355469, 0.984375\n",
      "Train loss and acc of batch 51: 49.21699523925781, 0.96875\n",
      "Train loss and acc of batch 52: 49.12390899658203, 0.953125\n",
      "Train loss and acc of batch 53: 47.86806106567383, 1.0\n",
      "Train loss and acc of batch 54: 48.084815979003906, 0.984375\n",
      "Train loss and acc of batch 55: 47.8680419921875, 1.0\n",
      "Train loss and acc of batch 56: 47.86803436279297, 1.0\n",
      "Train loss and acc of batch 57: 48.463722229003906, 0.984375\n",
      "Train loss and acc of batch 58: 47.86801528930664, 1.0\n",
      "Train loss and acc of batch 59: 47.868003845214844, 1.0\n",
      "Train loss and acc of batch 60: 47.86799621582031, 1.0\n",
      "Train loss and acc of batch 61: 47.867984771728516, 1.0\n",
      "Train loss and acc of batch 62: 47.86798095703125, 1.0\n",
      "Train loss and acc of batch 63: 49.05937194824219, 0.96875\n",
      "Train loss and acc of batch 64: 48.08472442626953, 0.984375\n",
      "Train loss and acc of batch 65: 47.867950439453125, 1.0\n",
      "Train loss and acc of batch 66: 47.867942810058594, 1.0\n",
      "Train loss and acc of batch 67: 48.68040084838867, 0.96875\n",
      "Train loss and acc of batch 68: 48.463623046875, 0.984375\n",
      "Train loss and acc of batch 69: 48.084686279296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.86790466308594, 1.0\n",
      "Training accuracy and loss of epoch #301: 0.9894, 48.1931\n",
      "Saved model by train loss 48.193128612679494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.867897033691406, 1.0\n",
      "Train loss and acc of batch 1: 47.86788558959961, 1.0\n",
      "Train loss and acc of batch 2: 48.15373229980469, 0.984375\n",
      "Train loss and acc of batch 3: 48.084632873535156, 0.984375\n",
      "Train loss and acc of batch 4: 47.867862701416016, 1.0\n",
      "Train loss and acc of batch 5: 49.21678161621094, 0.96875\n",
      "Train loss and acc of batch 6: 48.37046432495117, 0.96875\n",
      "Train loss and acc of batch 7: 47.86783981323242, 1.0\n",
      "Train loss and acc of batch 8: 48.463523864746094, 0.984375\n",
      "Train loss and acc of batch 9: 48.15367126464844, 0.984375\n",
      "Train loss and acc of batch 10: 47.86781311035156, 1.0\n",
      "Train loss and acc of batch 11: 47.867801666259766, 1.0\n",
      "Train loss and acc of batch 12: 48.62101745605469, 0.984375\n",
      "Train loss and acc of batch 13: 48.08454895019531, 0.984375\n",
      "Train loss and acc of batch 14: 48.08454132080078, 0.984375\n",
      "Train loss and acc of batch 15: 48.463462829589844, 0.984375\n",
      "Train loss and acc of batch 16: 48.46345520019531, 0.984375\n",
      "Train loss and acc of batch 17: 48.620967864990234, 0.984375\n",
      "Train loss and acc of batch 18: 48.749290466308594, 0.96875\n",
      "Train loss and acc of batch 19: 47.86772918701172, 1.0\n",
      "Train loss and acc of batch 20: 47.86772155761719, 1.0\n",
      "Train loss and acc of batch 21: 48.463417053222656, 0.984375\n",
      "Train loss and acc of batch 22: 48.463409423828125, 0.984375\n",
      "Train loss and acc of batch 23: 47.86769104003906, 1.0\n",
      "Train loss and acc of batch 24: 48.46338653564453, 0.984375\n",
      "Train loss and acc of batch 25: 47.867671966552734, 1.0\n",
      "Train loss and acc of batch 26: 47.867671966552734, 1.0\n",
      "Train loss and acc of batch 27: 47.86765670776367, 1.0\n",
      "Train loss and acc of batch 28: 47.86764907836914, 1.0\n",
      "Train loss and acc of batch 29: 48.463340759277344, 0.984375\n",
      "Train loss and acc of batch 30: 47.86763000488281, 1.0\n",
      "Train loss and acc of batch 31: 48.084388732910156, 0.984375\n",
      "Train loss and acc of batch 32: 47.867610931396484, 1.0\n",
      "Train loss and acc of batch 33: 47.86760330200195, 1.0\n",
      "Train loss and acc of batch 34: 48.463294982910156, 0.984375\n",
      "Train loss and acc of batch 35: 48.301116943359375, 0.96875\n",
      "Train loss and acc of batch 36: 47.86758041381836, 1.0\n",
      "Train loss and acc of batch 37: 48.620792388916016, 0.984375\n",
      "Train loss and acc of batch 38: 49.21648406982422, 0.96875\n",
      "Train loss and acc of batch 39: 48.084320068359375, 0.984375\n",
      "Train loss and acc of batch 40: 47.86754608154297, 1.0\n",
      "Train loss and acc of batch 41: 49.216461181640625, 0.96875\n",
      "Train loss and acc of batch 42: 47.867523193359375, 1.0\n",
      "Train loss and acc of batch 43: 48.463218688964844, 0.984375\n",
      "Train loss and acc of batch 44: 47.86751174926758, 1.0\n",
      "Train loss and acc of batch 45: 48.46320343017578, 0.984375\n",
      "Train loss and acc of batch 46: 48.15333557128906, 0.984375\n",
      "Train loss and acc of batch 47: 47.86748123168945, 1.0\n",
      "Train loss and acc of batch 48: 47.867469787597656, 1.0\n",
      "Train loss and acc of batch 49: 47.86746597290039, 1.0\n",
      "Train loss and acc of batch 50: 48.463157653808594, 0.984375\n",
      "Train loss and acc of batch 51: 49.21636962890625, 0.96875\n",
      "Train loss and acc of batch 52: 49.12327194213867, 0.953125\n",
      "Train loss and acc of batch 53: 47.86742401123047, 1.0\n",
      "Train loss and acc of batch 54: 48.08418273925781, 0.984375\n",
      "Train loss and acc of batch 55: 47.867408752441406, 1.0\n",
      "Train loss and acc of batch 56: 47.867401123046875, 1.0\n",
      "Train loss and acc of batch 57: 48.46308898925781, 0.984375\n",
      "Train loss and acc of batch 58: 47.86737823486328, 1.0\n",
      "Train loss and acc of batch 59: 47.867374420166016, 1.0\n",
      "Train loss and acc of batch 60: 47.86736297607422, 1.0\n",
      "Train loss and acc of batch 61: 47.86735153198242, 1.0\n",
      "Train loss and acc of batch 62: 48.0841064453125, 0.984375\n",
      "Train loss and acc of batch 63: 49.05874252319336, 0.96875\n",
      "Train loss and acc of batch 64: 48.08409118652344, 0.984375\n",
      "Train loss and acc of batch 65: 47.8673210144043, 1.0\n",
      "Train loss and acc of batch 66: 47.8673095703125, 1.0\n",
      "Train loss and acc of batch 67: 48.67976760864258, 0.96875\n",
      "Train loss and acc of batch 68: 48.46299743652344, 0.984375\n",
      "Train loss and acc of batch 69: 48.08404541015625, 0.984375\n",
      "Train loss and acc of batch 70: 47.86727523803711, 1.0\n",
      "Training accuracy and loss of epoch #302: 0.9892, 48.1955\n",
      "Train loss and acc of batch 0: 47.86726379394531, 1.0\n",
      "Train loss and acc of batch 1: 47.86725616455078, 1.0\n",
      "Train loss and acc of batch 2: 48.153099060058594, 0.984375\n",
      "Train loss and acc of batch 3: 48.08399963378906, 0.984375\n",
      "Train loss and acc of batch 4: 47.867225646972656, 1.0\n",
      "Train loss and acc of batch 5: 49.216148376464844, 0.96875\n",
      "Train loss and acc of batch 6: 48.36983108520508, 0.96875\n",
      "Train loss and acc of batch 7: 47.86720657348633, 1.0\n",
      "Train loss and acc of batch 8: 48.46289825439453, 0.984375\n",
      "Train loss and acc of batch 9: 48.153038024902344, 0.984375\n",
      "Train loss and acc of batch 10: 47.86717987060547, 1.0\n",
      "Train loss and acc of batch 11: 47.86717224121094, 1.0\n",
      "Train loss and acc of batch 12: 48.62038040161133, 0.984375\n",
      "Train loss and acc of batch 13: 48.08391571044922, 0.984375\n",
      "Train loss and acc of batch 14: 48.083900451660156, 0.984375\n",
      "Train loss and acc of batch 15: 48.46283721923828, 0.984375\n",
      "Train loss and acc of batch 16: 48.46282958984375, 0.984375\n",
      "Train loss and acc of batch 17: 48.62033462524414, 0.984375\n",
      "Train loss and acc of batch 18: 48.7486572265625, 0.96875\n",
      "Train loss and acc of batch 19: 47.867095947265625, 1.0\n",
      "Train loss and acc of batch 20: 47.867088317871094, 1.0\n",
      "Train loss and acc of batch 21: 48.46278381347656, 0.984375\n",
      "Train loss and acc of batch 22: 48.4627685546875, 0.984375\n",
      "Train loss and acc of batch 23: 47.867061614990234, 1.0\n",
      "Train loss and acc of batch 24: 48.46275329589844, 0.984375\n",
      "Train loss and acc of batch 25: 47.86704635620117, 1.0\n",
      "Train loss and acc of batch 26: 47.86703109741211, 1.0\n",
      "Train loss and acc of batch 27: 47.867027282714844, 1.0\n",
      "Train loss and acc of batch 28: 47.86701583862305, 1.0\n",
      "Train loss and acc of batch 29: 48.46270751953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.867000579833984, 1.0\n",
      "Train loss and acc of batch 31: 48.08375549316406, 0.984375\n",
      "Train loss and acc of batch 32: 47.866981506347656, 1.0\n",
      "Train loss and acc of batch 33: 47.86697006225586, 1.0\n",
      "Train loss and acc of batch 34: 48.462669372558594, 0.984375\n",
      "Train loss and acc of batch 35: 48.30048370361328, 0.96875\n",
      "Train loss and acc of batch 36: 47.866947174072266, 1.0\n",
      "Train loss and acc of batch 37: 48.62016296386719, 0.984375\n",
      "Train loss and acc of batch 38: 49.215858459472656, 0.96875\n",
      "Train loss and acc of batch 39: 48.08368682861328, 0.984375\n",
      "Train loss and acc of batch 40: 47.86690902709961, 1.0\n",
      "Train loss and acc of batch 41: 49.21582794189453, 0.96875\n",
      "Train loss and acc of batch 42: 47.86688995361328, 1.0\n",
      "Train loss and acc of batch 43: 48.46258544921875, 0.984375\n",
      "Train loss and acc of batch 44: 47.866878509521484, 1.0\n",
      "Train loss and acc of batch 45: 48.462562561035156, 0.984375\n",
      "Train loss and acc of batch 46: 48.1527099609375, 0.984375\n",
      "Train loss and acc of batch 47: 47.866844177246094, 1.0\n",
      "Train loss and acc of batch 48: 47.86684036254883, 1.0\n",
      "Train loss and acc of batch 49: 47.866825103759766, 1.0\n",
      "Train loss and acc of batch 50: 48.4625244140625, 0.984375\n",
      "Train loss and acc of batch 51: 49.215736389160156, 0.96875\n",
      "Train loss and acc of batch 52: 49.12264633178711, 0.953125\n",
      "Train loss and acc of batch 53: 47.866798400878906, 1.0\n",
      "Train loss and acc of batch 54: 48.08354187011719, 0.984375\n",
      "Train loss and acc of batch 55: 47.86677551269531, 1.0\n",
      "Train loss and acc of batch 56: 47.866764068603516, 1.0\n",
      "Train loss and acc of batch 57: 48.46245574951172, 0.984375\n",
      "Train loss and acc of batch 58: 47.866756439208984, 1.0\n",
      "Train loss and acc of batch 59: 47.86674118041992, 1.0\n",
      "Train loss and acc of batch 60: 47.866729736328125, 1.0\n",
      "Train loss and acc of batch 61: 47.866722106933594, 1.0\n",
      "Train loss and acc of batch 62: 48.08348083496094, 0.984375\n",
      "Train loss and acc of batch 63: 49.058109283447266, 0.96875\n",
      "Train loss and acc of batch 64: 48.083457946777344, 0.984375\n",
      "Train loss and acc of batch 65: 47.8666877746582, 1.0\n",
      "Train loss and acc of batch 66: 47.86668014526367, 1.0\n",
      "Train loss and acc of batch 67: 48.67913818359375, 0.96875\n",
      "Train loss and acc of batch 68: 48.46235656738281, 0.984375\n",
      "Train loss and acc of batch 69: 48.08341979980469, 0.984375\n",
      "Train loss and acc of batch 70: 47.86664581298828, 1.0\n",
      "Training accuracy and loss of epoch #303: 0.9892, 48.1949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.866634368896484, 1.0\n",
      "Train loss and acc of batch 1: 47.86662673950195, 1.0\n",
      "Train loss and acc of batch 2: 48.1524658203125, 0.984375\n",
      "Train loss and acc of batch 3: 48.08336639404297, 0.984375\n",
      "Train loss and acc of batch 4: 47.866600036621094, 1.0\n",
      "Train loss and acc of batch 5: 49.21551513671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.369197845458984, 0.96875\n",
      "Train loss and acc of batch 7: 47.86656951904297, 1.0\n",
      "Train loss and acc of batch 8: 48.46226501464844, 0.984375\n",
      "Train loss and acc of batch 9: 48.15240478515625, 0.984375\n",
      "Train loss and acc of batch 10: 47.86655044555664, 1.0\n",
      "Train loss and acc of batch 11: 47.86653518676758, 1.0\n",
      "Train loss and acc of batch 12: 48.6197509765625, 0.984375\n",
      "Train loss and acc of batch 13: 48.083282470703125, 0.984375\n",
      "Train loss and acc of batch 14: 48.08326721191406, 0.984375\n",
      "Train loss and acc of batch 15: 48.46220397949219, 0.984375\n",
      "Train loss and acc of batch 16: 48.462196350097656, 0.984375\n",
      "Train loss and acc of batch 17: 48.61970520019531, 0.984375\n",
      "Train loss and acc of batch 18: 48.7480354309082, 0.96875\n",
      "Train loss and acc of batch 19: 47.86646270751953, 1.0\n",
      "Train loss and acc of batch 20: 47.866455078125, 1.0\n",
      "Train loss and acc of batch 21: 48.46215057373047, 0.984375\n",
      "Train loss and acc of batch 22: 48.46214294433594, 0.984375\n",
      "Train loss and acc of batch 23: 47.86642837524414, 1.0\n",
      "Train loss and acc of batch 24: 48.462127685546875, 0.984375\n",
      "Train loss and acc of batch 25: 47.86641311645508, 1.0\n",
      "Train loss and acc of batch 26: 47.86640167236328, 1.0\n",
      "Train loss and acc of batch 27: 47.86639404296875, 1.0\n",
      "Train loss and acc of batch 28: 47.86638259887695, 1.0\n",
      "Train loss and acc of batch 29: 48.46208190917969, 0.984375\n",
      "Train loss and acc of batch 30: 47.866371154785156, 1.0\n",
      "Train loss and acc of batch 31: 48.08312225341797, 0.984375\n",
      "Train loss and acc of batch 32: 47.866355895996094, 1.0\n",
      "Train loss and acc of batch 33: 47.86634063720703, 1.0\n",
      "Train loss and acc of batch 34: 48.46202850341797, 0.984375\n",
      "Train loss and acc of batch 35: 48.29985427856445, 0.96875\n",
      "Train loss and acc of batch 36: 47.86631393432617, 1.0\n",
      "Train loss and acc of batch 37: 48.619529724121094, 0.984375\n",
      "Train loss and acc of batch 38: 49.21522521972656, 0.96875\n",
      "Train loss and acc of batch 39: 48.08305358886719, 0.984375\n",
      "Train loss and acc of batch 40: 47.86627960205078, 1.0\n",
      "Train loss and acc of batch 41: 49.2151985168457, 0.96875\n",
      "Train loss and acc of batch 42: 47.86626052856445, 1.0\n",
      "Train loss and acc of batch 43: 48.461952209472656, 0.984375\n",
      "Train loss and acc of batch 44: 47.86624526977539, 1.0\n",
      "Train loss and acc of batch 45: 48.461936950683594, 0.984375\n",
      "Train loss and acc of batch 46: 48.15208435058594, 0.984375\n",
      "Train loss and acc of batch 47: 47.86621856689453, 1.0\n",
      "Train loss and acc of batch 48: 47.86620330810547, 1.0\n",
      "Train loss and acc of batch 49: 47.8661994934082, 1.0\n",
      "Train loss and acc of batch 50: 48.461891174316406, 0.984375\n",
      "Train loss and acc of batch 51: 49.21510314941406, 0.96875\n",
      "Train loss and acc of batch 52: 49.122013092041016, 0.953125\n",
      "Train loss and acc of batch 53: 47.86616134643555, 1.0\n",
      "Train loss and acc of batch 54: 48.082916259765625, 0.984375\n",
      "Train loss and acc of batch 55: 47.866146087646484, 1.0\n",
      "Train loss and acc of batch 56: 47.86613464355469, 1.0\n",
      "Train loss and acc of batch 57: 48.461830139160156, 0.984375\n",
      "Train loss and acc of batch 58: 47.866119384765625, 1.0\n",
      "Train loss and acc of batch 59: 47.866111755371094, 1.0\n",
      "Train loss and acc of batch 60: 47.8661003112793, 1.0\n",
      "Train loss and acc of batch 61: 47.86609649658203, 1.0\n",
      "Train loss and acc of batch 62: 48.082847595214844, 0.984375\n",
      "Train loss and acc of batch 63: 49.05747604370117, 0.96875\n",
      "Train loss and acc of batch 64: 48.08283233642578, 0.984375\n",
      "Train loss and acc of batch 65: 47.86605453491211, 1.0\n",
      "Train loss and acc of batch 66: 47.86604690551758, 1.0\n",
      "Train loss and acc of batch 67: 48.678504943847656, 0.96875\n",
      "Train loss and acc of batch 68: 48.46173095703125, 0.984375\n",
      "Train loss and acc of batch 69: 48.082786560058594, 0.984375\n",
      "Train loss and acc of batch 70: 47.86601257324219, 1.0\n",
      "Training accuracy and loss of epoch #304: 0.9892, 48.1943\n",
      "Train loss and acc of batch 0: 47.86600112915039, 1.0\n",
      "Train loss and acc of batch 1: 47.865997314453125, 1.0\n",
      "Train loss and acc of batch 2: 48.151832580566406, 0.984375\n",
      "Train loss and acc of batch 3: 48.082740783691406, 0.984375\n",
      "Train loss and acc of batch 4: 47.865970611572266, 1.0\n",
      "Train loss and acc of batch 5: 49.214881896972656, 0.96875\n",
      "Train loss and acc of batch 6: 48.36856460571289, 0.96875\n",
      "Train loss and acc of batch 7: 47.86594009399414, 1.0\n",
      "Train loss and acc of batch 8: 48.461631774902344, 0.984375\n",
      "Train loss and acc of batch 9: 48.15177917480469, 0.984375\n",
      "Train loss and acc of batch 10: 47.865909576416016, 1.0\n",
      "Train loss and acc of batch 11: 47.86590576171875, 1.0\n",
      "Train loss and acc of batch 12: 48.61912155151367, 0.984375\n",
      "Train loss and acc of batch 13: 48.08265686035156, 0.984375\n",
      "Train loss and acc of batch 14: 48.0826416015625, 0.984375\n",
      "Train loss and acc of batch 15: 48.461570739746094, 0.984375\n",
      "Train loss and acc of batch 16: 48.46156311035156, 0.984375\n",
      "Train loss and acc of batch 17: 48.61907958984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.747398376464844, 0.96875\n",
      "Train loss and acc of batch 19: 47.86582946777344, 1.0\n",
      "Train loss and acc of batch 20: 47.86582565307617, 1.0\n",
      "Train loss and acc of batch 21: 48.461517333984375, 0.984375\n",
      "Train loss and acc of batch 22: 48.461509704589844, 0.984375\n",
      "Train loss and acc of batch 23: 47.86580276489258, 1.0\n",
      "Train loss and acc of batch 24: 48.46149444580078, 0.984375\n",
      "Train loss and acc of batch 25: 47.865779876708984, 1.0\n",
      "Train loss and acc of batch 26: 47.86577606201172, 1.0\n",
      "Train loss and acc of batch 27: 47.865760803222656, 1.0\n",
      "Train loss and acc of batch 28: 47.865753173828125, 1.0\n",
      "Train loss and acc of batch 29: 48.461448669433594, 0.984375\n",
      "Train loss and acc of batch 30: 47.8657341003418, 1.0\n",
      "Train loss and acc of batch 31: 48.082496643066406, 0.984375\n",
      "Train loss and acc of batch 32: 47.865718841552734, 1.0\n",
      "Train loss and acc of batch 33: 47.8657112121582, 1.0\n",
      "Train loss and acc of batch 34: 48.461402893066406, 0.984375\n",
      "Train loss and acc of batch 35: 48.29922103881836, 0.96875\n",
      "Train loss and acc of batch 36: 47.86568069458008, 1.0\n",
      "Train loss and acc of batch 37: 48.618900299072266, 0.984375\n",
      "Train loss and acc of batch 38: 49.21458435058594, 0.96875\n",
      "Train loss and acc of batch 39: 48.082420349121094, 0.984375\n",
      "Train loss and acc of batch 40: 47.86565017700195, 1.0\n",
      "Train loss and acc of batch 41: 49.21456527709961, 0.96875\n",
      "Train loss and acc of batch 42: 47.86562728881836, 1.0\n",
      "Train loss and acc of batch 43: 48.46131896972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.8656120300293, 1.0\n",
      "Train loss and acc of batch 45: 48.4613037109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.151451110839844, 0.984375\n",
      "Train loss and acc of batch 47: 47.86558151245117, 1.0\n",
      "Train loss and acc of batch 48: 47.865577697753906, 1.0\n",
      "Train loss and acc of batch 49: 47.865562438964844, 1.0\n",
      "Train loss and acc of batch 50: 48.46125793457031, 0.984375\n",
      "Train loss and acc of batch 51: 49.21446990966797, 0.96875\n",
      "Train loss and acc of batch 52: 49.12137985229492, 0.953125\n",
      "Train loss and acc of batch 53: 47.86553192138672, 1.0\n",
      "Train loss and acc of batch 54: 48.08229064941406, 0.984375\n",
      "Train loss and acc of batch 55: 47.86551284790039, 1.0\n",
      "Train loss and acc of batch 56: 47.86550521850586, 1.0\n",
      "Train loss and acc of batch 57: 48.46119689941406, 0.984375\n",
      "Train loss and acc of batch 58: 47.865482330322266, 1.0\n",
      "Train loss and acc of batch 59: 47.865478515625, 1.0\n",
      "Train loss and acc of batch 60: 47.86547088623047, 1.0\n",
      "Train loss and acc of batch 61: 47.86546325683594, 1.0\n",
      "Train loss and acc of batch 62: 48.08222198486328, 0.984375\n",
      "Train loss and acc of batch 63: 49.056846618652344, 0.96875\n",
      "Train loss and acc of batch 64: 48.08219909667969, 0.984375\n",
      "Train loss and acc of batch 65: 47.86542510986328, 1.0\n",
      "Train loss and acc of batch 66: 47.86540985107422, 1.0\n",
      "Train loss and acc of batch 67: 48.67787170410156, 0.96875\n",
      "Train loss and acc of batch 68: 48.461097717285156, 0.984375\n",
      "Train loss and acc of batch 69: 48.0821533203125, 0.984375\n",
      "Train loss and acc of batch 70: 47.865379333496094, 1.0\n",
      "Training accuracy and loss of epoch #305: 0.9892, 48.1937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.86537170410156, 1.0\n",
      "Train loss and acc of batch 1: 47.865360260009766, 1.0\n",
      "Train loss and acc of batch 2: 48.151206970214844, 0.984375\n",
      "Train loss and acc of batch 3: 48.082115173339844, 0.984375\n",
      "Train loss and acc of batch 4: 47.865333557128906, 1.0\n",
      "Train loss and acc of batch 5: 49.214256286621094, 0.96875\n",
      "Train loss and acc of batch 6: 48.36793518066406, 0.96875\n",
      "Train loss and acc of batch 7: 47.86531448364258, 1.0\n",
      "Train loss and acc of batch 8: 48.46100616455078, 0.984375\n",
      "Train loss and acc of batch 9: 48.15113830566406, 0.984375\n",
      "Train loss and acc of batch 10: 47.86528015136719, 1.0\n",
      "Train loss and acc of batch 11: 47.865272521972656, 1.0\n",
      "Train loss and acc of batch 12: 48.618492126464844, 0.984375\n",
      "Train loss and acc of batch 13: 48.08201599121094, 0.984375\n",
      "Train loss and acc of batch 14: 48.08201599121094, 0.984375\n",
      "Train loss and acc of batch 15: 48.4609375, 0.984375\n",
      "Train loss and acc of batch 16: 48.46092987060547, 0.984375\n",
      "Train loss and acc of batch 17: 48.61844253540039, 0.984375\n",
      "Train loss and acc of batch 18: 48.74676513671875, 0.96875\n",
      "Train loss and acc of batch 19: 47.865203857421875, 1.0\n",
      "Train loss and acc of batch 20: 47.86519241333008, 1.0\n",
      "Train loss and acc of batch 21: 48.46088409423828, 0.984375\n",
      "Train loss and acc of batch 22: 48.46087646484375, 0.984375\n",
      "Train loss and acc of batch 23: 47.86516571044922, 1.0\n",
      "Train loss and acc of batch 24: 48.46086120605469, 0.984375\n",
      "Train loss and acc of batch 25: 47.865150451660156, 1.0\n",
      "Train loss and acc of batch 26: 47.865142822265625, 1.0\n",
      "Train loss and acc of batch 27: 47.86513137817383, 1.0\n",
      "Train loss and acc of batch 28: 47.8651237487793, 1.0\n",
      "Train loss and acc of batch 29: 48.4608154296875, 0.984375\n",
      "Train loss and acc of batch 30: 47.865108489990234, 1.0\n",
      "Train loss and acc of batch 31: 48.08186340332031, 0.984375\n",
      "Train loss and acc of batch 32: 47.865081787109375, 1.0\n",
      "Train loss and acc of batch 33: 47.86507797241211, 1.0\n",
      "Train loss and acc of batch 34: 48.46076965332031, 0.984375\n",
      "Train loss and acc of batch 35: 48.29859161376953, 0.96875\n",
      "Train loss and acc of batch 36: 47.86505126953125, 1.0\n",
      "Train loss and acc of batch 37: 48.61827087402344, 0.984375\n",
      "Train loss and acc of batch 38: 49.213958740234375, 0.96875\n",
      "Train loss and acc of batch 39: 48.081787109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.865013122558594, 1.0\n",
      "Train loss and acc of batch 41: 49.21393585205078, 0.96875\n",
      "Train loss and acc of batch 42: 47.8650016784668, 1.0\n",
      "Train loss and acc of batch 43: 48.460693359375, 0.984375\n",
      "Train loss and acc of batch 44: 47.86498260498047, 1.0\n",
      "Train loss and acc of batch 45: 48.46067810058594, 0.984375\n",
      "Train loss and acc of batch 46: 48.15081024169922, 0.984375\n",
      "Train loss and acc of batch 47: 47.86495590209961, 1.0\n",
      "Train loss and acc of batch 48: 47.86494445800781, 1.0\n",
      "Train loss and acc of batch 49: 47.86493682861328, 1.0\n",
      "Train loss and acc of batch 50: 48.46062469482422, 0.984375\n",
      "Train loss and acc of batch 51: 49.213844299316406, 0.96875\n",
      "Train loss and acc of batch 52: 49.120750427246094, 0.953125\n",
      "Train loss and acc of batch 53: 47.864906311035156, 1.0\n",
      "Train loss and acc of batch 54: 48.08165740966797, 0.984375\n",
      "Train loss and acc of batch 55: 47.86488342285156, 1.0\n",
      "Train loss and acc of batch 56: 47.864871978759766, 1.0\n",
      "Train loss and acc of batch 57: 48.46056365966797, 0.984375\n",
      "Train loss and acc of batch 58: 47.8648567199707, 1.0\n",
      "Train loss and acc of batch 59: 47.86484909057617, 1.0\n",
      "Train loss and acc of batch 60: 47.864837646484375, 1.0\n",
      "Train loss and acc of batch 61: 47.86482620239258, 1.0\n",
      "Train loss and acc of batch 62: 48.08158874511719, 0.984375\n",
      "Train loss and acc of batch 63: 49.056217193603516, 0.96875\n",
      "Train loss and acc of batch 64: 48.081565856933594, 0.984375\n",
      "Train loss and acc of batch 65: 47.86479187011719, 1.0\n",
      "Train loss and acc of batch 66: 47.86478805541992, 1.0\n",
      "Train loss and acc of batch 67: 48.67723846435547, 0.96875\n",
      "Train loss and acc of batch 68: 48.460472106933594, 0.984375\n",
      "Train loss and acc of batch 69: 48.081520080566406, 0.984375\n",
      "Train loss and acc of batch 70: 47.864749908447266, 1.0\n",
      "Training accuracy and loss of epoch #306: 0.9892, 48.1930\n",
      "Saved model by train loss 48.19302330554371\n",
      "Train loss and acc of batch 0: 47.86473846435547, 1.0\n",
      "Train loss and acc of batch 1: 47.86473083496094, 1.0\n",
      "Train loss and acc of batch 2: 48.15057373046875, 0.984375\n",
      "Train loss and acc of batch 3: 48.08148193359375, 0.984375\n",
      "Train loss and acc of batch 4: 47.86470413208008, 1.0\n",
      "Train loss and acc of batch 5: 49.213623046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.36730194091797, 0.96875\n",
      "Train loss and acc of batch 7: 47.86467742919922, 1.0\n",
      "Train loss and acc of batch 8: 48.460365295410156, 0.984375\n",
      "Train loss and acc of batch 9: 48.1505126953125, 0.984375\n",
      "Train loss and acc of batch 10: 47.864654541015625, 1.0\n",
      "Train loss and acc of batch 11: 47.86464309692383, 1.0\n",
      "Train loss and acc of batch 12: 48.617855072021484, 0.984375\n",
      "Train loss and acc of batch 13: 48.081390380859375, 0.984375\n",
      "Train loss and acc of batch 14: 48.081382751464844, 0.984375\n",
      "Train loss and acc of batch 15: 48.46031188964844, 0.984375\n",
      "Train loss and acc of batch 16: 48.460296630859375, 0.984375\n",
      "Train loss and acc of batch 17: 48.61781311035156, 0.984375\n",
      "Train loss and acc of batch 18: 48.746131896972656, 0.96875\n",
      "Train loss and acc of batch 19: 47.86457061767578, 1.0\n",
      "Train loss and acc of batch 20: 47.86456298828125, 1.0\n",
      "Train loss and acc of batch 21: 48.46025085449219, 0.984375\n",
      "Train loss and acc of batch 22: 48.460243225097656, 0.984375\n",
      "Train loss and acc of batch 23: 47.86453628540039, 1.0\n",
      "Train loss and acc of batch 24: 48.460227966308594, 0.984375\n",
      "Train loss and acc of batch 25: 47.86452102661133, 1.0\n",
      "Train loss and acc of batch 26: 47.86450958251953, 1.0\n",
      "Train loss and acc of batch 27: 47.864498138427734, 1.0\n",
      "Train loss and acc of batch 28: 47.86449432373047, 1.0\n",
      "Train loss and acc of batch 29: 48.460182189941406, 0.984375\n",
      "Train loss and acc of batch 30: 47.86447525024414, 1.0\n",
      "Train loss and acc of batch 31: 48.08123016357422, 0.984375\n",
      "Train loss and acc of batch 32: 47.86445999145508, 1.0\n",
      "Train loss and acc of batch 33: 47.864444732666016, 1.0\n",
      "Train loss and acc of batch 34: 48.46014404296875, 0.984375\n",
      "Train loss and acc of batch 35: 48.29795455932617, 0.96875\n",
      "Train loss and acc of batch 36: 47.86442184448242, 1.0\n",
      "Train loss and acc of batch 37: 48.617637634277344, 0.984375\n",
      "Train loss and acc of batch 38: 49.21333312988281, 0.96875\n",
      "Train loss and acc of batch 39: 48.08116149902344, 0.984375\n",
      "Train loss and acc of batch 40: 47.86438751220703, 1.0\n",
      "Train loss and acc of batch 41: 49.21329879760742, 0.96875\n",
      "Train loss and acc of batch 42: 47.8643684387207, 1.0\n",
      "Train loss and acc of batch 43: 48.460060119628906, 0.984375\n",
      "Train loss and acc of batch 44: 47.864349365234375, 1.0\n",
      "Train loss and acc of batch 45: 48.46003723144531, 0.984375\n",
      "Train loss and acc of batch 46: 48.150184631347656, 0.984375\n",
      "Train loss and acc of batch 47: 47.864322662353516, 1.0\n",
      "Train loss and acc of batch 48: 47.864315032958984, 1.0\n",
      "Train loss and acc of batch 49: 47.86430358886719, 1.0\n",
      "Train loss and acc of batch 50: 48.459999084472656, 0.984375\n",
      "Train loss and acc of batch 51: 49.21321105957031, 0.96875\n",
      "Train loss and acc of batch 52: 49.120121002197266, 0.953125\n",
      "Train loss and acc of batch 53: 47.8642692565918, 1.0\n",
      "Train loss and acc of batch 54: 48.081031799316406, 0.984375\n",
      "Train loss and acc of batch 55: 47.86425018310547, 1.0\n",
      "Train loss and acc of batch 56: 47.86424255371094, 1.0\n",
      "Train loss and acc of batch 57: 48.459938049316406, 0.984375\n",
      "Train loss and acc of batch 58: 47.864219665527344, 1.0\n",
      "Train loss and acc of batch 59: 47.86421585083008, 1.0\n",
      "Train loss and acc of batch 60: 47.86420822143555, 1.0\n",
      "Train loss and acc of batch 61: 47.864200592041016, 1.0\n",
      "Train loss and acc of batch 62: 48.080955505371094, 0.984375\n",
      "Train loss and acc of batch 63: 49.055580139160156, 0.96875\n",
      "Train loss and acc of batch 64: 48.0809326171875, 0.984375\n",
      "Train loss and acc of batch 65: 47.864166259765625, 1.0\n",
      "Train loss and acc of batch 66: 47.86415481567383, 1.0\n",
      "Train loss and acc of batch 67: 48.676612854003906, 0.96875\n",
      "Train loss and acc of batch 68: 48.4598388671875, 0.984375\n",
      "Train loss and acc of batch 69: 48.08088684082031, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 70: 47.86411666870117, 1.0\n",
      "Training accuracy and loss of epoch #307: 0.9892, 48.1924\n",
      "Saved model by train loss 48.192391946282186\n",
      "Train loss and acc of batch 0: 47.86410903930664, 1.0\n",
      "Train loss and acc of batch 1: 47.86410140991211, 1.0\n",
      "Train loss and acc of batch 2: 48.149940490722656, 0.984375\n",
      "Train loss and acc of batch 3: 48.080841064453125, 0.984375\n",
      "Train loss and acc of batch 4: 47.86407470703125, 1.0\n",
      "Train loss and acc of batch 5: 49.212989807128906, 0.96875\n",
      "Train loss and acc of batch 6: 48.366668701171875, 0.96875\n",
      "Train loss and acc of batch 7: 47.864044189453125, 1.0\n",
      "Train loss and acc of batch 8: 48.459739685058594, 0.984375\n",
      "Train loss and acc of batch 9: 48.149879455566406, 0.984375\n",
      "Train loss and acc of batch 10: 47.86402130126953, 1.0\n",
      "Train loss and acc of batch 11: 47.864013671875, 1.0\n",
      "Train loss and acc of batch 12: 48.61722946166992, 0.984375\n",
      "Train loss and acc of batch 13: 48.08075714111328, 0.984375\n",
      "Train loss and acc of batch 14: 48.08074951171875, 0.984375\n",
      "Train loss and acc of batch 15: 48.45967102050781, 0.984375\n",
      "Train loss and acc of batch 16: 48.45966339111328, 0.984375\n",
      "Train loss and acc of batch 17: 48.61717987060547, 0.984375\n",
      "Train loss and acc of batch 18: 48.74549865722656, 0.96875\n",
      "Train loss and acc of batch 19: 47.86394119262695, 1.0\n",
      "Train loss and acc of batch 20: 47.86392593383789, 1.0\n",
      "Train loss and acc of batch 21: 48.459617614746094, 0.984375\n",
      "Train loss and acc of batch 22: 48.45960998535156, 0.984375\n",
      "Train loss and acc of batch 23: 47.8639030456543, 1.0\n",
      "Train loss and acc of batch 24: 48.4595947265625, 0.984375\n",
      "Train loss and acc of batch 25: 47.86388397216797, 1.0\n",
      "Train loss and acc of batch 26: 47.86387252807617, 1.0\n",
      "Train loss and acc of batch 27: 47.86387252807617, 1.0\n",
      "Train loss and acc of batch 28: 47.86385726928711, 1.0\n",
      "Train loss and acc of batch 29: 48.45954895019531, 0.984375\n",
      "Train loss and acc of batch 30: 47.86383819580078, 1.0\n",
      "Train loss and acc of batch 31: 48.080589294433594, 0.984375\n",
      "Train loss and acc of batch 32: 47.86382293701172, 1.0\n",
      "Train loss and acc of batch 33: 47.86381530761719, 1.0\n",
      "Train loss and acc of batch 34: 48.459503173828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.29732131958008, 0.96875\n",
      "Train loss and acc of batch 36: 47.86378479003906, 1.0\n",
      "Train loss and acc of batch 37: 48.61699676513672, 0.984375\n",
      "Train loss and acc of batch 38: 49.21269226074219, 0.96875\n",
      "Train loss and acc of batch 39: 48.080528259277344, 0.984375\n",
      "Train loss and acc of batch 40: 47.86375045776367, 1.0\n",
      "Train loss and acc of batch 41: 49.21266555786133, 0.96875\n",
      "Train loss and acc of batch 42: 47.863731384277344, 1.0\n",
      "Train loss and acc of batch 43: 48.45942687988281, 0.984375\n",
      "Train loss and acc of batch 44: 47.863712310791016, 1.0\n",
      "Train loss and acc of batch 45: 48.45940399169922, 0.984375\n",
      "Train loss and acc of batch 46: 48.14955139160156, 0.984375\n",
      "Train loss and acc of batch 47: 47.86368942260742, 1.0\n",
      "Train loss and acc of batch 48: 47.863677978515625, 1.0\n",
      "Train loss and acc of batch 49: 47.863670349121094, 1.0\n",
      "Train loss and acc of batch 50: 48.45936584472656, 0.984375\n",
      "Train loss and acc of batch 51: 49.21257781982422, 0.96875\n",
      "Train loss and acc of batch 52: 49.119483947753906, 0.953125\n",
      "Train loss and acc of batch 53: 47.86363220214844, 1.0\n",
      "Train loss and acc of batch 54: 48.08039093017578, 0.984375\n",
      "Train loss and acc of batch 55: 47.863616943359375, 1.0\n",
      "Train loss and acc of batch 56: 47.86361312866211, 1.0\n",
      "Train loss and acc of batch 57: 48.45929718017578, 0.984375\n",
      "Train loss and acc of batch 58: 47.86358642578125, 1.0\n",
      "Train loss and acc of batch 59: 47.863582611083984, 1.0\n",
      "Train loss and acc of batch 60: 47.86357116699219, 1.0\n",
      "Train loss and acc of batch 61: 47.863563537597656, 1.0\n",
      "Train loss and acc of batch 62: 48.080322265625, 0.984375\n",
      "Train loss and acc of batch 63: 49.05494689941406, 0.96875\n",
      "Train loss and acc of batch 64: 48.080299377441406, 0.984375\n",
      "Train loss and acc of batch 65: 47.863525390625, 1.0\n",
      "Train loss and acc of batch 66: 47.86351776123047, 1.0\n",
      "Train loss and acc of batch 67: 48.67597579956055, 0.96875\n",
      "Train loss and acc of batch 68: 48.459205627441406, 0.984375\n",
      "Train loss and acc of batch 69: 48.08026123046875, 0.984375\n",
      "Train loss and acc of batch 70: 47.863487243652344, 1.0\n",
      "Training accuracy and loss of epoch #308: 0.9892, 48.1918\n",
      "Saved model by train loss 48.19175768570161\n",
      "Train loss and acc of batch 0: 47.86347198486328, 1.0\n",
      "Train loss and acc of batch 1: 47.863460540771484, 1.0\n",
      "Train loss and acc of batch 2: 48.149314880371094, 0.984375\n",
      "Train loss and acc of batch 3: 48.08021545410156, 0.984375\n",
      "Train loss and acc of batch 4: 47.86343765258789, 1.0\n",
      "Train loss and acc of batch 5: 49.21234893798828, 0.96875\n",
      "Train loss and acc of batch 6: 48.36603927612305, 0.96875\n",
      "Train loss and acc of batch 7: 47.8634147644043, 1.0\n",
      "Train loss and acc of batch 8: 48.4591064453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.14924621582031, 0.984375\n",
      "Train loss and acc of batch 10: 47.86338424682617, 1.0\n",
      "Train loss and acc of batch 11: 47.86337661743164, 1.0\n",
      "Train loss and acc of batch 12: 48.61659240722656, 0.984375\n",
      "Train loss and acc of batch 13: 48.08012390136719, 0.984375\n",
      "Train loss and acc of batch 14: 48.080116271972656, 0.984375\n",
      "Train loss and acc of batch 15: 48.45903778076172, 0.984375\n",
      "Train loss and acc of batch 16: 48.45903778076172, 0.984375\n",
      "Train loss and acc of batch 17: 48.616546630859375, 0.984375\n",
      "Train loss and acc of batch 18: 48.744869232177734, 0.96875\n",
      "Train loss and acc of batch 19: 47.86330032348633, 1.0\n",
      "Train loss and acc of batch 20: 47.86329650878906, 1.0\n",
      "Train loss and acc of batch 21: 48.45899200439453, 0.984375\n",
      "Train loss and acc of batch 22: 48.45897674560547, 0.984375\n",
      "Train loss and acc of batch 23: 47.86326599121094, 1.0\n",
      "Train loss and acc of batch 24: 48.458961486816406, 0.984375\n",
      "Train loss and acc of batch 25: 47.863250732421875, 1.0\n",
      "Train loss and acc of batch 26: 47.863243103027344, 1.0\n",
      "Train loss and acc of batch 27: 47.86323547363281, 1.0\n",
      "Train loss and acc of batch 28: 47.86322784423828, 1.0\n",
      "Train loss and acc of batch 29: 48.45891571044922, 0.984375\n",
      "Train loss and acc of batch 30: 47.86320495605469, 1.0\n",
      "Train loss and acc of batch 31: 48.07996368408203, 0.984375\n",
      "Train loss and acc of batch 32: 47.863189697265625, 1.0\n",
      "Train loss and acc of batch 33: 47.863182067871094, 1.0\n",
      "Train loss and acc of batch 34: 48.45886993408203, 0.984375\n",
      "Train loss and acc of batch 35: 48.29669189453125, 0.96875\n",
      "Train loss and acc of batch 36: 47.86315155029297, 1.0\n",
      "Train loss and acc of batch 37: 48.616363525390625, 0.984375\n",
      "Train loss and acc of batch 38: 49.212059020996094, 0.96875\n",
      "Train loss and acc of batch 39: 48.07989501953125, 0.984375\n",
      "Train loss and acc of batch 40: 47.86311721801758, 1.0\n",
      "Train loss and acc of batch 41: 49.2120361328125, 0.96875\n",
      "Train loss and acc of batch 42: 47.863101959228516, 1.0\n",
      "Train loss and acc of batch 43: 48.45879364013672, 0.984375\n",
      "Train loss and acc of batch 44: 47.86308288574219, 1.0\n",
      "Train loss and acc of batch 45: 48.458778381347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.14891815185547, 0.984375\n",
      "Train loss and acc of batch 47: 47.86305618286133, 1.0\n",
      "Train loss and acc of batch 48: 47.86304473876953, 1.0\n",
      "Train loss and acc of batch 49: 47.863040924072266, 1.0\n",
      "Train loss and acc of batch 50: 48.45872497558594, 0.984375\n",
      "Train loss and acc of batch 51: 49.211944580078125, 0.96875\n",
      "Train loss and acc of batch 52: 49.11885070800781, 0.953125\n",
      "Train loss and acc of batch 53: 47.86300277709961, 1.0\n",
      "Train loss and acc of batch 54: 48.07975769042969, 0.984375\n",
      "Train loss and acc of batch 55: 47.86298751831055, 1.0\n",
      "Train loss and acc of batch 56: 47.86297607421875, 1.0\n",
      "Train loss and acc of batch 57: 48.45867156982422, 0.984375\n",
      "Train loss and acc of batch 58: 47.86296463012695, 1.0\n",
      "Train loss and acc of batch 59: 47.862953186035156, 1.0\n",
      "Train loss and acc of batch 60: 47.862937927246094, 1.0\n",
      "Train loss and acc of batch 61: 47.86293411254883, 1.0\n",
      "Train loss and acc of batch 62: 48.079681396484375, 0.984375\n",
      "Train loss and acc of batch 63: 49.0543212890625, 0.96875\n",
      "Train loss and acc of batch 64: 48.07966613769531, 0.984375\n",
      "Train loss and acc of batch 65: 47.86289596557617, 1.0\n",
      "Train loss and acc of batch 66: 47.862884521484375, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 67: 48.67534255981445, 0.96875\n",
      "Train loss and acc of batch 68: 48.45857238769531, 0.984375\n",
      "Train loss and acc of batch 69: 48.079627990722656, 0.984375\n",
      "Train loss and acc of batch 70: 47.862850189208984, 1.0\n",
      "Training accuracy and loss of epoch #309: 0.9892, 48.1911\n",
      "Saved model by train loss 48.19112530560561\n",
      "Train loss and acc of batch 0: 47.86284255981445, 1.0\n",
      "Train loss and acc of batch 1: 47.86283493041992, 1.0\n",
      "Train loss and acc of batch 2: 48.14867401123047, 0.984375\n",
      "Train loss and acc of batch 3: 48.07958221435547, 0.984375\n",
      "Train loss and acc of batch 4: 47.8628044128418, 1.0\n",
      "Train loss and acc of batch 5: 49.21172332763672, 0.96875\n",
      "Train loss and acc of batch 6: 48.36540985107422, 0.96875\n",
      "Train loss and acc of batch 7: 47.86277770996094, 1.0\n",
      "Train loss and acc of batch 8: 48.458473205566406, 0.984375\n",
      "Train loss and acc of batch 9: 48.14862060546875, 0.984375\n",
      "Train loss and acc of batch 10: 47.86275100708008, 1.0\n",
      "Train loss and acc of batch 11: 47.86274337768555, 1.0\n",
      "Train loss and acc of batch 12: 48.61595916748047, 0.984375\n",
      "Train loss and acc of batch 13: 48.079490661621094, 0.984375\n",
      "Train loss and acc of batch 14: 48.07948303222656, 0.984375\n",
      "Train loss and acc of batch 15: 48.458412170410156, 0.984375\n",
      "Train loss and acc of batch 16: 48.458404541015625, 0.984375\n",
      "Train loss and acc of batch 17: 48.61591339111328, 0.984375\n",
      "Train loss and acc of batch 18: 48.744232177734375, 0.96875\n",
      "Train loss and acc of batch 19: 47.8626708984375, 1.0\n",
      "Train loss and acc of batch 20: 47.862667083740234, 1.0\n",
      "Train loss and acc of batch 21: 48.458351135253906, 0.984375\n",
      "Train loss and acc of batch 22: 48.458343505859375, 0.984375\n",
      "Train loss and acc of batch 23: 47.862640380859375, 1.0\n",
      "Train loss and acc of batch 24: 48.45832824707031, 0.984375\n",
      "Train loss and acc of batch 25: 47.86262130737305, 1.0\n",
      "Train loss and acc of batch 26: 47.86260986328125, 1.0\n",
      "Train loss and acc of batch 27: 47.86260223388672, 1.0\n",
      "Train loss and acc of batch 28: 47.86259078979492, 1.0\n",
      "Train loss and acc of batch 29: 48.458290100097656, 0.984375\n",
      "Train loss and acc of batch 30: 47.86257553100586, 1.0\n",
      "Train loss and acc of batch 31: 48.07933044433594, 0.984375\n",
      "Train loss and acc of batch 32: 47.86255645751953, 1.0\n",
      "Train loss and acc of batch 33: 47.862545013427734, 1.0\n",
      "Train loss and acc of batch 34: 48.45824432373047, 0.984375\n",
      "Train loss and acc of batch 35: 48.29606246948242, 0.96875\n",
      "Train loss and acc of batch 36: 47.86252212524414, 1.0\n",
      "Train loss and acc of batch 37: 48.61573791503906, 0.984375\n",
      "Train loss and acc of batch 38: 49.21142578125, 0.96875\n",
      "Train loss and acc of batch 39: 48.079254150390625, 0.984375\n",
      "Train loss and acc of batch 40: 47.86248779296875, 1.0\n",
      "Train loss and acc of batch 41: 49.211402893066406, 0.96875\n",
      "Train loss and acc of batch 42: 47.86246871948242, 1.0\n",
      "Train loss and acc of batch 43: 48.458168029785156, 0.984375\n",
      "Train loss and acc of batch 44: 47.86245346069336, 1.0\n",
      "Train loss and acc of batch 45: 48.45813751220703, 0.984375\n",
      "Train loss and acc of batch 46: 48.148284912109375, 0.984375\n",
      "Train loss and acc of batch 47: 47.86241912841797, 1.0\n",
      "Train loss and acc of batch 48: 47.86241912841797, 1.0\n",
      "Train loss and acc of batch 49: 47.86240768432617, 1.0\n",
      "Train loss and acc of batch 50: 48.458099365234375, 0.984375\n",
      "Train loss and acc of batch 51: 49.21131134033203, 0.96875\n",
      "Train loss and acc of batch 52: 49.11821746826172, 0.953125\n",
      "Train loss and acc of batch 53: 47.862369537353516, 1.0\n",
      "Train loss and acc of batch 54: 48.079124450683594, 0.984375\n",
      "Train loss and acc of batch 55: 47.86235046386719, 1.0\n",
      "Train loss and acc of batch 56: 47.862342834472656, 1.0\n",
      "Train loss and acc of batch 57: 48.458038330078125, 0.984375\n",
      "Train loss and acc of batch 58: 47.86233139038086, 1.0\n",
      "Train loss and acc of batch 59: 47.8623161315918, 1.0\n",
      "Train loss and acc of batch 60: 47.862308502197266, 1.0\n",
      "Train loss and acc of batch 61: 47.862300872802734, 1.0\n",
      "Train loss and acc of batch 62: 48.07905578613281, 0.984375\n",
      "Train loss and acc of batch 63: 49.05368423461914, 0.96875\n",
      "Train loss and acc of batch 64: 48.07903289794922, 0.984375\n",
      "Train loss and acc of batch 65: 47.862266540527344, 1.0\n",
      "Train loss and acc of batch 66: 47.86225509643555, 1.0\n",
      "Train loss and acc of batch 67: 48.674713134765625, 0.96875\n",
      "Train loss and acc of batch 68: 48.45794677734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.07899475097656, 0.984375\n",
      "Train loss and acc of batch 70: 47.862220764160156, 1.0\n",
      "Training accuracy and loss of epoch #310: 0.9892, 48.1905\n",
      "Saved model by train loss 48.190493409062775\n",
      "Train loss and acc of batch 0: 47.862213134765625, 1.0\n",
      "Train loss and acc of batch 1: 47.862205505371094, 1.0\n",
      "Train loss and acc of batch 2: 48.148048400878906, 0.984375\n",
      "Train loss and acc of batch 3: 48.078948974609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.862178802490234, 1.0\n",
      "Train loss and acc of batch 5: 49.211090087890625, 0.96875\n",
      "Train loss and acc of batch 6: 48.36478042602539, 0.96875\n",
      "Train loss and acc of batch 7: 47.862144470214844, 1.0\n",
      "Train loss and acc of batch 8: 48.45783996582031, 0.984375\n",
      "Train loss and acc of batch 9: 48.147979736328125, 0.984375\n",
      "Train loss and acc of batch 10: 47.86212158203125, 1.0\n",
      "Train loss and acc of batch 11: 47.86211013793945, 1.0\n",
      "Train loss and acc of batch 12: 48.61532974243164, 0.984375\n",
      "Train loss and acc of batch 13: 48.078857421875, 0.984375\n",
      "Train loss and acc of batch 14: 48.07884979248047, 0.984375\n",
      "Train loss and acc of batch 15: 48.45777893066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.45777130126953, 0.984375\n",
      "Train loss and acc of batch 17: 48.61528778076172, 0.984375\n",
      "Train loss and acc of batch 18: 48.74360656738281, 0.96875\n",
      "Train loss and acc of batch 19: 47.86204147338867, 1.0\n",
      "Train loss and acc of batch 20: 47.86203384399414, 1.0\n",
      "Train loss and acc of batch 21: 48.457725524902344, 0.984375\n",
      "Train loss and acc of batch 22: 48.45771789550781, 0.984375\n",
      "Train loss and acc of batch 23: 47.86200714111328, 1.0\n",
      "Train loss and acc of batch 24: 48.45769500732422, 0.984375\n",
      "Train loss and acc of batch 25: 47.86198806762695, 1.0\n",
      "Train loss and acc of batch 26: 47.861976623535156, 1.0\n",
      "Train loss and acc of batch 27: 47.861968994140625, 1.0\n",
      "Train loss and acc of batch 28: 47.86196517944336, 1.0\n",
      "Train loss and acc of batch 29: 48.45765686035156, 0.984375\n",
      "Train loss and acc of batch 30: 47.861942291259766, 1.0\n",
      "Train loss and acc of batch 31: 48.078697204589844, 0.984375\n",
      "Train loss and acc of batch 32: 47.8619270324707, 1.0\n",
      "Train loss and acc of batch 33: 47.86191940307617, 1.0\n",
      "Train loss and acc of batch 34: 48.457618713378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.29542541503906, 0.96875\n",
      "Train loss and acc of batch 36: 47.86188888549805, 1.0\n",
      "Train loss and acc of batch 37: 48.615108489990234, 0.984375\n",
      "Train loss and acc of batch 38: 49.21080017089844, 0.96875\n",
      "Train loss and acc of batch 39: 48.07862854003906, 0.984375\n",
      "Train loss and acc of batch 40: 47.861854553222656, 1.0\n",
      "Train loss and acc of batch 41: 49.21076965332031, 0.96875\n",
      "Train loss and acc of batch 42: 47.86183547973633, 1.0\n",
      "Train loss and acc of batch 43: 48.45753479003906, 0.984375\n",
      "Train loss and acc of batch 44: 47.86181640625, 1.0\n",
      "Train loss and acc of batch 45: 48.45751190185547, 0.984375\n",
      "Train loss and acc of batch 46: 48.14765930175781, 0.984375\n",
      "Train loss and acc of batch 47: 47.861793518066406, 1.0\n",
      "Train loss and acc of batch 48: 47.86178207397461, 1.0\n",
      "Train loss and acc of batch 49: 47.86177062988281, 1.0\n",
      "Train loss and acc of batch 50: 48.45746612548828, 0.984375\n",
      "Train loss and acc of batch 51: 49.21068572998047, 0.96875\n",
      "Train loss and acc of batch 52: 49.11758804321289, 0.953125\n",
      "Train loss and acc of batch 53: 47.86174011230469, 1.0\n",
      "Train loss and acc of batch 54: 48.0784912109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.861717224121094, 1.0\n",
      "Train loss and acc of batch 56: 47.86171340942383, 1.0\n",
      "Train loss and acc of batch 57: 48.45740509033203, 0.984375\n",
      "Train loss and acc of batch 58: 47.8616943359375, 1.0\n",
      "Train loss and acc of batch 59: 47.86168670654297, 1.0\n",
      "Train loss and acc of batch 60: 47.86167907714844, 1.0\n",
      "Train loss and acc of batch 61: 47.861671447753906, 1.0\n",
      "Train loss and acc of batch 62: 48.07843017578125, 0.984375\n",
      "Train loss and acc of batch 63: 49.05305480957031, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 64: 48.078407287597656, 0.984375\n",
      "Train loss and acc of batch 65: 47.861629486083984, 1.0\n",
      "Train loss and acc of batch 66: 47.86162567138672, 1.0\n",
      "Train loss and acc of batch 67: 48.67407989501953, 0.96875\n",
      "Train loss and acc of batch 68: 48.457305908203125, 0.984375\n",
      "Train loss and acc of batch 69: 48.07835388183594, 0.984375\n",
      "Train loss and acc of batch 70: 47.86158752441406, 1.0\n",
      "Training accuracy and loss of epoch #311: 0.9892, 48.1899\n",
      "Saved model by train loss 48.18986221098564\n",
      "Train loss and acc of batch 0: 47.86157989501953, 1.0\n",
      "Train loss and acc of batch 1: 47.861568450927734, 1.0\n",
      "Train loss and acc of batch 2: 48.14741516113281, 0.984375\n",
      "Train loss and acc of batch 3: 48.07831573486328, 0.984375\n",
      "Train loss and acc of batch 4: 47.86154556274414, 1.0\n",
      "Train loss and acc of batch 5: 49.21045684814453, 0.96875\n",
      "Train loss and acc of batch 6: 48.364139556884766, 0.96875\n",
      "Train loss and acc of batch 7: 47.86151885986328, 1.0\n",
      "Train loss and acc of batch 8: 48.45720672607422, 0.984375\n",
      "Train loss and acc of batch 9: 48.14735412597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.861488342285156, 1.0\n",
      "Train loss and acc of batch 11: 47.861480712890625, 1.0\n",
      "Train loss and acc of batch 12: 48.61469268798828, 0.984375\n",
      "Train loss and acc of batch 13: 48.07823181152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.078216552734375, 0.984375\n",
      "Train loss and acc of batch 15: 48.45714569091797, 0.984375\n",
      "Train loss and acc of batch 16: 48.45713806152344, 0.984375\n",
      "Train loss and acc of batch 17: 48.614654541015625, 0.984375\n",
      "Train loss and acc of batch 18: 48.74297332763672, 0.96875\n",
      "Train loss and acc of batch 19: 47.86140823364258, 1.0\n",
      "Train loss and acc of batch 20: 47.86140060424805, 1.0\n",
      "Train loss and acc of batch 21: 48.45709228515625, 0.984375\n",
      "Train loss and acc of batch 22: 48.45708465576172, 0.984375\n",
      "Train loss and acc of batch 23: 47.86137771606445, 1.0\n",
      "Train loss and acc of batch 24: 48.457069396972656, 0.984375\n",
      "Train loss and acc of batch 25: 47.861358642578125, 1.0\n",
      "Train loss and acc of batch 26: 47.86134719848633, 1.0\n",
      "Train loss and acc of batch 27: 47.8613395690918, 1.0\n",
      "Train loss and acc of batch 28: 47.861331939697266, 1.0\n",
      "Train loss and acc of batch 29: 48.45701599121094, 0.984375\n",
      "Train loss and acc of batch 30: 47.86131286621094, 1.0\n",
      "Train loss and acc of batch 31: 48.07807159423828, 0.984375\n",
      "Train loss and acc of batch 32: 47.86129379272461, 1.0\n",
      "Train loss and acc of batch 33: 47.86128234863281, 1.0\n",
      "Train loss and acc of batch 34: 48.45697784423828, 0.984375\n",
      "Train loss and acc of batch 35: 48.294795989990234, 0.96875\n",
      "Train loss and acc of batch 36: 47.86125946044922, 1.0\n",
      "Train loss and acc of batch 37: 48.61447525024414, 0.984375\n",
      "Train loss and acc of batch 38: 49.210166931152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.07799530029297, 0.984375\n",
      "Train loss and acc of batch 40: 47.86122512817383, 1.0\n",
      "Train loss and acc of batch 41: 49.210140228271484, 0.96875\n",
      "Train loss and acc of batch 42: 47.8612060546875, 1.0\n",
      "Train loss and acc of batch 43: 48.45689392089844, 0.984375\n",
      "Train loss and acc of batch 44: 47.86119079589844, 1.0\n",
      "Train loss and acc of batch 45: 48.456878662109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.14702606201172, 0.984375\n",
      "Train loss and acc of batch 47: 47.861167907714844, 1.0\n",
      "Train loss and acc of batch 48: 47.86115264892578, 1.0\n",
      "Train loss and acc of batch 49: 47.861141204833984, 1.0\n",
      "Train loss and acc of batch 50: 48.45684051513672, 0.984375\n",
      "Train loss and acc of batch 51: 49.210044860839844, 0.96875\n",
      "Train loss and acc of batch 52: 49.1169548034668, 0.953125\n",
      "Train loss and acc of batch 53: 47.861106872558594, 1.0\n",
      "Train loss and acc of batch 54: 48.07786560058594, 0.984375\n",
      "Train loss and acc of batch 55: 47.861087799072266, 1.0\n",
      "Train loss and acc of batch 56: 47.861080169677734, 1.0\n",
      "Train loss and acc of batch 57: 48.45677185058594, 0.984375\n",
      "Train loss and acc of batch 58: 47.86106491088867, 1.0\n",
      "Train loss and acc of batch 59: 47.861053466796875, 1.0\n",
      "Train loss and acc of batch 60: 47.861045837402344, 1.0\n",
      "Train loss and acc of batch 61: 47.86103439331055, 1.0\n",
      "Train loss and acc of batch 62: 48.077789306640625, 0.984375\n",
      "Train loss and acc of batch 63: 49.05242156982422, 0.96875\n",
      "Train loss and acc of batch 64: 48.07777404785156, 0.984375\n",
      "Train loss and acc of batch 65: 47.86099624633789, 1.0\n",
      "Train loss and acc of batch 66: 47.860992431640625, 1.0\n",
      "Train loss and acc of batch 67: 48.67344665527344, 0.96875\n",
      "Train loss and acc of batch 68: 48.45667266845703, 0.984375\n",
      "Train loss and acc of batch 69: 48.077728271484375, 0.984375\n",
      "Train loss and acc of batch 70: 47.860958099365234, 1.0\n",
      "Training accuracy and loss of epoch #312: 0.9892, 48.1892\n",
      "Saved model by train loss 48.189230045802155\n",
      "Train loss and acc of batch 0: 47.86094284057617, 1.0\n",
      "Train loss and acc of batch 1: 47.860939025878906, 1.0\n",
      "Train loss and acc of batch 2: 48.14678192138672, 0.984375\n",
      "Train loss and acc of batch 3: 48.07768249511719, 0.984375\n",
      "Train loss and acc of batch 4: 47.86091613769531, 1.0\n",
      "Train loss and acc of batch 5: 49.20982360839844, 0.96875\n",
      "Train loss and acc of batch 6: 48.3635139465332, 0.96875\n",
      "Train loss and acc of batch 7: 47.86088562011719, 1.0\n",
      "Train loss and acc of batch 8: 48.456573486328125, 0.984375\n",
      "Train loss and acc of batch 9: 48.14672088623047, 0.984375\n",
      "Train loss and acc of batch 10: 47.86085891723633, 1.0\n",
      "Train loss and acc of batch 11: 47.86084747314453, 1.0\n",
      "Train loss and acc of batch 12: 48.614070892333984, 0.984375\n",
      "Train loss and acc of batch 13: 48.077598571777344, 0.984375\n",
      "Train loss and acc of batch 14: 48.07758331298828, 0.984375\n",
      "Train loss and acc of batch 15: 48.456512451171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.456504821777344, 0.984375\n",
      "Train loss and acc of batch 17: 48.614017486572266, 0.984375\n",
      "Train loss and acc of batch 18: 48.742340087890625, 0.96875\n",
      "Train loss and acc of batch 19: 47.86077880859375, 1.0\n",
      "Train loss and acc of batch 20: 47.86077117919922, 1.0\n",
      "Train loss and acc of batch 21: 48.45646667480469, 0.984375\n",
      "Train loss and acc of batch 22: 48.456451416015625, 0.984375\n",
      "Train loss and acc of batch 23: 47.860740661621094, 1.0\n",
      "Train loss and acc of batch 24: 48.45643615722656, 0.984375\n",
      "Train loss and acc of batch 25: 47.86072540283203, 1.0\n",
      "Train loss and acc of batch 26: 47.860721588134766, 1.0\n",
      "Train loss and acc of batch 27: 47.8607063293457, 1.0\n",
      "Train loss and acc of batch 28: 47.860694885253906, 1.0\n",
      "Train loss and acc of batch 29: 48.456390380859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.860679626464844, 1.0\n",
      "Train loss and acc of batch 31: 48.07743835449219, 0.984375\n",
      "Train loss and acc of batch 32: 47.86066436767578, 1.0\n",
      "Train loss and acc of batch 33: 47.860652923583984, 1.0\n",
      "Train loss and acc of batch 34: 48.45634460449219, 0.984375\n",
      "Train loss and acc of batch 35: 48.294166564941406, 0.96875\n",
      "Train loss and acc of batch 36: 47.860626220703125, 1.0\n",
      "Train loss and acc of batch 37: 48.61384201049805, 0.984375\n",
      "Train loss and acc of batch 38: 49.20953369140625, 0.96875\n",
      "Train loss and acc of batch 39: 48.077362060546875, 0.984375\n",
      "Train loss and acc of batch 40: 47.860595703125, 1.0\n",
      "Train loss and acc of batch 41: 49.209510803222656, 0.96875\n",
      "Train loss and acc of batch 42: 47.860572814941406, 1.0\n",
      "Train loss and acc of batch 43: 48.456268310546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.86055374145508, 1.0\n",
      "Train loss and acc of batch 45: 48.45625305175781, 0.984375\n",
      "Train loss and acc of batch 46: 48.146392822265625, 0.984375\n",
      "Train loss and acc of batch 47: 47.860530853271484, 1.0\n",
      "Train loss and acc of batch 48: 47.86051940917969, 1.0\n",
      "Train loss and acc of batch 49: 47.86051940917969, 1.0\n",
      "Train loss and acc of batch 50: 48.456199645996094, 0.984375\n",
      "Train loss and acc of batch 51: 49.20941925048828, 0.96875\n",
      "Train loss and acc of batch 52: 49.1163215637207, 0.953125\n",
      "Train loss and acc of batch 53: 47.860477447509766, 1.0\n",
      "Train loss and acc of batch 54: 48.077232360839844, 0.984375\n",
      "Train loss and acc of batch 55: 47.86045837402344, 1.0\n",
      "Train loss and acc of batch 56: 47.86044692993164, 1.0\n",
      "Train loss and acc of batch 57: 48.456138610839844, 0.984375\n",
      "Train loss and acc of batch 58: 47.86043167114258, 1.0\n",
      "Train loss and acc of batch 59: 47.86042404174805, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 60: 47.860416412353516, 1.0\n",
      "Train loss and acc of batch 61: 47.86040496826172, 1.0\n",
      "Train loss and acc of batch 62: 47.86039733886719, 1.0\n",
      "Train loss and acc of batch 63: 49.05179214477539, 0.96875\n",
      "Train loss and acc of batch 64: 48.07714080810547, 0.984375\n",
      "Train loss and acc of batch 65: 47.86036682128906, 1.0\n",
      "Train loss and acc of batch 66: 47.8603630065918, 1.0\n",
      "Train loss and acc of batch 67: 48.67281723022461, 0.96875\n",
      "Train loss and acc of batch 68: 48.45604705810547, 0.984375\n",
      "Train loss and acc of batch 69: 48.07709503173828, 0.984375\n",
      "Train loss and acc of batch 70: 47.86032485961914, 1.0\n",
      "Training accuracy and loss of epoch #313: 0.9894, 48.1855\n",
      "Saved model by train loss 48.185545639253\n",
      "Train loss and acc of batch 0: 47.86031723022461, 1.0\n",
      "Train loss and acc of batch 1: 47.86030578613281, 1.0\n",
      "Train loss and acc of batch 2: 48.146148681640625, 0.984375\n",
      "Train loss and acc of batch 3: 48.077049255371094, 0.984375\n",
      "Train loss and acc of batch 4: 47.86027526855469, 1.0\n",
      "Train loss and acc of batch 5: 49.209197998046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.36288070678711, 0.96875\n",
      "Train loss and acc of batch 7: 47.86025619506836, 1.0\n",
      "Train loss and acc of batch 8: 48.45594024658203, 0.984375\n",
      "Train loss and acc of batch 9: 48.146087646484375, 0.984375\n",
      "Train loss and acc of batch 10: 47.860225677490234, 1.0\n",
      "Train loss and acc of batch 11: 47.86022186279297, 1.0\n",
      "Train loss and acc of batch 12: 48.61343765258789, 0.984375\n",
      "Train loss and acc of batch 13: 48.07696533203125, 0.984375\n",
      "Train loss and acc of batch 14: 48.07695770263672, 0.984375\n",
      "Train loss and acc of batch 15: 48.45587921142578, 0.984375\n",
      "Train loss and acc of batch 16: 48.45587158203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.61338806152344, 0.984375\n",
      "Train loss and acc of batch 18: 48.74170684814453, 0.96875\n",
      "Train loss and acc of batch 19: 47.86014938354492, 1.0\n",
      "Train loss and acc of batch 20: 47.860137939453125, 1.0\n",
      "Train loss and acc of batch 21: 48.455833435058594, 0.984375\n",
      "Train loss and acc of batch 22: 48.45581817626953, 0.984375\n",
      "Train loss and acc of batch 23: 47.860111236572266, 1.0\n",
      "Train loss and acc of batch 24: 48.45580291748047, 0.984375\n",
      "Train loss and acc of batch 25: 47.8600959777832, 1.0\n",
      "Train loss and acc of batch 26: 47.86008834838867, 1.0\n",
      "Train loss and acc of batch 27: 47.860076904296875, 1.0\n",
      "Train loss and acc of batch 28: 47.860069274902344, 1.0\n",
      "Train loss and acc of batch 29: 48.45575714111328, 0.984375\n",
      "Train loss and acc of batch 30: 47.860050201416016, 1.0\n",
      "Train loss and acc of batch 31: 48.07679748535156, 0.984375\n",
      "Train loss and acc of batch 32: 47.86003112792969, 1.0\n",
      "Train loss and acc of batch 33: 47.86001968383789, 1.0\n",
      "Train loss and acc of batch 34: 48.455718994140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.29353332519531, 0.96875\n",
      "Train loss and acc of batch 36: 47.8599967956543, 1.0\n",
      "Train loss and acc of batch 37: 48.61320877075195, 0.984375\n",
      "Train loss and acc of batch 38: 49.208900451660156, 0.96875\n",
      "Train loss and acc of batch 39: 48.07673645019531, 0.984375\n",
      "Train loss and acc of batch 40: 47.85996627807617, 1.0\n",
      "Train loss and acc of batch 41: 49.20887756347656, 0.96875\n",
      "Train loss and acc of batch 42: 47.859947204589844, 1.0\n",
      "Train loss and acc of batch 43: 48.45563507080078, 0.984375\n",
      "Train loss and acc of batch 44: 47.859928131103516, 1.0\n",
      "Train loss and acc of batch 45: 48.45561218261719, 0.984375\n",
      "Train loss and acc of batch 46: 48.145751953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.859893798828125, 1.0\n",
      "Train loss and acc of batch 48: 47.85988998413086, 1.0\n",
      "Train loss and acc of batch 49: 47.85987854003906, 1.0\n",
      "Train loss and acc of batch 50: 48.45557403564453, 0.984375\n",
      "Train loss and acc of batch 51: 49.20878601074219, 0.96875\n",
      "Train loss and acc of batch 52: 49.115692138671875, 0.953125\n",
      "Train loss and acc of batch 53: 47.85984420776367, 1.0\n",
      "Train loss and acc of batch 54: 48.07659912109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.859825134277344, 1.0\n",
      "Train loss and acc of batch 56: 47.85981750488281, 1.0\n",
      "Train loss and acc of batch 57: 48.45551300048828, 0.984375\n",
      "Train loss and acc of batch 58: 47.859806060791016, 1.0\n",
      "Train loss and acc of batch 59: 47.85978698730469, 1.0\n",
      "Train loss and acc of batch 60: 47.859779357910156, 1.0\n",
      "Train loss and acc of batch 61: 47.85977554321289, 1.0\n",
      "Train loss and acc of batch 62: 47.859764099121094, 1.0\n",
      "Train loss and acc of batch 63: 49.0511589050293, 0.96875\n",
      "Train loss and acc of batch 64: 48.076507568359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.8597412109375, 1.0\n",
      "Train loss and acc of batch 66: 47.85972595214844, 1.0\n",
      "Train loss and acc of batch 67: 48.67218780517578, 0.96875\n",
      "Train loss and acc of batch 68: 48.455413818359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.07646942138672, 0.984375\n",
      "Train loss and acc of batch 70: 47.85969543457031, 1.0\n",
      "Training accuracy and loss of epoch #314: 0.9894, 48.1849\n",
      "Saved model by train loss 48.18491395762269\n",
      "Train loss and acc of batch 0: 47.859683990478516, 1.0\n",
      "Train loss and acc of batch 1: 47.85968017578125, 1.0\n",
      "Train loss and acc of batch 2: 48.14551544189453, 0.984375\n",
      "Train loss and acc of batch 3: 48.076416015625, 0.984375\n",
      "Train loss and acc of batch 4: 47.859649658203125, 1.0\n",
      "Train loss and acc of batch 5: 49.20856475830078, 0.96875\n",
      "Train loss and acc of batch 6: 48.362247467041016, 0.96875\n",
      "Train loss and acc of batch 7: 47.859619140625, 1.0\n",
      "Train loss and acc of batch 8: 48.45531463623047, 0.984375\n",
      "Train loss and acc of batch 9: 48.14545440673828, 0.984375\n",
      "Train loss and acc of batch 10: 47.859596252441406, 1.0\n",
      "Train loss and acc of batch 11: 47.85958480834961, 1.0\n",
      "Train loss and acc of batch 12: 48.61280059814453, 0.984375\n",
      "Train loss and acc of batch 13: 48.076332092285156, 0.984375\n",
      "Train loss and acc of batch 14: 48.076332092285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.45525360107422, 0.984375\n",
      "Train loss and acc of batch 16: 48.455238342285156, 0.984375\n",
      "Train loss and acc of batch 17: 48.612754821777344, 0.984375\n",
      "Train loss and acc of batch 18: 48.7410774230957, 0.96875\n",
      "Train loss and acc of batch 19: 47.85951614379883, 1.0\n",
      "Train loss and acc of batch 20: 47.85950469970703, 1.0\n",
      "Train loss and acc of batch 21: 48.4552001953125, 0.984375\n",
      "Train loss and acc of batch 22: 48.45519256591797, 0.984375\n",
      "Train loss and acc of batch 23: 47.85948181152344, 1.0\n",
      "Train loss and acc of batch 24: 48.455169677734375, 0.984375\n",
      "Train loss and acc of batch 25: 47.85946273803711, 1.0\n",
      "Train loss and acc of batch 26: 47.85945129394531, 1.0\n",
      "Train loss and acc of batch 27: 47.85944747924805, 1.0\n",
      "Train loss and acc of batch 28: 47.859439849853516, 1.0\n",
      "Train loss and acc of batch 29: 48.45513153076172, 0.984375\n",
      "Train loss and acc of batch 30: 47.859413146972656, 1.0\n",
      "Train loss and acc of batch 31: 48.07617950439453, 0.984375\n",
      "Train loss and acc of batch 32: 47.85940170288086, 1.0\n",
      "Train loss and acc of batch 33: 47.85939025878906, 1.0\n",
      "Train loss and acc of batch 34: 48.455078125, 0.984375\n",
      "Train loss and acc of batch 35: 48.29290008544922, 0.96875\n",
      "Train loss and acc of batch 36: 47.8593635559082, 1.0\n",
      "Train loss and acc of batch 37: 48.612579345703125, 0.984375\n",
      "Train loss and acc of batch 38: 49.20826721191406, 0.96875\n",
      "Train loss and acc of batch 39: 48.07610321044922, 0.984375\n",
      "Train loss and acc of batch 40: 47.85932540893555, 1.0\n",
      "Train loss and acc of batch 41: 49.20824432373047, 0.96875\n",
      "Train loss and acc of batch 42: 47.85931396484375, 1.0\n",
      "Train loss and acc of batch 43: 48.45500183105469, 0.984375\n",
      "Train loss and acc of batch 44: 47.85929489135742, 1.0\n",
      "Train loss and acc of batch 45: 48.454986572265625, 0.984375\n",
      "Train loss and acc of batch 46: 48.14512634277344, 0.984375\n",
      "Train loss and acc of batch 47: 47.85926818847656, 1.0\n",
      "Train loss and acc of batch 48: 47.859256744384766, 1.0\n",
      "Train loss and acc of batch 49: 47.859249114990234, 1.0\n",
      "Train loss and acc of batch 50: 48.45494079589844, 0.984375\n",
      "Train loss and acc of batch 51: 49.208152770996094, 0.96875\n",
      "Train loss and acc of batch 52: 49.11506652832031, 0.953125\n",
      "Train loss and acc of batch 53: 47.859214782714844, 1.0\n",
      "Train loss and acc of batch 54: 48.075965881347656, 0.984375\n",
      "Train loss and acc of batch 55: 47.85919189453125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 56: 47.85918426513672, 1.0\n",
      "Train loss and acc of batch 57: 48.45487976074219, 0.984375\n",
      "Train loss and acc of batch 58: 47.859169006347656, 1.0\n",
      "Train loss and acc of batch 59: 47.859161376953125, 1.0\n",
      "Train loss and acc of batch 60: 47.859153747558594, 1.0\n",
      "Train loss and acc of batch 61: 47.85913848876953, 1.0\n",
      "Train loss and acc of batch 62: 47.859130859375, 1.0\n",
      "Train loss and acc of batch 63: 49.0505256652832, 0.96875\n",
      "Train loss and acc of batch 64: 48.07588195800781, 0.984375\n",
      "Train loss and acc of batch 65: 47.85910415649414, 1.0\n",
      "Train loss and acc of batch 66: 47.85910415649414, 1.0\n",
      "Train loss and acc of batch 67: 48.67155838012695, 0.96875\n",
      "Train loss and acc of batch 68: 48.45478057861328, 0.984375\n",
      "Train loss and acc of batch 69: 48.075836181640625, 0.984375\n",
      "Train loss and acc of batch 70: 47.859066009521484, 1.0\n",
      "Training accuracy and loss of epoch #315: 0.9894, 48.1843\n",
      "Saved model by train loss 48.184282598361165\n",
      "Train loss and acc of batch 0: 47.85905075073242, 1.0\n",
      "Train loss and acc of batch 1: 47.85904312133789, 1.0\n",
      "Train loss and acc of batch 2: 48.14488220214844, 0.984375\n",
      "Train loss and acc of batch 3: 48.07579040527344, 0.984375\n",
      "Train loss and acc of batch 4: 47.859012603759766, 1.0\n",
      "Train loss and acc of batch 5: 49.20793151855469, 0.96875\n",
      "Train loss and acc of batch 6: 48.36161422729492, 0.96875\n",
      "Train loss and acc of batch 7: 47.85898971557617, 1.0\n",
      "Train loss and acc of batch 8: 48.454681396484375, 0.984375\n",
      "Train loss and acc of batch 9: 48.14482879638672, 0.984375\n",
      "Train loss and acc of batch 10: 47.85896682739258, 1.0\n",
      "Train loss and acc of batch 11: 47.858951568603516, 1.0\n",
      "Train loss and acc of batch 12: 48.61216735839844, 0.984375\n",
      "Train loss and acc of batch 13: 48.075706481933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.07569122314453, 0.984375\n",
      "Train loss and acc of batch 15: 48.454620361328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.454612731933594, 0.984375\n",
      "Train loss and acc of batch 17: 48.61212921142578, 0.984375\n",
      "Train loss and acc of batch 18: 48.740447998046875, 0.96875\n",
      "Train loss and acc of batch 19: 47.85887908935547, 1.0\n",
      "Train loss and acc of batch 20: 47.8588752746582, 1.0\n",
      "Train loss and acc of batch 21: 48.454566955566406, 0.984375\n",
      "Train loss and acc of batch 22: 48.454559326171875, 0.984375\n",
      "Train loss and acc of batch 23: 47.85885238647461, 1.0\n",
      "Train loss and acc of batch 24: 48.45454406738281, 0.984375\n",
      "Train loss and acc of batch 25: 47.858829498291016, 1.0\n",
      "Train loss and acc of batch 26: 47.85881805419922, 1.0\n",
      "Train loss and acc of batch 27: 47.85881423950195, 1.0\n",
      "Train loss and acc of batch 28: 47.85880661010742, 1.0\n",
      "Train loss and acc of batch 29: 48.454490661621094, 0.984375\n",
      "Train loss and acc of batch 30: 47.85878372192383, 1.0\n",
      "Train loss and acc of batch 31: 48.075538635253906, 0.984375\n",
      "Train loss and acc of batch 32: 47.85877227783203, 1.0\n",
      "Train loss and acc of batch 33: 47.8587646484375, 1.0\n",
      "Train loss and acc of batch 34: 48.45445251464844, 0.984375\n",
      "Train loss and acc of batch 35: 48.292266845703125, 0.96875\n",
      "Train loss and acc of batch 36: 47.858734130859375, 1.0\n",
      "Train loss and acc of batch 37: 48.61194610595703, 0.984375\n",
      "Train loss and acc of batch 38: 49.2076416015625, 0.96875\n",
      "Train loss and acc of batch 39: 48.075469970703125, 0.984375\n",
      "Train loss and acc of batch 40: 47.85869598388672, 1.0\n",
      "Train loss and acc of batch 41: 49.20761489868164, 0.96875\n",
      "Train loss and acc of batch 42: 47.858680725097656, 1.0\n",
      "Train loss and acc of batch 43: 48.454368591308594, 0.984375\n",
      "Train loss and acc of batch 44: 47.85866165161133, 1.0\n",
      "Train loss and acc of batch 45: 48.45435333251953, 0.984375\n",
      "Train loss and acc of batch 46: 48.144500732421875, 0.984375\n",
      "Train loss and acc of batch 47: 47.85863494873047, 1.0\n",
      "Train loss and acc of batch 48: 47.85862350463867, 1.0\n",
      "Train loss and acc of batch 49: 47.85861587524414, 1.0\n",
      "Train loss and acc of batch 50: 48.454307556152344, 0.984375\n",
      "Train loss and acc of batch 51: 49.20752716064453, 0.96875\n",
      "Train loss and acc of batch 52: 49.11442947387695, 0.953125\n",
      "Train loss and acc of batch 53: 47.85858154296875, 1.0\n",
      "Train loss and acc of batch 54: 48.075340270996094, 0.984375\n",
      "Train loss and acc of batch 55: 47.85856628417969, 1.0\n",
      "Train loss and acc of batch 56: 47.858551025390625, 1.0\n",
      "Train loss and acc of batch 57: 48.454246520996094, 0.984375\n",
      "Train loss and acc of batch 58: 47.8585319519043, 1.0\n",
      "Train loss and acc of batch 59: 47.85852813720703, 1.0\n",
      "Train loss and acc of batch 60: 47.8585205078125, 1.0\n",
      "Train loss and acc of batch 61: 47.85851287841797, 1.0\n",
      "Train loss and acc of batch 62: 47.85849380493164, 1.0\n",
      "Train loss and acc of batch 63: 49.04989242553711, 0.96875\n",
      "Train loss and acc of batch 64: 48.07524871826172, 0.984375\n",
      "Train loss and acc of batch 65: 47.85847473144531, 1.0\n",
      "Train loss and acc of batch 66: 47.858463287353516, 1.0\n",
      "Train loss and acc of batch 67: 48.670921325683594, 0.96875\n",
      "Train loss and acc of batch 68: 48.45414733886719, 0.984375\n",
      "Train loss and acc of batch 69: 48.07520294189453, 0.984375\n",
      "Train loss and acc of batch 70: 47.85842514038086, 1.0\n",
      "Training accuracy and loss of epoch #316: 0.9894, 48.1837\n",
      "Saved model by train loss 48.18365054063394\n",
      "Train loss and acc of batch 0: 47.85841751098633, 1.0\n",
      "Train loss and acc of batch 1: 47.85841369628906, 1.0\n",
      "Train loss and acc of batch 2: 48.144256591796875, 0.984375\n",
      "Train loss and acc of batch 3: 48.075157165527344, 0.984375\n",
      "Train loss and acc of batch 4: 47.85838317871094, 1.0\n",
      "Train loss and acc of batch 5: 49.207298278808594, 0.96875\n",
      "Train loss and acc of batch 6: 48.36098098754883, 0.96875\n",
      "Train loss and acc of batch 7: 47.85835647583008, 1.0\n",
      "Train loss and acc of batch 8: 48.45404815673828, 0.984375\n",
      "Train loss and acc of batch 9: 48.144195556640625, 0.984375\n",
      "Train loss and acc of batch 10: 47.858333587646484, 1.0\n",
      "Train loss and acc of batch 11: 47.85832214355469, 1.0\n",
      "Train loss and acc of batch 12: 48.611541748046875, 0.984375\n",
      "Train loss and acc of batch 13: 48.07506561279297, 0.984375\n",
      "Train loss and acc of batch 14: 48.07505798339844, 0.984375\n",
      "Train loss and acc of batch 15: 48.45398712158203, 0.984375\n",
      "Train loss and acc of batch 16: 48.4539794921875, 0.984375\n",
      "Train loss and acc of batch 17: 48.61149597167969, 0.984375\n",
      "Train loss and acc of batch 18: 48.73981857299805, 0.96875\n",
      "Train loss and acc of batch 19: 47.858253479003906, 1.0\n",
      "Train loss and acc of batch 20: 47.858245849609375, 1.0\n",
      "Train loss and acc of batch 21: 48.45393371582031, 0.984375\n",
      "Train loss and acc of batch 22: 48.45392608642578, 0.984375\n",
      "Train loss and acc of batch 23: 47.85821533203125, 1.0\n",
      "Train loss and acc of batch 24: 48.45390319824219, 0.984375\n",
      "Train loss and acc of batch 25: 47.85820007324219, 1.0\n",
      "Train loss and acc of batch 26: 47.858192443847656, 1.0\n",
      "Train loss and acc of batch 27: 47.858177185058594, 1.0\n",
      "Train loss and acc of batch 28: 47.85816955566406, 1.0\n",
      "Train loss and acc of batch 29: 48.45386505126953, 0.984375\n",
      "Train loss and acc of batch 30: 47.858154296875, 1.0\n",
      "Train loss and acc of batch 31: 48.074913024902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.85813522338867, 1.0\n",
      "Train loss and acc of batch 33: 47.85812759399414, 1.0\n",
      "Train loss and acc of batch 34: 48.453819274902344, 0.984375\n",
      "Train loss and acc of batch 35: 48.29164123535156, 0.96875\n",
      "Train loss and acc of batch 36: 47.85810089111328, 1.0\n",
      "Train loss and acc of batch 37: 48.61131286621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.207008361816406, 0.96875\n",
      "Train loss and acc of batch 39: 48.07483673095703, 0.984375\n",
      "Train loss and acc of batch 40: 47.858062744140625, 1.0\n",
      "Train loss and acc of batch 41: 49.20697784423828, 0.96875\n",
      "Train loss and acc of batch 42: 47.85804748535156, 1.0\n",
      "Train loss and acc of batch 43: 48.4537353515625, 0.984375\n",
      "Train loss and acc of batch 44: 47.858028411865234, 1.0\n",
      "Train loss and acc of batch 45: 48.45372009277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.14386749267578, 0.984375\n",
      "Train loss and acc of batch 47: 47.85800552368164, 1.0\n",
      "Train loss and acc of batch 48: 47.857994079589844, 1.0\n",
      "Train loss and acc of batch 49: 47.85798263549805, 1.0\n",
      "Train loss and acc of batch 50: 48.45368194580078, 0.984375\n",
      "Train loss and acc of batch 51: 49.206886291503906, 0.96875\n",
      "Train loss and acc of batch 52: 49.113800048828125, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.857948303222656, 1.0\n",
      "Train loss and acc of batch 54: 48.07470703125, 0.984375\n",
      "Train loss and acc of batch 55: 47.85793685913086, 1.0\n",
      "Train loss and acc of batch 56: 47.8579216003418, 1.0\n",
      "Train loss and acc of batch 57: 48.45361328125, 0.984375\n",
      "Train loss and acc of batch 58: 47.857906341552734, 1.0\n",
      "Train loss and acc of batch 59: 47.8578987121582, 1.0\n",
      "Train loss and acc of batch 60: 47.857887268066406, 1.0\n",
      "Train loss and acc of batch 61: 47.85787582397461, 1.0\n",
      "Train loss and acc of batch 62: 47.85786819458008, 1.0\n",
      "Train loss and acc of batch 63: 49.04926681518555, 0.96875\n",
      "Train loss and acc of batch 64: 48.074615478515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.85783767700195, 1.0\n",
      "Train loss and acc of batch 66: 47.85783386230469, 1.0\n",
      "Train loss and acc of batch 67: 48.670291900634766, 0.96875\n",
      "Train loss and acc of batch 68: 48.453521728515625, 0.984375\n",
      "Train loss and acc of batch 69: 48.07457733154297, 0.984375\n",
      "Train loss and acc of batch 70: 47.8577995300293, 1.0\n",
      "Training accuracy and loss of epoch #317: 0.9894, 48.1830\n",
      "Saved model by train loss 48.18301885900363\n",
      "Train loss and acc of batch 0: 47.8577880859375, 1.0\n",
      "Train loss and acc of batch 1: 47.8577766418457, 1.0\n",
      "Train loss and acc of batch 2: 48.14362335205078, 0.984375\n",
      "Train loss and acc of batch 3: 48.07452392578125, 0.984375\n",
      "Train loss and acc of batch 4: 47.85775375366211, 1.0\n",
      "Train loss and acc of batch 5: 49.2066650390625, 0.96875\n",
      "Train loss and acc of batch 6: 48.360355377197266, 0.96875\n",
      "Train loss and acc of batch 7: 47.85772705078125, 1.0\n",
      "Train loss and acc of batch 8: 48.45341491699219, 0.984375\n",
      "Train loss and acc of batch 9: 48.14356231689453, 0.984375\n",
      "Train loss and acc of batch 10: 47.85770034790039, 1.0\n",
      "Train loss and acc of batch 11: 47.85769271850586, 1.0\n",
      "Train loss and acc of batch 12: 48.61090850830078, 0.984375\n",
      "Train loss and acc of batch 13: 48.074440002441406, 0.984375\n",
      "Train loss and acc of batch 14: 48.074432373046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.45335388183594, 0.984375\n",
      "Train loss and acc of batch 16: 48.453346252441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.610862731933594, 0.984375\n",
      "Train loss and acc of batch 18: 48.73918151855469, 0.96875\n",
      "Train loss and acc of batch 19: 47.85762405395508, 1.0\n",
      "Train loss and acc of batch 20: 47.85761260986328, 1.0\n",
      "Train loss and acc of batch 21: 48.45330047607422, 0.984375\n",
      "Train loss and acc of batch 22: 48.45329284667969, 0.984375\n",
      "Train loss and acc of batch 23: 47.857582092285156, 1.0\n",
      "Train loss and acc of batch 24: 48.453277587890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.857566833496094, 1.0\n",
      "Train loss and acc of batch 26: 47.85756301879883, 1.0\n",
      "Train loss and acc of batch 27: 47.857547760009766, 1.0\n",
      "Train loss and acc of batch 28: 47.857540130615234, 1.0\n",
      "Train loss and acc of batch 29: 48.45323181152344, 0.984375\n",
      "Train loss and acc of batch 30: 47.85752487182617, 1.0\n",
      "Train loss and acc of batch 31: 48.07427215576172, 0.984375\n",
      "Train loss and acc of batch 32: 47.85750198364258, 1.0\n",
      "Train loss and acc of batch 33: 47.85749816894531, 1.0\n",
      "Train loss and acc of batch 34: 48.45319366455078, 0.984375\n",
      "Train loss and acc of batch 35: 48.2910041809082, 0.96875\n",
      "Train loss and acc of batch 36: 47.85746383666992, 1.0\n",
      "Train loss and acc of batch 37: 48.61068344116211, 0.984375\n",
      "Train loss and acc of batch 38: 49.20637512207031, 0.96875\n",
      "Train loss and acc of batch 39: 48.07420349121094, 0.984375\n",
      "Train loss and acc of batch 40: 47.85743713378906, 1.0\n",
      "Train loss and acc of batch 41: 49.20635223388672, 0.96875\n",
      "Train loss and acc of batch 42: 47.85741424560547, 1.0\n",
      "Train loss and acc of batch 43: 48.45310974121094, 0.984375\n",
      "Train loss and acc of batch 44: 47.857398986816406, 1.0\n",
      "Train loss and acc of batch 45: 48.453086853027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.143226623535156, 0.984375\n",
      "Train loss and acc of batch 47: 47.85737228393555, 1.0\n",
      "Train loss and acc of batch 48: 47.857364654541016, 1.0\n",
      "Train loss and acc of batch 49: 47.85735321044922, 1.0\n",
      "Train loss and acc of batch 50: 48.453041076660156, 0.984375\n",
      "Train loss and acc of batch 51: 49.206260681152344, 0.96875\n",
      "Train loss and acc of batch 52: 49.11316680908203, 0.953125\n",
      "Train loss and acc of batch 53: 47.85731887817383, 1.0\n",
      "Train loss and acc of batch 54: 48.074073791503906, 0.984375\n",
      "Train loss and acc of batch 55: 47.857303619384766, 1.0\n",
      "Train loss and acc of batch 56: 47.8572883605957, 1.0\n",
      "Train loss and acc of batch 57: 48.45298767089844, 0.984375\n",
      "Train loss and acc of batch 58: 47.857276916503906, 1.0\n",
      "Train loss and acc of batch 59: 47.857261657714844, 1.0\n",
      "Train loss and acc of batch 60: 47.85725402832031, 1.0\n",
      "Train loss and acc of batch 61: 47.85724639892578, 1.0\n",
      "Train loss and acc of batch 62: 47.85723876953125, 1.0\n",
      "Train loss and acc of batch 63: 49.04863357543945, 0.96875\n",
      "Train loss and acc of batch 64: 48.07398223876953, 0.984375\n",
      "Train loss and acc of batch 65: 47.857215881347656, 1.0\n",
      "Train loss and acc of batch 66: 47.857200622558594, 1.0\n",
      "Train loss and acc of batch 67: 48.66965866088867, 0.96875\n",
      "Train loss and acc of batch 68: 48.452880859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.073944091796875, 0.984375\n",
      "Train loss and acc of batch 70: 47.8571662902832, 1.0\n",
      "Training accuracy and loss of epoch #318: 0.9894, 48.1824\n",
      "Saved model by train loss 48.18238712364519\n",
      "Train loss and acc of batch 0: 47.8571662902832, 1.0\n",
      "Train loss and acc of batch 1: 47.85715103149414, 1.0\n",
      "Train loss and acc of batch 2: 48.14299011230469, 0.984375\n",
      "Train loss and acc of batch 3: 48.073890686035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.85712432861328, 1.0\n",
      "Train loss and acc of batch 5: 49.20603942871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.359718322753906, 0.96875\n",
      "Train loss and acc of batch 7: 47.857093811035156, 1.0\n",
      "Train loss and acc of batch 8: 48.452789306640625, 0.984375\n",
      "Train loss and acc of batch 9: 48.14292907714844, 0.984375\n",
      "Train loss and acc of batch 10: 47.8570671081543, 1.0\n",
      "Train loss and acc of batch 11: 47.857059478759766, 1.0\n",
      "Train loss and acc of batch 12: 48.61027526855469, 0.984375\n",
      "Train loss and acc of batch 13: 48.07380676269531, 0.984375\n",
      "Train loss and acc of batch 14: 48.07379913330078, 0.984375\n",
      "Train loss and acc of batch 15: 48.452728271484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.45271301269531, 0.984375\n",
      "Train loss and acc of batch 17: 48.610225677490234, 0.984375\n",
      "Train loss and acc of batch 18: 48.738555908203125, 0.96875\n",
      "Train loss and acc of batch 19: 47.856990814208984, 1.0\n",
      "Train loss and acc of batch 20: 47.85697555541992, 1.0\n",
      "Train loss and acc of batch 21: 48.452667236328125, 0.984375\n",
      "Train loss and acc of batch 22: 48.452667236328125, 0.984375\n",
      "Train loss and acc of batch 23: 47.85695266723633, 1.0\n",
      "Train loss and acc of batch 24: 48.45264434814453, 0.984375\n",
      "Train loss and acc of batch 25: 47.856937408447266, 1.0\n",
      "Train loss and acc of batch 26: 47.85692596435547, 1.0\n",
      "Train loss and acc of batch 27: 47.85691833496094, 1.0\n",
      "Train loss and acc of batch 28: 47.85691452026367, 1.0\n",
      "Train loss and acc of batch 29: 48.452606201171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.85688781738281, 1.0\n",
      "Train loss and acc of batch 31: 48.073646545410156, 0.984375\n",
      "Train loss and acc of batch 32: 47.85687255859375, 1.0\n",
      "Train loss and acc of batch 33: 47.85686492919922, 1.0\n",
      "Train loss and acc of batch 34: 48.452552795410156, 0.984375\n",
      "Train loss and acc of batch 35: 48.29037094116211, 0.96875\n",
      "Train loss and acc of batch 36: 47.85683822631836, 1.0\n",
      "Train loss and acc of batch 37: 48.61005401611328, 0.984375\n",
      "Train loss and acc of batch 38: 49.20574188232422, 0.96875\n",
      "Train loss and acc of batch 39: 48.073577880859375, 0.984375\n",
      "Train loss and acc of batch 40: 47.8568000793457, 1.0\n",
      "Train loss and acc of batch 41: 49.205718994140625, 0.96875\n",
      "Train loss and acc of batch 42: 47.85678482055664, 1.0\n",
      "Train loss and acc of batch 43: 48.452484130859375, 0.984375\n",
      "Train loss and acc of batch 44: 47.85676574707031, 1.0\n",
      "Train loss and acc of batch 45: 48.45245361328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.142601013183594, 0.984375\n",
      "Train loss and acc of batch 47: 47.85673904418945, 1.0\n",
      "Train loss and acc of batch 48: 47.856727600097656, 1.0\n",
      "Train loss and acc of batch 49: 47.85672378540039, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 50: 48.452415466308594, 0.984375\n",
      "Train loss and acc of batch 51: 49.20562744140625, 0.96875\n",
      "Train loss and acc of batch 52: 49.1125373840332, 0.953125\n",
      "Train loss and acc of batch 53: 47.856685638427734, 1.0\n",
      "Train loss and acc of batch 54: 48.07344055175781, 0.984375\n",
      "Train loss and acc of batch 55: 47.856666564941406, 1.0\n",
      "Train loss and acc of batch 56: 47.85666275024414, 1.0\n",
      "Train loss and acc of batch 57: 48.452354431152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.85664367675781, 1.0\n",
      "Train loss and acc of batch 59: 47.856632232666016, 1.0\n",
      "Train loss and acc of batch 60: 47.856624603271484, 1.0\n",
      "Train loss and acc of batch 61: 47.85661315917969, 1.0\n",
      "Train loss and acc of batch 62: 47.85660171508789, 1.0\n",
      "Train loss and acc of batch 63: 49.04800033569336, 0.96875\n",
      "Train loss and acc of batch 64: 48.07335662841797, 0.984375\n",
      "Train loss and acc of batch 65: 47.8565788269043, 1.0\n",
      "Train loss and acc of batch 66: 47.856571197509766, 1.0\n",
      "Train loss and acc of batch 67: 48.66902542114258, 0.96875\n",
      "Train loss and acc of batch 68: 48.45225524902344, 0.984375\n",
      "Train loss and acc of batch 69: 48.07330322265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.856536865234375, 1.0\n",
      "Training accuracy and loss of epoch #319: 0.9894, 48.1818\n",
      "Saved model by train loss 48.181755818111796\n",
      "Train loss and acc of batch 0: 47.85652542114258, 1.0\n",
      "Train loss and acc of batch 1: 47.85651779174805, 1.0\n",
      "Train loss and acc of batch 2: 48.142364501953125, 0.984375\n",
      "Train loss and acc of batch 3: 48.073265075683594, 0.984375\n",
      "Train loss and acc of batch 4: 47.85649108886719, 1.0\n",
      "Train loss and acc of batch 5: 49.205406188964844, 0.96875\n",
      "Train loss and acc of batch 6: 48.35908889770508, 0.96875\n",
      "Train loss and acc of batch 7: 47.85646438598633, 1.0\n",
      "Train loss and acc of batch 8: 48.45215606689453, 0.984375\n",
      "Train loss and acc of batch 9: 48.142295837402344, 0.984375\n",
      "Train loss and acc of batch 10: 47.8564338684082, 1.0\n",
      "Train loss and acc of batch 11: 47.85642623901367, 1.0\n",
      "Train loss and acc of batch 12: 48.609642028808594, 0.984375\n",
      "Train loss and acc of batch 13: 48.07317352294922, 0.984375\n",
      "Train loss and acc of batch 14: 48.07316589355469, 0.984375\n",
      "Train loss and acc of batch 15: 48.45209503173828, 0.984375\n",
      "Train loss and acc of batch 16: 48.45208740234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.60960006713867, 0.984375\n",
      "Train loss and acc of batch 18: 48.73792266845703, 0.96875\n",
      "Train loss and acc of batch 19: 47.856353759765625, 1.0\n",
      "Train loss and acc of batch 20: 47.85634994506836, 1.0\n",
      "Train loss and acc of batch 21: 48.45204162597656, 0.984375\n",
      "Train loss and acc of batch 22: 48.45203399658203, 0.984375\n",
      "Train loss and acc of batch 23: 47.856327056884766, 1.0\n",
      "Train loss and acc of batch 24: 48.45201873779297, 0.984375\n",
      "Train loss and acc of batch 25: 47.856300354003906, 1.0\n",
      "Train loss and acc of batch 26: 47.856292724609375, 1.0\n",
      "Train loss and acc of batch 27: 47.856285095214844, 1.0\n",
      "Train loss and acc of batch 28: 47.85628128051758, 1.0\n",
      "Train loss and acc of batch 29: 48.45196533203125, 0.984375\n",
      "Train loss and acc of batch 30: 47.85626220703125, 1.0\n",
      "Train loss and acc of batch 31: 48.07301330566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.856239318847656, 1.0\n",
      "Train loss and acc of batch 33: 47.856231689453125, 1.0\n",
      "Train loss and acc of batch 34: 48.451927185058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.28974151611328, 0.96875\n",
      "Train loss and acc of batch 36: 47.856204986572266, 1.0\n",
      "Train loss and acc of batch 37: 48.60942077636719, 0.984375\n",
      "Train loss and acc of batch 38: 49.205108642578125, 0.96875\n",
      "Train loss and acc of batch 39: 48.07293701171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.856163024902344, 1.0\n",
      "Train loss and acc of batch 41: 49.2050895690918, 0.96875\n",
      "Train loss and acc of batch 42: 47.85615158081055, 1.0\n",
      "Train loss and acc of batch 43: 48.45184326171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.85612869262695, 1.0\n",
      "Train loss and acc of batch 45: 48.45182800292969, 0.984375\n",
      "Train loss and acc of batch 46: 48.1419677734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.85610580444336, 1.0\n",
      "Train loss and acc of batch 48: 47.85609436035156, 1.0\n",
      "Train loss and acc of batch 49: 47.8560905456543, 1.0\n",
      "Train loss and acc of batch 50: 48.4517822265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.204994201660156, 0.96875\n",
      "Train loss and acc of batch 52: 49.111900329589844, 0.953125\n",
      "Train loss and acc of batch 53: 47.856048583984375, 1.0\n",
      "Train loss and acc of batch 54: 48.07280731201172, 0.984375\n",
      "Train loss and acc of batch 55: 47.85603332519531, 1.0\n",
      "Train loss and acc of batch 56: 47.85602569580078, 1.0\n",
      "Train loss and acc of batch 57: 48.45171356201172, 0.984375\n",
      "Train loss and acc of batch 58: 47.85600662231445, 1.0\n",
      "Train loss and acc of batch 59: 47.85599899291992, 1.0\n",
      "Train loss and acc of batch 60: 47.85599136352539, 1.0\n",
      "Train loss and acc of batch 61: 47.855979919433594, 1.0\n",
      "Train loss and acc of batch 62: 47.85597229003906, 1.0\n",
      "Train loss and acc of batch 63: 49.04736328125, 0.96875\n",
      "Train loss and acc of batch 64: 48.072715759277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.85594940185547, 1.0\n",
      "Train loss and acc of batch 66: 47.85593795776367, 1.0\n",
      "Train loss and acc of batch 67: 48.668392181396484, 0.96875\n",
      "Train loss and acc of batch 68: 48.45161437988281, 0.984375\n",
      "Train loss and acc of batch 69: 48.072669982910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.85590362548828, 1.0\n",
      "Training accuracy and loss of epoch #320: 0.9894, 48.1811\n",
      "Saved model by train loss 48.18112284700636\n",
      "Train loss and acc of batch 0: 47.85588836669922, 1.0\n",
      "Train loss and acc of batch 1: 47.85588455200195, 1.0\n",
      "Train loss and acc of batch 2: 48.1417236328125, 0.984375\n",
      "Train loss and acc of batch 3: 48.0726318359375, 0.984375\n",
      "Train loss and acc of batch 4: 47.85585403442383, 1.0\n",
      "Train loss and acc of batch 5: 49.20477294921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.358455657958984, 0.96875\n",
      "Train loss and acc of batch 7: 47.85582733154297, 1.0\n",
      "Train loss and acc of batch 8: 48.45152282714844, 0.984375\n",
      "Train loss and acc of batch 9: 48.14166259765625, 0.984375\n",
      "Train loss and acc of batch 10: 47.85580062866211, 1.0\n",
      "Train loss and acc of batch 11: 47.85579299926758, 1.0\n",
      "Train loss and acc of batch 12: 48.609004974365234, 0.984375\n",
      "Train loss and acc of batch 13: 48.072540283203125, 0.984375\n",
      "Train loss and acc of batch 14: 48.072532653808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.45146179199219, 0.984375\n",
      "Train loss and acc of batch 16: 48.451454162597656, 0.984375\n",
      "Train loss and acc of batch 17: 48.60896682739258, 0.984375\n",
      "Train loss and acc of batch 18: 48.737281799316406, 0.96875\n",
      "Train loss and acc of batch 19: 47.85572052001953, 1.0\n",
      "Train loss and acc of batch 20: 47.855712890625, 1.0\n",
      "Train loss and acc of batch 21: 48.45140838623047, 0.984375\n",
      "Train loss and acc of batch 22: 48.45140075683594, 0.984375\n",
      "Train loss and acc of batch 23: 47.855690002441406, 1.0\n",
      "Train loss and acc of batch 24: 48.451377868652344, 0.984375\n",
      "Train loss and acc of batch 25: 47.855674743652344, 1.0\n",
      "Train loss and acc of batch 26: 47.85565948486328, 1.0\n",
      "Train loss and acc of batch 27: 47.85565185546875, 1.0\n",
      "Train loss and acc of batch 28: 47.85564422607422, 1.0\n",
      "Train loss and acc of batch 29: 48.451332092285156, 0.984375\n",
      "Train loss and acc of batch 30: 47.85562515258789, 1.0\n",
      "Train loss and acc of batch 31: 48.07238006591797, 0.984375\n",
      "Train loss and acc of batch 32: 47.85560989379883, 1.0\n",
      "Train loss and acc of batch 33: 47.85559844970703, 1.0\n",
      "Train loss and acc of batch 34: 48.4512939453125, 0.984375\n",
      "Train loss and acc of batch 35: 48.28910827636719, 0.96875\n",
      "Train loss and acc of batch 36: 47.85557556152344, 1.0\n",
      "Train loss and acc of batch 37: 48.60878372192383, 0.984375\n",
      "Train loss and acc of batch 38: 49.20448303222656, 0.96875\n",
      "Train loss and acc of batch 39: 48.07231140136719, 0.984375\n",
      "Train loss and acc of batch 40: 47.85553741455078, 1.0\n",
      "Train loss and acc of batch 41: 49.20445251464844, 0.96875\n",
      "Train loss and acc of batch 42: 47.85551834106445, 1.0\n",
      "Train loss and acc of batch 43: 48.451210021972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.85550308227539, 1.0\n",
      "Train loss and acc of batch 45: 48.451194763183594, 0.984375\n",
      "Train loss and acc of batch 46: 48.141334533691406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 47.85547637939453, 1.0\n",
      "Train loss and acc of batch 48: 47.85546112060547, 1.0\n",
      "Train loss and acc of batch 49: 47.8554573059082, 1.0\n",
      "Train loss and acc of batch 50: 48.451148986816406, 0.984375\n",
      "Train loss and acc of batch 51: 49.20436096191406, 0.96875\n",
      "Train loss and acc of batch 52: 49.111270904541016, 0.953125\n",
      "Train loss and acc of batch 53: 47.85541915893555, 1.0\n",
      "Train loss and acc of batch 54: 48.072174072265625, 0.984375\n",
      "Train loss and acc of batch 55: 47.855403900146484, 1.0\n",
      "Train loss and acc of batch 56: 47.85539245605469, 1.0\n",
      "Train loss and acc of batch 57: 48.451087951660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.855377197265625, 1.0\n",
      "Train loss and acc of batch 59: 47.855369567871094, 1.0\n",
      "Train loss and acc of batch 60: 47.8553581237793, 1.0\n",
      "Train loss and acc of batch 61: 47.855350494384766, 1.0\n",
      "Train loss and acc of batch 62: 47.855342864990234, 1.0\n",
      "Train loss and acc of batch 63: 49.04673385620117, 0.96875\n",
      "Train loss and acc of batch 64: 48.07209014892578, 0.984375\n",
      "Train loss and acc of batch 65: 47.85531234741211, 1.0\n",
      "Train loss and acc of batch 66: 47.855308532714844, 1.0\n",
      "Train loss and acc of batch 67: 48.667762756347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.45098876953125, 0.984375\n",
      "Train loss and acc of batch 69: 48.072044372558594, 0.984375\n",
      "Train loss and acc of batch 70: 47.85526657104492, 1.0\n",
      "Training accuracy and loss of epoch #321: 0.9894, 48.1805\n",
      "Saved model by train loss 48.18049030572596\n",
      "Train loss and acc of batch 0: 47.85525894165039, 1.0\n",
      "Train loss and acc of batch 1: 47.85525131225586, 1.0\n",
      "Train loss and acc of batch 2: 48.14109802246094, 0.984375\n",
      "Train loss and acc of batch 3: 48.071998596191406, 0.984375\n",
      "Train loss and acc of batch 4: 47.855224609375, 1.0\n",
      "Train loss and acc of batch 5: 49.204139709472656, 0.96875\n",
      "Train loss and acc of batch 6: 48.357826232910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.85519790649414, 1.0\n",
      "Train loss and acc of batch 8: 48.450889587402344, 0.984375\n",
      "Train loss and acc of batch 9: 48.141029357910156, 0.984375\n",
      "Train loss and acc of batch 10: 47.85517501831055, 1.0\n",
      "Train loss and acc of batch 11: 47.85516357421875, 1.0\n",
      "Train loss and acc of batch 12: 48.60837936401367, 0.984375\n",
      "Train loss and acc of batch 13: 48.07190704345703, 0.984375\n",
      "Train loss and acc of batch 14: 48.0718994140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.450828552246094, 0.984375\n",
      "Train loss and acc of batch 16: 48.45081329345703, 0.984375\n",
      "Train loss and acc of batch 17: 48.60832977294922, 0.984375\n",
      "Train loss and acc of batch 18: 48.73665237426758, 0.96875\n",
      "Train loss and acc of batch 19: 47.8550910949707, 1.0\n",
      "Train loss and acc of batch 20: 47.855079650878906, 1.0\n",
      "Train loss and acc of batch 21: 48.450775146484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.45075988769531, 0.984375\n",
      "Train loss and acc of batch 23: 47.85505676269531, 1.0\n",
      "Train loss and acc of batch 24: 48.45075225830078, 0.984375\n",
      "Train loss and acc of batch 25: 47.855037689208984, 1.0\n",
      "Train loss and acc of batch 26: 47.85503005981445, 1.0\n",
      "Train loss and acc of batch 27: 47.855018615722656, 1.0\n",
      "Train loss and acc of batch 28: 47.85500717163086, 1.0\n",
      "Train loss and acc of batch 29: 48.450706481933594, 0.984375\n",
      "Train loss and acc of batch 30: 47.8549919128418, 1.0\n",
      "Train loss and acc of batch 31: 48.071746826171875, 0.984375\n",
      "Train loss and acc of batch 32: 47.85497283935547, 1.0\n",
      "Train loss and acc of batch 33: 47.85496520996094, 1.0\n",
      "Train loss and acc of batch 34: 48.450660705566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.28847885131836, 0.96875\n",
      "Train loss and acc of batch 36: 47.85493850708008, 1.0\n",
      "Train loss and acc of batch 37: 48.608154296875, 0.984375\n",
      "Train loss and acc of batch 38: 49.20384979248047, 0.96875\n",
      "Train loss and acc of batch 39: 48.071678161621094, 0.984375\n",
      "Train loss and acc of batch 40: 47.85491180419922, 1.0\n",
      "Train loss and acc of batch 41: 49.203819274902344, 0.96875\n",
      "Train loss and acc of batch 42: 47.85488510131836, 1.0\n",
      "Train loss and acc of batch 43: 48.450584411621094, 0.984375\n",
      "Train loss and acc of batch 44: 47.85486602783203, 1.0\n",
      "Train loss and acc of batch 45: 48.4505615234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.14070129394531, 0.984375\n",
      "Train loss and acc of batch 47: 47.85484313964844, 1.0\n",
      "Train loss and acc of batch 48: 47.854835510253906, 1.0\n",
      "Train loss and acc of batch 49: 47.85482406616211, 1.0\n",
      "Train loss and acc of batch 50: 48.45051574707031, 0.984375\n",
      "Train loss and acc of batch 51: 49.2037353515625, 0.96875\n",
      "Train loss and acc of batch 52: 49.11063766479492, 0.953125\n",
      "Train loss and acc of batch 53: 47.85478973388672, 1.0\n",
      "Train loss and acc of batch 54: 48.07154083251953, 0.984375\n",
      "Train loss and acc of batch 55: 47.85477066040039, 1.0\n",
      "Train loss and acc of batch 56: 47.85476303100586, 1.0\n",
      "Train loss and acc of batch 57: 48.45045471191406, 0.984375\n",
      "Train loss and acc of batch 58: 47.85474395751953, 1.0\n",
      "Train loss and acc of batch 59: 47.854732513427734, 1.0\n",
      "Train loss and acc of batch 60: 47.8547248840332, 1.0\n",
      "Train loss and acc of batch 61: 47.854713439941406, 1.0\n",
      "Train loss and acc of batch 62: 47.85470962524414, 1.0\n",
      "Train loss and acc of batch 63: 49.046104431152344, 0.96875\n",
      "Train loss and acc of batch 64: 48.071449279785156, 0.984375\n",
      "Train loss and acc of batch 65: 47.854679107666016, 1.0\n",
      "Train loss and acc of batch 66: 47.85467529296875, 1.0\n",
      "Train loss and acc of batch 67: 48.66712951660156, 0.96875\n",
      "Train loss and acc of batch 68: 48.45036315917969, 0.984375\n",
      "Train loss and acc of batch 69: 48.0714111328125, 0.984375\n",
      "Train loss and acc of batch 70: 47.85464096069336, 1.0\n",
      "Training accuracy and loss of epoch #322: 0.9894, 48.1799\n",
      "Saved model by train loss 48.1798581942706\n",
      "Train loss and acc of batch 0: 47.85462951660156, 1.0\n",
      "Train loss and acc of batch 1: 47.85462188720703, 1.0\n",
      "Train loss and acc of batch 2: 48.14045715332031, 0.984375\n",
      "Train loss and acc of batch 3: 48.07136535644531, 0.984375\n",
      "Train loss and acc of batch 4: 47.854591369628906, 1.0\n",
      "Train loss and acc of batch 5: 49.203514099121094, 0.96875\n",
      "Train loss and acc of batch 6: 48.35719299316406, 0.96875\n",
      "Train loss and acc of batch 7: 47.85456085205078, 1.0\n",
      "Train loss and acc of batch 8: 48.45025634765625, 0.984375\n",
      "Train loss and acc of batch 9: 48.140403747558594, 0.984375\n",
      "Train loss and acc of batch 10: 47.85453796386719, 1.0\n",
      "Train loss and acc of batch 11: 47.854530334472656, 1.0\n",
      "Train loss and acc of batch 12: 48.60774612426758, 0.984375\n",
      "Train loss and acc of batch 13: 48.07128143310547, 0.984375\n",
      "Train loss and acc of batch 14: 48.07127380371094, 0.984375\n",
      "Train loss and acc of batch 15: 48.4501953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.45018768310547, 0.984375\n",
      "Train loss and acc of batch 17: 48.607704162597656, 0.984375\n",
      "Train loss and acc of batch 18: 48.736019134521484, 0.96875\n",
      "Train loss and acc of batch 19: 47.854461669921875, 1.0\n",
      "Train loss and acc of batch 20: 47.85445022583008, 1.0\n",
      "Train loss and acc of batch 21: 48.45014190673828, 0.984375\n",
      "Train loss and acc of batch 22: 48.45013427734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.85442352294922, 1.0\n",
      "Train loss and acc of batch 24: 48.45011901855469, 0.984375\n",
      "Train loss and acc of batch 25: 47.85441207885742, 1.0\n",
      "Train loss and acc of batch 26: 47.854400634765625, 1.0\n",
      "Train loss and acc of batch 27: 47.85438919067383, 1.0\n",
      "Train loss and acc of batch 28: 47.8543815612793, 1.0\n",
      "Train loss and acc of batch 29: 48.4500732421875, 0.984375\n",
      "Train loss and acc of batch 30: 47.85436248779297, 1.0\n",
      "Train loss and acc of batch 31: 48.07111358642578, 0.984375\n",
      "Train loss and acc of batch 32: 47.85434341430664, 1.0\n",
      "Train loss and acc of batch 33: 47.85433578491211, 1.0\n",
      "Train loss and acc of batch 34: 48.45002746582031, 0.984375\n",
      "Train loss and acc of batch 35: 48.287841796875, 0.96875\n",
      "Train loss and acc of batch 36: 47.854312896728516, 1.0\n",
      "Train loss and acc of batch 37: 48.607521057128906, 0.984375\n",
      "Train loss and acc of batch 38: 49.203216552734375, 0.96875\n",
      "Train loss and acc of batch 39: 48.071044921875, 0.984375\n",
      "Train loss and acc of batch 40: 47.85427474975586, 1.0\n",
      "Train loss and acc of batch 41: 49.203189849853516, 0.96875\n",
      "Train loss and acc of batch 42: 47.8542594909668, 1.0\n",
      "Train loss and acc of batch 43: 48.449951171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.8542366027832, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 45: 48.449928283691406, 0.984375\n",
      "Train loss and acc of batch 46: 48.14007568359375, 0.984375\n",
      "Train loss and acc of batch 47: 47.854209899902344, 1.0\n",
      "Train loss and acc of batch 48: 47.85420227050781, 1.0\n",
      "Train loss and acc of batch 49: 47.854190826416016, 1.0\n",
      "Train loss and acc of batch 50: 48.44989013671875, 0.984375\n",
      "Train loss and acc of batch 51: 49.203102111816406, 0.96875\n",
      "Train loss and acc of batch 52: 49.11000442504883, 0.953125\n",
      "Train loss and acc of batch 53: 47.85416030883789, 1.0\n",
      "Train loss and acc of batch 54: 48.07091522216797, 0.984375\n",
      "Train loss and acc of batch 55: 47.85414123535156, 1.0\n",
      "Train loss and acc of batch 56: 47.85413360595703, 1.0\n",
      "Train loss and acc of batch 57: 48.44982147216797, 0.984375\n",
      "Train loss and acc of batch 58: 47.85411071777344, 1.0\n",
      "Train loss and acc of batch 59: 47.85409927368164, 1.0\n",
      "Train loss and acc of batch 60: 47.85409164428711, 1.0\n",
      "Train loss and acc of batch 61: 47.854087829589844, 1.0\n",
      "Train loss and acc of batch 62: 47.85407638549805, 1.0\n",
      "Train loss and acc of batch 63: 49.045467376708984, 0.96875\n",
      "Train loss and acc of batch 64: 48.070823669433594, 0.984375\n",
      "Train loss and acc of batch 65: 47.85404968261719, 1.0\n",
      "Train loss and acc of batch 66: 47.85403823852539, 1.0\n",
      "Train loss and acc of batch 67: 48.66649627685547, 0.96875\n",
      "Train loss and acc of batch 68: 48.44972229003906, 0.984375\n",
      "Train loss and acc of batch 69: 48.070777893066406, 0.984375\n",
      "Train loss and acc of batch 70: 47.85401153564453, 1.0\n",
      "Training accuracy and loss of epoch #323: 0.9894, 48.1792\n",
      "Saved model by train loss 48.17922699619347\n",
      "Train loss and acc of batch 0: 47.854000091552734, 1.0\n",
      "Train loss and acc of batch 1: 47.85398483276367, 1.0\n",
      "Train loss and acc of batch 2: 48.13983154296875, 0.984375\n",
      "Train loss and acc of batch 3: 48.07073211669922, 0.984375\n",
      "Train loss and acc of batch 4: 47.85396194458008, 1.0\n",
      "Train loss and acc of batch 5: 49.20287322998047, 0.96875\n",
      "Train loss and acc of batch 6: 48.3565559387207, 0.96875\n",
      "Train loss and acc of batch 7: 47.85393524169922, 1.0\n",
      "Train loss and acc of batch 8: 48.44963073730469, 0.984375\n",
      "Train loss and acc of batch 9: 48.1397705078125, 0.984375\n",
      "Train loss and acc of batch 10: 47.85390853881836, 1.0\n",
      "Train loss and acc of batch 11: 47.85389709472656, 1.0\n",
      "Train loss and acc of batch 12: 48.607112884521484, 0.984375\n",
      "Train loss and acc of batch 13: 48.070648193359375, 0.984375\n",
      "Train loss and acc of batch 14: 48.070640563964844, 0.984375\n",
      "Train loss and acc of batch 15: 48.449562072753906, 0.984375\n",
      "Train loss and acc of batch 16: 48.449546813964844, 0.984375\n",
      "Train loss and acc of batch 17: 48.60707092285156, 0.984375\n",
      "Train loss and acc of batch 18: 48.735389709472656, 0.96875\n",
      "Train loss and acc of batch 19: 47.85383224487305, 1.0\n",
      "Train loss and acc of batch 20: 47.85381317138672, 1.0\n",
      "Train loss and acc of batch 21: 48.44951629638672, 0.984375\n",
      "Train loss and acc of batch 22: 48.449501037597656, 0.984375\n",
      "Train loss and acc of batch 23: 47.85379409790039, 1.0\n",
      "Train loss and acc of batch 24: 48.449485778808594, 0.984375\n",
      "Train loss and acc of batch 25: 47.8537712097168, 1.0\n",
      "Train loss and acc of batch 26: 47.853763580322266, 1.0\n",
      "Train loss and acc of batch 27: 47.853759765625, 1.0\n",
      "Train loss and acc of batch 28: 47.8537483215332, 1.0\n",
      "Train loss and acc of batch 29: 48.449440002441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.853729248046875, 1.0\n",
      "Train loss and acc of batch 31: 48.07048797607422, 0.984375\n",
      "Train loss and acc of batch 32: 47.85371017456055, 1.0\n",
      "Train loss and acc of batch 33: 47.853702545166016, 1.0\n",
      "Train loss and acc of batch 34: 48.44939422607422, 0.984375\n",
      "Train loss and acc of batch 35: 48.28721618652344, 0.96875\n",
      "Train loss and acc of batch 36: 47.853675842285156, 1.0\n",
      "Train loss and acc of batch 37: 48.60689163208008, 0.984375\n",
      "Train loss and acc of batch 38: 49.20258331298828, 0.96875\n",
      "Train loss and acc of batch 39: 48.070411682128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.8536376953125, 1.0\n",
      "Train loss and acc of batch 41: 49.20256423950195, 0.96875\n",
      "Train loss and acc of batch 42: 47.85362243652344, 1.0\n",
      "Train loss and acc of batch 43: 48.449317932128906, 0.984375\n",
      "Train loss and acc of batch 44: 47.853607177734375, 1.0\n",
      "Train loss and acc of batch 45: 48.44929504394531, 0.984375\n",
      "Train loss and acc of batch 46: 48.139442443847656, 0.984375\n",
      "Train loss and acc of batch 47: 47.85358428955078, 1.0\n",
      "Train loss and acc of batch 48: 47.85356903076172, 1.0\n",
      "Train loss and acc of batch 49: 47.85356140136719, 1.0\n",
      "Train loss and acc of batch 50: 48.449256896972656, 0.984375\n",
      "Train loss and acc of batch 51: 49.20246887207031, 0.96875\n",
      "Train loss and acc of batch 52: 49.109375, 0.953125\n",
      "Train loss and acc of batch 53: 47.85352325439453, 1.0\n",
      "Train loss and acc of batch 54: 48.070281982421875, 0.984375\n",
      "Train loss and acc of batch 55: 47.85350799560547, 1.0\n",
      "Train loss and acc of batch 56: 47.85350036621094, 1.0\n",
      "Train loss and acc of batch 57: 48.449188232421875, 0.984375\n",
      "Train loss and acc of batch 58: 47.85348129272461, 1.0\n",
      "Train loss and acc of batch 59: 47.85347366333008, 1.0\n",
      "Train loss and acc of batch 60: 47.85346221923828, 1.0\n",
      "Train loss and acc of batch 61: 47.853450775146484, 1.0\n",
      "Train loss and acc of batch 62: 47.85344314575195, 1.0\n",
      "Train loss and acc of batch 63: 49.044837951660156, 0.96875\n",
      "Train loss and acc of batch 64: 48.0701904296875, 0.984375\n",
      "Train loss and acc of batch 65: 47.853416442871094, 1.0\n",
      "Train loss and acc of batch 66: 47.85341262817383, 1.0\n",
      "Train loss and acc of batch 67: 48.665863037109375, 0.96875\n",
      "Train loss and acc of batch 68: 48.44908905029297, 0.984375\n",
      "Train loss and acc of batch 69: 48.07014465332031, 0.984375\n",
      "Train loss and acc of batch 70: 47.85337448120117, 1.0\n",
      "Training accuracy and loss of epoch #324: 0.9894, 48.1786\n",
      "Saved model by train loss 48.17859472355372\n",
      "Train loss and acc of batch 0: 47.853363037109375, 1.0\n",
      "Train loss and acc of batch 1: 47.85335922241211, 1.0\n",
      "Train loss and acc of batch 2: 48.139198303222656, 0.984375\n",
      "Train loss and acc of batch 3: 48.070106506347656, 0.984375\n",
      "Train loss and acc of batch 4: 47.85333251953125, 1.0\n",
      "Train loss and acc of batch 5: 49.202247619628906, 0.96875\n",
      "Train loss and acc of batch 6: 48.355926513671875, 0.96875\n",
      "Train loss and acc of batch 7: 47.853302001953125, 1.0\n",
      "Train loss and acc of batch 8: 48.448997497558594, 0.984375\n",
      "Train loss and acc of batch 9: 48.13914489746094, 0.984375\n",
      "Train loss and acc of batch 10: 47.853275299072266, 1.0\n",
      "Train loss and acc of batch 11: 47.85326385498047, 1.0\n",
      "Train loss and acc of batch 12: 48.606483459472656, 0.984375\n",
      "Train loss and acc of batch 13: 48.07001495361328, 0.984375\n",
      "Train loss and acc of batch 14: 48.07000732421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.448936462402344, 0.984375\n",
      "Train loss and acc of batch 16: 48.44892120361328, 0.984375\n",
      "Train loss and acc of batch 17: 48.606441497802734, 0.984375\n",
      "Train loss and acc of batch 18: 48.73476028442383, 0.96875\n",
      "Train loss and acc of batch 19: 47.85319137573242, 1.0\n",
      "Train loss and acc of batch 20: 47.853187561035156, 1.0\n",
      "Train loss and acc of batch 21: 48.448875427246094, 0.984375\n",
      "Train loss and acc of batch 22: 48.44886779785156, 0.984375\n",
      "Train loss and acc of batch 23: 47.85316467285156, 1.0\n",
      "Train loss and acc of batch 24: 48.4488525390625, 0.984375\n",
      "Train loss and acc of batch 25: 47.85314178466797, 1.0\n",
      "Train loss and acc of batch 26: 47.8531379699707, 1.0\n",
      "Train loss and acc of batch 27: 47.85312271118164, 1.0\n",
      "Train loss and acc of batch 28: 47.85311508178711, 1.0\n",
      "Train loss and acc of batch 29: 48.44880676269531, 0.984375\n",
      "Train loss and acc of batch 30: 47.85309600830078, 1.0\n",
      "Train loss and acc of batch 31: 48.069854736328125, 0.984375\n",
      "Train loss and acc of batch 32: 47.853084564208984, 1.0\n",
      "Train loss and acc of batch 33: 47.85306930541992, 1.0\n",
      "Train loss and acc of batch 34: 48.448768615722656, 0.984375\n",
      "Train loss and acc of batch 35: 48.28657913208008, 0.96875\n",
      "Train loss and acc of batch 36: 47.85304641723633, 1.0\n",
      "Train loss and acc of batch 37: 48.60626220703125, 0.984375\n",
      "Train loss and acc of batch 38: 49.20195007324219, 0.96875\n",
      "Train loss and acc of batch 39: 48.069786071777344, 0.984375\n",
      "Train loss and acc of batch 40: 47.85301208496094, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.201927185058594, 0.96875\n",
      "Train loss and acc of batch 42: 47.852989196777344, 1.0\n",
      "Train loss and acc of batch 43: 48.44868469238281, 0.984375\n",
      "Train loss and acc of batch 44: 47.85297393798828, 1.0\n",
      "Train loss and acc of batch 45: 48.44866943359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.138816833496094, 0.984375\n",
      "Train loss and acc of batch 47: 47.852943420410156, 1.0\n",
      "Train loss and acc of batch 48: 47.85293960571289, 1.0\n",
      "Train loss and acc of batch 49: 47.85293197631836, 1.0\n",
      "Train loss and acc of batch 50: 48.44862365722656, 0.984375\n",
      "Train loss and acc of batch 51: 49.20183563232422, 0.96875\n",
      "Train loss and acc of batch 52: 49.108741760253906, 0.953125\n",
      "Train loss and acc of batch 53: 47.8528938293457, 1.0\n",
      "Train loss and acc of batch 54: 48.06964874267578, 0.984375\n",
      "Train loss and acc of batch 55: 47.852874755859375, 1.0\n",
      "Train loss and acc of batch 56: 47.85286331176758, 1.0\n",
      "Train loss and acc of batch 57: 48.44856262207031, 0.984375\n",
      "Train loss and acc of batch 58: 47.85285186767578, 1.0\n",
      "Train loss and acc of batch 59: 47.85284423828125, 1.0\n",
      "Train loss and acc of batch 60: 47.85283660888672, 1.0\n",
      "Train loss and acc of batch 61: 47.85282516479492, 1.0\n",
      "Train loss and acc of batch 62: 47.852813720703125, 1.0\n",
      "Train loss and acc of batch 63: 49.04420471191406, 0.96875\n",
      "Train loss and acc of batch 64: 48.069557189941406, 0.984375\n",
      "Train loss and acc of batch 65: 47.85279083251953, 1.0\n",
      "Train loss and acc of batch 66: 47.852779388427734, 1.0\n",
      "Train loss and acc of batch 67: 48.66523742675781, 0.96875\n",
      "Train loss and acc of batch 68: 48.448463439941406, 0.984375\n",
      "Train loss and acc of batch 69: 48.06951904296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.85274124145508, 1.0\n",
      "Training accuracy and loss of epoch #325: 0.9894, 48.1780\n",
      "Saved model by train loss 48.177963955301635\n",
      "Train loss and acc of batch 0: 47.85273361206055, 1.0\n",
      "Train loss and acc of batch 1: 47.85272216796875, 1.0\n",
      "Train loss and acc of batch 2: 48.138572692871094, 0.984375\n",
      "Train loss and acc of batch 3: 48.06947326660156, 0.984375\n",
      "Train loss and acc of batch 4: 47.85269546508789, 1.0\n",
      "Train loss and acc of batch 5: 49.20161437988281, 0.96875\n",
      "Train loss and acc of batch 6: 48.35529708862305, 0.96875\n",
      "Train loss and acc of batch 7: 47.85266876220703, 1.0\n",
      "Train loss and acc of batch 8: 48.4483642578125, 0.984375\n",
      "Train loss and acc of batch 9: 48.13850402832031, 0.984375\n",
      "Train loss and acc of batch 10: 47.85264587402344, 1.0\n",
      "Train loss and acc of batch 11: 47.852638244628906, 1.0\n",
      "Train loss and acc of batch 12: 48.60585403442383, 0.984375\n",
      "Train loss and acc of batch 13: 48.06938171386719, 0.984375\n",
      "Train loss and acc of batch 14: 48.069374084472656, 0.984375\n",
      "Train loss and acc of batch 15: 48.44830322265625, 0.984375\n",
      "Train loss and acc of batch 16: 48.44829559326172, 0.984375\n",
      "Train loss and acc of batch 17: 48.60580825805664, 0.984375\n",
      "Train loss and acc of batch 18: 48.734127044677734, 0.96875\n",
      "Train loss and acc of batch 19: 47.85256576538086, 1.0\n",
      "Train loss and acc of batch 20: 47.85255813598633, 1.0\n",
      "Train loss and acc of batch 21: 48.44824981689453, 0.984375\n",
      "Train loss and acc of batch 22: 48.4482421875, 0.984375\n",
      "Train loss and acc of batch 23: 47.85253143310547, 1.0\n",
      "Train loss and acc of batch 24: 48.448219299316406, 0.984375\n",
      "Train loss and acc of batch 25: 47.852516174316406, 1.0\n",
      "Train loss and acc of batch 26: 47.85250473022461, 1.0\n",
      "Train loss and acc of batch 27: 47.85248947143555, 1.0\n",
      "Train loss and acc of batch 28: 47.85248565673828, 1.0\n",
      "Train loss and acc of batch 29: 48.44817352294922, 0.984375\n",
      "Train loss and acc of batch 30: 47.85246658325195, 1.0\n",
      "Train loss and acc of batch 31: 48.06922912597656, 0.984375\n",
      "Train loss and acc of batch 32: 47.852447509765625, 1.0\n",
      "Train loss and acc of batch 33: 47.85244369506836, 1.0\n",
      "Train loss and acc of batch 34: 48.44813537597656, 0.984375\n",
      "Train loss and acc of batch 35: 48.28594970703125, 0.96875\n",
      "Train loss and acc of batch 36: 47.852413177490234, 1.0\n",
      "Train loss and acc of batch 37: 48.60563278198242, 0.984375\n",
      "Train loss and acc of batch 38: 49.201316833496094, 0.96875\n",
      "Train loss and acc of batch 39: 48.06915283203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.85237503051758, 1.0\n",
      "Train loss and acc of batch 41: 49.2012939453125, 0.96875\n",
      "Train loss and acc of batch 42: 47.852359771728516, 1.0\n",
      "Train loss and acc of batch 43: 48.44805145263672, 0.984375\n",
      "Train loss and acc of batch 44: 47.85234069824219, 1.0\n",
      "Train loss and acc of batch 45: 48.448036193847656, 0.984375\n",
      "Train loss and acc of batch 46: 48.13817596435547, 0.984375\n",
      "Train loss and acc of batch 47: 47.852317810058594, 1.0\n",
      "Train loss and acc of batch 48: 47.85231018066406, 1.0\n",
      "Train loss and acc of batch 49: 47.852298736572266, 1.0\n",
      "Train loss and acc of batch 50: 48.44799041748047, 0.984375\n",
      "Train loss and acc of batch 51: 49.201202392578125, 0.96875\n",
      "Train loss and acc of batch 52: 49.10811233520508, 0.953125\n",
      "Train loss and acc of batch 53: 47.852264404296875, 1.0\n",
      "Train loss and acc of batch 54: 48.06902313232422, 0.984375\n",
      "Train loss and acc of batch 55: 47.85224533081055, 1.0\n",
      "Train loss and acc of batch 56: 47.85223388671875, 1.0\n",
      "Train loss and acc of batch 57: 48.44792175292969, 0.984375\n",
      "Train loss and acc of batch 58: 47.85221862792969, 1.0\n",
      "Train loss and acc of batch 59: 47.852210998535156, 1.0\n",
      "Train loss and acc of batch 60: 47.85219955444336, 1.0\n",
      "Train loss and acc of batch 61: 47.85219192504883, 1.0\n",
      "Train loss and acc of batch 62: 47.85218811035156, 1.0\n",
      "Train loss and acc of batch 63: 49.043575286865234, 0.96875\n",
      "Train loss and acc of batch 64: 48.068931579589844, 0.984375\n",
      "Train loss and acc of batch 65: 47.85215377807617, 1.0\n",
      "Train loss and acc of batch 66: 47.852149963378906, 1.0\n",
      "Train loss and acc of batch 67: 48.664608001708984, 0.96875\n",
      "Train loss and acc of batch 68: 48.44783020019531, 0.984375\n",
      "Train loss and acc of batch 69: 48.068885803222656, 0.984375\n",
      "Train loss and acc of batch 70: 47.85211944580078, 1.0\n",
      "Training accuracy and loss of epoch #326: 0.9894, 48.1773\n",
      "Saved model by train loss 48.17733259604011\n",
      "Train loss and acc of batch 0: 47.85210037231445, 1.0\n",
      "Train loss and acc of batch 1: 47.85210037231445, 1.0\n",
      "Train loss and acc of batch 2: 48.13793182373047, 0.984375\n",
      "Train loss and acc of batch 3: 48.06884002685547, 0.984375\n",
      "Train loss and acc of batch 4: 47.85206985473633, 1.0\n",
      "Train loss and acc of batch 5: 49.20098114013672, 0.96875\n",
      "Train loss and acc of batch 6: 48.35466384887695, 0.96875\n",
      "Train loss and acc of batch 7: 47.8520393371582, 1.0\n",
      "Train loss and acc of batch 8: 48.447731018066406, 0.984375\n",
      "Train loss and acc of batch 9: 48.13787841796875, 0.984375\n",
      "Train loss and acc of batch 10: 47.85201644897461, 1.0\n",
      "Train loss and acc of batch 11: 47.85200119018555, 1.0\n",
      "Train loss and acc of batch 12: 48.605220794677734, 0.984375\n",
      "Train loss and acc of batch 13: 48.068756103515625, 0.984375\n",
      "Train loss and acc of batch 14: 48.06874084472656, 0.984375\n",
      "Train loss and acc of batch 15: 48.447669982910156, 0.984375\n",
      "Train loss and acc of batch 16: 48.447669982910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.60517120361328, 0.984375\n",
      "Train loss and acc of batch 18: 48.733497619628906, 0.96875\n",
      "Train loss and acc of batch 19: 47.851932525634766, 1.0\n",
      "Train loss and acc of batch 20: 47.851924896240234, 1.0\n",
      "Train loss and acc of batch 21: 48.44761657714844, 0.984375\n",
      "Train loss and acc of batch 22: 48.447608947753906, 0.984375\n",
      "Train loss and acc of batch 23: 47.851898193359375, 1.0\n",
      "Train loss and acc of batch 24: 48.447593688964844, 0.984375\n",
      "Train loss and acc of batch 25: 47.85187530517578, 1.0\n",
      "Train loss and acc of batch 26: 47.851871490478516, 1.0\n",
      "Train loss and acc of batch 27: 47.85186767578125, 1.0\n",
      "Train loss and acc of batch 28: 47.85185623168945, 1.0\n",
      "Train loss and acc of batch 29: 48.447547912597656, 0.984375\n",
      "Train loss and acc of batch 30: 47.85184097290039, 1.0\n",
      "Train loss and acc of batch 31: 48.06858825683594, 0.984375\n",
      "Train loss and acc of batch 32: 47.85182189941406, 1.0\n",
      "Train loss and acc of batch 33: 47.851806640625, 1.0\n",
      "Train loss and acc of batch 34: 48.44750213623047, 0.984375\n",
      "Train loss and acc of batch 35: 48.28532028198242, 0.96875\n",
      "Train loss and acc of batch 36: 47.851783752441406, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 37: 48.60499572753906, 0.984375\n",
      "Train loss and acc of batch 38: 49.20069122314453, 0.96875\n",
      "Train loss and acc of batch 39: 48.068519592285156, 0.984375\n",
      "Train loss and acc of batch 40: 47.85174560546875, 1.0\n",
      "Train loss and acc of batch 41: 49.20066452026367, 0.96875\n",
      "Train loss and acc of batch 42: 47.85173034667969, 1.0\n",
      "Train loss and acc of batch 43: 48.447425842285156, 0.984375\n",
      "Train loss and acc of batch 44: 47.85171890258789, 1.0\n",
      "Train loss and acc of batch 45: 48.44740295410156, 0.984375\n",
      "Train loss and acc of batch 46: 48.137542724609375, 0.984375\n",
      "Train loss and acc of batch 47: 47.8516845703125, 1.0\n",
      "Train loss and acc of batch 48: 47.8516731262207, 1.0\n",
      "Train loss and acc of batch 49: 47.85166931152344, 1.0\n",
      "Train loss and acc of batch 50: 48.447357177734375, 0.984375\n",
      "Train loss and acc of batch 51: 49.20057678222656, 0.96875\n",
      "Train loss and acc of batch 52: 49.107486724853516, 0.953125\n",
      "Train loss and acc of batch 53: 47.851627349853516, 1.0\n",
      "Train loss and acc of batch 54: 48.068382263183594, 0.984375\n",
      "Train loss and acc of batch 55: 47.85161590576172, 1.0\n",
      "Train loss and acc of batch 56: 47.851600646972656, 1.0\n",
      "Train loss and acc of batch 57: 48.447303771972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.85158920288086, 1.0\n",
      "Train loss and acc of batch 59: 47.85157775878906, 1.0\n",
      "Train loss and acc of batch 60: 47.85157012939453, 1.0\n",
      "Train loss and acc of batch 61: 47.851558685302734, 1.0\n",
      "Train loss and acc of batch 62: 47.85154724121094, 1.0\n",
      "Train loss and acc of batch 63: 49.042945861816406, 0.96875\n",
      "Train loss and acc of batch 64: 48.06829833984375, 0.984375\n",
      "Train loss and acc of batch 65: 47.85152816772461, 1.0\n",
      "Train loss and acc of batch 66: 47.85152053833008, 1.0\n",
      "Train loss and acc of batch 67: 48.663970947265625, 0.96875\n",
      "Train loss and acc of batch 68: 48.44719696044922, 0.984375\n",
      "Train loss and acc of batch 69: 48.06825256347656, 0.984375\n",
      "Train loss and acc of batch 70: 47.851478576660156, 1.0\n",
      "Training accuracy and loss of epoch #327: 0.9894, 48.1767\n",
      "Saved model by train loss 48.176701236778584\n",
      "Train loss and acc of batch 0: 47.85147476196289, 1.0\n",
      "Train loss and acc of batch 1: 47.851463317871094, 1.0\n",
      "Train loss and acc of batch 2: 48.137306213378906, 0.984375\n",
      "Train loss and acc of batch 3: 48.068214416503906, 0.984375\n",
      "Train loss and acc of batch 4: 47.85143280029297, 1.0\n",
      "Train loss and acc of batch 5: 49.200347900390625, 0.96875\n",
      "Train loss and acc of batch 6: 48.35403823852539, 0.96875\n",
      "Train loss and acc of batch 7: 47.851409912109375, 1.0\n",
      "Train loss and acc of batch 8: 48.447105407714844, 0.984375\n",
      "Train loss and acc of batch 9: 48.137245178222656, 0.984375\n",
      "Train loss and acc of batch 10: 47.85137939453125, 1.0\n",
      "Train loss and acc of batch 11: 47.851375579833984, 1.0\n",
      "Train loss and acc of batch 12: 48.604591369628906, 0.984375\n",
      "Train loss and acc of batch 13: 48.06812286376953, 0.984375\n",
      "Train loss and acc of batch 14: 48.068115234375, 0.984375\n",
      "Train loss and acc of batch 15: 48.447044372558594, 0.984375\n",
      "Train loss and acc of batch 16: 48.44702911376953, 0.984375\n",
      "Train loss and acc of batch 17: 48.60454559326172, 0.984375\n",
      "Train loss and acc of batch 18: 48.73286056518555, 0.96875\n",
      "Train loss and acc of batch 19: 47.85129928588867, 1.0\n",
      "Train loss and acc of batch 20: 47.85129165649414, 1.0\n",
      "Train loss and acc of batch 21: 48.446983337402344, 0.984375\n",
      "Train loss and acc of batch 22: 48.44697570800781, 0.984375\n",
      "Train loss and acc of batch 23: 47.85126876831055, 1.0\n",
      "Train loss and acc of batch 24: 48.44696044921875, 0.984375\n",
      "Train loss and acc of batch 25: 47.85124969482422, 1.0\n",
      "Train loss and acc of batch 26: 47.85123825073242, 1.0\n",
      "Train loss and acc of batch 27: 47.85123062133789, 1.0\n",
      "Train loss and acc of batch 28: 47.851219177246094, 1.0\n",
      "Train loss and acc of batch 29: 48.44691467285156, 0.984375\n",
      "Train loss and acc of batch 30: 47.851200103759766, 1.0\n",
      "Train loss and acc of batch 31: 48.067962646484375, 0.984375\n",
      "Train loss and acc of batch 32: 47.851192474365234, 1.0\n",
      "Train loss and acc of batch 33: 47.851173400878906, 1.0\n",
      "Train loss and acc of batch 34: 48.446868896484375, 0.984375\n",
      "Train loss and acc of batch 35: 48.28468704223633, 0.96875\n",
      "Train loss and acc of batch 36: 47.85115051269531, 1.0\n",
      "Train loss and acc of batch 37: 48.604366302490234, 0.984375\n",
      "Train loss and acc of batch 38: 49.20005798339844, 0.96875\n",
      "Train loss and acc of batch 39: 48.06788635253906, 0.984375\n",
      "Train loss and acc of batch 40: 47.85111618041992, 1.0\n",
      "Train loss and acc of batch 41: 49.20003128051758, 0.96875\n",
      "Train loss and acc of batch 42: 47.851097106933594, 1.0\n",
      "Train loss and acc of batch 43: 48.44679260253906, 0.984375\n",
      "Train loss and acc of batch 44: 47.851078033447266, 1.0\n",
      "Train loss and acc of batch 45: 48.44677734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.13691711425781, 0.984375\n",
      "Train loss and acc of batch 47: 47.85104751586914, 1.0\n",
      "Train loss and acc of batch 48: 47.85104751586914, 1.0\n",
      "Train loss and acc of batch 49: 47.85103225708008, 1.0\n",
      "Train loss and acc of batch 50: 48.44673156738281, 0.984375\n",
      "Train loss and acc of batch 51: 49.19994354248047, 0.96875\n",
      "Train loss and acc of batch 52: 49.106849670410156, 0.953125\n",
      "Train loss and acc of batch 53: 47.85100173950195, 1.0\n",
      "Train loss and acc of batch 54: 48.06775665283203, 0.984375\n",
      "Train loss and acc of batch 55: 47.85097885131836, 1.0\n",
      "Train loss and acc of batch 56: 47.850975036621094, 1.0\n",
      "Train loss and acc of batch 57: 48.44667053222656, 0.984375\n",
      "Train loss and acc of batch 58: 47.850955963134766, 1.0\n",
      "Train loss and acc of batch 59: 47.850948333740234, 1.0\n",
      "Train loss and acc of batch 60: 47.8509407043457, 1.0\n",
      "Train loss and acc of batch 61: 47.85092544555664, 1.0\n",
      "Train loss and acc of batch 62: 47.850921630859375, 1.0\n",
      "Train loss and acc of batch 63: 49.04230880737305, 0.96875\n",
      "Train loss and acc of batch 64: 48.067665100097656, 0.984375\n",
      "Train loss and acc of batch 65: 47.85089111328125, 1.0\n",
      "Train loss and acc of batch 66: 47.85088348388672, 1.0\n",
      "Train loss and acc of batch 67: 48.6633415222168, 0.96875\n",
      "Train loss and acc of batch 68: 48.446571350097656, 0.984375\n",
      "Train loss and acc of batch 69: 48.06761932373047, 0.984375\n",
      "Train loss and acc of batch 70: 47.850852966308594, 1.0\n",
      "Training accuracy and loss of epoch #328: 0.9894, 48.1761\n",
      "Saved model by train loss 48.17606971633266\n",
      "Train loss and acc of batch 0: 47.85083770751953, 1.0\n",
      "Train loss and acc of batch 1: 47.850830078125, 1.0\n",
      "Train loss and acc of batch 2: 48.13667297363281, 0.984375\n",
      "Train loss and acc of batch 3: 48.06758117675781, 0.984375\n",
      "Train loss and acc of batch 4: 47.85080337524414, 1.0\n",
      "Train loss and acc of batch 5: 49.19972229003906, 0.96875\n",
      "Train loss and acc of batch 6: 48.35340118408203, 0.96875\n",
      "Train loss and acc of batch 7: 47.85077667236328, 1.0\n",
      "Train loss and acc of batch 8: 48.44647216796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.13661193847656, 0.984375\n",
      "Train loss and acc of batch 10: 47.85075378417969, 1.0\n",
      "Train loss and acc of batch 11: 47.85074234008789, 1.0\n",
      "Train loss and acc of batch 12: 48.60395812988281, 0.984375\n",
      "Train loss and acc of batch 13: 48.067481994628906, 0.984375\n",
      "Train loss and acc of batch 14: 48.067481994628906, 0.984375\n",
      "Train loss and acc of batch 15: 48.4464111328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.44640350341797, 0.984375\n",
      "Train loss and acc of batch 17: 48.60391616821289, 0.984375\n",
      "Train loss and acc of batch 18: 48.732234954833984, 0.96875\n",
      "Train loss and acc of batch 19: 47.85066604614258, 1.0\n",
      "Train loss and acc of batch 20: 47.85066604614258, 1.0\n",
      "Train loss and acc of batch 21: 48.44635009765625, 0.984375\n",
      "Train loss and acc of batch 22: 48.44635009765625, 0.984375\n",
      "Train loss and acc of batch 23: 47.85063171386719, 1.0\n",
      "Train loss and acc of batch 24: 48.446327209472656, 0.984375\n",
      "Train loss and acc of batch 25: 47.85062026977539, 1.0\n",
      "Train loss and acc of batch 26: 47.85061264038086, 1.0\n",
      "Train loss and acc of batch 27: 47.85060119628906, 1.0\n",
      "Train loss and acc of batch 28: 47.850589752197266, 1.0\n",
      "Train loss and acc of batch 29: 48.44628143310547, 0.984375\n",
      "Train loss and acc of batch 30: 47.8505744934082, 1.0\n",
      "Train loss and acc of batch 31: 48.06732940673828, 0.984375\n",
      "Train loss and acc of batch 32: 47.85055923461914, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.850547790527344, 1.0\n",
      "Train loss and acc of batch 34: 48.44623565673828, 0.984375\n",
      "Train loss and acc of batch 35: 48.2840576171875, 0.96875\n",
      "Train loss and acc of batch 36: 47.850521087646484, 1.0\n",
      "Train loss and acc of batch 37: 48.60373306274414, 0.984375\n",
      "Train loss and acc of batch 38: 49.199424743652344, 0.96875\n",
      "Train loss and acc of batch 39: 48.0672607421875, 0.984375\n",
      "Train loss and acc of batch 40: 47.850486755371094, 1.0\n",
      "Train loss and acc of batch 41: 49.199405670166016, 0.96875\n",
      "Train loss and acc of batch 42: 47.8504638671875, 1.0\n",
      "Train loss and acc of batch 43: 48.44615936279297, 0.984375\n",
      "Train loss and acc of batch 44: 47.8504524230957, 1.0\n",
      "Train loss and acc of batch 45: 48.446144104003906, 0.984375\n",
      "Train loss and acc of batch 46: 48.13628387451172, 0.984375\n",
      "Train loss and acc of batch 47: 47.85042190551758, 1.0\n",
      "Train loss and acc of batch 48: 47.85041046142578, 1.0\n",
      "Train loss and acc of batch 49: 47.85040283203125, 1.0\n",
      "Train loss and acc of batch 50: 48.44609832763672, 0.984375\n",
      "Train loss and acc of batch 51: 49.199310302734375, 0.96875\n",
      "Train loss and acc of batch 52: 49.10621643066406, 0.953125\n",
      "Train loss and acc of batch 53: 47.850372314453125, 1.0\n",
      "Train loss and acc of batch 54: 48.06712341308594, 0.984375\n",
      "Train loss and acc of batch 55: 47.8503532409668, 1.0\n",
      "Train loss and acc of batch 56: 47.850337982177734, 1.0\n",
      "Train loss and acc of batch 57: 48.44603729248047, 0.984375\n",
      "Train loss and acc of batch 58: 47.85032653808594, 1.0\n",
      "Train loss and acc of batch 59: 47.850318908691406, 1.0\n",
      "Train loss and acc of batch 60: 47.85030746459961, 1.0\n",
      "Train loss and acc of batch 61: 47.85029983520508, 1.0\n",
      "Train loss and acc of batch 62: 47.85029220581055, 1.0\n",
      "Train loss and acc of batch 63: 49.041683197021484, 0.96875\n",
      "Train loss and acc of batch 64: 48.06703186035156, 0.984375\n",
      "Train loss and acc of batch 65: 47.850257873535156, 1.0\n",
      "Train loss and acc of batch 66: 47.850250244140625, 1.0\n",
      "Train loss and acc of batch 67: 48.6627082824707, 0.96875\n",
      "Train loss and acc of batch 68: 48.44593811035156, 0.984375\n",
      "Train loss and acc of batch 69: 48.066993713378906, 0.984375\n",
      "Train loss and acc of batch 70: 47.850215911865234, 1.0\n",
      "Training accuracy and loss of epoch #329: 0.9894, 48.1754\n",
      "Saved model by train loss 48.17543857198366\n",
      "Train loss and acc of batch 0: 47.85020446777344, 1.0\n",
      "Train loss and acc of batch 1: 47.85020065307617, 1.0\n",
      "Train loss and acc of batch 2: 48.13604736328125, 0.984375\n",
      "Train loss and acc of batch 3: 48.06694793701172, 0.984375\n",
      "Train loss and acc of batch 4: 47.85017395019531, 1.0\n",
      "Train loss and acc of batch 5: 49.19908905029297, 0.96875\n",
      "Train loss and acc of batch 6: 48.3527717590332, 0.96875\n",
      "Train loss and acc of batch 7: 47.85014724731445, 1.0\n",
      "Train loss and acc of batch 8: 48.445831298828125, 0.984375\n",
      "Train loss and acc of batch 9: 48.13597869873047, 0.984375\n",
      "Train loss and acc of batch 10: 47.850120544433594, 1.0\n",
      "Train loss and acc of batch 11: 47.85011291503906, 1.0\n",
      "Train loss and acc of batch 12: 48.603328704833984, 0.984375\n",
      "Train loss and acc of batch 13: 48.066856384277344, 0.984375\n",
      "Train loss and acc of batch 14: 48.06684875488281, 0.984375\n",
      "Train loss and acc of batch 15: 48.445777893066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.445770263671875, 0.984375\n",
      "Train loss and acc of batch 17: 48.60327911376953, 0.984375\n",
      "Train loss and acc of batch 18: 48.73160171508789, 0.96875\n",
      "Train loss and acc of batch 19: 47.85004425048828, 1.0\n",
      "Train loss and acc of batch 20: 47.85002899169922, 1.0\n",
      "Train loss and acc of batch 21: 48.44572448730469, 0.984375\n",
      "Train loss and acc of batch 22: 48.445709228515625, 0.984375\n",
      "Train loss and acc of batch 23: 47.85000228881836, 1.0\n",
      "Train loss and acc of batch 24: 48.44569396972656, 0.984375\n",
      "Train loss and acc of batch 25: 47.8499870300293, 1.0\n",
      "Train loss and acc of batch 26: 47.849979400634766, 1.0\n",
      "Train loss and acc of batch 27: 47.849971771240234, 1.0\n",
      "Train loss and acc of batch 28: 47.84996032714844, 1.0\n",
      "Train loss and acc of batch 29: 48.445655822753906, 0.984375\n",
      "Train loss and acc of batch 30: 47.84994125366211, 1.0\n",
      "Train loss and acc of batch 31: 48.06669616699219, 0.984375\n",
      "Train loss and acc of batch 32: 47.84992218017578, 1.0\n",
      "Train loss and acc of batch 33: 47.849910736083984, 1.0\n",
      "Train loss and acc of batch 34: 48.44561004638672, 0.984375\n",
      "Train loss and acc of batch 35: 48.28342819213867, 0.96875\n",
      "Train loss and acc of batch 36: 47.849884033203125, 1.0\n",
      "Train loss and acc of batch 37: 48.60310363769531, 0.984375\n",
      "Train loss and acc of batch 38: 49.19879150390625, 0.96875\n",
      "Train loss and acc of batch 39: 48.066627502441406, 0.984375\n",
      "Train loss and acc of batch 40: 47.849853515625, 1.0\n",
      "Train loss and acc of batch 41: 49.198768615722656, 0.96875\n",
      "Train loss and acc of batch 42: 47.84983444213867, 1.0\n",
      "Train loss and acc of batch 43: 48.445526123046875, 0.984375\n",
      "Train loss and acc of batch 44: 47.84981918334961, 1.0\n",
      "Train loss and acc of batch 45: 48.44551086425781, 0.984375\n",
      "Train loss and acc of batch 46: 48.135650634765625, 0.984375\n",
      "Train loss and acc of batch 47: 47.84979248046875, 1.0\n",
      "Train loss and acc of batch 48: 47.84978485107422, 1.0\n",
      "Train loss and acc of batch 49: 47.849769592285156, 1.0\n",
      "Train loss and acc of batch 50: 48.445457458496094, 0.984375\n",
      "Train loss and acc of batch 51: 49.19867706298828, 0.96875\n",
      "Train loss and acc of batch 52: 49.10558319091797, 0.953125\n",
      "Train loss and acc of batch 53: 47.849735260009766, 1.0\n",
      "Train loss and acc of batch 54: 48.066497802734375, 0.984375\n",
      "Train loss and acc of batch 55: 47.8497200012207, 1.0\n",
      "Train loss and acc of batch 56: 47.84971237182617, 1.0\n",
      "Train loss and acc of batch 57: 48.445404052734375, 0.984375\n",
      "Train loss and acc of batch 58: 47.849693298339844, 1.0\n",
      "Train loss and acc of batch 59: 47.84968185424805, 1.0\n",
      "Train loss and acc of batch 60: 47.849674224853516, 1.0\n",
      "Train loss and acc of batch 61: 47.84966278076172, 1.0\n",
      "Train loss and acc of batch 62: 47.84966278076172, 1.0\n",
      "Train loss and acc of batch 63: 49.041053771972656, 0.96875\n",
      "Train loss and acc of batch 64: 48.06639862060547, 0.984375\n",
      "Train loss and acc of batch 65: 47.84962844848633, 1.0\n",
      "Train loss and acc of batch 66: 47.8496208190918, 1.0\n",
      "Train loss and acc of batch 67: 48.662078857421875, 0.96875\n",
      "Train loss and acc of batch 68: 48.44530487060547, 0.984375\n",
      "Train loss and acc of batch 69: 48.06636047363281, 0.984375\n",
      "Train loss and acc of batch 70: 47.849586486816406, 1.0\n",
      "Training accuracy and loss of epoch #330: 0.9894, 48.1748\n",
      "Saved model by train loss 48.17480656798457\n",
      "Train loss and acc of batch 0: 47.849578857421875, 1.0\n",
      "Train loss and acc of batch 1: 47.84956741333008, 1.0\n",
      "Train loss and acc of batch 2: 48.135414123535156, 0.984375\n",
      "Train loss and acc of batch 3: 48.066314697265625, 0.984375\n",
      "Train loss and acc of batch 4: 47.84954071044922, 1.0\n",
      "Train loss and acc of batch 5: 49.198463439941406, 0.96875\n",
      "Train loss and acc of batch 6: 48.35213851928711, 0.96875\n",
      "Train loss and acc of batch 7: 47.849510192871094, 1.0\n",
      "Train loss and acc of batch 8: 48.44520568847656, 0.984375\n",
      "Train loss and acc of batch 9: 48.135345458984375, 0.984375\n",
      "Train loss and acc of batch 10: 47.8494873046875, 1.0\n",
      "Train loss and acc of batch 11: 47.84947967529297, 1.0\n",
      "Train loss and acc of batch 12: 48.602691650390625, 0.984375\n",
      "Train loss and acc of batch 13: 48.06622314453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.06622314453125, 0.984375\n",
      "Train loss and acc of batch 15: 48.44514465332031, 0.984375\n",
      "Train loss and acc of batch 16: 48.44513702392578, 0.984375\n",
      "Train loss and acc of batch 17: 48.60264587402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.7309684753418, 0.96875\n",
      "Train loss and acc of batch 19: 47.84941101074219, 1.0\n",
      "Train loss and acc of batch 20: 47.849403381347656, 1.0\n",
      "Train loss and acc of batch 21: 48.445091247558594, 0.984375\n",
      "Train loss and acc of batch 22: 48.44508361816406, 0.984375\n",
      "Train loss and acc of batch 23: 47.849369049072266, 1.0\n",
      "Train loss and acc of batch 24: 48.44506072998047, 0.984375\n",
      "Train loss and acc of batch 25: 47.8493537902832, 1.0\n",
      "Train loss and acc of batch 26: 47.849342346191406, 1.0\n",
      "Train loss and acc of batch 27: 47.849334716796875, 1.0\n",
      "Train loss and acc of batch 28: 47.849334716796875, 1.0\n",
      "Train loss and acc of batch 29: 48.44501495361328, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 30: 47.849308013916016, 1.0\n",
      "Train loss and acc of batch 31: 48.066062927246094, 0.984375\n",
      "Train loss and acc of batch 32: 47.84928894042969, 1.0\n",
      "Train loss and acc of batch 33: 47.849281311035156, 1.0\n",
      "Train loss and acc of batch 34: 48.444969177246094, 0.984375\n",
      "Train loss and acc of batch 35: 48.28279113769531, 0.96875\n",
      "Train loss and acc of batch 36: 47.84925842285156, 1.0\n",
      "Train loss and acc of batch 37: 48.60246658325195, 0.984375\n",
      "Train loss and acc of batch 38: 49.19816589355469, 0.96875\n",
      "Train loss and acc of batch 39: 48.06599426269531, 0.984375\n",
      "Train loss and acc of batch 40: 47.84921646118164, 1.0\n",
      "Train loss and acc of batch 41: 49.19813919067383, 0.96875\n",
      "Train loss and acc of batch 42: 47.849205017089844, 1.0\n",
      "Train loss and acc of batch 43: 48.44490051269531, 0.984375\n",
      "Train loss and acc of batch 44: 47.849185943603516, 1.0\n",
      "Train loss and acc of batch 45: 48.44487762451172, 0.984375\n",
      "Train loss and acc of batch 46: 48.13501739501953, 0.984375\n",
      "Train loss and acc of batch 47: 47.849159240722656, 1.0\n",
      "Train loss and acc of batch 48: 47.849143981933594, 1.0\n",
      "Train loss and acc of batch 49: 47.84914016723633, 1.0\n",
      "Train loss and acc of batch 50: 48.44483184814453, 0.984375\n",
      "Train loss and acc of batch 51: 49.19805145263672, 0.96875\n",
      "Train loss and acc of batch 52: 49.104949951171875, 0.953125\n",
      "Train loss and acc of batch 53: 47.84910583496094, 1.0\n",
      "Train loss and acc of batch 54: 48.06585693359375, 0.984375\n",
      "Train loss and acc of batch 55: 47.84908676147461, 1.0\n",
      "Train loss and acc of batch 56: 47.849082946777344, 1.0\n",
      "Train loss and acc of batch 57: 48.44477081298828, 0.984375\n",
      "Train loss and acc of batch 58: 47.84906005859375, 1.0\n",
      "Train loss and acc of batch 59: 47.84904861450195, 1.0\n",
      "Train loss and acc of batch 60: 47.84904098510742, 1.0\n",
      "Train loss and acc of batch 61: 47.849037170410156, 1.0\n",
      "Train loss and acc of batch 62: 47.84902572631836, 1.0\n",
      "Train loss and acc of batch 63: 49.0404167175293, 0.96875\n",
      "Train loss and acc of batch 64: 48.065773010253906, 0.984375\n",
      "Train loss and acc of batch 65: 47.848995208740234, 1.0\n",
      "Train loss and acc of batch 66: 47.8489875793457, 1.0\n",
      "Train loss and acc of batch 67: 48.66144561767578, 0.96875\n",
      "Train loss and acc of batch 68: 48.444671630859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.06572723388672, 0.984375\n",
      "Train loss and acc of batch 70: 47.84895324707031, 1.0\n",
      "Training accuracy and loss of epoch #331: 0.9894, 48.1742\n",
      "Saved model by train loss 48.17417424161669\n",
      "Train loss and acc of batch 0: 47.84894561767578, 1.0\n",
      "Train loss and acc of batch 1: 47.84893798828125, 1.0\n",
      "Train loss and acc of batch 2: 48.13478088378906, 0.984375\n",
      "Train loss and acc of batch 3: 48.06568145751953, 0.984375\n",
      "Train loss and acc of batch 4: 47.84891128540039, 1.0\n",
      "Train loss and acc of batch 5: 49.19783020019531, 0.96875\n",
      "Train loss and acc of batch 6: 48.351505279541016, 0.96875\n",
      "Train loss and acc of batch 7: 47.84888458251953, 1.0\n",
      "Train loss and acc of batch 8: 48.44457244873047, 0.984375\n",
      "Train loss and acc of batch 9: 48.13471221923828, 0.984375\n",
      "Train loss and acc of batch 10: 47.848854064941406, 1.0\n",
      "Train loss and acc of batch 11: 47.84884262084961, 1.0\n",
      "Train loss and acc of batch 12: 48.6020622253418, 0.984375\n",
      "Train loss and acc of batch 13: 48.06559753417969, 0.984375\n",
      "Train loss and acc of batch 14: 48.065582275390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.44451141357422, 0.984375\n",
      "Train loss and acc of batch 16: 48.44450378417969, 0.984375\n",
      "Train loss and acc of batch 17: 48.60201644897461, 0.984375\n",
      "Train loss and acc of batch 18: 48.73033905029297, 0.96875\n",
      "Train loss and acc of batch 19: 47.848777770996094, 1.0\n",
      "Train loss and acc of batch 20: 47.84876251220703, 1.0\n",
      "Train loss and acc of batch 21: 48.44446563720703, 0.984375\n",
      "Train loss and acc of batch 22: 48.44445037841797, 0.984375\n",
      "Train loss and acc of batch 23: 47.8487434387207, 1.0\n",
      "Train loss and acc of batch 24: 48.444435119628906, 0.984375\n",
      "Train loss and acc of batch 25: 47.848716735839844, 1.0\n",
      "Train loss and acc of batch 26: 47.84871292114258, 1.0\n",
      "Train loss and acc of batch 27: 47.84870910644531, 1.0\n",
      "Train loss and acc of batch 28: 47.84869384765625, 1.0\n",
      "Train loss and acc of batch 29: 48.44438934326172, 0.984375\n",
      "Train loss and acc of batch 30: 47.84867858886719, 1.0\n",
      "Train loss and acc of batch 31: 48.0654296875, 0.984375\n",
      "Train loss and acc of batch 32: 47.84865951538086, 1.0\n",
      "Train loss and acc of batch 33: 47.84865188598633, 1.0\n",
      "Train loss and acc of batch 34: 48.44434356689453, 0.984375\n",
      "Train loss and acc of batch 35: 48.28216552734375, 0.96875\n",
      "Train loss and acc of batch 36: 47.84862518310547, 1.0\n",
      "Train loss and acc of batch 37: 48.601837158203125, 0.984375\n",
      "Train loss and acc of batch 38: 49.197532653808594, 0.96875\n",
      "Train loss and acc of batch 39: 48.06535339355469, 0.984375\n",
      "Train loss and acc of batch 40: 47.84859085083008, 1.0\n",
      "Train loss and acc of batch 41: 49.197509765625, 0.96875\n",
      "Train loss and acc of batch 42: 47.84857177734375, 1.0\n",
      "Train loss and acc of batch 43: 48.44425964355469, 0.984375\n",
      "Train loss and acc of batch 44: 47.84855270385742, 1.0\n",
      "Train loss and acc of batch 45: 48.444244384765625, 0.984375\n",
      "Train loss and acc of batch 46: 48.13439178466797, 0.984375\n",
      "Train loss and acc of batch 47: 47.84852600097656, 1.0\n",
      "Train loss and acc of batch 48: 47.84851837158203, 1.0\n",
      "Train loss and acc of batch 49: 47.8485107421875, 1.0\n",
      "Train loss and acc of batch 50: 48.44420623779297, 0.984375\n",
      "Train loss and acc of batch 51: 49.197418212890625, 0.96875\n",
      "Train loss and acc of batch 52: 49.10432815551758, 0.953125\n",
      "Train loss and acc of batch 53: 47.848472595214844, 1.0\n",
      "Train loss and acc of batch 54: 48.065223693847656, 0.984375\n",
      "Train loss and acc of batch 55: 47.848453521728516, 1.0\n",
      "Train loss and acc of batch 56: 47.84844207763672, 1.0\n",
      "Train loss and acc of batch 57: 48.44413757324219, 0.984375\n",
      "Train loss and acc of batch 58: 47.848426818847656, 1.0\n",
      "Train loss and acc of batch 59: 47.848419189453125, 1.0\n",
      "Train loss and acc of batch 60: 47.84840774536133, 1.0\n",
      "Train loss and acc of batch 61: 47.8484001159668, 1.0\n",
      "Train loss and acc of batch 62: 47.848388671875, 1.0\n",
      "Train loss and acc of batch 63: 49.03978729248047, 0.96875\n",
      "Train loss and acc of batch 64: 48.06513977050781, 0.984375\n",
      "Train loss and acc of batch 65: 47.848365783691406, 1.0\n",
      "Train loss and acc of batch 66: 47.84835433959961, 1.0\n",
      "Train loss and acc of batch 67: 48.66081237792969, 0.96875\n",
      "Train loss and acc of batch 68: 48.44403839111328, 0.984375\n",
      "Train loss and acc of batch 69: 48.065093994140625, 0.984375\n",
      "Train loss and acc of batch 70: 47.84832000732422, 1.0\n",
      "Training accuracy and loss of epoch #332: 0.9894, 48.1735\n",
      "Saved model by train loss 48.17354250625825\n",
      "Train loss and acc of batch 0: 47.84830856323242, 1.0\n",
      "Train loss and acc of batch 1: 47.848304748535156, 1.0\n",
      "Train loss and acc of batch 2: 48.13414764404297, 0.984375\n",
      "Train loss and acc of batch 3: 48.06504821777344, 0.984375\n",
      "Train loss and acc of batch 4: 47.84827423095703, 1.0\n",
      "Train loss and acc of batch 5: 49.19718933105469, 0.96875\n",
      "Train loss and acc of batch 6: 48.35087585449219, 0.96875\n",
      "Train loss and acc of batch 7: 47.84824752807617, 1.0\n",
      "Train loss and acc of batch 8: 48.443939208984375, 0.984375\n",
      "Train loss and acc of batch 9: 48.13408660888672, 0.984375\n",
      "Train loss and acc of batch 10: 47.84822463989258, 1.0\n",
      "Train loss and acc of batch 11: 47.848209381103516, 1.0\n",
      "Train loss and acc of batch 12: 48.6014289855957, 0.984375\n",
      "Train loss and acc of batch 13: 48.064964294433594, 0.984375\n",
      "Train loss and acc of batch 14: 48.06494903564453, 0.984375\n",
      "Train loss and acc of batch 15: 48.443878173828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.443870544433594, 0.984375\n",
      "Train loss and acc of batch 17: 48.601383209228516, 0.984375\n",
      "Train loss and acc of batch 18: 48.72970199584961, 0.96875\n",
      "Train loss and acc of batch 19: 47.848140716552734, 1.0\n",
      "Train loss and acc of batch 20: 47.8481330871582, 1.0\n",
      "Train loss and acc of batch 21: 48.443824768066406, 0.984375\n",
      "Train loss and acc of batch 22: 48.443817138671875, 0.984375\n",
      "Train loss and acc of batch 23: 47.84811019897461, 1.0\n",
      "Train loss and acc of batch 24: 48.44380187988281, 0.984375\n",
      "Train loss and acc of batch 25: 47.84809112548828, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 26: 47.848079681396484, 1.0\n",
      "Train loss and acc of batch 27: 47.84806442260742, 1.0\n",
      "Train loss and acc of batch 28: 47.84805679321289, 1.0\n",
      "Train loss and acc of batch 29: 48.443756103515625, 0.984375\n",
      "Train loss and acc of batch 30: 47.84804153442383, 1.0\n",
      "Train loss and acc of batch 31: 48.06480407714844, 0.984375\n",
      "Train loss and acc of batch 32: 47.848026275634766, 1.0\n",
      "Train loss and acc of batch 33: 47.84801483154297, 1.0\n",
      "Train loss and acc of batch 34: 48.44371032714844, 0.984375\n",
      "Train loss and acc of batch 35: 48.28152847290039, 0.96875\n",
      "Train loss and acc of batch 36: 47.847991943359375, 1.0\n",
      "Train loss and acc of batch 37: 48.60121154785156, 0.984375\n",
      "Train loss and acc of batch 38: 49.1968994140625, 0.96875\n",
      "Train loss and acc of batch 39: 48.064727783203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.84795379638672, 1.0\n",
      "Train loss and acc of batch 41: 49.19687271118164, 0.96875\n",
      "Train loss and acc of batch 42: 47.84793472290039, 1.0\n",
      "Train loss and acc of batch 43: 48.443626403808594, 0.984375\n",
      "Train loss and acc of batch 44: 47.84791564941406, 1.0\n",
      "Train loss and acc of batch 45: 48.44361114501953, 0.984375\n",
      "Train loss and acc of batch 46: 48.133750915527344, 0.984375\n",
      "Train loss and acc of batch 47: 47.8478889465332, 1.0\n",
      "Train loss and acc of batch 48: 47.84788513183594, 1.0\n",
      "Train loss and acc of batch 49: 47.847877502441406, 1.0\n",
      "Train loss and acc of batch 50: 48.443565368652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.19678497314453, 0.96875\n",
      "Train loss and acc of batch 52: 49.10368728637695, 0.953125\n",
      "Train loss and acc of batch 53: 47.84783935546875, 1.0\n",
      "Train loss and acc of batch 54: 48.064598083496094, 0.984375\n",
      "Train loss and acc of batch 55: 47.84781265258789, 1.0\n",
      "Train loss and acc of batch 56: 47.847808837890625, 1.0\n",
      "Train loss and acc of batch 57: 48.443504333496094, 0.984375\n",
      "Train loss and acc of batch 58: 47.84779357910156, 1.0\n",
      "Train loss and acc of batch 59: 47.8477897644043, 1.0\n",
      "Train loss and acc of batch 60: 47.8477783203125, 1.0\n",
      "Train loss and acc of batch 61: 47.84776306152344, 1.0\n",
      "Train loss and acc of batch 62: 47.84775924682617, 1.0\n",
      "Train loss and acc of batch 63: 49.03915023803711, 0.96875\n",
      "Train loss and acc of batch 64: 48.06450653076172, 0.984375\n",
      "Train loss and acc of batch 65: 47.84773254394531, 1.0\n",
      "Train loss and acc of batch 66: 47.84772491455078, 1.0\n",
      "Train loss and acc of batch 67: 48.660179138183594, 0.96875\n",
      "Train loss and acc of batch 68: 48.44341278076172, 0.984375\n",
      "Train loss and acc of batch 69: 48.06446075439453, 0.984375\n",
      "Train loss and acc of batch 70: 47.847686767578125, 1.0\n",
      "Training accuracy and loss of epoch #333: 0.9894, 48.1729\n",
      "Saved model by train loss 48.172908729230855\n",
      "Train loss and acc of batch 0: 47.84767532348633, 1.0\n",
      "Train loss and acc of batch 1: 47.8476676940918, 1.0\n",
      "Train loss and acc of batch 2: 48.133514404296875, 0.984375\n",
      "Train loss and acc of batch 3: 48.064422607421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.84764099121094, 1.0\n",
      "Train loss and acc of batch 5: 49.196563720703125, 0.96875\n",
      "Train loss and acc of batch 6: 48.350242614746094, 0.96875\n",
      "Train loss and acc of batch 7: 47.84761428833008, 1.0\n",
      "Train loss and acc of batch 8: 48.44330596923828, 0.984375\n",
      "Train loss and acc of batch 9: 48.133453369140625, 0.984375\n",
      "Train loss and acc of batch 10: 47.84758758544922, 1.0\n",
      "Train loss and acc of batch 11: 47.84758758544922, 1.0\n",
      "Train loss and acc of batch 12: 48.60078811645508, 0.984375\n",
      "Train loss and acc of batch 13: 48.06432342529297, 0.984375\n",
      "Train loss and acc of batch 14: 48.06432342529297, 0.984375\n",
      "Train loss and acc of batch 15: 48.44324493408203, 0.984375\n",
      "Train loss and acc of batch 16: 48.4432373046875, 0.984375\n",
      "Train loss and acc of batch 17: 48.60074996948242, 0.984375\n",
      "Train loss and acc of batch 18: 48.72907257080078, 0.96875\n",
      "Train loss and acc of batch 19: 47.84750747680664, 1.0\n",
      "Train loss and acc of batch 20: 47.84749984741211, 1.0\n",
      "Train loss and acc of batch 21: 48.44319152832031, 0.984375\n",
      "Train loss and acc of batch 22: 48.44318389892578, 0.984375\n",
      "Train loss and acc of batch 23: 47.847476959228516, 1.0\n",
      "Train loss and acc of batch 24: 48.44316864013672, 0.984375\n",
      "Train loss and acc of batch 25: 47.84746170043945, 1.0\n",
      "Train loss and acc of batch 26: 47.847450256347656, 1.0\n",
      "Train loss and acc of batch 27: 47.847434997558594, 1.0\n",
      "Train loss and acc of batch 28: 47.84742736816406, 1.0\n",
      "Train loss and acc of batch 29: 48.443115234375, 0.984375\n",
      "Train loss and acc of batch 30: 47.847415924072266, 1.0\n",
      "Train loss and acc of batch 31: 48.064170837402344, 0.984375\n",
      "Train loss and acc of batch 32: 47.84739303588867, 1.0\n",
      "Train loss and acc of batch 33: 47.847389221191406, 1.0\n",
      "Train loss and acc of batch 34: 48.443077087402344, 0.984375\n",
      "Train loss and acc of batch 35: 48.2808952331543, 0.96875\n",
      "Train loss and acc of batch 36: 47.84736251831055, 1.0\n",
      "Train loss and acc of batch 37: 48.60057067871094, 0.984375\n",
      "Train loss and acc of batch 38: 49.196266174316406, 0.96875\n",
      "Train loss and acc of batch 39: 48.06410217285156, 0.984375\n",
      "Train loss and acc of batch 40: 47.84732437133789, 1.0\n",
      "Train loss and acc of batch 41: 49.19623947143555, 0.96875\n",
      "Train loss and acc of batch 42: 47.84730529785156, 1.0\n",
      "Train loss and acc of batch 43: 48.4429931640625, 0.984375\n",
      "Train loss and acc of batch 44: 47.8472900390625, 1.0\n",
      "Train loss and acc of batch 45: 48.44297790527344, 0.984375\n",
      "Train loss and acc of batch 46: 48.13311767578125, 0.984375\n",
      "Train loss and acc of batch 47: 47.84726333618164, 1.0\n",
      "Train loss and acc of batch 48: 47.84725570678711, 1.0\n",
      "Train loss and acc of batch 49: 47.84724426269531, 1.0\n",
      "Train loss and acc of batch 50: 48.44293975830078, 0.984375\n",
      "Train loss and acc of batch 51: 49.19615173339844, 0.96875\n",
      "Train loss and acc of batch 52: 49.10305404663086, 0.953125\n",
      "Train loss and acc of batch 53: 47.84720993041992, 1.0\n",
      "Train loss and acc of batch 54: 48.06396484375, 0.984375\n",
      "Train loss and acc of batch 55: 47.847190856933594, 1.0\n",
      "Train loss and acc of batch 56: 47.84718322753906, 1.0\n",
      "Train loss and acc of batch 57: 48.44287109375, 0.984375\n",
      "Train loss and acc of batch 58: 47.847164154052734, 1.0\n",
      "Train loss and acc of batch 59: 47.8471565246582, 1.0\n",
      "Train loss and acc of batch 60: 47.84714126586914, 1.0\n",
      "Train loss and acc of batch 61: 47.84714126586914, 1.0\n",
      "Train loss and acc of batch 62: 47.847129821777344, 1.0\n",
      "Train loss and acc of batch 63: 49.03852081298828, 0.96875\n",
      "Train loss and acc of batch 64: 48.063873291015625, 0.984375\n",
      "Train loss and acc of batch 65: 47.84709930419922, 1.0\n",
      "Train loss and acc of batch 66: 47.84709167480469, 1.0\n",
      "Train loss and acc of batch 67: 48.65955352783203, 0.96875\n",
      "Train loss and acc of batch 68: 48.442771911621094, 0.984375\n",
      "Train loss and acc of batch 69: 48.06382751464844, 0.984375\n",
      "Train loss and acc of batch 70: 47.8470573425293, 1.0\n",
      "Training accuracy and loss of epoch #334: 0.9894, 48.1723\n",
      "Saved model by train loss 48.172277208784934\n",
      "Train loss and acc of batch 0: 47.847049713134766, 1.0\n",
      "Train loss and acc of batch 1: 47.84703826904297, 1.0\n",
      "Train loss and acc of batch 2: 48.13288879394531, 0.984375\n",
      "Train loss and acc of batch 3: 48.06378173828125, 0.984375\n",
      "Train loss and acc of batch 4: 47.847015380859375, 1.0\n",
      "Train loss and acc of batch 5: 49.1959228515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.349613189697266, 0.96875\n",
      "Train loss and acc of batch 7: 47.84698486328125, 1.0\n",
      "Train loss and acc of batch 8: 48.44267272949219, 0.984375\n",
      "Train loss and acc of batch 9: 48.13282012939453, 0.984375\n",
      "Train loss and acc of batch 10: 47.846961975097656, 1.0\n",
      "Train loss and acc of batch 11: 47.84695053100586, 1.0\n",
      "Train loss and acc of batch 12: 48.600162506103516, 0.984375\n",
      "Train loss and acc of batch 13: 48.063697814941406, 0.984375\n",
      "Train loss and acc of batch 14: 48.063690185546875, 0.984375\n",
      "Train loss and acc of batch 15: 48.44261932373047, 0.984375\n",
      "Train loss and acc of batch 16: 48.442604064941406, 0.984375\n",
      "Train loss and acc of batch 17: 48.600120544433594, 0.984375\n",
      "Train loss and acc of batch 18: 48.72844314575195, 0.96875\n",
      "Train loss and acc of batch 19: 47.84687805175781, 1.0\n",
      "Train loss and acc of batch 20: 47.84687042236328, 1.0\n",
      "Train loss and acc of batch 21: 48.44255828857422, 0.984375\n",
      "Train loss and acc of batch 22: 48.44255065917969, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 23: 47.84684371948242, 1.0\n",
      "Train loss and acc of batch 24: 48.442535400390625, 0.984375\n",
      "Train loss and acc of batch 25: 47.846824645996094, 1.0\n",
      "Train loss and acc of batch 26: 47.8468132019043, 1.0\n",
      "Train loss and acc of batch 27: 47.84680938720703, 1.0\n",
      "Train loss and acc of batch 28: 47.84679412841797, 1.0\n",
      "Train loss and acc of batch 29: 48.44248962402344, 0.984375\n",
      "Train loss and acc of batch 30: 47.84678268432617, 1.0\n",
      "Train loss and acc of batch 31: 48.06353759765625, 0.984375\n",
      "Train loss and acc of batch 32: 47.846763610839844, 1.0\n",
      "Train loss and acc of batch 33: 47.84675216674805, 1.0\n",
      "Train loss and acc of batch 34: 48.44244384765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.280269622802734, 0.96875\n",
      "Train loss and acc of batch 36: 47.84672546386719, 1.0\n",
      "Train loss and acc of batch 37: 48.59994125366211, 0.984375\n",
      "Train loss and acc of batch 38: 49.19563293457031, 0.96875\n",
      "Train loss and acc of batch 39: 48.06346130371094, 0.984375\n",
      "Train loss and acc of batch 40: 47.8466911315918, 1.0\n",
      "Train loss and acc of batch 41: 49.195613861083984, 0.96875\n",
      "Train loss and acc of batch 42: 47.84667205810547, 1.0\n",
      "Train loss and acc of batch 43: 48.44236755371094, 0.984375\n",
      "Train loss and acc of batch 44: 47.846656799316406, 1.0\n",
      "Train loss and acc of batch 45: 48.442344665527344, 0.984375\n",
      "Train loss and acc of batch 46: 48.13249206542969, 0.984375\n",
      "Train loss and acc of batch 47: 47.84662628173828, 1.0\n",
      "Train loss and acc of batch 48: 47.846622467041016, 1.0\n",
      "Train loss and acc of batch 49: 47.84661102294922, 1.0\n",
      "Train loss and acc of batch 50: 48.44230651855469, 0.984375\n",
      "Train loss and acc of batch 51: 49.195518493652344, 0.96875\n",
      "Train loss and acc of batch 52: 49.1024284362793, 0.953125\n",
      "Train loss and acc of batch 53: 47.84657287597656, 1.0\n",
      "Train loss and acc of batch 54: 48.063331604003906, 0.984375\n",
      "Train loss and acc of batch 55: 47.8465576171875, 1.0\n",
      "Train loss and acc of batch 56: 47.846553802490234, 1.0\n",
      "Train loss and acc of batch 57: 48.442237854003906, 0.984375\n",
      "Train loss and acc of batch 58: 47.846534729003906, 1.0\n",
      "Train loss and acc of batch 59: 47.846519470214844, 1.0\n",
      "Train loss and acc of batch 60: 47.84651565551758, 1.0\n",
      "Train loss and acc of batch 61: 47.84650802612305, 1.0\n",
      "Train loss and acc of batch 62: 47.84649658203125, 1.0\n",
      "Train loss and acc of batch 63: 49.03789138793945, 0.96875\n",
      "Train loss and acc of batch 64: 48.06324768066406, 0.984375\n",
      "Train loss and acc of batch 65: 47.846466064453125, 1.0\n",
      "Train loss and acc of batch 66: 47.846458435058594, 1.0\n",
      "Train loss and acc of batch 67: 48.658912658691406, 0.96875\n",
      "Train loss and acc of batch 68: 48.44214630126953, 0.984375\n",
      "Train loss and acc of batch 69: 48.063201904296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.84642791748047, 1.0\n",
      "Training accuracy and loss of epoch #335: 0.9894, 48.1716\n",
      "Saved model by train loss 48.17164574206715\n",
      "Train loss and acc of batch 0: 47.84642028808594, 1.0\n",
      "Train loss and acc of batch 1: 47.84640884399414, 1.0\n",
      "Train loss and acc of batch 2: 48.13224792480469, 0.984375\n",
      "Train loss and acc of batch 3: 48.06315612792969, 0.984375\n",
      "Train loss and acc of batch 4: 47.84638214111328, 1.0\n",
      "Train loss and acc of batch 5: 49.19529724121094, 0.96875\n",
      "Train loss and acc of batch 6: 48.34897994995117, 0.96875\n",
      "Train loss and acc of batch 7: 47.84635925292969, 1.0\n",
      "Train loss and acc of batch 8: 48.442047119140625, 0.984375\n",
      "Train loss and acc of batch 9: 48.13218688964844, 0.984375\n",
      "Train loss and acc of batch 10: 47.8463249206543, 1.0\n",
      "Train loss and acc of batch 11: 47.846317291259766, 1.0\n",
      "Train loss and acc of batch 12: 48.59953308105469, 0.984375\n",
      "Train loss and acc of batch 13: 48.06306457519531, 0.984375\n",
      "Train loss and acc of batch 14: 48.06305694580078, 0.984375\n",
      "Train loss and acc of batch 15: 48.441986083984375, 0.984375\n",
      "Train loss and acc of batch 16: 48.441978454589844, 0.984375\n",
      "Train loss and acc of batch 17: 48.5994873046875, 0.984375\n",
      "Train loss and acc of batch 18: 48.727813720703125, 0.96875\n",
      "Train loss and acc of batch 19: 47.846248626708984, 1.0\n",
      "Train loss and acc of batch 20: 47.84624099731445, 1.0\n",
      "Train loss and acc of batch 21: 48.441932678222656, 0.984375\n",
      "Train loss and acc of batch 22: 48.441925048828125, 0.984375\n",
      "Train loss and acc of batch 23: 47.84621047973633, 1.0\n",
      "Train loss and acc of batch 24: 48.44190216064453, 0.984375\n",
      "Train loss and acc of batch 25: 47.84619140625, 1.0\n",
      "Train loss and acc of batch 26: 47.846187591552734, 1.0\n",
      "Train loss and acc of batch 27: 47.84617614746094, 1.0\n",
      "Train loss and acc of batch 28: 47.84617233276367, 1.0\n",
      "Train loss and acc of batch 29: 48.441856384277344, 0.984375\n",
      "Train loss and acc of batch 30: 47.84614944458008, 1.0\n",
      "Train loss and acc of batch 31: 48.062904357910156, 0.984375\n",
      "Train loss and acc of batch 32: 47.846134185791016, 1.0\n",
      "Train loss and acc of batch 33: 47.84611892700195, 1.0\n",
      "Train loss and acc of batch 34: 48.44181823730469, 0.984375\n",
      "Train loss and acc of batch 35: 48.27963638305664, 0.96875\n",
      "Train loss and acc of batch 36: 47.846099853515625, 1.0\n",
      "Train loss and acc of batch 37: 48.599308013916016, 0.984375\n",
      "Train loss and acc of batch 38: 49.19499969482422, 0.96875\n",
      "Train loss and acc of batch 39: 48.062835693359375, 0.984375\n",
      "Train loss and acc of batch 40: 47.8460578918457, 1.0\n",
      "Train loss and acc of batch 41: 49.194976806640625, 0.96875\n",
      "Train loss and acc of batch 42: 47.846046447753906, 1.0\n",
      "Train loss and acc of batch 43: 48.441734313964844, 0.984375\n",
      "Train loss and acc of batch 44: 47.84602737426758, 1.0\n",
      "Train loss and acc of batch 45: 48.44171905517578, 0.984375\n",
      "Train loss and acc of batch 46: 48.131858825683594, 0.984375\n",
      "Train loss and acc of batch 47: 47.84599685668945, 1.0\n",
      "Train loss and acc of batch 48: 47.84598922729492, 1.0\n",
      "Train loss and acc of batch 49: 47.84598159790039, 1.0\n",
      "Train loss and acc of batch 50: 48.441673278808594, 0.984375\n",
      "Train loss and acc of batch 51: 49.19488525390625, 0.96875\n",
      "Train loss and acc of batch 52: 49.10178756713867, 0.953125\n",
      "Train loss and acc of batch 53: 47.845943450927734, 1.0\n",
      "Train loss and acc of batch 54: 48.06269836425781, 0.984375\n",
      "Train loss and acc of batch 55: 47.84592819213867, 1.0\n",
      "Train loss and acc of batch 56: 47.84592056274414, 1.0\n",
      "Train loss and acc of batch 57: 48.441612243652344, 0.984375\n",
      "Train loss and acc of batch 58: 47.84589767456055, 1.0\n",
      "Train loss and acc of batch 59: 47.84589385986328, 1.0\n",
      "Train loss and acc of batch 60: 47.84588623046875, 1.0\n",
      "Train loss and acc of batch 61: 47.84587097167969, 1.0\n",
      "Train loss and acc of batch 62: 47.845863342285156, 1.0\n",
      "Train loss and acc of batch 63: 49.037261962890625, 0.96875\n",
      "Train loss and acc of batch 64: 48.06261444091797, 0.984375\n",
      "Train loss and acc of batch 65: 47.84584045410156, 1.0\n",
      "Train loss and acc of batch 66: 47.8458251953125, 1.0\n",
      "Train loss and acc of batch 67: 48.658287048339844, 0.96875\n",
      "Train loss and acc of batch 68: 48.44151306152344, 0.984375\n",
      "Train loss and acc of batch 69: 48.06256866455078, 0.984375\n",
      "Train loss and acc of batch 70: 47.845794677734375, 1.0\n",
      "Training accuracy and loss of epoch #336: 0.9894, 48.1710\n",
      "Saved model by train loss 48.171014812630666\n",
      "Train loss and acc of batch 0: 47.845787048339844, 1.0\n",
      "Train loss and acc of batch 1: 47.84577560424805, 1.0\n",
      "Train loss and acc of batch 2: 48.131622314453125, 0.984375\n",
      "Train loss and acc of batch 3: 48.062522888183594, 0.984375\n",
      "Train loss and acc of batch 4: 47.84574508666992, 1.0\n",
      "Train loss and acc of batch 5: 49.194664001464844, 0.96875\n",
      "Train loss and acc of batch 6: 48.348350524902344, 0.96875\n",
      "Train loss and acc of batch 7: 47.84572219848633, 1.0\n",
      "Train loss and acc of batch 8: 48.44142150878906, 0.984375\n",
      "Train loss and acc of batch 9: 48.131553649902344, 0.984375\n",
      "Train loss and acc of batch 10: 47.84569549560547, 1.0\n",
      "Train loss and acc of batch 11: 47.84568786621094, 1.0\n",
      "Train loss and acc of batch 12: 48.598899841308594, 0.984375\n",
      "Train loss and acc of batch 13: 48.06243133544922, 0.984375\n",
      "Train loss and acc of batch 14: 48.06242370605469, 0.984375\n",
      "Train loss and acc of batch 15: 48.44135284423828, 0.984375\n",
      "Train loss and acc of batch 16: 48.44134521484375, 0.984375\n",
      "Train loss and acc of batch 17: 48.59885787963867, 0.984375\n",
      "Train loss and acc of batch 18: 48.7271728515625, 0.96875\n",
      "Train loss and acc of batch 19: 47.84561538696289, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 20: 47.84560775756836, 1.0\n",
      "Train loss and acc of batch 21: 48.44129943847656, 0.984375\n",
      "Train loss and acc of batch 22: 48.44129180908203, 0.984375\n",
      "Train loss and acc of batch 23: 47.845584869384766, 1.0\n",
      "Train loss and acc of batch 24: 48.44126892089844, 0.984375\n",
      "Train loss and acc of batch 25: 47.845558166503906, 1.0\n",
      "Train loss and acc of batch 26: 47.845550537109375, 1.0\n",
      "Train loss and acc of batch 27: 47.84554672241211, 1.0\n",
      "Train loss and acc of batch 28: 47.84553527832031, 1.0\n",
      "Train loss and acc of batch 29: 48.44123077392578, 0.984375\n",
      "Train loss and acc of batch 30: 47.84552001953125, 1.0\n",
      "Train loss and acc of batch 31: 48.06227111816406, 0.984375\n",
      "Train loss and acc of batch 32: 47.845497131347656, 1.0\n",
      "Train loss and acc of batch 33: 47.84549331665039, 1.0\n",
      "Train loss and acc of batch 34: 48.441184997558594, 0.984375\n",
      "Train loss and acc of batch 35: 48.27900695800781, 0.96875\n",
      "Train loss and acc of batch 36: 47.84546661376953, 1.0\n",
      "Train loss and acc of batch 37: 48.59868240356445, 0.984375\n",
      "Train loss and acc of batch 38: 49.194374084472656, 0.96875\n",
      "Train loss and acc of batch 39: 48.06220245361328, 0.984375\n",
      "Train loss and acc of batch 40: 47.845428466796875, 1.0\n",
      "Train loss and acc of batch 41: 49.19435119628906, 0.96875\n",
      "Train loss and acc of batch 42: 47.84540939331055, 1.0\n",
      "Train loss and acc of batch 43: 48.44110107421875, 0.984375\n",
      "Train loss and acc of batch 44: 47.845394134521484, 1.0\n",
      "Train loss and acc of batch 45: 48.44109344482422, 0.984375\n",
      "Train loss and acc of batch 46: 48.1312255859375, 0.984375\n",
      "Train loss and acc of batch 47: 47.845367431640625, 1.0\n",
      "Train loss and acc of batch 48: 47.845359802246094, 1.0\n",
      "Train loss and acc of batch 49: 47.8453483581543, 1.0\n",
      "Train loss and acc of batch 50: 48.4410400390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.19425964355469, 0.96875\n",
      "Train loss and acc of batch 52: 49.101165771484375, 0.953125\n",
      "Train loss and acc of batch 53: 47.845314025878906, 1.0\n",
      "Train loss and acc of batch 54: 48.06207275390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.845298767089844, 1.0\n",
      "Train loss and acc of batch 56: 47.84528732299805, 1.0\n",
      "Train loss and acc of batch 57: 48.44097900390625, 0.984375\n",
      "Train loss and acc of batch 58: 47.845272064208984, 1.0\n",
      "Train loss and acc of batch 59: 47.84526062011719, 1.0\n",
      "Train loss and acc of batch 60: 47.845252990722656, 1.0\n",
      "Train loss and acc of batch 61: 47.84524154663086, 1.0\n",
      "Train loss and acc of batch 62: 47.84523391723633, 1.0\n",
      "Train loss and acc of batch 63: 49.03662872314453, 0.96875\n",
      "Train loss and acc of batch 64: 48.061981201171875, 0.984375\n",
      "Train loss and acc of batch 65: 47.84520721435547, 1.0\n",
      "Train loss and acc of batch 66: 47.84519958496094, 1.0\n",
      "Train loss and acc of batch 67: 48.65765380859375, 0.96875\n",
      "Train loss and acc of batch 68: 48.440887451171875, 0.984375\n",
      "Train loss and acc of batch 69: 48.06193542480469, 0.984375\n",
      "Train loss and acc of batch 70: 47.845157623291016, 1.0\n",
      "Training accuracy and loss of epoch #337: 0.9894, 48.1704\n",
      "Saved model by train loss 48.17038350709727\n",
      "Train loss and acc of batch 0: 47.84515380859375, 1.0\n",
      "Train loss and acc of batch 1: 47.84514617919922, 1.0\n",
      "Train loss and acc of batch 2: 48.13098907470703, 0.984375\n",
      "Train loss and acc of batch 3: 48.06189727783203, 0.984375\n",
      "Train loss and acc of batch 4: 47.845115661621094, 1.0\n",
      "Train loss and acc of batch 5: 49.19403076171875, 0.96875\n",
      "Train loss and acc of batch 6: 48.34771728515625, 0.96875\n",
      "Train loss and acc of batch 7: 47.845096588134766, 1.0\n",
      "Train loss and acc of batch 8: 48.44078063964844, 0.984375\n",
      "Train loss and acc of batch 9: 48.13092803955078, 0.984375\n",
      "Train loss and acc of batch 10: 47.84506607055664, 1.0\n",
      "Train loss and acc of batch 11: 47.845054626464844, 1.0\n",
      "Train loss and acc of batch 12: 48.598270416259766, 0.984375\n",
      "Train loss and acc of batch 13: 48.061798095703125, 0.984375\n",
      "Train loss and acc of batch 14: 48.061790466308594, 0.984375\n",
      "Train loss and acc of batch 15: 48.44071960449219, 0.984375\n",
      "Train loss and acc of batch 16: 48.440711975097656, 0.984375\n",
      "Train loss and acc of batch 17: 48.598228454589844, 0.984375\n",
      "Train loss and acc of batch 18: 48.7265510559082, 0.96875\n",
      "Train loss and acc of batch 19: 47.84498977661133, 1.0\n",
      "Train loss and acc of batch 20: 47.84497833251953, 1.0\n",
      "Train loss and acc of batch 21: 48.44066619873047, 0.984375\n",
      "Train loss and acc of batch 22: 48.44065856933594, 0.984375\n",
      "Train loss and acc of batch 23: 47.844947814941406, 1.0\n",
      "Train loss and acc of batch 24: 48.440643310546875, 0.984375\n",
      "Train loss and acc of batch 25: 47.84492874145508, 1.0\n",
      "Train loss and acc of batch 26: 47.84492874145508, 1.0\n",
      "Train loss and acc of batch 27: 47.844913482666016, 1.0\n",
      "Train loss and acc of batch 28: 47.84490203857422, 1.0\n",
      "Train loss and acc of batch 29: 48.44059753417969, 0.984375\n",
      "Train loss and acc of batch 30: 47.84489059448242, 1.0\n",
      "Train loss and acc of batch 31: 48.0616455078125, 0.984375\n",
      "Train loss and acc of batch 32: 47.844871520996094, 1.0\n",
      "Train loss and acc of batch 33: 47.8448600769043, 1.0\n",
      "Train loss and acc of batch 34: 48.4405517578125, 0.984375\n",
      "Train loss and acc of batch 35: 48.27836990356445, 0.96875\n",
      "Train loss and acc of batch 36: 47.84483337402344, 1.0\n",
      "Train loss and acc of batch 37: 48.59804916381836, 0.984375\n",
      "Train loss and acc of batch 38: 49.19374084472656, 0.96875\n",
      "Train loss and acc of batch 39: 48.06156921386719, 0.984375\n",
      "Train loss and acc of batch 40: 47.84479904174805, 1.0\n",
      "Train loss and acc of batch 41: 49.193721771240234, 0.96875\n",
      "Train loss and acc of batch 42: 47.84477615356445, 1.0\n",
      "Train loss and acc of batch 43: 48.44047546386719, 0.984375\n",
      "Train loss and acc of batch 44: 47.84476089477539, 1.0\n",
      "Train loss and acc of batch 45: 48.440452575683594, 0.984375\n",
      "Train loss and acc of batch 46: 48.13059997558594, 0.984375\n",
      "Train loss and acc of batch 47: 47.8447380065918, 1.0\n",
      "Train loss and acc of batch 48: 47.844730377197266, 1.0\n",
      "Train loss and acc of batch 49: 47.84471893310547, 1.0\n",
      "Train loss and acc of batch 50: 48.440406799316406, 0.984375\n",
      "Train loss and acc of batch 51: 49.193626403808594, 0.96875\n",
      "Train loss and acc of batch 52: 49.10053253173828, 0.953125\n",
      "Train loss and acc of batch 53: 47.84468460083008, 1.0\n",
      "Train loss and acc of batch 54: 48.061439514160156, 0.984375\n",
      "Train loss and acc of batch 55: 47.844669342041016, 1.0\n",
      "Train loss and acc of batch 56: 47.84465026855469, 1.0\n",
      "Train loss and acc of batch 57: 48.440345764160156, 0.984375\n",
      "Train loss and acc of batch 58: 47.84463882446289, 1.0\n",
      "Train loss and acc of batch 59: 47.84463119506836, 1.0\n",
      "Train loss and acc of batch 60: 47.8446159362793, 1.0\n",
      "Train loss and acc of batch 61: 47.8446159362793, 1.0\n",
      "Train loss and acc of batch 62: 47.8446044921875, 1.0\n",
      "Train loss and acc of batch 63: 49.0359992980957, 0.96875\n",
      "Train loss and acc of batch 64: 48.06134796142578, 0.984375\n",
      "Train loss and acc of batch 65: 47.84457778930664, 1.0\n",
      "Train loss and acc of batch 66: 47.844566345214844, 1.0\n",
      "Train loss and acc of batch 67: 48.65702819824219, 0.96875\n",
      "Train loss and acc of batch 68: 48.44024658203125, 0.984375\n",
      "Train loss and acc of batch 69: 48.061302185058594, 0.984375\n",
      "Train loss and acc of batch 70: 47.84452819824219, 1.0\n",
      "Training accuracy and loss of epoch #338: 0.9894, 48.1698\n",
      "Saved model by train loss 48.16975230902013\n",
      "Train loss and acc of batch 0: 47.844520568847656, 1.0\n",
      "Train loss and acc of batch 1: 47.844512939453125, 1.0\n",
      "Train loss and acc of batch 2: 48.13035583496094, 0.984375\n",
      "Train loss and acc of batch 3: 48.061256408691406, 0.984375\n",
      "Train loss and acc of batch 4: 47.84449005126953, 1.0\n",
      "Train loss and acc of batch 5: 49.19340515136719, 0.96875\n",
      "Train loss and acc of batch 6: 48.34708786010742, 0.96875\n",
      "Train loss and acc of batch 7: 47.84446334838867, 1.0\n",
      "Train loss and acc of batch 8: 48.440147399902344, 0.984375\n",
      "Train loss and acc of batch 9: 48.13029479980469, 0.984375\n",
      "Train loss and acc of batch 10: 47.84443283081055, 1.0\n",
      "Train loss and acc of batch 11: 47.84442901611328, 1.0\n",
      "Train loss and acc of batch 12: 48.5976448059082, 0.984375\n",
      "Train loss and acc of batch 13: 48.06117248535156, 0.984375\n",
      "Train loss and acc of batch 14: 48.06116485595703, 0.984375\n",
      "Train loss and acc of batch 15: 48.440093994140625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 16: 48.44007873535156, 0.984375\n",
      "Train loss and acc of batch 17: 48.59759521484375, 0.984375\n",
      "Train loss and acc of batch 18: 48.725914001464844, 0.96875\n",
      "Train loss and acc of batch 19: 47.8443489074707, 1.0\n",
      "Train loss and acc of batch 20: 47.84434509277344, 1.0\n",
      "Train loss and acc of batch 21: 48.440040588378906, 0.984375\n",
      "Train loss and acc of batch 22: 48.440025329589844, 0.984375\n",
      "Train loss and acc of batch 23: 47.84431838989258, 1.0\n",
      "Train loss and acc of batch 24: 48.44001007080078, 0.984375\n",
      "Train loss and acc of batch 25: 47.84429931640625, 1.0\n",
      "Train loss and acc of batch 26: 47.84429168701172, 1.0\n",
      "Train loss and acc of batch 27: 47.84428405761719, 1.0\n",
      "Train loss and acc of batch 28: 47.84427261352539, 1.0\n",
      "Train loss and acc of batch 29: 48.439971923828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.84425735473633, 1.0\n",
      "Train loss and acc of batch 31: 48.061012268066406, 0.984375\n",
      "Train loss and acc of batch 32: 47.84423828125, 1.0\n",
      "Train loss and acc of batch 33: 47.84423065185547, 1.0\n",
      "Train loss and acc of batch 34: 48.439918518066406, 0.984375\n",
      "Train loss and acc of batch 35: 48.27774429321289, 0.96875\n",
      "Train loss and acc of batch 36: 47.844200134277344, 1.0\n",
      "Train loss and acc of batch 37: 48.59741973876953, 0.984375\n",
      "Train loss and acc of batch 38: 49.19310760498047, 0.96875\n",
      "Train loss and acc of batch 39: 48.060943603515625, 0.984375\n",
      "Train loss and acc of batch 40: 47.84416961669922, 1.0\n",
      "Train loss and acc of batch 41: 49.19308853149414, 0.96875\n",
      "Train loss and acc of batch 42: 47.84415054321289, 1.0\n",
      "Train loss and acc of batch 43: 48.439842224121094, 0.984375\n",
      "Train loss and acc of batch 44: 47.84413146972656, 1.0\n",
      "Train loss and acc of batch 45: 48.4398193359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.129966735839844, 0.984375\n",
      "Train loss and acc of batch 47: 47.8441047668457, 1.0\n",
      "Train loss and acc of batch 48: 47.84409713745117, 1.0\n",
      "Train loss and acc of batch 49: 47.84408950805664, 1.0\n",
      "Train loss and acc of batch 50: 48.439781188964844, 0.984375\n",
      "Train loss and acc of batch 51: 49.1929931640625, 0.96875\n",
      "Train loss and acc of batch 52: 49.09990310668945, 0.953125\n",
      "Train loss and acc of batch 53: 47.84404754638672, 1.0\n",
      "Train loss and acc of batch 54: 48.060813903808594, 0.984375\n",
      "Train loss and acc of batch 55: 47.844032287597656, 1.0\n",
      "Train loss and acc of batch 56: 47.844024658203125, 1.0\n",
      "Train loss and acc of batch 57: 48.439720153808594, 0.984375\n",
      "Train loss and acc of batch 58: 47.84400939941406, 1.0\n",
      "Train loss and acc of batch 59: 47.843997955322266, 1.0\n",
      "Train loss and acc of batch 60: 47.843994140625, 1.0\n",
      "Train loss and acc of batch 61: 47.8439826965332, 1.0\n",
      "Train loss and acc of batch 62: 47.843971252441406, 1.0\n",
      "Train loss and acc of batch 63: 49.035362243652344, 0.96875\n",
      "Train loss and acc of batch 64: 48.06072235107422, 0.984375\n",
      "Train loss and acc of batch 65: 47.84394454956055, 1.0\n",
      "Train loss and acc of batch 66: 47.843936920166016, 1.0\n",
      "Train loss and acc of batch 67: 48.656394958496094, 0.96875\n",
      "Train loss and acc of batch 68: 48.43962097167969, 0.984375\n",
      "Train loss and acc of batch 69: 48.0606689453125, 0.984375\n",
      "Train loss and acc of batch 70: 47.84389877319336, 1.0\n",
      "Training accuracy and loss of epoch #339: 0.9894, 48.1691\n",
      "Saved model by train loss 48.16912143331179\n",
      "Train loss and acc of batch 0: 47.843894958496094, 1.0\n",
      "Train loss and acc of batch 1: 47.8438835144043, 1.0\n",
      "Train loss and acc of batch 2: 48.129730224609375, 0.984375\n",
      "Train loss and acc of batch 3: 48.060630798339844, 0.984375\n",
      "Train loss and acc of batch 4: 47.84385681152344, 1.0\n",
      "Train loss and acc of batch 5: 49.192771911621094, 0.96875\n",
      "Train loss and acc of batch 6: 48.34645462036133, 0.96875\n",
      "Train loss and acc of batch 7: 47.84382629394531, 1.0\n",
      "Train loss and acc of batch 8: 48.43952178955078, 0.984375\n",
      "Train loss and acc of batch 9: 48.129661560058594, 0.984375\n",
      "Train loss and acc of batch 10: 47.84380340576172, 1.0\n",
      "Train loss and acc of batch 11: 47.84379959106445, 1.0\n",
      "Train loss and acc of batch 12: 48.597007751464844, 0.984375\n",
      "Train loss and acc of batch 13: 48.06053924560547, 0.984375\n",
      "Train loss and acc of batch 14: 48.06053161621094, 0.984375\n",
      "Train loss and acc of batch 15: 48.43946075439453, 0.984375\n",
      "Train loss and acc of batch 16: 48.439453125, 0.984375\n",
      "Train loss and acc of batch 17: 48.59696578979492, 0.984375\n",
      "Train loss and acc of batch 18: 48.72528839111328, 0.96875\n",
      "Train loss and acc of batch 19: 47.843727111816406, 1.0\n",
      "Train loss and acc of batch 20: 47.843711853027344, 1.0\n",
      "Train loss and acc of batch 21: 48.43940734863281, 0.984375\n",
      "Train loss and acc of batch 22: 48.43939971923828, 0.984375\n",
      "Train loss and acc of batch 23: 47.843685150146484, 1.0\n",
      "Train loss and acc of batch 24: 48.43938446044922, 0.984375\n",
      "Train loss and acc of batch 25: 47.84367370605469, 1.0\n",
      "Train loss and acc of batch 26: 47.843658447265625, 1.0\n",
      "Train loss and acc of batch 27: 47.843650817871094, 1.0\n",
      "Train loss and acc of batch 28: 47.84364318847656, 1.0\n",
      "Train loss and acc of batch 29: 48.4393310546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.8436279296875, 1.0\n",
      "Train loss and acc of batch 31: 48.060386657714844, 0.984375\n",
      "Train loss and acc of batch 32: 47.84360885620117, 1.0\n",
      "Train loss and acc of batch 33: 47.84360122680664, 1.0\n",
      "Train loss and acc of batch 34: 48.43928527832031, 0.984375\n",
      "Train loss and acc of batch 35: 48.27710723876953, 0.96875\n",
      "Train loss and acc of batch 36: 47.843570709228516, 1.0\n",
      "Train loss and acc of batch 37: 48.59678649902344, 0.984375\n",
      "Train loss and acc of batch 38: 49.192481994628906, 0.96875\n",
      "Train loss and acc of batch 39: 48.06031036376953, 0.984375\n",
      "Train loss and acc of batch 40: 47.843536376953125, 1.0\n",
      "Train loss and acc of batch 41: 49.19245529174805, 0.96875\n",
      "Train loss and acc of batch 42: 47.84352111816406, 1.0\n",
      "Train loss and acc of batch 43: 48.439208984375, 0.984375\n",
      "Train loss and acc of batch 44: 47.84349822998047, 1.0\n",
      "Train loss and acc of batch 45: 48.43919372558594, 0.984375\n",
      "Train loss and acc of batch 46: 48.12933349609375, 0.984375\n",
      "Train loss and acc of batch 47: 47.84347915649414, 1.0\n",
      "Train loss and acc of batch 48: 47.84347152709961, 1.0\n",
      "Train loss and acc of batch 49: 47.84345626831055, 1.0\n",
      "Train loss and acc of batch 50: 48.43914794921875, 0.984375\n",
      "Train loss and acc of batch 51: 49.19236755371094, 0.96875\n",
      "Train loss and acc of batch 52: 49.099273681640625, 0.953125\n",
      "Train loss and acc of batch 53: 47.843421936035156, 1.0\n",
      "Train loss and acc of batch 54: 48.06017303466797, 0.984375\n",
      "Train loss and acc of batch 55: 47.84340286254883, 1.0\n",
      "Train loss and acc of batch 56: 47.84339141845703, 1.0\n",
      "Train loss and acc of batch 57: 48.4390869140625, 0.984375\n",
      "Train loss and acc of batch 58: 47.84337615966797, 1.0\n",
      "Train loss and acc of batch 59: 47.8433723449707, 1.0\n",
      "Train loss and acc of batch 60: 47.84335708618164, 1.0\n",
      "Train loss and acc of batch 61: 47.843353271484375, 1.0\n",
      "Train loss and acc of batch 62: 47.843345642089844, 1.0\n",
      "Train loss and acc of batch 63: 49.03473663330078, 0.96875\n",
      "Train loss and acc of batch 64: 48.060081481933594, 0.984375\n",
      "Train loss and acc of batch 65: 47.843318939208984, 1.0\n",
      "Train loss and acc of batch 66: 47.84330368041992, 1.0\n",
      "Train loss and acc of batch 67: 48.655765533447266, 0.96875\n",
      "Train loss and acc of batch 68: 48.438987731933594, 0.984375\n",
      "Train loss and acc of batch 69: 48.06004333496094, 0.984375\n",
      "Train loss and acc of batch 70: 47.84326934814453, 1.0\n",
      "Training accuracy and loss of epoch #340: 0.9894, 48.1685\n",
      "Saved model by train loss 48.16849087997222\n",
      "Train loss and acc of batch 0: 47.843257904052734, 1.0\n",
      "Train loss and acc of batch 1: 47.8432502746582, 1.0\n",
      "Train loss and acc of batch 2: 48.12909698486328, 0.984375\n",
      "Train loss and acc of batch 3: 48.05999755859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.843223571777344, 1.0\n",
      "Train loss and acc of batch 5: 49.19214630126953, 0.96875\n",
      "Train loss and acc of batch 6: 48.3458251953125, 0.96875\n",
      "Train loss and acc of batch 7: 47.84320068359375, 1.0\n",
      "Train loss and acc of batch 8: 48.43889617919922, 0.984375\n",
      "Train loss and acc of batch 9: 48.12903594970703, 0.984375\n",
      "Train loss and acc of batch 10: 47.84317398071289, 1.0\n",
      "Train loss and acc of batch 11: 47.84315872192383, 1.0\n",
      "Train loss and acc of batch 12: 48.596378326416016, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 13: 48.059913635253906, 0.984375\n",
      "Train loss and acc of batch 14: 48.059898376464844, 0.984375\n",
      "Train loss and acc of batch 15: 48.43882751464844, 0.984375\n",
      "Train loss and acc of batch 16: 48.438819885253906, 0.984375\n",
      "Train loss and acc of batch 17: 48.59633255004883, 0.984375\n",
      "Train loss and acc of batch 18: 48.72465515136719, 0.96875\n",
      "Train loss and acc of batch 19: 47.84309387207031, 1.0\n",
      "Train loss and acc of batch 20: 47.843082427978516, 1.0\n",
      "Train loss and acc of batch 21: 48.43877410888672, 0.984375\n",
      "Train loss and acc of batch 22: 48.43876647949219, 0.984375\n",
      "Train loss and acc of batch 23: 47.843055725097656, 1.0\n",
      "Train loss and acc of batch 24: 48.438751220703125, 0.984375\n",
      "Train loss and acc of batch 25: 47.843040466308594, 1.0\n",
      "Train loss and acc of batch 26: 47.8430290222168, 1.0\n",
      "Train loss and acc of batch 27: 47.84302520751953, 1.0\n",
      "Train loss and acc of batch 28: 47.84300994873047, 1.0\n",
      "Train loss and acc of batch 29: 48.43870544433594, 0.984375\n",
      "Train loss and acc of batch 30: 47.84299087524414, 1.0\n",
      "Train loss and acc of batch 31: 48.05974578857422, 0.984375\n",
      "Train loss and acc of batch 32: 47.842979431152344, 1.0\n",
      "Train loss and acc of batch 33: 47.84297180175781, 1.0\n",
      "Train loss and acc of batch 34: 48.43865966796875, 0.984375\n",
      "Train loss and acc of batch 35: 48.27648162841797, 0.96875\n",
      "Train loss and acc of batch 36: 47.84294128417969, 1.0\n",
      "Train loss and acc of batch 37: 48.596153259277344, 0.984375\n",
      "Train loss and acc of batch 38: 49.19184875488281, 0.96875\n",
      "Train loss and acc of batch 39: 48.05968475341797, 0.984375\n",
      "Train loss and acc of batch 40: 47.84290313720703, 1.0\n",
      "Train loss and acc of batch 41: 49.19182205200195, 0.96875\n",
      "Train loss and acc of batch 42: 47.84288787841797, 1.0\n",
      "Train loss and acc of batch 43: 48.438575744628906, 0.984375\n",
      "Train loss and acc of batch 44: 47.84286880493164, 1.0\n",
      "Train loss and acc of batch 45: 48.438560485839844, 0.984375\n",
      "Train loss and acc of batch 46: 48.12870788574219, 0.984375\n",
      "Train loss and acc of batch 47: 47.84284591674805, 1.0\n",
      "Train loss and acc of batch 48: 47.84283447265625, 1.0\n",
      "Train loss and acc of batch 49: 47.842830657958984, 1.0\n",
      "Train loss and acc of batch 50: 48.43852233886719, 0.984375\n",
      "Train loss and acc of batch 51: 49.191734313964844, 0.96875\n",
      "Train loss and acc of batch 52: 49.09864044189453, 0.953125\n",
      "Train loss and acc of batch 53: 47.84278869628906, 1.0\n",
      "Train loss and acc of batch 54: 48.059547424316406, 0.984375\n",
      "Train loss and acc of batch 55: 47.8427734375, 1.0\n",
      "Train loss and acc of batch 56: 47.8427619934082, 1.0\n",
      "Train loss and acc of batch 57: 48.438453674316406, 0.984375\n",
      "Train loss and acc of batch 58: 47.84274673461914, 1.0\n",
      "Train loss and acc of batch 59: 47.84273147583008, 1.0\n",
      "Train loss and acc of batch 60: 47.84273147583008, 1.0\n",
      "Train loss and acc of batch 61: 47.84272003173828, 1.0\n",
      "Train loss and acc of batch 62: 47.842708587646484, 1.0\n",
      "Train loss and acc of batch 63: 49.03410339355469, 0.96875\n",
      "Train loss and acc of batch 64: 48.05945587158203, 0.984375\n",
      "Train loss and acc of batch 65: 47.842681884765625, 1.0\n",
      "Train loss and acc of batch 66: 47.842674255371094, 1.0\n",
      "Train loss and acc of batch 67: 48.655128479003906, 0.96875\n",
      "Train loss and acc of batch 68: 48.43836212158203, 0.984375\n",
      "Train loss and acc of batch 69: 48.059417724609375, 0.984375\n",
      "Train loss and acc of batch 70: 47.84264373779297, 1.0\n",
      "Training accuracy and loss of epoch #341: 0.9894, 48.1679\n",
      "Saved model by train loss 48.16785978935134\n",
      "Train loss and acc of batch 0: 47.842628479003906, 1.0\n",
      "Train loss and acc of batch 1: 47.84261703491211, 1.0\n",
      "Train loss and acc of batch 2: 48.12846374511719, 0.984375\n",
      "Train loss and acc of batch 3: 48.05937194824219, 0.984375\n",
      "Train loss and acc of batch 4: 47.84259033203125, 1.0\n",
      "Train loss and acc of batch 5: 49.191505432128906, 0.96875\n",
      "Train loss and acc of batch 6: 48.34519577026367, 0.96875\n",
      "Train loss and acc of batch 7: 47.84257125854492, 1.0\n",
      "Train loss and acc of batch 8: 48.438262939453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.12840270996094, 0.984375\n",
      "Train loss and acc of batch 10: 47.8425407409668, 1.0\n",
      "Train loss and acc of batch 11: 47.842529296875, 1.0\n",
      "Train loss and acc of batch 12: 48.59574890136719, 0.984375\n",
      "Train loss and acc of batch 13: 48.05927276611328, 0.984375\n",
      "Train loss and acc of batch 14: 48.05927276611328, 0.984375\n",
      "Train loss and acc of batch 15: 48.438194274902344, 0.984375\n",
      "Train loss and acc of batch 16: 48.43818664550781, 0.984375\n",
      "Train loss and acc of batch 17: 48.595703125, 0.984375\n",
      "Train loss and acc of batch 18: 48.72402572631836, 0.96875\n",
      "Train loss and acc of batch 19: 47.84245681762695, 1.0\n",
      "Train loss and acc of batch 20: 47.84245300292969, 1.0\n",
      "Train loss and acc of batch 21: 48.438148498535156, 0.984375\n",
      "Train loss and acc of batch 22: 48.438133239746094, 0.984375\n",
      "Train loss and acc of batch 23: 47.84242248535156, 1.0\n",
      "Train loss and acc of batch 24: 48.43811798095703, 0.984375\n",
      "Train loss and acc of batch 25: 47.8424072265625, 1.0\n",
      "Train loss and acc of batch 26: 47.84239959716797, 1.0\n",
      "Train loss and acc of batch 27: 47.84239196777344, 1.0\n",
      "Train loss and acc of batch 28: 47.84238052368164, 1.0\n",
      "Train loss and acc of batch 29: 48.438072204589844, 0.984375\n",
      "Train loss and acc of batch 30: 47.84235763549805, 1.0\n",
      "Train loss and acc of batch 31: 48.059120178222656, 0.984375\n",
      "Train loss and acc of batch 32: 47.84234619140625, 1.0\n",
      "Train loss and acc of batch 33: 47.84233474731445, 1.0\n",
      "Train loss and acc of batch 34: 48.43803405761719, 0.984375\n",
      "Train loss and acc of batch 35: 48.275848388671875, 0.96875\n",
      "Train loss and acc of batch 36: 47.84231185913086, 1.0\n",
      "Train loss and acc of batch 37: 48.595523834228516, 0.984375\n",
      "Train loss and acc of batch 38: 49.19121551513672, 0.96875\n",
      "Train loss and acc of batch 39: 48.059043884277344, 0.984375\n",
      "Train loss and acc of batch 40: 47.8422737121582, 1.0\n",
      "Train loss and acc of batch 41: 49.191192626953125, 0.96875\n",
      "Train loss and acc of batch 42: 47.842254638671875, 1.0\n",
      "Train loss and acc of batch 43: 48.437950134277344, 0.984375\n",
      "Train loss and acc of batch 44: 47.84223937988281, 1.0\n",
      "Train loss and acc of batch 45: 48.43793487548828, 0.984375\n",
      "Train loss and acc of batch 46: 48.128074645996094, 0.984375\n",
      "Train loss and acc of batch 47: 47.84220886230469, 1.0\n",
      "Train loss and acc of batch 48: 47.842201232910156, 1.0\n",
      "Train loss and acc of batch 49: 47.84219741821289, 1.0\n",
      "Train loss and acc of batch 50: 48.437889099121094, 0.984375\n",
      "Train loss and acc of batch 51: 49.19110107421875, 0.96875\n",
      "Train loss and acc of batch 52: 49.09800720214844, 0.953125\n",
      "Train loss and acc of batch 53: 47.842159271240234, 1.0\n",
      "Train loss and acc of batch 54: 48.05891418457031, 0.984375\n",
      "Train loss and acc of batch 55: 47.84214401245117, 1.0\n",
      "Train loss and acc of batch 56: 47.84212875366211, 1.0\n",
      "Train loss and acc of batch 57: 48.437828063964844, 0.984375\n",
      "Train loss and acc of batch 58: 47.84211730957031, 1.0\n",
      "Train loss and acc of batch 59: 47.842105865478516, 1.0\n",
      "Train loss and acc of batch 60: 47.84209442138672, 1.0\n",
      "Train loss and acc of batch 61: 47.84208297729492, 1.0\n",
      "Train loss and acc of batch 62: 47.842079162597656, 1.0\n",
      "Train loss and acc of batch 63: 49.03347396850586, 0.96875\n",
      "Train loss and acc of batch 64: 48.05882263183594, 0.984375\n",
      "Train loss and acc of batch 65: 47.8420524597168, 1.0\n",
      "Train loss and acc of batch 66: 47.842044830322266, 1.0\n",
      "Train loss and acc of batch 67: 48.65449905395508, 0.96875\n",
      "Train loss and acc of batch 68: 48.437721252441406, 0.984375\n",
      "Train loss and acc of batch 69: 48.05878448486328, 0.984375\n",
      "Train loss and acc of batch 70: 47.84200668334961, 1.0\n",
      "Training accuracy and loss of epoch #342: 0.9894, 48.1672\n",
      "Saved model by train loss 48.16722800026477\n",
      "Train loss and acc of batch 0: 47.84199905395508, 1.0\n",
      "Train loss and acc of batch 1: 47.84199142456055, 1.0\n",
      "Train loss and acc of batch 2: 48.127838134765625, 0.984375\n",
      "Train loss and acc of batch 3: 48.058738708496094, 0.984375\n",
      "Train loss and acc of batch 4: 47.84196090698242, 1.0\n",
      "Train loss and acc of batch 5: 49.190879821777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.34456253051758, 0.96875\n",
      "Train loss and acc of batch 7: 47.84193801879883, 1.0\n",
      "Train loss and acc of batch 8: 48.43762969970703, 0.984375\n",
      "Train loss and acc of batch 9: 48.127769470214844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 10: 47.8419075012207, 1.0\n",
      "Train loss and acc of batch 11: 47.84190368652344, 1.0\n",
      "Train loss and acc of batch 12: 48.595115661621094, 0.984375\n",
      "Train loss and acc of batch 13: 48.05864715576172, 0.984375\n",
      "Train loss and acc of batch 14: 48.05863952636719, 0.984375\n",
      "Train loss and acc of batch 15: 48.43756866455078, 0.984375\n",
      "Train loss and acc of batch 16: 48.43756103515625, 0.984375\n",
      "Train loss and acc of batch 17: 48.595069885253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.723392486572266, 0.96875\n",
      "Train loss and acc of batch 19: 47.84183120727539, 1.0\n",
      "Train loss and acc of batch 20: 47.841819763183594, 1.0\n",
      "Train loss and acc of batch 21: 48.43750762939453, 0.984375\n",
      "Train loss and acc of batch 22: 48.4375, 0.984375\n",
      "Train loss and acc of batch 23: 47.841796875, 1.0\n",
      "Train loss and acc of batch 24: 48.43748474121094, 0.984375\n",
      "Train loss and acc of batch 25: 47.84177780151367, 1.0\n",
      "Train loss and acc of batch 26: 47.841766357421875, 1.0\n",
      "Train loss and acc of batch 27: 47.841758728027344, 1.0\n",
      "Train loss and acc of batch 28: 47.84175109863281, 1.0\n",
      "Train loss and acc of batch 29: 48.43744659423828, 0.984375\n",
      "Train loss and acc of batch 30: 47.841732025146484, 1.0\n",
      "Train loss and acc of batch 31: 48.05848693847656, 0.984375\n",
      "Train loss and acc of batch 32: 47.841712951660156, 1.0\n",
      "Train loss and acc of batch 33: 47.841705322265625, 1.0\n",
      "Train loss and acc of batch 34: 48.43739318847656, 0.984375\n",
      "Train loss and acc of batch 35: 48.27521514892578, 0.96875\n",
      "Train loss and acc of batch 36: 47.841678619384766, 1.0\n",
      "Train loss and acc of batch 37: 48.59489440917969, 0.984375\n",
      "Train loss and acc of batch 38: 49.190582275390625, 0.96875\n",
      "Train loss and acc of batch 39: 48.05841827392578, 0.984375\n",
      "Train loss and acc of batch 40: 47.841644287109375, 1.0\n",
      "Train loss and acc of batch 41: 49.190555572509766, 0.96875\n",
      "Train loss and acc of batch 42: 47.84162521362305, 1.0\n",
      "Train loss and acc of batch 43: 48.43731689453125, 0.984375\n",
      "Train loss and acc of batch 44: 47.841609954833984, 1.0\n",
      "Train loss and acc of batch 45: 48.43730926513672, 0.984375\n",
      "Train loss and acc of batch 46: 48.12744140625, 0.984375\n",
      "Train loss and acc of batch 47: 47.84157943725586, 1.0\n",
      "Train loss and acc of batch 48: 47.84157180786133, 1.0\n",
      "Train loss and acc of batch 49: 47.841556549072266, 1.0\n",
      "Train loss and acc of batch 50: 48.437255859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.190467834472656, 0.96875\n",
      "Train loss and acc of batch 52: 49.09737777709961, 0.953125\n",
      "Train loss and acc of batch 53: 47.841529846191406, 1.0\n",
      "Train loss and acc of batch 54: 48.05828094482422, 0.984375\n",
      "Train loss and acc of batch 55: 47.84150695800781, 1.0\n",
      "Train loss and acc of batch 56: 47.84150314331055, 1.0\n",
      "Train loss and acc of batch 57: 48.43719482421875, 0.984375\n",
      "Train loss and acc of batch 58: 47.84148406982422, 1.0\n",
      "Train loss and acc of batch 59: 47.84147262573242, 1.0\n",
      "Train loss and acc of batch 60: 47.84145736694336, 1.0\n",
      "Train loss and acc of batch 61: 47.84145736694336, 1.0\n",
      "Train loss and acc of batch 62: 47.84144973754883, 1.0\n",
      "Train loss and acc of batch 63: 49.0328369140625, 0.96875\n",
      "Train loss and acc of batch 64: 48.058197021484375, 0.984375\n",
      "Train loss and acc of batch 65: 47.8414192199707, 1.0\n",
      "Train loss and acc of batch 66: 47.84141159057617, 1.0\n",
      "Train loss and acc of batch 67: 48.653865814208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.437095642089844, 0.984375\n",
      "Train loss and acc of batch 69: 48.05815124511719, 0.984375\n",
      "Train loss and acc of batch 70: 47.84137725830078, 1.0\n",
      "Training accuracy and loss of epoch #343: 0.9894, 48.1666\n",
      "Saved model by train loss 48.16659685591577\n",
      "Train loss and acc of batch 0: 47.841365814208984, 1.0\n",
      "Train loss and acc of batch 1: 47.84136199951172, 1.0\n",
      "Train loss and acc of batch 2: 48.12720489501953, 0.984375\n",
      "Train loss and acc of batch 3: 48.05810546875, 0.984375\n",
      "Train loss and acc of batch 4: 47.841331481933594, 1.0\n",
      "Train loss and acc of batch 5: 49.19024658203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.34392547607422, 0.96875\n",
      "Train loss and acc of batch 7: 47.84130096435547, 1.0\n",
      "Train loss and acc of batch 8: 48.43699645996094, 0.984375\n",
      "Train loss and acc of batch 9: 48.12713623046875, 0.984375\n",
      "Train loss and acc of batch 10: 47.84128189086914, 1.0\n",
      "Train loss and acc of batch 11: 47.841270446777344, 1.0\n",
      "Train loss and acc of batch 12: 48.594482421875, 0.984375\n",
      "Train loss and acc of batch 13: 48.058013916015625, 0.984375\n",
      "Train loss and acc of batch 14: 48.058006286621094, 0.984375\n",
      "Train loss and acc of batch 15: 48.43693542480469, 0.984375\n",
      "Train loss and acc of batch 16: 48.436927795410156, 0.984375\n",
      "Train loss and acc of batch 17: 48.59443664550781, 0.984375\n",
      "Train loss and acc of batch 18: 48.72276306152344, 0.96875\n",
      "Train loss and acc of batch 19: 47.84119415283203, 1.0\n",
      "Train loss and acc of batch 20: 47.841190338134766, 1.0\n",
      "Train loss and acc of batch 21: 48.43688201904297, 0.984375\n",
      "Train loss and acc of batch 22: 48.43687438964844, 0.984375\n",
      "Train loss and acc of batch 23: 47.84115982055664, 1.0\n",
      "Train loss and acc of batch 24: 48.436859130859375, 0.984375\n",
      "Train loss and acc of batch 25: 47.84114456176758, 1.0\n",
      "Train loss and acc of batch 26: 47.84113311767578, 1.0\n",
      "Train loss and acc of batch 27: 47.841129302978516, 1.0\n",
      "Train loss and acc of batch 28: 47.84111785888672, 1.0\n",
      "Train loss and acc of batch 29: 48.43681335449219, 0.984375\n",
      "Train loss and acc of batch 30: 47.84110641479492, 1.0\n",
      "Train loss and acc of batch 31: 48.05785369873047, 0.984375\n",
      "Train loss and acc of batch 32: 47.841087341308594, 1.0\n",
      "Train loss and acc of batch 33: 47.84107208251953, 1.0\n",
      "Train loss and acc of batch 34: 48.436767578125, 0.984375\n",
      "Train loss and acc of batch 35: 48.27458572387695, 0.96875\n",
      "Train loss and acc of batch 36: 47.84104537963867, 1.0\n",
      "Train loss and acc of batch 37: 48.594261169433594, 0.984375\n",
      "Train loss and acc of batch 38: 49.18995666503906, 0.96875\n",
      "Train loss and acc of batch 39: 48.05778503417969, 0.984375\n",
      "Train loss and acc of batch 40: 47.841007232666016, 1.0\n",
      "Train loss and acc of batch 41: 49.1899299621582, 0.96875\n",
      "Train loss and acc of batch 42: 47.84099197387695, 1.0\n",
      "Train loss and acc of batch 43: 48.43669128417969, 0.984375\n",
      "Train loss and acc of batch 44: 47.840972900390625, 1.0\n",
      "Train loss and acc of batch 45: 48.436668395996094, 0.984375\n",
      "Train loss and acc of batch 46: 48.126808166503906, 0.984375\n",
      "Train loss and acc of batch 47: 47.84095001220703, 1.0\n",
      "Train loss and acc of batch 48: 47.840938568115234, 1.0\n",
      "Train loss and acc of batch 49: 47.8409309387207, 1.0\n",
      "Train loss and acc of batch 50: 48.436622619628906, 0.984375\n",
      "Train loss and acc of batch 51: 49.18983459472656, 0.96875\n",
      "Train loss and acc of batch 52: 49.096744537353516, 0.953125\n",
      "Train loss and acc of batch 53: 47.84089660644531, 1.0\n",
      "Train loss and acc of batch 54: 48.057647705078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.84088134765625, 1.0\n",
      "Train loss and acc of batch 56: 47.84086608886719, 1.0\n",
      "Train loss and acc of batch 57: 48.436561584472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.840850830078125, 1.0\n",
      "Train loss and acc of batch 59: 47.840843200683594, 1.0\n",
      "Train loss and acc of batch 60: 47.84083557128906, 1.0\n",
      "Train loss and acc of batch 61: 47.840824127197266, 1.0\n",
      "Train loss and acc of batch 62: 47.84081268310547, 1.0\n",
      "Train loss and acc of batch 63: 49.032203674316406, 0.96875\n",
      "Train loss and acc of batch 64: 48.05756378173828, 0.984375\n",
      "Train loss and acc of batch 65: 47.84078598022461, 1.0\n",
      "Train loss and acc of batch 66: 47.84077835083008, 1.0\n",
      "Train loss and acc of batch 67: 48.65323257446289, 0.96875\n",
      "Train loss and acc of batch 68: 48.43646240234375, 0.984375\n",
      "Train loss and acc of batch 69: 48.05751037597656, 0.984375\n",
      "Train loss and acc of batch 70: 47.84074020385742, 1.0\n",
      "Training accuracy and loss of epoch #344: 0.9894, 48.1660\n",
      "Saved model by train loss 48.16596479818855\n",
      "Train loss and acc of batch 0: 47.84073257446289, 1.0\n",
      "Train loss and acc of batch 1: 47.840728759765625, 1.0\n",
      "Train loss and acc of batch 2: 48.126564025878906, 0.984375\n",
      "Train loss and acc of batch 3: 48.057472229003906, 0.984375\n",
      "Train loss and acc of batch 4: 47.8406982421875, 1.0\n",
      "Train loss and acc of batch 5: 49.189613342285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.343292236328125, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 7: 47.840667724609375, 1.0\n",
      "Train loss and acc of batch 8: 48.436363220214844, 0.984375\n",
      "Train loss and acc of batch 9: 48.126502990722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.84064865112305, 1.0\n",
      "Train loss and acc of batch 11: 47.84063720703125, 1.0\n",
      "Train loss and acc of batch 12: 48.59385299682617, 0.984375\n",
      "Train loss and acc of batch 13: 48.05738067626953, 0.984375\n",
      "Train loss and acc of batch 14: 48.057373046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.436302185058594, 0.984375\n",
      "Train loss and acc of batch 16: 48.43628692626953, 0.984375\n",
      "Train loss and acc of batch 17: 48.593807220458984, 0.984375\n",
      "Train loss and acc of batch 18: 48.72212600708008, 0.96875\n",
      "Train loss and acc of batch 19: 47.8405647277832, 1.0\n",
      "Train loss and acc of batch 20: 47.840553283691406, 1.0\n",
      "Train loss and acc of batch 21: 48.436248779296875, 0.984375\n",
      "Train loss and acc of batch 22: 48.436241149902344, 0.984375\n",
      "Train loss and acc of batch 23: 47.84053039550781, 1.0\n",
      "Train loss and acc of batch 24: 48.43621826171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.84050750732422, 1.0\n",
      "Train loss and acc of batch 26: 47.84050369262695, 1.0\n",
      "Train loss and acc of batch 27: 47.840492248535156, 1.0\n",
      "Train loss and acc of batch 28: 47.840484619140625, 1.0\n",
      "Train loss and acc of batch 29: 48.436180114746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.8404655456543, 1.0\n",
      "Train loss and acc of batch 31: 48.057220458984375, 0.984375\n",
      "Train loss and acc of batch 32: 47.840450286865234, 1.0\n",
      "Train loss and acc of batch 33: 47.84043884277344, 1.0\n",
      "Train loss and acc of batch 34: 48.436134338378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.27394485473633, 0.96875\n",
      "Train loss and acc of batch 36: 47.84041213989258, 1.0\n",
      "Train loss and acc of batch 37: 48.593624114990234, 0.984375\n",
      "Train loss and acc of batch 38: 49.18932342529297, 0.96875\n",
      "Train loss and acc of batch 39: 48.057151794433594, 0.984375\n",
      "Train loss and acc of batch 40: 47.84038162231445, 1.0\n",
      "Train loss and acc of batch 41: 49.189292907714844, 0.96875\n",
      "Train loss and acc of batch 42: 47.84035873413086, 1.0\n",
      "Train loss and acc of batch 43: 48.43605041503906, 0.984375\n",
      "Train loss and acc of batch 44: 47.84033966064453, 1.0\n",
      "Train loss and acc of batch 45: 48.43603515625, 0.984375\n",
      "Train loss and acc of batch 46: 48.126182556152344, 0.984375\n",
      "Train loss and acc of batch 47: 47.84031295776367, 1.0\n",
      "Train loss and acc of batch 48: 47.840309143066406, 1.0\n",
      "Train loss and acc of batch 49: 47.84029769897461, 1.0\n",
      "Train loss and acc of batch 50: 48.43598937988281, 0.984375\n",
      "Train loss and acc of batch 51: 49.18920135498047, 0.96875\n",
      "Train loss and acc of batch 52: 49.096107482910156, 0.953125\n",
      "Train loss and acc of batch 53: 47.84025955200195, 1.0\n",
      "Train loss and acc of batch 54: 48.05701446533203, 0.984375\n",
      "Train loss and acc of batch 55: 47.84024429321289, 1.0\n",
      "Train loss and acc of batch 56: 47.84023666381836, 1.0\n",
      "Train loss and acc of batch 57: 48.43592834472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.840213775634766, 1.0\n",
      "Train loss and acc of batch 59: 47.8402099609375, 1.0\n",
      "Train loss and acc of batch 60: 47.84020233154297, 1.0\n",
      "Train loss and acc of batch 61: 47.84019088745117, 1.0\n",
      "Train loss and acc of batch 62: 47.84018325805664, 1.0\n",
      "Train loss and acc of batch 63: 49.031578063964844, 0.96875\n",
      "Train loss and acc of batch 64: 48.05693054199219, 0.984375\n",
      "Train loss and acc of batch 65: 47.840152740478516, 1.0\n",
      "Train loss and acc of batch 66: 47.84014892578125, 1.0\n",
      "Train loss and acc of batch 67: 48.65260314941406, 0.96875\n",
      "Train loss and acc of batch 68: 48.435829162597656, 0.984375\n",
      "Train loss and acc of batch 69: 48.056884765625, 0.984375\n",
      "Train loss and acc of batch 70: 47.840110778808594, 1.0\n",
      "Training accuracy and loss of epoch #345: 0.9894, 48.1653\n",
      "Saved model by train loss 48.1653312898018\n",
      "Train loss and acc of batch 0: 47.8400993347168, 1.0\n",
      "Train loss and acc of batch 1: 47.840087890625, 1.0\n",
      "Train loss and acc of batch 2: 48.125938415527344, 0.984375\n",
      "Train loss and acc of batch 3: 48.05683898925781, 0.984375\n",
      "Train loss and acc of batch 4: 47.840065002441406, 1.0\n",
      "Train loss and acc of batch 5: 49.18898010253906, 0.96875\n",
      "Train loss and acc of batch 6: 48.34266662597656, 0.96875\n",
      "Train loss and acc of batch 7: 47.84004211425781, 1.0\n",
      "Train loss and acc of batch 8: 48.43573760986328, 0.984375\n",
      "Train loss and acc of batch 9: 48.12586975097656, 0.984375\n",
      "Train loss and acc of batch 10: 47.84001159667969, 1.0\n",
      "Train loss and acc of batch 11: 47.84000015258789, 1.0\n",
      "Train loss and acc of batch 12: 48.593223571777344, 0.984375\n",
      "Train loss and acc of batch 13: 48.05674743652344, 0.984375\n",
      "Train loss and acc of batch 14: 48.056739807128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.4356689453125, 0.984375\n",
      "Train loss and acc of batch 16: 48.43566131591797, 0.984375\n",
      "Train loss and acc of batch 17: 48.59317398071289, 0.984375\n",
      "Train loss and acc of batch 18: 48.721492767333984, 0.96875\n",
      "Train loss and acc of batch 19: 47.83993148803711, 1.0\n",
      "Train loss and acc of batch 20: 47.839927673339844, 1.0\n",
      "Train loss and acc of batch 21: 48.43561553955078, 0.984375\n",
      "Train loss and acc of batch 22: 48.43560791015625, 0.984375\n",
      "Train loss and acc of batch 23: 47.83989715576172, 1.0\n",
      "Train loss and acc of batch 24: 48.435585021972656, 0.984375\n",
      "Train loss and acc of batch 25: 47.839881896972656, 1.0\n",
      "Train loss and acc of batch 26: 47.839866638183594, 1.0\n",
      "Train loss and acc of batch 27: 47.83986282348633, 1.0\n",
      "Train loss and acc of batch 28: 47.83985137939453, 1.0\n",
      "Train loss and acc of batch 29: 48.435546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.8398323059082, 1.0\n",
      "Train loss and acc of batch 31: 48.05659484863281, 0.984375\n",
      "Train loss and acc of batch 32: 47.839813232421875, 1.0\n",
      "Train loss and acc of batch 33: 47.83980941772461, 1.0\n",
      "Train loss and acc of batch 34: 48.43550109863281, 0.984375\n",
      "Train loss and acc of batch 35: 48.27332305908203, 0.96875\n",
      "Train loss and acc of batch 36: 47.839778900146484, 1.0\n",
      "Train loss and acc of batch 37: 48.59299850463867, 0.984375\n",
      "Train loss and acc of batch 38: 49.188690185546875, 0.96875\n",
      "Train loss and acc of batch 39: 48.0565185546875, 0.984375\n",
      "Train loss and acc of batch 40: 47.83974838256836, 1.0\n",
      "Train loss and acc of batch 41: 49.188663482666016, 0.96875\n",
      "Train loss and acc of batch 42: 47.839725494384766, 1.0\n",
      "Train loss and acc of batch 43: 48.43541717529297, 0.984375\n",
      "Train loss and acc of batch 44: 47.83970642089844, 1.0\n",
      "Train loss and acc of batch 45: 48.435401916503906, 0.984375\n",
      "Train loss and acc of batch 46: 48.12554931640625, 0.984375\n",
      "Train loss and acc of batch 47: 47.839683532714844, 1.0\n",
      "Train loss and acc of batch 48: 47.83967590332031, 1.0\n",
      "Train loss and acc of batch 49: 47.83966827392578, 1.0\n",
      "Train loss and acc of batch 50: 48.43536376953125, 0.984375\n",
      "Train loss and acc of batch 51: 49.188575744628906, 0.96875\n",
      "Train loss and acc of batch 52: 49.09547805786133, 0.953125\n",
      "Train loss and acc of batch 53: 47.839630126953125, 1.0\n",
      "Train loss and acc of batch 54: 48.05638122558594, 0.984375\n",
      "Train loss and acc of batch 55: 47.8396110534668, 1.0\n",
      "Train loss and acc of batch 56: 47.839603424072266, 1.0\n",
      "Train loss and acc of batch 57: 48.435302734375, 0.984375\n",
      "Train loss and acc of batch 58: 47.83958435058594, 1.0\n",
      "Train loss and acc of batch 59: 47.839576721191406, 1.0\n",
      "Train loss and acc of batch 60: 47.83956527709961, 1.0\n",
      "Train loss and acc of batch 61: 47.83955764770508, 1.0\n",
      "Train loss and acc of batch 62: 47.83955001831055, 1.0\n",
      "Train loss and acc of batch 63: 49.03094482421875, 0.96875\n",
      "Train loss and acc of batch 64: 48.056297302246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.83952331542969, 1.0\n",
      "Train loss and acc of batch 66: 47.839515686035156, 1.0\n",
      "Train loss and acc of batch 67: 48.6519660949707, 0.96875\n",
      "Train loss and acc of batch 68: 48.435203552246094, 0.984375\n",
      "Train loss and acc of batch 69: 48.056251525878906, 0.984375\n",
      "Train loss and acc of batch 70: 47.8394775390625, 1.0\n",
      "Training accuracy and loss of epoch #346: 0.9894, 48.1647\n",
      "Saved model by train loss 48.16469971562775\n",
      "Train loss and acc of batch 0: 47.839473724365234, 1.0\n",
      "Train loss and acc of batch 1: 47.83946228027344, 1.0\n",
      "Train loss and acc of batch 2: 48.12530517578125, 0.984375\n",
      "Train loss and acc of batch 3: 48.05621337890625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 4: 47.83943176269531, 1.0\n",
      "Train loss and acc of batch 5: 49.1883544921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.34203338623047, 0.96875\n",
      "Train loss and acc of batch 7: 47.839412689208984, 1.0\n",
      "Train loss and acc of batch 8: 48.435096740722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.125244140625, 0.984375\n",
      "Train loss and acc of batch 10: 47.839378356933594, 1.0\n",
      "Train loss and acc of batch 11: 47.83937454223633, 1.0\n",
      "Train loss and acc of batch 12: 48.59259033203125, 0.984375\n",
      "Train loss and acc of batch 13: 48.056114196777344, 0.984375\n",
      "Train loss and acc of batch 14: 48.056114196777344, 0.984375\n",
      "Train loss and acc of batch 15: 48.43504333496094, 0.984375\n",
      "Train loss and acc of batch 16: 48.435028076171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.59253692626953, 0.984375\n",
      "Train loss and acc of batch 18: 48.720863342285156, 0.96875\n",
      "Train loss and acc of batch 19: 47.839298248291016, 1.0\n",
      "Train loss and acc of batch 20: 47.83929443359375, 1.0\n",
      "Train loss and acc of batch 21: 48.43498229980469, 0.984375\n",
      "Train loss and acc of batch 22: 48.434974670410156, 0.984375\n",
      "Train loss and acc of batch 23: 47.83926773071289, 1.0\n",
      "Train loss and acc of batch 24: 48.434959411621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.83924865722656, 1.0\n",
      "Train loss and acc of batch 26: 47.83924102783203, 1.0\n",
      "Train loss and acc of batch 27: 47.83922576904297, 1.0\n",
      "Train loss and acc of batch 28: 47.8392219543457, 1.0\n",
      "Train loss and acc of batch 29: 48.434913635253906, 0.984375\n",
      "Train loss and acc of batch 30: 47.83920669555664, 1.0\n",
      "Train loss and acc of batch 31: 48.05596160888672, 0.984375\n",
      "Train loss and acc of batch 32: 47.83917999267578, 1.0\n",
      "Train loss and acc of batch 33: 47.83917236328125, 1.0\n",
      "Train loss and acc of batch 34: 48.43486785888672, 0.984375\n",
      "Train loss and acc of batch 35: 48.27268981933594, 0.96875\n",
      "Train loss and acc of batch 36: 47.83915328979492, 1.0\n",
      "Train loss and acc of batch 37: 48.59236526489258, 0.984375\n",
      "Train loss and acc of batch 38: 49.18805694580078, 0.96875\n",
      "Train loss and acc of batch 39: 48.055885314941406, 0.984375\n",
      "Train loss and acc of batch 40: 47.839115142822266, 1.0\n",
      "Train loss and acc of batch 41: 49.18803024291992, 0.96875\n",
      "Train loss and acc of batch 42: 47.8390998840332, 1.0\n",
      "Train loss and acc of batch 43: 48.434791564941406, 0.984375\n",
      "Train loss and acc of batch 44: 47.839080810546875, 1.0\n",
      "Train loss and acc of batch 45: 48.43476867675781, 0.984375\n",
      "Train loss and acc of batch 46: 48.124908447265625, 0.984375\n",
      "Train loss and acc of batch 47: 47.83905029296875, 1.0\n",
      "Train loss and acc of batch 48: 47.83904266357422, 1.0\n",
      "Train loss and acc of batch 49: 47.83903503417969, 1.0\n",
      "Train loss and acc of batch 50: 48.434722900390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.18794250488281, 0.96875\n",
      "Train loss and acc of batch 52: 49.0948486328125, 0.953125\n",
      "Train loss and acc of batch 53: 47.83899688720703, 1.0\n",
      "Train loss and acc of batch 54: 48.055747985839844, 0.984375\n",
      "Train loss and acc of batch 55: 47.83898162841797, 1.0\n",
      "Train loss and acc of batch 56: 47.83897018432617, 1.0\n",
      "Train loss and acc of batch 57: 48.434661865234375, 0.984375\n",
      "Train loss and acc of batch 58: 47.838958740234375, 1.0\n",
      "Train loss and acc of batch 59: 47.83894729614258, 1.0\n",
      "Train loss and acc of batch 60: 47.83893585205078, 1.0\n",
      "Train loss and acc of batch 61: 47.83892822265625, 1.0\n",
      "Train loss and acc of batch 62: 47.83891677856445, 1.0\n",
      "Train loss and acc of batch 63: 49.030311584472656, 0.96875\n",
      "Train loss and acc of batch 64: 48.0556640625, 0.984375\n",
      "Train loss and acc of batch 65: 47.83889389038086, 1.0\n",
      "Train loss and acc of batch 66: 47.8388786315918, 1.0\n",
      "Train loss and acc of batch 67: 48.65134048461914, 0.96875\n",
      "Train loss and acc of batch 68: 48.43456268310547, 0.984375\n",
      "Train loss and acc of batch 69: 48.05561828613281, 0.984375\n",
      "Train loss and acc of batch 70: 47.83884811401367, 1.0\n",
      "Training accuracy and loss of epoch #347: 0.9894, 48.1641\n",
      "Saved model by train loss 48.164068141453704\n",
      "Train loss and acc of batch 0: 47.83884048461914, 1.0\n",
      "Train loss and acc of batch 1: 47.838829040527344, 1.0\n",
      "Train loss and acc of batch 2: 48.124671936035156, 0.984375\n",
      "Train loss and acc of batch 3: 48.055572509765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.83879852294922, 1.0\n",
      "Train loss and acc of batch 5: 49.187713623046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.341400146484375, 0.96875\n",
      "Train loss and acc of batch 7: 47.838775634765625, 1.0\n",
      "Train loss and acc of batch 8: 48.434471130371094, 0.984375\n",
      "Train loss and acc of batch 9: 48.124610900878906, 0.984375\n",
      "Train loss and acc of batch 10: 47.838748931884766, 1.0\n",
      "Train loss and acc of batch 11: 47.838741302490234, 1.0\n",
      "Train loss and acc of batch 12: 48.59195327758789, 0.984375\n",
      "Train loss and acc of batch 13: 48.05548858642578, 0.984375\n",
      "Train loss and acc of batch 14: 48.05548095703125, 0.984375\n",
      "Train loss and acc of batch 15: 48.434410095214844, 0.984375\n",
      "Train loss and acc of batch 16: 48.43440246582031, 0.984375\n",
      "Train loss and acc of batch 17: 48.59191131591797, 0.984375\n",
      "Train loss and acc of batch 18: 48.7202262878418, 0.96875\n",
      "Train loss and acc of batch 19: 47.83866882324219, 1.0\n",
      "Train loss and acc of batch 20: 47.838661193847656, 1.0\n",
      "Train loss and acc of batch 21: 48.434349060058594, 0.984375\n",
      "Train loss and acc of batch 22: 48.43434143066406, 0.984375\n",
      "Train loss and acc of batch 23: 47.8386344909668, 1.0\n",
      "Train loss and acc of batch 24: 48.434326171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.838619232177734, 1.0\n",
      "Train loss and acc of batch 26: 47.83860397338867, 1.0\n",
      "Train loss and acc of batch 27: 47.838600158691406, 1.0\n",
      "Train loss and acc of batch 28: 47.83858871459961, 1.0\n",
      "Train loss and acc of batch 29: 48.434288024902344, 0.984375\n",
      "Train loss and acc of batch 30: 47.83857345581055, 1.0\n",
      "Train loss and acc of batch 31: 48.055328369140625, 0.984375\n",
      "Train loss and acc of batch 32: 47.83855438232422, 1.0\n",
      "Train loss and acc of batch 33: 47.83854675292969, 1.0\n",
      "Train loss and acc of batch 34: 48.434242248535156, 0.984375\n",
      "Train loss and acc of batch 35: 48.27205276489258, 0.96875\n",
      "Train loss and acc of batch 36: 47.83851623535156, 1.0\n",
      "Train loss and acc of batch 37: 48.591732025146484, 0.984375\n",
      "Train loss and acc of batch 38: 49.18742370605469, 0.96875\n",
      "Train loss and acc of batch 39: 48.055259704589844, 0.984375\n",
      "Train loss and acc of batch 40: 47.83848190307617, 1.0\n",
      "Train loss and acc of batch 41: 49.187400817871094, 0.96875\n",
      "Train loss and acc of batch 42: 47.83846664428711, 1.0\n",
      "Train loss and acc of batch 43: 48.43415832519531, 0.984375\n",
      "Train loss and acc of batch 44: 47.83844757080078, 1.0\n",
      "Train loss and acc of batch 45: 48.43414306640625, 0.984375\n",
      "Train loss and acc of batch 46: 48.12427520751953, 0.984375\n",
      "Train loss and acc of batch 47: 47.838417053222656, 1.0\n",
      "Train loss and acc of batch 48: 47.838409423828125, 1.0\n",
      "Train loss and acc of batch 49: 47.83839797973633, 1.0\n",
      "Train loss and acc of batch 50: 48.43409729003906, 0.984375\n",
      "Train loss and acc of batch 51: 49.18730926513672, 0.96875\n",
      "Train loss and acc of batch 52: 49.094215393066406, 0.953125\n",
      "Train loss and acc of batch 53: 47.8383674621582, 1.0\n",
      "Train loss and acc of batch 54: 48.05512237548828, 0.984375\n",
      "Train loss and acc of batch 55: 47.838348388671875, 1.0\n",
      "Train loss and acc of batch 56: 47.838340759277344, 1.0\n",
      "Train loss and acc of batch 57: 48.43403625488281, 0.984375\n",
      "Train loss and acc of batch 58: 47.83832550048828, 1.0\n",
      "Train loss and acc of batch 59: 47.83831024169922, 1.0\n",
      "Train loss and acc of batch 60: 47.83830642700195, 1.0\n",
      "Train loss and acc of batch 61: 47.838294982910156, 1.0\n",
      "Train loss and acc of batch 62: 47.83829116821289, 1.0\n",
      "Train loss and acc of batch 63: 49.0296745300293, 0.96875\n",
      "Train loss and acc of batch 64: 48.05503845214844, 0.984375\n",
      "Train loss and acc of batch 65: 47.8382568359375, 1.0\n",
      "Train loss and acc of batch 66: 47.838253021240234, 1.0\n",
      "Train loss and acc of batch 67: 48.65071105957031, 0.96875\n",
      "Train loss and acc of batch 68: 48.433929443359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.05498504638672, 0.984375\n",
      "Train loss and acc of batch 70: 47.838218688964844, 1.0\n",
      "Training accuracy and loss of epoch #348: 0.9894, 48.1634\n",
      "Saved model by train loss 48.163436459823394\n",
      "Train loss and acc of batch 0: 47.83820724487305, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 1: 47.838199615478516, 1.0\n",
      "Train loss and acc of batch 2: 48.12403869628906, 0.984375\n",
      "Train loss and acc of batch 3: 48.05494689941406, 0.984375\n",
      "Train loss and acc of batch 4: 47.838172912597656, 1.0\n",
      "Train loss and acc of batch 5: 49.18708038330078, 0.96875\n",
      "Train loss and acc of batch 6: 48.34076690673828, 0.96875\n",
      "Train loss and acc of batch 7: 47.8381462097168, 1.0\n",
      "Train loss and acc of batch 8: 48.433837890625, 0.984375\n",
      "Train loss and acc of batch 9: 48.12397766113281, 0.984375\n",
      "Train loss and acc of batch 10: 47.83811950683594, 1.0\n",
      "Train loss and acc of batch 11: 47.838104248046875, 1.0\n",
      "Train loss and acc of batch 12: 48.59132385253906, 0.984375\n",
      "Train loss and acc of batch 13: 48.05486297607422, 0.984375\n",
      "Train loss and acc of batch 14: 48.054847717285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.43377685546875, 0.984375\n",
      "Train loss and acc of batch 16: 48.43376922607422, 0.984375\n",
      "Train loss and acc of batch 17: 48.59128189086914, 0.984375\n",
      "Train loss and acc of batch 18: 48.719600677490234, 0.96875\n",
      "Train loss and acc of batch 19: 47.838035583496094, 1.0\n",
      "Train loss and acc of batch 20: 47.83803176879883, 1.0\n",
      "Train loss and acc of batch 21: 48.4337158203125, 0.984375\n",
      "Train loss and acc of batch 22: 48.4337158203125, 0.984375\n",
      "Train loss and acc of batch 23: 47.8380012512207, 1.0\n",
      "Train loss and acc of batch 24: 48.43370056152344, 0.984375\n",
      "Train loss and acc of batch 25: 47.837982177734375, 1.0\n",
      "Train loss and acc of batch 26: 47.837974548339844, 1.0\n",
      "Train loss and acc of batch 27: 47.83796691894531, 1.0\n",
      "Train loss and acc of batch 28: 47.83795928955078, 1.0\n",
      "Train loss and acc of batch 29: 48.43364715576172, 0.984375\n",
      "Train loss and acc of batch 30: 47.83794021606445, 1.0\n",
      "Train loss and acc of batch 31: 48.05469512939453, 0.984375\n",
      "Train loss and acc of batch 32: 47.83792495727539, 1.0\n",
      "Train loss and acc of batch 33: 47.83790969848633, 1.0\n",
      "Train loss and acc of batch 34: 48.43360900878906, 0.984375\n",
      "Train loss and acc of batch 35: 48.27142333984375, 0.96875\n",
      "Train loss and acc of batch 36: 47.837886810302734, 1.0\n",
      "Train loss and acc of batch 37: 48.59109878540039, 0.984375\n",
      "Train loss and acc of batch 38: 49.186798095703125, 0.96875\n",
      "Train loss and acc of batch 39: 48.05462646484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.837852478027344, 1.0\n",
      "Train loss and acc of batch 41: 49.186767578125, 0.96875\n",
      "Train loss and acc of batch 42: 47.83783721923828, 1.0\n",
      "Train loss and acc of batch 43: 48.43352508544922, 0.984375\n",
      "Train loss and acc of batch 44: 47.83781051635742, 1.0\n",
      "Train loss and acc of batch 45: 48.433509826660156, 0.984375\n",
      "Train loss and acc of batch 46: 48.12364959716797, 0.984375\n",
      "Train loss and acc of batch 47: 47.83778762817383, 1.0\n",
      "Train loss and acc of batch 48: 47.83778762817383, 1.0\n",
      "Train loss and acc of batch 49: 47.8377685546875, 1.0\n",
      "Train loss and acc of batch 50: 48.43346405029297, 0.984375\n",
      "Train loss and acc of batch 51: 49.186683654785156, 0.96875\n",
      "Train loss and acc of batch 52: 49.093589782714844, 0.953125\n",
      "Train loss and acc of batch 53: 47.837738037109375, 1.0\n",
      "Train loss and acc of batch 54: 48.05448913574219, 0.984375\n",
      "Train loss and acc of batch 55: 47.83771896362305, 1.0\n",
      "Train loss and acc of batch 56: 47.837711334228516, 1.0\n",
      "Train loss and acc of batch 57: 48.43340301513672, 0.984375\n",
      "Train loss and acc of batch 58: 47.83769607543945, 1.0\n",
      "Train loss and acc of batch 59: 47.837684631347656, 1.0\n",
      "Train loss and acc of batch 60: 47.83767318725586, 1.0\n",
      "Train loss and acc of batch 61: 47.83766555786133, 1.0\n",
      "Train loss and acc of batch 62: 47.83766174316406, 1.0\n",
      "Train loss and acc of batch 63: 49.029048919677734, 0.96875\n",
      "Train loss and acc of batch 64: 48.05439758300781, 0.984375\n",
      "Train loss and acc of batch 65: 47.8376350402832, 1.0\n",
      "Train loss and acc of batch 66: 47.83761978149414, 1.0\n",
      "Train loss and acc of batch 67: 48.65007781982422, 0.96875\n",
      "Train loss and acc of batch 68: 48.43330383300781, 0.984375\n",
      "Train loss and acc of batch 69: 48.054359436035156, 0.984375\n",
      "Train loss and acc of batch 70: 47.83758544921875, 1.0\n",
      "Training accuracy and loss of epoch #349: 0.9894, 48.1628\n",
      "Saved model by train loss 48.16280574529943\n",
      "Train loss and acc of batch 0: 47.83757400512695, 1.0\n",
      "Train loss and acc of batch 1: 47.837562561035156, 1.0\n",
      "Train loss and acc of batch 2: 48.1234130859375, 0.984375\n",
      "Train loss and acc of batch 3: 48.05431365966797, 0.984375\n",
      "Train loss and acc of batch 4: 47.83753967285156, 1.0\n",
      "Train loss and acc of batch 5: 49.18646240234375, 0.96875\n",
      "Train loss and acc of batch 6: 48.34014129638672, 0.96875\n",
      "Train loss and acc of batch 7: 47.8375129699707, 1.0\n",
      "Train loss and acc of batch 8: 48.43321228027344, 0.984375\n",
      "Train loss and acc of batch 9: 48.12335205078125, 0.984375\n",
      "Train loss and acc of batch 10: 47.837486267089844, 1.0\n",
      "Train loss and acc of batch 11: 47.83747863769531, 1.0\n",
      "Train loss and acc of batch 12: 48.590694427490234, 0.984375\n",
      "Train loss and acc of batch 13: 48.054222106933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.05421447753906, 0.984375\n",
      "Train loss and acc of batch 15: 48.433143615722656, 0.984375\n",
      "Train loss and acc of batch 16: 48.433135986328125, 0.984375\n",
      "Train loss and acc of batch 17: 48.59064865112305, 0.984375\n",
      "Train loss and acc of batch 18: 48.71896743774414, 0.96875\n",
      "Train loss and acc of batch 19: 47.83740997314453, 1.0\n",
      "Train loss and acc of batch 20: 47.837398529052734, 1.0\n",
      "Train loss and acc of batch 21: 48.43309020996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.433082580566406, 0.984375\n",
      "Train loss and acc of batch 23: 47.837371826171875, 1.0\n",
      "Train loss and acc of batch 24: 48.43305969238281, 0.984375\n",
      "Train loss and acc of batch 25: 47.83735656738281, 1.0\n",
      "Train loss and acc of batch 26: 47.837345123291016, 1.0\n",
      "Train loss and acc of batch 27: 47.83734130859375, 1.0\n",
      "Train loss and acc of batch 28: 47.83732223510742, 1.0\n",
      "Train loss and acc of batch 29: 48.433013916015625, 0.984375\n",
      "Train loss and acc of batch 30: 47.83730697631836, 1.0\n",
      "Train loss and acc of batch 31: 48.05406951904297, 0.984375\n",
      "Train loss and acc of batch 32: 47.8372917175293, 1.0\n",
      "Train loss and acc of batch 33: 47.83728790283203, 1.0\n",
      "Train loss and acc of batch 34: 48.43297576904297, 0.984375\n",
      "Train loss and acc of batch 35: 48.270790100097656, 0.96875\n",
      "Train loss and acc of batch 36: 47.837257385253906, 1.0\n",
      "Train loss and acc of batch 37: 48.59047317504883, 0.984375\n",
      "Train loss and acc of batch 38: 49.1861572265625, 0.96875\n",
      "Train loss and acc of batch 39: 48.05400085449219, 0.984375\n",
      "Train loss and acc of batch 40: 47.83721923828125, 1.0\n",
      "Train loss and acc of batch 41: 49.18614196777344, 0.96875\n",
      "Train loss and acc of batch 42: 47.83720016479492, 1.0\n",
      "Train loss and acc of batch 43: 48.432891845703125, 0.984375\n",
      "Train loss and acc of batch 44: 47.83718490600586, 1.0\n",
      "Train loss and acc of batch 45: 48.43287658691406, 0.984375\n",
      "Train loss and acc of batch 46: 48.123016357421875, 0.984375\n",
      "Train loss and acc of batch 47: 47.837158203125, 1.0\n",
      "Train loss and acc of batch 48: 47.83715057373047, 1.0\n",
      "Train loss and acc of batch 49: 47.83713912963867, 1.0\n",
      "Train loss and acc of batch 50: 48.432830810546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.18604278564453, 0.96875\n",
      "Train loss and acc of batch 52: 49.092952728271484, 0.953125\n",
      "Train loss and acc of batch 53: 47.83710861206055, 1.0\n",
      "Train loss and acc of batch 54: 48.053863525390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.83708953857422, 1.0\n",
      "Train loss and acc of batch 56: 47.83707809448242, 1.0\n",
      "Train loss and acc of batch 57: 48.432769775390625, 0.984375\n",
      "Train loss and acc of batch 58: 47.83706283569336, 1.0\n",
      "Train loss and acc of batch 59: 47.83705139160156, 1.0\n",
      "Train loss and acc of batch 60: 47.83704376220703, 1.0\n",
      "Train loss and acc of batch 61: 47.8370361328125, 1.0\n",
      "Train loss and acc of batch 62: 47.83702087402344, 1.0\n",
      "Train loss and acc of batch 63: 49.028419494628906, 0.96875\n",
      "Train loss and acc of batch 64: 48.05377197265625, 0.984375\n",
      "Train loss and acc of batch 65: 47.836997985839844, 1.0\n",
      "Train loss and acc of batch 66: 47.83698654174805, 1.0\n",
      "Train loss and acc of batch 67: 48.64944839477539, 0.96875\n",
      "Train loss and acc of batch 68: 48.43267059326172, 0.984375\n",
      "Train loss and acc of batch 69: 48.05372619628906, 0.984375\n",
      "Train loss and acc of batch 70: 47.83695983886719, 1.0\n",
      "Training accuracy and loss of epoch #350: 0.9894, 48.1622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.16217449349417\n",
      "Train loss and acc of batch 0: 47.83694076538086, 1.0\n",
      "Train loss and acc of batch 1: 47.836936950683594, 1.0\n",
      "Train loss and acc of batch 2: 48.122779846191406, 0.984375\n",
      "Train loss and acc of batch 3: 48.053680419921875, 0.984375\n",
      "Train loss and acc of batch 4: 47.836910247802734, 1.0\n",
      "Train loss and acc of batch 5: 49.185821533203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.339508056640625, 0.96875\n",
      "Train loss and acc of batch 7: 47.83688735961914, 1.0\n",
      "Train loss and acc of batch 8: 48.43257141113281, 0.984375\n",
      "Train loss and acc of batch 9: 48.122711181640625, 0.984375\n",
      "Train loss and acc of batch 10: 47.836856842041016, 1.0\n",
      "Train loss and acc of batch 11: 47.83684539794922, 1.0\n",
      "Train loss and acc of batch 12: 48.59006118774414, 0.984375\n",
      "Train loss and acc of batch 13: 48.05359649658203, 0.984375\n",
      "Train loss and acc of batch 14: 48.05358123779297, 0.984375\n",
      "Train loss and acc of batch 15: 48.43251037597656, 0.984375\n",
      "Train loss and acc of batch 16: 48.43250274658203, 0.984375\n",
      "Train loss and acc of batch 17: 48.59001922607422, 0.984375\n",
      "Train loss and acc of batch 18: 48.71834182739258, 0.96875\n",
      "Train loss and acc of batch 19: 47.836769104003906, 1.0\n",
      "Train loss and acc of batch 20: 47.83676528930664, 1.0\n",
      "Train loss and acc of batch 21: 48.432464599609375, 0.984375\n",
      "Train loss and acc of batch 22: 48.43244934082031, 0.984375\n",
      "Train loss and acc of batch 23: 47.836734771728516, 1.0\n",
      "Train loss and acc of batch 24: 48.43243408203125, 0.984375\n",
      "Train loss and acc of batch 25: 47.83671951293945, 1.0\n",
      "Train loss and acc of batch 26: 47.83671569824219, 1.0\n",
      "Train loss and acc of batch 27: 47.836708068847656, 1.0\n",
      "Train loss and acc of batch 28: 47.83669662475586, 1.0\n",
      "Train loss and acc of batch 29: 48.43238830566406, 0.984375\n",
      "Train loss and acc of batch 30: 47.83667755126953, 1.0\n",
      "Train loss and acc of batch 31: 48.053428649902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.8366584777832, 1.0\n",
      "Train loss and acc of batch 33: 47.83665084838867, 1.0\n",
      "Train loss and acc of batch 34: 48.432342529296875, 0.984375\n",
      "Train loss and acc of batch 35: 48.270164489746094, 0.96875\n",
      "Train loss and acc of batch 36: 47.83662414550781, 1.0\n",
      "Train loss and acc of batch 37: 48.58983612060547, 0.984375\n",
      "Train loss and acc of batch 38: 49.18553161621094, 0.96875\n",
      "Train loss and acc of batch 39: 48.05335998535156, 0.984375\n",
      "Train loss and acc of batch 40: 47.83658981323242, 1.0\n",
      "Train loss and acc of batch 41: 49.18550491333008, 0.96875\n",
      "Train loss and acc of batch 42: 47.836570739746094, 1.0\n",
      "Train loss and acc of batch 43: 48.43226623535156, 0.984375\n",
      "Train loss and acc of batch 44: 47.836551666259766, 1.0\n",
      "Train loss and acc of batch 45: 48.43224334716797, 0.984375\n",
      "Train loss and acc of batch 46: 48.12238311767578, 0.984375\n",
      "Train loss and acc of batch 47: 47.83652877807617, 1.0\n",
      "Train loss and acc of batch 48: 47.836517333984375, 1.0\n",
      "Train loss and acc of batch 49: 47.836509704589844, 1.0\n",
      "Train loss and acc of batch 50: 48.43219757080078, 0.984375\n",
      "Train loss and acc of batch 51: 49.18540954589844, 0.96875\n",
      "Train loss and acc of batch 52: 49.092323303222656, 0.953125\n",
      "Train loss and acc of batch 53: 47.83647155761719, 1.0\n",
      "Train loss and acc of batch 54: 48.05323028564453, 0.984375\n",
      "Train loss and acc of batch 55: 47.836456298828125, 1.0\n",
      "Train loss and acc of batch 56: 47.83644485473633, 1.0\n",
      "Train loss and acc of batch 57: 48.43214416503906, 0.984375\n",
      "Train loss and acc of batch 58: 47.836429595947266, 1.0\n",
      "Train loss and acc of batch 59: 47.83641815185547, 1.0\n",
      "Train loss and acc of batch 60: 47.83640670776367, 1.0\n",
      "Train loss and acc of batch 61: 47.836402893066406, 1.0\n",
      "Train loss and acc of batch 62: 47.83639144897461, 1.0\n",
      "Train loss and acc of batch 63: 49.02779006958008, 0.96875\n",
      "Train loss and acc of batch 64: 48.05314636230469, 0.984375\n",
      "Train loss and acc of batch 65: 47.836368560791016, 1.0\n",
      "Train loss and acc of batch 66: 47.83635711669922, 1.0\n",
      "Train loss and acc of batch 67: 48.6488151550293, 0.96875\n",
      "Train loss and acc of batch 68: 48.432037353515625, 0.984375\n",
      "Train loss and acc of batch 69: 48.0531005859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.83631896972656, 1.0\n",
      "Training accuracy and loss of epoch #351: 0.9894, 48.1615\n",
      "Saved model by train loss 48.16154238203882\n",
      "Train loss and acc of batch 0: 47.8363151550293, 1.0\n",
      "Train loss and acc of batch 1: 47.8363037109375, 1.0\n",
      "Train loss and acc of batch 2: 48.122154235839844, 0.984375\n",
      "Train loss and acc of batch 3: 48.05304718017578, 0.984375\n",
      "Train loss and acc of batch 4: 47.83627700805664, 1.0\n",
      "Train loss and acc of batch 5: 49.18519592285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.3388786315918, 0.96875\n",
      "Train loss and acc of batch 7: 47.83625030517578, 1.0\n",
      "Train loss and acc of batch 8: 48.43194580078125, 0.984375\n",
      "Train loss and acc of batch 9: 48.12208557128906, 0.984375\n",
      "Train loss and acc of batch 10: 47.836219787597656, 1.0\n",
      "Train loss and acc of batch 11: 47.83621597290039, 1.0\n",
      "Train loss and acc of batch 12: 48.58943176269531, 0.984375\n",
      "Train loss and acc of batch 13: 48.05296325683594, 0.984375\n",
      "Train loss and acc of batch 14: 48.052955627441406, 0.984375\n",
      "Train loss and acc of batch 15: 48.431884765625, 0.984375\n",
      "Train loss and acc of batch 16: 48.43187713623047, 0.984375\n",
      "Train loss and acc of batch 17: 48.589385986328125, 0.984375\n",
      "Train loss and acc of batch 18: 48.71770477294922, 0.96875\n",
      "Train loss and acc of batch 19: 47.83614730834961, 1.0\n",
      "Train loss and acc of batch 20: 47.83613586425781, 1.0\n",
      "Train loss and acc of batch 21: 48.43183135986328, 0.984375\n",
      "Train loss and acc of batch 22: 48.43181610107422, 0.984375\n",
      "Train loss and acc of batch 23: 47.83611297607422, 1.0\n",
      "Train loss and acc of batch 24: 48.431800842285156, 0.984375\n",
      "Train loss and acc of batch 25: 47.836090087890625, 1.0\n",
      "Train loss and acc of batch 26: 47.836082458496094, 1.0\n",
      "Train loss and acc of batch 27: 47.8360710144043, 1.0\n",
      "Train loss and acc of batch 28: 47.836063385009766, 1.0\n",
      "Train loss and acc of batch 29: 48.4317626953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.8360481262207, 1.0\n",
      "Train loss and acc of batch 31: 48.05280303955078, 0.984375\n",
      "Train loss and acc of batch 32: 47.83602523803711, 1.0\n",
      "Train loss and acc of batch 33: 47.83601760864258, 1.0\n",
      "Train loss and acc of batch 34: 48.43170928955078, 0.984375\n",
      "Train loss and acc of batch 35: 48.269527435302734, 0.96875\n",
      "Train loss and acc of batch 36: 47.835994720458984, 1.0\n",
      "Train loss and acc of batch 37: 48.589210510253906, 0.984375\n",
      "Train loss and acc of batch 38: 49.184898376464844, 0.96875\n",
      "Train loss and acc of batch 39: 48.052734375, 0.984375\n",
      "Train loss and acc of batch 40: 47.83595657348633, 1.0\n",
      "Train loss and acc of batch 41: 49.184871673583984, 0.96875\n",
      "Train loss and acc of batch 42: 47.835941314697266, 1.0\n",
      "Train loss and acc of batch 43: 48.43163299560547, 0.984375\n",
      "Train loss and acc of batch 44: 47.83592224121094, 1.0\n",
      "Train loss and acc of batch 45: 48.431617736816406, 0.984375\n",
      "Train loss and acc of batch 46: 48.12175750732422, 0.984375\n",
      "Train loss and acc of batch 47: 47.83589553833008, 1.0\n",
      "Train loss and acc of batch 48: 47.83588790893555, 1.0\n",
      "Train loss and acc of batch 49: 47.835880279541016, 1.0\n",
      "Train loss and acc of batch 50: 48.43157196044922, 0.984375\n",
      "Train loss and acc of batch 51: 49.184783935546875, 0.96875\n",
      "Train loss and acc of batch 52: 49.09169387817383, 0.953125\n",
      "Train loss and acc of batch 53: 47.835845947265625, 1.0\n",
      "Train loss and acc of batch 54: 48.05259704589844, 0.984375\n",
      "Train loss and acc of batch 55: 47.83582305908203, 1.0\n",
      "Train loss and acc of batch 56: 47.835819244384766, 1.0\n",
      "Train loss and acc of batch 57: 48.43151092529297, 0.984375\n",
      "Train loss and acc of batch 58: 47.83579635620117, 1.0\n",
      "Train loss and acc of batch 59: 47.83578872680664, 1.0\n",
      "Train loss and acc of batch 60: 47.83578109741211, 1.0\n",
      "Train loss and acc of batch 61: 47.83576965332031, 1.0\n",
      "Train loss and acc of batch 62: 47.83576583862305, 1.0\n",
      "Train loss and acc of batch 63: 49.02715301513672, 0.96875\n",
      "Train loss and acc of batch 64: 48.052513122558594, 0.984375\n",
      "Train loss and acc of batch 65: 47.83573532104492, 1.0\n",
      "Train loss and acc of batch 66: 47.835731506347656, 1.0\n",
      "Train loss and acc of batch 67: 48.6481819152832, 0.96875\n",
      "Train loss and acc of batch 68: 48.43141174316406, 0.984375\n",
      "Train loss and acc of batch 69: 48.052459716796875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 70: 47.835689544677734, 1.0\n",
      "Training accuracy and loss of epoch #352: 0.9894, 48.1609\n",
      "Saved model by train loss 48.16091215106803\n",
      "Train loss and acc of batch 0: 47.8356819152832, 1.0\n",
      "Train loss and acc of batch 1: 47.835670471191406, 1.0\n",
      "Train loss and acc of batch 2: 48.12151336669922, 0.984375\n",
      "Train loss and acc of batch 3: 48.05242156982422, 0.984375\n",
      "Train loss and acc of batch 4: 47.83564376831055, 1.0\n",
      "Train loss and acc of batch 5: 49.18456268310547, 0.96875\n",
      "Train loss and acc of batch 6: 48.3382453918457, 0.96875\n",
      "Train loss and acc of batch 7: 47.83562088012695, 1.0\n",
      "Train loss and acc of batch 8: 48.431312561035156, 0.984375\n",
      "Train loss and acc of batch 9: 48.12145233154297, 0.984375\n",
      "Train loss and acc of batch 10: 47.83559799194336, 1.0\n",
      "Train loss and acc of batch 11: 47.83558654785156, 1.0\n",
      "Train loss and acc of batch 12: 48.58879852294922, 0.984375\n",
      "Train loss and acc of batch 13: 48.052330017089844, 0.984375\n",
      "Train loss and acc of batch 14: 48.05232238769531, 0.984375\n",
      "Train loss and acc of batch 15: 48.431243896484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.431243896484375, 0.984375\n",
      "Train loss and acc of batch 17: 48.58875274658203, 0.984375\n",
      "Train loss and acc of batch 18: 48.717079162597656, 0.96875\n",
      "Train loss and acc of batch 19: 47.835514068603516, 1.0\n",
      "Train loss and acc of batch 20: 47.835506439208984, 1.0\n",
      "Train loss and acc of batch 21: 48.43119812011719, 0.984375\n",
      "Train loss and acc of batch 22: 48.431190490722656, 0.984375\n",
      "Train loss and acc of batch 23: 47.835479736328125, 1.0\n",
      "Train loss and acc of batch 24: 48.431175231933594, 0.984375\n",
      "Train loss and acc of batch 25: 47.8354606628418, 1.0\n",
      "Train loss and acc of batch 26: 47.83544921875, 1.0\n",
      "Train loss and acc of batch 27: 47.8354377746582, 1.0\n",
      "Train loss and acc of batch 28: 47.83543395996094, 1.0\n",
      "Train loss and acc of batch 29: 48.431121826171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.83541488647461, 1.0\n",
      "Train loss and acc of batch 31: 48.05216979980469, 0.984375\n",
      "Train loss and acc of batch 32: 47.83539962768555, 1.0\n",
      "Train loss and acc of batch 33: 47.83538818359375, 1.0\n",
      "Train loss and acc of batch 34: 48.43108367919922, 0.984375\n",
      "Train loss and acc of batch 35: 48.268898010253906, 0.96875\n",
      "Train loss and acc of batch 36: 47.83536148071289, 1.0\n",
      "Train loss and acc of batch 37: 48.58857345581055, 0.984375\n",
      "Train loss and acc of batch 38: 49.18427276611328, 0.96875\n",
      "Train loss and acc of batch 39: 48.052101135253906, 0.984375\n",
      "Train loss and acc of batch 40: 47.835323333740234, 1.0\n",
      "Train loss and acc of batch 41: 49.184242248535156, 0.96875\n",
      "Train loss and acc of batch 42: 47.83530807495117, 1.0\n",
      "Train loss and acc of batch 43: 48.430999755859375, 0.984375\n",
      "Train loss and acc of batch 44: 47.83528518676758, 1.0\n",
      "Train loss and acc of batch 45: 48.43098449707031, 0.984375\n",
      "Train loss and acc of batch 46: 48.121124267578125, 0.984375\n",
      "Train loss and acc of batch 47: 47.835262298583984, 1.0\n",
      "Train loss and acc of batch 48: 47.83525466918945, 1.0\n",
      "Train loss and acc of batch 49: 47.83524703979492, 1.0\n",
      "Train loss and acc of batch 50: 48.430938720703125, 0.984375\n",
      "Train loss and acc of batch 51: 49.18415832519531, 0.96875\n",
      "Train loss and acc of batch 52: 49.091064453125, 0.953125\n",
      "Train loss and acc of batch 53: 47.83521270751953, 1.0\n",
      "Train loss and acc of batch 54: 48.051963806152344, 0.984375\n",
      "Train loss and acc of batch 55: 47.8351936340332, 1.0\n",
      "Train loss and acc of batch 56: 47.835182189941406, 1.0\n",
      "Train loss and acc of batch 57: 48.430870056152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.835166931152344, 1.0\n",
      "Train loss and acc of batch 59: 47.83515930175781, 1.0\n",
      "Train loss and acc of batch 60: 47.835147857666016, 1.0\n",
      "Train loss and acc of batch 61: 47.83514404296875, 1.0\n",
      "Train loss and acc of batch 62: 47.83512878417969, 1.0\n",
      "Train loss and acc of batch 63: 49.02652359008789, 0.96875\n",
      "Train loss and acc of batch 64: 48.05187225341797, 0.984375\n",
      "Train loss and acc of batch 65: 47.83510971069336, 1.0\n",
      "Train loss and acc of batch 66: 47.83509826660156, 1.0\n",
      "Train loss and acc of batch 67: 48.647552490234375, 0.96875\n",
      "Train loss and acc of batch 68: 48.43077850341797, 0.984375\n",
      "Train loss and acc of batch 69: 48.05183410644531, 0.984375\n",
      "Train loss and acc of batch 70: 47.83505630493164, 1.0\n",
      "Training accuracy and loss of epoch #353: 0.9894, 48.1603\n",
      "Saved model by train loss 48.1602802545252\n",
      "Train loss and acc of batch 0: 47.835044860839844, 1.0\n",
      "Train loss and acc of batch 1: 47.83504104614258, 1.0\n",
      "Train loss and acc of batch 2: 48.120880126953125, 0.984375\n",
      "Train loss and acc of batch 3: 48.051788330078125, 0.984375\n",
      "Train loss and acc of batch 4: 47.83501434326172, 1.0\n",
      "Train loss and acc of batch 5: 49.183929443359375, 0.96875\n",
      "Train loss and acc of batch 6: 48.33761215209961, 0.96875\n",
      "Train loss and acc of batch 7: 47.83498764038086, 1.0\n",
      "Train loss and acc of batch 8: 48.43067932128906, 0.984375\n",
      "Train loss and acc of batch 9: 48.120826721191406, 0.984375\n",
      "Train loss and acc of batch 10: 47.8349609375, 1.0\n",
      "Train loss and acc of batch 11: 47.83495330810547, 1.0\n",
      "Train loss and acc of batch 12: 48.58816909790039, 0.984375\n",
      "Train loss and acc of batch 13: 48.05170440673828, 0.984375\n",
      "Train loss and acc of batch 14: 48.05168914794922, 0.984375\n",
      "Train loss and acc of batch 15: 48.43061828613281, 0.984375\n",
      "Train loss and acc of batch 16: 48.43061065673828, 0.984375\n",
      "Train loss and acc of batch 17: 48.5881233215332, 0.984375\n",
      "Train loss and acc of batch 18: 48.7164421081543, 0.96875\n",
      "Train loss and acc of batch 19: 47.83488464355469, 1.0\n",
      "Train loss and acc of batch 20: 47.834869384765625, 1.0\n",
      "Train loss and acc of batch 21: 48.430564880371094, 0.984375\n",
      "Train loss and acc of batch 22: 48.43055725097656, 0.984375\n",
      "Train loss and acc of batch 23: 47.8348503112793, 1.0\n",
      "Train loss and acc of batch 24: 48.43053436279297, 0.984375\n",
      "Train loss and acc of batch 25: 47.83483123779297, 1.0\n",
      "Train loss and acc of batch 26: 47.83481979370117, 1.0\n",
      "Train loss and acc of batch 27: 47.83481216430664, 1.0\n",
      "Train loss and acc of batch 28: 47.834800720214844, 1.0\n",
      "Train loss and acc of batch 29: 48.43049621582031, 0.984375\n",
      "Train loss and acc of batch 30: 47.834781646728516, 1.0\n",
      "Train loss and acc of batch 31: 48.051536560058594, 0.984375\n",
      "Train loss and acc of batch 32: 47.83476638793945, 1.0\n",
      "Train loss and acc of batch 33: 47.83475875854492, 1.0\n",
      "Train loss and acc of batch 34: 48.430450439453125, 0.984375\n",
      "Train loss and acc of batch 35: 48.26826477050781, 0.96875\n",
      "Train loss and acc of batch 36: 47.8347282409668, 1.0\n",
      "Train loss and acc of batch 37: 48.587947845458984, 0.984375\n",
      "Train loss and acc of batch 38: 49.18363952636719, 0.96875\n",
      "Train loss and acc of batch 39: 48.05146789550781, 0.984375\n",
      "Train loss and acc of batch 40: 47.83469772338867, 1.0\n",
      "Train loss and acc of batch 41: 49.18361282348633, 0.96875\n",
      "Train loss and acc of batch 42: 47.834678649902344, 1.0\n",
      "Train loss and acc of batch 43: 48.43036651611328, 0.984375\n",
      "Train loss and acc of batch 44: 47.834659576416016, 1.0\n",
      "Train loss and acc of batch 45: 48.43035125732422, 0.984375\n",
      "Train loss and acc of batch 46: 48.12049102783203, 0.984375\n",
      "Train loss and acc of batch 47: 47.834632873535156, 1.0\n",
      "Train loss and acc of batch 48: 47.834625244140625, 1.0\n",
      "Train loss and acc of batch 49: 47.834617614746094, 1.0\n",
      "Train loss and acc of batch 50: 48.43030548095703, 0.984375\n",
      "Train loss and acc of batch 51: 49.18352508544922, 0.96875\n",
      "Train loss and acc of batch 52: 49.09042739868164, 0.953125\n",
      "Train loss and acc of batch 53: 47.83457565307617, 1.0\n",
      "Train loss and acc of batch 54: 48.05133819580078, 0.984375\n",
      "Train loss and acc of batch 55: 47.834564208984375, 1.0\n",
      "Train loss and acc of batch 56: 47.834556579589844, 1.0\n",
      "Train loss and acc of batch 57: 48.43024444580078, 0.984375\n",
      "Train loss and acc of batch 58: 47.834537506103516, 1.0\n",
      "Train loss and acc of batch 59: 47.83452606201172, 1.0\n",
      "Train loss and acc of batch 60: 47.83452224731445, 1.0\n",
      "Train loss and acc of batch 61: 47.83450698852539, 1.0\n",
      "Train loss and acc of batch 62: 47.834503173828125, 1.0\n",
      "Train loss and acc of batch 63: 49.0258903503418, 0.96875\n",
      "Train loss and acc of batch 64: 48.051246643066406, 0.984375\n",
      "Train loss and acc of batch 65: 47.83447265625, 1.0\n",
      "Train loss and acc of batch 66: 47.8344612121582, 1.0\n",
      "Train loss and acc of batch 67: 48.64691925048828, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 68: 48.430152893066406, 0.984375\n",
      "Train loss and acc of batch 69: 48.05120086669922, 0.984375\n",
      "Train loss and acc of batch 70: 47.83443069458008, 1.0\n",
      "Training accuracy and loss of epoch #354: 0.9894, 48.1596\n",
      "Saved model by train loss 48.15964900271993\n",
      "Train loss and acc of batch 0: 47.83441925048828, 1.0\n",
      "Train loss and acc of batch 1: 47.834407806396484, 1.0\n",
      "Train loss and acc of batch 2: 48.12025451660156, 0.984375\n",
      "Train loss and acc of batch 3: 48.05115509033203, 0.984375\n",
      "Train loss and acc of batch 4: 47.83438491821289, 1.0\n",
      "Train loss and acc of batch 5: 49.18329620361328, 0.96875\n",
      "Train loss and acc of batch 6: 48.33698654174805, 0.96875\n",
      "Train loss and acc of batch 7: 47.834354400634766, 1.0\n",
      "Train loss and acc of batch 8: 48.4300537109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.12018585205078, 0.984375\n",
      "Train loss and acc of batch 10: 47.834327697753906, 1.0\n",
      "Train loss and acc of batch 11: 47.83432388305664, 1.0\n",
      "Train loss and acc of batch 12: 48.58753967285156, 0.984375\n",
      "Train loss and acc of batch 13: 48.05107116699219, 0.984375\n",
      "Train loss and acc of batch 14: 48.051055908203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.42998504638672, 0.984375\n",
      "Train loss and acc of batch 16: 48.42997741699219, 0.984375\n",
      "Train loss and acc of batch 17: 48.587493896484375, 0.984375\n",
      "Train loss and acc of batch 18: 48.71581268310547, 0.96875\n",
      "Train loss and acc of batch 19: 47.834251403808594, 1.0\n",
      "Train loss and acc of batch 20: 47.8342399597168, 1.0\n",
      "Train loss and acc of batch 21: 48.429931640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.42992401123047, 0.984375\n",
      "Train loss and acc of batch 23: 47.83420944213867, 1.0\n",
      "Train loss and acc of batch 24: 48.429908752441406, 0.984375\n",
      "Train loss and acc of batch 25: 47.834197998046875, 1.0\n",
      "Train loss and acc of batch 26: 47.834190368652344, 1.0\n",
      "Train loss and acc of batch 27: 47.83417892456055, 1.0\n",
      "Train loss and acc of batch 28: 47.83417510986328, 1.0\n",
      "Train loss and acc of batch 29: 48.42986297607422, 0.984375\n",
      "Train loss and acc of batch 30: 47.83415222167969, 1.0\n",
      "Train loss and acc of batch 31: 48.05091094970703, 0.984375\n",
      "Train loss and acc of batch 32: 47.83413314819336, 1.0\n",
      "Train loss and acc of batch 33: 47.83412551879883, 1.0\n",
      "Train loss and acc of batch 34: 48.42982482910156, 0.984375\n",
      "Train loss and acc of batch 35: 48.26763916015625, 0.96875\n",
      "Train loss and acc of batch 36: 47.83409881591797, 1.0\n",
      "Train loss and acc of batch 37: 48.587310791015625, 0.984375\n",
      "Train loss and acc of batch 38: 49.183006286621094, 0.96875\n",
      "Train loss and acc of batch 39: 48.05083465576172, 0.984375\n",
      "Train loss and acc of batch 40: 47.83406066894531, 1.0\n",
      "Train loss and acc of batch 41: 49.1829833984375, 0.96875\n",
      "Train loss and acc of batch 42: 47.834049224853516, 1.0\n",
      "Train loss and acc of batch 43: 48.42974090576172, 0.984375\n",
      "Train loss and acc of batch 44: 47.83402633666992, 1.0\n",
      "Train loss and acc of batch 45: 48.429725646972656, 0.984375\n",
      "Train loss and acc of batch 46: 48.11985778808594, 0.984375\n",
      "Train loss and acc of batch 47: 47.83400344848633, 1.0\n",
      "Train loss and acc of batch 48: 47.8339958190918, 1.0\n",
      "Train loss and acc of batch 49: 47.833984375, 1.0\n",
      "Train loss and acc of batch 50: 48.42967224121094, 0.984375\n",
      "Train loss and acc of batch 51: 49.182891845703125, 0.96875\n",
      "Train loss and acc of batch 52: 49.08979415893555, 0.953125\n",
      "Train loss and acc of batch 53: 47.83395004272461, 1.0\n",
      "Train loss and acc of batch 54: 48.05070495605469, 0.984375\n",
      "Train loss and acc of batch 55: 47.83393096923828, 1.0\n",
      "Train loss and acc of batch 56: 47.83392333984375, 1.0\n",
      "Train loss and acc of batch 57: 48.42961120605469, 0.984375\n",
      "Train loss and acc of batch 58: 47.83390426635742, 1.0\n",
      "Train loss and acc of batch 59: 47.833900451660156, 1.0\n",
      "Train loss and acc of batch 60: 47.83388137817383, 1.0\n",
      "Train loss and acc of batch 61: 47.83387756347656, 1.0\n",
      "Train loss and acc of batch 62: 47.83386993408203, 1.0\n",
      "Train loss and acc of batch 63: 49.02526092529297, 0.96875\n",
      "Train loss and acc of batch 64: 48.050621032714844, 0.984375\n",
      "Train loss and acc of batch 65: 47.83383560180664, 1.0\n",
      "Train loss and acc of batch 66: 47.833831787109375, 1.0\n",
      "Train loss and acc of batch 67: 48.64628982543945, 0.96875\n",
      "Train loss and acc of batch 68: 48.42951965332031, 0.984375\n",
      "Train loss and acc of batch 69: 48.050567626953125, 0.984375\n",
      "Train loss and acc of batch 70: 47.833797454833984, 1.0\n",
      "Training accuracy and loss of epoch #355: 0.9894, 48.1590\n",
      "Saved model by train loss 48.159017697186535\n",
      "Train loss and acc of batch 0: 47.83378601074219, 1.0\n",
      "Train loss and acc of batch 1: 47.833778381347656, 1.0\n",
      "Train loss and acc of batch 2: 48.11962127685547, 0.984375\n",
      "Train loss and acc of batch 3: 48.05052185058594, 0.984375\n",
      "Train loss and acc of batch 4: 47.8337516784668, 1.0\n",
      "Train loss and acc of batch 5: 49.18267059326172, 0.96875\n",
      "Train loss and acc of batch 6: 48.33634948730469, 0.96875\n",
      "Train loss and acc of batch 7: 47.8337287902832, 1.0\n",
      "Train loss and acc of batch 8: 48.429420471191406, 0.984375\n",
      "Train loss and acc of batch 9: 48.11956024169922, 0.984375\n",
      "Train loss and acc of batch 10: 47.83369827270508, 1.0\n",
      "Train loss and acc of batch 11: 47.83369064331055, 1.0\n",
      "Train loss and acc of batch 12: 48.5869026184082, 0.984375\n",
      "Train loss and acc of batch 13: 48.050437927246094, 0.984375\n",
      "Train loss and acc of batch 14: 48.05042266845703, 0.984375\n",
      "Train loss and acc of batch 15: 48.429359436035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.429351806640625, 0.984375\n",
      "Train loss and acc of batch 17: 48.586856842041016, 0.984375\n",
      "Train loss and acc of batch 18: 48.715179443359375, 0.96875\n",
      "Train loss and acc of batch 19: 47.833621978759766, 1.0\n",
      "Train loss and acc of batch 20: 47.8336067199707, 1.0\n",
      "Train loss and acc of batch 21: 48.42930603027344, 0.984375\n",
      "Train loss and acc of batch 22: 48.429298400878906, 0.984375\n",
      "Train loss and acc of batch 23: 47.833580017089844, 1.0\n",
      "Train loss and acc of batch 24: 48.42927551269531, 0.984375\n",
      "Train loss and acc of batch 25: 47.83356857299805, 1.0\n",
      "Train loss and acc of batch 26: 47.833553314208984, 1.0\n",
      "Train loss and acc of batch 27: 47.83354949951172, 1.0\n",
      "Train loss and acc of batch 28: 47.83353805541992, 1.0\n",
      "Train loss and acc of batch 29: 48.429237365722656, 0.984375\n",
      "Train loss and acc of batch 30: 47.83352279663086, 1.0\n",
      "Train loss and acc of batch 31: 48.050270080566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.83350372314453, 1.0\n",
      "Train loss and acc of batch 33: 47.833499908447266, 1.0\n",
      "Train loss and acc of batch 34: 48.42918395996094, 0.984375\n",
      "Train loss and acc of batch 35: 48.26700973510742, 0.96875\n",
      "Train loss and acc of batch 36: 47.83346939086914, 1.0\n",
      "Train loss and acc of batch 37: 48.5866813659668, 0.984375\n",
      "Train loss and acc of batch 38: 49.182373046875, 0.96875\n",
      "Train loss and acc of batch 39: 48.050201416015625, 0.984375\n",
      "Train loss and acc of batch 40: 47.833431243896484, 1.0\n",
      "Train loss and acc of batch 41: 49.182350158691406, 0.96875\n",
      "Train loss and acc of batch 42: 47.83341598510742, 1.0\n",
      "Train loss and acc of batch 43: 48.429107666015625, 0.984375\n",
      "Train loss and acc of batch 44: 47.83340072631836, 1.0\n",
      "Train loss and acc of batch 45: 48.42908477783203, 0.984375\n",
      "Train loss and acc of batch 46: 48.119232177734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.833370208740234, 1.0\n",
      "Train loss and acc of batch 48: 47.8333625793457, 1.0\n",
      "Train loss and acc of batch 49: 47.833351135253906, 1.0\n",
      "Train loss and acc of batch 50: 48.429046630859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.18225860595703, 0.96875\n",
      "Train loss and acc of batch 52: 49.08916473388672, 0.953125\n",
      "Train loss and acc of batch 53: 47.833316802978516, 1.0\n",
      "Train loss and acc of batch 54: 48.050071716308594, 0.984375\n",
      "Train loss and acc of batch 55: 47.83329772949219, 1.0\n",
      "Train loss and acc of batch 56: 47.83328628540039, 1.0\n",
      "Train loss and acc of batch 57: 48.428985595703125, 0.984375\n",
      "Train loss and acc of batch 58: 47.83327865600586, 1.0\n",
      "Train loss and acc of batch 59: 47.83325958251953, 1.0\n",
      "Train loss and acc of batch 60: 47.833251953125, 1.0\n",
      "Train loss and acc of batch 61: 47.83324432373047, 1.0\n",
      "Train loss and acc of batch 62: 47.83323669433594, 1.0\n",
      "Train loss and acc of batch 63: 49.024627685546875, 0.96875\n",
      "Train loss and acc of batch 64: 48.04998779296875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 47.83320999145508, 1.0\n",
      "Train loss and acc of batch 66: 47.83320617675781, 1.0\n",
      "Train loss and acc of batch 67: 48.645660400390625, 0.96875\n",
      "Train loss and acc of batch 68: 48.42887878417969, 0.984375\n",
      "Train loss and acc of batch 69: 48.04994201660156, 0.984375\n",
      "Train loss and acc of batch 70: 47.833168029785156, 1.0\n",
      "Training accuracy and loss of epoch #356: 0.9894, 48.1584\n",
      "Saved model by train loss 48.15838628419688\n",
      "Train loss and acc of batch 0: 47.83315658569336, 1.0\n",
      "Train loss and acc of batch 1: 47.833152770996094, 1.0\n",
      "Train loss and acc of batch 2: 48.118988037109375, 0.984375\n",
      "Train loss and acc of batch 3: 48.049896240234375, 0.984375\n",
      "Train loss and acc of batch 4: 47.83312225341797, 1.0\n",
      "Train loss and acc of batch 5: 49.182037353515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.33572006225586, 0.96875\n",
      "Train loss and acc of batch 7: 47.83309555053711, 1.0\n",
      "Train loss and acc of batch 8: 48.42878723144531, 0.984375\n",
      "Train loss and acc of batch 9: 48.118934631347656, 0.984375\n",
      "Train loss and acc of batch 10: 47.83306884765625, 1.0\n",
      "Train loss and acc of batch 11: 47.83305358886719, 1.0\n",
      "Train loss and acc of batch 12: 48.586273193359375, 0.984375\n",
      "Train loss and acc of batch 13: 48.0498046875, 0.984375\n",
      "Train loss and acc of batch 14: 48.04979705810547, 0.984375\n",
      "Train loss and acc of batch 15: 48.42872619628906, 0.984375\n",
      "Train loss and acc of batch 16: 48.4287109375, 0.984375\n",
      "Train loss and acc of batch 17: 48.58622741699219, 0.984375\n",
      "Train loss and acc of batch 18: 48.71455383300781, 0.96875\n",
      "Train loss and acc of batch 19: 47.832984924316406, 1.0\n",
      "Train loss and acc of batch 20: 47.832977294921875, 1.0\n",
      "Train loss and acc of batch 21: 48.428672790527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.42865753173828, 0.984375\n",
      "Train loss and acc of batch 23: 47.832950592041016, 1.0\n",
      "Train loss and acc of batch 24: 48.42864990234375, 0.984375\n",
      "Train loss and acc of batch 25: 47.83292770385742, 1.0\n",
      "Train loss and acc of batch 26: 47.832923889160156, 1.0\n",
      "Train loss and acc of batch 27: 47.832916259765625, 1.0\n",
      "Train loss and acc of batch 28: 47.83290481567383, 1.0\n",
      "Train loss and acc of batch 29: 48.42860412597656, 0.984375\n",
      "Train loss and acc of batch 30: 47.8328857421875, 1.0\n",
      "Train loss and acc of batch 31: 48.049644470214844, 0.984375\n",
      "Train loss and acc of batch 32: 47.83287811279297, 1.0\n",
      "Train loss and acc of batch 33: 47.83285903930664, 1.0\n",
      "Train loss and acc of batch 34: 48.428558349609375, 0.984375\n",
      "Train loss and acc of batch 35: 48.26637268066406, 0.96875\n",
      "Train loss and acc of batch 36: 47.83283233642578, 1.0\n",
      "Train loss and acc of batch 37: 48.58605194091797, 0.984375\n",
      "Train loss and acc of batch 38: 49.181739807128906, 0.96875\n",
      "Train loss and acc of batch 39: 48.04957580566406, 0.984375\n",
      "Train loss and acc of batch 40: 47.83279800415039, 1.0\n",
      "Train loss and acc of batch 41: 49.18172073364258, 0.96875\n",
      "Train loss and acc of batch 42: 47.83277893066406, 1.0\n",
      "Train loss and acc of batch 43: 48.42847442626953, 0.984375\n",
      "Train loss and acc of batch 44: 47.832763671875, 1.0\n",
      "Train loss and acc of batch 45: 48.42845916748047, 0.984375\n",
      "Train loss and acc of batch 46: 48.11860656738281, 0.984375\n",
      "Train loss and acc of batch 47: 47.832733154296875, 1.0\n",
      "Train loss and acc of batch 48: 47.83272933959961, 1.0\n",
      "Train loss and acc of batch 49: 47.83271789550781, 1.0\n",
      "Train loss and acc of batch 50: 48.42840576171875, 0.984375\n",
      "Train loss and acc of batch 51: 49.18162536621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.08853530883789, 0.953125\n",
      "Train loss and acc of batch 53: 47.83268356323242, 1.0\n",
      "Train loss and acc of batch 54: 48.0494384765625, 0.984375\n",
      "Train loss and acc of batch 55: 47.832664489746094, 1.0\n",
      "Train loss and acc of batch 56: 47.83265686035156, 1.0\n",
      "Train loss and acc of batch 57: 48.42835235595703, 0.984375\n",
      "Train loss and acc of batch 58: 47.832637786865234, 1.0\n",
      "Train loss and acc of batch 59: 47.8326301574707, 1.0\n",
      "Train loss and acc of batch 60: 47.83262634277344, 1.0\n",
      "Train loss and acc of batch 61: 47.83261489868164, 1.0\n",
      "Train loss and acc of batch 62: 47.832603454589844, 1.0\n",
      "Train loss and acc of batch 63: 49.02399444580078, 0.96875\n",
      "Train loss and acc of batch 64: 48.049346923828125, 0.984375\n",
      "Train loss and acc of batch 65: 47.83258056640625, 1.0\n",
      "Train loss and acc of batch 66: 47.83256912231445, 1.0\n",
      "Train loss and acc of batch 67: 48.64502716064453, 0.96875\n",
      "Train loss and acc of batch 68: 48.428253173828125, 0.984375\n",
      "Train loss and acc of batch 69: 48.04930877685547, 0.984375\n",
      "Train loss and acc of batch 70: 47.83253479003906, 1.0\n",
      "Training accuracy and loss of epoch #357: 0.9894, 48.1578\n",
      "Saved model by train loss 48.15775417274153\n",
      "Train loss and acc of batch 0: 47.83252716064453, 1.0\n",
      "Train loss and acc of batch 1: 47.832515716552734, 1.0\n",
      "Train loss and acc of batch 2: 48.11835479736328, 0.984375\n",
      "Train loss and acc of batch 3: 48.04926300048828, 0.984375\n",
      "Train loss and acc of batch 4: 47.832489013671875, 1.0\n",
      "Train loss and acc of batch 5: 49.18140411376953, 0.96875\n",
      "Train loss and acc of batch 6: 48.3350830078125, 0.96875\n",
      "Train loss and acc of batch 7: 47.83245849609375, 1.0\n",
      "Train loss and acc of batch 8: 48.42815399169922, 0.984375\n",
      "Train loss and acc of batch 9: 48.11830139160156, 0.984375\n",
      "Train loss and acc of batch 10: 47.832435607910156, 1.0\n",
      "Train loss and acc of batch 11: 47.83243179321289, 1.0\n",
      "Train loss and acc of batch 12: 48.585636138916016, 0.984375\n",
      "Train loss and acc of batch 13: 48.049171447753906, 0.984375\n",
      "Train loss and acc of batch 14: 48.049163818359375, 0.984375\n",
      "Train loss and acc of batch 15: 48.42808532714844, 0.984375\n",
      "Train loss and acc of batch 16: 48.428077697753906, 0.984375\n",
      "Train loss and acc of batch 17: 48.585601806640625, 0.984375\n",
      "Train loss and acc of batch 18: 48.71391677856445, 0.96875\n",
      "Train loss and acc of batch 19: 47.832359313964844, 1.0\n",
      "Train loss and acc of batch 20: 47.83234405517578, 1.0\n",
      "Train loss and acc of batch 21: 48.42803192138672, 0.984375\n",
      "Train loss and acc of batch 22: 48.42803192138672, 0.984375\n",
      "Train loss and acc of batch 23: 47.83231735229492, 1.0\n",
      "Train loss and acc of batch 24: 48.428009033203125, 0.984375\n",
      "Train loss and acc of batch 25: 47.83230209350586, 1.0\n",
      "Train loss and acc of batch 26: 47.83229446411133, 1.0\n",
      "Train loss and acc of batch 27: 47.83228302001953, 1.0\n",
      "Train loss and acc of batch 28: 47.832275390625, 1.0\n",
      "Train loss and acc of batch 29: 48.42796325683594, 0.984375\n",
      "Train loss and acc of batch 30: 47.83225631713867, 1.0\n",
      "Train loss and acc of batch 31: 48.04901885986328, 0.984375\n",
      "Train loss and acc of batch 32: 47.83224105834961, 1.0\n",
      "Train loss and acc of batch 33: 47.83223342895508, 1.0\n",
      "Train loss and acc of batch 34: 48.42792510986328, 0.984375\n",
      "Train loss and acc of batch 35: 48.2657356262207, 0.96875\n",
      "Train loss and acc of batch 36: 47.83220672607422, 1.0\n",
      "Train loss and acc of batch 37: 48.585418701171875, 0.984375\n",
      "Train loss and acc of batch 38: 49.18110656738281, 0.96875\n",
      "Train loss and acc of batch 39: 48.04894256591797, 0.984375\n",
      "Train loss and acc of batch 40: 47.83216857910156, 1.0\n",
      "Train loss and acc of batch 41: 49.18108367919922, 0.96875\n",
      "Train loss and acc of batch 42: 47.8321533203125, 1.0\n",
      "Train loss and acc of batch 43: 48.42784118652344, 0.984375\n",
      "Train loss and acc of batch 44: 47.832130432128906, 1.0\n",
      "Train loss and acc of batch 45: 48.427825927734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.11796569824219, 0.984375\n",
      "Train loss and acc of batch 47: 47.83210754394531, 1.0\n",
      "Train loss and acc of batch 48: 47.83209991455078, 1.0\n",
      "Train loss and acc of batch 49: 47.83208465576172, 1.0\n",
      "Train loss and acc of batch 50: 48.42778015136719, 0.984375\n",
      "Train loss and acc of batch 51: 49.180999755859375, 0.96875\n",
      "Train loss and acc of batch 52: 49.08789825439453, 0.953125\n",
      "Train loss and acc of batch 53: 47.832054138183594, 1.0\n",
      "Train loss and acc of batch 54: 48.04881286621094, 0.984375\n",
      "Train loss and acc of batch 55: 47.832035064697266, 1.0\n",
      "Train loss and acc of batch 56: 47.832027435302734, 1.0\n",
      "Train loss and acc of batch 57: 48.42771911621094, 0.984375\n",
      "Train loss and acc of batch 58: 47.832008361816406, 1.0\n",
      "Train loss and acc of batch 59: 47.832000732421875, 1.0\n",
      "Train loss and acc of batch 60: 47.83198928833008, 1.0\n",
      "Train loss and acc of batch 61: 47.83198165893555, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 62: 47.83197784423828, 1.0\n",
      "Train loss and acc of batch 63: 49.02336502075195, 0.96875\n",
      "Train loss and acc of batch 64: 48.04872131347656, 0.984375\n",
      "Train loss and acc of batch 65: 47.831947326660156, 1.0\n",
      "Train loss and acc of batch 66: 47.831932067871094, 1.0\n",
      "Train loss and acc of batch 67: 48.64439392089844, 0.96875\n",
      "Train loss and acc of batch 68: 48.42761993408203, 0.984375\n",
      "Train loss and acc of batch 69: 48.048675537109375, 0.984375\n",
      "Train loss and acc of batch 70: 47.831905364990234, 1.0\n",
      "Training accuracy and loss of epoch #358: 0.9894, 48.1571\n",
      "Saved model by train loss 48.15712216874243\n",
      "Train loss and acc of batch 0: 47.83189392089844, 1.0\n",
      "Train loss and acc of batch 1: 47.83188247680664, 1.0\n",
      "Train loss and acc of batch 2: 48.11772918701172, 0.984375\n",
      "Train loss and acc of batch 3: 48.04862976074219, 0.984375\n",
      "Train loss and acc of batch 4: 47.83185958862305, 1.0\n",
      "Train loss and acc of batch 5: 49.18077087402344, 0.96875\n",
      "Train loss and acc of batch 6: 48.33445739746094, 0.96875\n",
      "Train loss and acc of batch 7: 47.83182907104492, 1.0\n",
      "Train loss and acc of batch 8: 48.427528381347656, 0.984375\n",
      "Train loss and acc of batch 9: 48.11766052246094, 0.984375\n",
      "Train loss and acc of batch 10: 47.83180618286133, 1.0\n",
      "Train loss and acc of batch 11: 47.831790924072266, 1.0\n",
      "Train loss and acc of batch 12: 48.58500671386719, 0.984375\n",
      "Train loss and acc of batch 13: 48.048545837402344, 0.984375\n",
      "Train loss and acc of batch 14: 48.04853820800781, 0.984375\n",
      "Train loss and acc of batch 15: 48.427459716796875, 0.984375\n",
      "Train loss and acc of batch 16: 48.427452087402344, 0.984375\n",
      "Train loss and acc of batch 17: 48.5849609375, 0.984375\n",
      "Train loss and acc of batch 18: 48.713287353515625, 0.96875\n",
      "Train loss and acc of batch 19: 47.83172607421875, 1.0\n",
      "Train loss and acc of batch 20: 47.83171463012695, 1.0\n",
      "Train loss and acc of batch 21: 48.427406311035156, 0.984375\n",
      "Train loss and acc of batch 22: 48.427398681640625, 0.984375\n",
      "Train loss and acc of batch 23: 47.831687927246094, 1.0\n",
      "Train loss and acc of batch 24: 48.42738342285156, 0.984375\n",
      "Train loss and acc of batch 25: 47.831668853759766, 1.0\n",
      "Train loss and acc of batch 26: 47.83165740966797, 1.0\n",
      "Train loss and acc of batch 27: 47.8316535949707, 1.0\n",
      "Train loss and acc of batch 28: 47.83164596557617, 1.0\n",
      "Train loss and acc of batch 29: 48.427337646484375, 0.984375\n",
      "Train loss and acc of batch 30: 47.83163070678711, 1.0\n",
      "Train loss and acc of batch 31: 48.04838562011719, 0.984375\n",
      "Train loss and acc of batch 32: 47.831607818603516, 1.0\n",
      "Train loss and acc of batch 33: 47.831600189208984, 1.0\n",
      "Train loss and acc of batch 34: 48.42729187011719, 0.984375\n",
      "Train loss and acc of batch 35: 48.265113830566406, 0.96875\n",
      "Train loss and acc of batch 36: 47.83156967163086, 1.0\n",
      "Train loss and acc of batch 37: 48.58478927612305, 0.984375\n",
      "Train loss and acc of batch 38: 49.18048095703125, 0.96875\n",
      "Train loss and acc of batch 39: 48.048316955566406, 0.984375\n",
      "Train loss and acc of batch 40: 47.83153533935547, 1.0\n",
      "Train loss and acc of batch 41: 49.18045425415039, 0.96875\n",
      "Train loss and acc of batch 42: 47.831520080566406, 1.0\n",
      "Train loss and acc of batch 43: 48.427215576171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.831504821777344, 1.0\n",
      "Train loss and acc of batch 45: 48.42719268798828, 0.984375\n",
      "Train loss and acc of batch 46: 48.117332458496094, 0.984375\n",
      "Train loss and acc of batch 47: 47.831478118896484, 1.0\n",
      "Train loss and acc of batch 48: 47.83146286010742, 1.0\n",
      "Train loss and acc of batch 49: 47.831459045410156, 1.0\n",
      "Train loss and acc of batch 50: 48.427146911621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.18036651611328, 0.96875\n",
      "Train loss and acc of batch 52: 49.08727264404297, 0.953125\n",
      "Train loss and acc of batch 53: 47.831417083740234, 1.0\n",
      "Train loss and acc of batch 54: 48.04817199707031, 0.984375\n",
      "Train loss and acc of batch 55: 47.83140563964844, 1.0\n",
      "Train loss and acc of batch 56: 47.83139419555664, 1.0\n",
      "Train loss and acc of batch 57: 48.427093505859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.83137893676758, 1.0\n",
      "Train loss and acc of batch 59: 47.83137130737305, 1.0\n",
      "Train loss and acc of batch 60: 47.83135986328125, 1.0\n",
      "Train loss and acc of batch 61: 47.831356048583984, 1.0\n",
      "Train loss and acc of batch 62: 47.83134078979492, 1.0\n",
      "Train loss and acc of batch 63: 49.02273178100586, 0.96875\n",
      "Train loss and acc of batch 64: 48.04808807373047, 0.984375\n",
      "Train loss and acc of batch 65: 47.83131408691406, 1.0\n",
      "Train loss and acc of batch 66: 47.83130645751953, 1.0\n",
      "Train loss and acc of batch 67: 48.64376449584961, 0.96875\n",
      "Train loss and acc of batch 68: 48.42698669433594, 0.984375\n",
      "Train loss and acc of batch 69: 48.04804229736328, 0.984375\n",
      "Train loss and acc of batch 70: 47.83127212524414, 1.0\n",
      "Training accuracy and loss of epoch #359: 0.9894, 48.1565\n",
      "Saved model by train loss 48.156491454218475\n",
      "Train loss and acc of batch 0: 47.83126449584961, 1.0\n",
      "Train loss and acc of batch 1: 47.83125686645508, 1.0\n",
      "Train loss and acc of batch 2: 48.117095947265625, 0.984375\n",
      "Train loss and acc of batch 3: 48.048004150390625, 0.984375\n",
      "Train loss and acc of batch 4: 47.83122634887695, 1.0\n",
      "Train loss and acc of batch 5: 49.180145263671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.333824157714844, 0.96875\n",
      "Train loss and acc of batch 7: 47.831199645996094, 1.0\n",
      "Train loss and acc of batch 8: 48.42688751220703, 0.984375\n",
      "Train loss and acc of batch 9: 48.117034912109375, 0.984375\n",
      "Train loss and acc of batch 10: 47.83116912841797, 1.0\n",
      "Train loss and acc of batch 11: 47.83116149902344, 1.0\n",
      "Train loss and acc of batch 12: 48.58437728881836, 0.984375\n",
      "Train loss and acc of batch 13: 48.04791259765625, 0.984375\n",
      "Train loss and acc of batch 14: 48.04790496826172, 0.984375\n",
      "Train loss and acc of batch 15: 48.42683410644531, 0.984375\n",
      "Train loss and acc of batch 16: 48.42681884765625, 0.984375\n",
      "Train loss and acc of batch 17: 48.58433532714844, 0.984375\n",
      "Train loss and acc of batch 18: 48.7126579284668, 0.96875\n",
      "Train loss and acc of batch 19: 47.83109664916992, 1.0\n",
      "Train loss and acc of batch 20: 47.83108139038086, 1.0\n",
      "Train loss and acc of batch 21: 48.42677307128906, 0.984375\n",
      "Train loss and acc of batch 22: 48.42676544189453, 0.984375\n",
      "Train loss and acc of batch 23: 47.83106231689453, 1.0\n",
      "Train loss and acc of batch 24: 48.42675018310547, 0.984375\n",
      "Train loss and acc of batch 25: 47.83103561401367, 1.0\n",
      "Train loss and acc of batch 26: 47.831031799316406, 1.0\n",
      "Train loss and acc of batch 27: 47.83102035522461, 1.0\n",
      "Train loss and acc of batch 28: 47.83101272583008, 1.0\n",
      "Train loss and acc of batch 29: 48.42670440673828, 0.984375\n",
      "Train loss and acc of batch 30: 47.830997467041016, 1.0\n",
      "Train loss and acc of batch 31: 48.047752380371094, 0.984375\n",
      "Train loss and acc of batch 32: 47.83097839355469, 1.0\n",
      "Train loss and acc of batch 33: 47.830970764160156, 1.0\n",
      "Train loss and acc of batch 34: 48.426658630371094, 0.984375\n",
      "Train loss and acc of batch 35: 48.26447677612305, 0.96875\n",
      "Train loss and acc of batch 36: 47.83094024658203, 1.0\n",
      "Train loss and acc of batch 37: 48.58415985107422, 0.984375\n",
      "Train loss and acc of batch 38: 49.17985534667969, 0.96875\n",
      "Train loss and acc of batch 39: 48.04767608642578, 0.984375\n",
      "Train loss and acc of batch 40: 47.83090591430664, 1.0\n",
      "Train loss and acc of batch 41: 49.1798210144043, 0.96875\n",
      "Train loss and acc of batch 42: 47.83089065551758, 1.0\n",
      "Train loss and acc of batch 43: 48.42658233642578, 0.984375\n",
      "Train loss and acc of batch 44: 47.83087158203125, 1.0\n",
      "Train loss and acc of batch 45: 48.42656707763672, 0.984375\n",
      "Train loss and acc of batch 46: 48.11670684814453, 0.984375\n",
      "Train loss and acc of batch 47: 47.83084487915039, 1.0\n",
      "Train loss and acc of batch 48: 47.830833435058594, 1.0\n",
      "Train loss and acc of batch 49: 47.8308219909668, 1.0\n",
      "Train loss and acc of batch 50: 48.426513671875, 0.984375\n",
      "Train loss and acc of batch 51: 49.17973327636719, 0.96875\n",
      "Train loss and acc of batch 52: 49.08664321899414, 0.953125\n",
      "Train loss and acc of batch 53: 47.830787658691406, 1.0\n",
      "Train loss and acc of batch 54: 48.04754638671875, 0.984375\n",
      "Train loss and acc of batch 55: 47.830772399902344, 1.0\n",
      "Train loss and acc of batch 56: 47.83076477050781, 1.0\n",
      "Train loss and acc of batch 57: 48.42645263671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.830745697021484, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 59: 47.83073806762695, 1.0\n",
      "Train loss and acc of batch 60: 47.83073043823242, 1.0\n",
      "Train loss and acc of batch 61: 47.830718994140625, 1.0\n",
      "Train loss and acc of batch 62: 47.83070755004883, 1.0\n",
      "Train loss and acc of batch 63: 49.0221061706543, 0.96875\n",
      "Train loss and acc of batch 64: 48.047454833984375, 0.984375\n",
      "Train loss and acc of batch 65: 47.830684661865234, 1.0\n",
      "Train loss and acc of batch 66: 47.8306770324707, 1.0\n",
      "Train loss and acc of batch 67: 48.643131256103516, 0.96875\n",
      "Train loss and acc of batch 68: 48.426361083984375, 0.984375\n",
      "Train loss and acc of batch 69: 48.04740905761719, 0.984375\n",
      "Train loss and acc of batch 70: 47.83063888549805, 1.0\n",
      "Training accuracy and loss of epoch #360: 0.9894, 48.1559\n",
      "Saved model by train loss 48.15586020241321\n",
      "Train loss and acc of batch 0: 47.83062744140625, 1.0\n",
      "Train loss and acc of batch 1: 47.83061981201172, 1.0\n",
      "Train loss and acc of batch 2: 48.11647033691406, 0.984375\n",
      "Train loss and acc of batch 3: 48.04737091064453, 0.984375\n",
      "Train loss and acc of batch 4: 47.830596923828125, 1.0\n",
      "Train loss and acc of batch 5: 49.17951202392578, 0.96875\n",
      "Train loss and acc of batch 6: 48.333194732666016, 0.96875\n",
      "Train loss and acc of batch 7: 47.83056640625, 1.0\n",
      "Train loss and acc of batch 8: 48.42626190185547, 0.984375\n",
      "Train loss and acc of batch 9: 48.11640167236328, 0.984375\n",
      "Train loss and acc of batch 10: 47.83053970336914, 1.0\n",
      "Train loss and acc of batch 11: 47.830535888671875, 1.0\n",
      "Train loss and acc of batch 12: 48.58374786376953, 0.984375\n",
      "Train loss and acc of batch 13: 48.047279357910156, 0.984375\n",
      "Train loss and acc of batch 14: 48.047271728515625, 0.984375\n",
      "Train loss and acc of batch 15: 48.42619323730469, 0.984375\n",
      "Train loss and acc of batch 16: 48.42619323730469, 0.984375\n",
      "Train loss and acc of batch 17: 48.583702087402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.71202850341797, 0.96875\n",
      "Train loss and acc of batch 19: 47.83046340942383, 1.0\n",
      "Train loss and acc of batch 20: 47.83045196533203, 1.0\n",
      "Train loss and acc of batch 21: 48.4261474609375, 0.984375\n",
      "Train loss and acc of batch 22: 48.42613983154297, 0.984375\n",
      "Train loss and acc of batch 23: 47.83042526245117, 1.0\n",
      "Train loss and acc of batch 24: 48.426116943359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.83041000366211, 1.0\n",
      "Train loss and acc of batch 26: 47.83040237426758, 1.0\n",
      "Train loss and acc of batch 27: 47.83039093017578, 1.0\n",
      "Train loss and acc of batch 28: 47.830387115478516, 1.0\n",
      "Train loss and acc of batch 29: 48.42607116699219, 0.984375\n",
      "Train loss and acc of batch 30: 47.83036422729492, 1.0\n",
      "Train loss and acc of batch 31: 48.047119140625, 0.984375\n",
      "Train loss and acc of batch 32: 47.83034896850586, 1.0\n",
      "Train loss and acc of batch 33: 47.83033752441406, 1.0\n",
      "Train loss and acc of batch 34: 48.426025390625, 0.984375\n",
      "Train loss and acc of batch 35: 48.263851165771484, 0.96875\n",
      "Train loss and acc of batch 36: 47.8303108215332, 1.0\n",
      "Train loss and acc of batch 37: 48.583526611328125, 0.984375\n",
      "Train loss and acc of batch 38: 49.17921447753906, 0.96875\n",
      "Train loss and acc of batch 39: 48.04705047607422, 0.984375\n",
      "Train loss and acc of batch 40: 47.83027648925781, 1.0\n",
      "Train loss and acc of batch 41: 49.17919158935547, 0.96875\n",
      "Train loss and acc of batch 42: 47.83025360107422, 1.0\n",
      "Train loss and acc of batch 43: 48.42594909667969, 0.984375\n",
      "Train loss and acc of batch 44: 47.830238342285156, 1.0\n",
      "Train loss and acc of batch 45: 48.425933837890625, 0.984375\n",
      "Train loss and acc of batch 46: 48.11607360839844, 0.984375\n",
      "Train loss and acc of batch 47: 47.83021545410156, 1.0\n",
      "Train loss and acc of batch 48: 47.8302001953125, 1.0\n",
      "Train loss and acc of batch 49: 47.830196380615234, 1.0\n",
      "Train loss and acc of batch 50: 48.42588806152344, 0.984375\n",
      "Train loss and acc of batch 51: 49.179100036621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.08600616455078, 0.953125\n",
      "Train loss and acc of batch 53: 47.830162048339844, 1.0\n",
      "Train loss and acc of batch 54: 48.046913146972656, 0.984375\n",
      "Train loss and acc of batch 55: 47.83013916015625, 1.0\n",
      "Train loss and acc of batch 56: 47.83013153076172, 1.0\n",
      "Train loss and acc of batch 57: 48.425819396972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.830116271972656, 1.0\n",
      "Train loss and acc of batch 59: 47.830108642578125, 1.0\n",
      "Train loss and acc of batch 60: 47.83009719848633, 1.0\n",
      "Train loss and acc of batch 61: 47.8300895690918, 1.0\n",
      "Train loss and acc of batch 62: 47.830081939697266, 1.0\n",
      "Train loss and acc of batch 63: 49.0214729309082, 0.96875\n",
      "Train loss and acc of batch 64: 48.04682922363281, 0.984375\n",
      "Train loss and acc of batch 65: 47.83005142211914, 1.0\n",
      "Train loss and acc of batch 66: 47.83004379272461, 1.0\n",
      "Train loss and acc of batch 67: 48.64250183105469, 0.96875\n",
      "Train loss and acc of batch 68: 48.42572784423828, 0.984375\n",
      "Train loss and acc of batch 69: 48.046783447265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.83000946044922, 1.0\n",
      "Training accuracy and loss of epoch #361: 0.9894, 48.1552\n",
      "Saved model by train loss 48.15522916552047\n",
      "Train loss and acc of batch 0: 47.82999801635742, 1.0\n",
      "Train loss and acc of batch 1: 47.82999038696289, 1.0\n",
      "Train loss and acc of batch 2: 48.11582946777344, 0.984375\n",
      "Train loss and acc of batch 3: 48.04673767089844, 0.984375\n",
      "Train loss and acc of batch 4: 47.82996368408203, 1.0\n",
      "Train loss and acc of batch 5: 49.17888641357422, 0.96875\n",
      "Train loss and acc of batch 6: 48.33256149291992, 0.96875\n",
      "Train loss and acc of batch 7: 47.82993698120117, 1.0\n",
      "Train loss and acc of batch 8: 48.425628662109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.11577606201172, 0.984375\n",
      "Train loss and acc of batch 10: 47.82991027832031, 1.0\n",
      "Train loss and acc of batch 11: 47.82990264892578, 1.0\n",
      "Train loss and acc of batch 12: 48.5831184387207, 0.984375\n",
      "Train loss and acc of batch 13: 48.04664611816406, 0.984375\n",
      "Train loss and acc of batch 14: 48.04663848876953, 0.984375\n",
      "Train loss and acc of batch 15: 48.425567626953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.425559997558594, 0.984375\n",
      "Train loss and acc of batch 17: 48.583072662353516, 0.984375\n",
      "Train loss and acc of batch 18: 48.71139144897461, 0.96875\n",
      "Train loss and acc of batch 19: 47.829830169677734, 1.0\n",
      "Train loss and acc of batch 20: 47.8298225402832, 1.0\n",
      "Train loss and acc of batch 21: 48.425514221191406, 0.984375\n",
      "Train loss and acc of batch 22: 48.425506591796875, 0.984375\n",
      "Train loss and acc of batch 23: 47.829795837402344, 1.0\n",
      "Train loss and acc of batch 24: 48.42548370361328, 0.984375\n",
      "Train loss and acc of batch 25: 47.82978057861328, 1.0\n",
      "Train loss and acc of batch 26: 47.829769134521484, 1.0\n",
      "Train loss and acc of batch 27: 47.82975769042969, 1.0\n",
      "Train loss and acc of batch 28: 47.829750061035156, 1.0\n",
      "Train loss and acc of batch 29: 48.425437927246094, 0.984375\n",
      "Train loss and acc of batch 30: 47.82973098754883, 1.0\n",
      "Train loss and acc of batch 31: 48.046485900878906, 0.984375\n",
      "Train loss and acc of batch 32: 47.829715728759766, 1.0\n",
      "Train loss and acc of batch 33: 47.82970428466797, 1.0\n",
      "Train loss and acc of batch 34: 48.42539978027344, 0.984375\n",
      "Train loss and acc of batch 35: 48.263221740722656, 0.96875\n",
      "Train loss and acc of batch 36: 47.82967758178711, 1.0\n",
      "Train loss and acc of batch 37: 48.58289337158203, 0.984375\n",
      "Train loss and acc of batch 38: 49.1785888671875, 0.96875\n",
      "Train loss and acc of batch 39: 48.046417236328125, 0.984375\n",
      "Train loss and acc of batch 40: 47.82964324951172, 1.0\n",
      "Train loss and acc of batch 41: 49.178558349609375, 0.96875\n",
      "Train loss and acc of batch 42: 47.829627990722656, 1.0\n",
      "Train loss and acc of batch 43: 48.425315856933594, 0.984375\n",
      "Train loss and acc of batch 44: 47.82960891723633, 1.0\n",
      "Train loss and acc of batch 45: 48.42530059814453, 0.984375\n",
      "Train loss and acc of batch 46: 48.115440368652344, 0.984375\n",
      "Train loss and acc of batch 47: 47.8295783996582, 1.0\n",
      "Train loss and acc of batch 48: 47.82957458496094, 1.0\n",
      "Train loss and acc of batch 49: 47.829566955566406, 1.0\n",
      "Train loss and acc of batch 50: 48.425254821777344, 0.984375\n",
      "Train loss and acc of batch 51: 49.178466796875, 0.96875\n",
      "Train loss and acc of batch 52: 49.08537673950195, 0.953125\n",
      "Train loss and acc of batch 53: 47.82952880859375, 1.0\n",
      "Train loss and acc of batch 54: 48.046287536621094, 0.984375\n",
      "Train loss and acc of batch 55: 47.82950973510742, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 56: 47.82950210571289, 1.0\n",
      "Train loss and acc of batch 57: 48.425193786621094, 0.984375\n",
      "Train loss and acc of batch 58: 47.82948684692383, 1.0\n",
      "Train loss and acc of batch 59: 47.82947540283203, 1.0\n",
      "Train loss and acc of batch 60: 47.829463958740234, 1.0\n",
      "Train loss and acc of batch 61: 47.8294563293457, 1.0\n",
      "Train loss and acc of batch 62: 47.82944869995117, 1.0\n",
      "Train loss and acc of batch 63: 49.020843505859375, 0.96875\n",
      "Train loss and acc of batch 64: 48.04618835449219, 0.984375\n",
      "Train loss and acc of batch 65: 47.82942199707031, 1.0\n",
      "Train loss and acc of batch 66: 47.82941436767578, 1.0\n",
      "Train loss and acc of batch 67: 48.64187240600586, 0.96875\n",
      "Train loss and acc of batch 68: 48.42509460449219, 0.984375\n",
      "Train loss and acc of batch 69: 48.04615020751953, 0.984375\n",
      "Train loss and acc of batch 70: 47.829376220703125, 1.0\n",
      "Training accuracy and loss of epoch #362: 0.9894, 48.1546\n",
      "Saved model by train loss 48.154597591346416\n",
      "Train loss and acc of batch 0: 47.82937240600586, 1.0\n",
      "Train loss and acc of batch 1: 47.8293571472168, 1.0\n",
      "Train loss and acc of batch 2: 48.115203857421875, 0.984375\n",
      "Train loss and acc of batch 3: 48.046104431152344, 0.984375\n",
      "Train loss and acc of batch 4: 47.82933044433594, 1.0\n",
      "Train loss and acc of batch 5: 49.178245544433594, 0.96875\n",
      "Train loss and acc of batch 6: 48.33193588256836, 0.96875\n",
      "Train loss and acc of batch 7: 47.82930374145508, 1.0\n",
      "Train loss and acc of batch 8: 48.42499542236328, 0.984375\n",
      "Train loss and acc of batch 9: 48.115142822265625, 0.984375\n",
      "Train loss and acc of batch 10: 47.829280853271484, 1.0\n",
      "Train loss and acc of batch 11: 47.82926940917969, 1.0\n",
      "Train loss and acc of batch 12: 48.582481384277344, 0.984375\n",
      "Train loss and acc of batch 13: 48.04601287841797, 0.984375\n",
      "Train loss and acc of batch 14: 48.04600524902344, 0.984375\n",
      "Train loss and acc of batch 15: 48.42494201660156, 0.984375\n",
      "Train loss and acc of batch 16: 48.4249267578125, 0.984375\n",
      "Train loss and acc of batch 17: 48.58243942260742, 0.984375\n",
      "Train loss and acc of batch 18: 48.71076202392578, 0.96875\n",
      "Train loss and acc of batch 19: 47.82919692993164, 1.0\n",
      "Train loss and acc of batch 20: 47.829193115234375, 1.0\n",
      "Train loss and acc of batch 21: 48.42488098144531, 0.984375\n",
      "Train loss and acc of batch 22: 48.42487335205078, 0.984375\n",
      "Train loss and acc of batch 23: 47.82916259765625, 1.0\n",
      "Train loss and acc of batch 24: 48.42485809326172, 0.984375\n",
      "Train loss and acc of batch 25: 47.82914733886719, 1.0\n",
      "Train loss and acc of batch 26: 47.82913589477539, 1.0\n",
      "Train loss and acc of batch 27: 47.82912826538086, 1.0\n",
      "Train loss and acc of batch 28: 47.82912063598633, 1.0\n",
      "Train loss and acc of batch 29: 48.42481231689453, 0.984375\n",
      "Train loss and acc of batch 30: 47.829097747802734, 1.0\n",
      "Train loss and acc of batch 31: 48.04585266113281, 0.984375\n",
      "Train loss and acc of batch 32: 47.82908630371094, 1.0\n",
      "Train loss and acc of batch 33: 47.829078674316406, 1.0\n",
      "Train loss and acc of batch 34: 48.424766540527344, 0.984375\n",
      "Train loss and acc of batch 35: 48.2625846862793, 0.96875\n",
      "Train loss and acc of batch 36: 47.82904815673828, 1.0\n",
      "Train loss and acc of batch 37: 48.5822639465332, 0.984375\n",
      "Train loss and acc of batch 38: 49.177955627441406, 0.96875\n",
      "Train loss and acc of batch 39: 48.04578399658203, 0.984375\n",
      "Train loss and acc of batch 40: 47.829010009765625, 1.0\n",
      "Train loss and acc of batch 41: 49.17793273925781, 0.96875\n",
      "Train loss and acc of batch 42: 47.82899856567383, 1.0\n",
      "Train loss and acc of batch 43: 48.42469024658203, 0.984375\n",
      "Train loss and acc of batch 44: 47.828975677490234, 1.0\n",
      "Train loss and acc of batch 45: 48.42466735839844, 0.984375\n",
      "Train loss and acc of batch 46: 48.11480712890625, 0.984375\n",
      "Train loss and acc of batch 47: 47.828948974609375, 1.0\n",
      "Train loss and acc of batch 48: 47.82893753051758, 1.0\n",
      "Train loss and acc of batch 49: 47.82892990112305, 1.0\n",
      "Train loss and acc of batch 50: 48.42462158203125, 0.984375\n",
      "Train loss and acc of batch 51: 49.17784118652344, 0.96875\n",
      "Train loss and acc of batch 52: 49.08474349975586, 0.953125\n",
      "Train loss and acc of batch 53: 47.828895568847656, 1.0\n",
      "Train loss and acc of batch 54: 48.045654296875, 0.984375\n",
      "Train loss and acc of batch 55: 47.828880310058594, 1.0\n",
      "Train loss and acc of batch 56: 47.8288688659668, 1.0\n",
      "Train loss and acc of batch 57: 48.424560546875, 0.984375\n",
      "Train loss and acc of batch 58: 47.828853607177734, 1.0\n",
      "Train loss and acc of batch 59: 47.82884216308594, 1.0\n",
      "Train loss and acc of batch 60: 47.828834533691406, 1.0\n",
      "Train loss and acc of batch 61: 47.82882308959961, 1.0\n",
      "Train loss and acc of batch 62: 47.828819274902344, 1.0\n",
      "Train loss and acc of batch 63: 49.020206451416016, 0.96875\n",
      "Train loss and acc of batch 64: 48.045562744140625, 0.984375\n",
      "Train loss and acc of batch 65: 47.82878875732422, 1.0\n",
      "Train loss and acc of batch 66: 47.82878494262695, 1.0\n",
      "Train loss and acc of batch 67: 48.6412353515625, 0.96875\n",
      "Train loss and acc of batch 68: 48.424468994140625, 0.984375\n",
      "Train loss and acc of batch 69: 48.04551696777344, 0.984375\n",
      "Train loss and acc of batch 70: 47.82875061035156, 1.0\n",
      "Training accuracy and loss of epoch #363: 0.9894, 48.1540\n",
      "Saved model by train loss 48.1539660709005\n",
      "Train loss and acc of batch 0: 47.828739166259766, 1.0\n",
      "Train loss and acc of batch 1: 47.828731536865234, 1.0\n",
      "Train loss and acc of batch 2: 48.11457061767578, 0.984375\n",
      "Train loss and acc of batch 3: 48.04547119140625, 0.984375\n",
      "Train loss and acc of batch 4: 47.82870101928711, 1.0\n",
      "Train loss and acc of batch 5: 49.17761993408203, 0.96875\n",
      "Train loss and acc of batch 6: 48.331302642822266, 0.96875\n",
      "Train loss and acc of batch 7: 47.82867431640625, 1.0\n",
      "Train loss and acc of batch 8: 48.42436981201172, 0.984375\n",
      "Train loss and acc of batch 9: 48.11451721191406, 0.984375\n",
      "Train loss and acc of batch 10: 47.828643798828125, 1.0\n",
      "Train loss and acc of batch 11: 47.828636169433594, 1.0\n",
      "Train loss and acc of batch 12: 48.581851959228516, 0.984375\n",
      "Train loss and acc of batch 13: 48.045387268066406, 0.984375\n",
      "Train loss and acc of batch 14: 48.045379638671875, 0.984375\n",
      "Train loss and acc of batch 15: 48.42430877685547, 0.984375\n",
      "Train loss and acc of batch 16: 48.424293518066406, 0.984375\n",
      "Train loss and acc of batch 17: 48.58180618286133, 0.984375\n",
      "Train loss and acc of batch 18: 48.71013259887695, 0.96875\n",
      "Train loss and acc of batch 19: 47.82856750488281, 1.0\n",
      "Train loss and acc of batch 20: 47.82855987548828, 1.0\n",
      "Train loss and acc of batch 21: 48.42424774169922, 0.984375\n",
      "Train loss and acc of batch 22: 48.42424011230469, 0.984375\n",
      "Train loss and acc of batch 23: 47.82853317260742, 1.0\n",
      "Train loss and acc of batch 24: 48.424224853515625, 0.984375\n",
      "Train loss and acc of batch 25: 47.82851028442383, 1.0\n",
      "Train loss and acc of batch 26: 47.82850646972656, 1.0\n",
      "Train loss and acc of batch 27: 47.82849884033203, 1.0\n",
      "Train loss and acc of batch 28: 47.8284912109375, 1.0\n",
      "Train loss and acc of batch 29: 48.42418670654297, 0.984375\n",
      "Train loss and acc of batch 30: 47.82847213745117, 1.0\n",
      "Train loss and acc of batch 31: 48.04522705078125, 0.984375\n",
      "Train loss and acc of batch 32: 47.82845687866211, 1.0\n",
      "Train loss and acc of batch 33: 47.82844543457031, 1.0\n",
      "Train loss and acc of batch 34: 48.42414093017578, 0.984375\n",
      "Train loss and acc of batch 35: 48.261959075927734, 0.96875\n",
      "Train loss and acc of batch 36: 47.82841873168945, 1.0\n",
      "Train loss and acc of batch 37: 48.581634521484375, 0.984375\n",
      "Train loss and acc of batch 38: 49.177330017089844, 0.96875\n",
      "Train loss and acc of batch 39: 48.04515075683594, 0.984375\n",
      "Train loss and acc of batch 40: 47.8283805847168, 1.0\n",
      "Train loss and acc of batch 41: 49.17729568481445, 0.96875\n",
      "Train loss and acc of batch 42: 47.828365325927734, 1.0\n",
      "Train loss and acc of batch 43: 48.42405700683594, 0.984375\n",
      "Train loss and acc of batch 44: 47.82835006713867, 1.0\n",
      "Train loss and acc of batch 45: 48.424041748046875, 0.984375\n",
      "Train loss and acc of batch 46: 48.11418914794922, 0.984375\n",
      "Train loss and acc of batch 47: 47.82831573486328, 1.0\n",
      "Train loss and acc of batch 48: 47.828311920166016, 1.0\n",
      "Train loss and acc of batch 49: 47.828304290771484, 1.0\n",
      "Train loss and acc of batch 50: 48.423988342285156, 0.984375\n",
      "Train loss and acc of batch 51: 49.177207946777344, 0.96875\n",
      "Train loss and acc of batch 52: 49.0841178894043, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.82826614379883, 1.0\n",
      "Train loss and acc of batch 54: 48.045021057128906, 0.984375\n",
      "Train loss and acc of batch 55: 47.8282470703125, 1.0\n",
      "Train loss and acc of batch 56: 47.82823944091797, 1.0\n",
      "Train loss and acc of batch 57: 48.42393493652344, 0.984375\n",
      "Train loss and acc of batch 58: 47.82822036743164, 1.0\n",
      "Train loss and acc of batch 59: 47.82821273803711, 1.0\n",
      "Train loss and acc of batch 60: 47.828208923339844, 1.0\n",
      "Train loss and acc of batch 61: 47.82819747924805, 1.0\n",
      "Train loss and acc of batch 62: 47.828182220458984, 1.0\n",
      "Train loss and acc of batch 63: 49.01958084106445, 0.96875\n",
      "Train loss and acc of batch 64: 48.04492950439453, 0.984375\n",
      "Train loss and acc of batch 65: 47.828163146972656, 1.0\n",
      "Train loss and acc of batch 66: 47.82815170288086, 1.0\n",
      "Train loss and acc of batch 67: 48.64060592651367, 0.96875\n",
      "Train loss and acc of batch 68: 48.42383575439453, 0.984375\n",
      "Train loss and acc of batch 69: 48.044891357421875, 0.984375\n",
      "Train loss and acc of batch 70: 47.8281135559082, 1.0\n",
      "Training accuracy and loss of epoch #364: 0.9894, 48.1533\n",
      "Saved model by train loss 48.1533361622985\n",
      "Train loss and acc of batch 0: 47.82810974121094, 1.0\n",
      "Train loss and acc of batch 1: 47.82809829711914, 1.0\n",
      "Train loss and acc of batch 2: 48.11394500732422, 0.984375\n",
      "Train loss and acc of batch 3: 48.04484558105469, 0.984375\n",
      "Train loss and acc of batch 4: 47.82807159423828, 1.0\n",
      "Train loss and acc of batch 5: 49.17698669433594, 0.96875\n",
      "Train loss and acc of batch 6: 48.33067321777344, 0.96875\n",
      "Train loss and acc of batch 7: 47.828041076660156, 1.0\n",
      "Train loss and acc of batch 8: 48.423736572265625, 0.984375\n",
      "Train loss and acc of batch 9: 48.11387634277344, 0.984375\n",
      "Train loss and acc of batch 10: 47.82801818847656, 1.0\n",
      "Train loss and acc of batch 11: 47.828006744384766, 1.0\n",
      "Train loss and acc of batch 12: 48.58122253417969, 0.984375\n",
      "Train loss and acc of batch 13: 48.04475402832031, 0.984375\n",
      "Train loss and acc of batch 14: 48.04474639892578, 0.984375\n",
      "Train loss and acc of batch 15: 48.423675537109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.423667907714844, 0.984375\n",
      "Train loss and acc of batch 17: 48.581180572509766, 0.984375\n",
      "Train loss and acc of batch 18: 48.709503173828125, 0.96875\n",
      "Train loss and acc of batch 19: 47.82793426513672, 1.0\n",
      "Train loss and acc of batch 20: 47.82792282104492, 1.0\n",
      "Train loss and acc of batch 21: 48.423622131347656, 0.984375\n",
      "Train loss and acc of batch 22: 48.423614501953125, 0.984375\n",
      "Train loss and acc of batch 23: 47.82789993286133, 1.0\n",
      "Train loss and acc of batch 24: 48.42359161376953, 0.984375\n",
      "Train loss and acc of batch 25: 47.827884674072266, 1.0\n",
      "Train loss and acc of batch 26: 47.827877044677734, 1.0\n",
      "Train loss and acc of batch 27: 47.82786560058594, 1.0\n",
      "Train loss and acc of batch 28: 47.827857971191406, 1.0\n",
      "Train loss and acc of batch 29: 48.423545837402344, 0.984375\n",
      "Train loss and acc of batch 30: 47.82783889770508, 1.0\n",
      "Train loss and acc of batch 31: 48.044593811035156, 0.984375\n",
      "Train loss and acc of batch 32: 47.82781982421875, 1.0\n",
      "Train loss and acc of batch 33: 47.827816009521484, 1.0\n",
      "Train loss and acc of batch 34: 48.423500061035156, 0.984375\n",
      "Train loss and acc of batch 35: 48.26132583618164, 0.96875\n",
      "Train loss and acc of batch 36: 47.82778549194336, 1.0\n",
      "Train loss and acc of batch 37: 48.58100128173828, 0.984375\n",
      "Train loss and acc of batch 38: 49.17668914794922, 0.96875\n",
      "Train loss and acc of batch 39: 48.044525146484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.82775115966797, 1.0\n",
      "Train loss and acc of batch 41: 49.176666259765625, 0.96875\n",
      "Train loss and acc of batch 42: 47.82773208618164, 1.0\n",
      "Train loss and acc of batch 43: 48.423423767089844, 0.984375\n",
      "Train loss and acc of batch 44: 47.82771301269531, 1.0\n",
      "Train loss and acc of batch 45: 48.42340850830078, 0.984375\n",
      "Train loss and acc of batch 46: 48.113548278808594, 0.984375\n",
      "Train loss and acc of batch 47: 47.82769012451172, 1.0\n",
      "Train loss and acc of batch 48: 47.82767868041992, 1.0\n",
      "Train loss and acc of batch 49: 47.827667236328125, 1.0\n",
      "Train loss and acc of batch 50: 48.423362731933594, 0.984375\n",
      "Train loss and acc of batch 51: 49.17657470703125, 0.96875\n",
      "Train loss and acc of batch 52: 49.0834846496582, 0.953125\n",
      "Train loss and acc of batch 53: 47.82763671875, 1.0\n",
      "Train loss and acc of batch 54: 48.04438781738281, 0.984375\n",
      "Train loss and acc of batch 55: 47.827613830566406, 1.0\n",
      "Train loss and acc of batch 56: 47.82761001586914, 1.0\n",
      "Train loss and acc of batch 57: 48.423301696777344, 0.984375\n",
      "Train loss and acc of batch 58: 47.82759094238281, 1.0\n",
      "Train loss and acc of batch 59: 47.82758331298828, 1.0\n",
      "Train loss and acc of batch 60: 47.827571868896484, 1.0\n",
      "Train loss and acc of batch 61: 47.82756423950195, 1.0\n",
      "Train loss and acc of batch 62: 47.82755661010742, 1.0\n",
      "Train loss and acc of batch 63: 49.01894760131836, 0.96875\n",
      "Train loss and acc of batch 64: 48.04430389404297, 0.984375\n",
      "Train loss and acc of batch 65: 47.82753372192383, 1.0\n",
      "Train loss and acc of batch 66: 47.827518463134766, 1.0\n",
      "Train loss and acc of batch 67: 48.639976501464844, 0.96875\n",
      "Train loss and acc of batch 68: 48.42320251464844, 0.984375\n",
      "Train loss and acc of batch 69: 48.04425811767578, 0.984375\n",
      "Train loss and acc of batch 70: 47.827484130859375, 1.0\n",
      "Training accuracy and loss of epoch #365: 0.9894, 48.1527\n",
      "Saved model by train loss 48.152704426940055\n",
      "Train loss and acc of batch 0: 47.82747268676758, 1.0\n",
      "Train loss and acc of batch 1: 47.82746505737305, 1.0\n",
      "Train loss and acc of batch 2: 48.113311767578125, 0.984375\n",
      "Train loss and acc of batch 3: 48.044212341308594, 0.984375\n",
      "Train loss and acc of batch 4: 47.82743835449219, 1.0\n",
      "Train loss and acc of batch 5: 49.176361083984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.33003616333008, 0.96875\n",
      "Train loss and acc of batch 7: 47.827415466308594, 1.0\n",
      "Train loss and acc of batch 8: 48.42311096191406, 0.984375\n",
      "Train loss and acc of batch 9: 48.113250732421875, 0.984375\n",
      "Train loss and acc of batch 10: 47.82738494873047, 1.0\n",
      "Train loss and acc of batch 11: 47.82737731933594, 1.0\n",
      "Train loss and acc of batch 12: 48.58059310913086, 0.984375\n",
      "Train loss and acc of batch 13: 48.04412078857422, 0.984375\n",
      "Train loss and acc of batch 14: 48.04411315917969, 0.984375\n",
      "Train loss and acc of batch 15: 48.42304229736328, 0.984375\n",
      "Train loss and acc of batch 16: 48.42303466796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.58055114746094, 0.984375\n",
      "Train loss and acc of batch 18: 48.70886993408203, 0.96875\n",
      "Train loss and acc of batch 19: 47.827308654785156, 1.0\n",
      "Train loss and acc of batch 20: 47.82729721069336, 1.0\n",
      "Train loss and acc of batch 21: 48.42298889160156, 0.984375\n",
      "Train loss and acc of batch 22: 48.42298126220703, 0.984375\n",
      "Train loss and acc of batch 23: 47.827266693115234, 1.0\n",
      "Train loss and acc of batch 24: 48.42296600341797, 0.984375\n",
      "Train loss and acc of batch 25: 47.82725143432617, 1.0\n",
      "Train loss and acc of batch 26: 47.82724380493164, 1.0\n",
      "Train loss and acc of batch 27: 47.827232360839844, 1.0\n",
      "Train loss and acc of batch 28: 47.82722473144531, 1.0\n",
      "Train loss and acc of batch 29: 48.42291259765625, 0.984375\n",
      "Train loss and acc of batch 30: 47.82720947265625, 1.0\n",
      "Train loss and acc of batch 31: 48.04396057128906, 0.984375\n",
      "Train loss and acc of batch 32: 47.82719039916992, 1.0\n",
      "Train loss and acc of batch 33: 47.82718276977539, 1.0\n",
      "Train loss and acc of batch 34: 48.422874450683594, 0.984375\n",
      "Train loss and acc of batch 35: 48.26069259643555, 0.96875\n",
      "Train loss and acc of batch 36: 47.8271598815918, 1.0\n",
      "Train loss and acc of batch 37: 48.58036804199219, 0.984375\n",
      "Train loss and acc of batch 38: 49.176063537597656, 0.96875\n",
      "Train loss and acc of batch 39: 48.04389190673828, 0.984375\n",
      "Train loss and acc of batch 40: 47.82712173461914, 1.0\n",
      "Train loss and acc of batch 41: 49.1760368347168, 0.96875\n",
      "Train loss and acc of batch 42: 47.82710266113281, 1.0\n",
      "Train loss and acc of batch 43: 48.42279052734375, 0.984375\n",
      "Train loss and acc of batch 44: 47.82708740234375, 1.0\n",
      "Train loss and acc of batch 45: 48.42277526855469, 0.984375\n",
      "Train loss and acc of batch 46: 48.1129150390625, 0.984375\n",
      "Train loss and acc of batch 47: 47.827056884765625, 1.0\n",
      "Train loss and acc of batch 48: 47.827049255371094, 1.0\n",
      "Train loss and acc of batch 49: 47.8270378112793, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 50: 48.42273712158203, 0.984375\n",
      "Train loss and acc of batch 51: 49.175941467285156, 0.96875\n",
      "Train loss and acc of batch 52: 49.082855224609375, 0.953125\n",
      "Train loss and acc of batch 53: 47.82700729370117, 1.0\n",
      "Train loss and acc of batch 54: 48.04376220703125, 0.984375\n",
      "Train loss and acc of batch 55: 47.82699203491211, 1.0\n",
      "Train loss and acc of batch 56: 47.82698059082031, 1.0\n",
      "Train loss and acc of batch 57: 48.42266845703125, 0.984375\n",
      "Train loss and acc of batch 58: 47.826961517333984, 1.0\n",
      "Train loss and acc of batch 59: 47.82695007324219, 1.0\n",
      "Train loss and acc of batch 60: 47.82693862915039, 1.0\n",
      "Train loss and acc of batch 61: 47.826934814453125, 1.0\n",
      "Train loss and acc of batch 62: 47.82691955566406, 1.0\n",
      "Train loss and acc of batch 63: 49.01831817626953, 0.96875\n",
      "Train loss and acc of batch 64: 48.043670654296875, 0.984375\n",
      "Train loss and acc of batch 65: 47.82689666748047, 1.0\n",
      "Train loss and acc of batch 66: 47.82688903808594, 1.0\n",
      "Train loss and acc of batch 67: 48.639347076416016, 0.96875\n",
      "Train loss and acc of batch 68: 48.422569274902344, 0.984375\n",
      "Train loss and acc of batch 69: 48.04363250732422, 0.984375\n",
      "Train loss and acc of batch 70: 47.82685470581055, 1.0\n",
      "Training accuracy and loss of epoch #366: 0.9894, 48.1521\n",
      "Saved model by train loss 48.15207365868797\n",
      "Train loss and acc of batch 0: 47.826839447021484, 1.0\n",
      "Train loss and acc of batch 1: 47.82683563232422, 1.0\n",
      "Train loss and acc of batch 2: 48.11267852783203, 0.984375\n",
      "Train loss and acc of batch 3: 48.0435791015625, 0.984375\n",
      "Train loss and acc of batch 4: 47.82680892944336, 1.0\n",
      "Train loss and acc of batch 5: 49.17572021484375, 0.96875\n",
      "Train loss and acc of batch 6: 48.329410552978516, 0.96875\n",
      "Train loss and acc of batch 7: 47.8267822265625, 1.0\n",
      "Train loss and acc of batch 8: 48.42247009277344, 0.984375\n",
      "Train loss and acc of batch 9: 48.11261749267578, 0.984375\n",
      "Train loss and acc of batch 10: 47.826759338378906, 1.0\n",
      "Train loss and acc of batch 11: 47.82674789428711, 1.0\n",
      "Train loss and acc of batch 12: 48.5799674987793, 0.984375\n",
      "Train loss and acc of batch 13: 48.043495178222656, 0.984375\n",
      "Train loss and acc of batch 14: 48.043487548828125, 0.984375\n",
      "Train loss and acc of batch 15: 48.42240905761719, 0.984375\n",
      "Train loss and acc of batch 16: 48.422401428222656, 0.984375\n",
      "Train loss and acc of batch 17: 48.57991409301758, 0.984375\n",
      "Train loss and acc of batch 18: 48.70823669433594, 0.96875\n",
      "Train loss and acc of batch 19: 47.82667541503906, 1.0\n",
      "Train loss and acc of batch 20: 47.82666778564453, 1.0\n",
      "Train loss and acc of batch 21: 48.42236328125, 0.984375\n",
      "Train loss and acc of batch 22: 48.42234802246094, 0.984375\n",
      "Train loss and acc of batch 23: 47.82664108276367, 1.0\n",
      "Train loss and acc of batch 24: 48.422332763671875, 0.984375\n",
      "Train loss and acc of batch 25: 47.826622009277344, 1.0\n",
      "Train loss and acc of batch 26: 47.82661819458008, 1.0\n",
      "Train loss and acc of batch 27: 47.82660675048828, 1.0\n",
      "Train loss and acc of batch 28: 47.826595306396484, 1.0\n",
      "Train loss and acc of batch 29: 48.42228698730469, 0.984375\n",
      "Train loss and acc of batch 30: 47.826576232910156, 1.0\n",
      "Train loss and acc of batch 31: 48.0433349609375, 0.984375\n",
      "Train loss and acc of batch 32: 47.82655715942383, 1.0\n",
      "Train loss and acc of batch 33: 47.82655334472656, 1.0\n",
      "Train loss and acc of batch 34: 48.4222412109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.26006317138672, 0.96875\n",
      "Train loss and acc of batch 36: 47.82652282714844, 1.0\n",
      "Train loss and acc of batch 37: 48.57973861694336, 0.984375\n",
      "Train loss and acc of batch 38: 49.17543029785156, 0.96875\n",
      "Train loss and acc of batch 39: 48.04326629638672, 0.984375\n",
      "Train loss and acc of batch 40: 47.82649230957031, 1.0\n",
      "Train loss and acc of batch 41: 49.17540740966797, 0.96875\n",
      "Train loss and acc of batch 42: 47.82646942138672, 1.0\n",
      "Train loss and acc of batch 43: 48.42217254638672, 0.984375\n",
      "Train loss and acc of batch 44: 47.826454162597656, 1.0\n",
      "Train loss and acc of batch 45: 48.422142028808594, 0.984375\n",
      "Train loss and acc of batch 46: 48.112281799316406, 0.984375\n",
      "Train loss and acc of batch 47: 47.8264274597168, 1.0\n",
      "Train loss and acc of batch 48: 47.826416015625, 1.0\n",
      "Train loss and acc of batch 49: 47.82640838623047, 1.0\n",
      "Train loss and acc of batch 50: 48.422096252441406, 0.984375\n",
      "Train loss and acc of batch 51: 49.175315856933594, 0.96875\n",
      "Train loss and acc of batch 52: 49.08222198486328, 0.953125\n",
      "Train loss and acc of batch 53: 47.82637023925781, 1.0\n",
      "Train loss and acc of batch 54: 48.043128967285156, 0.984375\n",
      "Train loss and acc of batch 55: 47.826358795166016, 1.0\n",
      "Train loss and acc of batch 56: 47.82634735107422, 1.0\n",
      "Train loss and acc of batch 57: 48.42204284667969, 0.984375\n",
      "Train loss and acc of batch 58: 47.82633590698242, 1.0\n",
      "Train loss and acc of batch 59: 47.826316833496094, 1.0\n",
      "Train loss and acc of batch 60: 47.82631301879883, 1.0\n",
      "Train loss and acc of batch 61: 47.826297760009766, 1.0\n",
      "Train loss and acc of batch 62: 47.8262939453125, 1.0\n",
      "Train loss and acc of batch 63: 49.01769256591797, 0.96875\n",
      "Train loss and acc of batch 64: 48.04303741455078, 0.984375\n",
      "Train loss and acc of batch 65: 47.826263427734375, 1.0\n",
      "Train loss and acc of batch 66: 47.82625961303711, 1.0\n",
      "Train loss and acc of batch 67: 48.638710021972656, 0.96875\n",
      "Train loss and acc of batch 68: 48.42194366455078, 0.984375\n",
      "Train loss and acc of batch 69: 48.042999267578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.82622146606445, 1.0\n",
      "Training accuracy and loss of epoch #367: 0.9894, 48.1514\n",
      "Saved model by train loss 48.151442836707744\n",
      "Train loss and acc of batch 0: 47.82621383666992, 1.0\n",
      "Train loss and acc of batch 1: 47.826210021972656, 1.0\n",
      "Train loss and acc of batch 2: 47.826194763183594, 1.0\n",
      "Train loss and acc of batch 3: 48.04295349121094, 0.984375\n",
      "Train loss and acc of batch 4: 47.826175689697266, 1.0\n",
      "Train loss and acc of batch 5: 49.17509460449219, 0.96875\n",
      "Train loss and acc of batch 6: 48.32878112792969, 0.96875\n",
      "Train loss and acc of batch 7: 47.826148986816406, 1.0\n",
      "Train loss and acc of batch 8: 48.421844482421875, 0.984375\n",
      "Train loss and acc of batch 9: 48.11199188232422, 0.984375\n",
      "Train loss and acc of batch 10: 47.82612228393555, 1.0\n",
      "Train loss and acc of batch 11: 47.82611846923828, 1.0\n",
      "Train loss and acc of batch 12: 48.57932662963867, 0.984375\n",
      "Train loss and acc of batch 13: 48.04286193847656, 0.984375\n",
      "Train loss and acc of batch 14: 48.04285430908203, 0.984375\n",
      "Train loss and acc of batch 15: 48.421783447265625, 0.984375\n",
      "Train loss and acc of batch 16: 48.42176818847656, 0.984375\n",
      "Train loss and acc of batch 17: 48.579288482666016, 0.984375\n",
      "Train loss and acc of batch 18: 48.707603454589844, 0.96875\n",
      "Train loss and acc of batch 19: 47.82604217529297, 1.0\n",
      "Train loss and acc of batch 20: 47.8260383605957, 1.0\n",
      "Train loss and acc of batch 21: 48.421722412109375, 0.984375\n",
      "Train loss and acc of batch 22: 48.421722412109375, 0.984375\n",
      "Train loss and acc of batch 23: 47.826011657714844, 1.0\n",
      "Train loss and acc of batch 24: 48.42169952392578, 0.984375\n",
      "Train loss and acc of batch 25: 47.825992584228516, 1.0\n",
      "Train loss and acc of batch 26: 47.825984954833984, 1.0\n",
      "Train loss and acc of batch 27: 47.82596969604492, 1.0\n",
      "Train loss and acc of batch 28: 47.825965881347656, 1.0\n",
      "Train loss and acc of batch 29: 48.421661376953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.82594680786133, 1.0\n",
      "Train loss and acc of batch 31: 48.042701721191406, 0.984375\n",
      "Train loss and acc of batch 32: 47.825923919677734, 1.0\n",
      "Train loss and acc of batch 33: 47.82592010498047, 1.0\n",
      "Train loss and acc of batch 34: 48.42161560058594, 0.984375\n",
      "Train loss and acc of batch 35: 48.25942611694336, 0.96875\n",
      "Train loss and acc of batch 36: 47.82589340209961, 1.0\n",
      "Train loss and acc of batch 37: 48.57910919189453, 0.984375\n",
      "Train loss and acc of batch 38: 49.17479705810547, 0.96875\n",
      "Train loss and acc of batch 39: 48.042633056640625, 0.984375\n",
      "Train loss and acc of batch 40: 47.82585906982422, 1.0\n",
      "Train loss and acc of batch 41: 49.174774169921875, 0.96875\n",
      "Train loss and acc of batch 42: 47.825843811035156, 1.0\n",
      "Train loss and acc of batch 43: 48.421539306640625, 0.984375\n",
      "Train loss and acc of batch 44: 47.82582092285156, 1.0\n",
      "Train loss and acc of batch 45: 48.42151641845703, 0.984375\n",
      "Train loss and acc of batch 46: 48.111656188964844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 47.8257942199707, 1.0\n",
      "Train loss and acc of batch 48: 47.82579040527344, 1.0\n",
      "Train loss and acc of batch 49: 47.825775146484375, 1.0\n",
      "Train loss and acc of batch 50: 48.421470642089844, 0.984375\n",
      "Train loss and acc of batch 51: 49.1746826171875, 0.96875\n",
      "Train loss and acc of batch 52: 49.08159255981445, 0.953125\n",
      "Train loss and acc of batch 53: 47.82574462890625, 1.0\n",
      "Train loss and acc of batch 54: 48.04249572753906, 0.984375\n",
      "Train loss and acc of batch 55: 47.825721740722656, 1.0\n",
      "Train loss and acc of batch 56: 47.82571792602539, 1.0\n",
      "Train loss and acc of batch 57: 48.421409606933594, 0.984375\n",
      "Train loss and acc of batch 58: 47.82569885253906, 1.0\n",
      "Train loss and acc of batch 59: 47.82569122314453, 1.0\n",
      "Train loss and acc of batch 60: 47.825679779052734, 1.0\n",
      "Train loss and acc of batch 61: 47.8256721496582, 1.0\n",
      "Train loss and acc of batch 62: 47.82566452026367, 1.0\n",
      "Train loss and acc of batch 63: 49.01705551147461, 0.96875\n",
      "Train loss and acc of batch 64: 48.04240417480469, 0.984375\n",
      "Train loss and acc of batch 65: 47.82563781738281, 1.0\n",
      "Train loss and acc of batch 66: 47.825626373291016, 1.0\n",
      "Train loss and acc of batch 67: 48.63808822631836, 0.96875\n",
      "Train loss and acc of batch 68: 48.421302795410156, 0.984375\n",
      "Train loss and acc of batch 69: 48.04236602783203, 0.984375\n",
      "Train loss and acc of batch 70: 47.825592041015625, 1.0\n",
      "Training accuracy and loss of epoch #368: 0.9897, 48.1468\n",
      "Saved model by train acc 0.9896566901408451\n",
      "Saved model by train loss 48.14678589726837\n",
      "Train loss and acc of batch 0: 47.82558059692383, 1.0\n",
      "Train loss and acc of batch 1: 47.82556915283203, 1.0\n",
      "Train loss and acc of batch 2: 47.825565338134766, 1.0\n",
      "Train loss and acc of batch 3: 48.042320251464844, 0.984375\n",
      "Train loss and acc of batch 4: 47.8255500793457, 1.0\n",
      "Train loss and acc of batch 5: 49.174461364746094, 0.96875\n",
      "Train loss and acc of batch 6: 48.32814407348633, 0.96875\n",
      "Train loss and acc of batch 7: 47.82551574707031, 1.0\n",
      "Train loss and acc of batch 8: 48.42121124267578, 0.984375\n",
      "Train loss and acc of batch 9: 48.111351013183594, 0.984375\n",
      "Train loss and acc of batch 10: 47.82549285888672, 1.0\n",
      "Train loss and acc of batch 11: 47.82548522949219, 1.0\n",
      "Train loss and acc of batch 12: 48.578697204589844, 0.984375\n",
      "Train loss and acc of batch 13: 48.04222869873047, 0.984375\n",
      "Train loss and acc of batch 14: 48.04222106933594, 0.984375\n",
      "Train loss and acc of batch 15: 48.42115020751953, 0.984375\n",
      "Train loss and acc of batch 16: 48.421142578125, 0.984375\n",
      "Train loss and acc of batch 17: 48.57865524291992, 0.984375\n",
      "Train loss and acc of batch 18: 48.70697784423828, 0.96875\n",
      "Train loss and acc of batch 19: 47.82541275024414, 1.0\n",
      "Train loss and acc of batch 20: 47.825408935546875, 1.0\n",
      "Train loss and acc of batch 21: 48.42109680175781, 0.984375\n",
      "Train loss and acc of batch 22: 48.42108917236328, 0.984375\n",
      "Train loss and acc of batch 23: 47.82537841796875, 1.0\n",
      "Train loss and acc of batch 24: 48.42106628417969, 0.984375\n",
      "Train loss and acc of batch 25: 47.82536315917969, 1.0\n",
      "Train loss and acc of batch 26: 47.825347900390625, 1.0\n",
      "Train loss and acc of batch 27: 47.82534408569336, 1.0\n",
      "Train loss and acc of batch 28: 47.8253288269043, 1.0\n",
      "Train loss and acc of batch 29: 48.4210205078125, 0.984375\n",
      "Train loss and acc of batch 30: 47.82530975341797, 1.0\n",
      "Train loss and acc of batch 31: 48.04206848144531, 0.984375\n",
      "Train loss and acc of batch 32: 47.825294494628906, 1.0\n",
      "Train loss and acc of batch 33: 47.825286865234375, 1.0\n",
      "Train loss and acc of batch 34: 48.420982360839844, 0.984375\n",
      "Train loss and acc of batch 35: 48.25879669189453, 0.96875\n",
      "Train loss and acc of batch 36: 47.82525634765625, 1.0\n",
      "Train loss and acc of batch 37: 48.57847595214844, 0.984375\n",
      "Train loss and acc of batch 38: 49.174163818359375, 0.96875\n",
      "Train loss and acc of batch 39: 48.0419921875, 0.984375\n",
      "Train loss and acc of batch 40: 47.82522201538086, 1.0\n",
      "Train loss and acc of batch 41: 49.17414474487305, 0.96875\n",
      "Train loss and acc of batch 42: 47.8252067565918, 1.0\n",
      "Train loss and acc of batch 43: 48.42089080810547, 0.984375\n",
      "Train loss and acc of batch 44: 47.82518768310547, 1.0\n",
      "Train loss and acc of batch 45: 48.42088317871094, 0.984375\n",
      "Train loss and acc of batch 46: 48.11102294921875, 0.984375\n",
      "Train loss and acc of batch 47: 47.825164794921875, 1.0\n",
      "Train loss and acc of batch 48: 47.82515335083008, 1.0\n",
      "Train loss and acc of batch 49: 47.82514572143555, 1.0\n",
      "Train loss and acc of batch 50: 48.42083740234375, 0.984375\n",
      "Train loss and acc of batch 51: 49.174049377441406, 0.96875\n",
      "Train loss and acc of batch 52: 49.080955505371094, 0.953125\n",
      "Train loss and acc of batch 53: 47.82510757446289, 1.0\n",
      "Train loss and acc of batch 54: 48.0418701171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.82509231567383, 1.0\n",
      "Train loss and acc of batch 56: 47.8250846862793, 1.0\n",
      "Train loss and acc of batch 57: 48.42076873779297, 0.984375\n",
      "Train loss and acc of batch 58: 47.8250617980957, 1.0\n",
      "Train loss and acc of batch 59: 47.82505416870117, 1.0\n",
      "Train loss and acc of batch 60: 47.82504653930664, 1.0\n",
      "Train loss and acc of batch 61: 47.82503890991211, 1.0\n",
      "Train loss and acc of batch 62: 47.82502746582031, 1.0\n",
      "Train loss and acc of batch 63: 49.016422271728516, 0.96875\n",
      "Train loss and acc of batch 64: 48.041778564453125, 0.984375\n",
      "Train loss and acc of batch 65: 47.82500457763672, 1.0\n",
      "Train loss and acc of batch 66: 47.82499313354492, 1.0\n",
      "Train loss and acc of batch 67: 48.637447357177734, 0.96875\n",
      "Train loss and acc of batch 68: 48.420677185058594, 0.984375\n",
      "Train loss and acc of batch 69: 48.04173278808594, 0.984375\n",
      "Train loss and acc of batch 70: 47.8249626159668, 1.0\n",
      "Training accuracy and loss of epoch #369: 0.9897, 48.1462\n",
      "Saved model by train loss 48.14615265752228\n",
      "Train loss and acc of batch 0: 47.824947357177734, 1.0\n",
      "Train loss and acc of batch 1: 47.82493591308594, 1.0\n",
      "Train loss and acc of batch 2: 47.824928283691406, 1.0\n",
      "Train loss and acc of batch 3: 48.04168701171875, 0.984375\n",
      "Train loss and acc of batch 4: 47.824913024902344, 1.0\n",
      "Train loss and acc of batch 5: 49.173828125, 0.96875\n",
      "Train loss and acc of batch 6: 48.3275146484375, 0.96875\n",
      "Train loss and acc of batch 7: 47.824886322021484, 1.0\n",
      "Train loss and acc of batch 8: 48.42057800292969, 0.984375\n",
      "Train loss and acc of batch 9: 48.1107177734375, 0.984375\n",
      "Train loss and acc of batch 10: 47.824859619140625, 1.0\n",
      "Train loss and acc of batch 11: 47.824851989746094, 1.0\n",
      "Train loss and acc of batch 12: 48.578067779541016, 0.984375\n",
      "Train loss and acc of batch 13: 48.041603088378906, 0.984375\n",
      "Train loss and acc of batch 14: 48.041587829589844, 0.984375\n",
      "Train loss and acc of batch 15: 48.420509338378906, 0.984375\n",
      "Train loss and acc of batch 16: 48.420509338378906, 0.984375\n",
      "Train loss and acc of batch 17: 48.57802200317383, 0.984375\n",
      "Train loss and acc of batch 18: 48.70634460449219, 0.96875\n",
      "Train loss and acc of batch 19: 47.82477569580078, 1.0\n",
      "Train loss and acc of batch 20: 47.824771881103516, 1.0\n",
      "Train loss and acc of batch 21: 48.42046356201172, 0.984375\n",
      "Train loss and acc of batch 22: 48.42045593261719, 0.984375\n",
      "Train loss and acc of batch 23: 47.82474136352539, 1.0\n",
      "Train loss and acc of batch 24: 48.420440673828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.82472229003906, 1.0\n",
      "Train loss and acc of batch 26: 47.8247184753418, 1.0\n",
      "Train loss and acc of batch 27: 47.824710845947266, 1.0\n",
      "Train loss and acc of batch 28: 47.82469940185547, 1.0\n",
      "Train loss and acc of batch 29: 48.42039489746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.82468032836914, 1.0\n",
      "Train loss and acc of batch 31: 48.04143524169922, 0.984375\n",
      "Train loss and acc of batch 32: 47.82466506958008, 1.0\n",
      "Train loss and acc of batch 33: 47.82465362548828, 1.0\n",
      "Train loss and acc of batch 34: 48.42034912109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.2581672668457, 0.96875\n",
      "Train loss and acc of batch 36: 47.82463073730469, 1.0\n",
      "Train loss and acc of batch 37: 48.577842712402344, 0.984375\n",
      "Train loss and acc of batch 38: 49.17353820800781, 0.96875\n",
      "Train loss and acc of batch 39: 48.04136657714844, 0.984375\n",
      "Train loss and acc of batch 40: 47.82459259033203, 1.0\n",
      "Train loss and acc of batch 41: 49.17351150512695, 0.96875\n",
      "Train loss and acc of batch 42: 47.8245735168457, 1.0\n",
      "Train loss and acc of batch 43: 48.420265197753906, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 44: 47.824554443359375, 1.0\n",
      "Train loss and acc of batch 45: 48.420249938964844, 0.984375\n",
      "Train loss and acc of batch 46: 48.110389709472656, 0.984375\n",
      "Train loss and acc of batch 47: 47.824527740478516, 1.0\n",
      "Train loss and acc of batch 48: 47.82452392578125, 1.0\n",
      "Train loss and acc of batch 49: 47.82451629638672, 1.0\n",
      "Train loss and acc of batch 50: 48.42021179199219, 0.984375\n",
      "Train loss and acc of batch 51: 49.173423767089844, 0.96875\n",
      "Train loss and acc of batch 52: 49.080326080322266, 0.953125\n",
      "Train loss and acc of batch 53: 47.82447814941406, 1.0\n",
      "Train loss and acc of batch 54: 48.041229248046875, 0.984375\n",
      "Train loss and acc of batch 55: 47.824462890625, 1.0\n",
      "Train loss and acc of batch 56: 47.82444763183594, 1.0\n",
      "Train loss and acc of batch 57: 48.420143127441406, 0.984375\n",
      "Train loss and acc of batch 58: 47.82442855834961, 1.0\n",
      "Train loss and acc of batch 59: 47.824424743652344, 1.0\n",
      "Train loss and acc of batch 60: 47.82441329956055, 1.0\n",
      "Train loss and acc of batch 61: 47.824405670166016, 1.0\n",
      "Train loss and acc of batch 62: 47.824398040771484, 1.0\n",
      "Train loss and acc of batch 63: 49.01579284667969, 0.96875\n",
      "Train loss and acc of batch 64: 48.04114532470703, 0.984375\n",
      "Train loss and acc of batch 65: 47.824371337890625, 1.0\n",
      "Train loss and acc of batch 66: 47.82435989379883, 1.0\n",
      "Train loss and acc of batch 67: 48.636817932128906, 0.96875\n",
      "Train loss and acc of batch 68: 48.4200439453125, 0.984375\n",
      "Train loss and acc of batch 69: 48.041107177734375, 0.984375\n",
      "Train loss and acc of batch 70: 47.82432556152344, 1.0\n",
      "Training accuracy and loss of epoch #370: 0.9897, 48.1455\n",
      "Saved model by train loss 48.14552081470758\n",
      "Train loss and acc of batch 0: 47.824317932128906, 1.0\n",
      "Train loss and acc of batch 1: 47.824310302734375, 1.0\n",
      "Train loss and acc of batch 2: 47.82429885864258, 1.0\n",
      "Train loss and acc of batch 3: 48.041053771972656, 0.984375\n",
      "Train loss and acc of batch 4: 47.82427978515625, 1.0\n",
      "Train loss and acc of batch 5: 49.173194885253906, 0.96875\n",
      "Train loss and acc of batch 6: 48.32688522338867, 0.96875\n",
      "Train loss and acc of batch 7: 47.824256896972656, 1.0\n",
      "Train loss and acc of batch 8: 48.419952392578125, 0.984375\n",
      "Train loss and acc of batch 9: 48.11009216308594, 0.984375\n",
      "Train loss and acc of batch 10: 47.82422637939453, 1.0\n",
      "Train loss and acc of batch 11: 47.82421875, 1.0\n",
      "Train loss and acc of batch 12: 48.57743453979492, 0.984375\n",
      "Train loss and acc of batch 13: 48.04096221923828, 0.984375\n",
      "Train loss and acc of batch 14: 48.04095458984375, 0.984375\n",
      "Train loss and acc of batch 15: 48.419883728027344, 0.984375\n",
      "Train loss and acc of batch 16: 48.41987609863281, 0.984375\n",
      "Train loss and acc of batch 17: 48.577392578125, 0.984375\n",
      "Train loss and acc of batch 18: 48.705711364746094, 0.96875\n",
      "Train loss and acc of batch 19: 47.82415008544922, 1.0\n",
      "Train loss and acc of batch 20: 47.82413864135742, 1.0\n",
      "Train loss and acc of batch 21: 48.419830322265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.419822692871094, 0.984375\n",
      "Train loss and acc of batch 23: 47.82411193847656, 1.0\n",
      "Train loss and acc of batch 24: 48.41980743408203, 0.984375\n",
      "Train loss and acc of batch 25: 47.8240966796875, 1.0\n",
      "Train loss and acc of batch 26: 47.8240852355957, 1.0\n",
      "Train loss and acc of batch 27: 47.82408142089844, 1.0\n",
      "Train loss and acc of batch 28: 47.824066162109375, 1.0\n",
      "Train loss and acc of batch 29: 48.419761657714844, 0.984375\n",
      "Train loss and acc of batch 30: 47.82405090332031, 1.0\n",
      "Train loss and acc of batch 31: 48.040809631347656, 0.984375\n",
      "Train loss and acc of batch 32: 47.82402801513672, 1.0\n",
      "Train loss and acc of batch 33: 47.82402420043945, 1.0\n",
      "Train loss and acc of batch 34: 48.419715881347656, 0.984375\n",
      "Train loss and acc of batch 35: 48.257537841796875, 0.96875\n",
      "Train loss and acc of batch 36: 47.82400131225586, 1.0\n",
      "Train loss and acc of batch 37: 48.577213287353516, 0.984375\n",
      "Train loss and acc of batch 38: 49.17290496826172, 0.96875\n",
      "Train loss and acc of batch 39: 48.040733337402344, 0.984375\n",
      "Train loss and acc of batch 40: 47.8239631652832, 1.0\n",
      "Train loss and acc of batch 41: 49.172882080078125, 0.96875\n",
      "Train loss and acc of batch 42: 47.823944091796875, 1.0\n",
      "Train loss and acc of batch 43: 48.41963195800781, 0.984375\n",
      "Train loss and acc of batch 44: 47.82392501831055, 1.0\n",
      "Train loss and acc of batch 45: 48.41961669921875, 0.984375\n",
      "Train loss and acc of batch 46: 48.10975646972656, 0.984375\n",
      "Train loss and acc of batch 47: 47.82389831542969, 1.0\n",
      "Train loss and acc of batch 48: 47.823890686035156, 1.0\n",
      "Train loss and acc of batch 49: 47.82387924194336, 1.0\n",
      "Train loss and acc of batch 50: 48.41957092285156, 0.984375\n",
      "Train loss and acc of batch 51: 49.17278289794922, 0.96875\n",
      "Train loss and acc of batch 52: 49.07969665527344, 0.953125\n",
      "Train loss and acc of batch 53: 47.823848724365234, 1.0\n",
      "Train loss and acc of batch 54: 48.04060363769531, 0.984375\n",
      "Train loss and acc of batch 55: 47.823829650878906, 1.0\n",
      "Train loss and acc of batch 56: 47.82381820678711, 1.0\n",
      "Train loss and acc of batch 57: 48.41950988769531, 0.984375\n",
      "Train loss and acc of batch 58: 47.82380294799805, 1.0\n",
      "Train loss and acc of batch 59: 47.82379150390625, 1.0\n",
      "Train loss and acc of batch 60: 47.82378387451172, 1.0\n",
      "Train loss and acc of batch 61: 47.82377243041992, 1.0\n",
      "Train loss and acc of batch 62: 47.823768615722656, 1.0\n",
      "Train loss and acc of batch 63: 49.015159606933594, 0.96875\n",
      "Train loss and acc of batch 64: 48.04051971435547, 0.984375\n",
      "Train loss and acc of batch 65: 47.82373809814453, 1.0\n",
      "Train loss and acc of batch 66: 47.82373046875, 1.0\n",
      "Train loss and acc of batch 67: 48.63618850708008, 0.96875\n",
      "Train loss and acc of batch 68: 48.419410705566406, 0.984375\n",
      "Train loss and acc of batch 69: 48.04046630859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.82369613647461, 1.0\n",
      "Training accuracy and loss of epoch #371: 0.9897, 48.1449\n",
      "Saved model by train loss 48.144889455446055\n",
      "Train loss and acc of batch 0: 47.82368469238281, 1.0\n",
      "Train loss and acc of batch 1: 47.82367706298828, 1.0\n",
      "Train loss and acc of batch 2: 47.82366943359375, 1.0\n",
      "Train loss and acc of batch 3: 48.04042053222656, 0.984375\n",
      "Train loss and acc of batch 4: 47.82365036010742, 1.0\n",
      "Train loss and acc of batch 5: 49.172569274902344, 0.96875\n",
      "Train loss and acc of batch 6: 48.32624816894531, 0.96875\n",
      "Train loss and acc of batch 7: 47.82362747192383, 1.0\n",
      "Train loss and acc of batch 8: 48.41931915283203, 0.984375\n",
      "Train loss and acc of batch 9: 48.109458923339844, 0.984375\n",
      "Train loss and acc of batch 10: 47.82360076904297, 1.0\n",
      "Train loss and acc of batch 11: 47.82358932495117, 1.0\n",
      "Train loss and acc of batch 12: 48.576805114746094, 0.984375\n",
      "Train loss and acc of batch 13: 48.04033660888672, 0.984375\n",
      "Train loss and acc of batch 14: 48.04032897949219, 0.984375\n",
      "Train loss and acc of batch 15: 48.41925811767578, 0.984375\n",
      "Train loss and acc of batch 16: 48.41924285888672, 0.984375\n",
      "Train loss and acc of batch 17: 48.57675552368164, 0.984375\n",
      "Train loss and acc of batch 18: 48.705081939697266, 0.96875\n",
      "Train loss and acc of batch 19: 47.823516845703125, 1.0\n",
      "Train loss and acc of batch 20: 47.82351303100586, 1.0\n",
      "Train loss and acc of batch 21: 48.41920471191406, 0.984375\n",
      "Train loss and acc of batch 22: 48.41919708251953, 0.984375\n",
      "Train loss and acc of batch 23: 47.823486328125, 1.0\n",
      "Train loss and acc of batch 24: 48.41917419433594, 0.984375\n",
      "Train loss and acc of batch 25: 47.823463439941406, 1.0\n",
      "Train loss and acc of batch 26: 48.04022216796875, 0.984375\n",
      "Train loss and acc of batch 27: 47.82345199584961, 1.0\n",
      "Train loss and acc of batch 28: 47.82344055175781, 1.0\n",
      "Train loss and acc of batch 29: 48.41913604736328, 0.984375\n",
      "Train loss and acc of batch 30: 47.82342529296875, 1.0\n",
      "Train loss and acc of batch 31: 48.04017639160156, 0.984375\n",
      "Train loss and acc of batch 32: 47.82341003417969, 1.0\n",
      "Train loss and acc of batch 33: 47.823394775390625, 1.0\n",
      "Train loss and acc of batch 34: 48.419090270996094, 0.984375\n",
      "Train loss and acc of batch 35: 48.25690460205078, 0.96875\n",
      "Train loss and acc of batch 36: 47.823368072509766, 1.0\n",
      "Train loss and acc of batch 37: 48.57658386230469, 0.984375\n",
      "Train loss and acc of batch 38: 49.172279357910156, 0.96875\n",
      "Train loss and acc of batch 39: 48.04010009765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.823333740234375, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.17224884033203, 0.96875\n",
      "Train loss and acc of batch 42: 47.82331466674805, 1.0\n",
      "Train loss and acc of batch 43: 48.41900634765625, 0.984375\n",
      "Train loss and acc of batch 44: 47.82329559326172, 1.0\n",
      "Train loss and acc of batch 45: 48.41899108886719, 0.984375\n",
      "Train loss and acc of batch 46: 48.109130859375, 0.984375\n",
      "Train loss and acc of batch 47: 47.82326889038086, 1.0\n",
      "Train loss and acc of batch 48: 47.82326126098633, 1.0\n",
      "Train loss and acc of batch 49: 47.8232536315918, 1.0\n",
      "Train loss and acc of batch 50: 48.4189453125, 0.984375\n",
      "Train loss and acc of batch 51: 49.172157287597656, 0.96875\n",
      "Train loss and acc of batch 52: 49.07906723022461, 0.953125\n",
      "Train loss and acc of batch 53: 47.823219299316406, 1.0\n",
      "Train loss and acc of batch 54: 48.03997039794922, 0.984375\n",
      "Train loss and acc of batch 55: 47.82319641113281, 1.0\n",
      "Train loss and acc of batch 56: 47.82318878173828, 1.0\n",
      "Train loss and acc of batch 57: 48.41888427734375, 0.984375\n",
      "Train loss and acc of batch 58: 47.823177337646484, 1.0\n",
      "Train loss and acc of batch 59: 47.82316589355469, 1.0\n",
      "Train loss and acc of batch 60: 47.823158264160156, 1.0\n",
      "Train loss and acc of batch 61: 47.823150634765625, 1.0\n",
      "Train loss and acc of batch 62: 47.82313537597656, 1.0\n",
      "Train loss and acc of batch 63: 49.014530181884766, 0.96875\n",
      "Train loss and acc of batch 64: 48.039878845214844, 0.984375\n",
      "Train loss and acc of batch 65: 47.82311248779297, 1.0\n",
      "Train loss and acc of batch 66: 47.82310485839844, 1.0\n",
      "Train loss and acc of batch 67: 48.63555908203125, 0.96875\n",
      "Train loss and acc of batch 68: 48.418785095214844, 0.984375\n",
      "Train loss and acc of batch 69: 48.03984069824219, 0.984375\n",
      "Train loss and acc of batch 70: 47.82306671142578, 1.0\n",
      "Training accuracy and loss of epoch #372: 0.9894, 48.1473\n",
      "Train loss and acc of batch 0: 47.82305908203125, 1.0\n",
      "Train loss and acc of batch 1: 47.82304382324219, 1.0\n",
      "Train loss and acc of batch 2: 47.823036193847656, 1.0\n",
      "Train loss and acc of batch 3: 48.039794921875, 0.984375\n",
      "Train loss and acc of batch 4: 47.82302474975586, 1.0\n",
      "Train loss and acc of batch 5: 49.17193603515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.32562255859375, 0.96875\n",
      "Train loss and acc of batch 7: 47.822994232177734, 1.0\n",
      "Train loss and acc of batch 8: 48.41868591308594, 0.984375\n",
      "Train loss and acc of batch 9: 48.10883331298828, 0.984375\n",
      "Train loss and acc of batch 10: 47.82297134399414, 1.0\n",
      "Train loss and acc of batch 11: 47.822959899902344, 1.0\n",
      "Train loss and acc of batch 12: 48.576171875, 0.984375\n",
      "Train loss and acc of batch 13: 48.039703369140625, 0.984375\n",
      "Train loss and acc of batch 14: 48.039695739746094, 0.984375\n",
      "Train loss and acc of batch 15: 48.41862487792969, 0.984375\n",
      "Train loss and acc of batch 16: 48.418617248535156, 0.984375\n",
      "Train loss and acc of batch 17: 48.57612991333008, 0.984375\n",
      "Train loss and acc of batch 18: 48.70445251464844, 0.96875\n",
      "Train loss and acc of batch 19: 47.8228874206543, 1.0\n",
      "Train loss and acc of batch 20: 47.8228759765625, 1.0\n",
      "Train loss and acc of batch 21: 48.41857147216797, 0.984375\n",
      "Train loss and acc of batch 22: 48.41856384277344, 0.984375\n",
      "Train loss and acc of batch 23: 47.82285690307617, 1.0\n",
      "Train loss and acc of batch 24: 48.418540954589844, 0.984375\n",
      "Train loss and acc of batch 25: 47.822837829589844, 1.0\n",
      "Train loss and acc of batch 26: 47.82282257080078, 1.0\n",
      "Train loss and acc of batch 27: 47.822818756103516, 1.0\n",
      "Train loss and acc of batch 28: 47.82280731201172, 1.0\n",
      "Train loss and acc of batch 29: 48.418495178222656, 0.984375\n",
      "Train loss and acc of batch 30: 47.822784423828125, 1.0\n",
      "Train loss and acc of batch 31: 48.03954315185547, 0.984375\n",
      "Train loss and acc of batch 32: 47.82277297973633, 1.0\n",
      "Train loss and acc of batch 33: 47.8227653503418, 1.0\n",
      "Train loss and acc of batch 34: 48.41845703125, 0.984375\n",
      "Train loss and acc of batch 35: 48.25627517700195, 0.96875\n",
      "Train loss and acc of batch 36: 47.82273483276367, 1.0\n",
      "Train loss and acc of batch 37: 48.575950622558594, 0.984375\n",
      "Train loss and acc of batch 38: 49.17163848876953, 0.96875\n",
      "Train loss and acc of batch 39: 48.03947448730469, 0.984375\n",
      "Train loss and acc of batch 40: 47.82270431518555, 1.0\n",
      "Train loss and acc of batch 41: 49.17161560058594, 0.96875\n",
      "Train loss and acc of batch 42: 47.82268524169922, 1.0\n",
      "Train loss and acc of batch 43: 48.41838073730469, 0.984375\n",
      "Train loss and acc of batch 44: 47.82266616821289, 1.0\n",
      "Train loss and acc of batch 45: 48.418357849121094, 0.984375\n",
      "Train loss and acc of batch 46: 48.108497619628906, 0.984375\n",
      "Train loss and acc of batch 47: 47.82263946533203, 1.0\n",
      "Train loss and acc of batch 48: 47.8226318359375, 1.0\n",
      "Train loss and acc of batch 49: 47.8226203918457, 1.0\n",
      "Train loss and acc of batch 50: 48.418312072753906, 0.984375\n",
      "Train loss and acc of batch 51: 49.171531677246094, 0.96875\n",
      "Train loss and acc of batch 52: 49.07843780517578, 0.953125\n",
      "Train loss and acc of batch 53: 47.82258605957031, 1.0\n",
      "Train loss and acc of batch 54: 48.039344787597656, 0.984375\n",
      "Train loss and acc of batch 55: 47.822566986083984, 1.0\n",
      "Train loss and acc of batch 56: 47.82256317138672, 1.0\n",
      "Train loss and acc of batch 57: 48.418243408203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.822540283203125, 1.0\n",
      "Train loss and acc of batch 59: 47.82253646850586, 1.0\n",
      "Train loss and acc of batch 60: 47.82252502441406, 1.0\n",
      "Train loss and acc of batch 61: 47.8225212097168, 1.0\n",
      "Train loss and acc of batch 62: 47.822509765625, 1.0\n",
      "Train loss and acc of batch 63: 49.01389694213867, 0.96875\n",
      "Train loss and acc of batch 64: 48.03925323486328, 0.984375\n",
      "Train loss and acc of batch 65: 47.822479248046875, 1.0\n",
      "Train loss and acc of batch 66: 47.82247543334961, 1.0\n",
      "Train loss and acc of batch 67: 48.634925842285156, 0.96875\n",
      "Train loss and acc of batch 68: 48.41815948486328, 0.984375\n",
      "Train loss and acc of batch 69: 48.039215087890625, 0.984375\n",
      "Train loss and acc of batch 70: 47.82243728637695, 1.0\n",
      "Training accuracy and loss of epoch #373: 0.9897, 48.1436\n",
      "Saved model by train loss 48.14362947705766\n",
      "Train loss and acc of batch 0: 47.822425842285156, 1.0\n",
      "Train loss and acc of batch 1: 47.822418212890625, 1.0\n",
      "Train loss and acc of batch 2: 47.822410583496094, 1.0\n",
      "Train loss and acc of batch 3: 48.039161682128906, 0.984375\n",
      "Train loss and acc of batch 4: 47.8223876953125, 1.0\n",
      "Train loss and acc of batch 5: 49.171302795410156, 0.96875\n",
      "Train loss and acc of batch 6: 48.324989318847656, 0.96875\n",
      "Train loss and acc of batch 7: 47.82236099243164, 1.0\n",
      "Train loss and acc of batch 8: 48.418052673339844, 0.984375\n",
      "Train loss and acc of batch 9: 48.10820007324219, 0.984375\n",
      "Train loss and acc of batch 10: 47.82233810424805, 1.0\n",
      "Train loss and acc of batch 11: 47.82232666015625, 1.0\n",
      "Train loss and acc of batch 12: 48.57554626464844, 0.984375\n",
      "Train loss and acc of batch 13: 48.03907775878906, 0.984375\n",
      "Train loss and acc of batch 14: 48.03907012939453, 0.984375\n",
      "Train loss and acc of batch 15: 48.41798400878906, 0.984375\n",
      "Train loss and acc of batch 16: 48.41798400878906, 0.984375\n",
      "Train loss and acc of batch 17: 48.575496673583984, 0.984375\n",
      "Train loss and acc of batch 18: 48.70382308959961, 0.96875\n",
      "Train loss and acc of batch 19: 47.82225799560547, 1.0\n",
      "Train loss and acc of batch 20: 47.82225036621094, 1.0\n",
      "Train loss and acc of batch 21: 48.417938232421875, 0.984375\n",
      "Train loss and acc of batch 22: 48.417930603027344, 0.984375\n",
      "Train loss and acc of batch 23: 47.82222366333008, 1.0\n",
      "Train loss and acc of batch 24: 48.41791534423828, 0.984375\n",
      "Train loss and acc of batch 25: 47.82220458984375, 1.0\n",
      "Train loss and acc of batch 26: 47.82219696044922, 1.0\n",
      "Train loss and acc of batch 27: 47.82218933105469, 1.0\n",
      "Train loss and acc of batch 28: 47.82217788696289, 1.0\n",
      "Train loss and acc of batch 29: 48.417869567871094, 0.984375\n",
      "Train loss and acc of batch 30: 47.82216262817383, 1.0\n",
      "Train loss and acc of batch 31: 48.038917541503906, 0.984375\n",
      "Train loss and acc of batch 32: 47.822139739990234, 1.0\n",
      "Train loss and acc of batch 33: 47.82213592529297, 1.0\n",
      "Train loss and acc of batch 34: 48.417823791503906, 0.984375\n",
      "Train loss and acc of batch 35: 48.255645751953125, 0.96875\n",
      "Train loss and acc of batch 36: 47.82210922241211, 1.0\n",
      "Train loss and acc of batch 37: 48.575321197509766, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 38: 49.17101287841797, 0.96875\n",
      "Train loss and acc of batch 39: 48.038841247558594, 0.984375\n",
      "Train loss and acc of batch 40: 47.82207489013672, 1.0\n",
      "Train loss and acc of batch 41: 49.170989990234375, 0.96875\n",
      "Train loss and acc of batch 42: 47.82205581665039, 1.0\n",
      "Train loss and acc of batch 43: 48.417747497558594, 0.984375\n",
      "Train loss and acc of batch 44: 47.82203674316406, 1.0\n",
      "Train loss and acc of batch 45: 48.417724609375, 0.984375\n",
      "Train loss and acc of batch 46: 48.107872009277344, 0.984375\n",
      "Train loss and acc of batch 47: 47.8220100402832, 1.0\n",
      "Train loss and acc of batch 48: 47.82200241088867, 1.0\n",
      "Train loss and acc of batch 49: 47.821990966796875, 1.0\n",
      "Train loss and acc of batch 50: 48.41767883300781, 0.984375\n",
      "Train loss and acc of batch 51: 49.1708984375, 0.96875\n",
      "Train loss and acc of batch 52: 49.07780838012695, 0.953125\n",
      "Train loss and acc of batch 53: 47.821956634521484, 1.0\n",
      "Train loss and acc of batch 54: 48.03871154785156, 0.984375\n",
      "Train loss and acc of batch 55: 47.821937561035156, 1.0\n",
      "Train loss and acc of batch 56: 47.821929931640625, 1.0\n",
      "Train loss and acc of batch 57: 48.417625427246094, 0.984375\n",
      "Train loss and acc of batch 58: 47.8219108581543, 1.0\n",
      "Train loss and acc of batch 59: 47.821903228759766, 1.0\n",
      "Train loss and acc of batch 60: 47.8218879699707, 1.0\n",
      "Train loss and acc of batch 61: 47.82188415527344, 1.0\n",
      "Train loss and acc of batch 62: 47.821876525878906, 1.0\n",
      "Train loss and acc of batch 63: 49.01327133178711, 0.96875\n",
      "Train loss and acc of batch 64: 48.03861999511719, 0.984375\n",
      "Train loss and acc of batch 65: 47.82184982299805, 1.0\n",
      "Train loss and acc of batch 66: 47.821834564208984, 1.0\n",
      "Train loss and acc of batch 67: 48.63429260253906, 0.96875\n",
      "Train loss and acc of batch 68: 48.41752624511719, 0.984375\n",
      "Train loss and acc of batch 69: 48.03858184814453, 0.984375\n",
      "Train loss and acc of batch 70: 47.82180404663086, 1.0\n",
      "Training accuracy and loss of epoch #374: 0.9897, 48.1430\n",
      "Saved model by train loss 48.14299881626183\n",
      "Train loss and acc of batch 0: 47.821800231933594, 1.0\n",
      "Train loss and acc of batch 1: 47.82178497314453, 1.0\n",
      "Train loss and acc of batch 2: 47.82177734375, 1.0\n",
      "Train loss and acc of batch 3: 48.038536071777344, 0.984375\n",
      "Train loss and acc of batch 4: 47.82176208496094, 1.0\n",
      "Train loss and acc of batch 5: 49.170677185058594, 0.96875\n",
      "Train loss and acc of batch 6: 48.32435607910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.82173538208008, 1.0\n",
      "Train loss and acc of batch 8: 48.41742706298828, 0.984375\n",
      "Train loss and acc of batch 9: 48.107566833496094, 0.984375\n",
      "Train loss and acc of batch 10: 47.82170486450195, 1.0\n",
      "Train loss and acc of batch 11: 47.82169723510742, 1.0\n",
      "Train loss and acc of batch 12: 48.574913024902344, 0.984375\n",
      "Train loss and acc of batch 13: 48.03844451904297, 0.984375\n",
      "Train loss and acc of batch 14: 48.03843688964844, 0.984375\n",
      "Train loss and acc of batch 15: 48.41736602783203, 0.984375\n",
      "Train loss and acc of batch 16: 48.4173583984375, 0.984375\n",
      "Train loss and acc of batch 17: 48.574867248535156, 0.984375\n",
      "Train loss and acc of batch 18: 48.70318603515625, 0.96875\n",
      "Train loss and acc of batch 19: 47.82162857055664, 1.0\n",
      "Train loss and acc of batch 20: 47.82162094116211, 1.0\n",
      "Train loss and acc of batch 21: 48.41731262207031, 0.984375\n",
      "Train loss and acc of batch 22: 48.41729736328125, 0.984375\n",
      "Train loss and acc of batch 23: 47.82158660888672, 1.0\n",
      "Train loss and acc of batch 24: 48.41728210449219, 0.984375\n",
      "Train loss and acc of batch 25: 47.82157516479492, 1.0\n",
      "Train loss and acc of batch 26: 47.82156753540039, 1.0\n",
      "Train loss and acc of batch 27: 47.821556091308594, 1.0\n",
      "Train loss and acc of batch 28: 47.82154846191406, 1.0\n",
      "Train loss and acc of batch 29: 48.417236328125, 0.984375\n",
      "Train loss and acc of batch 30: 47.82152557373047, 1.0\n",
      "Train loss and acc of batch 31: 48.03828430175781, 0.984375\n",
      "Train loss and acc of batch 32: 47.821510314941406, 1.0\n",
      "Train loss and acc of batch 33: 47.821502685546875, 1.0\n",
      "Train loss and acc of batch 34: 48.417198181152344, 0.984375\n",
      "Train loss and acc of batch 35: 48.2550163269043, 0.96875\n",
      "Train loss and acc of batch 36: 47.821475982666016, 1.0\n",
      "Train loss and acc of batch 37: 48.57468795776367, 0.984375\n",
      "Train loss and acc of batch 38: 49.170379638671875, 0.96875\n",
      "Train loss and acc of batch 39: 48.03821563720703, 0.984375\n",
      "Train loss and acc of batch 40: 47.82143783569336, 1.0\n",
      "Train loss and acc of batch 41: 49.17036056518555, 0.96875\n",
      "Train loss and acc of batch 42: 47.8214225769043, 1.0\n",
      "Train loss and acc of batch 43: 48.4171142578125, 0.984375\n",
      "Train loss and acc of batch 44: 47.82140350341797, 1.0\n",
      "Train loss and acc of batch 45: 48.41709899902344, 0.984375\n",
      "Train loss and acc of batch 46: 48.10723876953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.82137680053711, 1.0\n",
      "Train loss and acc of batch 48: 47.82136917114258, 1.0\n",
      "Train loss and acc of batch 49: 47.82136535644531, 1.0\n",
      "Train loss and acc of batch 50: 48.41705322265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.170257568359375, 0.96875\n",
      "Train loss and acc of batch 52: 49.07717514038086, 0.953125\n",
      "Train loss and acc of batch 53: 47.82132339477539, 1.0\n",
      "Train loss and acc of batch 54: 48.03807830810547, 0.984375\n",
      "Train loss and acc of batch 55: 47.82130432128906, 1.0\n",
      "Train loss and acc of batch 56: 47.8213005065918, 1.0\n",
      "Train loss and acc of batch 57: 48.4169921875, 0.984375\n",
      "Train loss and acc of batch 58: 47.82128143310547, 1.0\n",
      "Train loss and acc of batch 59: 47.82127380371094, 1.0\n",
      "Train loss and acc of batch 60: 47.82126235961914, 1.0\n",
      "Train loss and acc of batch 61: 47.82125473022461, 1.0\n",
      "Train loss and acc of batch 62: 47.82124710083008, 1.0\n",
      "Train loss and acc of batch 63: 49.01264190673828, 0.96875\n",
      "Train loss and acc of batch 64: 48.037994384765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.82122039794922, 1.0\n",
      "Train loss and acc of batch 66: 47.82121276855469, 1.0\n",
      "Train loss and acc of batch 67: 48.633663177490234, 0.96875\n",
      "Train loss and acc of batch 68: 48.416893005371094, 0.984375\n",
      "Train loss and acc of batch 69: 48.03794860839844, 0.984375\n",
      "Train loss and acc of batch 70: 47.82117462158203, 1.0\n",
      "Training accuracy and loss of epoch #375: 0.9897, 48.1424\n",
      "Saved model by train loss 48.14236826292226\n",
      "Train loss and acc of batch 0: 47.821163177490234, 1.0\n",
      "Train loss and acc of batch 1: 47.82115936279297, 1.0\n",
      "Train loss and acc of batch 2: 47.82114791870117, 1.0\n",
      "Train loss and acc of batch 3: 48.03790283203125, 0.984375\n",
      "Train loss and acc of batch 4: 47.82112503051758, 1.0\n",
      "Train loss and acc of batch 5: 49.1700439453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.32373046875, 0.96875\n",
      "Train loss and acc of batch 7: 47.821102142333984, 1.0\n",
      "Train loss and acc of batch 8: 48.41679382324219, 0.984375\n",
      "Train loss and acc of batch 9: 48.10694122314453, 0.984375\n",
      "Train loss and acc of batch 10: 47.821075439453125, 1.0\n",
      "Train loss and acc of batch 11: 47.821067810058594, 1.0\n",
      "Train loss and acc of batch 12: 48.574283599853516, 0.984375\n",
      "Train loss and acc of batch 13: 48.037811279296875, 0.984375\n",
      "Train loss and acc of batch 14: 48.037803649902344, 0.984375\n",
      "Train loss and acc of batch 15: 48.41673278808594, 0.984375\n",
      "Train loss and acc of batch 16: 48.416725158691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.57423400878906, 0.984375\n",
      "Train loss and acc of batch 18: 48.70255661010742, 0.96875\n",
      "Train loss and acc of batch 19: 47.82099914550781, 1.0\n",
      "Train loss and acc of batch 20: 47.820987701416016, 1.0\n",
      "Train loss and acc of batch 21: 48.41667938232422, 0.984375\n",
      "Train loss and acc of batch 22: 48.41667175292969, 0.984375\n",
      "Train loss and acc of batch 23: 47.82096481323242, 1.0\n",
      "Train loss and acc of batch 24: 48.416648864746094, 0.984375\n",
      "Train loss and acc of batch 25: 47.82093811035156, 1.0\n",
      "Train loss and acc of batch 26: 47.8209342956543, 1.0\n",
      "Train loss and acc of batch 27: 47.8209228515625, 1.0\n",
      "Train loss and acc of batch 28: 47.82091522216797, 1.0\n",
      "Train loss and acc of batch 29: 48.41661071777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.82090377807617, 1.0\n",
      "Train loss and acc of batch 31: 48.03765106201172, 0.984375\n",
      "Train loss and acc of batch 32: 47.82087707519531, 1.0\n",
      "Train loss and acc of batch 33: 47.82086944580078, 1.0\n",
      "Train loss and acc of batch 34: 48.41656494140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.25437927246094, 0.96875\n",
      "Train loss and acc of batch 36: 47.82084655761719, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 37: 48.574058532714844, 0.984375\n",
      "Train loss and acc of batch 38: 49.16975402832031, 0.96875\n",
      "Train loss and acc of batch 39: 48.03758239746094, 0.984375\n",
      "Train loss and acc of batch 40: 47.82080841064453, 1.0\n",
      "Train loss and acc of batch 41: 49.16972351074219, 0.96875\n",
      "Train loss and acc of batch 42: 47.8207893371582, 1.0\n",
      "Train loss and acc of batch 43: 48.416481018066406, 0.984375\n",
      "Train loss and acc of batch 44: 47.820777893066406, 1.0\n",
      "Train loss and acc of batch 45: 48.416465759277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.106605529785156, 0.984375\n",
      "Train loss and acc of batch 47: 47.82074737548828, 1.0\n",
      "Train loss and acc of batch 48: 47.820735931396484, 1.0\n",
      "Train loss and acc of batch 49: 47.82072830200195, 1.0\n",
      "Train loss and acc of batch 50: 48.416419982910156, 0.984375\n",
      "Train loss and acc of batch 51: 49.169639587402344, 0.96875\n",
      "Train loss and acc of batch 52: 49.07654571533203, 0.953125\n",
      "Train loss and acc of batch 53: 47.82069396972656, 1.0\n",
      "Train loss and acc of batch 54: 48.037452697753906, 0.984375\n",
      "Train loss and acc of batch 55: 47.820674896240234, 1.0\n",
      "Train loss and acc of batch 56: 47.8206672668457, 1.0\n",
      "Train loss and acc of batch 57: 48.416358947753906, 0.984375\n",
      "Train loss and acc of batch 58: 47.820648193359375, 1.0\n",
      "Train loss and acc of batch 59: 47.820640563964844, 1.0\n",
      "Train loss and acc of batch 60: 47.82062530517578, 1.0\n",
      "Train loss and acc of batch 61: 47.820621490478516, 1.0\n",
      "Train loss and acc of batch 62: 47.820613861083984, 1.0\n",
      "Train loss and acc of batch 63: 49.01201248168945, 0.96875\n",
      "Train loss and acc of batch 64: 48.03736114501953, 0.984375\n",
      "Train loss and acc of batch 65: 47.820587158203125, 1.0\n",
      "Train loss and acc of batch 66: 47.820579528808594, 1.0\n",
      "Train loss and acc of batch 67: 48.63303756713867, 0.96875\n",
      "Train loss and acc of batch 68: 48.416259765625, 0.984375\n",
      "Train loss and acc of batch 69: 48.037315368652344, 0.984375\n",
      "Train loss and acc of batch 70: 47.82053756713867, 1.0\n",
      "Training accuracy and loss of epoch #376: 0.9897, 48.1417\n",
      "Saved model by train loss 48.141736849932606\n",
      "Train loss and acc of batch 0: 47.820533752441406, 1.0\n",
      "Train loss and acc of batch 1: 47.82052230834961, 1.0\n",
      "Train loss and acc of batch 2: 47.82051467895508, 1.0\n",
      "Train loss and acc of batch 3: 48.037269592285156, 0.984375\n",
      "Train loss and acc of batch 4: 47.82049560546875, 1.0\n",
      "Train loss and acc of batch 5: 49.169410705566406, 0.96875\n",
      "Train loss and acc of batch 6: 48.32309341430664, 0.96875\n",
      "Train loss and acc of batch 7: 47.82046890258789, 1.0\n",
      "Train loss and acc of batch 8: 48.416168212890625, 0.984375\n",
      "Train loss and acc of batch 9: 48.10630798339844, 0.984375\n",
      "Train loss and acc of batch 10: 47.82044982910156, 1.0\n",
      "Train loss and acc of batch 11: 47.8204345703125, 1.0\n",
      "Train loss and acc of batch 12: 48.57365036010742, 0.984375\n",
      "Train loss and acc of batch 13: 48.03718566894531, 0.984375\n",
      "Train loss and acc of batch 14: 48.03717803955078, 0.984375\n",
      "Train loss and acc of batch 15: 48.416099548339844, 0.984375\n",
      "Train loss and acc of batch 16: 48.41608428955078, 0.984375\n",
      "Train loss and acc of batch 17: 48.5736083984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.701927185058594, 0.96875\n",
      "Train loss and acc of batch 19: 47.82036590576172, 1.0\n",
      "Train loss and acc of batch 20: 47.82035827636719, 1.0\n",
      "Train loss and acc of batch 21: 48.416046142578125, 0.984375\n",
      "Train loss and acc of batch 22: 48.416038513183594, 0.984375\n",
      "Train loss and acc of batch 23: 47.82033157348633, 1.0\n",
      "Train loss and acc of batch 24: 48.41602325439453, 0.984375\n",
      "Train loss and acc of batch 25: 47.820316314697266, 1.0\n",
      "Train loss and acc of batch 26: 47.82029724121094, 1.0\n",
      "Train loss and acc of batch 27: 47.82029342651367, 1.0\n",
      "Train loss and acc of batch 28: 47.820281982421875, 1.0\n",
      "Train loss and acc of batch 29: 48.415977478027344, 0.984375\n",
      "Train loss and acc of batch 30: 47.82026672363281, 1.0\n",
      "Train loss and acc of batch 31: 48.037025451660156, 0.984375\n",
      "Train loss and acc of batch 32: 47.820247650146484, 1.0\n",
      "Train loss and acc of batch 33: 47.82023620605469, 1.0\n",
      "Train loss and acc of batch 34: 48.415931701660156, 0.984375\n",
      "Train loss and acc of batch 35: 48.25374984741211, 0.96875\n",
      "Train loss and acc of batch 36: 47.820213317871094, 1.0\n",
      "Train loss and acc of batch 37: 48.57343292236328, 0.984375\n",
      "Train loss and acc of batch 38: 49.16912078857422, 0.96875\n",
      "Train loss and acc of batch 39: 48.036956787109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.8201789855957, 1.0\n",
      "Train loss and acc of batch 41: 49.169097900390625, 0.96875\n",
      "Train loss and acc of batch 42: 47.820159912109375, 1.0\n",
      "Train loss and acc of batch 43: 48.41584777832031, 0.984375\n",
      "Train loss and acc of batch 44: 47.82014465332031, 1.0\n",
      "Train loss and acc of batch 45: 48.41583251953125, 0.984375\n",
      "Train loss and acc of batch 46: 48.105979919433594, 0.984375\n",
      "Train loss and acc of batch 47: 47.82012176513672, 1.0\n",
      "Train loss and acc of batch 48: 47.82011032104492, 1.0\n",
      "Train loss and acc of batch 49: 47.82009506225586, 1.0\n",
      "Train loss and acc of batch 50: 48.41578674316406, 0.984375\n",
      "Train loss and acc of batch 51: 49.16900634765625, 0.96875\n",
      "Train loss and acc of batch 52: 49.07591247558594, 0.953125\n",
      "Train loss and acc of batch 53: 47.820064544677734, 1.0\n",
      "Train loss and acc of batch 54: 48.03681945800781, 0.984375\n",
      "Train loss and acc of batch 55: 47.82004928588867, 1.0\n",
      "Train loss and acc of batch 56: 47.820037841796875, 1.0\n",
      "Train loss and acc of batch 57: 48.415733337402344, 0.984375\n",
      "Train loss and acc of batch 58: 47.82002258300781, 1.0\n",
      "Train loss and acc of batch 59: 47.82000732421875, 1.0\n",
      "Train loss and acc of batch 60: 47.81999969482422, 1.0\n",
      "Train loss and acc of batch 61: 47.81998825073242, 1.0\n",
      "Train loss and acc of batch 62: 47.819984436035156, 1.0\n",
      "Train loss and acc of batch 63: 49.01137161254883, 0.96875\n",
      "Train loss and acc of batch 64: 48.03672790527344, 0.984375\n",
      "Train loss and acc of batch 65: 47.8199577331543, 1.0\n",
      "Train loss and acc of batch 66: 47.819950103759766, 1.0\n",
      "Train loss and acc of batch 67: 48.63240432739258, 0.96875\n",
      "Train loss and acc of batch 68: 48.41563415527344, 0.984375\n",
      "Train loss and acc of batch 69: 48.03668975830078, 0.984375\n",
      "Train loss and acc of batch 70: 47.81991195678711, 1.0\n",
      "Training accuracy and loss of epoch #377: 0.9897, 48.1411\n",
      "Saved model by train loss 48.14110624286491\n",
      "Train loss and acc of batch 0: 47.81990432739258, 1.0\n",
      "Train loss and acc of batch 1: 47.81989288330078, 1.0\n",
      "Train loss and acc of batch 2: 47.819881439208984, 1.0\n",
      "Train loss and acc of batch 3: 48.036643981933594, 0.984375\n",
      "Train loss and acc of batch 4: 47.81986618041992, 1.0\n",
      "Train loss and acc of batch 5: 49.168785095214844, 0.96875\n",
      "Train loss and acc of batch 6: 48.32246398925781, 0.96875\n",
      "Train loss and acc of batch 7: 47.8198356628418, 1.0\n",
      "Train loss and acc of batch 8: 48.41553497314453, 0.984375\n",
      "Train loss and acc of batch 9: 48.105674743652344, 0.984375\n",
      "Train loss and acc of batch 10: 47.8198127746582, 1.0\n",
      "Train loss and acc of batch 11: 47.81980514526367, 1.0\n",
      "Train loss and acc of batch 12: 48.573020935058594, 0.984375\n",
      "Train loss and acc of batch 13: 48.03655242919922, 0.984375\n",
      "Train loss and acc of batch 14: 48.03654479980469, 0.984375\n",
      "Train loss and acc of batch 15: 48.41546630859375, 0.984375\n",
      "Train loss and acc of batch 16: 48.41546630859375, 0.984375\n",
      "Train loss and acc of batch 17: 48.57297134399414, 0.984375\n",
      "Train loss and acc of batch 18: 48.701297760009766, 0.96875\n",
      "Train loss and acc of batch 19: 47.81973648071289, 1.0\n",
      "Train loss and acc of batch 20: 47.819725036621094, 1.0\n",
      "Train loss and acc of batch 21: 48.41541290283203, 0.984375\n",
      "Train loss and acc of batch 22: 48.4154052734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.819698333740234, 1.0\n",
      "Train loss and acc of batch 24: 48.41539001464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.819679260253906, 1.0\n",
      "Train loss and acc of batch 26: 47.81967544555664, 1.0\n",
      "Train loss and acc of batch 27: 47.819664001464844, 1.0\n",
      "Train loss and acc of batch 28: 47.81965637207031, 1.0\n",
      "Train loss and acc of batch 29: 48.41534423828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.819637298583984, 1.0\n",
      "Train loss and acc of batch 31: 48.03639221191406, 0.984375\n",
      "Train loss and acc of batch 32: 47.819618225097656, 1.0\n",
      "Train loss and acc of batch 33: 47.819610595703125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 34: 48.41529846191406, 0.984375\n",
      "Train loss and acc of batch 35: 48.253116607666016, 0.96875\n",
      "Train loss and acc of batch 36: 47.819580078125, 1.0\n",
      "Train loss and acc of batch 37: 48.57279586791992, 0.984375\n",
      "Train loss and acc of batch 38: 49.168487548828125, 0.96875\n",
      "Train loss and acc of batch 39: 48.03631591796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.819549560546875, 1.0\n",
      "Train loss and acc of batch 41: 49.16846466064453, 0.96875\n",
      "Train loss and acc of batch 42: 47.81953048706055, 1.0\n",
      "Train loss and acc of batch 43: 48.41521453857422, 0.984375\n",
      "Train loss and acc of batch 44: 47.81951141357422, 1.0\n",
      "Train loss and acc of batch 45: 48.41520690917969, 0.984375\n",
      "Train loss and acc of batch 46: 48.1053466796875, 0.984375\n",
      "Train loss and acc of batch 47: 47.81948471069336, 1.0\n",
      "Train loss and acc of batch 48: 47.81947708129883, 1.0\n",
      "Train loss and acc of batch 49: 47.81946563720703, 1.0\n",
      "Train loss and acc of batch 50: 48.41515350341797, 0.984375\n",
      "Train loss and acc of batch 51: 49.168373107910156, 0.96875\n",
      "Train loss and acc of batch 52: 49.075279235839844, 0.953125\n",
      "Train loss and acc of batch 53: 47.81943130493164, 1.0\n",
      "Train loss and acc of batch 54: 48.03618621826172, 0.984375\n",
      "Train loss and acc of batch 55: 47.81941604614258, 1.0\n",
      "Train loss and acc of batch 56: 47.81940841674805, 1.0\n",
      "Train loss and acc of batch 57: 48.41510009765625, 0.984375\n",
      "Train loss and acc of batch 58: 47.81938552856445, 1.0\n",
      "Train loss and acc of batch 59: 47.81937789916992, 1.0\n",
      "Train loss and acc of batch 60: 47.819366455078125, 1.0\n",
      "Train loss and acc of batch 61: 47.81936264038086, 1.0\n",
      "Train loss and acc of batch 62: 47.8193473815918, 1.0\n",
      "Train loss and acc of batch 63: 49.01074981689453, 0.96875\n",
      "Train loss and acc of batch 64: 48.036094665527344, 0.984375\n",
      "Train loss and acc of batch 65: 47.8193244934082, 1.0\n",
      "Train loss and acc of batch 66: 47.819313049316406, 1.0\n",
      "Train loss and acc of batch 67: 48.631771087646484, 0.96875\n",
      "Train loss and acc of batch 68: 48.415000915527344, 0.984375\n",
      "Train loss and acc of batch 69: 48.03605651855469, 0.984375\n",
      "Train loss and acc of batch 70: 47.81928253173828, 1.0\n",
      "Training accuracy and loss of epoch #378: 0.9897, 48.1405\n",
      "Saved model by train loss 48.1404745612346\n",
      "Train loss and acc of batch 0: 47.81927490234375, 1.0\n",
      "Train loss and acc of batch 1: 47.81925964355469, 1.0\n",
      "Train loss and acc of batch 2: 47.81925582885742, 1.0\n",
      "Train loss and acc of batch 3: 48.0360107421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.819236755371094, 1.0\n",
      "Train loss and acc of batch 5: 49.16815185546875, 0.96875\n",
      "Train loss and acc of batch 6: 48.321834564208984, 0.96875\n",
      "Train loss and acc of batch 7: 47.819210052490234, 1.0\n",
      "Train loss and acc of batch 8: 48.41490173339844, 0.984375\n",
      "Train loss and acc of batch 9: 48.10504150390625, 0.984375\n",
      "Train loss and acc of batch 10: 47.81917953491211, 1.0\n",
      "Train loss and acc of batch 11: 47.81917190551758, 1.0\n",
      "Train loss and acc of batch 12: 48.5723876953125, 0.984375\n",
      "Train loss and acc of batch 13: 48.035919189453125, 0.984375\n",
      "Train loss and acc of batch 14: 48.035911560058594, 0.984375\n",
      "Train loss and acc of batch 15: 48.41484069824219, 0.984375\n",
      "Train loss and acc of batch 16: 48.414825439453125, 0.984375\n",
      "Train loss and acc of batch 17: 48.57234573364258, 0.984375\n",
      "Train loss and acc of batch 18: 48.70066452026367, 0.96875\n",
      "Train loss and acc of batch 19: 47.8191032409668, 1.0\n",
      "Train loss and acc of batch 20: 47.819095611572266, 1.0\n",
      "Train loss and acc of batch 21: 48.41478729248047, 0.984375\n",
      "Train loss and acc of batch 22: 48.414772033691406, 0.984375\n",
      "Train loss and acc of batch 23: 47.81906509399414, 1.0\n",
      "Train loss and acc of batch 24: 48.414756774902344, 0.984375\n",
      "Train loss and acc of batch 25: 47.81904983520508, 1.0\n",
      "Train loss and acc of batch 26: 47.81904220581055, 1.0\n",
      "Train loss and acc of batch 27: 47.819034576416016, 1.0\n",
      "Train loss and acc of batch 28: 47.81902313232422, 1.0\n",
      "Train loss and acc of batch 29: 48.41471862792969, 0.984375\n",
      "Train loss and acc of batch 30: 47.81900405883789, 1.0\n",
      "Train loss and acc of batch 31: 48.0357666015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.81898498535156, 1.0\n",
      "Train loss and acc of batch 33: 47.81897735595703, 1.0\n",
      "Train loss and acc of batch 34: 48.4146728515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.25249481201172, 0.96875\n",
      "Train loss and acc of batch 36: 47.81895446777344, 1.0\n",
      "Train loss and acc of batch 37: 48.572166442871094, 0.984375\n",
      "Train loss and acc of batch 38: 49.16785430908203, 0.96875\n",
      "Train loss and acc of batch 39: 48.03569030761719, 0.984375\n",
      "Train loss and acc of batch 40: 47.81891632080078, 1.0\n",
      "Train loss and acc of batch 41: 49.1678352355957, 0.96875\n",
      "Train loss and acc of batch 42: 47.81889724731445, 1.0\n",
      "Train loss and acc of batch 43: 48.414588928222656, 0.984375\n",
      "Train loss and acc of batch 44: 47.818878173828125, 1.0\n",
      "Train loss and acc of batch 45: 48.414573669433594, 0.984375\n",
      "Train loss and acc of batch 46: 48.104713439941406, 0.984375\n",
      "Train loss and acc of batch 47: 47.81885528564453, 1.0\n",
      "Train loss and acc of batch 48: 47.81884765625, 1.0\n",
      "Train loss and acc of batch 49: 47.81884002685547, 1.0\n",
      "Train loss and acc of batch 50: 48.414527893066406, 0.984375\n",
      "Train loss and acc of batch 51: 49.16773986816406, 0.96875\n",
      "Train loss and acc of batch 52: 49.07464599609375, 0.953125\n",
      "Train loss and acc of batch 53: 47.81879806518555, 1.0\n",
      "Train loss and acc of batch 54: 48.035560607910156, 0.984375\n",
      "Train loss and acc of batch 55: 47.818782806396484, 1.0\n",
      "Train loss and acc of batch 56: 47.81877517700195, 1.0\n",
      "Train loss and acc of batch 57: 48.414466857910156, 0.984375\n",
      "Train loss and acc of batch 58: 47.818756103515625, 1.0\n",
      "Train loss and acc of batch 59: 47.81874465942383, 1.0\n",
      "Train loss and acc of batch 60: 47.8187370300293, 1.0\n",
      "Train loss and acc of batch 61: 47.8187255859375, 1.0\n",
      "Train loss and acc of batch 62: 47.8187255859375, 1.0\n",
      "Train loss and acc of batch 63: 49.01011657714844, 0.96875\n",
      "Train loss and acc of batch 64: 48.03546905517578, 0.984375\n",
      "Train loss and acc of batch 65: 47.818695068359375, 1.0\n",
      "Train loss and acc of batch 66: 47.81867980957031, 1.0\n",
      "Train loss and acc of batch 67: 48.63113784790039, 0.96875\n",
      "Train loss and acc of batch 68: 48.41436767578125, 0.984375\n",
      "Train loss and acc of batch 69: 48.035423278808594, 0.984375\n",
      "Train loss and acc of batch 70: 47.81864929199219, 1.0\n",
      "Training accuracy and loss of epoch #379: 0.9897, 48.1398\n",
      "Saved model by train loss 48.139843792982504\n",
      "Train loss and acc of batch 0: 47.818641662597656, 1.0\n",
      "Train loss and acc of batch 1: 47.818634033203125, 1.0\n",
      "Train loss and acc of batch 2: 47.81862258911133, 1.0\n",
      "Train loss and acc of batch 3: 48.035377502441406, 0.984375\n",
      "Train loss and acc of batch 4: 47.818603515625, 1.0\n",
      "Train loss and acc of batch 5: 49.167518615722656, 0.96875\n",
      "Train loss and acc of batch 6: 48.321205139160156, 0.96875\n",
      "Train loss and acc of batch 7: 47.818580627441406, 1.0\n",
      "Train loss and acc of batch 8: 48.414268493652344, 0.984375\n",
      "Train loss and acc of batch 9: 48.104408264160156, 0.984375\n",
      "Train loss and acc of batch 10: 47.81855010986328, 1.0\n",
      "Train loss and acc of batch 11: 47.81854248046875, 1.0\n",
      "Train loss and acc of batch 12: 48.57175827026367, 0.984375\n",
      "Train loss and acc of batch 13: 48.03528594970703, 0.984375\n",
      "Train loss and acc of batch 14: 48.0352783203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.414207458496094, 0.984375\n",
      "Train loss and acc of batch 16: 48.41419982910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.57170867919922, 0.984375\n",
      "Train loss and acc of batch 18: 48.70003128051758, 0.96875\n",
      "Train loss and acc of batch 19: 47.81847381591797, 1.0\n",
      "Train loss and acc of batch 20: 47.81846618652344, 1.0\n",
      "Train loss and acc of batch 21: 48.414161682128906, 0.984375\n",
      "Train loss and acc of batch 22: 48.414146423339844, 0.984375\n",
      "Train loss and acc of batch 23: 47.81843948364258, 1.0\n",
      "Train loss and acc of batch 24: 48.41413116455078, 0.984375\n",
      "Train loss and acc of batch 25: 47.818416595458984, 1.0\n",
      "Train loss and acc of batch 26: 47.81840896606445, 1.0\n",
      "Train loss and acc of batch 27: 47.818397521972656, 1.0\n",
      "Train loss and acc of batch 28: 47.81839370727539, 1.0\n",
      "Train loss and acc of batch 29: 48.414085388183594, 0.984375\n",
      "Train loss and acc of batch 30: 47.81837844848633, 1.0\n",
      "Train loss and acc of batch 31: 48.035125732421875, 0.984375\n",
      "Train loss and acc of batch 32: 47.818355560302734, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.8183479309082, 1.0\n",
      "Train loss and acc of batch 34: 48.414039611816406, 0.984375\n",
      "Train loss and acc of batch 35: 48.25185775756836, 0.96875\n",
      "Train loss and acc of batch 36: 47.81832504272461, 1.0\n",
      "Train loss and acc of batch 37: 48.571537017822266, 0.984375\n",
      "Train loss and acc of batch 38: 49.16722869873047, 0.96875\n",
      "Train loss and acc of batch 39: 48.035057067871094, 0.984375\n",
      "Train loss and acc of batch 40: 47.81828308105469, 1.0\n",
      "Train loss and acc of batch 41: 49.16720199584961, 0.96875\n",
      "Train loss and acc of batch 42: 47.818267822265625, 1.0\n",
      "Train loss and acc of batch 43: 48.41395568847656, 0.984375\n",
      "Train loss and acc of batch 44: 47.81825256347656, 1.0\n",
      "Train loss and acc of batch 45: 48.4139404296875, 0.984375\n",
      "Train loss and acc of batch 46: 48.10408020019531, 0.984375\n",
      "Train loss and acc of batch 47: 47.81822204589844, 1.0\n",
      "Train loss and acc of batch 48: 47.818214416503906, 1.0\n",
      "Train loss and acc of batch 49: 47.818206787109375, 1.0\n",
      "Train loss and acc of batch 50: 48.41389465332031, 0.984375\n",
      "Train loss and acc of batch 51: 49.1671142578125, 0.96875\n",
      "Train loss and acc of batch 52: 49.07402038574219, 0.953125\n",
      "Train loss and acc of batch 53: 47.818172454833984, 1.0\n",
      "Train loss and acc of batch 54: 48.03491973876953, 0.984375\n",
      "Train loss and acc of batch 55: 47.81814956665039, 1.0\n",
      "Train loss and acc of batch 56: 47.81814193725586, 1.0\n",
      "Train loss and acc of batch 57: 48.41383361816406, 0.984375\n",
      "Train loss and acc of batch 58: 47.8181266784668, 1.0\n",
      "Train loss and acc of batch 59: 47.818119049072266, 1.0\n",
      "Train loss and acc of batch 60: 47.8181037902832, 1.0\n",
      "Train loss and acc of batch 61: 47.81809616088867, 1.0\n",
      "Train loss and acc of batch 62: 47.81808853149414, 1.0\n",
      "Train loss and acc of batch 63: 49.00948715209961, 0.96875\n",
      "Train loss and acc of batch 64: 48.03483581542969, 0.984375\n",
      "Train loss and acc of batch 65: 47.81806564331055, 1.0\n",
      "Train loss and acc of batch 66: 47.818058013916016, 1.0\n",
      "Train loss and acc of batch 67: 48.630516052246094, 0.96875\n",
      "Train loss and acc of batch 68: 48.413734436035156, 0.984375\n",
      "Train loss and acc of batch 69: 48.0347900390625, 0.984375\n",
      "Train loss and acc of batch 70: 47.81801986694336, 1.0\n",
      "Training accuracy and loss of epoch #380: 0.9897, 48.1392\n",
      "Saved model by train loss 48.13921280981789\n",
      "Train loss and acc of batch 0: 47.81800842285156, 1.0\n",
      "Train loss and acc of batch 1: 47.817996978759766, 1.0\n",
      "Train loss and acc of batch 2: 47.8179931640625, 1.0\n",
      "Train loss and acc of batch 3: 48.03474426269531, 0.984375\n",
      "Train loss and acc of batch 4: 47.817970275878906, 1.0\n",
      "Train loss and acc of batch 5: 49.16688537597656, 0.96875\n",
      "Train loss and acc of batch 6: 48.32057571411133, 0.96875\n",
      "Train loss and acc of batch 7: 47.81794738769531, 1.0\n",
      "Train loss and acc of batch 8: 48.41364288330078, 0.984375\n",
      "Train loss and acc of batch 9: 48.103782653808594, 0.984375\n",
      "Train loss and acc of batch 10: 47.81792449951172, 1.0\n",
      "Train loss and acc of batch 11: 47.817909240722656, 1.0\n",
      "Train loss and acc of batch 12: 48.571128845214844, 0.984375\n",
      "Train loss and acc of batch 13: 48.03466033935547, 0.984375\n",
      "Train loss and acc of batch 14: 48.034645080566406, 0.984375\n",
      "Train loss and acc of batch 15: 48.41358184814453, 0.984375\n",
      "Train loss and acc of batch 16: 48.41357421875, 0.984375\n",
      "Train loss and acc of batch 17: 48.571083068847656, 0.984375\n",
      "Train loss and acc of batch 18: 48.69940185546875, 0.96875\n",
      "Train loss and acc of batch 19: 47.81784439086914, 1.0\n",
      "Train loss and acc of batch 20: 47.81782913208008, 1.0\n",
      "Train loss and acc of batch 21: 48.41352844238281, 0.984375\n",
      "Train loss and acc of batch 22: 48.41351318359375, 0.984375\n",
      "Train loss and acc of batch 23: 47.81781005859375, 1.0\n",
      "Train loss and acc of batch 24: 48.41349792480469, 0.984375\n",
      "Train loss and acc of batch 25: 47.817787170410156, 1.0\n",
      "Train loss and acc of batch 26: 47.817771911621094, 1.0\n",
      "Train loss and acc of batch 27: 47.817771911621094, 1.0\n",
      "Train loss and acc of batch 28: 47.8177604675293, 1.0\n",
      "Train loss and acc of batch 29: 48.4134521484375, 0.984375\n",
      "Train loss and acc of batch 30: 47.81774139404297, 1.0\n",
      "Train loss and acc of batch 31: 48.03450012207031, 0.984375\n",
      "Train loss and acc of batch 32: 47.817726135253906, 1.0\n",
      "Train loss and acc of batch 33: 47.817718505859375, 1.0\n",
      "Train loss and acc of batch 34: 48.41340637207031, 0.984375\n",
      "Train loss and acc of batch 35: 48.251224517822266, 0.96875\n",
      "Train loss and acc of batch 36: 47.81768798828125, 1.0\n",
      "Train loss and acc of batch 37: 48.57090759277344, 0.984375\n",
      "Train loss and acc of batch 38: 49.166595458984375, 0.96875\n",
      "Train loss and acc of batch 39: 48.03443145751953, 0.984375\n",
      "Train loss and acc of batch 40: 47.81765365600586, 1.0\n",
      "Train loss and acc of batch 41: 49.16657257080078, 0.96875\n",
      "Train loss and acc of batch 42: 47.81763458251953, 1.0\n",
      "Train loss and acc of batch 43: 48.41332244873047, 0.984375\n",
      "Train loss and acc of batch 44: 47.8176155090332, 1.0\n",
      "Train loss and acc of batch 45: 48.413307189941406, 0.984375\n",
      "Train loss and acc of batch 46: 48.10344696044922, 0.984375\n",
      "Train loss and acc of batch 47: 47.817588806152344, 1.0\n",
      "Train loss and acc of batch 48: 47.81757736206055, 1.0\n",
      "Train loss and acc of batch 49: 47.81756591796875, 1.0\n",
      "Train loss and acc of batch 50: 48.41326141357422, 0.984375\n",
      "Train loss and acc of batch 51: 49.166481018066406, 0.96875\n",
      "Train loss and acc of batch 52: 49.073387145996094, 0.953125\n",
      "Train loss and acc of batch 53: 47.81753921508789, 1.0\n",
      "Train loss and acc of batch 54: 48.03429412841797, 0.984375\n",
      "Train loss and acc of batch 55: 47.8175163269043, 1.0\n",
      "Train loss and acc of batch 56: 47.81751251220703, 1.0\n",
      "Train loss and acc of batch 57: 48.41320037841797, 0.984375\n",
      "Train loss and acc of batch 58: 47.81748962402344, 1.0\n",
      "Train loss and acc of batch 59: 47.81747817993164, 1.0\n",
      "Train loss and acc of batch 60: 47.817474365234375, 1.0\n",
      "Train loss and acc of batch 61: 47.817466735839844, 1.0\n",
      "Train loss and acc of batch 62: 47.81745147705078, 1.0\n",
      "Train loss and acc of batch 63: 49.008846282958984, 0.96875\n",
      "Train loss and acc of batch 64: 48.034202575683594, 0.984375\n",
      "Train loss and acc of batch 65: 47.81742858886719, 1.0\n",
      "Train loss and acc of batch 66: 47.817420959472656, 1.0\n",
      "Train loss and acc of batch 67: 48.62987518310547, 0.96875\n",
      "Train loss and acc of batch 68: 48.413108825683594, 0.984375\n",
      "Train loss and acc of batch 69: 48.034156799316406, 0.984375\n",
      "Train loss and acc of batch 70: 47.817386627197266, 1.0\n",
      "Training accuracy and loss of epoch #381: 0.9897, 48.1386\n",
      "Saved model by train loss 48.13858064463441\n",
      "Train loss and acc of batch 0: 47.817378997802734, 1.0\n",
      "Train loss and acc of batch 1: 47.81736755371094, 1.0\n",
      "Train loss and acc of batch 2: 47.817359924316406, 1.0\n",
      "Train loss and acc of batch 3: 48.03411865234375, 0.984375\n",
      "Train loss and acc of batch 4: 47.81734085083008, 1.0\n",
      "Train loss and acc of batch 5: 49.16625213623047, 0.96875\n",
      "Train loss and acc of batch 6: 48.31993865966797, 0.96875\n",
      "Train loss and acc of batch 7: 47.81731033325195, 1.0\n",
      "Train loss and acc of batch 8: 48.41300964355469, 0.984375\n",
      "Train loss and acc of batch 9: 48.1031494140625, 0.984375\n",
      "Train loss and acc of batch 10: 47.81728744506836, 1.0\n",
      "Train loss and acc of batch 11: 47.81727981567383, 1.0\n",
      "Train loss and acc of batch 12: 48.57049560546875, 0.984375\n",
      "Train loss and acc of batch 13: 48.034027099609375, 0.984375\n",
      "Train loss and acc of batch 14: 48.03401184082031, 0.984375\n",
      "Train loss and acc of batch 15: 48.412940979003906, 0.984375\n",
      "Train loss and acc of batch 16: 48.412940979003906, 0.984375\n",
      "Train loss and acc of batch 17: 48.5704460144043, 0.984375\n",
      "Train loss and acc of batch 18: 48.69877243041992, 0.96875\n",
      "Train loss and acc of batch 19: 47.817203521728516, 1.0\n",
      "Train loss and acc of batch 20: 47.817195892333984, 1.0\n",
      "Train loss and acc of batch 21: 48.41288757324219, 0.984375\n",
      "Train loss and acc of batch 22: 48.412879943847656, 0.984375\n",
      "Train loss and acc of batch 23: 47.817169189453125, 1.0\n",
      "Train loss and acc of batch 24: 48.412864685058594, 0.984375\n",
      "Train loss and acc of batch 25: 47.81715393066406, 1.0\n",
      "Train loss and acc of batch 26: 47.81714630126953, 1.0\n",
      "Train loss and acc of batch 27: 47.817138671875, 1.0\n",
      "Train loss and acc of batch 28: 47.81713104248047, 1.0\n",
      "Train loss and acc of batch 29: 48.412818908691406, 0.984375\n",
      "Train loss and acc of batch 30: 47.81711196899414, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 31: 48.03386688232422, 0.984375\n",
      "Train loss and acc of batch 32: 47.81709671020508, 1.0\n",
      "Train loss and acc of batch 33: 47.81708526611328, 1.0\n",
      "Train loss and acc of batch 34: 48.41277313232422, 0.984375\n",
      "Train loss and acc of batch 35: 48.25059127807617, 0.96875\n",
      "Train loss and acc of batch 36: 47.817054748535156, 1.0\n",
      "Train loss and acc of batch 37: 48.57027053833008, 0.984375\n",
      "Train loss and acc of batch 38: 49.16596221923828, 0.96875\n",
      "Train loss and acc of batch 39: 48.03379821777344, 0.984375\n",
      "Train loss and acc of batch 40: 47.817020416259766, 1.0\n",
      "Train loss and acc of batch 41: 49.16593933105469, 0.96875\n",
      "Train loss and acc of batch 42: 47.81699752807617, 1.0\n",
      "Train loss and acc of batch 43: 48.412696838378906, 0.984375\n",
      "Train loss and acc of batch 44: 47.816986083984375, 1.0\n",
      "Train loss and acc of batch 45: 48.412681579589844, 0.984375\n",
      "Train loss and acc of batch 46: 48.102821350097656, 0.984375\n",
      "Train loss and acc of batch 47: 47.81696319580078, 1.0\n",
      "Train loss and acc of batch 48: 47.81694412231445, 1.0\n",
      "Train loss and acc of batch 49: 47.81694412231445, 1.0\n",
      "Train loss and acc of batch 50: 48.412628173828125, 0.984375\n",
      "Train loss and acc of batch 51: 49.16584777832031, 0.96875\n",
      "Train loss and acc of batch 52: 49.072750091552734, 0.953125\n",
      "Train loss and acc of batch 53: 47.81690216064453, 1.0\n",
      "Train loss and acc of batch 54: 48.033660888671875, 0.984375\n",
      "Train loss and acc of batch 55: 47.816890716552734, 1.0\n",
      "Train loss and acc of batch 56: 47.8168830871582, 1.0\n",
      "Train loss and acc of batch 57: 48.412567138671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.81686019897461, 1.0\n",
      "Train loss and acc of batch 59: 47.81685256958008, 1.0\n",
      "Train loss and acc of batch 60: 47.81684494018555, 1.0\n",
      "Train loss and acc of batch 61: 47.816837310791016, 1.0\n",
      "Train loss and acc of batch 62: 47.81682586669922, 1.0\n",
      "Train loss and acc of batch 63: 49.00822448730469, 0.96875\n",
      "Train loss and acc of batch 64: 48.0335693359375, 0.984375\n",
      "Train loss and acc of batch 65: 47.816795349121094, 1.0\n",
      "Train loss and acc of batch 66: 47.81678771972656, 1.0\n",
      "Train loss and acc of batch 67: 48.62924575805664, 0.96875\n",
      "Train loss and acc of batch 68: 48.4124755859375, 0.984375\n",
      "Train loss and acc of batch 69: 48.033531188964844, 0.984375\n",
      "Train loss and acc of batch 70: 47.81675338745117, 1.0\n",
      "Training accuracy and loss of epoch #382: 0.9897, 48.1379\n",
      "Saved model by train loss 48.137948694363445\n",
      "Train loss and acc of batch 0: 47.81674575805664, 1.0\n",
      "Train loss and acc of batch 1: 47.816734313964844, 1.0\n",
      "Train loss and acc of batch 2: 47.81673049926758, 1.0\n",
      "Train loss and acc of batch 3: 48.033485412597656, 0.984375\n",
      "Train loss and acc of batch 4: 47.81671142578125, 1.0\n",
      "Train loss and acc of batch 5: 49.165626525878906, 0.96875\n",
      "Train loss and acc of batch 6: 48.319313049316406, 0.96875\n",
      "Train loss and acc of batch 7: 47.81668472290039, 1.0\n",
      "Train loss and acc of batch 8: 48.41236877441406, 0.984375\n",
      "Train loss and acc of batch 9: 48.102516174316406, 0.984375\n",
      "Train loss and acc of batch 10: 47.816654205322266, 1.0\n",
      "Train loss and acc of batch 11: 47.816646575927734, 1.0\n",
      "Train loss and acc of batch 12: 48.56985855102539, 0.984375\n",
      "Train loss and acc of batch 13: 48.03339385986328, 0.984375\n",
      "Train loss and acc of batch 14: 48.03338623046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.41230773925781, 0.984375\n",
      "Train loss and acc of batch 16: 48.41230010986328, 0.984375\n",
      "Train loss and acc of batch 17: 48.569820404052734, 0.984375\n",
      "Train loss and acc of batch 18: 48.69813919067383, 0.96875\n",
      "Train loss and acc of batch 19: 47.81658172607422, 1.0\n",
      "Train loss and acc of batch 20: 47.81657028198242, 1.0\n",
      "Train loss and acc of batch 21: 48.412261962890625, 0.984375\n",
      "Train loss and acc of batch 22: 48.412254333496094, 0.984375\n",
      "Train loss and acc of batch 23: 47.8165397644043, 1.0\n",
      "Train loss and acc of batch 24: 48.4122314453125, 0.984375\n",
      "Train loss and acc of batch 25: 47.816524505615234, 1.0\n",
      "Train loss and acc of batch 26: 47.81651306152344, 1.0\n",
      "Train loss and acc of batch 27: 47.816505432128906, 1.0\n",
      "Train loss and acc of batch 28: 47.81649398803711, 1.0\n",
      "Train loss and acc of batch 29: 48.41218566894531, 0.984375\n",
      "Train loss and acc of batch 30: 47.81648254394531, 1.0\n",
      "Train loss and acc of batch 31: 48.033233642578125, 0.984375\n",
      "Train loss and acc of batch 32: 47.81645965576172, 1.0\n",
      "Train loss and acc of batch 33: 47.81645584106445, 1.0\n",
      "Train loss and acc of batch 34: 48.412147521972656, 0.984375\n",
      "Train loss and acc of batch 35: 48.24996566772461, 0.96875\n",
      "Train loss and acc of batch 36: 47.81642532348633, 1.0\n",
      "Train loss and acc of batch 37: 48.569644927978516, 0.984375\n",
      "Train loss and acc of batch 38: 49.16532897949219, 0.96875\n",
      "Train loss and acc of batch 39: 48.03315734863281, 0.984375\n",
      "Train loss and acc of batch 40: 47.81639099121094, 1.0\n",
      "Train loss and acc of batch 41: 49.16530990600586, 0.96875\n",
      "Train loss and acc of batch 42: 47.81637191772461, 1.0\n",
      "Train loss and acc of batch 43: 48.41206359863281, 0.984375\n",
      "Train loss and acc of batch 44: 47.81635284423828, 1.0\n",
      "Train loss and acc of batch 45: 48.41204833984375, 0.984375\n",
      "Train loss and acc of batch 46: 48.10218811035156, 0.984375\n",
      "Train loss and acc of batch 47: 47.81632995605469, 1.0\n",
      "Train loss and acc of batch 48: 47.816322326660156, 1.0\n",
      "Train loss and acc of batch 49: 47.81631088256836, 1.0\n",
      "Train loss and acc of batch 50: 48.41200256347656, 0.984375\n",
      "Train loss and acc of batch 51: 49.16522216796875, 0.96875\n",
      "Train loss and acc of batch 52: 49.072120666503906, 0.953125\n",
      "Train loss and acc of batch 53: 47.8162727355957, 1.0\n",
      "Train loss and acc of batch 54: 48.03302764892578, 0.984375\n",
      "Train loss and acc of batch 55: 47.816253662109375, 1.0\n",
      "Train loss and acc of batch 56: 47.816246032714844, 1.0\n",
      "Train loss and acc of batch 57: 48.41194152832031, 0.984375\n",
      "Train loss and acc of batch 58: 47.81623458862305, 1.0\n",
      "Train loss and acc of batch 59: 47.816219329833984, 1.0\n",
      "Train loss and acc of batch 60: 47.81621170043945, 1.0\n",
      "Train loss and acc of batch 61: 47.81620407104492, 1.0\n",
      "Train loss and acc of batch 62: 47.81619644165039, 1.0\n",
      "Train loss and acc of batch 63: 49.00758743286133, 0.96875\n",
      "Train loss and acc of batch 64: 48.03294372558594, 0.984375\n",
      "Train loss and acc of batch 65: 47.8161735534668, 1.0\n",
      "Train loss and acc of batch 66: 47.8161506652832, 1.0\n",
      "Train loss and acc of batch 67: 48.62861251831055, 0.96875\n",
      "Train loss and acc of batch 68: 48.411842346191406, 0.984375\n",
      "Train loss and acc of batch 69: 48.03289794921875, 0.984375\n",
      "Train loss and acc of batch 70: 47.81612777709961, 1.0\n",
      "Training accuracy and loss of epoch #383: 0.9897, 48.1373\n",
      "Saved model by train loss 48.13731781865509\n",
      "Train loss and acc of batch 0: 47.81611251831055, 1.0\n",
      "Train loss and acc of batch 1: 47.816104888916016, 1.0\n",
      "Train loss and acc of batch 2: 47.816097259521484, 1.0\n",
      "Train loss and acc of batch 3: 48.03285217285156, 0.984375\n",
      "Train loss and acc of batch 4: 47.816078186035156, 1.0\n",
      "Train loss and acc of batch 5: 49.16499328613281, 0.96875\n",
      "Train loss and acc of batch 6: 48.31867980957031, 0.96875\n",
      "Train loss and acc of batch 7: 47.81605529785156, 1.0\n",
      "Train loss and acc of batch 8: 48.4117431640625, 0.984375\n",
      "Train loss and acc of batch 9: 48.101890563964844, 0.984375\n",
      "Train loss and acc of batch 10: 47.81602478027344, 1.0\n",
      "Train loss and acc of batch 11: 47.81601333618164, 1.0\n",
      "Train loss and acc of batch 12: 48.56922912597656, 0.984375\n",
      "Train loss and acc of batch 13: 48.03276062011719, 0.984375\n",
      "Train loss and acc of batch 14: 48.032752990722656, 0.984375\n",
      "Train loss and acc of batch 15: 48.41168212890625, 0.984375\n",
      "Train loss and acc of batch 16: 48.41167449951172, 0.984375\n",
      "Train loss and acc of batch 17: 48.569183349609375, 0.984375\n",
      "Train loss and acc of batch 18: 48.697509765625, 0.96875\n",
      "Train loss and acc of batch 19: 47.81594467163086, 1.0\n",
      "Train loss and acc of batch 20: 47.81593704223633, 1.0\n",
      "Train loss and acc of batch 21: 48.41162872314453, 0.984375\n",
      "Train loss and acc of batch 22: 48.41162109375, 0.984375\n",
      "Train loss and acc of batch 23: 47.81591033935547, 1.0\n",
      "Train loss and acc of batch 24: 48.41160583496094, 0.984375\n",
      "Train loss and acc of batch 25: 47.81589126586914, 1.0\n",
      "Train loss and acc of batch 26: 47.81588363647461, 1.0\n",
      "Train loss and acc of batch 27: 47.81587600708008, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 28: 47.815860748291016, 1.0\n",
      "Train loss and acc of batch 29: 48.41156005859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.81584930419922, 1.0\n",
      "Train loss and acc of batch 31: 48.03260040283203, 0.984375\n",
      "Train loss and acc of batch 32: 47.81583023071289, 1.0\n",
      "Train loss and acc of batch 33: 47.815818786621094, 1.0\n",
      "Train loss and acc of batch 34: 48.41151428222656, 0.984375\n",
      "Train loss and acc of batch 35: 48.249332427978516, 0.96875\n",
      "Train loss and acc of batch 36: 47.815799713134766, 1.0\n",
      "Train loss and acc of batch 37: 48.569007873535156, 0.984375\n",
      "Train loss and acc of batch 38: 49.164703369140625, 0.96875\n",
      "Train loss and acc of batch 39: 48.03253173828125, 0.984375\n",
      "Train loss and acc of batch 40: 47.81575393676758, 1.0\n",
      "Train loss and acc of batch 41: 49.164676666259766, 0.96875\n",
      "Train loss and acc of batch 42: 47.815738677978516, 1.0\n",
      "Train loss and acc of batch 43: 48.41143798828125, 0.984375\n",
      "Train loss and acc of batch 44: 47.81572723388672, 1.0\n",
      "Train loss and acc of batch 45: 48.411415100097656, 0.984375\n",
      "Train loss and acc of batch 46: 48.10155487060547, 0.984375\n",
      "Train loss and acc of batch 47: 47.815696716308594, 1.0\n",
      "Train loss and acc of batch 48: 47.8156852722168, 1.0\n",
      "Train loss and acc of batch 49: 47.81568145751953, 1.0\n",
      "Train loss and acc of batch 50: 48.411376953125, 0.984375\n",
      "Train loss and acc of batch 51: 49.164588928222656, 0.96875\n",
      "Train loss and acc of batch 52: 49.071495056152344, 0.953125\n",
      "Train loss and acc of batch 53: 47.81564712524414, 1.0\n",
      "Train loss and acc of batch 54: 48.03239440917969, 0.984375\n",
      "Train loss and acc of batch 55: 47.81562805175781, 1.0\n",
      "Train loss and acc of batch 56: 47.815616607666016, 1.0\n",
      "Train loss and acc of batch 57: 48.41131591796875, 0.984375\n",
      "Train loss and acc of batch 58: 47.81559753417969, 1.0\n",
      "Train loss and acc of batch 59: 47.81559371948242, 1.0\n",
      "Train loss and acc of batch 60: 47.815582275390625, 1.0\n",
      "Train loss and acc of batch 61: 47.81557083129883, 1.0\n",
      "Train loss and acc of batch 62: 47.81555938720703, 1.0\n",
      "Train loss and acc of batch 63: 49.0069580078125, 0.96875\n",
      "Train loss and acc of batch 64: 48.032310485839844, 0.984375\n",
      "Train loss and acc of batch 65: 47.81553268432617, 1.0\n",
      "Train loss and acc of batch 66: 47.815528869628906, 1.0\n",
      "Train loss and acc of batch 67: 48.627986907958984, 0.96875\n",
      "Train loss and acc of batch 68: 48.41120910644531, 0.984375\n",
      "Train loss and acc of batch 69: 48.032264709472656, 0.984375\n",
      "Train loss and acc of batch 70: 47.81549072265625, 1.0\n",
      "Training accuracy and loss of epoch #384: 0.9897, 48.1367\n",
      "Saved model by train loss 48.13668678176235\n",
      "Train loss and acc of batch 0: 47.81548309326172, 1.0\n",
      "Train loss and acc of batch 1: 47.81547546386719, 1.0\n",
      "Train loss and acc of batch 2: 47.815467834472656, 1.0\n",
      "Train loss and acc of batch 3: 48.03221893310547, 0.984375\n",
      "Train loss and acc of batch 4: 47.81544494628906, 1.0\n",
      "Train loss and acc of batch 5: 49.16436004638672, 0.96875\n",
      "Train loss and acc of batch 6: 48.31804656982422, 0.96875\n",
      "Train loss and acc of batch 7: 47.81542205810547, 1.0\n",
      "Train loss and acc of batch 8: 48.411109924316406, 0.984375\n",
      "Train loss and acc of batch 9: 48.10125732421875, 0.984375\n",
      "Train loss and acc of batch 10: 47.81539535522461, 1.0\n",
      "Train loss and acc of batch 11: 47.81538772583008, 1.0\n",
      "Train loss and acc of batch 12: 48.568599700927734, 0.984375\n",
      "Train loss and acc of batch 13: 48.032135009765625, 0.984375\n",
      "Train loss and acc of batch 14: 48.032127380371094, 0.984375\n",
      "Train loss and acc of batch 15: 48.411048889160156, 0.984375\n",
      "Train loss and acc of batch 16: 48.411048889160156, 0.984375\n",
      "Train loss and acc of batch 17: 48.56855773925781, 0.984375\n",
      "Train loss and acc of batch 18: 48.69687271118164, 0.96875\n",
      "Train loss and acc of batch 19: 47.815311431884766, 1.0\n",
      "Train loss and acc of batch 20: 47.815303802490234, 1.0\n",
      "Train loss and acc of batch 21: 48.41100311279297, 0.984375\n",
      "Train loss and acc of batch 22: 48.410987854003906, 0.984375\n",
      "Train loss and acc of batch 23: 47.81528091430664, 1.0\n",
      "Train loss and acc of batch 24: 48.410972595214844, 0.984375\n",
      "Train loss and acc of batch 25: 47.81526565551758, 1.0\n",
      "Train loss and acc of batch 26: 47.815250396728516, 1.0\n",
      "Train loss and acc of batch 27: 47.815242767333984, 1.0\n",
      "Train loss and acc of batch 28: 47.81523132324219, 1.0\n",
      "Train loss and acc of batch 29: 48.410926818847656, 0.984375\n",
      "Train loss and acc of batch 30: 47.81521987915039, 1.0\n",
      "Train loss and acc of batch 31: 48.03197479248047, 0.984375\n",
      "Train loss and acc of batch 32: 47.8151969909668, 1.0\n",
      "Train loss and acc of batch 33: 47.815189361572266, 1.0\n",
      "Train loss and acc of batch 34: 48.41088104248047, 0.984375\n",
      "Train loss and acc of batch 35: 48.24870300292969, 0.96875\n",
      "Train loss and acc of batch 36: 47.815162658691406, 1.0\n",
      "Train loss and acc of batch 37: 48.56837844848633, 0.984375\n",
      "Train loss and acc of batch 38: 49.16407012939453, 0.96875\n",
      "Train loss and acc of batch 39: 48.031898498535156, 0.984375\n",
      "Train loss and acc of batch 40: 47.815128326416016, 1.0\n",
      "Train loss and acc of batch 41: 49.16404342651367, 0.96875\n",
      "Train loss and acc of batch 42: 47.81511306762695, 1.0\n",
      "Train loss and acc of batch 43: 48.410804748535156, 0.984375\n",
      "Train loss and acc of batch 44: 47.815093994140625, 1.0\n",
      "Train loss and acc of batch 45: 48.41078186035156, 0.984375\n",
      "Train loss and acc of batch 46: 48.100929260253906, 0.984375\n",
      "Train loss and acc of batch 47: 47.81507110595703, 1.0\n",
      "Train loss and acc of batch 48: 47.81505584716797, 1.0\n",
      "Train loss and acc of batch 49: 47.81504821777344, 1.0\n",
      "Train loss and acc of batch 50: 48.410743713378906, 0.984375\n",
      "Train loss and acc of batch 51: 49.16395568847656, 0.96875\n",
      "Train loss and acc of batch 52: 49.070865631103516, 0.953125\n",
      "Train loss and acc of batch 53: 47.81501388549805, 1.0\n",
      "Train loss and acc of batch 54: 48.031768798828125, 0.984375\n",
      "Train loss and acc of batch 55: 47.81499099731445, 1.0\n",
      "Train loss and acc of batch 56: 47.81498336791992, 1.0\n",
      "Train loss and acc of batch 57: 48.410682678222656, 0.984375\n",
      "Train loss and acc of batch 58: 47.814971923828125, 1.0\n",
      "Train loss and acc of batch 59: 47.81495666503906, 1.0\n",
      "Train loss and acc of batch 60: 47.81494903564453, 1.0\n",
      "Train loss and acc of batch 61: 47.81494140625, 1.0\n",
      "Train loss and acc of batch 62: 47.81493377685547, 1.0\n",
      "Train loss and acc of batch 63: 49.006324768066406, 0.96875\n",
      "Train loss and acc of batch 64: 48.03167724609375, 0.984375\n",
      "Train loss and acc of batch 65: 47.814903259277344, 1.0\n",
      "Train loss and acc of batch 66: 47.81489944458008, 1.0\n",
      "Train loss and acc of batch 67: 48.62735366821289, 0.96875\n",
      "Train loss and acc of batch 68: 48.41058349609375, 0.984375\n",
      "Train loss and acc of batch 69: 48.03163146972656, 0.984375\n",
      "Train loss and acc of batch 70: 47.81486129760742, 1.0\n",
      "Training accuracy and loss of epoch #385: 0.9897, 48.1361\n",
      "Saved model by train loss 48.136055959782134\n",
      "Train loss and acc of batch 0: 47.81485366821289, 1.0\n",
      "Train loss and acc of batch 1: 47.81484603881836, 1.0\n",
      "Train loss and acc of batch 2: 47.81483459472656, 1.0\n",
      "Train loss and acc of batch 3: 48.031593322753906, 0.984375\n",
      "Train loss and acc of batch 4: 47.8148193359375, 1.0\n",
      "Train loss and acc of batch 5: 49.163734436035156, 0.96875\n",
      "Train loss and acc of batch 6: 48.31741714477539, 0.96875\n",
      "Train loss and acc of batch 7: 47.814788818359375, 1.0\n",
      "Train loss and acc of batch 8: 48.410484313964844, 0.984375\n",
      "Train loss and acc of batch 9: 48.100624084472656, 0.984375\n",
      "Train loss and acc of batch 10: 47.81476593017578, 1.0\n",
      "Train loss and acc of batch 11: 47.814754486083984, 1.0\n",
      "Train loss and acc of batch 12: 48.567970275878906, 0.984375\n",
      "Train loss and acc of batch 13: 48.031494140625, 0.984375\n",
      "Train loss and acc of batch 14: 48.031494140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.410423278808594, 0.984375\n",
      "Train loss and acc of batch 16: 48.41040802001953, 0.984375\n",
      "Train loss and acc of batch 17: 48.567928314208984, 0.984375\n",
      "Train loss and acc of batch 18: 48.696250915527344, 0.96875\n",
      "Train loss and acc of batch 19: 47.8146858215332, 1.0\n",
      "Train loss and acc of batch 20: 47.814674377441406, 1.0\n",
      "Train loss and acc of batch 21: 48.410362243652344, 0.984375\n",
      "Train loss and acc of batch 22: 48.41035461425781, 0.984375\n",
      "Train loss and acc of batch 23: 47.81464767456055, 1.0\n",
      "Train loss and acc of batch 24: 48.41034698486328, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 25: 47.81462860107422, 1.0\n",
      "Train loss and acc of batch 26: 47.81462097167969, 1.0\n",
      "Train loss and acc of batch 27: 47.814613342285156, 1.0\n",
      "Train loss and acc of batch 28: 47.814605712890625, 1.0\n",
      "Train loss and acc of batch 29: 48.41029357910156, 0.984375\n",
      "Train loss and acc of batch 30: 47.81458282470703, 1.0\n",
      "Train loss and acc of batch 31: 48.031341552734375, 0.984375\n",
      "Train loss and acc of batch 32: 47.814571380615234, 1.0\n",
      "Train loss and acc of batch 33: 47.81455993652344, 1.0\n",
      "Train loss and acc of batch 34: 48.41026306152344, 0.984375\n",
      "Train loss and acc of batch 35: 48.248069763183594, 0.96875\n",
      "Train loss and acc of batch 36: 47.81453323364258, 1.0\n",
      "Train loss and acc of batch 37: 48.5677490234375, 0.984375\n",
      "Train loss and acc of batch 38: 49.16344451904297, 0.96875\n",
      "Train loss and acc of batch 39: 48.031272888183594, 0.984375\n",
      "Train loss and acc of batch 40: 47.81449508666992, 1.0\n",
      "Train loss and acc of batch 41: 49.163414001464844, 0.96875\n",
      "Train loss and acc of batch 42: 47.81447982788086, 1.0\n",
      "Train loss and acc of batch 43: 48.41017150878906, 0.984375\n",
      "Train loss and acc of batch 44: 47.81446075439453, 1.0\n",
      "Train loss and acc of batch 45: 48.41015625, 0.984375\n",
      "Train loss and acc of batch 46: 48.10029602050781, 0.984375\n",
      "Train loss and acc of batch 47: 47.81443786621094, 1.0\n",
      "Train loss and acc of batch 48: 47.81442642211914, 1.0\n",
      "Train loss and acc of batch 49: 47.81441879272461, 1.0\n",
      "Train loss and acc of batch 50: 48.41011047363281, 0.984375\n",
      "Train loss and acc of batch 51: 49.16332244873047, 0.96875\n",
      "Train loss and acc of batch 52: 49.07023239135742, 0.953125\n",
      "Train loss and acc of batch 53: 47.81438064575195, 1.0\n",
      "Train loss and acc of batch 54: 48.03113555908203, 0.984375\n",
      "Train loss and acc of batch 55: 47.81436538696289, 1.0\n",
      "Train loss and acc of batch 56: 47.81435775756836, 1.0\n",
      "Train loss and acc of batch 57: 48.41004943847656, 0.984375\n",
      "Train loss and acc of batch 58: 47.814334869384766, 1.0\n",
      "Train loss and acc of batch 59: 47.8143310546875, 1.0\n",
      "Train loss and acc of batch 60: 47.8143196105957, 1.0\n",
      "Train loss and acc of batch 61: 47.81431198120117, 1.0\n",
      "Train loss and acc of batch 62: 47.814308166503906, 1.0\n",
      "Train loss and acc of batch 63: 49.00569534301758, 0.96875\n",
      "Train loss and acc of batch 64: 48.031044006347656, 0.984375\n",
      "Train loss and acc of batch 65: 47.814273834228516, 1.0\n",
      "Train loss and acc of batch 66: 47.814266204833984, 1.0\n",
      "Train loss and acc of batch 67: 48.6267204284668, 0.96875\n",
      "Train loss and acc of batch 68: 48.409950256347656, 0.984375\n",
      "Train loss and acc of batch 69: 48.031005859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.814231872558594, 1.0\n",
      "Training accuracy and loss of epoch #386: 0.9897, 48.1354\n",
      "Saved model by train loss 48.135425513898824\n",
      "Train loss and acc of batch 0: 47.8142204284668, 1.0\n",
      "Train loss and acc of batch 1: 47.814212799072266, 1.0\n",
      "Train loss and acc of batch 2: 47.814205169677734, 1.0\n",
      "Train loss and acc of batch 3: 48.03096008300781, 0.984375\n",
      "Train loss and acc of batch 4: 47.814186096191406, 1.0\n",
      "Train loss and acc of batch 5: 49.163108825683594, 0.96875\n",
      "Train loss and acc of batch 6: 48.31678771972656, 0.96875\n",
      "Train loss and acc of batch 7: 47.81415939331055, 1.0\n",
      "Train loss and acc of batch 8: 48.40985870361328, 0.984375\n",
      "Train loss and acc of batch 9: 48.099998474121094, 0.984375\n",
      "Train loss and acc of batch 10: 47.81412887573242, 1.0\n",
      "Train loss and acc of batch 11: 47.814125061035156, 1.0\n",
      "Train loss and acc of batch 12: 48.56733703613281, 0.984375\n",
      "Train loss and acc of batch 13: 48.03087615966797, 0.984375\n",
      "Train loss and acc of batch 14: 48.030860900878906, 0.984375\n",
      "Train loss and acc of batch 15: 48.4097900390625, 0.984375\n",
      "Train loss and acc of batch 16: 48.40978240966797, 0.984375\n",
      "Train loss and acc of batch 17: 48.56729507446289, 0.984375\n",
      "Train loss and acc of batch 18: 48.695613861083984, 0.96875\n",
      "Train loss and acc of batch 19: 47.814056396484375, 1.0\n",
      "Train loss and acc of batch 20: 47.81404113769531, 1.0\n",
      "Train loss and acc of batch 21: 48.40973663330078, 0.984375\n",
      "Train loss and acc of batch 22: 48.40972900390625, 0.984375\n",
      "Train loss and acc of batch 23: 47.81401443481445, 1.0\n",
      "Train loss and acc of batch 24: 48.409706115722656, 0.984375\n",
      "Train loss and acc of batch 25: 47.81399917602539, 1.0\n",
      "Train loss and acc of batch 26: 47.81399154663086, 1.0\n",
      "Train loss and acc of batch 27: 47.81398391723633, 1.0\n",
      "Train loss and acc of batch 28: 47.8139762878418, 1.0\n",
      "Train loss and acc of batch 29: 48.40966033935547, 0.984375\n",
      "Train loss and acc of batch 30: 47.8139533996582, 1.0\n",
      "Train loss and acc of batch 31: 48.03070831298828, 0.984375\n",
      "Train loss and acc of batch 32: 47.81393814086914, 1.0\n",
      "Train loss and acc of batch 33: 47.813934326171875, 1.0\n",
      "Train loss and acc of batch 34: 48.40962219238281, 0.984375\n",
      "Train loss and acc of batch 35: 48.247440338134766, 0.96875\n",
      "Train loss and acc of batch 36: 47.813907623291016, 1.0\n",
      "Train loss and acc of batch 37: 48.567115783691406, 0.984375\n",
      "Train loss and acc of batch 38: 49.162811279296875, 0.96875\n",
      "Train loss and acc of batch 39: 48.0306396484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.813865661621094, 1.0\n",
      "Train loss and acc of batch 41: 49.162784576416016, 0.96875\n",
      "Train loss and acc of batch 42: 47.81385040283203, 1.0\n",
      "Train loss and acc of batch 43: 48.4095458984375, 0.984375\n",
      "Train loss and acc of batch 44: 47.8138313293457, 1.0\n",
      "Train loss and acc of batch 45: 48.409523010253906, 0.984375\n",
      "Train loss and acc of batch 46: 48.09966278076172, 0.984375\n",
      "Train loss and acc of batch 47: 47.81380844116211, 1.0\n",
      "Train loss and acc of batch 48: 47.81379699707031, 1.0\n",
      "Train loss and acc of batch 49: 47.813785552978516, 1.0\n",
      "Train loss and acc of batch 50: 48.40948486328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.162696838378906, 0.96875\n",
      "Train loss and acc of batch 52: 49.069602966308594, 0.953125\n",
      "Train loss and acc of batch 53: 47.81375503540039, 1.0\n",
      "Train loss and acc of batch 54: 48.03050994873047, 0.984375\n",
      "Train loss and acc of batch 55: 47.81373596191406, 1.0\n",
      "Train loss and acc of batch 56: 47.81372833251953, 1.0\n",
      "Train loss and acc of batch 57: 48.40941619873047, 0.984375\n",
      "Train loss and acc of batch 58: 47.8137092590332, 1.0\n",
      "Train loss and acc of batch 59: 47.81369400024414, 1.0\n",
      "Train loss and acc of batch 60: 47.81368637084961, 1.0\n",
      "Train loss and acc of batch 61: 47.813682556152344, 1.0\n",
      "Train loss and acc of batch 62: 47.81367111206055, 1.0\n",
      "Train loss and acc of batch 63: 49.005062103271484, 0.96875\n",
      "Train loss and acc of batch 64: 48.030426025390625, 0.984375\n",
      "Train loss and acc of batch 65: 47.81364440917969, 1.0\n",
      "Train loss and acc of batch 66: 47.813636779785156, 1.0\n",
      "Train loss and acc of batch 67: 48.62609100341797, 0.96875\n",
      "Train loss and acc of batch 68: 48.409324645996094, 0.984375\n",
      "Train loss and acc of batch 69: 48.030372619628906, 0.984375\n",
      "Train loss and acc of batch 70: 47.8135986328125, 1.0\n",
      "Training accuracy and loss of epoch #387: 0.9897, 48.1348\n",
      "Saved model by train loss 48.13479517547177\n",
      "Train loss and acc of batch 0: 47.81359100341797, 1.0\n",
      "Train loss and acc of batch 1: 47.81358337402344, 1.0\n",
      "Train loss and acc of batch 2: 47.81357192993164, 1.0\n",
      "Train loss and acc of batch 3: 48.03032684326172, 0.984375\n",
      "Train loss and acc of batch 4: 47.81355667114258, 1.0\n",
      "Train loss and acc of batch 5: 49.16246795654297, 0.96875\n",
      "Train loss and acc of batch 6: 48.31615447998047, 0.96875\n",
      "Train loss and acc of batch 7: 47.813533782958984, 1.0\n",
      "Train loss and acc of batch 8: 48.40922546386719, 0.984375\n",
      "Train loss and acc of batch 9: 48.099365234375, 0.984375\n",
      "Train loss and acc of batch 10: 47.81350326538086, 1.0\n",
      "Train loss and acc of batch 11: 47.81349182128906, 1.0\n",
      "Train loss and acc of batch 12: 48.56671142578125, 0.984375\n",
      "Train loss and acc of batch 13: 48.030242919921875, 0.984375\n",
      "Train loss and acc of batch 14: 48.030235290527344, 0.984375\n",
      "Train loss and acc of batch 15: 48.409156799316406, 0.984375\n",
      "Train loss and acc of batch 16: 48.409149169921875, 0.984375\n",
      "Train loss and acc of batch 17: 48.5666618347168, 0.984375\n",
      "Train loss and acc of batch 18: 48.69498825073242, 0.96875\n",
      "Train loss and acc of batch 19: 47.813419342041016, 1.0\n",
      "Train loss and acc of batch 20: 47.813411712646484, 1.0\n",
      "Train loss and acc of batch 21: 48.40911102294922, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 22: 48.409095764160156, 0.984375\n",
      "Train loss and acc of batch 23: 47.813385009765625, 1.0\n",
      "Train loss and acc of batch 24: 48.409080505371094, 0.984375\n",
      "Train loss and acc of batch 25: 47.81336975097656, 1.0\n",
      "Train loss and acc of batch 26: 47.81336212158203, 1.0\n",
      "Train loss and acc of batch 27: 47.813350677490234, 1.0\n",
      "Train loss and acc of batch 28: 47.8133430480957, 1.0\n",
      "Train loss and acc of batch 29: 48.409034729003906, 0.984375\n",
      "Train loss and acc of batch 30: 47.81332778930664, 1.0\n",
      "Train loss and acc of batch 31: 48.03007507324219, 0.984375\n",
      "Train loss and acc of batch 32: 47.81330871582031, 1.0\n",
      "Train loss and acc of batch 33: 47.813297271728516, 1.0\n",
      "Train loss and acc of batch 34: 48.40898895263672, 0.984375\n",
      "Train loss and acc of batch 35: 48.24681091308594, 0.96875\n",
      "Train loss and acc of batch 36: 47.81327438354492, 1.0\n",
      "Train loss and acc of batch 37: 48.56648635864258, 0.984375\n",
      "Train loss and acc of batch 38: 49.16218566894531, 0.96875\n",
      "Train loss and acc of batch 39: 48.030006408691406, 0.984375\n",
      "Train loss and acc of batch 40: 47.813232421875, 1.0\n",
      "Train loss and acc of batch 41: 49.16215515136719, 0.96875\n",
      "Train loss and acc of batch 42: 47.81321716308594, 1.0\n",
      "Train loss and acc of batch 43: 48.408912658691406, 0.984375\n",
      "Train loss and acc of batch 44: 47.813201904296875, 1.0\n",
      "Train loss and acc of batch 45: 48.40888977050781, 0.984375\n",
      "Train loss and acc of batch 46: 48.099037170410156, 0.984375\n",
      "Train loss and acc of batch 47: 47.81317138671875, 1.0\n",
      "Train loss and acc of batch 48: 47.81316375732422, 1.0\n",
      "Train loss and acc of batch 49: 47.81315994262695, 1.0\n",
      "Train loss and acc of batch 50: 48.408851623535156, 0.984375\n",
      "Train loss and acc of batch 51: 49.16206359863281, 0.96875\n",
      "Train loss and acc of batch 52: 49.068973541259766, 0.953125\n",
      "Train loss and acc of batch 53: 47.8131217956543, 1.0\n",
      "Train loss and acc of batch 54: 48.029876708984375, 0.984375\n",
      "Train loss and acc of batch 55: 47.8130989074707, 1.0\n",
      "Train loss and acc of batch 56: 47.81309127807617, 1.0\n",
      "Train loss and acc of batch 57: 48.408790588378906, 0.984375\n",
      "Train loss and acc of batch 58: 47.81307601928711, 1.0\n",
      "Train loss and acc of batch 59: 47.81306838989258, 1.0\n",
      "Train loss and acc of batch 60: 47.81305694580078, 1.0\n",
      "Train loss and acc of batch 61: 47.81304931640625, 1.0\n",
      "Train loss and acc of batch 62: 47.81303787231445, 1.0\n",
      "Train loss and acc of batch 63: 49.00443649291992, 0.96875\n",
      "Train loss and acc of batch 64: 48.02978515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.81301498413086, 1.0\n",
      "Train loss and acc of batch 66: 47.81300735473633, 1.0\n",
      "Train loss and acc of batch 67: 48.62546157836914, 0.96875\n",
      "Train loss and acc of batch 68: 48.40868377685547, 0.984375\n",
      "Train loss and acc of batch 69: 48.029747009277344, 0.984375\n",
      "Train loss and acc of batch 70: 47.812965393066406, 1.0\n",
      "Training accuracy and loss of epoch #388: 0.9897, 48.1342\n",
      "Saved model by train loss 48.13416397739464\n",
      "Train loss and acc of batch 0: 47.81296157836914, 1.0\n",
      "Train loss and acc of batch 1: 47.812950134277344, 1.0\n",
      "Train loss and acc of batch 2: 47.81294250488281, 1.0\n",
      "Train loss and acc of batch 3: 48.029701232910156, 0.984375\n",
      "Train loss and acc of batch 4: 47.812923431396484, 1.0\n",
      "Train loss and acc of batch 5: 49.161842346191406, 0.96875\n",
      "Train loss and acc of batch 6: 48.31552505493164, 0.96875\n",
      "Train loss and acc of batch 7: 47.81290054321289, 1.0\n",
      "Train loss and acc of batch 8: 48.408592224121094, 0.984375\n",
      "Train loss and acc of batch 9: 48.098731994628906, 0.984375\n",
      "Train loss and acc of batch 10: 47.812870025634766, 1.0\n",
      "Train loss and acc of batch 11: 47.812862396240234, 1.0\n",
      "Train loss and acc of batch 12: 48.566078186035156, 0.984375\n",
      "Train loss and acc of batch 13: 48.02960968017578, 0.984375\n",
      "Train loss and acc of batch 14: 48.02960205078125, 0.984375\n",
      "Train loss and acc of batch 15: 48.408531188964844, 0.984375\n",
      "Train loss and acc of batch 16: 48.40851593017578, 0.984375\n",
      "Train loss and acc of batch 17: 48.566036224365234, 0.984375\n",
      "Train loss and acc of batch 18: 48.69435119628906, 0.96875\n",
      "Train loss and acc of batch 19: 47.81278991699219, 1.0\n",
      "Train loss and acc of batch 20: 47.812782287597656, 1.0\n",
      "Train loss and acc of batch 21: 48.408477783203125, 0.984375\n",
      "Train loss and acc of batch 22: 48.40846252441406, 0.984375\n",
      "Train loss and acc of batch 23: 47.81275939941406, 1.0\n",
      "Train loss and acc of batch 24: 48.408447265625, 0.984375\n",
      "Train loss and acc of batch 25: 47.812740325927734, 1.0\n",
      "Train loss and acc of batch 26: 47.8127326965332, 1.0\n",
      "Train loss and acc of batch 27: 47.812721252441406, 1.0\n",
      "Train loss and acc of batch 28: 47.81270980834961, 1.0\n",
      "Train loss and acc of batch 29: 48.408409118652344, 0.984375\n",
      "Train loss and acc of batch 30: 47.81269454956055, 1.0\n",
      "Train loss and acc of batch 31: 48.029457092285156, 0.984375\n",
      "Train loss and acc of batch 32: 47.81267166137695, 1.0\n",
      "Train loss and acc of batch 33: 47.81266403198242, 1.0\n",
      "Train loss and acc of batch 34: 48.408355712890625, 0.984375\n",
      "Train loss and acc of batch 35: 48.24618148803711, 0.96875\n",
      "Train loss and acc of batch 36: 47.81264114379883, 1.0\n",
      "Train loss and acc of batch 37: 48.56585693359375, 0.984375\n",
      "Train loss and acc of batch 38: 49.16154479980469, 0.96875\n",
      "Train loss and acc of batch 39: 48.029380798339844, 0.984375\n",
      "Train loss and acc of batch 40: 47.81260681152344, 1.0\n",
      "Train loss and acc of batch 41: 49.16151809692383, 0.96875\n",
      "Train loss and acc of batch 42: 47.81258773803711, 1.0\n",
      "Train loss and acc of batch 43: 48.40827941894531, 0.984375\n",
      "Train loss and acc of batch 44: 47.81256866455078, 1.0\n",
      "Train loss and acc of batch 45: 48.40826416015625, 0.984375\n",
      "Train loss and acc of batch 46: 48.09840393066406, 0.984375\n",
      "Train loss and acc of batch 47: 47.812538146972656, 1.0\n",
      "Train loss and acc of batch 48: 47.812538146972656, 1.0\n",
      "Train loss and acc of batch 49: 47.812522888183594, 1.0\n",
      "Train loss and acc of batch 50: 48.40821838378906, 0.984375\n",
      "Train loss and acc of batch 51: 49.16143035888672, 0.96875\n",
      "Train loss and acc of batch 52: 49.06834411621094, 0.953125\n",
      "Train loss and acc of batch 53: 47.81249237060547, 1.0\n",
      "Train loss and acc of batch 54: 48.02925109863281, 0.984375\n",
      "Train loss and acc of batch 55: 47.812469482421875, 1.0\n",
      "Train loss and acc of batch 56: 47.81246566772461, 1.0\n",
      "Train loss and acc of batch 57: 48.40815734863281, 0.984375\n",
      "Train loss and acc of batch 58: 47.81244659423828, 1.0\n",
      "Train loss and acc of batch 59: 47.812435150146484, 1.0\n",
      "Train loss and acc of batch 60: 47.81242752075195, 1.0\n",
      "Train loss and acc of batch 61: 47.812416076660156, 1.0\n",
      "Train loss and acc of batch 62: 47.812408447265625, 1.0\n",
      "Train loss and acc of batch 63: 49.00380325317383, 0.96875\n",
      "Train loss and acc of batch 64: 48.02915954589844, 0.984375\n",
      "Train loss and acc of batch 65: 47.812381744384766, 1.0\n",
      "Train loss and acc of batch 66: 47.8123779296875, 1.0\n",
      "Train loss and acc of batch 67: 48.62482833862305, 0.96875\n",
      "Train loss and acc of batch 68: 48.408058166503906, 0.984375\n",
      "Train loss and acc of batch 69: 48.02911376953125, 0.984375\n",
      "Train loss and acc of batch 70: 47.812339782714844, 1.0\n",
      "Training accuracy and loss of epoch #389: 0.9897, 48.1335\n",
      "Saved model by train loss 48.13353326287068\n",
      "Train loss and acc of batch 0: 47.81233215332031, 1.0\n",
      "Train loss and acc of batch 1: 47.81232452392578, 1.0\n",
      "Train loss and acc of batch 2: 47.812313079833984, 1.0\n",
      "Train loss and acc of batch 3: 48.029075622558594, 0.984375\n",
      "Train loss and acc of batch 4: 47.812294006347656, 1.0\n",
      "Train loss and acc of batch 5: 49.161216735839844, 0.96875\n",
      "Train loss and acc of batch 6: 48.31489562988281, 0.96875\n",
      "Train loss and acc of batch 7: 47.81226348876953, 1.0\n",
      "Train loss and acc of batch 8: 48.407958984375, 0.984375\n",
      "Train loss and acc of batch 9: 48.098106384277344, 0.984375\n",
      "Train loss and acc of batch 10: 47.81224060058594, 1.0\n",
      "Train loss and acc of batch 11: 47.81222915649414, 1.0\n",
      "Train loss and acc of batch 12: 48.56544876098633, 0.984375\n",
      "Train loss and acc of batch 13: 48.02897644042969, 0.984375\n",
      "Train loss and acc of batch 14: 48.028968811035156, 0.984375\n",
      "Train loss and acc of batch 15: 48.40790557861328, 0.984375\n",
      "Train loss and acc of batch 16: 48.40789031982422, 0.984375\n",
      "Train loss and acc of batch 17: 48.56540298461914, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 18: 48.693721771240234, 0.96875\n",
      "Train loss and acc of batch 19: 47.81216049194336, 1.0\n",
      "Train loss and acc of batch 20: 47.812156677246094, 1.0\n",
      "Train loss and acc of batch 21: 48.40784454345703, 0.984375\n",
      "Train loss and acc of batch 22: 48.4078369140625, 0.984375\n",
      "Train loss and acc of batch 23: 47.81212615966797, 1.0\n",
      "Train loss and acc of batch 24: 48.40782165527344, 0.984375\n",
      "Train loss and acc of batch 25: 47.81210708618164, 1.0\n",
      "Train loss and acc of batch 26: 47.812103271484375, 1.0\n",
      "Train loss and acc of batch 27: 47.81208801269531, 1.0\n",
      "Train loss and acc of batch 28: 47.81208419799805, 1.0\n",
      "Train loss and acc of batch 29: 48.40777587890625, 0.984375\n",
      "Train loss and acc of batch 30: 47.81206130981445, 1.0\n",
      "Train loss and acc of batch 31: 48.02882385253906, 0.984375\n",
      "Train loss and acc of batch 32: 47.81204605102539, 1.0\n",
      "Train loss and acc of batch 33: 47.812034606933594, 1.0\n",
      "Train loss and acc of batch 34: 48.40773010253906, 0.984375\n",
      "Train loss and acc of batch 35: 48.245548248291016, 0.96875\n",
      "Train loss and acc of batch 36: 47.812007904052734, 1.0\n",
      "Train loss and acc of batch 37: 48.565223693847656, 0.984375\n",
      "Train loss and acc of batch 38: 49.160911560058594, 0.96875\n",
      "Train loss and acc of batch 39: 48.02874755859375, 0.984375\n",
      "Train loss and acc of batch 40: 47.811973571777344, 1.0\n",
      "Train loss and acc of batch 41: 49.160892486572266, 0.96875\n",
      "Train loss and acc of batch 42: 47.81196212768555, 1.0\n",
      "Train loss and acc of batch 43: 48.40765380859375, 0.984375\n",
      "Train loss and acc of batch 44: 47.81193542480469, 1.0\n",
      "Train loss and acc of batch 45: 48.407630920410156, 0.984375\n",
      "Train loss and acc of batch 46: 48.0977783203125, 0.984375\n",
      "Train loss and acc of batch 47: 47.811912536621094, 1.0\n",
      "Train loss and acc of batch 48: 47.81190490722656, 1.0\n",
      "Train loss and acc of batch 49: 47.811893463134766, 1.0\n",
      "Train loss and acc of batch 50: 48.40758514404297, 0.984375\n",
      "Train loss and acc of batch 51: 49.160804748535156, 0.96875\n",
      "Train loss and acc of batch 52: 49.06770706176758, 0.953125\n",
      "Train loss and acc of batch 53: 47.811859130859375, 1.0\n",
      "Train loss and acc of batch 54: 48.02861785888672, 0.984375\n",
      "Train loss and acc of batch 55: 47.81184005737305, 1.0\n",
      "Train loss and acc of batch 56: 47.81183624267578, 1.0\n",
      "Train loss and acc of batch 57: 48.40753173828125, 0.984375\n",
      "Train loss and acc of batch 58: 47.81180953979492, 1.0\n",
      "Train loss and acc of batch 59: 47.81180953979492, 1.0\n",
      "Train loss and acc of batch 60: 47.81179428100586, 1.0\n",
      "Train loss and acc of batch 61: 47.811790466308594, 1.0\n",
      "Train loss and acc of batch 62: 47.8117790222168, 1.0\n",
      "Train loss and acc of batch 63: 49.003170013427734, 0.96875\n",
      "Train loss and acc of batch 64: 48.028526306152344, 0.984375\n",
      "Train loss and acc of batch 65: 47.81175231933594, 1.0\n",
      "Train loss and acc of batch 66: 47.81174087524414, 1.0\n",
      "Train loss and acc of batch 67: 48.62419891357422, 0.96875\n",
      "Train loss and acc of batch 68: 48.40742492675781, 0.984375\n",
      "Train loss and acc of batch 69: 48.028480529785156, 0.984375\n",
      "Train loss and acc of batch 70: 47.811710357666016, 1.0\n",
      "Training accuracy and loss of epoch #390: 0.9897, 48.1329\n",
      "Saved model by train loss 48.132902978171764\n",
      "Train loss and acc of batch 0: 47.811702728271484, 1.0\n",
      "Train loss and acc of batch 1: 47.81169128417969, 1.0\n",
      "Train loss and acc of batch 2: 47.811683654785156, 1.0\n",
      "Train loss and acc of batch 3: 48.02843475341797, 0.984375\n",
      "Train loss and acc of batch 4: 47.81166458129883, 1.0\n",
      "Train loss and acc of batch 5: 49.16058349609375, 0.96875\n",
      "Train loss and acc of batch 6: 48.31426239013672, 0.96875\n",
      "Train loss and acc of batch 7: 47.81163787841797, 1.0\n",
      "Train loss and acc of batch 8: 48.40733337402344, 0.984375\n",
      "Train loss and acc of batch 9: 48.09747314453125, 0.984375\n",
      "Train loss and acc of batch 10: 47.811607360839844, 1.0\n",
      "Train loss and acc of batch 11: 47.81160354614258, 1.0\n",
      "Train loss and acc of batch 12: 48.564815521240234, 0.984375\n",
      "Train loss and acc of batch 13: 48.028350830078125, 0.984375\n",
      "Train loss and acc of batch 14: 48.028343200683594, 0.984375\n",
      "Train loss and acc of batch 15: 48.407264709472656, 0.984375\n",
      "Train loss and acc of batch 16: 48.407257080078125, 0.984375\n",
      "Train loss and acc of batch 17: 48.56477355957031, 0.984375\n",
      "Train loss and acc of batch 18: 48.693092346191406, 0.96875\n",
      "Train loss and acc of batch 19: 47.8115348815918, 1.0\n",
      "Train loss and acc of batch 20: 47.8115234375, 1.0\n",
      "Train loss and acc of batch 21: 48.40721893310547, 0.984375\n",
      "Train loss and acc of batch 22: 48.40721130371094, 0.984375\n",
      "Train loss and acc of batch 23: 47.81149673461914, 1.0\n",
      "Train loss and acc of batch 24: 48.407188415527344, 0.984375\n",
      "Train loss and acc of batch 25: 47.81147766113281, 1.0\n",
      "Train loss and acc of batch 26: 47.811466217041016, 1.0\n",
      "Train loss and acc of batch 27: 47.81146240234375, 1.0\n",
      "Train loss and acc of batch 28: 47.81145095825195, 1.0\n",
      "Train loss and acc of batch 29: 48.407142639160156, 0.984375\n",
      "Train loss and acc of batch 30: 47.81143569946289, 1.0\n",
      "Train loss and acc of batch 31: 48.02819061279297, 0.984375\n",
      "Train loss and acc of batch 32: 47.8114128112793, 1.0\n",
      "Train loss and acc of batch 33: 47.81140899658203, 1.0\n",
      "Train loss and acc of batch 34: 48.40709686279297, 0.984375\n",
      "Train loss and acc of batch 35: 48.24491882324219, 0.96875\n",
      "Train loss and acc of batch 36: 47.81138229370117, 1.0\n",
      "Train loss and acc of batch 37: 48.56459426879883, 0.984375\n",
      "Train loss and acc of batch 38: 49.16028594970703, 0.96875\n",
      "Train loss and acc of batch 39: 48.028114318847656, 0.984375\n",
      "Train loss and acc of batch 40: 47.811344146728516, 1.0\n",
      "Train loss and acc of batch 41: 49.16026306152344, 0.96875\n",
      "Train loss and acc of batch 42: 47.81132888793945, 1.0\n",
      "Train loss and acc of batch 43: 48.407020568847656, 0.984375\n",
      "Train loss and acc of batch 44: 47.811309814453125, 1.0\n",
      "Train loss and acc of batch 45: 48.40699768066406, 0.984375\n",
      "Train loss and acc of batch 46: 48.097145080566406, 0.984375\n",
      "Train loss and acc of batch 47: 47.811283111572266, 1.0\n",
      "Train loss and acc of batch 48: 47.811275482177734, 1.0\n",
      "Train loss and acc of batch 49: 47.81126403808594, 1.0\n",
      "Train loss and acc of batch 50: 48.406959533691406, 0.984375\n",
      "Train loss and acc of batch 51: 49.16016387939453, 0.96875\n",
      "Train loss and acc of batch 52: 49.067081451416016, 0.953125\n",
      "Train loss and acc of batch 53: 47.81122970581055, 1.0\n",
      "Train loss and acc of batch 54: 48.027984619140625, 0.984375\n",
      "Train loss and acc of batch 55: 47.811214447021484, 1.0\n",
      "Train loss and acc of batch 56: 47.81120300292969, 1.0\n",
      "Train loss and acc of batch 57: 48.406890869140625, 0.984375\n",
      "Train loss and acc of batch 58: 47.811187744140625, 1.0\n",
      "Train loss and acc of batch 59: 47.81117630004883, 1.0\n",
      "Train loss and acc of batch 60: 47.81116485595703, 1.0\n",
      "Train loss and acc of batch 61: 47.8111572265625, 1.0\n",
      "Train loss and acc of batch 62: 47.811153411865234, 1.0\n",
      "Train loss and acc of batch 63: 49.002540588378906, 0.96875\n",
      "Train loss and acc of batch 64: 48.02790069580078, 0.984375\n",
      "Train loss and acc of batch 65: 47.811119079589844, 1.0\n",
      "Train loss and acc of batch 66: 47.81110763549805, 1.0\n",
      "Train loss and acc of batch 67: 48.62356948852539, 0.96875\n",
      "Train loss and acc of batch 68: 48.40679168701172, 0.984375\n",
      "Train loss and acc of batch 69: 48.02784729003906, 0.984375\n",
      "Train loss and acc of batch 70: 47.81108474731445, 1.0\n",
      "Training accuracy and loss of epoch #391: 0.9897, 48.1323\n",
      "Saved model by train loss 48.13227253228846\n",
      "Train loss and acc of batch 0: 47.811065673828125, 1.0\n",
      "Train loss and acc of batch 1: 47.81106185913086, 1.0\n",
      "Train loss and acc of batch 2: 47.81105422973633, 1.0\n",
      "Train loss and acc of batch 3: 48.027801513671875, 0.984375\n",
      "Train loss and acc of batch 4: 47.811031341552734, 1.0\n",
      "Train loss and acc of batch 5: 49.159942626953125, 0.96875\n",
      "Train loss and acc of batch 6: 48.31363296508789, 0.96875\n",
      "Train loss and acc of batch 7: 47.811012268066406, 1.0\n",
      "Train loss and acc of batch 8: 48.406700134277344, 0.984375\n",
      "Train loss and acc of batch 9: 48.096839904785156, 0.984375\n",
      "Train loss and acc of batch 10: 47.81098175048828, 1.0\n",
      "Train loss and acc of batch 11: 47.81096649169922, 1.0\n",
      "Train loss and acc of batch 12: 48.564186096191406, 0.984375\n",
      "Train loss and acc of batch 13: 48.02771759033203, 0.984375\n",
      "Train loss and acc of batch 14: 48.0277099609375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 15: 48.406639099121094, 0.984375\n",
      "Train loss and acc of batch 16: 48.40663146972656, 0.984375\n",
      "Train loss and acc of batch 17: 48.56414031982422, 0.984375\n",
      "Train loss and acc of batch 18: 48.69246292114258, 0.96875\n",
      "Train loss and acc of batch 19: 47.81089401245117, 1.0\n",
      "Train loss and acc of batch 20: 47.810890197753906, 1.0\n",
      "Train loss and acc of batch 21: 48.406585693359375, 0.984375\n",
      "Train loss and acc of batch 22: 48.40657043457031, 0.984375\n",
      "Train loss and acc of batch 23: 47.81086349487305, 1.0\n",
      "Train loss and acc of batch 24: 48.40656280517578, 0.984375\n",
      "Train loss and acc of batch 25: 47.81084442138672, 1.0\n",
      "Train loss and acc of batch 26: 47.81084060668945, 1.0\n",
      "Train loss and acc of batch 27: 47.810829162597656, 1.0\n",
      "Train loss and acc of batch 28: 47.81081771850586, 1.0\n",
      "Train loss and acc of batch 29: 48.40650939941406, 0.984375\n",
      "Train loss and acc of batch 30: 47.81080627441406, 1.0\n",
      "Train loss and acc of batch 31: 48.027557373046875, 0.984375\n",
      "Train loss and acc of batch 32: 47.81078338623047, 1.0\n",
      "Train loss and acc of batch 33: 47.810768127441406, 1.0\n",
      "Train loss and acc of batch 34: 48.406463623046875, 0.984375\n",
      "Train loss and acc of batch 35: 48.244285583496094, 0.96875\n",
      "Train loss and acc of batch 36: 47.81074905395508, 1.0\n",
      "Train loss and acc of batch 37: 48.563961029052734, 0.984375\n",
      "Train loss and acc of batch 38: 49.15966033935547, 0.96875\n",
      "Train loss and acc of batch 39: 48.027488708496094, 0.984375\n",
      "Train loss and acc of batch 40: 47.81071472167969, 1.0\n",
      "Train loss and acc of batch 41: 49.159629821777344, 0.96875\n",
      "Train loss and acc of batch 42: 47.810691833496094, 1.0\n",
      "Train loss and acc of batch 43: 48.40638732910156, 0.984375\n",
      "Train loss and acc of batch 44: 47.81067657470703, 1.0\n",
      "Train loss and acc of batch 45: 48.4063720703125, 0.984375\n",
      "Train loss and acc of batch 46: 48.09651184082031, 0.984375\n",
      "Train loss and acc of batch 47: 47.81065368652344, 1.0\n",
      "Train loss and acc of batch 48: 47.810638427734375, 1.0\n",
      "Train loss and acc of batch 49: 47.81063461303711, 1.0\n",
      "Train loss and acc of batch 50: 48.40631866455078, 0.984375\n",
      "Train loss and acc of batch 51: 49.15953826904297, 0.96875\n",
      "Train loss and acc of batch 52: 49.06644821166992, 0.953125\n",
      "Train loss and acc of batch 53: 47.81060028076172, 1.0\n",
      "Train loss and acc of batch 54: 48.02735137939453, 0.984375\n",
      "Train loss and acc of batch 55: 47.81058120727539, 1.0\n",
      "Train loss and acc of batch 56: 47.81056594848633, 1.0\n",
      "Train loss and acc of batch 57: 48.40626525878906, 0.984375\n",
      "Train loss and acc of batch 58: 47.81055450439453, 1.0\n",
      "Train loss and acc of batch 59: 47.810546875, 1.0\n",
      "Train loss and acc of batch 60: 47.8105354309082, 1.0\n",
      "Train loss and acc of batch 61: 47.81052780151367, 1.0\n",
      "Train loss and acc of batch 62: 47.81051254272461, 1.0\n",
      "Train loss and acc of batch 63: 49.001914978027344, 0.96875\n",
      "Train loss and acc of batch 64: 48.027259826660156, 0.984375\n",
      "Train loss and acc of batch 65: 47.810489654541016, 1.0\n",
      "Train loss and acc of batch 66: 47.810482025146484, 1.0\n",
      "Train loss and acc of batch 67: 48.6229362487793, 0.96875\n",
      "Train loss and acc of batch 68: 48.406166076660156, 0.984375\n",
      "Train loss and acc of batch 69: 48.0272216796875, 0.984375\n",
      "Train loss and acc of batch 70: 47.81044387817383, 1.0\n",
      "Training accuracy and loss of epoch #392: 0.9897, 48.1316\n",
      "Saved model by train loss 48.131640582017496\n",
      "Train loss and acc of batch 0: 47.8104362487793, 1.0\n",
      "Train loss and acc of batch 1: 47.810428619384766, 1.0\n",
      "Train loss and acc of batch 2: 47.810420989990234, 1.0\n",
      "Train loss and acc of batch 3: 48.02717590332031, 0.984375\n",
      "Train loss and acc of batch 4: 47.81040573120117, 1.0\n",
      "Train loss and acc of batch 5: 49.15931701660156, 0.96875\n",
      "Train loss and acc of batch 6: 48.31300354003906, 0.96875\n",
      "Train loss and acc of batch 7: 47.810367584228516, 1.0\n",
      "Train loss and acc of batch 8: 48.40606689453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.096214294433594, 0.984375\n",
      "Train loss and acc of batch 10: 47.81034469604492, 1.0\n",
      "Train loss and acc of batch 11: 47.810340881347656, 1.0\n",
      "Train loss and acc of batch 12: 48.56355667114258, 0.984375\n",
      "Train loss and acc of batch 13: 48.02708435058594, 0.984375\n",
      "Train loss and acc of batch 14: 48.027076721191406, 0.984375\n",
      "Train loss and acc of batch 15: 48.406005859375, 0.984375\n",
      "Train loss and acc of batch 16: 48.40599822998047, 0.984375\n",
      "Train loss and acc of batch 17: 48.563514709472656, 0.984375\n",
      "Train loss and acc of batch 18: 48.691829681396484, 0.96875\n",
      "Train loss and acc of batch 19: 47.810272216796875, 1.0\n",
      "Train loss and acc of batch 20: 47.81026077270508, 1.0\n",
      "Train loss and acc of batch 21: 48.40595245361328, 0.984375\n",
      "Train loss and acc of batch 22: 48.40593719482422, 0.984375\n",
      "Train loss and acc of batch 23: 47.81023406982422, 1.0\n",
      "Train loss and acc of batch 24: 48.40592956542969, 0.984375\n",
      "Train loss and acc of batch 25: 47.810218811035156, 1.0\n",
      "Train loss and acc of batch 26: 47.81020736694336, 1.0\n",
      "Train loss and acc of batch 27: 47.81019592285156, 1.0\n",
      "Train loss and acc of batch 28: 47.81018829345703, 1.0\n",
      "Train loss and acc of batch 29: 48.4058837890625, 0.984375\n",
      "Train loss and acc of batch 30: 47.8101692199707, 1.0\n",
      "Train loss and acc of batch 31: 48.02693176269531, 0.984375\n",
      "Train loss and acc of batch 32: 47.81015396118164, 1.0\n",
      "Train loss and acc of batch 33: 47.81014633178711, 1.0\n",
      "Train loss and acc of batch 34: 48.40583801269531, 0.984375\n",
      "Train loss and acc of batch 35: 48.24364471435547, 0.96875\n",
      "Train loss and acc of batch 36: 47.810115814208984, 1.0\n",
      "Train loss and acc of batch 37: 48.563331604003906, 0.984375\n",
      "Train loss and acc of batch 38: 49.159027099609375, 0.96875\n",
      "Train loss and acc of batch 39: 48.02685546875, 0.984375\n",
      "Train loss and acc of batch 40: 47.810081481933594, 1.0\n",
      "Train loss and acc of batch 41: 49.15899658203125, 0.96875\n",
      "Train loss and acc of batch 42: 47.81006622314453, 1.0\n",
      "Train loss and acc of batch 43: 48.40575408935547, 0.984375\n",
      "Train loss and acc of batch 44: 47.8100471496582, 1.0\n",
      "Train loss and acc of batch 45: 48.405738830566406, 0.984375\n",
      "Train loss and acc of batch 46: 48.09588623046875, 0.984375\n",
      "Train loss and acc of batch 47: 47.81001663208008, 1.0\n",
      "Train loss and acc of batch 48: 47.81001281738281, 1.0\n",
      "Train loss and acc of batch 49: 47.80999755859375, 1.0\n",
      "Train loss and acc of batch 50: 48.40569305419922, 0.984375\n",
      "Train loss and acc of batch 51: 49.158905029296875, 0.96875\n",
      "Train loss and acc of batch 52: 49.0658073425293, 0.953125\n",
      "Train loss and acc of batch 53: 47.80996322631836, 1.0\n",
      "Train loss and acc of batch 54: 48.02671813964844, 0.984375\n",
      "Train loss and acc of batch 55: 47.80994415283203, 1.0\n",
      "Train loss and acc of batch 56: 47.8099365234375, 1.0\n",
      "Train loss and acc of batch 57: 48.40562438964844, 0.984375\n",
      "Train loss and acc of batch 58: 47.80991744995117, 1.0\n",
      "Train loss and acc of batch 59: 47.80990982055664, 1.0\n",
      "Train loss and acc of batch 60: 47.80990219116211, 1.0\n",
      "Train loss and acc of batch 61: 47.80989074707031, 1.0\n",
      "Train loss and acc of batch 62: 47.80989074707031, 1.0\n",
      "Train loss and acc of batch 63: 49.001277923583984, 0.96875\n",
      "Train loss and acc of batch 64: 48.02662658691406, 0.984375\n",
      "Train loss and acc of batch 65: 47.80985641479492, 1.0\n",
      "Train loss and acc of batch 66: 47.809844970703125, 1.0\n",
      "Train loss and acc of batch 67: 48.62230682373047, 0.96875\n",
      "Train loss and acc of batch 68: 48.40553283691406, 0.984375\n",
      "Train loss and acc of batch 69: 48.026580810546875, 0.984375\n",
      "Train loss and acc of batch 70: 47.809810638427734, 1.0\n",
      "Training accuracy and loss of epoch #393: 0.9897, 48.1310\n",
      "Saved model by train loss 48.1310087392028\n",
      "Train loss and acc of batch 0: 47.8098030090332, 1.0\n",
      "Train loss and acc of batch 1: 47.809791564941406, 1.0\n",
      "Train loss and acc of batch 2: 47.80978775024414, 1.0\n",
      "Train loss and acc of batch 3: 48.02653503417969, 0.984375\n",
      "Train loss and acc of batch 4: 47.80976867675781, 1.0\n",
      "Train loss and acc of batch 5: 49.15869140625, 0.96875\n",
      "Train loss and acc of batch 6: 48.31237030029297, 0.96875\n",
      "Train loss and acc of batch 7: 47.80973815917969, 1.0\n",
      "Train loss and acc of batch 8: 48.405433654785156, 0.984375\n",
      "Train loss and acc of batch 9: 48.09557342529297, 0.984375\n",
      "Train loss and acc of batch 10: 47.809715270996094, 1.0\n",
      "Train loss and acc of batch 11: 47.8097038269043, 1.0\n",
      "Train loss and acc of batch 12: 48.56291961669922, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 13: 48.026451110839844, 0.984375\n",
      "Train loss and acc of batch 14: 48.02644348144531, 0.984375\n",
      "Train loss and acc of batch 15: 48.405364990234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.405364990234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.56287384033203, 0.984375\n",
      "Train loss and acc of batch 18: 48.69119644165039, 0.96875\n",
      "Train loss and acc of batch 19: 47.80963897705078, 1.0\n",
      "Train loss and acc of batch 20: 47.80962371826172, 1.0\n",
      "Train loss and acc of batch 21: 48.40531921386719, 0.984375\n",
      "Train loss and acc of batch 22: 48.405311584472656, 0.984375\n",
      "Train loss and acc of batch 23: 47.80959701538086, 1.0\n",
      "Train loss and acc of batch 24: 48.40528869628906, 0.984375\n",
      "Train loss and acc of batch 25: 47.8095817565918, 1.0\n",
      "Train loss and acc of batch 26: 47.809574127197266, 1.0\n",
      "Train loss and acc of batch 27: 47.80956268310547, 1.0\n",
      "Train loss and acc of batch 28: 47.80955505371094, 1.0\n",
      "Train loss and acc of batch 29: 48.405242919921875, 0.984375\n",
      "Train loss and acc of batch 30: 47.80953598022461, 1.0\n",
      "Train loss and acc of batch 31: 48.02629089355469, 0.984375\n",
      "Train loss and acc of batch 32: 47.80951690673828, 1.0\n",
      "Train loss and acc of batch 33: 47.809513092041016, 1.0\n",
      "Train loss and acc of batch 34: 48.40520477294922, 0.984375\n",
      "Train loss and acc of batch 35: 48.24302291870117, 0.96875\n",
      "Train loss and acc of batch 36: 47.80948257446289, 1.0\n",
      "Train loss and acc of batch 37: 48.56269836425781, 0.984375\n",
      "Train loss and acc of batch 38: 49.15838623046875, 0.96875\n",
      "Train loss and acc of batch 39: 48.026222229003906, 0.984375\n",
      "Train loss and acc of batch 40: 47.8094482421875, 1.0\n",
      "Train loss and acc of batch 41: 49.15836715698242, 0.96875\n",
      "Train loss and acc of batch 42: 47.8094367980957, 1.0\n",
      "Train loss and acc of batch 43: 48.405120849609375, 0.984375\n",
      "Train loss and acc of batch 44: 47.809410095214844, 1.0\n",
      "Train loss and acc of batch 45: 48.40510559082031, 0.984375\n",
      "Train loss and acc of batch 46: 48.095245361328125, 0.984375\n",
      "Train loss and acc of batch 47: 47.809391021728516, 1.0\n",
      "Train loss and acc of batch 48: 47.80937194824219, 1.0\n",
      "Train loss and acc of batch 49: 47.80936813354492, 1.0\n",
      "Train loss and acc of batch 50: 48.405059814453125, 0.984375\n",
      "Train loss and acc of batch 51: 49.15827941894531, 0.96875\n",
      "Train loss and acc of batch 52: 49.06517791748047, 0.953125\n",
      "Train loss and acc of batch 53: 47.80933380126953, 1.0\n",
      "Train loss and acc of batch 54: 48.026084899902344, 0.984375\n",
      "Train loss and acc of batch 55: 47.8093147277832, 1.0\n",
      "Train loss and acc of batch 56: 47.80931091308594, 1.0\n",
      "Train loss and acc of batch 57: 48.404991149902344, 0.984375\n",
      "Train loss and acc of batch 58: 47.809288024902344, 1.0\n",
      "Train loss and acc of batch 59: 47.80928421020508, 1.0\n",
      "Train loss and acc of batch 60: 47.809268951416016, 1.0\n",
      "Train loss and acc of batch 61: 47.80926513671875, 1.0\n",
      "Train loss and acc of batch 62: 47.80925369262695, 1.0\n",
      "Train loss and acc of batch 63: 49.00064468383789, 0.96875\n",
      "Train loss and acc of batch 64: 48.0260009765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.80922317504883, 1.0\n",
      "Train loss and acc of batch 66: 47.80921936035156, 1.0\n",
      "Train loss and acc of batch 67: 48.621673583984375, 0.96875\n",
      "Train loss and acc of batch 68: 48.40489959716797, 0.984375\n",
      "Train loss and acc of batch 69: 48.02595520019531, 0.984375\n",
      "Train loss and acc of batch 70: 47.80918502807617, 1.0\n",
      "Training accuracy and loss of epoch #394: 0.9897, 48.1304\n",
      "Saved model by train loss 48.13037571436922\n",
      "Train loss and acc of batch 0: 47.80916976928711, 1.0\n",
      "Train loss and acc of batch 1: 47.80916213989258, 1.0\n",
      "Train loss and acc of batch 2: 47.80915832519531, 1.0\n",
      "Train loss and acc of batch 3: 48.025909423828125, 0.984375\n",
      "Train loss and acc of batch 4: 47.809139251708984, 1.0\n",
      "Train loss and acc of batch 5: 49.158050537109375, 0.96875\n",
      "Train loss and acc of batch 6: 48.31173324584961, 0.96875\n",
      "Train loss and acc of batch 7: 47.809112548828125, 1.0\n",
      "Train loss and acc of batch 8: 48.404808044433594, 0.984375\n",
      "Train loss and acc of batch 9: 48.094940185546875, 0.984375\n",
      "Train loss and acc of batch 10: 47.809085845947266, 1.0\n",
      "Train loss and acc of batch 11: 47.80907440185547, 1.0\n",
      "Train loss and acc of batch 12: 48.56229019165039, 0.984375\n",
      "Train loss and acc of batch 13: 48.02582550048828, 0.984375\n",
      "Train loss and acc of batch 14: 48.02581024169922, 0.984375\n",
      "Train loss and acc of batch 15: 48.40473937988281, 0.984375\n",
      "Train loss and acc of batch 16: 48.40473175048828, 0.984375\n",
      "Train loss and acc of batch 17: 48.56224060058594, 0.984375\n",
      "Train loss and acc of batch 18: 48.69056701660156, 0.96875\n",
      "Train loss and acc of batch 19: 47.80900573730469, 1.0\n",
      "Train loss and acc of batch 20: 47.80899429321289, 1.0\n",
      "Train loss and acc of batch 21: 48.404693603515625, 0.984375\n",
      "Train loss and acc of batch 22: 48.40467834472656, 0.984375\n",
      "Train loss and acc of batch 23: 47.808963775634766, 1.0\n",
      "Train loss and acc of batch 24: 48.4046630859375, 0.984375\n",
      "Train loss and acc of batch 25: 47.80894470214844, 1.0\n",
      "Train loss and acc of batch 26: 47.80894088745117, 1.0\n",
      "Train loss and acc of batch 27: 47.80894088745117, 1.0\n",
      "Train loss and acc of batch 28: 47.80892562866211, 1.0\n",
      "Train loss and acc of batch 29: 48.40461730957031, 0.984375\n",
      "Train loss and acc of batch 30: 47.80891036987305, 1.0\n",
      "Train loss and acc of batch 31: 48.025657653808594, 0.984375\n",
      "Train loss and acc of batch 32: 47.80889129638672, 1.0\n",
      "Train loss and acc of batch 33: 47.808876037597656, 1.0\n",
      "Train loss and acc of batch 34: 48.404571533203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.242393493652344, 0.96875\n",
      "Train loss and acc of batch 36: 47.80885314941406, 1.0\n",
      "Train loss and acc of batch 37: 48.56206512451172, 0.984375\n",
      "Train loss and acc of batch 38: 49.15776062011719, 0.96875\n",
      "Train loss and acc of batch 39: 48.02558898925781, 0.984375\n",
      "Train loss and acc of batch 40: 47.80881881713867, 1.0\n",
      "Train loss and acc of batch 41: 49.15774154663086, 0.96875\n",
      "Train loss and acc of batch 42: 47.80879592895508, 1.0\n",
      "Train loss and acc of batch 43: 48.40449523925781, 0.984375\n",
      "Train loss and acc of batch 44: 47.80878448486328, 1.0\n",
      "Train loss and acc of batch 45: 48.40447235107422, 0.984375\n",
      "Train loss and acc of batch 46: 48.09461975097656, 0.984375\n",
      "Train loss and acc of batch 47: 47.80875015258789, 1.0\n",
      "Train loss and acc of batch 48: 47.80874252319336, 1.0\n",
      "Train loss and acc of batch 49: 47.808738708496094, 1.0\n",
      "Train loss and acc of batch 50: 48.40442657470703, 0.984375\n",
      "Train loss and acc of batch 51: 49.15763854980469, 0.96875\n",
      "Train loss and acc of batch 52: 49.064552307128906, 0.953125\n",
      "Train loss and acc of batch 53: 47.80870056152344, 1.0\n",
      "Train loss and acc of batch 54: 48.02545928955078, 0.984375\n",
      "Train loss and acc of batch 55: 47.80868911743164, 1.0\n",
      "Train loss and acc of batch 56: 47.808677673339844, 1.0\n",
      "Train loss and acc of batch 57: 48.40436553955078, 0.984375\n",
      "Train loss and acc of batch 58: 47.80866241455078, 1.0\n",
      "Train loss and acc of batch 59: 47.80864715576172, 1.0\n",
      "Train loss and acc of batch 60: 47.80864334106445, 1.0\n",
      "Train loss and acc of batch 61: 47.80862808227539, 1.0\n",
      "Train loss and acc of batch 62: 47.808616638183594, 1.0\n",
      "Train loss and acc of batch 63: 49.00001525878906, 0.96875\n",
      "Train loss and acc of batch 64: 48.025367736816406, 0.984375\n",
      "Train loss and acc of batch 65: 47.80859375, 1.0\n",
      "Train loss and acc of batch 66: 47.80858612060547, 1.0\n",
      "Train loss and acc of batch 67: 48.62104034423828, 0.96875\n",
      "Train loss and acc of batch 68: 48.404266357421875, 0.984375\n",
      "Train loss and acc of batch 69: 48.02532958984375, 0.984375\n",
      "Train loss and acc of batch 70: 47.80855178833008, 1.0\n",
      "Training accuracy and loss of epoch #395: 0.9897, 48.1297\n",
      "Saved model by train loss 48.129745107301524\n",
      "Train loss and acc of batch 0: 47.80854415893555, 1.0\n",
      "Train loss and acc of batch 1: 47.808536529541016, 1.0\n",
      "Train loss and acc of batch 2: 47.80852508544922, 1.0\n",
      "Train loss and acc of batch 3: 48.02528381347656, 0.984375\n",
      "Train loss and acc of batch 4: 47.808509826660156, 1.0\n",
      "Train loss and acc of batch 5: 49.15741729736328, 0.96875\n",
      "Train loss and acc of batch 6: 48.31110763549805, 0.96875\n",
      "Train loss and acc of batch 7: 47.8084831237793, 1.0\n",
      "Train loss and acc of batch 8: 48.40416717529297, 0.984375\n",
      "Train loss and acc of batch 9: 48.09431457519531, 0.984375\n",
      "Train loss and acc of batch 10: 47.808448791503906, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 11: 47.808441162109375, 1.0\n",
      "Train loss and acc of batch 12: 48.56166458129883, 0.984375\n",
      "Train loss and acc of batch 13: 48.02519226074219, 0.984375\n",
      "Train loss and acc of batch 14: 48.025184631347656, 0.984375\n",
      "Train loss and acc of batch 15: 48.40411376953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.40409851074219, 0.984375\n",
      "Train loss and acc of batch 17: 48.561614990234375, 0.984375\n",
      "Train loss and acc of batch 18: 48.689937591552734, 0.96875\n",
      "Train loss and acc of batch 19: 47.808372497558594, 1.0\n",
      "Train loss and acc of batch 20: 47.80836868286133, 1.0\n",
      "Train loss and acc of batch 21: 48.404052734375, 0.984375\n",
      "Train loss and acc of batch 22: 48.404052734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.8083381652832, 1.0\n",
      "Train loss and acc of batch 24: 48.404022216796875, 0.984375\n",
      "Train loss and acc of batch 25: 47.808319091796875, 1.0\n",
      "Train loss and acc of batch 26: 47.80831527709961, 1.0\n",
      "Train loss and acc of batch 27: 47.80830001831055, 1.0\n",
      "Train loss and acc of batch 28: 47.808292388916016, 1.0\n",
      "Train loss and acc of batch 29: 48.40398406982422, 0.984375\n",
      "Train loss and acc of batch 30: 47.80827713012695, 1.0\n",
      "Train loss and acc of batch 31: 48.02503204345703, 0.984375\n",
      "Train loss and acc of batch 32: 47.808258056640625, 1.0\n",
      "Train loss and acc of batch 33: 47.80824661254883, 1.0\n",
      "Train loss and acc of batch 34: 48.40394592285156, 0.984375\n",
      "Train loss and acc of batch 35: 48.24176025390625, 0.96875\n",
      "Train loss and acc of batch 36: 47.808223724365234, 1.0\n",
      "Train loss and acc of batch 37: 48.561439514160156, 0.984375\n",
      "Train loss and acc of batch 38: 49.15711975097656, 0.96875\n",
      "Train loss and acc of batch 39: 48.02495574951172, 0.984375\n",
      "Train loss and acc of batch 40: 47.808189392089844, 1.0\n",
      "Train loss and acc of batch 41: 49.1571044921875, 0.96875\n",
      "Train loss and acc of batch 42: 47.80816650390625, 1.0\n",
      "Train loss and acc of batch 43: 48.40386199951172, 0.984375\n",
      "Train loss and acc of batch 44: 47.80815124511719, 1.0\n",
      "Train loss and acc of batch 45: 48.403846740722656, 0.984375\n",
      "Train loss and acc of batch 46: 48.09398651123047, 0.984375\n",
      "Train loss and acc of batch 47: 47.80812454223633, 1.0\n",
      "Train loss and acc of batch 48: 47.8081169128418, 1.0\n",
      "Train loss and acc of batch 49: 47.80811309814453, 1.0\n",
      "Train loss and acc of batch 50: 48.40379333496094, 0.984375\n",
      "Train loss and acc of batch 51: 49.157012939453125, 0.96875\n",
      "Train loss and acc of batch 52: 49.06391906738281, 0.953125\n",
      "Train loss and acc of batch 53: 47.808074951171875, 1.0\n",
      "Train loss and acc of batch 54: 48.02483367919922, 0.984375\n",
      "Train loss and acc of batch 55: 47.808048248291016, 1.0\n",
      "Train loss and acc of batch 56: 47.80804443359375, 1.0\n",
      "Train loss and acc of batch 57: 48.40373992919922, 0.984375\n",
      "Train loss and acc of batch 58: 47.80802536010742, 1.0\n",
      "Train loss and acc of batch 59: 47.80801773071289, 1.0\n",
      "Train loss and acc of batch 60: 47.80801010131836, 1.0\n",
      "Train loss and acc of batch 61: 47.80799865722656, 1.0\n",
      "Train loss and acc of batch 62: 47.80799102783203, 1.0\n",
      "Train loss and acc of batch 63: 48.999385833740234, 0.96875\n",
      "Train loss and acc of batch 64: 48.02473449707031, 0.984375\n",
      "Train loss and acc of batch 65: 47.80796813964844, 1.0\n",
      "Train loss and acc of batch 66: 47.80795669555664, 1.0\n",
      "Train loss and acc of batch 67: 48.62041091918945, 0.96875\n",
      "Train loss and acc of batch 68: 48.40364074707031, 0.984375\n",
      "Train loss and acc of batch 69: 48.024688720703125, 0.984375\n",
      "Train loss and acc of batch 70: 47.807918548583984, 1.0\n",
      "Training accuracy and loss of epoch #396: 0.9897, 48.1291\n",
      "Saved model by train loss 48.129114607690084\n",
      "Train loss and acc of batch 0: 47.80791091918945, 1.0\n",
      "Train loss and acc of batch 1: 47.807899475097656, 1.0\n",
      "Train loss and acc of batch 2: 47.80789566040039, 1.0\n",
      "Train loss and acc of batch 3: 48.02465057373047, 0.984375\n",
      "Train loss and acc of batch 4: 47.8078727722168, 1.0\n",
      "Train loss and acc of batch 5: 49.15679168701172, 0.96875\n",
      "Train loss and acc of batch 6: 48.31047821044922, 0.96875\n",
      "Train loss and acc of batch 7: 47.80784606933594, 1.0\n",
      "Train loss and acc of batch 8: 48.403541564941406, 0.984375\n",
      "Train loss and acc of batch 9: 48.09368896484375, 0.984375\n",
      "Train loss and acc of batch 10: 47.80781936645508, 1.0\n",
      "Train loss and acc of batch 11: 47.80781936645508, 1.0\n",
      "Train loss and acc of batch 12: 48.56102752685547, 0.984375\n",
      "Train loss and acc of batch 13: 48.024559020996094, 0.984375\n",
      "Train loss and acc of batch 14: 48.02455139160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.403480529785156, 0.984375\n",
      "Train loss and acc of batch 16: 48.403465270996094, 0.984375\n",
      "Train loss and acc of batch 17: 48.56098556518555, 0.984375\n",
      "Train loss and acc of batch 18: 48.68930435180664, 0.96875\n",
      "Train loss and acc of batch 19: 47.807743072509766, 1.0\n",
      "Train loss and acc of batch 20: 47.807735443115234, 1.0\n",
      "Train loss and acc of batch 21: 48.40342712402344, 0.984375\n",
      "Train loss and acc of batch 22: 48.403419494628906, 0.984375\n",
      "Train loss and acc of batch 23: 47.80770492553711, 1.0\n",
      "Train loss and acc of batch 24: 48.40339660644531, 0.984375\n",
      "Train loss and acc of batch 25: 47.80769348144531, 1.0\n",
      "Train loss and acc of batch 26: 47.80767822265625, 1.0\n",
      "Train loss and acc of batch 27: 47.80766677856445, 1.0\n",
      "Train loss and acc of batch 28: 47.80766296386719, 1.0\n",
      "Train loss and acc of batch 29: 48.403350830078125, 0.984375\n",
      "Train loss and acc of batch 30: 47.80764389038086, 1.0\n",
      "Train loss and acc of batch 31: 48.02440643310547, 0.984375\n",
      "Train loss and acc of batch 32: 47.8076286315918, 1.0\n",
      "Train loss and acc of batch 33: 47.807621002197266, 1.0\n",
      "Train loss and acc of batch 34: 48.40331268310547, 0.984375\n",
      "Train loss and acc of batch 35: 48.24112319946289, 0.96875\n",
      "Train loss and acc of batch 36: 47.807594299316406, 1.0\n",
      "Train loss and acc of batch 37: 48.56080627441406, 0.984375\n",
      "Train loss and acc of batch 38: 49.15650177001953, 0.96875\n",
      "Train loss and acc of batch 39: 48.024330139160156, 0.984375\n",
      "Train loss and acc of batch 40: 47.80755615234375, 1.0\n",
      "Train loss and acc of batch 41: 49.15647506713867, 0.96875\n",
      "Train loss and acc of batch 42: 47.80754089355469, 1.0\n",
      "Train loss and acc of batch 43: 48.403228759765625, 0.984375\n",
      "Train loss and acc of batch 44: 47.807518005371094, 1.0\n",
      "Train loss and acc of batch 45: 48.40321350097656, 0.984375\n",
      "Train loss and acc of batch 46: 48.093353271484375, 0.984375\n",
      "Train loss and acc of batch 47: 47.8074951171875, 1.0\n",
      "Train loss and acc of batch 48: 47.807491302490234, 1.0\n",
      "Train loss and acc of batch 49: 47.807472229003906, 1.0\n",
      "Train loss and acc of batch 50: 48.403167724609375, 0.984375\n",
      "Train loss and acc of batch 51: 49.15638732910156, 0.96875\n",
      "Train loss and acc of batch 52: 49.06329345703125, 0.953125\n",
      "Train loss and acc of batch 53: 47.80744171142578, 1.0\n",
      "Train loss and acc of batch 54: 48.024200439453125, 0.984375\n",
      "Train loss and acc of batch 55: 47.80742263793945, 1.0\n",
      "Train loss and acc of batch 56: 47.80741882324219, 1.0\n",
      "Train loss and acc of batch 57: 48.403106689453125, 0.984375\n",
      "Train loss and acc of batch 58: 47.80739212036133, 1.0\n",
      "Train loss and acc of batch 59: 47.80738830566406, 1.0\n",
      "Train loss and acc of batch 60: 47.807376861572266, 1.0\n",
      "Train loss and acc of batch 61: 47.807369232177734, 1.0\n",
      "Train loss and acc of batch 62: 47.80736541748047, 1.0\n",
      "Train loss and acc of batch 63: 48.99875259399414, 0.96875\n",
      "Train loss and acc of batch 64: 48.02410888671875, 0.984375\n",
      "Train loss and acc of batch 65: 47.807334899902344, 1.0\n",
      "Train loss and acc of batch 66: 47.80732727050781, 1.0\n",
      "Train loss and acc of batch 67: 48.619781494140625, 0.96875\n",
      "Train loss and acc of batch 68: 48.40300750732422, 0.984375\n",
      "Train loss and acc of batch 69: 48.02406311035156, 0.984375\n",
      "Train loss and acc of batch 70: 47.80729293823242, 1.0\n",
      "Training accuracy and loss of epoch #397: 0.9897, 48.1285\n",
      "Saved model by train loss 48.12848421553491\n",
      "Train loss and acc of batch 0: 47.80727767944336, 1.0\n",
      "Train loss and acc of batch 1: 47.80727005004883, 1.0\n",
      "Train loss and acc of batch 2: 47.80726623535156, 1.0\n",
      "Train loss and acc of batch 3: 48.024017333984375, 0.984375\n",
      "Train loss and acc of batch 4: 47.807247161865234, 1.0\n",
      "Train loss and acc of batch 5: 49.156158447265625, 0.96875\n",
      "Train loss and acc of batch 6: 48.309844970703125, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 7: 47.80721664428711, 1.0\n",
      "Train loss and acc of batch 8: 48.402915954589844, 0.984375\n",
      "Train loss and acc of batch 9: 48.093055725097656, 0.984375\n",
      "Train loss and acc of batch 10: 47.807193756103516, 1.0\n",
      "Train loss and acc of batch 11: 47.80718231201172, 1.0\n",
      "Train loss and acc of batch 12: 48.56039810180664, 0.984375\n",
      "Train loss and acc of batch 13: 48.02393341064453, 0.984375\n",
      "Train loss and acc of batch 14: 48.02391815185547, 0.984375\n",
      "Train loss and acc of batch 15: 48.40284729003906, 0.984375\n",
      "Train loss and acc of batch 16: 48.40283966064453, 0.984375\n",
      "Train loss and acc of batch 17: 48.56034851074219, 0.984375\n",
      "Train loss and acc of batch 18: 48.68867492675781, 0.96875\n",
      "Train loss and acc of batch 19: 47.80711364746094, 1.0\n",
      "Train loss and acc of batch 20: 47.80710220336914, 1.0\n",
      "Train loss and acc of batch 21: 48.402793884277344, 0.984375\n",
      "Train loss and acc of batch 22: 48.40278625488281, 0.984375\n",
      "Train loss and acc of batch 23: 47.80707550048828, 1.0\n",
      "Train loss and acc of batch 24: 48.40277099609375, 0.984375\n",
      "Train loss and acc of batch 25: 47.80705642700195, 1.0\n",
      "Train loss and acc of batch 26: 47.80704879760742, 1.0\n",
      "Train loss and acc of batch 27: 47.80704116821289, 1.0\n",
      "Train loss and acc of batch 28: 47.80703353881836, 1.0\n",
      "Train loss and acc of batch 29: 48.40271759033203, 0.984375\n",
      "Train loss and acc of batch 30: 47.8070182800293, 1.0\n",
      "Train loss and acc of batch 31: 48.023773193359375, 0.984375\n",
      "Train loss and acc of batch 32: 47.8069953918457, 1.0\n",
      "Train loss and acc of batch 33: 47.806983947753906, 1.0\n",
      "Train loss and acc of batch 34: 48.402679443359375, 0.984375\n",
      "Train loss and acc of batch 35: 48.240501403808594, 0.96875\n",
      "Train loss and acc of batch 36: 47.80696105957031, 1.0\n",
      "Train loss and acc of batch 37: 48.560176849365234, 0.984375\n",
      "Train loss and acc of batch 38: 49.15586853027344, 0.96875\n",
      "Train loss and acc of batch 39: 48.02369689941406, 0.984375\n",
      "Train loss and acc of batch 40: 47.806922912597656, 1.0\n",
      "Train loss and acc of batch 41: 49.155845642089844, 0.96875\n",
      "Train loss and acc of batch 42: 47.806907653808594, 1.0\n",
      "Train loss and acc of batch 43: 48.40260314941406, 0.984375\n",
      "Train loss and acc of batch 44: 47.80689239501953, 1.0\n",
      "Train loss and acc of batch 45: 48.40258026123047, 0.984375\n",
      "Train loss and acc of batch 46: 48.09272766113281, 0.984375\n",
      "Train loss and acc of batch 47: 47.80686950683594, 1.0\n",
      "Train loss and acc of batch 48: 47.80685043334961, 1.0\n",
      "Train loss and acc of batch 49: 47.806846618652344, 1.0\n",
      "Train loss and acc of batch 50: 48.40253448486328, 0.984375\n",
      "Train loss and acc of batch 51: 49.15575408935547, 0.96875\n",
      "Train loss and acc of batch 52: 49.06265640258789, 0.953125\n",
      "Train loss and acc of batch 53: 47.80681228637695, 1.0\n",
      "Train loss and acc of batch 54: 48.0235595703125, 0.984375\n",
      "Train loss and acc of batch 55: 47.80679702758789, 1.0\n",
      "Train loss and acc of batch 56: 47.80678176879883, 1.0\n",
      "Train loss and acc of batch 57: 48.40247344970703, 0.984375\n",
      "Train loss and acc of batch 58: 47.806766510009766, 1.0\n",
      "Train loss and acc of batch 59: 47.80675506591797, 1.0\n",
      "Train loss and acc of batch 60: 47.80674743652344, 1.0\n",
      "Train loss and acc of batch 61: 47.806739807128906, 1.0\n",
      "Train loss and acc of batch 62: 47.80672836303711, 1.0\n",
      "Train loss and acc of batch 63: 48.99812316894531, 0.96875\n",
      "Train loss and acc of batch 64: 48.023475646972656, 0.984375\n",
      "Train loss and acc of batch 65: 47.806705474853516, 1.0\n",
      "Train loss and acc of batch 66: 47.80669403076172, 1.0\n",
      "Train loss and acc of batch 67: 48.61914825439453, 0.96875\n",
      "Train loss and acc of batch 68: 48.402381896972656, 0.984375\n",
      "Train loss and acc of batch 69: 48.0234375, 0.984375\n",
      "Train loss and acc of batch 70: 47.80665969848633, 1.0\n",
      "Training accuracy and loss of epoch #398: 0.9897, 48.1279\n",
      "Saved model by train loss 48.1278532323703\n",
      "Train loss and acc of batch 0: 47.80664825439453, 1.0\n",
      "Train loss and acc of batch 1: 47.806644439697266, 1.0\n",
      "Train loss and acc of batch 2: 47.8066291809082, 1.0\n",
      "Train loss and acc of batch 3: 48.02339172363281, 0.984375\n",
      "Train loss and acc of batch 4: 47.80662155151367, 1.0\n",
      "Train loss and acc of batch 5: 49.15553283691406, 0.96875\n",
      "Train loss and acc of batch 6: 48.30921173095703, 0.96875\n",
      "Train loss and acc of batch 7: 47.80658721923828, 1.0\n",
      "Train loss and acc of batch 8: 48.40228271484375, 0.984375\n",
      "Train loss and acc of batch 9: 48.09242248535156, 0.984375\n",
      "Train loss and acc of batch 10: 47.80656051635742, 1.0\n",
      "Train loss and acc of batch 11: 47.80655288696289, 1.0\n",
      "Train loss and acc of batch 12: 48.55976867675781, 0.984375\n",
      "Train loss and acc of batch 13: 48.02330017089844, 0.984375\n",
      "Train loss and acc of batch 14: 48.023292541503906, 0.984375\n",
      "Train loss and acc of batch 15: 48.4022216796875, 0.984375\n",
      "Train loss and acc of batch 16: 48.40220642089844, 0.984375\n",
      "Train loss and acc of batch 17: 48.559722900390625, 0.984375\n",
      "Train loss and acc of batch 18: 48.68803787231445, 0.96875\n",
      "Train loss and acc of batch 19: 47.80647659301758, 1.0\n",
      "Train loss and acc of batch 20: 47.80647277832031, 1.0\n",
      "Train loss and acc of batch 21: 48.40216827392578, 0.984375\n",
      "Train loss and acc of batch 22: 48.40215301513672, 0.984375\n",
      "Train loss and acc of batch 23: 47.80644226074219, 1.0\n",
      "Train loss and acc of batch 24: 48.402137756347656, 0.984375\n",
      "Train loss and acc of batch 25: 47.806427001953125, 1.0\n",
      "Train loss and acc of batch 26: 47.806419372558594, 1.0\n",
      "Train loss and acc of batch 27: 47.80641174316406, 1.0\n",
      "Train loss and acc of batch 28: 47.80640411376953, 1.0\n",
      "Train loss and acc of batch 29: 48.402099609375, 0.984375\n",
      "Train loss and acc of batch 30: 47.8063850402832, 1.0\n",
      "Train loss and acc of batch 31: 48.02313995361328, 0.984375\n",
      "Train loss and acc of batch 32: 47.80636978149414, 1.0\n",
      "Train loss and acc of batch 33: 47.80635452270508, 1.0\n",
      "Train loss and acc of batch 34: 48.40204620361328, 0.984375\n",
      "Train loss and acc of batch 35: 48.239864349365234, 0.96875\n",
      "Train loss and acc of batch 36: 47.806331634521484, 1.0\n",
      "Train loss and acc of batch 37: 48.55955123901367, 0.984375\n",
      "Train loss and acc of batch 38: 49.155235290527344, 0.96875\n",
      "Train loss and acc of batch 39: 48.02306365966797, 0.984375\n",
      "Train loss and acc of batch 40: 47.806297302246094, 1.0\n",
      "Train loss and acc of batch 41: 49.15521240234375, 0.96875\n",
      "Train loss and acc of batch 42: 47.806278228759766, 1.0\n",
      "Train loss and acc of batch 43: 48.40196990966797, 0.984375\n",
      "Train loss and acc of batch 44: 47.8062629699707, 1.0\n",
      "Train loss and acc of batch 45: 48.401947021484375, 0.984375\n",
      "Train loss and acc of batch 46: 48.09209442138672, 0.984375\n",
      "Train loss and acc of batch 47: 47.80623245239258, 1.0\n",
      "Train loss and acc of batch 48: 47.80622482299805, 1.0\n",
      "Train loss and acc of batch 49: 47.80622100830078, 1.0\n",
      "Train loss and acc of batch 50: 48.40190887451172, 0.984375\n",
      "Train loss and acc of batch 51: 49.155120849609375, 0.96875\n",
      "Train loss and acc of batch 52: 49.06202697753906, 0.953125\n",
      "Train loss and acc of batch 53: 47.806175231933594, 1.0\n",
      "Train loss and acc of batch 54: 48.02293395996094, 0.984375\n",
      "Train loss and acc of batch 55: 47.8061637878418, 1.0\n",
      "Train loss and acc of batch 56: 47.806156158447266, 1.0\n",
      "Train loss and acc of batch 57: 48.40184783935547, 0.984375\n",
      "Train loss and acc of batch 58: 47.80613708496094, 1.0\n",
      "Train loss and acc of batch 59: 47.806129455566406, 1.0\n",
      "Train loss and acc of batch 60: 47.806121826171875, 1.0\n",
      "Train loss and acc of batch 61: 47.80610656738281, 1.0\n",
      "Train loss and acc of batch 62: 47.80609893798828, 1.0\n",
      "Train loss and acc of batch 63: 48.99748992919922, 0.96875\n",
      "Train loss and acc of batch 64: 48.022850036621094, 0.984375\n",
      "Train loss and acc of batch 65: 47.80607223510742, 1.0\n",
      "Train loss and acc of batch 66: 47.806068420410156, 1.0\n",
      "Train loss and acc of batch 67: 48.6185188293457, 0.96875\n",
      "Train loss and acc of batch 68: 48.40174865722656, 0.984375\n",
      "Train loss and acc of batch 69: 48.022804260253906, 0.984375\n",
      "Train loss and acc of batch 70: 47.8060302734375, 1.0\n",
      "Training accuracy and loss of epoch #399: 0.9897, 48.1272\n",
      "Saved model by train loss 48.12722310885577\n",
      "Train loss and acc of batch 0: 47.8060188293457, 1.0\n",
      "Train loss and acc of batch 1: 47.80601119995117, 1.0\n",
      "Train loss and acc of batch 2: 47.80600357055664, 1.0\n",
      "Train loss and acc of batch 3: 48.02275848388672, 0.984375\n",
      "Train loss and acc of batch 4: 47.80598449707031, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 5: 49.15489959716797, 0.96875\n",
      "Train loss and acc of batch 6: 48.30858612060547, 0.96875\n",
      "Train loss and acc of batch 7: 47.80595779418945, 1.0\n",
      "Train loss and acc of batch 8: 48.401649475097656, 0.984375\n",
      "Train loss and acc of batch 9: 48.09178924560547, 0.984375\n",
      "Train loss and acc of batch 10: 47.805931091308594, 1.0\n",
      "Train loss and acc of batch 11: 47.8059196472168, 1.0\n",
      "Train loss and acc of batch 12: 48.559139251708984, 0.984375\n",
      "Train loss and acc of batch 13: 48.022666931152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.02265930175781, 0.984375\n",
      "Train loss and acc of batch 15: 48.401588439941406, 0.984375\n",
      "Train loss and acc of batch 16: 48.401580810546875, 0.984375\n",
      "Train loss and acc of batch 17: 48.55909729003906, 0.984375\n",
      "Train loss and acc of batch 18: 48.68741226196289, 0.96875\n",
      "Train loss and acc of batch 19: 47.805850982666016, 1.0\n",
      "Train loss and acc of batch 20: 47.80583572387695, 1.0\n",
      "Train loss and acc of batch 21: 48.40153503417969, 0.984375\n",
      "Train loss and acc of batch 22: 48.401527404785156, 0.984375\n",
      "Train loss and acc of batch 23: 47.80581283569336, 1.0\n",
      "Train loss and acc of batch 24: 48.40150451660156, 0.984375\n",
      "Train loss and acc of batch 25: 47.80579376220703, 1.0\n",
      "Train loss and acc of batch 26: 47.8057861328125, 1.0\n",
      "Train loss and acc of batch 27: 47.80577850341797, 1.0\n",
      "Train loss and acc of batch 28: 47.80577087402344, 1.0\n",
      "Train loss and acc of batch 29: 48.401458740234375, 0.984375\n",
      "Train loss and acc of batch 30: 47.805755615234375, 1.0\n",
      "Train loss and acc of batch 31: 48.02250671386719, 0.984375\n",
      "Train loss and acc of batch 32: 47.80573654174805, 1.0\n",
      "Train loss and acc of batch 33: 47.80572509765625, 1.0\n",
      "Train loss and acc of batch 34: 48.40142059326172, 0.984375\n",
      "Train loss and acc of batch 35: 48.23923873901367, 0.96875\n",
      "Train loss and acc of batch 36: 47.80569839477539, 1.0\n",
      "Train loss and acc of batch 37: 48.55891036987305, 0.984375\n",
      "Train loss and acc of batch 38: 49.15460205078125, 0.96875\n",
      "Train loss and acc of batch 39: 48.022438049316406, 0.984375\n",
      "Train loss and acc of batch 40: 47.8056640625, 1.0\n",
      "Train loss and acc of batch 41: 49.154579162597656, 0.96875\n",
      "Train loss and acc of batch 42: 47.80564498901367, 1.0\n",
      "Train loss and acc of batch 43: 48.401336669921875, 0.984375\n",
      "Train loss and acc of batch 44: 47.80562973022461, 1.0\n",
      "Train loss and acc of batch 45: 48.40132141113281, 0.984375\n",
      "Train loss and acc of batch 46: 48.091461181640625, 0.984375\n",
      "Train loss and acc of batch 47: 47.80560302734375, 1.0\n",
      "Train loss and acc of batch 48: 47.80559158325195, 1.0\n",
      "Train loss and acc of batch 49: 47.80558776855469, 1.0\n",
      "Train loss and acc of batch 50: 48.401275634765625, 0.984375\n",
      "Train loss and acc of batch 51: 49.15449523925781, 0.96875\n",
      "Train loss and acc of batch 52: 49.061397552490234, 0.953125\n",
      "Train loss and acc of batch 53: 47.80554962158203, 1.0\n",
      "Train loss and acc of batch 54: 48.022300720214844, 0.984375\n",
      "Train loss and acc of batch 55: 47.80552673339844, 1.0\n",
      "Train loss and acc of batch 56: 47.805519104003906, 1.0\n",
      "Train loss and acc of batch 57: 48.401214599609375, 0.984375\n",
      "Train loss and acc of batch 58: 47.805503845214844, 1.0\n",
      "Train loss and acc of batch 59: 47.80550003051758, 1.0\n",
      "Train loss and acc of batch 60: 47.805484771728516, 1.0\n",
      "Train loss and acc of batch 61: 47.805477142333984, 1.0\n",
      "Train loss and acc of batch 62: 47.80546951293945, 1.0\n",
      "Train loss and acc of batch 63: 48.996864318847656, 0.96875\n",
      "Train loss and acc of batch 64: 48.022216796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.80543518066406, 1.0\n",
      "Train loss and acc of batch 66: 47.8054313659668, 1.0\n",
      "Train loss and acc of batch 67: 48.61789321899414, 0.96875\n",
      "Train loss and acc of batch 68: 48.40111541748047, 0.984375\n",
      "Train loss and acc of batch 69: 48.02217102050781, 0.984375\n",
      "Train loss and acc of batch 70: 47.805397033691406, 1.0\n",
      "Training accuracy and loss of epoch #400: 0.9897, 48.1266\n",
      "Saved model by train loss 48.12659153468172\n",
      "Train loss and acc of batch 0: 47.80538558959961, 1.0\n",
      "Train loss and acc of batch 1: 47.805381774902344, 1.0\n",
      "Train loss and acc of batch 2: 47.80537414550781, 1.0\n",
      "Train loss and acc of batch 3: 48.022125244140625, 0.984375\n",
      "Train loss and acc of batch 4: 47.80535125732422, 1.0\n",
      "Train loss and acc of batch 5: 49.154273986816406, 0.96875\n",
      "Train loss and acc of batch 6: 48.307945251464844, 0.96875\n",
      "Train loss and acc of batch 7: 47.805328369140625, 1.0\n",
      "Train loss and acc of batch 8: 48.40101623535156, 0.984375\n",
      "Train loss and acc of batch 9: 48.091163635253906, 0.984375\n",
      "Train loss and acc of batch 10: 47.805301666259766, 1.0\n",
      "Train loss and acc of batch 11: 47.805294036865234, 1.0\n",
      "Train loss and acc of batch 12: 48.55850601196289, 0.984375\n",
      "Train loss and acc of batch 13: 48.02204132080078, 0.984375\n",
      "Train loss and acc of batch 14: 48.02202606201172, 0.984375\n",
      "Train loss and acc of batch 15: 48.40095520019531, 0.984375\n",
      "Train loss and acc of batch 16: 48.40095520019531, 0.984375\n",
      "Train loss and acc of batch 17: 48.5584602355957, 0.984375\n",
      "Train loss and acc of batch 18: 48.6867790222168, 0.96875\n",
      "Train loss and acc of batch 19: 47.80522537231445, 1.0\n",
      "Train loss and acc of batch 20: 47.80521011352539, 1.0\n",
      "Train loss and acc of batch 21: 48.400901794433594, 0.984375\n",
      "Train loss and acc of batch 22: 48.40089416503906, 0.984375\n",
      "Train loss and acc of batch 23: 47.805179595947266, 1.0\n",
      "Train loss and acc of batch 24: 48.40087890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.80516815185547, 1.0\n",
      "Train loss and acc of batch 26: 47.80515670776367, 1.0\n",
      "Train loss and acc of batch 27: 47.805152893066406, 1.0\n",
      "Train loss and acc of batch 28: 47.805137634277344, 1.0\n",
      "Train loss and acc of batch 29: 48.40082550048828, 0.984375\n",
      "Train loss and acc of batch 30: 47.80512237548828, 1.0\n",
      "Train loss and acc of batch 31: 48.021881103515625, 0.984375\n",
      "Train loss and acc of batch 32: 47.80510330200195, 1.0\n",
      "Train loss and acc of batch 33: 47.80509948730469, 1.0\n",
      "Train loss and acc of batch 34: 48.400787353515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.23860549926758, 0.96875\n",
      "Train loss and acc of batch 36: 47.80506896972656, 1.0\n",
      "Train loss and acc of batch 37: 48.55828094482422, 0.984375\n",
      "Train loss and acc of batch 38: 49.15397644042969, 0.96875\n",
      "Train loss and acc of batch 39: 48.02180480957031, 0.984375\n",
      "Train loss and acc of batch 40: 47.80503463745117, 1.0\n",
      "Train loss and acc of batch 41: 49.153953552246094, 0.96875\n",
      "Train loss and acc of batch 42: 47.80501937866211, 1.0\n",
      "Train loss and acc of batch 43: 48.40071105957031, 0.984375\n",
      "Train loss and acc of batch 44: 47.80500030517578, 1.0\n",
      "Train loss and acc of batch 45: 48.40069580078125, 0.984375\n",
      "Train loss and acc of batch 46: 48.09083557128906, 0.984375\n",
      "Train loss and acc of batch 47: 47.80497360229492, 1.0\n",
      "Train loss and acc of batch 48: 47.804962158203125, 1.0\n",
      "Train loss and acc of batch 49: 47.804954528808594, 1.0\n",
      "Train loss and acc of batch 50: 48.40064239501953, 0.984375\n",
      "Train loss and acc of batch 51: 49.15386199951172, 0.96875\n",
      "Train loss and acc of batch 52: 49.060768127441406, 0.953125\n",
      "Train loss and acc of batch 53: 47.80491638183594, 1.0\n",
      "Train loss and acc of batch 54: 48.02167510986328, 0.984375\n",
      "Train loss and acc of batch 55: 47.804901123046875, 1.0\n",
      "Train loss and acc of batch 56: 47.804893493652344, 1.0\n",
      "Train loss and acc of batch 57: 48.40058135986328, 0.984375\n",
      "Train loss and acc of batch 58: 47.804874420166016, 1.0\n",
      "Train loss and acc of batch 59: 47.804866790771484, 1.0\n",
      "Train loss and acc of batch 60: 47.80485153198242, 1.0\n",
      "Train loss and acc of batch 61: 47.804847717285156, 1.0\n",
      "Train loss and acc of batch 62: 47.804840087890625, 1.0\n",
      "Train loss and acc of batch 63: 48.99623107910156, 0.96875\n",
      "Train loss and acc of batch 64: 48.02159118652344, 0.984375\n",
      "Train loss and acc of batch 65: 47.8048095703125, 1.0\n",
      "Train loss and acc of batch 66: 47.80480194091797, 1.0\n",
      "Train loss and acc of batch 67: 48.61725997924805, 0.96875\n",
      "Train loss and acc of batch 68: 48.400482177734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.02153778076172, 0.984375\n",
      "Train loss and acc of batch 70: 47.80476760864258, 1.0\n",
      "Training accuracy and loss of epoch #401: 0.9897, 48.1260\n",
      "Saved model by train loss 48.12596151862346\n",
      "Train loss and acc of batch 0: 47.80475997924805, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 1: 47.804752349853516, 1.0\n",
      "Train loss and acc of batch 2: 47.80474090576172, 1.0\n",
      "Train loss and acc of batch 3: 48.02149200439453, 0.984375\n",
      "Train loss and acc of batch 4: 47.804725646972656, 1.0\n",
      "Train loss and acc of batch 5: 49.15364074707031, 0.96875\n",
      "Train loss and acc of batch 6: 48.30732345581055, 0.96875\n",
      "Train loss and acc of batch 7: 47.804691314697266, 1.0\n",
      "Train loss and acc of batch 8: 48.400390625, 0.984375\n",
      "Train loss and acc of batch 9: 48.09053039550781, 0.984375\n",
      "Train loss and acc of batch 10: 47.80466842651367, 1.0\n",
      "Train loss and acc of batch 11: 47.804656982421875, 1.0\n",
      "Train loss and acc of batch 12: 48.55787658691406, 0.984375\n",
      "Train loss and acc of batch 13: 48.021400451660156, 0.984375\n",
      "Train loss and acc of batch 14: 48.021400451660156, 0.984375\n",
      "Train loss and acc of batch 15: 48.40032958984375, 0.984375\n",
      "Train loss and acc of batch 16: 48.40032196044922, 0.984375\n",
      "Train loss and acc of batch 17: 48.55782699584961, 0.984375\n",
      "Train loss and acc of batch 18: 48.686153411865234, 0.96875\n",
      "Train loss and acc of batch 19: 47.804588317871094, 1.0\n",
      "Train loss and acc of batch 20: 47.80458068847656, 1.0\n",
      "Train loss and acc of batch 21: 48.40027618408203, 0.984375\n",
      "Train loss and acc of batch 22: 48.40026092529297, 0.984375\n",
      "Train loss and acc of batch 23: 47.8045539855957, 1.0\n",
      "Train loss and acc of batch 24: 48.400245666503906, 0.984375\n",
      "Train loss and acc of batch 25: 47.804534912109375, 1.0\n",
      "Train loss and acc of batch 26: 47.804527282714844, 1.0\n",
      "Train loss and acc of batch 27: 47.80451583862305, 1.0\n",
      "Train loss and acc of batch 28: 47.80451202392578, 1.0\n",
      "Train loss and acc of batch 29: 48.40020751953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.80448532104492, 1.0\n",
      "Train loss and acc of batch 31: 48.02124786376953, 0.984375\n",
      "Train loss and acc of batch 32: 47.804473876953125, 1.0\n",
      "Train loss and acc of batch 33: 47.804466247558594, 1.0\n",
      "Train loss and acc of batch 34: 48.40015411376953, 0.984375\n",
      "Train loss and acc of batch 35: 48.23797607421875, 0.96875\n",
      "Train loss and acc of batch 36: 47.804439544677734, 1.0\n",
      "Train loss and acc of batch 37: 48.557655334472656, 0.984375\n",
      "Train loss and acc of batch 38: 49.153350830078125, 0.96875\n",
      "Train loss and acc of batch 39: 48.02117156982422, 0.984375\n",
      "Train loss and acc of batch 40: 47.80440139770508, 1.0\n",
      "Train loss and acc of batch 41: 49.153316497802734, 0.96875\n",
      "Train loss and acc of batch 42: 47.804386138916016, 1.0\n",
      "Train loss and acc of batch 43: 48.40007781982422, 0.984375\n",
      "Train loss and acc of batch 44: 47.80436706542969, 1.0\n",
      "Train loss and acc of batch 45: 48.400062561035156, 0.984375\n",
      "Train loss and acc of batch 46: 48.09020233154297, 0.984375\n",
      "Train loss and acc of batch 47: 47.80434036254883, 1.0\n",
      "Train loss and acc of batch 48: 47.80432891845703, 1.0\n",
      "Train loss and acc of batch 49: 47.804325103759766, 1.0\n",
      "Train loss and acc of batch 50: 48.40001678466797, 0.984375\n",
      "Train loss and acc of batch 51: 49.153228759765625, 0.96875\n",
      "Train loss and acc of batch 52: 49.06013870239258, 0.953125\n",
      "Train loss and acc of batch 53: 47.804283142089844, 1.0\n",
      "Train loss and acc of batch 54: 48.02104187011719, 0.984375\n",
      "Train loss and acc of batch 55: 47.80426788330078, 1.0\n",
      "Train loss and acc of batch 56: 47.80426025390625, 1.0\n",
      "Train loss and acc of batch 57: 48.39995574951172, 0.984375\n",
      "Train loss and acc of batch 58: 47.804237365722656, 1.0\n",
      "Train loss and acc of batch 59: 47.80423355102539, 1.0\n",
      "Train loss and acc of batch 60: 47.80422592163086, 1.0\n",
      "Train loss and acc of batch 61: 47.80421829223633, 1.0\n",
      "Train loss and acc of batch 62: 47.8042106628418, 1.0\n",
      "Train loss and acc of batch 63: 48.995601654052734, 0.96875\n",
      "Train loss and acc of batch 64: 48.02095031738281, 0.984375\n",
      "Train loss and acc of batch 65: 47.80418395996094, 1.0\n",
      "Train loss and acc of batch 66: 47.80417251586914, 1.0\n",
      "Train loss and acc of batch 67: 48.61662673950195, 0.96875\n",
      "Train loss and acc of batch 68: 48.39985656738281, 0.984375\n",
      "Train loss and acc of batch 69: 48.020912170410156, 0.984375\n",
      "Train loss and acc of batch 70: 47.80413818359375, 1.0\n",
      "Training accuracy and loss of epoch #402: 0.9897, 48.1253\n",
      "Saved model by train loss 48.12533064291511\n",
      "Train loss and acc of batch 0: 47.80412673950195, 1.0\n",
      "Train loss and acc of batch 1: 47.80411911010742, 1.0\n",
      "Train loss and acc of batch 2: 47.80411148071289, 1.0\n",
      "Train loss and acc of batch 3: 48.02086639404297, 0.984375\n",
      "Train loss and acc of batch 4: 47.8040885925293, 1.0\n",
      "Train loss and acc of batch 5: 49.15300750732422, 0.96875\n",
      "Train loss and acc of batch 6: 48.30669021606445, 0.96875\n",
      "Train loss and acc of batch 7: 47.8040657043457, 1.0\n",
      "Train loss and acc of batch 8: 48.399757385253906, 0.984375\n",
      "Train loss and acc of batch 9: 48.08990478515625, 0.984375\n",
      "Train loss and acc of batch 10: 47.804039001464844, 1.0\n",
      "Train loss and acc of batch 11: 47.80403137207031, 1.0\n",
      "Train loss and acc of batch 12: 48.55724334716797, 0.984375\n",
      "Train loss and acc of batch 13: 48.020774841308594, 0.984375\n",
      "Train loss and acc of batch 14: 48.02076721191406, 0.984375\n",
      "Train loss and acc of batch 15: 48.399696350097656, 0.984375\n",
      "Train loss and acc of batch 16: 48.399688720703125, 0.984375\n",
      "Train loss and acc of batch 17: 48.55719757080078, 0.984375\n",
      "Train loss and acc of batch 18: 48.685516357421875, 0.96875\n",
      "Train loss and acc of batch 19: 47.803955078125, 1.0\n",
      "Train loss and acc of batch 20: 47.80394744873047, 1.0\n",
      "Train loss and acc of batch 21: 48.39964294433594, 0.984375\n",
      "Train loss and acc of batch 22: 48.399635314941406, 0.984375\n",
      "Train loss and acc of batch 23: 47.80392837524414, 1.0\n",
      "Train loss and acc of batch 24: 48.39961242675781, 0.984375\n",
      "Train loss and acc of batch 25: 47.80390548706055, 1.0\n",
      "Train loss and acc of batch 26: 47.803897857666016, 1.0\n",
      "Train loss and acc of batch 27: 47.803890228271484, 1.0\n",
      "Train loss and acc of batch 28: 47.80387878417969, 1.0\n",
      "Train loss and acc of batch 29: 48.399566650390625, 0.984375\n",
      "Train loss and acc of batch 30: 47.80385971069336, 1.0\n",
      "Train loss and acc of batch 31: 48.02061462402344, 0.984375\n",
      "Train loss and acc of batch 32: 47.8038444519043, 1.0\n",
      "Train loss and acc of batch 33: 47.803836822509766, 1.0\n",
      "Train loss and acc of batch 34: 48.39952850341797, 0.984375\n",
      "Train loss and acc of batch 35: 48.23734664916992, 0.96875\n",
      "Train loss and acc of batch 36: 47.80380630493164, 1.0\n",
      "Train loss and acc of batch 37: 48.55702590942383, 0.984375\n",
      "Train loss and acc of batch 38: 49.15271759033203, 0.96875\n",
      "Train loss and acc of batch 39: 48.020545959472656, 0.984375\n",
      "Train loss and acc of batch 40: 47.80377197265625, 1.0\n",
      "Train loss and acc of batch 41: 49.152687072753906, 0.96875\n",
      "Train loss and acc of batch 42: 47.80375671386719, 1.0\n",
      "Train loss and acc of batch 43: 48.399444580078125, 0.984375\n",
      "Train loss and acc of batch 44: 47.80373764038086, 1.0\n",
      "Train loss and acc of batch 45: 48.39942932128906, 0.984375\n",
      "Train loss and acc of batch 46: 48.089569091796875, 0.984375\n",
      "Train loss and acc of batch 47: 47.80370330810547, 1.0\n",
      "Train loss and acc of batch 48: 47.80370330810547, 1.0\n",
      "Train loss and acc of batch 49: 47.80369567871094, 1.0\n",
      "Train loss and acc of batch 50: 48.399383544921875, 0.984375\n",
      "Train loss and acc of batch 51: 49.15260314941406, 0.96875\n",
      "Train loss and acc of batch 52: 49.059505462646484, 0.953125\n",
      "Train loss and acc of batch 53: 47.803653717041016, 1.0\n",
      "Train loss and acc of batch 54: 48.020416259765625, 0.984375\n",
      "Train loss and acc of batch 55: 47.80363845825195, 1.0\n",
      "Train loss and acc of batch 56: 47.80363464355469, 1.0\n",
      "Train loss and acc of batch 57: 48.399322509765625, 0.984375\n",
      "Train loss and acc of batch 58: 47.803611755371094, 1.0\n",
      "Train loss and acc of batch 59: 47.80360794067383, 1.0\n",
      "Train loss and acc of batch 60: 47.8036003112793, 1.0\n",
      "Train loss and acc of batch 61: 47.803585052490234, 1.0\n",
      "Train loss and acc of batch 62: 47.8035774230957, 1.0\n",
      "Train loss and acc of batch 63: 48.99496841430664, 0.96875\n",
      "Train loss and acc of batch 64: 48.02032470703125, 0.984375\n",
      "Train loss and acc of batch 65: 47.80354690551758, 1.0\n",
      "Train loss and acc of batch 66: 47.80353927612305, 1.0\n",
      "Train loss and acc of batch 67: 48.615997314453125, 0.96875\n",
      "Train loss and acc of batch 68: 48.39922332763672, 0.984375\n",
      "Train loss and acc of batch 69: 48.02027893066406, 0.984375\n",
      "Train loss and acc of batch 70: 47.80350875854492, 1.0\n",
      "Training accuracy and loss of epoch #403: 0.9897, 48.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.12470008957554\n",
      "Train loss and acc of batch 0: 47.803497314453125, 1.0\n",
      "Train loss and acc of batch 1: 47.803489685058594, 1.0\n",
      "Train loss and acc of batch 2: 47.80348205566406, 1.0\n",
      "Train loss and acc of batch 3: 48.020233154296875, 0.984375\n",
      "Train loss and acc of batch 4: 47.80345916748047, 1.0\n",
      "Train loss and acc of batch 5: 49.152374267578125, 0.96875\n",
      "Train loss and acc of batch 6: 48.306060791015625, 0.96875\n",
      "Train loss and acc of batch 7: 47.803436279296875, 1.0\n",
      "Train loss and acc of batch 8: 48.399131774902344, 0.984375\n",
      "Train loss and acc of batch 9: 48.089263916015625, 0.984375\n",
      "Train loss and acc of batch 10: 47.803409576416016, 1.0\n",
      "Train loss and acc of batch 11: 47.80339813232422, 1.0\n",
      "Train loss and acc of batch 12: 48.55661392211914, 0.984375\n",
      "Train loss and acc of batch 13: 48.02014923095703, 0.984375\n",
      "Train loss and acc of batch 14: 48.02013397216797, 0.984375\n",
      "Train loss and acc of batch 15: 48.39906311035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.39906311035156, 0.984375\n",
      "Train loss and acc of batch 17: 48.55657196044922, 0.984375\n",
      "Train loss and acc of batch 18: 48.68489074707031, 0.96875\n",
      "Train loss and acc of batch 19: 47.80332946777344, 1.0\n",
      "Train loss and acc of batch 20: 47.80331802368164, 1.0\n",
      "Train loss and acc of batch 21: 48.399009704589844, 0.984375\n",
      "Train loss and acc of batch 22: 48.39900207519531, 0.984375\n",
      "Train loss and acc of batch 23: 47.80329132080078, 1.0\n",
      "Train loss and acc of batch 24: 48.39898681640625, 0.984375\n",
      "Train loss and acc of batch 25: 47.80327606201172, 1.0\n",
      "Train loss and acc of batch 26: 47.80326461791992, 1.0\n",
      "Train loss and acc of batch 27: 47.80325698852539, 1.0\n",
      "Train loss and acc of batch 28: 47.803245544433594, 1.0\n",
      "Train loss and acc of batch 29: 48.39894104003906, 0.984375\n",
      "Train loss and acc of batch 30: 47.8032341003418, 1.0\n",
      "Train loss and acc of batch 31: 48.019981384277344, 0.984375\n",
      "Train loss and acc of batch 32: 47.80321502685547, 1.0\n",
      "Train loss and acc of batch 33: 47.80320358276367, 1.0\n",
      "Train loss and acc of batch 34: 48.398895263671875, 0.984375\n",
      "Train loss and acc of batch 35: 48.23671340942383, 0.96875\n",
      "Train loss and acc of batch 36: 47.803184509277344, 1.0\n",
      "Train loss and acc of batch 37: 48.55638885498047, 0.984375\n",
      "Train loss and acc of batch 38: 49.15208435058594, 0.96875\n",
      "Train loss and acc of batch 39: 48.01991271972656, 0.984375\n",
      "Train loss and acc of batch 40: 47.80314254760742, 1.0\n",
      "Train loss and acc of batch 41: 49.152061462402344, 0.96875\n",
      "Train loss and acc of batch 42: 47.80311584472656, 1.0\n",
      "Train loss and acc of batch 43: 48.39881134033203, 0.984375\n",
      "Train loss and acc of batch 44: 47.80310821533203, 1.0\n",
      "Train loss and acc of batch 45: 48.3988037109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.08894348144531, 0.984375\n",
      "Train loss and acc of batch 47: 47.80308151245117, 1.0\n",
      "Train loss and acc of batch 48: 47.80306625366211, 1.0\n",
      "Train loss and acc of batch 49: 47.803062438964844, 1.0\n",
      "Train loss and acc of batch 50: 48.39875793457031, 0.984375\n",
      "Train loss and acc of batch 51: 49.15196228027344, 0.96875\n",
      "Train loss and acc of batch 52: 49.058876037597656, 0.953125\n",
      "Train loss and acc of batch 53: 47.80302810668945, 1.0\n",
      "Train loss and acc of batch 54: 48.01978302001953, 0.984375\n",
      "Train loss and acc of batch 55: 47.803009033203125, 1.0\n",
      "Train loss and acc of batch 56: 47.80299377441406, 1.0\n",
      "Train loss and acc of batch 57: 48.39868927001953, 0.984375\n",
      "Train loss and acc of batch 58: 47.802982330322266, 1.0\n",
      "Train loss and acc of batch 59: 47.80297088623047, 1.0\n",
      "Train loss and acc of batch 60: 47.80295944213867, 1.0\n",
      "Train loss and acc of batch 61: 47.80295944213867, 1.0\n",
      "Train loss and acc of batch 62: 47.802947998046875, 1.0\n",
      "Train loss and acc of batch 63: 48.99434280395508, 0.96875\n",
      "Train loss and acc of batch 64: 48.01969909667969, 0.984375\n",
      "Train loss and acc of batch 65: 47.80291748046875, 1.0\n",
      "Train loss and acc of batch 66: 47.80290985107422, 1.0\n",
      "Train loss and acc of batch 67: 48.6153678894043, 0.96875\n",
      "Train loss and acc of batch 68: 48.398590087890625, 0.984375\n",
      "Train loss and acc of batch 69: 48.0196533203125, 0.984375\n",
      "Train loss and acc of batch 70: 47.80287551879883, 1.0\n",
      "Training accuracy and loss of epoch #404: 0.9897, 48.1241\n",
      "Saved model by train loss 48.12406942877971\n",
      "Train loss and acc of batch 0: 47.80286407470703, 1.0\n",
      "Train loss and acc of batch 1: 47.8028564453125, 1.0\n",
      "Train loss and acc of batch 2: 47.80284881591797, 1.0\n",
      "Train loss and acc of batch 3: 48.01960754394531, 0.984375\n",
      "Train loss and acc of batch 4: 47.802833557128906, 1.0\n",
      "Train loss and acc of batch 5: 49.15174102783203, 0.96875\n",
      "Train loss and acc of batch 6: 48.3054313659668, 0.96875\n",
      "Train loss and acc of batch 7: 47.80280303955078, 1.0\n",
      "Train loss and acc of batch 8: 48.39849090576172, 0.984375\n",
      "Train loss and acc of batch 9: 48.08863830566406, 0.984375\n",
      "Train loss and acc of batch 10: 47.80277633666992, 1.0\n",
      "Train loss and acc of batch 11: 47.802772521972656, 1.0\n",
      "Train loss and acc of batch 12: 48.55598449707031, 0.984375\n",
      "Train loss and acc of batch 13: 48.019508361816406, 0.984375\n",
      "Train loss and acc of batch 14: 48.019500732421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.3984375, 0.984375\n",
      "Train loss and acc of batch 16: 48.39842987060547, 0.984375\n",
      "Train loss and acc of batch 17: 48.555938720703125, 0.984375\n",
      "Train loss and acc of batch 18: 48.684261322021484, 0.96875\n",
      "Train loss and acc of batch 19: 47.80270004272461, 1.0\n",
      "Train loss and acc of batch 20: 47.80269241333008, 1.0\n",
      "Train loss and acc of batch 21: 48.39837646484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.39836883544922, 0.984375\n",
      "Train loss and acc of batch 23: 47.80266189575195, 1.0\n",
      "Train loss and acc of batch 24: 48.398353576660156, 0.984375\n",
      "Train loss and acc of batch 25: 47.80264663696289, 1.0\n",
      "Train loss and acc of batch 26: 47.802635192871094, 1.0\n",
      "Train loss and acc of batch 27: 47.80262756347656, 1.0\n",
      "Train loss and acc of batch 28: 47.802616119384766, 1.0\n",
      "Train loss and acc of batch 29: 48.3983154296875, 0.984375\n",
      "Train loss and acc of batch 30: 47.80259704589844, 1.0\n",
      "Train loss and acc of batch 31: 48.01935577392578, 0.984375\n",
      "Train loss and acc of batch 32: 47.802581787109375, 1.0\n",
      "Train loss and acc of batch 33: 47.80257034301758, 1.0\n",
      "Train loss and acc of batch 34: 48.39826965332031, 0.984375\n",
      "Train loss and acc of batch 35: 48.236080169677734, 0.96875\n",
      "Train loss and acc of batch 36: 47.802547454833984, 1.0\n",
      "Train loss and acc of batch 37: 48.555763244628906, 0.984375\n",
      "Train loss and acc of batch 38: 49.151451110839844, 0.96875\n",
      "Train loss and acc of batch 39: 48.019287109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.802513122558594, 1.0\n",
      "Train loss and acc of batch 41: 49.15142822265625, 0.96875\n",
      "Train loss and acc of batch 42: 47.802494049072266, 1.0\n",
      "Train loss and acc of batch 43: 48.39818572998047, 0.984375\n",
      "Train loss and acc of batch 44: 47.8024787902832, 1.0\n",
      "Train loss and acc of batch 45: 48.398162841796875, 0.984375\n",
      "Train loss and acc of batch 46: 48.08831024169922, 0.984375\n",
      "Train loss and acc of batch 47: 47.80244827270508, 1.0\n",
      "Train loss and acc of batch 48: 47.80244064331055, 1.0\n",
      "Train loss and acc of batch 49: 47.80242919921875, 1.0\n",
      "Train loss and acc of batch 50: 48.39811706542969, 0.984375\n",
      "Train loss and acc of batch 51: 49.151336669921875, 0.96875\n",
      "Train loss and acc of batch 52: 49.05824279785156, 0.953125\n",
      "Train loss and acc of batch 53: 47.80239486694336, 1.0\n",
      "Train loss and acc of batch 54: 48.01914978027344, 0.984375\n",
      "Train loss and acc of batch 55: 47.80237579345703, 1.0\n",
      "Train loss and acc of batch 56: 47.8023681640625, 1.0\n",
      "Train loss and acc of batch 57: 48.39806365966797, 0.984375\n",
      "Train loss and acc of batch 58: 47.80234909057617, 1.0\n",
      "Train loss and acc of batch 59: 47.802337646484375, 1.0\n",
      "Train loss and acc of batch 60: 47.80233383178711, 1.0\n",
      "Train loss and acc of batch 61: 47.80232238769531, 1.0\n",
      "Train loss and acc of batch 62: 47.80231857299805, 1.0\n",
      "Train loss and acc of batch 63: 48.993709564208984, 0.96875\n",
      "Train loss and acc of batch 64: 48.01905822753906, 0.984375\n",
      "Train loss and acc of batch 65: 47.80228805541992, 1.0\n",
      "Train loss and acc of batch 66: 47.802276611328125, 1.0\n",
      "Train loss and acc of batch 67: 48.6147346496582, 0.96875\n",
      "Train loss and acc of batch 68: 48.397972106933594, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 48.019020080566406, 0.984375\n",
      "Train loss and acc of batch 70: 47.80224609375, 1.0\n",
      "Training accuracy and loss of epoch #405: 0.9897, 48.1234\n",
      "Saved model by train loss 48.12343844561509\n",
      "Train loss and acc of batch 0: 47.8022346496582, 1.0\n",
      "Train loss and acc of batch 1: 47.802223205566406, 1.0\n",
      "Train loss and acc of batch 2: 47.80221176147461, 1.0\n",
      "Train loss and acc of batch 3: 48.01897430419922, 0.984375\n",
      "Train loss and acc of batch 4: 47.80219650268555, 1.0\n",
      "Train loss and acc of batch 5: 49.15111541748047, 0.96875\n",
      "Train loss and acc of batch 6: 48.3047981262207, 0.96875\n",
      "Train loss and acc of batch 7: 47.80216598510742, 1.0\n",
      "Train loss and acc of batch 8: 48.397865295410156, 0.984375\n",
      "Train loss and acc of batch 9: 48.08800506591797, 0.984375\n",
      "Train loss and acc of batch 10: 47.80214309692383, 1.0\n",
      "Train loss and acc of batch 11: 47.80213928222656, 1.0\n",
      "Train loss and acc of batch 12: 48.55534744262695, 0.984375\n",
      "Train loss and acc of batch 13: 48.018882751464844, 0.984375\n",
      "Train loss and acc of batch 14: 48.01887512207031, 0.984375\n",
      "Train loss and acc of batch 15: 48.397796630859375, 0.984375\n",
      "Train loss and acc of batch 16: 48.397789001464844, 0.984375\n",
      "Train loss and acc of batch 17: 48.555301666259766, 0.984375\n",
      "Train loss and acc of batch 18: 48.68362808227539, 0.96875\n",
      "Train loss and acc of batch 19: 47.80206298828125, 1.0\n",
      "Train loss and acc of batch 20: 47.80206298828125, 1.0\n",
      "Train loss and acc of batch 21: 48.397743225097656, 0.984375\n",
      "Train loss and acc of batch 22: 48.397735595703125, 0.984375\n",
      "Train loss and acc of batch 23: 47.80202865600586, 1.0\n",
      "Train loss and acc of batch 24: 48.39772033691406, 0.984375\n",
      "Train loss and acc of batch 25: 47.8020133972168, 1.0\n",
      "Train loss and acc of batch 26: 47.801998138427734, 1.0\n",
      "Train loss and acc of batch 27: 47.80199432373047, 1.0\n",
      "Train loss and acc of batch 28: 47.8019905090332, 1.0\n",
      "Train loss and acc of batch 29: 48.397674560546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.80196762084961, 1.0\n",
      "Train loss and acc of batch 31: 48.01872253417969, 0.984375\n",
      "Train loss and acc of batch 32: 47.801944732666016, 1.0\n",
      "Train loss and acc of batch 33: 47.80194091796875, 1.0\n",
      "Train loss and acc of batch 34: 48.39762878417969, 0.984375\n",
      "Train loss and acc of batch 35: 48.235450744628906, 0.96875\n",
      "Train loss and acc of batch 36: 47.80191421508789, 1.0\n",
      "Train loss and acc of batch 37: 48.55513000488281, 0.984375\n",
      "Train loss and acc of batch 38: 49.15081787109375, 0.96875\n",
      "Train loss and acc of batch 39: 48.018653869628906, 0.984375\n",
      "Train loss and acc of batch 40: 47.8018798828125, 1.0\n",
      "Train loss and acc of batch 41: 49.150794982910156, 0.96875\n",
      "Train loss and acc of batch 42: 47.80186462402344, 1.0\n",
      "Train loss and acc of batch 43: 48.397544860839844, 0.984375\n",
      "Train loss and acc of batch 44: 47.801841735839844, 1.0\n",
      "Train loss and acc of batch 45: 48.39752960205078, 0.984375\n",
      "Train loss and acc of batch 46: 48.087677001953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.80181884765625, 1.0\n",
      "Train loss and acc of batch 48: 47.80180358886719, 1.0\n",
      "Train loss and acc of batch 49: 47.801795959472656, 1.0\n",
      "Train loss and acc of batch 50: 48.397491455078125, 0.984375\n",
      "Train loss and acc of batch 51: 49.15070343017578, 0.96875\n",
      "Train loss and acc of batch 52: 49.05760955810547, 0.953125\n",
      "Train loss and acc of batch 53: 47.80176544189453, 1.0\n",
      "Train loss and acc of batch 54: 48.018516540527344, 0.984375\n",
      "Train loss and acc of batch 55: 47.8017463684082, 1.0\n",
      "Train loss and acc of batch 56: 47.80173873901367, 1.0\n",
      "Train loss and acc of batch 57: 48.397430419921875, 0.984375\n",
      "Train loss and acc of batch 58: 47.801719665527344, 1.0\n",
      "Train loss and acc of batch 59: 47.80170822143555, 1.0\n",
      "Train loss and acc of batch 60: 47.80169677734375, 1.0\n",
      "Train loss and acc of batch 61: 47.801692962646484, 1.0\n",
      "Train loss and acc of batch 62: 47.80168151855469, 1.0\n",
      "Train loss and acc of batch 63: 48.993072509765625, 0.96875\n",
      "Train loss and acc of batch 64: 48.0184326171875, 0.984375\n",
      "Train loss and acc of batch 65: 47.801658630371094, 1.0\n",
      "Train loss and acc of batch 66: 47.8016471862793, 1.0\n",
      "Train loss and acc of batch 67: 48.614105224609375, 0.96875\n",
      "Train loss and acc of batch 68: 48.39733123779297, 0.984375\n",
      "Train loss and acc of batch 69: 48.01837921142578, 0.984375\n",
      "Train loss and acc of batch 70: 47.801612854003906, 1.0\n",
      "Training accuracy and loss of epoch #406: 0.9897, 48.1228\n",
      "Saved model by train loss 48.122805367053395\n",
      "Train loss and acc of batch 0: 47.801605224609375, 1.0\n",
      "Train loss and acc of batch 1: 47.80159378051758, 1.0\n",
      "Train loss and acc of batch 2: 47.80158615112305, 1.0\n",
      "Train loss and acc of batch 3: 48.018341064453125, 0.984375\n",
      "Train loss and acc of batch 4: 47.80156707763672, 1.0\n",
      "Train loss and acc of batch 5: 49.150482177734375, 0.96875\n",
      "Train loss and acc of batch 6: 48.304161071777344, 0.96875\n",
      "Train loss and acc of batch 7: 47.801544189453125, 1.0\n",
      "Train loss and acc of batch 8: 48.39723205566406, 0.984375\n",
      "Train loss and acc of batch 9: 48.087371826171875, 0.984375\n",
      "Train loss and acc of batch 10: 47.801513671875, 1.0\n",
      "Train loss and acc of batch 11: 47.80150604248047, 1.0\n",
      "Train loss and acc of batch 12: 48.554718017578125, 0.984375\n",
      "Train loss and acc of batch 13: 48.01825714111328, 0.984375\n",
      "Train loss and acc of batch 14: 48.01824188232422, 0.984375\n",
      "Train loss and acc of batch 15: 48.39717102050781, 0.984375\n",
      "Train loss and acc of batch 16: 48.39716339111328, 0.984375\n",
      "Train loss and acc of batch 17: 48.5546760559082, 0.984375\n",
      "Train loss and acc of batch 18: 48.6829948425293, 0.96875\n",
      "Train loss and acc of batch 19: 47.80143737792969, 1.0\n",
      "Train loss and acc of batch 20: 47.801422119140625, 1.0\n",
      "Train loss and acc of batch 21: 48.397117614746094, 0.984375\n",
      "Train loss and acc of batch 22: 48.39710998535156, 0.984375\n",
      "Train loss and acc of batch 23: 47.801395416259766, 1.0\n",
      "Train loss and acc of batch 24: 48.39708709716797, 0.984375\n",
      "Train loss and acc of batch 25: 47.8013801574707, 1.0\n",
      "Train loss and acc of batch 26: 47.801368713378906, 1.0\n",
      "Train loss and acc of batch 27: 47.80136489868164, 1.0\n",
      "Train loss and acc of batch 28: 47.801353454589844, 1.0\n",
      "Train loss and acc of batch 29: 48.39704895019531, 0.984375\n",
      "Train loss and acc of batch 30: 47.80133819580078, 1.0\n",
      "Train loss and acc of batch 31: 48.018089294433594, 0.984375\n",
      "Train loss and acc of batch 32: 47.80131912231445, 1.0\n",
      "Train loss and acc of batch 33: 47.80130386352539, 1.0\n",
      "Train loss and acc of batch 34: 48.396995544433594, 0.984375\n",
      "Train loss and acc of batch 35: 48.23482131958008, 0.96875\n",
      "Train loss and acc of batch 36: 47.80128479003906, 1.0\n",
      "Train loss and acc of batch 37: 48.554500579833984, 0.984375\n",
      "Train loss and acc of batch 38: 49.15019226074219, 0.96875\n",
      "Train loss and acc of batch 39: 48.01802062988281, 0.984375\n",
      "Train loss and acc of batch 40: 47.801246643066406, 1.0\n",
      "Train loss and acc of batch 41: 49.15016555786133, 0.96875\n",
      "Train loss and acc of batch 42: 47.801231384277344, 1.0\n",
      "Train loss and acc of batch 43: 48.39691925048828, 0.984375\n",
      "Train loss and acc of batch 44: 47.80121612548828, 1.0\n",
      "Train loss and acc of batch 45: 48.39690399169922, 0.984375\n",
      "Train loss and acc of batch 46: 48.08704376220703, 0.984375\n",
      "Train loss and acc of batch 47: 47.801185607910156, 1.0\n",
      "Train loss and acc of batch 48: 47.80117416381836, 1.0\n",
      "Train loss and acc of batch 49: 47.80116653442383, 1.0\n",
      "Train loss and acc of batch 50: 48.39685821533203, 0.984375\n",
      "Train loss and acc of batch 51: 49.15007019042969, 0.96875\n",
      "Train loss and acc of batch 52: 49.05698013305664, 0.953125\n",
      "Train loss and acc of batch 53: 47.80113220214844, 1.0\n",
      "Train loss and acc of batch 54: 48.01788330078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.80111312866211, 1.0\n",
      "Train loss and acc of batch 56: 47.80110168457031, 1.0\n",
      "Train loss and acc of batch 57: 48.39679718017578, 0.984375\n",
      "Train loss and acc of batch 58: 47.801090240478516, 1.0\n",
      "Train loss and acc of batch 59: 47.80107879638672, 1.0\n",
      "Train loss and acc of batch 60: 47.80107116699219, 1.0\n",
      "Train loss and acc of batch 61: 47.80105972290039, 1.0\n",
      "Train loss and acc of batch 62: 47.80105209350586, 1.0\n",
      "Train loss and acc of batch 63: 48.9924430847168, 0.96875\n",
      "Train loss and acc of batch 64: 48.01780700683594, 0.984375\n",
      "Train loss and acc of batch 65: 47.801025390625, 1.0\n",
      "Train loss and acc of batch 66: 47.80101776123047, 1.0\n",
      "Train loss and acc of batch 67: 48.61347198486328, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 68: 48.396697998046875, 0.984375\n",
      "Train loss and acc of batch 69: 48.01775360107422, 0.984375\n",
      "Train loss and acc of batch 70: 47.80098342895508, 1.0\n",
      "Training accuracy and loss of epoch #407: 0.9897, 48.1222\n",
      "Saved model by train loss 48.122174921170085\n",
      "Train loss and acc of batch 0: 47.800968170166016, 1.0\n",
      "Train loss and acc of batch 1: 47.80096435546875, 1.0\n",
      "Train loss and acc of batch 2: 47.80095672607422, 1.0\n",
      "Train loss and acc of batch 3: 48.01770782470703, 0.984375\n",
      "Train loss and acc of batch 4: 47.80093765258789, 1.0\n",
      "Train loss and acc of batch 5: 49.14984893798828, 0.96875\n",
      "Train loss and acc of batch 6: 48.30353546142578, 0.96875\n",
      "Train loss and acc of batch 7: 47.80091094970703, 1.0\n",
      "Train loss and acc of batch 8: 48.3966064453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.08674621582031, 0.984375\n",
      "Train loss and acc of batch 10: 47.80088424682617, 1.0\n",
      "Train loss and acc of batch 11: 47.80086898803711, 1.0\n",
      "Train loss and acc of batch 12: 48.55409240722656, 0.984375\n",
      "Train loss and acc of batch 13: 48.017616271972656, 0.984375\n",
      "Train loss and acc of batch 14: 48.017608642578125, 0.984375\n",
      "Train loss and acc of batch 15: 48.39653778076172, 0.984375\n",
      "Train loss and acc of batch 16: 48.39653015136719, 0.984375\n",
      "Train loss and acc of batch 17: 48.55404281616211, 0.984375\n",
      "Train loss and acc of batch 18: 48.682369232177734, 0.96875\n",
      "Train loss and acc of batch 19: 47.80080032348633, 1.0\n",
      "Train loss and acc of batch 20: 47.8007926940918, 1.0\n",
      "Train loss and acc of batch 21: 48.39649200439453, 0.984375\n",
      "Train loss and acc of batch 22: 48.39647674560547, 0.984375\n",
      "Train loss and acc of batch 23: 47.80076599121094, 1.0\n",
      "Train loss and acc of batch 24: 48.396461486816406, 0.984375\n",
      "Train loss and acc of batch 25: 47.80074691772461, 1.0\n",
      "Train loss and acc of batch 26: 47.800743103027344, 1.0\n",
      "Train loss and acc of batch 27: 47.80073165893555, 1.0\n",
      "Train loss and acc of batch 28: 47.80072021484375, 1.0\n",
      "Train loss and acc of batch 29: 48.39641571044922, 0.984375\n",
      "Train loss and acc of batch 30: 47.80070495605469, 1.0\n",
      "Train loss and acc of batch 31: 48.01746368408203, 0.984375\n",
      "Train loss and acc of batch 32: 47.800689697265625, 1.0\n",
      "Train loss and acc of batch 33: 47.80067443847656, 1.0\n",
      "Train loss and acc of batch 34: 48.39636993408203, 0.984375\n",
      "Train loss and acc of batch 35: 48.23419189453125, 0.96875\n",
      "Train loss and acc of batch 36: 47.8006477355957, 1.0\n",
      "Train loss and acc of batch 37: 48.55386734008789, 0.984375\n",
      "Train loss and acc of batch 38: 49.149559020996094, 0.96875\n",
      "Train loss and acc of batch 39: 48.01739501953125, 0.984375\n",
      "Train loss and acc of batch 40: 47.80061721801758, 1.0\n",
      "Train loss and acc of batch 41: 49.14952850341797, 0.96875\n",
      "Train loss and acc of batch 42: 47.800594329833984, 1.0\n",
      "Train loss and acc of batch 43: 48.39629364013672, 0.984375\n",
      "Train loss and acc of batch 44: 47.80058288574219, 1.0\n",
      "Train loss and acc of batch 45: 48.396278381347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.08641815185547, 0.984375\n",
      "Train loss and acc of batch 47: 47.80055236816406, 1.0\n",
      "Train loss and acc of batch 48: 47.80054473876953, 1.0\n",
      "Train loss and acc of batch 49: 47.800540924072266, 1.0\n",
      "Train loss and acc of batch 50: 48.39622497558594, 0.984375\n",
      "Train loss and acc of batch 51: 49.149444580078125, 0.96875\n",
      "Train loss and acc of batch 52: 49.05634689331055, 0.953125\n",
      "Train loss and acc of batch 53: 47.80050277709961, 1.0\n",
      "Train loss and acc of batch 54: 48.01725769042969, 0.984375\n",
      "Train loss and acc of batch 55: 47.80048370361328, 1.0\n",
      "Train loss and acc of batch 56: 47.800472259521484, 1.0\n",
      "Train loss and acc of batch 57: 48.39616394042969, 0.984375\n",
      "Train loss and acc of batch 58: 47.800453186035156, 1.0\n",
      "Train loss and acc of batch 59: 47.80044937133789, 1.0\n",
      "Train loss and acc of batch 60: 47.800437927246094, 1.0\n",
      "Train loss and acc of batch 61: 47.8004264831543, 1.0\n",
      "Train loss and acc of batch 62: 47.800418853759766, 1.0\n",
      "Train loss and acc of batch 63: 48.991817474365234, 0.96875\n",
      "Train loss and acc of batch 64: 48.01716613769531, 0.984375\n",
      "Train loss and acc of batch 65: 47.80039596557617, 1.0\n",
      "Train loss and acc of batch 66: 47.80038833618164, 1.0\n",
      "Train loss and acc of batch 67: 48.61284255981445, 0.96875\n",
      "Train loss and acc of batch 68: 48.39607238769531, 0.984375\n",
      "Train loss and acc of batch 69: 48.017120361328125, 0.984375\n",
      "Train loss and acc of batch 70: 47.80034637451172, 1.0\n",
      "Training accuracy and loss of epoch #408: 0.9897, 48.1215\n",
      "Saved model by train loss 48.12154404546173\n",
      "Train loss and acc of batch 0: 47.80034255981445, 1.0\n",
      "Train loss and acc of batch 1: 47.80033493041992, 1.0\n",
      "Train loss and acc of batch 2: 47.800323486328125, 1.0\n",
      "Train loss and acc of batch 3: 48.01708221435547, 0.984375\n",
      "Train loss and acc of batch 4: 47.8003044128418, 1.0\n",
      "Train loss and acc of batch 5: 49.14922332763672, 0.96875\n",
      "Train loss and acc of batch 6: 48.30290603637695, 0.96875\n",
      "Train loss and acc of batch 7: 47.80027770996094, 1.0\n",
      "Train loss and acc of batch 8: 48.395973205566406, 0.984375\n",
      "Train loss and acc of batch 9: 48.08612060546875, 0.984375\n",
      "Train loss and acc of batch 10: 47.80025100708008, 1.0\n",
      "Train loss and acc of batch 11: 47.80024719238281, 1.0\n",
      "Train loss and acc of batch 12: 48.5534553527832, 0.984375\n",
      "Train loss and acc of batch 13: 48.01698303222656, 0.984375\n",
      "Train loss and acc of batch 14: 48.01698303222656, 0.984375\n",
      "Train loss and acc of batch 15: 48.395904541015625, 0.984375\n",
      "Train loss and acc of batch 16: 48.395896911621094, 0.984375\n",
      "Train loss and acc of batch 17: 48.55341339111328, 0.984375\n",
      "Train loss and acc of batch 18: 48.68173599243164, 0.96875\n",
      "Train loss and acc of batch 19: 47.800174713134766, 1.0\n",
      "Train loss and acc of batch 20: 47.80016326904297, 1.0\n",
      "Train loss and acc of batch 21: 48.39585876464844, 0.984375\n",
      "Train loss and acc of batch 22: 48.395843505859375, 0.984375\n",
      "Train loss and acc of batch 23: 47.800140380859375, 1.0\n",
      "Train loss and acc of batch 24: 48.39582824707031, 0.984375\n",
      "Train loss and acc of batch 25: 47.80012130737305, 1.0\n",
      "Train loss and acc of batch 26: 47.80010986328125, 1.0\n",
      "Train loss and acc of batch 27: 47.80009460449219, 1.0\n",
      "Train loss and acc of batch 28: 47.80009078979492, 1.0\n",
      "Train loss and acc of batch 29: 48.395782470703125, 0.984375\n",
      "Train loss and acc of batch 30: 47.80007553100586, 1.0\n",
      "Train loss and acc of batch 31: 48.01683807373047, 0.984375\n",
      "Train loss and acc of batch 32: 47.80005645751953, 1.0\n",
      "Train loss and acc of batch 33: 47.800048828125, 1.0\n",
      "Train loss and acc of batch 34: 48.39574432373047, 0.984375\n",
      "Train loss and acc of batch 35: 48.23355484008789, 0.96875\n",
      "Train loss and acc of batch 36: 47.800018310546875, 1.0\n",
      "Train loss and acc of batch 37: 48.55323791503906, 0.984375\n",
      "Train loss and acc of batch 38: 49.14892578125, 0.96875\n",
      "Train loss and acc of batch 39: 48.016761779785156, 0.984375\n",
      "Train loss and acc of batch 40: 47.799991607666016, 1.0\n",
      "Train loss and acc of batch 41: 49.14889907836914, 0.96875\n",
      "Train loss and acc of batch 42: 47.79996871948242, 1.0\n",
      "Train loss and acc of batch 43: 48.395652770996094, 0.984375\n",
      "Train loss and acc of batch 44: 47.799949645996094, 1.0\n",
      "Train loss and acc of batch 45: 48.39564514160156, 0.984375\n",
      "Train loss and acc of batch 46: 48.085777282714844, 0.984375\n",
      "Train loss and acc of batch 47: 47.799922943115234, 1.0\n",
      "Train loss and acc of batch 48: 47.79991912841797, 1.0\n",
      "Train loss and acc of batch 49: 47.79990005493164, 1.0\n",
      "Train loss and acc of batch 50: 48.395599365234375, 0.984375\n",
      "Train loss and acc of batch 51: 49.14881134033203, 0.96875\n",
      "Train loss and acc of batch 52: 49.05571746826172, 0.953125\n",
      "Train loss and acc of batch 53: 47.799869537353516, 1.0\n",
      "Train loss and acc of batch 54: 48.016632080078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.79985046386719, 1.0\n",
      "Train loss and acc of batch 56: 47.79984664916992, 1.0\n",
      "Train loss and acc of batch 57: 48.395530700683594, 0.984375\n",
      "Train loss and acc of batch 58: 47.79982376098633, 1.0\n",
      "Train loss and acc of batch 59: 47.79981994628906, 1.0\n",
      "Train loss and acc of batch 60: 47.7998046875, 1.0\n",
      "Train loss and acc of batch 61: 47.79979705810547, 1.0\n",
      "Train loss and acc of batch 62: 47.79979705810547, 1.0\n",
      "Train loss and acc of batch 63: 48.991180419921875, 0.96875\n",
      "Train loss and acc of batch 64: 48.01653289794922, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 47.799766540527344, 1.0\n",
      "Train loss and acc of batch 66: 47.79975128173828, 1.0\n",
      "Train loss and acc of batch 67: 48.612213134765625, 0.96875\n",
      "Train loss and acc of batch 68: 48.39544677734375, 0.984375\n",
      "Train loss and acc of batch 69: 48.01649475097656, 0.984375\n",
      "Train loss and acc of batch 70: 47.799720764160156, 1.0\n",
      "Training accuracy and loss of epoch #409: 0.9897, 48.1209\n",
      "Saved model by train loss 48.1209135458503\n",
      "Train loss and acc of batch 0: 47.799705505371094, 1.0\n",
      "Train loss and acc of batch 1: 47.79969787597656, 1.0\n",
      "Train loss and acc of batch 2: 47.7996940612793, 1.0\n",
      "Train loss and acc of batch 3: 48.016448974609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.79967498779297, 1.0\n",
      "Train loss and acc of batch 5: 49.148597717285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.302276611328125, 0.96875\n",
      "Train loss and acc of batch 7: 47.799644470214844, 1.0\n",
      "Train loss and acc of batch 8: 48.39533996582031, 0.984375\n",
      "Train loss and acc of batch 9: 48.085479736328125, 0.984375\n",
      "Train loss and acc of batch 10: 47.79962158203125, 1.0\n",
      "Train loss and acc of batch 11: 47.799617767333984, 1.0\n",
      "Train loss and acc of batch 12: 48.552825927734375, 0.984375\n",
      "Train loss and acc of batch 13: 48.01636505126953, 0.984375\n",
      "Train loss and acc of batch 14: 48.016357421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.39527893066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.39527130126953, 0.984375\n",
      "Train loss and acc of batch 17: 48.55278015136719, 0.984375\n",
      "Train loss and acc of batch 18: 48.68110656738281, 0.96875\n",
      "Train loss and acc of batch 19: 47.79954528808594, 1.0\n",
      "Train loss and acc of batch 20: 47.799537658691406, 1.0\n",
      "Train loss and acc of batch 21: 48.395225524902344, 0.984375\n",
      "Train loss and acc of batch 22: 48.39521789550781, 0.984375\n",
      "Train loss and acc of batch 23: 47.799503326416016, 1.0\n",
      "Train loss and acc of batch 24: 48.39520263671875, 0.984375\n",
      "Train loss and acc of batch 25: 47.79949188232422, 1.0\n",
      "Train loss and acc of batch 26: 47.799476623535156, 1.0\n",
      "Train loss and acc of batch 27: 47.799468994140625, 1.0\n",
      "Train loss and acc of batch 28: 47.79946517944336, 1.0\n",
      "Train loss and acc of batch 29: 48.39515686035156, 0.984375\n",
      "Train loss and acc of batch 30: 47.79944610595703, 1.0\n",
      "Train loss and acc of batch 31: 48.016204833984375, 0.984375\n",
      "Train loss and acc of batch 32: 47.7994270324707, 1.0\n",
      "Train loss and acc of batch 33: 47.79941940307617, 1.0\n",
      "Train loss and acc of batch 34: 48.395111083984375, 0.984375\n",
      "Train loss and acc of batch 35: 48.23292922973633, 0.96875\n",
      "Train loss and acc of batch 36: 47.79938888549805, 1.0\n",
      "Train loss and acc of batch 37: 48.55260467529297, 0.984375\n",
      "Train loss and acc of batch 38: 49.14830017089844, 0.96875\n",
      "Train loss and acc of batch 39: 48.01612854003906, 0.984375\n",
      "Train loss and acc of batch 40: 47.79935073852539, 1.0\n",
      "Train loss and acc of batch 41: 49.14827346801758, 0.96875\n",
      "Train loss and acc of batch 42: 47.79934310913086, 1.0\n",
      "Train loss and acc of batch 43: 48.39502716064453, 0.984375\n",
      "Train loss and acc of batch 44: 47.799320220947266, 1.0\n",
      "Train loss and acc of batch 45: 48.39501190185547, 0.984375\n",
      "Train loss and acc of batch 46: 48.08515167236328, 0.984375\n",
      "Train loss and acc of batch 47: 47.79929733276367, 1.0\n",
      "Train loss and acc of batch 48: 47.79928207397461, 1.0\n",
      "Train loss and acc of batch 49: 47.79927444458008, 1.0\n",
      "Train loss and acc of batch 50: 48.39497375488281, 0.984375\n",
      "Train loss and acc of batch 51: 49.14817810058594, 0.96875\n",
      "Train loss and acc of batch 52: 49.05508804321289, 0.953125\n",
      "Train loss and acc of batch 53: 47.79924392700195, 1.0\n",
      "Train loss and acc of batch 54: 48.0159912109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.79922103881836, 1.0\n",
      "Train loss and acc of batch 56: 47.79921340942383, 1.0\n",
      "Train loss and acc of batch 57: 48.39491271972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.7991943359375, 1.0\n",
      "Train loss and acc of batch 59: 47.79918670654297, 1.0\n",
      "Train loss and acc of batch 60: 47.79917526245117, 1.0\n",
      "Train loss and acc of batch 61: 47.799171447753906, 1.0\n",
      "Train loss and acc of batch 62: 47.79916000366211, 1.0\n",
      "Train loss and acc of batch 63: 48.99055099487305, 0.96875\n",
      "Train loss and acc of batch 64: 48.015907287597656, 0.984375\n",
      "Train loss and acc of batch 65: 47.79913330078125, 1.0\n",
      "Train loss and acc of batch 66: 47.79912567138672, 1.0\n",
      "Train loss and acc of batch 67: 48.611576080322266, 0.96875\n",
      "Train loss and acc of batch 68: 48.394805908203125, 0.984375\n",
      "Train loss and acc of batch 69: 48.01586151123047, 0.984375\n",
      "Train loss and acc of batch 70: 47.79909133911133, 1.0\n",
      "Training accuracy and loss of epoch #410: 0.9897, 48.1203\n",
      "Saved model by train loss 48.12028352979203\n",
      "Train loss and acc of batch 0: 47.79907989501953, 1.0\n",
      "Train loss and acc of batch 1: 47.799072265625, 1.0\n",
      "Train loss and acc of batch 2: 47.7990608215332, 1.0\n",
      "Train loss and acc of batch 3: 48.01581573486328, 0.984375\n",
      "Train loss and acc of batch 4: 47.799049377441406, 1.0\n",
      "Train loss and acc of batch 5: 49.14795684814453, 0.96875\n",
      "Train loss and acc of batch 6: 48.30164337158203, 0.96875\n",
      "Train loss and acc of batch 7: 47.79901885986328, 1.0\n",
      "Train loss and acc of batch 8: 48.39470672607422, 0.984375\n",
      "Train loss and acc of batch 9: 48.08485412597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.79899215698242, 1.0\n",
      "Train loss and acc of batch 11: 47.798980712890625, 1.0\n",
      "Train loss and acc of batch 12: 48.55219650268555, 0.984375\n",
      "Train loss and acc of batch 13: 48.01573181152344, 0.984375\n",
      "Train loss and acc of batch 14: 48.015724182128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.3946533203125, 0.984375\n",
      "Train loss and acc of batch 16: 48.39463806152344, 0.984375\n",
      "Train loss and acc of batch 17: 48.55215072631836, 0.984375\n",
      "Train loss and acc of batch 18: 48.68047332763672, 0.96875\n",
      "Train loss and acc of batch 19: 47.79890823364258, 1.0\n",
      "Train loss and acc of batch 20: 47.79890060424805, 1.0\n",
      "Train loss and acc of batch 21: 48.39459991455078, 0.984375\n",
      "Train loss and acc of batch 22: 48.39458465576172, 0.984375\n",
      "Train loss and acc of batch 23: 47.79887771606445, 1.0\n",
      "Train loss and acc of batch 24: 48.394569396972656, 0.984375\n",
      "Train loss and acc of batch 25: 47.79885482788086, 1.0\n",
      "Train loss and acc of batch 26: 47.79884719848633, 1.0\n",
      "Train loss and acc of batch 27: 47.79884338378906, 1.0\n",
      "Train loss and acc of batch 28: 47.798831939697266, 1.0\n",
      "Train loss and acc of batch 29: 48.39452362060547, 0.984375\n",
      "Train loss and acc of batch 30: 47.79881286621094, 1.0\n",
      "Train loss and acc of batch 31: 48.01556396484375, 0.984375\n",
      "Train loss and acc of batch 32: 47.798797607421875, 1.0\n",
      "Train loss and acc of batch 33: 47.79878234863281, 1.0\n",
      "Train loss and acc of batch 34: 48.39447784423828, 0.984375\n",
      "Train loss and acc of batch 35: 48.2322998046875, 0.96875\n",
      "Train loss and acc of batch 36: 47.79875946044922, 1.0\n",
      "Train loss and acc of batch 37: 48.55197525024414, 0.984375\n",
      "Train loss and acc of batch 38: 49.147666931152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.01549530029297, 0.984375\n",
      "Train loss and acc of batch 40: 47.79872512817383, 1.0\n",
      "Train loss and acc of batch 41: 49.147647857666016, 0.96875\n",
      "Train loss and acc of batch 42: 47.798709869384766, 1.0\n",
      "Train loss and acc of batch 43: 48.39440155029297, 0.984375\n",
      "Train loss and acc of batch 44: 47.79869079589844, 1.0\n",
      "Train loss and acc of batch 45: 48.394378662109375, 0.984375\n",
      "Train loss and acc of batch 46: 48.08452606201172, 0.984375\n",
      "Train loss and acc of batch 47: 47.79866027832031, 1.0\n",
      "Train loss and acc of batch 48: 47.79865264892578, 1.0\n",
      "Train loss and acc of batch 49: 47.798648834228516, 1.0\n",
      "Train loss and acc of batch 50: 48.39434051513672, 0.984375\n",
      "Train loss and acc of batch 51: 49.147552490234375, 0.96875\n",
      "Train loss and acc of batch 52: 49.0544548034668, 0.953125\n",
      "Train loss and acc of batch 53: 47.798606872558594, 1.0\n",
      "Train loss and acc of batch 54: 48.01536560058594, 0.984375\n",
      "Train loss and acc of batch 55: 47.79859161376953, 1.0\n",
      "Train loss and acc of batch 56: 47.798583984375, 1.0\n",
      "Train loss and acc of batch 57: 48.39427185058594, 0.984375\n",
      "Train loss and acc of batch 58: 47.79856491088867, 1.0\n",
      "Train loss and acc of batch 59: 47.79855728149414, 1.0\n",
      "Train loss and acc of batch 60: 47.79854965209961, 1.0\n",
      "Train loss and acc of batch 61: 47.79853439331055, 1.0\n",
      "Train loss and acc of batch 62: 47.798526763916016, 1.0\n",
      "Train loss and acc of batch 63: 48.98992156982422, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 64: 48.015281677246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.79850769042969, 1.0\n",
      "Train loss and acc of batch 66: 47.798500061035156, 1.0\n",
      "Train loss and acc of batch 67: 48.61094665527344, 0.96875\n",
      "Train loss and acc of batch 68: 48.39418029785156, 0.984375\n",
      "Train loss and acc of batch 69: 48.015228271484375, 0.984375\n",
      "Train loss and acc of batch 70: 47.79845428466797, 1.0\n",
      "Training accuracy and loss of epoch #411: 0.9897, 48.1197\n",
      "Saved model by train loss 48.11965260035555\n",
      "Train loss and acc of batch 0: 47.7984504699707, 1.0\n",
      "Train loss and acc of batch 1: 47.79844284057617, 1.0\n",
      "Train loss and acc of batch 2: 47.798431396484375, 1.0\n",
      "Train loss and acc of batch 3: 48.01519012451172, 0.984375\n",
      "Train loss and acc of batch 4: 47.79841613769531, 1.0\n",
      "Train loss and acc of batch 5: 49.14733123779297, 0.96875\n",
      "Train loss and acc of batch 6: 48.3010139465332, 0.96875\n",
      "Train loss and acc of batch 7: 47.79838562011719, 1.0\n",
      "Train loss and acc of batch 8: 48.394081115722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.08422088623047, 0.984375\n",
      "Train loss and acc of batch 10: 47.79835891723633, 1.0\n",
      "Train loss and acc of batch 11: 47.7983512878418, 1.0\n",
      "Train loss and acc of batch 12: 48.55156707763672, 0.984375\n",
      "Train loss and acc of batch 13: 48.01509094238281, 0.984375\n",
      "Train loss and acc of batch 14: 48.01509094238281, 0.984375\n",
      "Train loss and acc of batch 15: 48.394012451171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.394012451171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.5515251159668, 0.984375\n",
      "Train loss and acc of batch 18: 48.67983627319336, 0.96875\n",
      "Train loss and acc of batch 19: 47.79827880859375, 1.0\n",
      "Train loss and acc of batch 20: 47.798274993896484, 1.0\n",
      "Train loss and acc of batch 21: 48.39396667480469, 0.984375\n",
      "Train loss and acc of batch 22: 48.393959045410156, 0.984375\n",
      "Train loss and acc of batch 23: 47.798248291015625, 1.0\n",
      "Train loss and acc of batch 24: 48.39393615722656, 0.984375\n",
      "Train loss and acc of batch 25: 47.79822540283203, 1.0\n",
      "Train loss and acc of batch 26: 47.7982177734375, 1.0\n",
      "Train loss and acc of batch 27: 47.7982063293457, 1.0\n",
      "Train loss and acc of batch 28: 47.79819869995117, 1.0\n",
      "Train loss and acc of batch 29: 48.393890380859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.79818344116211, 1.0\n",
      "Train loss and acc of batch 31: 48.01493835449219, 0.984375\n",
      "Train loss and acc of batch 32: 47.79816436767578, 1.0\n",
      "Train loss and acc of batch 33: 47.79815673828125, 1.0\n",
      "Train loss and acc of batch 34: 48.39385223388672, 0.984375\n",
      "Train loss and acc of batch 35: 48.231666564941406, 0.96875\n",
      "Train loss and acc of batch 36: 47.79813003540039, 1.0\n",
      "Train loss and acc of batch 37: 48.55134201049805, 0.984375\n",
      "Train loss and acc of batch 38: 49.14703369140625, 0.96875\n",
      "Train loss and acc of batch 39: 48.014869689941406, 0.984375\n",
      "Train loss and acc of batch 40: 47.798091888427734, 1.0\n",
      "Train loss and acc of batch 41: 49.14701461791992, 0.96875\n",
      "Train loss and acc of batch 42: 47.798072814941406, 1.0\n",
      "Train loss and acc of batch 43: 48.393768310546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.798057556152344, 1.0\n",
      "Train loss and acc of batch 45: 48.39375305175781, 0.984375\n",
      "Train loss and acc of batch 46: 48.083892822265625, 0.984375\n",
      "Train loss and acc of batch 47: 47.798030853271484, 1.0\n",
      "Train loss and acc of batch 48: 47.79802322387695, 1.0\n",
      "Train loss and acc of batch 49: 47.79801559448242, 1.0\n",
      "Train loss and acc of batch 50: 48.393707275390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.14692687988281, 0.96875\n",
      "Train loss and acc of batch 52: 49.05382537841797, 0.953125\n",
      "Train loss and acc of batch 53: 47.79798126220703, 1.0\n",
      "Train loss and acc of batch 54: 48.014732360839844, 0.984375\n",
      "Train loss and acc of batch 55: 47.7979621887207, 1.0\n",
      "Train loss and acc of batch 56: 47.797950744628906, 1.0\n",
      "Train loss and acc of batch 57: 48.393646240234375, 0.984375\n",
      "Train loss and acc of batch 58: 47.79793167114258, 1.0\n",
      "Train loss and acc of batch 59: 47.79792785644531, 1.0\n",
      "Train loss and acc of batch 60: 47.797916412353516, 1.0\n",
      "Train loss and acc of batch 61: 47.797908782958984, 1.0\n",
      "Train loss and acc of batch 62: 47.79789733886719, 1.0\n",
      "Train loss and acc of batch 63: 48.989295959472656, 0.96875\n",
      "Train loss and acc of batch 64: 48.0146484375, 0.984375\n",
      "Train loss and acc of batch 65: 47.797874450683594, 1.0\n",
      "Train loss and acc of batch 66: 47.7978630065918, 1.0\n",
      "Train loss and acc of batch 67: 48.610321044921875, 0.96875\n",
      "Train loss and acc of batch 68: 48.3935546875, 0.984375\n",
      "Train loss and acc of batch 69: 48.01460266113281, 0.984375\n",
      "Train loss and acc of batch 70: 47.797828674316406, 1.0\n",
      "Training accuracy and loss of epoch #412: 0.9897, 48.1190\n",
      "Saved model by train loss 48.11902215447224\n",
      "Train loss and acc of batch 0: 47.79781723022461, 1.0\n",
      "Train loss and acc of batch 1: 47.79780960083008, 1.0\n",
      "Train loss and acc of batch 2: 47.79780197143555, 1.0\n",
      "Train loss and acc of batch 3: 48.014556884765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.79778289794922, 1.0\n",
      "Train loss and acc of batch 5: 49.146697998046875, 0.96875\n",
      "Train loss and acc of batch 6: 48.30038070678711, 0.96875\n",
      "Train loss and acc of batch 7: 47.797760009765625, 1.0\n",
      "Train loss and acc of batch 8: 48.39344787597656, 0.984375\n",
      "Train loss and acc of batch 9: 48.083587646484375, 0.984375\n",
      "Train loss and acc of batch 10: 47.7977294921875, 1.0\n",
      "Train loss and acc of batch 11: 47.797725677490234, 1.0\n",
      "Train loss and acc of batch 12: 48.55093765258789, 0.984375\n",
      "Train loss and acc of batch 13: 48.01447296142578, 0.984375\n",
      "Train loss and acc of batch 14: 48.01446533203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.39338684082031, 0.984375\n",
      "Train loss and acc of batch 16: 48.39337921142578, 0.984375\n",
      "Train loss and acc of batch 17: 48.5508918762207, 0.984375\n",
      "Train loss and acc of batch 18: 48.6792106628418, 0.96875\n",
      "Train loss and acc of batch 19: 47.79765319824219, 1.0\n",
      "Train loss and acc of batch 20: 47.79764175415039, 1.0\n",
      "Train loss and acc of batch 21: 48.393333435058594, 0.984375\n",
      "Train loss and acc of batch 22: 48.39332580566406, 0.984375\n",
      "Train loss and acc of batch 23: 47.797611236572266, 1.0\n",
      "Train loss and acc of batch 24: 48.393310546875, 0.984375\n",
      "Train loss and acc of batch 25: 47.797603607177734, 1.0\n",
      "Train loss and acc of batch 26: 47.79758834838867, 1.0\n",
      "Train loss and acc of batch 27: 47.797576904296875, 1.0\n",
      "Train loss and acc of batch 28: 47.79757308959961, 1.0\n",
      "Train loss and acc of batch 29: 48.39326477050781, 0.984375\n",
      "Train loss and acc of batch 30: 47.797550201416016, 1.0\n",
      "Train loss and acc of batch 31: 48.014305114746094, 0.984375\n",
      "Train loss and acc of batch 32: 47.79753494262695, 1.0\n",
      "Train loss and acc of batch 33: 47.79753112792969, 1.0\n",
      "Train loss and acc of batch 34: 48.393218994140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.23103713989258, 0.96875\n",
      "Train loss and acc of batch 36: 47.79750061035156, 1.0\n",
      "Train loss and acc of batch 37: 48.55070877075195, 0.984375\n",
      "Train loss and acc of batch 38: 49.14640808105469, 0.96875\n",
      "Train loss and acc of batch 39: 48.014244079589844, 0.984375\n",
      "Train loss and acc of batch 40: 47.79746627807617, 1.0\n",
      "Train loss and acc of batch 41: 49.14637756347656, 0.96875\n",
      "Train loss and acc of batch 42: 47.79744338989258, 1.0\n",
      "Train loss and acc of batch 43: 48.39313507080078, 0.984375\n",
      "Train loss and acc of batch 44: 47.79743194580078, 1.0\n",
      "Train loss and acc of batch 45: 48.39311981201172, 0.984375\n",
      "Train loss and acc of batch 46: 48.08325958251953, 0.984375\n",
      "Train loss and acc of batch 47: 47.797401428222656, 1.0\n",
      "Train loss and acc of batch 48: 47.797393798828125, 1.0\n",
      "Train loss and acc of batch 49: 47.79738235473633, 1.0\n",
      "Train loss and acc of batch 50: 48.39307403564453, 0.984375\n",
      "Train loss and acc of batch 51: 49.14628601074219, 0.96875\n",
      "Train loss and acc of batch 52: 49.053199768066406, 0.953125\n",
      "Train loss and acc of batch 53: 47.7973518371582, 1.0\n",
      "Train loss and acc of batch 54: 48.01410675048828, 0.984375\n",
      "Train loss and acc of batch 55: 47.797332763671875, 1.0\n",
      "Train loss and acc of batch 56: 47.797325134277344, 1.0\n",
      "Train loss and acc of batch 57: 48.39301300048828, 0.984375\n",
      "Train loss and acc of batch 58: 47.797306060791016, 1.0\n",
      "Train loss and acc of batch 59: 47.797298431396484, 1.0\n",
      "Train loss and acc of batch 60: 47.79728317260742, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 61: 47.797279357910156, 1.0\n",
      "Train loss and acc of batch 62: 47.79726791381836, 1.0\n",
      "Train loss and acc of batch 63: 48.9886589050293, 0.96875\n",
      "Train loss and acc of batch 64: 48.014015197753906, 0.984375\n",
      "Train loss and acc of batch 65: 47.7972412109375, 1.0\n",
      "Train loss and acc of batch 66: 47.79723358154297, 1.0\n",
      "Train loss and acc of batch 67: 48.60969161987305, 0.96875\n",
      "Train loss and acc of batch 68: 48.392913818359375, 0.984375\n",
      "Train loss and acc of batch 69: 48.01396942138672, 0.984375\n",
      "Train loss and acc of batch 70: 47.797203063964844, 1.0\n",
      "Training accuracy and loss of epoch #413: 0.9897, 48.1184\n",
      "Saved model by train loss 48.118391923501456\n",
      "Train loss and acc of batch 0: 47.79718780517578, 1.0\n",
      "Train loss and acc of batch 1: 47.79718017578125, 1.0\n",
      "Train loss and acc of batch 2: 47.79716873168945, 1.0\n",
      "Train loss and acc of batch 3: 48.01392364501953, 0.984375\n",
      "Train loss and acc of batch 4: 47.79715347290039, 1.0\n",
      "Train loss and acc of batch 5: 49.14607238769531, 0.96875\n",
      "Train loss and acc of batch 6: 48.29975128173828, 0.96875\n",
      "Train loss and acc of batch 7: 47.79712677001953, 1.0\n",
      "Train loss and acc of batch 8: 48.39281463623047, 0.984375\n",
      "Train loss and acc of batch 9: 48.08296203613281, 0.984375\n",
      "Train loss and acc of batch 10: 47.79710006713867, 1.0\n",
      "Train loss and acc of batch 11: 47.797088623046875, 1.0\n",
      "Train loss and acc of batch 12: 48.55030822753906, 0.984375\n",
      "Train loss and acc of batch 13: 48.01383972167969, 0.984375\n",
      "Train loss and acc of batch 14: 48.013832092285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.39276123046875, 0.984375\n",
      "Train loss and acc of batch 16: 48.39275360107422, 0.984375\n",
      "Train loss and acc of batch 17: 48.55025863647461, 0.984375\n",
      "Train loss and acc of batch 18: 48.678585052490234, 0.96875\n",
      "Train loss and acc of batch 19: 47.79701614379883, 1.0\n",
      "Train loss and acc of batch 20: 47.79701232910156, 1.0\n",
      "Train loss and acc of batch 21: 48.3927001953125, 0.984375\n",
      "Train loss and acc of batch 22: 48.39269256591797, 0.984375\n",
      "Train loss and acc of batch 23: 47.79698181152344, 1.0\n",
      "Train loss and acc of batch 24: 48.392677307128906, 0.984375\n",
      "Train loss and acc of batch 25: 47.796966552734375, 1.0\n",
      "Train loss and acc of batch 26: 47.796958923339844, 1.0\n",
      "Train loss and acc of batch 27: 47.79695129394531, 1.0\n",
      "Train loss and acc of batch 28: 47.79694366455078, 1.0\n",
      "Train loss and acc of batch 29: 48.39263153076172, 0.984375\n",
      "Train loss and acc of batch 30: 47.79692459106445, 1.0\n",
      "Train loss and acc of batch 31: 48.01367950439453, 0.984375\n",
      "Train loss and acc of batch 32: 47.79690933227539, 1.0\n",
      "Train loss and acc of batch 33: 47.79689407348633, 1.0\n",
      "Train loss and acc of batch 34: 48.39258575439453, 0.984375\n",
      "Train loss and acc of batch 35: 48.23040771484375, 0.96875\n",
      "Train loss and acc of batch 36: 47.7968635559082, 1.0\n",
      "Train loss and acc of batch 37: 48.55008316040039, 0.984375\n",
      "Train loss and acc of batch 38: 49.145774841308594, 0.96875\n",
      "Train loss and acc of batch 39: 48.01360321044922, 0.984375\n",
      "Train loss and acc of batch 40: 47.79683303833008, 1.0\n",
      "Train loss and acc of batch 41: 49.145751953125, 0.96875\n",
      "Train loss and acc of batch 42: 47.796817779541016, 1.0\n",
      "Train loss and acc of batch 43: 48.39250946044922, 0.984375\n",
      "Train loss and acc of batch 44: 47.796791076660156, 1.0\n",
      "Train loss and acc of batch 45: 48.392486572265625, 0.984375\n",
      "Train loss and acc of batch 46: 48.08263397216797, 0.984375\n",
      "Train loss and acc of batch 47: 47.79677200317383, 1.0\n",
      "Train loss and acc of batch 48: 47.7967643737793, 1.0\n",
      "Train loss and acc of batch 49: 47.796756744384766, 1.0\n",
      "Train loss and acc of batch 50: 48.39244842529297, 0.984375\n",
      "Train loss and acc of batch 51: 49.145660400390625, 0.96875\n",
      "Train loss and acc of batch 52: 49.05256652832031, 0.953125\n",
      "Train loss and acc of batch 53: 47.796714782714844, 1.0\n",
      "Train loss and acc of batch 54: 48.01347351074219, 0.984375\n",
      "Train loss and acc of batch 55: 47.79670333862305, 1.0\n",
      "Train loss and acc of batch 56: 47.79669189453125, 1.0\n",
      "Train loss and acc of batch 57: 48.39238739013672, 0.984375\n",
      "Train loss and acc of batch 58: 47.79667282104492, 1.0\n",
      "Train loss and acc of batch 59: 47.796661376953125, 1.0\n",
      "Train loss and acc of batch 60: 47.79665756225586, 1.0\n",
      "Train loss and acc of batch 61: 47.79664611816406, 1.0\n",
      "Train loss and acc of batch 62: 47.796634674072266, 1.0\n",
      "Train loss and acc of batch 63: 48.988033294677734, 0.96875\n",
      "Train loss and acc of batch 64: 48.013389587402344, 0.984375\n",
      "Train loss and acc of batch 65: 47.796607971191406, 1.0\n",
      "Train loss and acc of batch 66: 47.796600341796875, 1.0\n",
      "Train loss and acc of batch 67: 48.60905456542969, 0.96875\n",
      "Train loss and acc of batch 68: 48.39228057861328, 0.984375\n",
      "Train loss and acc of batch 69: 48.013336181640625, 0.984375\n",
      "Train loss and acc of batch 70: 47.796566009521484, 1.0\n",
      "Training accuracy and loss of epoch #414: 0.9897, 48.1178\n",
      "Saved model by train loss 48.11776099406497\n",
      "Train loss and acc of batch 0: 47.79656219482422, 1.0\n",
      "Train loss and acc of batch 1: 47.79655075073242, 1.0\n",
      "Train loss and acc of batch 2: 47.79653549194336, 1.0\n",
      "Train loss and acc of batch 3: 48.01329803466797, 0.984375\n",
      "Train loss and acc of batch 4: 47.79652786254883, 1.0\n",
      "Train loss and acc of batch 5: 49.14543914794922, 0.96875\n",
      "Train loss and acc of batch 6: 48.29912185668945, 0.96875\n",
      "Train loss and acc of batch 7: 47.7964973449707, 1.0\n",
      "Train loss and acc of batch 8: 48.392189025878906, 0.984375\n",
      "Train loss and acc of batch 9: 48.08232879638672, 0.984375\n",
      "Train loss and acc of batch 10: 47.79646301269531, 1.0\n",
      "Train loss and acc of batch 11: 47.79645919799805, 1.0\n",
      "Train loss and acc of batch 12: 48.549678802490234, 0.984375\n",
      "Train loss and acc of batch 13: 48.013206481933594, 0.984375\n",
      "Train loss and acc of batch 14: 48.01319885253906, 0.984375\n",
      "Train loss and acc of batch 15: 48.392127990722656, 0.984375\n",
      "Train loss and acc of batch 16: 48.392112731933594, 0.984375\n",
      "Train loss and acc of batch 17: 48.54963302612305, 0.984375\n",
      "Train loss and acc of batch 18: 48.677955627441406, 0.96875\n",
      "Train loss and acc of batch 19: 47.79638671875, 1.0\n",
      "Train loss and acc of batch 20: 47.79637908935547, 1.0\n",
      "Train loss and acc of batch 21: 48.392066955566406, 0.984375\n",
      "Train loss and acc of batch 22: 48.392066955566406, 0.984375\n",
      "Train loss and acc of batch 23: 47.79636001586914, 1.0\n",
      "Train loss and acc of batch 24: 48.39204406738281, 0.984375\n",
      "Train loss and acc of batch 25: 47.79633331298828, 1.0\n",
      "Train loss and acc of batch 26: 47.796329498291016, 1.0\n",
      "Train loss and acc of batch 27: 47.79631805419922, 1.0\n",
      "Train loss and acc of batch 28: 47.79630661010742, 1.0\n",
      "Train loss and acc of batch 29: 48.392005920410156, 0.984375\n",
      "Train loss and acc of batch 30: 47.796287536621094, 1.0\n",
      "Train loss and acc of batch 31: 48.01304626464844, 0.984375\n",
      "Train loss and acc of batch 32: 47.7962760925293, 1.0\n",
      "Train loss and acc of batch 33: 47.796260833740234, 1.0\n",
      "Train loss and acc of batch 34: 48.39196014404297, 0.984375\n",
      "Train loss and acc of batch 35: 48.22978210449219, 0.96875\n",
      "Train loss and acc of batch 36: 47.79623794555664, 1.0\n",
      "Train loss and acc of batch 37: 48.54945755004883, 0.984375\n",
      "Train loss and acc of batch 38: 49.1451416015625, 0.96875\n",
      "Train loss and acc of batch 39: 48.012977600097656, 0.984375\n",
      "Train loss and acc of batch 40: 47.79620361328125, 1.0\n",
      "Train loss and acc of batch 41: 49.145118713378906, 0.96875\n",
      "Train loss and acc of batch 42: 47.79618453979492, 1.0\n",
      "Train loss and acc of batch 43: 48.391876220703125, 0.984375\n",
      "Train loss and acc of batch 44: 47.796165466308594, 1.0\n",
      "Train loss and acc of batch 45: 48.39186096191406, 0.984375\n",
      "Train loss and acc of batch 46: 48.082000732421875, 0.984375\n",
      "Train loss and acc of batch 47: 47.79613494873047, 1.0\n",
      "Train loss and acc of batch 48: 47.7961311340332, 1.0\n",
      "Train loss and acc of batch 49: 47.79612350463867, 1.0\n",
      "Train loss and acc of batch 50: 48.391815185546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.14503479003906, 0.96875\n",
      "Train loss and acc of batch 52: 49.051937103271484, 0.953125\n",
      "Train loss and acc of batch 53: 47.796085357666016, 1.0\n",
      "Train loss and acc of batch 54: 48.012847900390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.79606628417969, 1.0\n",
      "Train loss and acc of batch 56: 47.79606628417969, 1.0\n",
      "Train loss and acc of batch 57: 48.391754150390625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 58: 47.796043395996094, 1.0\n",
      "Train loss and acc of batch 59: 47.7960319519043, 1.0\n",
      "Train loss and acc of batch 60: 47.796024322509766, 1.0\n",
      "Train loss and acc of batch 61: 47.796016693115234, 1.0\n",
      "Train loss and acc of batch 62: 47.7960090637207, 1.0\n",
      "Train loss and acc of batch 63: 48.987403869628906, 0.96875\n",
      "Train loss and acc of batch 64: 48.01275634765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.795982360839844, 1.0\n",
      "Train loss and acc of batch 66: 47.79597091674805, 1.0\n",
      "Train loss and acc of batch 67: 48.60842514038086, 0.96875\n",
      "Train loss and acc of batch 68: 48.39166259765625, 0.984375\n",
      "Train loss and acc of batch 69: 48.01271057128906, 0.984375\n",
      "Train loss and acc of batch 70: 47.79594039916992, 1.0\n",
      "Training accuracy and loss of epoch #415: 0.9897, 48.1171\n",
      "Saved model by train loss 48.117130924278584\n",
      "Train loss and acc of batch 0: 47.795928955078125, 1.0\n",
      "Train loss and acc of batch 1: 47.79591751098633, 1.0\n",
      "Train loss and acc of batch 2: 47.79591369628906, 1.0\n",
      "Train loss and acc of batch 3: 48.012664794921875, 0.984375\n",
      "Train loss and acc of batch 4: 47.79589080810547, 1.0\n",
      "Train loss and acc of batch 5: 49.144805908203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.298492431640625, 0.96875\n",
      "Train loss and acc of batch 7: 47.79586410522461, 1.0\n",
      "Train loss and acc of batch 8: 48.391563415527344, 0.984375\n",
      "Train loss and acc of batch 9: 48.081695556640625, 0.984375\n",
      "Train loss and acc of batch 10: 47.795841217041016, 1.0\n",
      "Train loss and acc of batch 11: 47.79582977294922, 1.0\n",
      "Train loss and acc of batch 12: 48.54904556274414, 0.984375\n",
      "Train loss and acc of batch 13: 48.01258087158203, 0.984375\n",
      "Train loss and acc of batch 14: 48.0125732421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.39149475097656, 0.984375\n",
      "Train loss and acc of batch 16: 48.39148712158203, 0.984375\n",
      "Train loss and acc of batch 17: 48.54899978637695, 0.984375\n",
      "Train loss and acc of batch 18: 48.67732238769531, 0.96875\n",
      "Train loss and acc of batch 19: 47.79575729370117, 1.0\n",
      "Train loss and acc of batch 20: 47.795745849609375, 1.0\n",
      "Train loss and acc of batch 21: 48.391441345214844, 0.984375\n",
      "Train loss and acc of batch 22: 48.39143371582031, 0.984375\n",
      "Train loss and acc of batch 23: 47.79572296142578, 1.0\n",
      "Train loss and acc of batch 24: 48.39141845703125, 0.984375\n",
      "Train loss and acc of batch 25: 47.79570770263672, 1.0\n",
      "Train loss and acc of batch 26: 47.79569625854492, 1.0\n",
      "Train loss and acc of batch 27: 47.79568862915039, 1.0\n",
      "Train loss and acc of batch 28: 47.79568099975586, 1.0\n",
      "Train loss and acc of batch 29: 48.39136505126953, 0.984375\n",
      "Train loss and acc of batch 30: 47.7956657409668, 1.0\n",
      "Train loss and acc of batch 31: 48.012420654296875, 0.984375\n",
      "Train loss and acc of batch 32: 47.79564666748047, 1.0\n",
      "Train loss and acc of batch 33: 47.79563522338867, 1.0\n",
      "Train loss and acc of batch 34: 48.391326904296875, 0.984375\n",
      "Train loss and acc of batch 35: 48.22914505004883, 0.96875\n",
      "Train loss and acc of batch 36: 47.79561233520508, 1.0\n",
      "Train loss and acc of batch 37: 48.54882049560547, 0.984375\n",
      "Train loss and acc of batch 38: 49.14451599121094, 0.96875\n",
      "Train loss and acc of batch 39: 48.01234436035156, 0.984375\n",
      "Train loss and acc of batch 40: 47.795570373535156, 1.0\n",
      "Train loss and acc of batch 41: 49.14448928833008, 0.96875\n",
      "Train loss and acc of batch 42: 47.795555114746094, 1.0\n",
      "Train loss and acc of batch 43: 48.39124298095703, 0.984375\n",
      "Train loss and acc of batch 44: 47.79553985595703, 1.0\n",
      "Train loss and acc of batch 45: 48.3912353515625, 0.984375\n",
      "Train loss and acc of batch 46: 48.08137512207031, 0.984375\n",
      "Train loss and acc of batch 47: 47.795509338378906, 1.0\n",
      "Train loss and acc of batch 48: 47.795501708984375, 1.0\n",
      "Train loss and acc of batch 49: 47.795494079589844, 1.0\n",
      "Train loss and acc of batch 50: 48.39118957519531, 0.984375\n",
      "Train loss and acc of batch 51: 49.14440155029297, 0.96875\n",
      "Train loss and acc of batch 52: 49.05130386352539, 0.953125\n",
      "Train loss and acc of batch 53: 47.79545974731445, 1.0\n",
      "Train loss and acc of batch 54: 48.01220703125, 0.984375\n",
      "Train loss and acc of batch 55: 47.795440673828125, 1.0\n",
      "Train loss and acc of batch 56: 47.79542922973633, 1.0\n",
      "Train loss and acc of batch 57: 48.39112091064453, 0.984375\n",
      "Train loss and acc of batch 58: 47.795413970947266, 1.0\n",
      "Train loss and acc of batch 59: 47.795406341552734, 1.0\n",
      "Train loss and acc of batch 60: 47.79539489746094, 1.0\n",
      "Train loss and acc of batch 61: 47.79539108276367, 1.0\n",
      "Train loss and acc of batch 62: 47.795372009277344, 1.0\n",
      "Train loss and acc of batch 63: 48.98677062988281, 0.96875\n",
      "Train loss and acc of batch 64: 48.012123107910156, 0.984375\n",
      "Train loss and acc of batch 65: 47.795352935791016, 1.0\n",
      "Train loss and acc of batch 66: 47.79533767700195, 1.0\n",
      "Train loss and acc of batch 67: 48.60780334472656, 0.96875\n",
      "Train loss and acc of batch 68: 48.391029357910156, 0.984375\n",
      "Train loss and acc of batch 69: 48.01207733154297, 0.984375\n",
      "Train loss and acc of batch 70: 47.79530334472656, 1.0\n",
      "Training accuracy and loss of epoch #416: 0.9897, 48.1165\n",
      "Saved model by train loss 48.11650063957966\n",
      "Train loss and acc of batch 0: 47.795291900634766, 1.0\n",
      "Train loss and acc of batch 1: 47.7952880859375, 1.0\n",
      "Train loss and acc of batch 2: 47.79528045654297, 1.0\n",
      "Train loss and acc of batch 3: 48.01203155517578, 0.984375\n",
      "Train loss and acc of batch 4: 47.79526138305664, 1.0\n",
      "Train loss and acc of batch 5: 49.14418029785156, 0.96875\n",
      "Train loss and acc of batch 6: 48.29785919189453, 0.96875\n",
      "Train loss and acc of batch 7: 47.79523468017578, 1.0\n",
      "Train loss and acc of batch 8: 48.39092254638672, 0.984375\n",
      "Train loss and acc of batch 9: 48.08106994628906, 0.984375\n",
      "Train loss and acc of batch 10: 47.79521179199219, 1.0\n",
      "Train loss and acc of batch 11: 47.79520034790039, 1.0\n",
      "Train loss and acc of batch 12: 48.54841232299805, 0.984375\n",
      "Train loss and acc of batch 13: 48.01194763183594, 0.984375\n",
      "Train loss and acc of batch 14: 48.011932373046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.390869140625, 0.984375\n",
      "Train loss and acc of batch 16: 48.39086151123047, 0.984375\n",
      "Train loss and acc of batch 17: 48.548370361328125, 0.984375\n",
      "Train loss and acc of batch 18: 48.676692962646484, 0.96875\n",
      "Train loss and acc of batch 19: 47.79513168334961, 1.0\n",
      "Train loss and acc of batch 20: 47.79511642456055, 1.0\n",
      "Train loss and acc of batch 21: 48.39081573486328, 0.984375\n",
      "Train loss and acc of batch 22: 48.39080047607422, 0.984375\n",
      "Train loss and acc of batch 23: 47.79509353637695, 1.0\n",
      "Train loss and acc of batch 24: 48.390785217285156, 0.984375\n",
      "Train loss and acc of batch 25: 47.79507827758789, 1.0\n",
      "Train loss and acc of batch 26: 47.79506301879883, 1.0\n",
      "Train loss and acc of batch 27: 47.79505920410156, 1.0\n",
      "Train loss and acc of batch 28: 47.795047760009766, 1.0\n",
      "Train loss and acc of batch 29: 48.39073944091797, 0.984375\n",
      "Train loss and acc of batch 30: 47.7950325012207, 1.0\n",
      "Train loss and acc of batch 31: 48.01178741455078, 0.984375\n",
      "Train loss and acc of batch 32: 47.795013427734375, 1.0\n",
      "Train loss and acc of batch 33: 47.795005798339844, 1.0\n",
      "Train loss and acc of batch 34: 48.39069366455078, 0.984375\n",
      "Train loss and acc of batch 35: 48.228519439697266, 0.96875\n",
      "Train loss and acc of batch 36: 47.79497528076172, 1.0\n",
      "Train loss and acc of batch 37: 48.54819107055664, 0.984375\n",
      "Train loss and acc of batch 38: 49.143882751464844, 0.96875\n",
      "Train loss and acc of batch 39: 48.01171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.79494094848633, 1.0\n",
      "Train loss and acc of batch 41: 49.14385986328125, 0.96875\n",
      "Train loss and acc of batch 42: 47.794925689697266, 1.0\n",
      "Train loss and acc of batch 43: 48.39061737060547, 0.984375\n",
      "Train loss and acc of batch 44: 47.7949104309082, 1.0\n",
      "Train loss and acc of batch 45: 48.390594482421875, 0.984375\n",
      "Train loss and acc of batch 46: 48.08074188232422, 0.984375\n",
      "Train loss and acc of batch 47: 47.794883728027344, 1.0\n",
      "Train loss and acc of batch 48: 47.79487228393555, 1.0\n",
      "Train loss and acc of batch 49: 47.794864654541016, 1.0\n",
      "Train loss and acc of batch 50: 48.39055633544922, 0.984375\n",
      "Train loss and acc of batch 51: 49.143768310546875, 0.96875\n",
      "Train loss and acc of batch 52: 49.05067825317383, 0.953125\n",
      "Train loss and acc of batch 53: 47.79482650756836, 1.0\n",
      "Train loss and acc of batch 54: 48.01158142089844, 0.984375\n",
      "Train loss and acc of batch 55: 47.7948112487793, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 56: 47.7947998046875, 1.0\n",
      "Train loss and acc of batch 57: 48.39048767089844, 0.984375\n",
      "Train loss and acc of batch 58: 47.79478454589844, 1.0\n",
      "Train loss and acc of batch 59: 47.794776916503906, 1.0\n",
      "Train loss and acc of batch 60: 47.79476547241211, 1.0\n",
      "Train loss and acc of batch 61: 47.79475402832031, 1.0\n",
      "Train loss and acc of batch 62: 47.79475021362305, 1.0\n",
      "Train loss and acc of batch 63: 48.98613739013672, 0.96875\n",
      "Train loss and acc of batch 64: 48.01148986816406, 0.984375\n",
      "Train loss and acc of batch 65: 47.794715881347656, 1.0\n",
      "Train loss and acc of batch 66: 47.79471206665039, 1.0\n",
      "Train loss and acc of batch 67: 48.60717010498047, 0.96875\n",
      "Train loss and acc of batch 68: 48.39039611816406, 0.984375\n",
      "Train loss and acc of batch 69: 48.011451721191406, 0.984375\n",
      "Train loss and acc of batch 70: 47.79467010498047, 1.0\n",
      "Training accuracy and loss of epoch #417: 0.9897, 48.1159\n",
      "Saved model by train loss 48.115869925055705\n",
      "Train loss and acc of batch 0: 47.7946662902832, 1.0\n",
      "Train loss and acc of batch 1: 47.79466247558594, 1.0\n",
      "Train loss and acc of batch 2: 47.794647216796875, 1.0\n",
      "Train loss and acc of batch 3: 48.01140594482422, 0.984375\n",
      "Train loss and acc of batch 4: 47.79463195800781, 1.0\n",
      "Train loss and acc of batch 5: 49.14354705810547, 0.96875\n",
      "Train loss and acc of batch 6: 48.2972297668457, 0.96875\n",
      "Train loss and acc of batch 7: 47.79460525512695, 1.0\n",
      "Train loss and acc of batch 8: 48.390296936035156, 0.984375\n",
      "Train loss and acc of batch 9: 48.08043670654297, 0.984375\n",
      "Train loss and acc of batch 10: 47.794578552246094, 1.0\n",
      "Train loss and acc of batch 11: 47.7945671081543, 1.0\n",
      "Train loss and acc of batch 12: 48.54778289794922, 0.984375\n",
      "Train loss and acc of batch 13: 48.011314392089844, 0.984375\n",
      "Train loss and acc of batch 14: 48.01130676269531, 0.984375\n",
      "Train loss and acc of batch 15: 48.390235900878906, 0.984375\n",
      "Train loss and acc of batch 16: 48.390220642089844, 0.984375\n",
      "Train loss and acc of batch 17: 48.54773712158203, 0.984375\n",
      "Train loss and acc of batch 18: 48.676063537597656, 0.96875\n",
      "Train loss and acc of batch 19: 47.794498443603516, 1.0\n",
      "Train loss and acc of batch 20: 47.794490814208984, 1.0\n",
      "Train loss and acc of batch 21: 48.390174865722656, 0.984375\n",
      "Train loss and acc of batch 22: 48.390167236328125, 0.984375\n",
      "Train loss and acc of batch 23: 47.79446029663086, 1.0\n",
      "Train loss and acc of batch 24: 48.39015197753906, 0.984375\n",
      "Train loss and acc of batch 25: 47.79444122314453, 1.0\n",
      "Train loss and acc of batch 26: 47.79443359375, 1.0\n",
      "Train loss and acc of batch 27: 47.7944221496582, 1.0\n",
      "Train loss and acc of batch 28: 47.794410705566406, 1.0\n",
      "Train loss and acc of batch 29: 48.390106201171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.79439163208008, 1.0\n",
      "Train loss and acc of batch 31: 48.01115417480469, 0.984375\n",
      "Train loss and acc of batch 32: 47.79438018798828, 1.0\n",
      "Train loss and acc of batch 33: 47.79437255859375, 1.0\n",
      "Train loss and acc of batch 34: 48.39006805419922, 0.984375\n",
      "Train loss and acc of batch 35: 48.22789001464844, 0.96875\n",
      "Train loss and acc of batch 36: 47.794342041015625, 1.0\n",
      "Train loss and acc of batch 37: 48.54755783081055, 0.984375\n",
      "Train loss and acc of batch 38: 49.14324951171875, 0.96875\n",
      "Train loss and acc of batch 39: 48.011085510253906, 0.984375\n",
      "Train loss and acc of batch 40: 47.794307708740234, 1.0\n",
      "Train loss and acc of batch 41: 49.14322280883789, 0.96875\n",
      "Train loss and acc of batch 42: 47.79429244995117, 1.0\n",
      "Train loss and acc of batch 43: 48.389984130859375, 0.984375\n",
      "Train loss and acc of batch 44: 47.79426574707031, 1.0\n",
      "Train loss and acc of batch 45: 48.38996124267578, 0.984375\n",
      "Train loss and acc of batch 46: 48.080108642578125, 0.984375\n",
      "Train loss and acc of batch 47: 47.794246673583984, 1.0\n",
      "Train loss and acc of batch 48: 47.79423904418945, 1.0\n",
      "Train loss and acc of batch 49: 47.79422378540039, 1.0\n",
      "Train loss and acc of batch 50: 48.389915466308594, 0.984375\n",
      "Train loss and acc of batch 51: 49.14313507080078, 0.96875\n",
      "Train loss and acc of batch 52: 49.05004119873047, 0.953125\n",
      "Train loss and acc of batch 53: 47.794193267822266, 1.0\n",
      "Train loss and acc of batch 54: 48.010948181152344, 0.984375\n",
      "Train loss and acc of batch 55: 47.79417419433594, 1.0\n",
      "Train loss and acc of batch 56: 47.794166564941406, 1.0\n",
      "Train loss and acc of batch 57: 48.389862060546875, 0.984375\n",
      "Train loss and acc of batch 58: 47.79414367675781, 1.0\n",
      "Train loss and acc of batch 59: 47.79413986206055, 1.0\n",
      "Train loss and acc of batch 60: 47.79412841796875, 1.0\n",
      "Train loss and acc of batch 61: 47.79412078857422, 1.0\n",
      "Train loss and acc of batch 62: 47.79411315917969, 1.0\n",
      "Train loss and acc of batch 63: 48.98551559448242, 0.96875\n",
      "Train loss and acc of batch 64: 48.01085662841797, 0.984375\n",
      "Train loss and acc of batch 65: 47.79408645629883, 1.0\n",
      "Train loss and acc of batch 66: 47.79407501220703, 1.0\n",
      "Train loss and acc of batch 67: 48.606529235839844, 0.96875\n",
      "Train loss and acc of batch 68: 48.38976287841797, 0.984375\n",
      "Train loss and acc of batch 69: 48.01081085205078, 0.984375\n",
      "Train loss and acc of batch 70: 47.79404067993164, 1.0\n",
      "Training accuracy and loss of epoch #418: 0.9897, 48.1152\n",
      "Saved model by train loss 48.11523657785335\n",
      "Train loss and acc of batch 0: 47.794036865234375, 1.0\n",
      "Train loss and acc of batch 1: 47.79401779174805, 1.0\n",
      "Train loss and acc of batch 2: 47.79401397705078, 1.0\n",
      "Train loss and acc of batch 3: 48.010772705078125, 0.984375\n",
      "Train loss and acc of batch 4: 47.79399490356445, 1.0\n",
      "Train loss and acc of batch 5: 49.142913818359375, 0.96875\n",
      "Train loss and acc of batch 6: 48.29659652709961, 0.96875\n",
      "Train loss and acc of batch 7: 47.79397201538086, 1.0\n",
      "Train loss and acc of batch 8: 48.38966369628906, 0.984375\n",
      "Train loss and acc of batch 9: 48.079811096191406, 0.984375\n",
      "Train loss and acc of batch 10: 47.7939453125, 1.0\n",
      "Train loss and acc of batch 11: 47.79393768310547, 1.0\n",
      "Train loss and acc of batch 12: 48.54714584350586, 0.984375\n",
      "Train loss and acc of batch 13: 48.01068115234375, 0.984375\n",
      "Train loss and acc of batch 14: 48.01068115234375, 0.984375\n",
      "Train loss and acc of batch 15: 48.38959503173828, 0.984375\n",
      "Train loss and acc of batch 16: 48.38958740234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.5471076965332, 0.984375\n",
      "Train loss and acc of batch 18: 48.67542266845703, 0.96875\n",
      "Train loss and acc of batch 19: 47.79386520385742, 1.0\n",
      "Train loss and acc of batch 20: 47.79385757446289, 1.0\n",
      "Train loss and acc of batch 21: 48.389549255371094, 0.984375\n",
      "Train loss and acc of batch 22: 48.38953399658203, 0.984375\n",
      "Train loss and acc of batch 23: 47.79383087158203, 1.0\n",
      "Train loss and acc of batch 24: 48.38951873779297, 0.984375\n",
      "Train loss and acc of batch 25: 47.7938117980957, 1.0\n",
      "Train loss and acc of batch 26: 47.79380798339844, 1.0\n",
      "Train loss and acc of batch 27: 47.793792724609375, 1.0\n",
      "Train loss and acc of batch 28: 47.79378890991211, 1.0\n",
      "Train loss and acc of batch 29: 48.38948059082031, 0.984375\n",
      "Train loss and acc of batch 30: 47.793766021728516, 1.0\n",
      "Train loss and acc of batch 31: 48.010520935058594, 0.984375\n",
      "Train loss and acc of batch 32: 47.79374694824219, 1.0\n",
      "Train loss and acc of batch 33: 47.79374313354492, 1.0\n",
      "Train loss and acc of batch 34: 48.389434814453125, 0.984375\n",
      "Train loss and acc of batch 35: 48.22724914550781, 0.96875\n",
      "Train loss and acc of batch 36: 47.7937126159668, 1.0\n",
      "Train loss and acc of batch 37: 48.54693603515625, 0.984375\n",
      "Train loss and acc of batch 38: 49.14262390136719, 0.96875\n",
      "Train loss and acc of batch 39: 48.01045227050781, 0.984375\n",
      "Train loss and acc of batch 40: 47.79367446899414, 1.0\n",
      "Train loss and acc of batch 41: 49.14259338378906, 0.96875\n",
      "Train loss and acc of batch 42: 47.793663024902344, 1.0\n",
      "Train loss and acc of batch 43: 48.38935089111328, 0.984375\n",
      "Train loss and acc of batch 44: 47.793643951416016, 1.0\n",
      "Train loss and acc of batch 45: 48.38933563232422, 0.984375\n",
      "Train loss and acc of batch 46: 48.07947540283203, 0.984375\n",
      "Train loss and acc of batch 47: 47.793617248535156, 1.0\n",
      "Train loss and acc of batch 48: 47.793609619140625, 1.0\n",
      "Train loss and acc of batch 49: 47.79359436035156, 1.0\n",
      "Train loss and acc of batch 50: 48.38928985595703, 0.984375\n",
      "Train loss and acc of batch 51: 49.14250946044922, 0.96875\n",
      "Train loss and acc of batch 52: 49.04941177368164, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.79356002807617, 1.0\n",
      "Train loss and acc of batch 54: 48.01032257080078, 0.984375\n",
      "Train loss and acc of batch 55: 47.79354476928711, 1.0\n",
      "Train loss and acc of batch 56: 47.793540954589844, 1.0\n",
      "Train loss and acc of batch 57: 48.38922882080078, 0.984375\n",
      "Train loss and acc of batch 58: 47.79351806640625, 1.0\n",
      "Train loss and acc of batch 59: 47.79351043701172, 1.0\n",
      "Train loss and acc of batch 60: 47.793495178222656, 1.0\n",
      "Train loss and acc of batch 61: 47.79349136352539, 1.0\n",
      "Train loss and acc of batch 62: 47.793487548828125, 1.0\n",
      "Train loss and acc of batch 63: 48.9848747253418, 0.96875\n",
      "Train loss and acc of batch 64: 48.010231018066406, 0.984375\n",
      "Train loss and acc of batch 65: 47.793460845947266, 1.0\n",
      "Train loss and acc of batch 66: 47.79344940185547, 1.0\n",
      "Train loss and acc of batch 67: 48.60590362548828, 0.96875\n",
      "Train loss and acc of batch 68: 48.389129638671875, 0.984375\n",
      "Train loss and acc of batch 69: 48.01018524169922, 0.984375\n",
      "Train loss and acc of batch 70: 47.79341506958008, 1.0\n",
      "Training accuracy and loss of epoch #419: 0.9897, 48.1146\n",
      "Saved model by train loss 48.11460618569817\n",
      "Train loss and acc of batch 0: 47.79340744018555, 1.0\n",
      "Train loss and acc of batch 1: 47.793392181396484, 1.0\n",
      "Train loss and acc of batch 2: 47.79338455200195, 1.0\n",
      "Train loss and acc of batch 3: 48.01013946533203, 0.984375\n",
      "Train loss and acc of batch 4: 47.79336929321289, 1.0\n",
      "Train loss and acc of batch 5: 49.14228820800781, 0.96875\n",
      "Train loss and acc of batch 6: 48.295963287353516, 0.96875\n",
      "Train loss and acc of batch 7: 47.79334259033203, 1.0\n",
      "Train loss and acc of batch 8: 48.3890380859375, 0.984375\n",
      "Train loss and acc of batch 9: 48.07917785644531, 0.984375\n",
      "Train loss and acc of batch 10: 47.793312072753906, 1.0\n",
      "Train loss and acc of batch 11: 47.79330825805664, 1.0\n",
      "Train loss and acc of batch 12: 48.5465202331543, 0.984375\n",
      "Train loss and acc of batch 13: 48.01005554199219, 0.984375\n",
      "Train loss and acc of batch 14: 48.010040283203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.38896942138672, 0.984375\n",
      "Train loss and acc of batch 16: 48.38896942138672, 0.984375\n",
      "Train loss and acc of batch 17: 48.546470642089844, 0.984375\n",
      "Train loss and acc of batch 18: 48.67479705810547, 0.96875\n",
      "Train loss and acc of batch 19: 47.79322814941406, 1.0\n",
      "Train loss and acc of batch 20: 47.7932243347168, 1.0\n",
      "Train loss and acc of batch 21: 48.388916015625, 0.984375\n",
      "Train loss and acc of batch 22: 48.388916015625, 0.984375\n",
      "Train loss and acc of batch 23: 47.79319763183594, 1.0\n",
      "Train loss and acc of batch 24: 48.388885498046875, 0.984375\n",
      "Train loss and acc of batch 25: 47.79317855834961, 1.0\n",
      "Train loss and acc of batch 26: 47.79317092895508, 1.0\n",
      "Train loss and acc of batch 27: 47.79315948486328, 1.0\n",
      "Train loss and acc of batch 28: 47.79315185546875, 1.0\n",
      "Train loss and acc of batch 29: 48.38884735107422, 0.984375\n",
      "Train loss and acc of batch 30: 47.79314041137695, 1.0\n",
      "Train loss and acc of batch 31: 48.0098876953125, 0.984375\n",
      "Train loss and acc of batch 32: 47.79311752319336, 1.0\n",
      "Train loss and acc of batch 33: 47.79310989379883, 1.0\n",
      "Train loss and acc of batch 34: 48.38880157470703, 0.984375\n",
      "Train loss and acc of batch 35: 48.226619720458984, 0.96875\n",
      "Train loss and acc of batch 36: 47.7930793762207, 1.0\n",
      "Train loss and acc of batch 37: 48.54629898071289, 0.984375\n",
      "Train loss and acc of batch 38: 49.141990661621094, 0.96875\n",
      "Train loss and acc of batch 39: 48.00981903076172, 0.984375\n",
      "Train loss and acc of batch 40: 47.79304885864258, 1.0\n",
      "Train loss and acc of batch 41: 49.141963958740234, 0.96875\n",
      "Train loss and acc of batch 42: 47.79302978515625, 1.0\n",
      "Train loss and acc of batch 43: 48.38872528076172, 0.984375\n",
      "Train loss and acc of batch 44: 47.79301071166992, 1.0\n",
      "Train loss and acc of batch 45: 48.388710021972656, 0.984375\n",
      "Train loss and acc of batch 46: 48.07884979248047, 0.984375\n",
      "Train loss and acc of batch 47: 47.79298782348633, 1.0\n",
      "Train loss and acc of batch 48: 47.7929801940918, 1.0\n",
      "Train loss and acc of batch 49: 47.79296875, 1.0\n",
      "Train loss and acc of batch 50: 48.38865661621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.141876220703125, 0.96875\n",
      "Train loss and acc of batch 52: 49.04877853393555, 0.953125\n",
      "Train loss and acc of batch 53: 47.79293441772461, 1.0\n",
      "Train loss and acc of batch 54: 48.00968933105469, 0.984375\n",
      "Train loss and acc of batch 55: 47.792911529541016, 1.0\n",
      "Train loss and acc of batch 56: 47.792903900146484, 1.0\n",
      "Train loss and acc of batch 57: 48.38859558105469, 0.984375\n",
      "Train loss and acc of batch 58: 47.79288864135742, 1.0\n",
      "Train loss and acc of batch 59: 47.792884826660156, 1.0\n",
      "Train loss and acc of batch 60: 47.79286575317383, 1.0\n",
      "Train loss and acc of batch 61: 47.79286193847656, 1.0\n",
      "Train loss and acc of batch 62: 47.79285430908203, 1.0\n",
      "Train loss and acc of batch 63: 48.98424530029297, 0.96875\n",
      "Train loss and acc of batch 64: 48.00959777832031, 0.984375\n",
      "Train loss and acc of batch 65: 47.792823791503906, 1.0\n",
      "Train loss and acc of batch 66: 47.792816162109375, 1.0\n",
      "Train loss and acc of batch 67: 48.60527420043945, 0.96875\n",
      "Train loss and acc of batch 68: 48.38850402832031, 0.984375\n",
      "Train loss and acc of batch 69: 48.009552001953125, 0.984375\n",
      "Train loss and acc of batch 70: 47.792781829833984, 1.0\n",
      "Training accuracy and loss of epoch #420: 0.9897, 48.1140\n",
      "Saved model by train loss 48.113975471174214\n",
      "Train loss and acc of batch 0: 47.79277038574219, 1.0\n",
      "Train loss and acc of batch 1: 47.792762756347656, 1.0\n",
      "Train loss and acc of batch 2: 47.79275894165039, 1.0\n",
      "Train loss and acc of batch 3: 48.00951385498047, 0.984375\n",
      "Train loss and acc of batch 4: 47.7927360534668, 1.0\n",
      "Train loss and acc of batch 5: 49.14165496826172, 0.96875\n",
      "Train loss and acc of batch 6: 48.29533386230469, 0.96875\n",
      "Train loss and acc of batch 7: 47.79270553588867, 1.0\n",
      "Train loss and acc of batch 8: 48.388397216796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.07854461669922, 0.984375\n",
      "Train loss and acc of batch 10: 47.79268264770508, 1.0\n",
      "Train loss and acc of batch 11: 47.79267501831055, 1.0\n",
      "Train loss and acc of batch 12: 48.54589080810547, 0.984375\n",
      "Train loss and acc of batch 13: 48.009422302246094, 0.984375\n",
      "Train loss and acc of batch 14: 48.00940704345703, 0.984375\n",
      "Train loss and acc of batch 15: 48.388343811035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.388336181640625, 0.984375\n",
      "Train loss and acc of batch 17: 48.545841217041016, 0.984375\n",
      "Train loss and acc of batch 18: 48.674163818359375, 0.96875\n",
      "Train loss and acc of batch 19: 47.792606353759766, 1.0\n",
      "Train loss and acc of batch 20: 47.792598724365234, 1.0\n",
      "Train loss and acc of batch 21: 48.38829040527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.388275146484375, 0.984375\n",
      "Train loss and acc of batch 23: 47.79256820678711, 1.0\n",
      "Train loss and acc of batch 24: 48.38825988769531, 0.984375\n",
      "Train loss and acc of batch 25: 47.79255294799805, 1.0\n",
      "Train loss and acc of batch 26: 47.79254150390625, 1.0\n",
      "Train loss and acc of batch 27: 47.792537689208984, 1.0\n",
      "Train loss and acc of batch 28: 47.79252243041992, 1.0\n",
      "Train loss and acc of batch 29: 48.388221740722656, 0.984375\n",
      "Train loss and acc of batch 30: 47.79250717163086, 1.0\n",
      "Train loss and acc of batch 31: 48.00926208496094, 0.984375\n",
      "Train loss and acc of batch 32: 47.79248809814453, 1.0\n",
      "Train loss and acc of batch 33: 47.792484283447266, 1.0\n",
      "Train loss and acc of batch 34: 48.38816833496094, 0.984375\n",
      "Train loss and acc of batch 35: 48.225990295410156, 0.96875\n",
      "Train loss and acc of batch 36: 47.792449951171875, 1.0\n",
      "Train loss and acc of batch 37: 48.5456657409668, 0.984375\n",
      "Train loss and acc of batch 38: 49.141357421875, 0.96875\n",
      "Train loss and acc of batch 39: 48.009193420410156, 0.984375\n",
      "Train loss and acc of batch 40: 47.79241943359375, 1.0\n",
      "Train loss and acc of batch 41: 49.141334533691406, 0.96875\n",
      "Train loss and acc of batch 42: 47.79240036010742, 1.0\n",
      "Train loss and acc of batch 43: 48.388092041015625, 0.984375\n",
      "Train loss and acc of batch 44: 47.792381286621094, 1.0\n",
      "Train loss and acc of batch 45: 48.38807678222656, 0.984375\n",
      "Train loss and acc of batch 46: 48.078216552734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.7923583984375, 1.0\n",
      "Train loss and acc of batch 48: 47.7923469543457, 1.0\n",
      "Train loss and acc of batch 49: 47.79233932495117, 1.0\n",
      "Train loss and acc of batch 50: 48.388031005859375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 51: 49.14124298095703, 0.96875\n",
      "Train loss and acc of batch 52: 49.048152923583984, 0.953125\n",
      "Train loss and acc of batch 53: 47.792301177978516, 1.0\n",
      "Train loss and acc of batch 54: 48.009056091308594, 0.984375\n",
      "Train loss and acc of batch 55: 47.79228591918945, 1.0\n",
      "Train loss and acc of batch 56: 47.79227828979492, 1.0\n",
      "Train loss and acc of batch 57: 48.387969970703125, 0.984375\n",
      "Train loss and acc of batch 58: 47.792259216308594, 1.0\n",
      "Train loss and acc of batch 59: 47.7922477722168, 1.0\n",
      "Train loss and acc of batch 60: 47.792236328125, 1.0\n",
      "Train loss and acc of batch 61: 47.79222869873047, 1.0\n",
      "Train loss and acc of batch 62: 47.79222869873047, 1.0\n",
      "Train loss and acc of batch 63: 48.983612060546875, 0.96875\n",
      "Train loss and acc of batch 64: 48.00897216796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.792198181152344, 1.0\n",
      "Train loss and acc of batch 66: 47.79219055175781, 1.0\n",
      "Train loss and acc of batch 67: 48.60464859008789, 0.96875\n",
      "Train loss and acc of batch 68: 48.38787078857422, 0.984375\n",
      "Train loss and acc of batch 69: 48.00892639160156, 0.984375\n",
      "Train loss and acc of batch 70: 47.79215621948242, 1.0\n",
      "Training accuracy and loss of epoch #421: 0.9897, 48.1133\n",
      "Saved model by train loss 48.11334567002847\n",
      "Train loss and acc of batch 0: 47.792144775390625, 1.0\n",
      "Train loss and acc of batch 1: 47.792137145996094, 1.0\n",
      "Train loss and acc of batch 2: 47.7921257019043, 1.0\n",
      "Train loss and acc of batch 3: 48.008880615234375, 0.984375\n",
      "Train loss and acc of batch 4: 47.79210662841797, 1.0\n",
      "Train loss and acc of batch 5: 49.141021728515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.29470443725586, 0.96875\n",
      "Train loss and acc of batch 7: 47.792083740234375, 1.0\n",
      "Train loss and acc of batch 8: 48.38777160644531, 0.984375\n",
      "Train loss and acc of batch 9: 48.077919006347656, 0.984375\n",
      "Train loss and acc of batch 10: 47.792057037353516, 1.0\n",
      "Train loss and acc of batch 11: 47.792049407958984, 1.0\n",
      "Train loss and acc of batch 12: 48.54526138305664, 0.984375\n",
      "Train loss and acc of batch 13: 48.0087890625, 0.984375\n",
      "Train loss and acc of batch 14: 48.00878143310547, 0.984375\n",
      "Train loss and acc of batch 15: 48.38771057128906, 0.984375\n",
      "Train loss and acc of batch 16: 48.38770294189453, 0.984375\n",
      "Train loss and acc of batch 17: 48.54521560668945, 0.984375\n",
      "Train loss and acc of batch 18: 48.67353820800781, 0.96875\n",
      "Train loss and acc of batch 19: 47.79197692871094, 1.0\n",
      "Train loss and acc of batch 20: 47.791961669921875, 1.0\n",
      "Train loss and acc of batch 21: 48.387657165527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.38764953613281, 0.984375\n",
      "Train loss and acc of batch 23: 47.79193878173828, 1.0\n",
      "Train loss and acc of batch 24: 48.38763427734375, 0.984375\n",
      "Train loss and acc of batch 25: 47.79191589355469, 1.0\n",
      "Train loss and acc of batch 26: 47.79191207885742, 1.0\n",
      "Train loss and acc of batch 27: 47.79190444946289, 1.0\n",
      "Train loss and acc of batch 28: 47.791900634765625, 1.0\n",
      "Train loss and acc of batch 29: 48.38758850097656, 0.984375\n",
      "Train loss and acc of batch 30: 47.79187774658203, 1.0\n",
      "Train loss and acc of batch 31: 48.008628845214844, 0.984375\n",
      "Train loss and acc of batch 32: 47.79186248779297, 1.0\n",
      "Train loss and acc of batch 33: 47.79185104370117, 1.0\n",
      "Train loss and acc of batch 34: 48.387535095214844, 0.984375\n",
      "Train loss and acc of batch 35: 48.22536087036133, 0.96875\n",
      "Train loss and acc of batch 36: 47.79182434082031, 1.0\n",
      "Train loss and acc of batch 37: 48.54503631591797, 0.984375\n",
      "Train loss and acc of batch 38: 49.14073181152344, 0.96875\n",
      "Train loss and acc of batch 39: 48.00856018066406, 0.984375\n",
      "Train loss and acc of batch 40: 47.791786193847656, 1.0\n",
      "Train loss and acc of batch 41: 49.14070510864258, 0.96875\n",
      "Train loss and acc of batch 42: 47.79176712036133, 1.0\n",
      "Train loss and acc of batch 43: 48.38745880126953, 0.984375\n",
      "Train loss and acc of batch 44: 47.79175567626953, 1.0\n",
      "Train loss and acc of batch 45: 48.38744354248047, 0.984375\n",
      "Train loss and acc of batch 46: 48.07759094238281, 0.984375\n",
      "Train loss and acc of batch 47: 47.79172897338867, 1.0\n",
      "Train loss and acc of batch 48: 47.791709899902344, 1.0\n",
      "Train loss and acc of batch 49: 47.791709899902344, 1.0\n",
      "Train loss and acc of batch 50: 48.38740539550781, 0.984375\n",
      "Train loss and acc of batch 51: 49.14061737060547, 0.96875\n",
      "Train loss and acc of batch 52: 49.047523498535156, 0.953125\n",
      "Train loss and acc of batch 53: 47.79167556762695, 1.0\n",
      "Train loss and acc of batch 54: 48.00843048095703, 0.984375\n",
      "Train loss and acc of batch 55: 47.791656494140625, 1.0\n",
      "Train loss and acc of batch 56: 47.791648864746094, 1.0\n",
      "Train loss and acc of batch 57: 48.38733673095703, 0.984375\n",
      "Train loss and acc of batch 58: 47.7916259765625, 1.0\n",
      "Train loss and acc of batch 59: 47.79161834716797, 1.0\n",
      "Train loss and acc of batch 60: 47.7916145324707, 1.0\n",
      "Train loss and acc of batch 61: 47.79160690307617, 1.0\n",
      "Train loss and acc of batch 62: 47.791587829589844, 1.0\n",
      "Train loss and acc of batch 63: 48.98298645019531, 0.96875\n",
      "Train loss and acc of batch 64: 48.008338928222656, 0.984375\n",
      "Train loss and acc of batch 65: 47.791568756103516, 1.0\n",
      "Train loss and acc of batch 66: 47.79155731201172, 1.0\n",
      "Train loss and acc of batch 67: 48.6040153503418, 0.96875\n",
      "Train loss and acc of batch 68: 48.387237548828125, 0.984375\n",
      "Train loss and acc of batch 69: 48.00829315185547, 0.984375\n",
      "Train loss and acc of batch 70: 47.79151916503906, 1.0\n",
      "Training accuracy and loss of epoch #422: 0.9897, 48.1127\n",
      "Saved model by train loss 48.11271592261086\n",
      "Train loss and acc of batch 0: 47.79151153564453, 1.0\n",
      "Train loss and acc of batch 1: 47.79150390625, 1.0\n",
      "Train loss and acc of batch 2: 47.791500091552734, 1.0\n",
      "Train loss and acc of batch 3: 48.00825500488281, 0.984375\n",
      "Train loss and acc of batch 4: 47.791481018066406, 1.0\n",
      "Train loss and acc of batch 5: 49.14038848876953, 0.96875\n",
      "Train loss and acc of batch 6: 48.29407501220703, 0.96875\n",
      "Train loss and acc of batch 7: 47.79145050048828, 1.0\n",
      "Train loss and acc of batch 8: 48.38714599609375, 0.984375\n",
      "Train loss and acc of batch 9: 48.07728576660156, 0.984375\n",
      "Train loss and acc of batch 10: 47.79142379760742, 1.0\n",
      "Train loss and acc of batch 11: 47.79141616821289, 1.0\n",
      "Train loss and acc of batch 12: 48.54463577270508, 0.984375\n",
      "Train loss and acc of batch 13: 48.00816345214844, 0.984375\n",
      "Train loss and acc of batch 14: 48.008148193359375, 0.984375\n",
      "Train loss and acc of batch 15: 48.38707733154297, 0.984375\n",
      "Train loss and acc of batch 16: 48.38706970214844, 0.984375\n",
      "Train loss and acc of batch 17: 48.544586181640625, 0.984375\n",
      "Train loss and acc of batch 18: 48.672908782958984, 0.96875\n",
      "Train loss and acc of batch 19: 47.791343688964844, 1.0\n",
      "Train loss and acc of batch 20: 47.79133605957031, 1.0\n",
      "Train loss and acc of batch 21: 48.38703155517578, 0.984375\n",
      "Train loss and acc of batch 22: 48.38701629638672, 0.984375\n",
      "Train loss and acc of batch 23: 47.79130935668945, 1.0\n",
      "Train loss and acc of batch 24: 48.387001037597656, 0.984375\n",
      "Train loss and acc of batch 25: 47.79129409790039, 1.0\n",
      "Train loss and acc of batch 26: 47.79128646850586, 1.0\n",
      "Train loss and acc of batch 27: 47.79127502441406, 1.0\n",
      "Train loss and acc of batch 28: 47.791259765625, 1.0\n",
      "Train loss and acc of batch 29: 48.38695526123047, 0.984375\n",
      "Train loss and acc of batch 30: 47.79124069213867, 1.0\n",
      "Train loss and acc of batch 31: 48.00800323486328, 0.984375\n",
      "Train loss and acc of batch 32: 47.791229248046875, 1.0\n",
      "Train loss and acc of batch 33: 47.79121780395508, 1.0\n",
      "Train loss and acc of batch 34: 48.38690948486328, 0.984375\n",
      "Train loss and acc of batch 35: 48.224735260009766, 0.96875\n",
      "Train loss and acc of batch 36: 47.79119110107422, 1.0\n",
      "Train loss and acc of batch 37: 48.54440689086914, 0.984375\n",
      "Train loss and acc of batch 38: 49.140098571777344, 0.96875\n",
      "Train loss and acc of batch 39: 48.0079345703125, 0.984375\n",
      "Train loss and acc of batch 40: 47.791160583496094, 1.0\n",
      "Train loss and acc of batch 41: 49.140079498291016, 0.96875\n",
      "Train loss and acc of batch 42: 47.7911376953125, 1.0\n",
      "Train loss and acc of batch 43: 48.38683319091797, 0.984375\n",
      "Train loss and acc of batch 44: 47.79112243652344, 1.0\n",
      "Train loss and acc of batch 45: 48.386817932128906, 0.984375\n",
      "Train loss and acc of batch 46: 48.07695770263672, 0.984375\n",
      "Train loss and acc of batch 47: 47.79109191894531, 1.0\n",
      "Train loss and acc of batch 48: 47.79108810424805, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 49: 47.791080474853516, 1.0\n",
      "Train loss and acc of batch 50: 48.38677215576172, 0.984375\n",
      "Train loss and acc of batch 51: 49.139984130859375, 0.96875\n",
      "Train loss and acc of batch 52: 49.04689407348633, 0.953125\n",
      "Train loss and acc of batch 53: 47.79104232788086, 1.0\n",
      "Train loss and acc of batch 54: 48.00779724121094, 0.984375\n",
      "Train loss and acc of batch 55: 47.7910270690918, 1.0\n",
      "Train loss and acc of batch 56: 47.791019439697266, 1.0\n",
      "Train loss and acc of batch 57: 48.38670349121094, 0.984375\n",
      "Train loss and acc of batch 58: 47.79099655151367, 1.0\n",
      "Train loss and acc of batch 59: 47.79098892211914, 1.0\n",
      "Train loss and acc of batch 60: 47.79098129272461, 1.0\n",
      "Train loss and acc of batch 61: 47.79096603393555, 1.0\n",
      "Train loss and acc of batch 62: 47.79096221923828, 1.0\n",
      "Train loss and acc of batch 63: 48.98236083984375, 0.96875\n",
      "Train loss and acc of batch 64: 48.00770568847656, 0.984375\n",
      "Train loss and acc of batch 65: 47.790931701660156, 1.0\n",
      "Train loss and acc of batch 66: 47.790924072265625, 1.0\n",
      "Train loss and acc of batch 67: 48.6033821105957, 0.96875\n",
      "Train loss and acc of batch 68: 48.38661193847656, 0.984375\n",
      "Train loss and acc of batch 69: 48.007667541503906, 0.984375\n",
      "Train loss and acc of batch 70: 47.790889739990234, 1.0\n",
      "Training accuracy and loss of epoch #423: 0.9897, 48.1121\n",
      "Saved model by train loss 48.112085637911946\n",
      "Train loss and acc of batch 0: 47.79088592529297, 1.0\n",
      "Train loss and acc of batch 1: 47.79087448120117, 1.0\n",
      "Train loss and acc of batch 2: 47.790863037109375, 1.0\n",
      "Train loss and acc of batch 3: 48.00762176513672, 0.984375\n",
      "Train loss and acc of batch 4: 47.79084396362305, 1.0\n",
      "Train loss and acc of batch 5: 49.13976287841797, 0.96875\n",
      "Train loss and acc of batch 6: 48.2934455871582, 0.96875\n",
      "Train loss and acc of batch 7: 47.79082107543945, 1.0\n",
      "Train loss and acc of batch 8: 48.386512756347656, 0.984375\n",
      "Train loss and acc of batch 9: 48.07665252685547, 0.984375\n",
      "Train loss and acc of batch 10: 47.790794372558594, 1.0\n",
      "Train loss and acc of batch 11: 47.79078674316406, 1.0\n",
      "Train loss and acc of batch 12: 48.54399871826172, 0.984375\n",
      "Train loss and acc of batch 13: 48.007530212402344, 0.984375\n",
      "Train loss and acc of batch 14: 48.00752258300781, 0.984375\n",
      "Train loss and acc of batch 15: 48.386451721191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.386444091796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.54396057128906, 0.984375\n",
      "Train loss and acc of batch 18: 48.67227554321289, 0.96875\n",
      "Train loss and acc of batch 19: 47.790714263916016, 1.0\n",
      "Train loss and acc of batch 20: 47.790706634521484, 1.0\n",
      "Train loss and acc of batch 21: 48.386390686035156, 0.984375\n",
      "Train loss and acc of batch 22: 48.386390686035156, 0.984375\n",
      "Train loss and acc of batch 23: 47.79067611694336, 1.0\n",
      "Train loss and acc of batch 24: 48.38636779785156, 0.984375\n",
      "Train loss and acc of batch 25: 47.7906608581543, 1.0\n",
      "Train loss and acc of batch 26: 47.790653228759766, 1.0\n",
      "Train loss and acc of batch 27: 47.79064178466797, 1.0\n",
      "Train loss and acc of batch 28: 47.7906379699707, 1.0\n",
      "Train loss and acc of batch 29: 48.386322021484375, 0.984375\n",
      "Train loss and acc of batch 30: 47.790618896484375, 1.0\n",
      "Train loss and acc of batch 31: 48.00736999511719, 0.984375\n",
      "Train loss and acc of batch 32: 47.79059600830078, 1.0\n",
      "Train loss and acc of batch 33: 47.79058837890625, 1.0\n",
      "Train loss and acc of batch 34: 48.38628387451172, 0.984375\n",
      "Train loss and acc of batch 35: 48.22410202026367, 0.96875\n",
      "Train loss and acc of batch 36: 47.790565490722656, 1.0\n",
      "Train loss and acc of batch 37: 48.54377746582031, 0.984375\n",
      "Train loss and acc of batch 38: 49.13946533203125, 0.96875\n",
      "Train loss and acc of batch 39: 48.007301330566406, 0.984375\n",
      "Train loss and acc of batch 40: 47.790531158447266, 1.0\n",
      "Train loss and acc of batch 41: 49.139442443847656, 0.96875\n",
      "Train loss and acc of batch 42: 47.79051208496094, 1.0\n",
      "Train loss and acc of batch 43: 48.386199951171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.79049301147461, 1.0\n",
      "Train loss and acc of batch 45: 48.38618469238281, 0.984375\n",
      "Train loss and acc of batch 46: 48.076324462890625, 0.984375\n",
      "Train loss and acc of batch 47: 47.79046630859375, 1.0\n",
      "Train loss and acc of batch 48: 47.79045867919922, 1.0\n",
      "Train loss and acc of batch 49: 47.79044723510742, 1.0\n",
      "Train loss and acc of batch 50: 48.386138916015625, 0.984375\n",
      "Train loss and acc of batch 51: 49.13935089111328, 0.96875\n",
      "Train loss and acc of batch 52: 49.04625701904297, 0.953125\n",
      "Train loss and acc of batch 53: 47.79041290283203, 1.0\n",
      "Train loss and acc of batch 54: 48.007164001464844, 0.984375\n",
      "Train loss and acc of batch 55: 47.7903938293457, 1.0\n",
      "Train loss and acc of batch 56: 47.79038619995117, 1.0\n",
      "Train loss and acc of batch 57: 48.386077880859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.79037094116211, 1.0\n",
      "Train loss and acc of batch 59: 47.79035568237305, 1.0\n",
      "Train loss and acc of batch 60: 47.790348052978516, 1.0\n",
      "Train loss and acc of batch 61: 47.79034423828125, 1.0\n",
      "Train loss and acc of batch 62: 47.79032897949219, 1.0\n",
      "Train loss and acc of batch 63: 48.981727600097656, 0.96875\n",
      "Train loss and acc of batch 64: 48.007080078125, 0.984375\n",
      "Train loss and acc of batch 65: 47.79030990600586, 1.0\n",
      "Train loss and acc of batch 66: 47.79029083251953, 1.0\n",
      "Train loss and acc of batch 67: 48.602752685546875, 0.96875\n",
      "Train loss and acc of batch 68: 48.38597869873047, 0.984375\n",
      "Train loss and acc of batch 69: 48.00703430175781, 0.984375\n",
      "Train loss and acc of batch 70: 47.790260314941406, 1.0\n",
      "Training accuracy and loss of epoch #424: 0.9897, 48.1115\n",
      "Saved model by train loss 48.11145497711612\n",
      "Train loss and acc of batch 0: 47.790252685546875, 1.0\n",
      "Train loss and acc of batch 1: 47.790245056152344, 1.0\n",
      "Train loss and acc of batch 2: 47.79023742675781, 1.0\n",
      "Train loss and acc of batch 3: 48.006996154785156, 0.984375\n",
      "Train loss and acc of batch 4: 47.79021453857422, 1.0\n",
      "Train loss and acc of batch 5: 49.139129638671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.29281997680664, 0.96875\n",
      "Train loss and acc of batch 7: 47.79018783569336, 1.0\n",
      "Train loss and acc of batch 8: 48.38587951660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.076026916503906, 0.984375\n",
      "Train loss and acc of batch 10: 47.79016876220703, 1.0\n",
      "Train loss and acc of batch 11: 47.79015350341797, 1.0\n",
      "Train loss and acc of batch 12: 48.543365478515625, 0.984375\n",
      "Train loss and acc of batch 13: 48.00689697265625, 0.984375\n",
      "Train loss and acc of batch 14: 48.00689697265625, 0.984375\n",
      "Train loss and acc of batch 15: 48.38581848144531, 0.984375\n",
      "Train loss and acc of batch 16: 48.38581085205078, 0.984375\n",
      "Train loss and acc of batch 17: 48.5433235168457, 0.984375\n",
      "Train loss and acc of batch 18: 48.67164611816406, 0.96875\n",
      "Train loss and acc of batch 19: 47.79008483886719, 1.0\n",
      "Train loss and acc of batch 20: 47.790077209472656, 1.0\n",
      "Train loss and acc of batch 21: 48.385765075683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.38575744628906, 0.984375\n",
      "Train loss and acc of batch 23: 47.7900505065918, 1.0\n",
      "Train loss and acc of batch 24: 48.3857421875, 0.984375\n",
      "Train loss and acc of batch 25: 47.7900276184082, 1.0\n",
      "Train loss and acc of batch 26: 47.790016174316406, 1.0\n",
      "Train loss and acc of batch 27: 47.790016174316406, 1.0\n",
      "Train loss and acc of batch 28: 47.79000473022461, 1.0\n",
      "Train loss and acc of batch 29: 48.38569641113281, 0.984375\n",
      "Train loss and acc of batch 30: 47.78998565673828, 1.0\n",
      "Train loss and acc of batch 31: 48.006744384765625, 0.984375\n",
      "Train loss and acc of batch 32: 47.78996658325195, 1.0\n",
      "Train loss and acc of batch 33: 47.78995895385742, 1.0\n",
      "Train loss and acc of batch 34: 48.385650634765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.223472595214844, 0.96875\n",
      "Train loss and acc of batch 36: 47.7899284362793, 1.0\n",
      "Train loss and acc of batch 37: 48.54315185546875, 0.984375\n",
      "Train loss and acc of batch 38: 49.13883972167969, 0.96875\n",
      "Train loss and acc of batch 39: 48.00666809082031, 0.984375\n",
      "Train loss and acc of batch 40: 47.78989791870117, 1.0\n",
      "Train loss and acc of batch 41: 49.13881301879883, 0.96875\n",
      "Train loss and acc of batch 42: 47.789878845214844, 1.0\n",
      "Train loss and acc of batch 43: 48.38557434082031, 0.984375\n",
      "Train loss and acc of batch 44: 47.789859771728516, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 45: 48.38555145263672, 0.984375\n",
      "Train loss and acc of batch 46: 48.07569122314453, 0.984375\n",
      "Train loss and acc of batch 47: 47.78982925415039, 1.0\n",
      "Train loss and acc of batch 48: 47.789825439453125, 1.0\n",
      "Train loss and acc of batch 49: 47.78981399536133, 1.0\n",
      "Train loss and acc of batch 50: 48.38550567626953, 0.984375\n",
      "Train loss and acc of batch 51: 49.13872528076172, 0.96875\n",
      "Train loss and acc of batch 52: 49.045631408691406, 0.953125\n",
      "Train loss and acc of batch 53: 47.78977966308594, 1.0\n",
      "Train loss and acc of batch 54: 48.00653839111328, 0.984375\n",
      "Train loss and acc of batch 55: 47.789764404296875, 1.0\n",
      "Train loss and acc of batch 56: 47.78975296020508, 1.0\n",
      "Train loss and acc of batch 57: 48.38544464111328, 0.984375\n",
      "Train loss and acc of batch 58: 47.789737701416016, 1.0\n",
      "Train loss and acc of batch 59: 47.789730072021484, 1.0\n",
      "Train loss and acc of batch 60: 47.78972244262695, 1.0\n",
      "Train loss and acc of batch 61: 47.789710998535156, 1.0\n",
      "Train loss and acc of batch 62: 47.789703369140625, 1.0\n",
      "Train loss and acc of batch 63: 48.98109436035156, 0.96875\n",
      "Train loss and acc of batch 64: 48.006446838378906, 0.984375\n",
      "Train loss and acc of batch 65: 47.789676666259766, 1.0\n",
      "Train loss and acc of batch 66: 47.789669036865234, 1.0\n",
      "Train loss and acc of batch 67: 48.60211944580078, 0.96875\n",
      "Train loss and acc of batch 68: 48.385353088378906, 0.984375\n",
      "Train loss and acc of batch 69: 48.00640106201172, 0.984375\n",
      "Train loss and acc of batch 70: 47.78963088989258, 1.0\n",
      "Training accuracy and loss of epoch #425: 0.9897, 48.1108\n",
      "Saved model by train loss 48.11082463868907\n",
      "Train loss and acc of batch 0: 47.78961944580078, 1.0\n",
      "Train loss and acc of batch 1: 47.789608001708984, 1.0\n",
      "Train loss and acc of batch 2: 47.78960037231445, 1.0\n",
      "Train loss and acc of batch 3: 48.00636291503906, 0.984375\n",
      "Train loss and acc of batch 4: 47.789588928222656, 1.0\n",
      "Train loss and acc of batch 5: 49.13850402832031, 0.96875\n",
      "Train loss and acc of batch 6: 48.29218292236328, 0.96875\n",
      "Train loss and acc of batch 7: 47.78955841064453, 1.0\n",
      "Train loss and acc of batch 8: 48.38525390625, 0.984375\n",
      "Train loss and acc of batch 9: 48.07539367675781, 0.984375\n",
      "Train loss and acc of batch 10: 47.78953170776367, 1.0\n",
      "Train loss and acc of batch 11: 47.789527893066406, 1.0\n",
      "Train loss and acc of batch 12: 48.54273986816406, 0.984375\n",
      "Train loss and acc of batch 13: 48.00627136230469, 0.984375\n",
      "Train loss and acc of batch 14: 48.006263732910156, 0.984375\n",
      "Train loss and acc of batch 15: 48.38519287109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.38517761230469, 0.984375\n",
      "Train loss and acc of batch 17: 48.542694091796875, 0.984375\n",
      "Train loss and acc of batch 18: 48.671016693115234, 0.96875\n",
      "Train loss and acc of batch 19: 47.78945541381836, 1.0\n",
      "Train loss and acc of batch 20: 47.78944396972656, 1.0\n",
      "Train loss and acc of batch 21: 48.38513946533203, 0.984375\n",
      "Train loss and acc of batch 22: 48.3851318359375, 0.984375\n",
      "Train loss and acc of batch 23: 47.78942108154297, 1.0\n",
      "Train loss and acc of batch 24: 48.385108947753906, 0.984375\n",
      "Train loss and acc of batch 25: 47.78940200805664, 1.0\n",
      "Train loss and acc of batch 26: 47.78939437866211, 1.0\n",
      "Train loss and acc of batch 27: 47.78937911987305, 1.0\n",
      "Train loss and acc of batch 28: 47.78937530517578, 1.0\n",
      "Train loss and acc of batch 29: 48.38506317138672, 0.984375\n",
      "Train loss and acc of batch 30: 47.78935623168945, 1.0\n",
      "Train loss and acc of batch 31: 48.00611114501953, 0.984375\n",
      "Train loss and acc of batch 32: 47.78934097290039, 1.0\n",
      "Train loss and acc of batch 33: 47.78933334350586, 1.0\n",
      "Train loss and acc of batch 34: 48.38501739501953, 0.984375\n",
      "Train loss and acc of batch 35: 48.222835540771484, 0.96875\n",
      "Train loss and acc of batch 36: 47.789302825927734, 1.0\n",
      "Train loss and acc of batch 37: 48.542518615722656, 0.984375\n",
      "Train loss and acc of batch 38: 49.138206481933594, 0.96875\n",
      "Train loss and acc of batch 39: 48.00604248046875, 0.984375\n",
      "Train loss and acc of batch 40: 47.789268493652344, 1.0\n",
      "Train loss and acc of batch 41: 49.138179779052734, 0.96875\n",
      "Train loss and acc of batch 42: 47.78925323486328, 1.0\n",
      "Train loss and acc of batch 43: 48.38494110107422, 0.984375\n",
      "Train loss and acc of batch 44: 47.78923034667969, 1.0\n",
      "Train loss and acc of batch 45: 48.384918212890625, 0.984375\n",
      "Train loss and acc of batch 46: 48.07506561279297, 0.984375\n",
      "Train loss and acc of batch 47: 47.78920364379883, 1.0\n",
      "Train loss and acc of batch 48: 47.78919219970703, 1.0\n",
      "Train loss and acc of batch 49: 47.7891845703125, 1.0\n",
      "Train loss and acc of batch 50: 48.38488006591797, 0.984375\n",
      "Train loss and acc of batch 51: 49.138092041015625, 0.96875\n",
      "Train loss and acc of batch 52: 49.04499435424805, 0.953125\n",
      "Train loss and acc of batch 53: 47.78915023803711, 1.0\n",
      "Train loss and acc of batch 54: 48.00590515136719, 0.984375\n",
      "Train loss and acc of batch 55: 47.78913497924805, 1.0\n",
      "Train loss and acc of batch 56: 47.789127349853516, 1.0\n",
      "Train loss and acc of batch 57: 48.38481903076172, 0.984375\n",
      "Train loss and acc of batch 58: 47.78910446166992, 1.0\n",
      "Train loss and acc of batch 59: 47.78909683227539, 1.0\n",
      "Train loss and acc of batch 60: 47.78908920288086, 1.0\n",
      "Train loss and acc of batch 61: 47.78908157348633, 1.0\n",
      "Train loss and acc of batch 62: 47.78907012939453, 1.0\n",
      "Train loss and acc of batch 63: 48.980464935302734, 0.96875\n",
      "Train loss and acc of batch 64: 48.00581359863281, 0.984375\n",
      "Train loss and acc of batch 65: 47.78904724121094, 1.0\n",
      "Train loss and acc of batch 66: 47.78903579711914, 1.0\n",
      "Train loss and acc of batch 67: 48.60149383544922, 0.96875\n",
      "Train loss and acc of batch 68: 48.38471984863281, 0.984375\n",
      "Train loss and acc of batch 69: 48.005775451660156, 0.984375\n",
      "Train loss and acc of batch 70: 47.789005279541016, 1.0\n",
      "Training accuracy and loss of epoch #426: 0.9897, 48.1102\n",
      "Saved model by train loss 48.11019446144641\n",
      "Train loss and acc of batch 0: 47.78899002075195, 1.0\n",
      "Train loss and acc of batch 1: 47.788978576660156, 1.0\n",
      "Train loss and acc of batch 2: 47.788978576660156, 1.0\n",
      "Train loss and acc of batch 3: 48.00572967529297, 0.984375\n",
      "Train loss and acc of batch 4: 47.78895950317383, 1.0\n",
      "Train loss and acc of batch 5: 49.13787078857422, 0.96875\n",
      "Train loss and acc of batch 6: 48.29155731201172, 0.96875\n",
      "Train loss and acc of batch 7: 47.7889289855957, 1.0\n",
      "Train loss and acc of batch 8: 48.384620666503906, 0.984375\n",
      "Train loss and acc of batch 9: 48.07476043701172, 0.984375\n",
      "Train loss and acc of batch 10: 47.788902282714844, 1.0\n",
      "Train loss and acc of batch 11: 47.78889083862305, 1.0\n",
      "Train loss and acc of batch 12: 48.54210662841797, 0.984375\n",
      "Train loss and acc of batch 13: 48.005645751953125, 0.984375\n",
      "Train loss and acc of batch 14: 48.00563049316406, 0.984375\n",
      "Train loss and acc of batch 15: 48.384559631347656, 0.984375\n",
      "Train loss and acc of batch 16: 48.384552001953125, 0.984375\n",
      "Train loss and acc of batch 17: 48.54206466674805, 0.984375\n",
      "Train loss and acc of batch 18: 48.670387268066406, 0.96875\n",
      "Train loss and acc of batch 19: 47.788822174072266, 1.0\n",
      "Train loss and acc of batch 20: 47.78881072998047, 1.0\n",
      "Train loss and acc of batch 21: 48.38450622558594, 0.984375\n",
      "Train loss and acc of batch 22: 48.384498596191406, 0.984375\n",
      "Train loss and acc of batch 23: 47.788787841796875, 1.0\n",
      "Train loss and acc of batch 24: 48.38447570800781, 0.984375\n",
      "Train loss and acc of batch 25: 47.78876876831055, 1.0\n",
      "Train loss and acc of batch 26: 47.788761138916016, 1.0\n",
      "Train loss and acc of batch 27: 47.788753509521484, 1.0\n",
      "Train loss and acc of batch 28: 47.78874206542969, 1.0\n",
      "Train loss and acc of batch 29: 48.384429931640625, 0.984375\n",
      "Train loss and acc of batch 30: 47.788726806640625, 1.0\n",
      "Train loss and acc of batch 31: 48.00548553466797, 0.984375\n",
      "Train loss and acc of batch 32: 47.7887077331543, 1.0\n",
      "Train loss and acc of batch 33: 47.788700103759766, 1.0\n",
      "Train loss and acc of batch 34: 48.38439178466797, 0.984375\n",
      "Train loss and acc of batch 35: 48.22220993041992, 0.96875\n",
      "Train loss and acc of batch 36: 47.78866958618164, 1.0\n",
      "Train loss and acc of batch 37: 48.54188537597656, 0.984375\n",
      "Train loss and acc of batch 38: 49.1375732421875, 0.96875\n",
      "Train loss and acc of batch 39: 48.005409240722656, 0.984375\n",
      "Train loss and acc of batch 40: 47.788639068603516, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.13755798339844, 0.96875\n",
      "Train loss and acc of batch 42: 47.78861618041992, 1.0\n",
      "Train loss and acc of batch 43: 48.384315490722656, 0.984375\n",
      "Train loss and acc of batch 44: 47.788597106933594, 1.0\n",
      "Train loss and acc of batch 45: 48.38429260253906, 0.984375\n",
      "Train loss and acc of batch 46: 48.074432373046875, 0.984375\n",
      "Train loss and acc of batch 47: 47.788570404052734, 1.0\n",
      "Train loss and acc of batch 48: 47.78856658935547, 1.0\n",
      "Train loss and acc of batch 49: 47.7885627746582, 1.0\n",
      "Train loss and acc of batch 50: 48.384246826171875, 0.984375\n",
      "Train loss and acc of batch 51: 49.13745880126953, 0.96875\n",
      "Train loss and acc of batch 52: 49.044368743896484, 0.953125\n",
      "Train loss and acc of batch 53: 47.78852081298828, 1.0\n",
      "Train loss and acc of batch 54: 48.005279541015625, 0.984375\n",
      "Train loss and acc of batch 55: 47.78850555419922, 1.0\n",
      "Train loss and acc of batch 56: 47.78849411010742, 1.0\n",
      "Train loss and acc of batch 57: 48.384185791015625, 0.984375\n",
      "Train loss and acc of batch 58: 47.788475036621094, 1.0\n",
      "Train loss and acc of batch 59: 47.78846740722656, 1.0\n",
      "Train loss and acc of batch 60: 47.78845977783203, 1.0\n",
      "Train loss and acc of batch 61: 47.7884521484375, 1.0\n",
      "Train loss and acc of batch 62: 47.7884407043457, 1.0\n",
      "Train loss and acc of batch 63: 48.979835510253906, 0.96875\n",
      "Train loss and acc of batch 64: 48.00518798828125, 0.984375\n",
      "Train loss and acc of batch 65: 47.78841781616211, 1.0\n",
      "Train loss and acc of batch 66: 47.78840255737305, 1.0\n",
      "Train loss and acc of batch 67: 48.600860595703125, 0.96875\n",
      "Train loss and acc of batch 68: 48.38409423828125, 0.984375\n",
      "Train loss and acc of batch 69: 48.00514221191406, 0.984375\n",
      "Train loss and acc of batch 70: 47.78837203979492, 1.0\n",
      "Training accuracy and loss of epoch #427: 0.9897, 48.1096\n",
      "Saved model by train loss 48.10956406929124\n",
      "Train loss and acc of batch 0: 47.788360595703125, 1.0\n",
      "Train loss and acc of batch 1: 47.788352966308594, 1.0\n",
      "Train loss and acc of batch 2: 47.7883415222168, 1.0\n",
      "Train loss and acc of batch 3: 48.005096435546875, 0.984375\n",
      "Train loss and acc of batch 4: 47.788326263427734, 1.0\n",
      "Train loss and acc of batch 5: 49.137245178222656, 0.96875\n",
      "Train loss and acc of batch 6: 48.29092788696289, 0.96875\n",
      "Train loss and acc of batch 7: 47.78830337524414, 1.0\n",
      "Train loss and acc of batch 8: 48.383995056152344, 0.984375\n",
      "Train loss and acc of batch 9: 48.074127197265625, 0.984375\n",
      "Train loss and acc of batch 10: 47.78826904296875, 1.0\n",
      "Train loss and acc of batch 11: 47.78826141357422, 1.0\n",
      "Train loss and acc of batch 12: 48.54147720336914, 0.984375\n",
      "Train loss and acc of batch 13: 48.00501251220703, 0.984375\n",
      "Train loss and acc of batch 14: 48.0050048828125, 0.984375\n",
      "Train loss and acc of batch 15: 48.38392639160156, 0.984375\n",
      "Train loss and acc of batch 16: 48.38391876220703, 0.984375\n",
      "Train loss and acc of batch 17: 48.54143524169922, 0.984375\n",
      "Train loss and acc of batch 18: 48.66975402832031, 0.96875\n",
      "Train loss and acc of batch 19: 47.78818893432617, 1.0\n",
      "Train loss and acc of batch 20: 47.78818130493164, 1.0\n",
      "Train loss and acc of batch 21: 48.383880615234375, 0.984375\n",
      "Train loss and acc of batch 22: 48.383872985839844, 0.984375\n",
      "Train loss and acc of batch 23: 47.78815460205078, 1.0\n",
      "Train loss and acc of batch 24: 48.38385009765625, 0.984375\n",
      "Train loss and acc of batch 25: 47.78813934326172, 1.0\n",
      "Train loss and acc of batch 26: 47.78813171386719, 1.0\n",
      "Train loss and acc of batch 27: 47.788124084472656, 1.0\n",
      "Train loss and acc of batch 28: 47.78811264038086, 1.0\n",
      "Train loss and acc of batch 29: 48.38380432128906, 0.984375\n",
      "Train loss and acc of batch 30: 47.7880973815918, 1.0\n",
      "Train loss and acc of batch 31: 48.004852294921875, 0.984375\n",
      "Train loss and acc of batch 32: 47.7880744934082, 1.0\n",
      "Train loss and acc of batch 33: 47.78806686401367, 1.0\n",
      "Train loss and acc of batch 34: 48.383766174316406, 0.984375\n",
      "Train loss and acc of batch 35: 48.221580505371094, 0.96875\n",
      "Train loss and acc of batch 36: 47.78804016113281, 1.0\n",
      "Train loss and acc of batch 37: 48.54125213623047, 0.984375\n",
      "Train loss and acc of batch 38: 49.13694763183594, 0.96875\n",
      "Train loss and acc of batch 39: 48.00477600097656, 0.984375\n",
      "Train loss and acc of batch 40: 47.78800582885742, 1.0\n",
      "Train loss and acc of batch 41: 49.136924743652344, 0.96875\n",
      "Train loss and acc of batch 42: 47.787986755371094, 1.0\n",
      "Train loss and acc of batch 43: 48.38367462158203, 0.984375\n",
      "Train loss and acc of batch 44: 47.7879753112793, 1.0\n",
      "Train loss and acc of batch 45: 48.38365936279297, 0.984375\n",
      "Train loss and acc of batch 46: 48.07380676269531, 0.984375\n",
      "Train loss and acc of batch 47: 47.78794479370117, 1.0\n",
      "Train loss and acc of batch 48: 47.78792953491211, 1.0\n",
      "Train loss and acc of batch 49: 47.787925720214844, 1.0\n",
      "Train loss and acc of batch 50: 48.38361358642578, 0.984375\n",
      "Train loss and acc of batch 51: 49.13683319091797, 0.96875\n",
      "Train loss and acc of batch 52: 49.043739318847656, 0.953125\n",
      "Train loss and acc of batch 53: 47.78788757324219, 1.0\n",
      "Train loss and acc of batch 54: 48.00464630126953, 0.984375\n",
      "Train loss and acc of batch 55: 47.787872314453125, 1.0\n",
      "Train loss and acc of batch 56: 47.787864685058594, 1.0\n",
      "Train loss and acc of batch 57: 48.38355255126953, 0.984375\n",
      "Train loss and acc of batch 58: 47.78784942626953, 1.0\n",
      "Train loss and acc of batch 59: 47.787841796875, 1.0\n",
      "Train loss and acc of batch 60: 47.78782272338867, 1.0\n",
      "Train loss and acc of batch 61: 47.787818908691406, 1.0\n",
      "Train loss and acc of batch 62: 47.787811279296875, 1.0\n",
      "Train loss and acc of batch 63: 48.97920608520508, 0.96875\n",
      "Train loss and acc of batch 64: 48.00456237792969, 0.984375\n",
      "Train loss and acc of batch 65: 47.78778076171875, 1.0\n",
      "Train loss and acc of batch 66: 47.787776947021484, 1.0\n",
      "Train loss and acc of batch 67: 48.60023498535156, 0.96875\n",
      "Train loss and acc of batch 68: 48.383460998535156, 0.984375\n",
      "Train loss and acc of batch 69: 48.0045166015625, 0.984375\n",
      "Train loss and acc of batch 70: 47.78773880004883, 1.0\n",
      "Training accuracy and loss of epoch #428: 0.9897, 48.1089\n",
      "Saved model by train loss 48.10893373086419\n",
      "Train loss and acc of batch 0: 47.7877311706543, 1.0\n",
      "Train loss and acc of batch 1: 47.787723541259766, 1.0\n",
      "Train loss and acc of batch 2: 47.78771209716797, 1.0\n",
      "Train loss and acc of batch 3: 48.00446319580078, 0.984375\n",
      "Train loss and acc of batch 4: 47.78769302368164, 1.0\n",
      "Train loss and acc of batch 5: 49.13661193847656, 0.96875\n",
      "Train loss and acc of batch 6: 48.2902946472168, 0.96875\n",
      "Train loss and acc of batch 7: 47.78767013549805, 1.0\n",
      "Train loss and acc of batch 8: 48.38336181640625, 0.984375\n",
      "Train loss and acc of batch 9: 48.07350158691406, 0.984375\n",
      "Train loss and acc of batch 10: 47.78764724731445, 1.0\n",
      "Train loss and acc of batch 11: 47.787628173828125, 1.0\n",
      "Train loss and acc of batch 12: 48.54084777832031, 0.984375\n",
      "Train loss and acc of batch 13: 48.00437927246094, 0.984375\n",
      "Train loss and acc of batch 14: 48.004371643066406, 0.984375\n",
      "Train loss and acc of batch 15: 48.38330078125, 0.984375\n",
      "Train loss and acc of batch 16: 48.38328552246094, 0.984375\n",
      "Train loss and acc of batch 17: 48.540802001953125, 0.984375\n",
      "Train loss and acc of batch 18: 48.66912841796875, 0.96875\n",
      "Train loss and acc of batch 19: 47.787559509277344, 1.0\n",
      "Train loss and acc of batch 20: 47.78755187988281, 1.0\n",
      "Train loss and acc of batch 21: 48.38324737548828, 0.984375\n",
      "Train loss and acc of batch 22: 48.38323974609375, 0.984375\n",
      "Train loss and acc of batch 23: 47.78752517700195, 1.0\n",
      "Train loss and acc of batch 24: 48.38322448730469, 0.984375\n",
      "Train loss and acc of batch 25: 47.78750991821289, 1.0\n",
      "Train loss and acc of batch 26: 47.787498474121094, 1.0\n",
      "Train loss and acc of batch 27: 47.78749084472656, 1.0\n",
      "Train loss and acc of batch 28: 47.787479400634766, 1.0\n",
      "Train loss and acc of batch 29: 48.3831787109375, 0.984375\n",
      "Train loss and acc of batch 30: 47.78746032714844, 1.0\n",
      "Train loss and acc of batch 31: 48.00421905517578, 0.984375\n",
      "Train loss and acc of batch 32: 47.78744888305664, 1.0\n",
      "Train loss and acc of batch 33: 47.787437438964844, 1.0\n",
      "Train loss and acc of batch 34: 48.38312530517578, 0.984375\n",
      "Train loss and acc of batch 35: 48.220951080322266, 0.96875\n",
      "Train loss and acc of batch 36: 47.787410736083984, 1.0\n",
      "Train loss and acc of batch 37: 48.540626525878906, 0.984375\n",
      "Train loss and acc of batch 38: 49.136322021484375, 0.96875\n",
      "Train loss and acc of batch 39: 48.004150390625, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 40: 47.78737258911133, 1.0\n",
      "Train loss and acc of batch 41: 49.136295318603516, 0.96875\n",
      "Train loss and acc of batch 42: 47.787353515625, 1.0\n",
      "Train loss and acc of batch 43: 48.38304901123047, 0.984375\n",
      "Train loss and acc of batch 44: 47.7873420715332, 1.0\n",
      "Train loss and acc of batch 45: 48.383033752441406, 0.984375\n",
      "Train loss and acc of batch 46: 48.07317352294922, 0.984375\n",
      "Train loss and acc of batch 47: 47.78731155395508, 1.0\n",
      "Train loss and acc of batch 48: 47.78730392456055, 1.0\n",
      "Train loss and acc of batch 49: 47.787296295166016, 1.0\n",
      "Train loss and acc of batch 50: 48.38298797607422, 0.984375\n",
      "Train loss and acc of batch 51: 49.136199951171875, 0.96875\n",
      "Train loss and acc of batch 52: 49.04310989379883, 0.953125\n",
      "Train loss and acc of batch 53: 47.78726577758789, 1.0\n",
      "Train loss and acc of batch 54: 48.00401306152344, 0.984375\n",
      "Train loss and acc of batch 55: 47.7872428894043, 1.0\n",
      "Train loss and acc of batch 56: 47.7872314453125, 1.0\n",
      "Train loss and acc of batch 57: 48.38292694091797, 0.984375\n",
      "Train loss and acc of batch 58: 47.7872200012207, 1.0\n",
      "Train loss and acc of batch 59: 47.78720474243164, 1.0\n",
      "Train loss and acc of batch 60: 47.78719711303711, 1.0\n",
      "Train loss and acc of batch 61: 47.78718948364258, 1.0\n",
      "Train loss and acc of batch 62: 47.78718185424805, 1.0\n",
      "Train loss and acc of batch 63: 48.97857666015625, 0.96875\n",
      "Train loss and acc of batch 64: 48.003929138183594, 0.984375\n",
      "Train loss and acc of batch 65: 47.78715133666992, 1.0\n",
      "Train loss and acc of batch 66: 47.787147521972656, 1.0\n",
      "Train loss and acc of batch 67: 48.5995979309082, 0.96875\n",
      "Train loss and acc of batch 68: 48.38282775878906, 0.984375\n",
      "Train loss and acc of batch 69: 48.003883361816406, 0.984375\n",
      "Train loss and acc of batch 70: 47.787105560302734, 1.0\n",
      "Training accuracy and loss of epoch #429: 0.9897, 48.1083\n",
      "Saved model by train loss 48.108303284980884\n",
      "Train loss and acc of batch 0: 47.7870979309082, 1.0\n",
      "Train loss and acc of batch 1: 47.78709411621094, 1.0\n",
      "Train loss and acc of batch 2: 47.787078857421875, 1.0\n",
      "Train loss and acc of batch 3: 48.00383758544922, 0.984375\n",
      "Train loss and acc of batch 4: 47.78706359863281, 1.0\n",
      "Train loss and acc of batch 5: 49.13597869873047, 0.96875\n",
      "Train loss and acc of batch 6: 48.28966522216797, 0.96875\n",
      "Train loss and acc of batch 7: 47.78704071044922, 1.0\n",
      "Train loss and acc of batch 8: 48.382728576660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.0728759765625, 0.984375\n",
      "Train loss and acc of batch 10: 47.78700637817383, 1.0\n",
      "Train loss and acc of batch 11: 47.78700256347656, 1.0\n",
      "Train loss and acc of batch 12: 48.540218353271484, 0.984375\n",
      "Train loss and acc of batch 13: 48.003746032714844, 0.984375\n",
      "Train loss and acc of batch 14: 48.00373840332031, 0.984375\n",
      "Train loss and acc of batch 15: 48.38267517089844, 0.984375\n",
      "Train loss and acc of batch 16: 48.382659912109375, 0.984375\n",
      "Train loss and acc of batch 17: 48.5401725769043, 0.984375\n",
      "Train loss and acc of batch 18: 48.66849136352539, 0.96875\n",
      "Train loss and acc of batch 19: 47.786930084228516, 1.0\n",
      "Train loss and acc of batch 20: 47.786922454833984, 1.0\n",
      "Train loss and acc of batch 21: 48.38261413574219, 0.984375\n",
      "Train loss and acc of batch 22: 48.382606506347656, 0.984375\n",
      "Train loss and acc of batch 23: 47.786895751953125, 1.0\n",
      "Train loss and acc of batch 24: 48.38258361816406, 0.984375\n",
      "Train loss and acc of batch 25: 47.78688049316406, 1.0\n",
      "Train loss and acc of batch 26: 47.786869049072266, 1.0\n",
      "Train loss and acc of batch 27: 47.78685760498047, 1.0\n",
      "Train loss and acc of batch 28: 47.78684997558594, 1.0\n",
      "Train loss and acc of batch 29: 48.382545471191406, 0.984375\n",
      "Train loss and acc of batch 30: 47.786834716796875, 1.0\n",
      "Train loss and acc of batch 31: 48.00358581542969, 0.984375\n",
      "Train loss and acc of batch 32: 47.78681564331055, 1.0\n",
      "Train loss and acc of batch 33: 47.78680419921875, 1.0\n",
      "Train loss and acc of batch 34: 48.38249969482422, 0.984375\n",
      "Train loss and acc of batch 35: 48.22031784057617, 0.96875\n",
      "Train loss and acc of batch 36: 47.786781311035156, 1.0\n",
      "Train loss and acc of batch 37: 48.53999710083008, 0.984375\n",
      "Train loss and acc of batch 38: 49.13568878173828, 0.96875\n",
      "Train loss and acc of batch 39: 48.003517150878906, 0.984375\n",
      "Train loss and acc of batch 40: 47.786746978759766, 1.0\n",
      "Train loss and acc of batch 41: 49.135658264160156, 0.96875\n",
      "Train loss and acc of batch 42: 47.78672790527344, 1.0\n",
      "Train loss and acc of batch 43: 48.382415771484375, 0.984375\n",
      "Train loss and acc of batch 44: 47.786705017089844, 1.0\n",
      "Train loss and acc of batch 45: 48.38240051269531, 0.984375\n",
      "Train loss and acc of batch 46: 48.072540283203125, 0.984375\n",
      "Train loss and acc of batch 47: 47.786678314208984, 1.0\n",
      "Train loss and acc of batch 48: 47.78667449951172, 1.0\n",
      "Train loss and acc of batch 49: 47.78666305541992, 1.0\n",
      "Train loss and acc of batch 50: 48.382354736328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.13556671142578, 0.96875\n",
      "Train loss and acc of batch 52: 49.042476654052734, 0.953125\n",
      "Train loss and acc of batch 53: 47.78662872314453, 1.0\n",
      "Train loss and acc of batch 54: 48.003379821777344, 0.984375\n",
      "Train loss and acc of batch 55: 47.7866096496582, 1.0\n",
      "Train loss and acc of batch 56: 47.78660202026367, 1.0\n",
      "Train loss and acc of batch 57: 48.382293701171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.78657913208008, 1.0\n",
      "Train loss and acc of batch 59: 47.78657150268555, 1.0\n",
      "Train loss and acc of batch 60: 47.78656005859375, 1.0\n",
      "Train loss and acc of batch 61: 47.786556243896484, 1.0\n",
      "Train loss and acc of batch 62: 47.78654861450195, 1.0\n",
      "Train loss and acc of batch 63: 48.977943420410156, 0.96875\n",
      "Train loss and acc of batch 64: 48.00328826904297, 0.984375\n",
      "Train loss and acc of batch 65: 47.786521911621094, 1.0\n",
      "Train loss and acc of batch 66: 47.7865104675293, 1.0\n",
      "Train loss and acc of batch 67: 48.598968505859375, 0.96875\n",
      "Train loss and acc of batch 68: 48.38219451904297, 0.984375\n",
      "Train loss and acc of batch 69: 48.00325012207031, 0.984375\n",
      "Train loss and acc of batch 70: 47.786476135253906, 1.0\n",
      "Training accuracy and loss of epoch #430: 0.9897, 48.1077\n",
      "Saved model by train loss 48.10767128098179\n",
      "Train loss and acc of batch 0: 47.78647232055664, 1.0\n",
      "Train loss and acc of batch 1: 47.78645324707031, 1.0\n",
      "Train loss and acc of batch 2: 47.78644561767578, 1.0\n",
      "Train loss and acc of batch 3: 48.003204345703125, 0.984375\n",
      "Train loss and acc of batch 4: 47.78643035888672, 1.0\n",
      "Train loss and acc of batch 5: 49.135345458984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.289031982421875, 0.96875\n",
      "Train loss and acc of batch 7: 47.78640365600586, 1.0\n",
      "Train loss and acc of batch 8: 48.38209533691406, 0.984375\n",
      "Train loss and acc of batch 9: 48.072235107421875, 0.984375\n",
      "Train loss and acc of batch 10: 47.786380767822266, 1.0\n",
      "Train loss and acc of batch 11: 47.78636932373047, 1.0\n",
      "Train loss and acc of batch 12: 48.539581298828125, 0.984375\n",
      "Train loss and acc of batch 13: 48.00311279296875, 0.984375\n",
      "Train loss and acc of batch 14: 48.00310516357422, 0.984375\n",
      "Train loss and acc of batch 15: 48.38203430175781, 0.984375\n",
      "Train loss and acc of batch 16: 48.38202667236328, 0.984375\n",
      "Train loss and acc of batch 17: 48.53953552246094, 0.984375\n",
      "Train loss and acc of batch 18: 48.6678581237793, 0.96875\n",
      "Train loss and acc of batch 19: 47.78630065917969, 1.0\n",
      "Train loss and acc of batch 20: 47.78628921508789, 1.0\n",
      "Train loss and acc of batch 21: 48.381980895996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.38197326660156, 0.984375\n",
      "Train loss and acc of batch 23: 47.78626251220703, 1.0\n",
      "Train loss and acc of batch 24: 48.3819580078125, 0.984375\n",
      "Train loss and acc of batch 25: 47.78624725341797, 1.0\n",
      "Train loss and acc of batch 26: 47.786231994628906, 1.0\n",
      "Train loss and acc of batch 27: 47.78622817993164, 1.0\n",
      "Train loss and acc of batch 28: 47.78622055053711, 1.0\n",
      "Train loss and acc of batch 29: 48.38191223144531, 0.984375\n",
      "Train loss and acc of batch 30: 47.78619384765625, 1.0\n",
      "Train loss and acc of batch 31: 48.002952575683594, 0.984375\n",
      "Train loss and acc of batch 32: 47.78617858886719, 1.0\n",
      "Train loss and acc of batch 33: 47.78617477416992, 1.0\n",
      "Train loss and acc of batch 34: 48.381866455078125, 0.984375\n",
      "Train loss and acc of batch 35: 48.21968460083008, 0.96875\n",
      "Train loss and acc of batch 36: 47.7861442565918, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 37: 48.53936004638672, 0.984375\n",
      "Train loss and acc of batch 38: 49.13505554199219, 0.96875\n",
      "Train loss and acc of batch 39: 48.00288391113281, 0.984375\n",
      "Train loss and acc of batch 40: 47.786109924316406, 1.0\n",
      "Train loss and acc of batch 41: 49.13502883911133, 0.96875\n",
      "Train loss and acc of batch 42: 47.78609085083008, 1.0\n",
      "Train loss and acc of batch 43: 48.38179016113281, 0.984375\n",
      "Train loss and acc of batch 44: 47.78607177734375, 1.0\n",
      "Train loss and acc of batch 45: 48.38176727294922, 0.984375\n",
      "Train loss and acc of batch 46: 48.07190704345703, 0.984375\n",
      "Train loss and acc of batch 47: 47.78605270385742, 1.0\n",
      "Train loss and acc of batch 48: 47.786041259765625, 1.0\n",
      "Train loss and acc of batch 49: 47.78602981567383, 1.0\n",
      "Train loss and acc of batch 50: 48.38172149658203, 0.984375\n",
      "Train loss and acc of batch 51: 49.13494110107422, 0.96875\n",
      "Train loss and acc of batch 52: 49.041847229003906, 0.953125\n",
      "Train loss and acc of batch 53: 47.7859992980957, 1.0\n",
      "Train loss and acc of batch 54: 48.00275421142578, 0.984375\n",
      "Train loss and acc of batch 55: 47.785980224609375, 1.0\n",
      "Train loss and acc of batch 56: 47.78596878051758, 1.0\n",
      "Train loss and acc of batch 57: 48.38166046142578, 0.984375\n",
      "Train loss and acc of batch 58: 47.785953521728516, 1.0\n",
      "Train loss and acc of batch 59: 47.78594207763672, 1.0\n",
      "Train loss and acc of batch 60: 47.78593444824219, 1.0\n",
      "Train loss and acc of batch 61: 47.785926818847656, 1.0\n",
      "Train loss and acc of batch 62: 47.78591537475586, 1.0\n",
      "Train loss and acc of batch 63: 48.97731018066406, 0.96875\n",
      "Train loss and acc of batch 64: 48.002662658691406, 0.984375\n",
      "Train loss and acc of batch 65: 47.785888671875, 1.0\n",
      "Train loss and acc of batch 66: 47.78588104248047, 1.0\n",
      "Train loss and acc of batch 67: 48.598331451416016, 0.96875\n",
      "Train loss and acc of batch 68: 48.381561279296875, 0.984375\n",
      "Train loss and acc of batch 69: 48.00261688232422, 0.984375\n",
      "Train loss and acc of batch 70: 47.785850524902344, 1.0\n",
      "Training accuracy and loss of epoch #431: 0.9897, 48.1070\n",
      "Saved model by train loss 48.10703884715765\n",
      "Train loss and acc of batch 0: 47.78583908081055, 1.0\n",
      "Train loss and acc of batch 1: 47.785831451416016, 1.0\n",
      "Train loss and acc of batch 2: 47.78582000732422, 1.0\n",
      "Train loss and acc of batch 3: 48.00257873535156, 0.984375\n",
      "Train loss and acc of batch 4: 47.78580093383789, 1.0\n",
      "Train loss and acc of batch 5: 49.13471221923828, 0.96875\n",
      "Train loss and acc of batch 6: 48.28839874267578, 0.96875\n",
      "Train loss and acc of batch 7: 47.78577423095703, 1.0\n",
      "Train loss and acc of batch 8: 48.38146209716797, 0.984375\n",
      "Train loss and acc of batch 9: 48.07160949707031, 0.984375\n",
      "Train loss and acc of batch 10: 47.78574752807617, 1.0\n",
      "Train loss and acc of batch 11: 47.785736083984375, 1.0\n",
      "Train loss and acc of batch 12: 48.5389518737793, 0.984375\n",
      "Train loss and acc of batch 13: 48.00248718261719, 0.984375\n",
      "Train loss and acc of batch 14: 48.002479553222656, 0.984375\n",
      "Train loss and acc of batch 15: 48.38140869140625, 0.984375\n",
      "Train loss and acc of batch 16: 48.38140106201172, 0.984375\n",
      "Train loss and acc of batch 17: 48.53890609741211, 0.984375\n",
      "Train loss and acc of batch 18: 48.66722869873047, 0.96875\n",
      "Train loss and acc of batch 19: 47.78567123413086, 1.0\n",
      "Train loss and acc of batch 20: 47.78565979003906, 1.0\n",
      "Train loss and acc of batch 21: 48.38134765625, 0.984375\n",
      "Train loss and acc of batch 22: 48.38134002685547, 0.984375\n",
      "Train loss and acc of batch 23: 47.78563690185547, 1.0\n",
      "Train loss and acc of batch 24: 48.381324768066406, 0.984375\n",
      "Train loss and acc of batch 25: 47.78561019897461, 1.0\n",
      "Train loss and acc of batch 26: 47.785606384277344, 1.0\n",
      "Train loss and acc of batch 27: 47.78559875488281, 1.0\n",
      "Train loss and acc of batch 28: 47.785587310791016, 1.0\n",
      "Train loss and acc of batch 29: 48.38127899169922, 0.984375\n",
      "Train loss and acc of batch 30: 47.78557205200195, 1.0\n",
      "Train loss and acc of batch 31: 48.0023193359375, 0.984375\n",
      "Train loss and acc of batch 32: 47.785552978515625, 1.0\n",
      "Train loss and acc of batch 33: 47.785545349121094, 1.0\n",
      "Train loss and acc of batch 34: 48.38123321533203, 0.984375\n",
      "Train loss and acc of batch 35: 48.21905517578125, 0.96875\n",
      "Train loss and acc of batch 36: 47.7855224609375, 1.0\n",
      "Train loss and acc of batch 37: 48.538734436035156, 0.984375\n",
      "Train loss and acc of batch 38: 49.134429931640625, 0.96875\n",
      "Train loss and acc of batch 39: 48.00225067138672, 0.984375\n",
      "Train loss and acc of batch 40: 47.78548049926758, 1.0\n",
      "Train loss and acc of batch 41: 49.134395599365234, 0.96875\n",
      "Train loss and acc of batch 42: 47.78546142578125, 1.0\n",
      "Train loss and acc of batch 43: 48.38115692138672, 0.984375\n",
      "Train loss and acc of batch 44: 47.78544616699219, 1.0\n",
      "Train loss and acc of batch 45: 48.381141662597656, 0.984375\n",
      "Train loss and acc of batch 46: 48.07128143310547, 0.984375\n",
      "Train loss and acc of batch 47: 47.78541946411133, 1.0\n",
      "Train loss and acc of batch 48: 47.78540802001953, 1.0\n",
      "Train loss and acc of batch 49: 47.785400390625, 1.0\n",
      "Train loss and acc of batch 50: 48.38109588623047, 0.984375\n",
      "Train loss and acc of batch 51: 49.134307861328125, 0.96875\n",
      "Train loss and acc of batch 52: 49.04121017456055, 0.953125\n",
      "Train loss and acc of batch 53: 47.785362243652344, 1.0\n",
      "Train loss and acc of batch 54: 48.00212097167969, 0.984375\n",
      "Train loss and acc of batch 55: 47.78534698486328, 1.0\n",
      "Train loss and acc of batch 56: 47.785335540771484, 1.0\n",
      "Train loss and acc of batch 57: 48.38103485107422, 0.984375\n",
      "Train loss and acc of batch 58: 47.78532028198242, 1.0\n",
      "Train loss and acc of batch 59: 47.78531265258789, 1.0\n",
      "Train loss and acc of batch 60: 47.785308837890625, 1.0\n",
      "Train loss and acc of batch 61: 47.78529739379883, 1.0\n",
      "Train loss and acc of batch 62: 47.785282135009766, 1.0\n",
      "Train loss and acc of batch 63: 48.976680755615234, 0.96875\n",
      "Train loss and acc of batch 64: 48.002037048339844, 0.984375\n",
      "Train loss and acc of batch 65: 47.78526306152344, 1.0\n",
      "Train loss and acc of batch 66: 47.78525161743164, 1.0\n",
      "Train loss and acc of batch 67: 48.59770584106445, 0.96875\n",
      "Train loss and acc of batch 68: 48.38093566894531, 0.984375\n",
      "Train loss and acc of batch 69: 48.001983642578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.78520965576172, 1.0\n",
      "Training accuracy and loss of epoch #432: 0.9897, 48.1064\n",
      "Saved model by train loss 48.10640909974004\n",
      "Train loss and acc of batch 0: 47.78520584106445, 1.0\n",
      "Train loss and acc of batch 1: 47.785194396972656, 1.0\n",
      "Train loss and acc of batch 2: 47.78519058227539, 1.0\n",
      "Train loss and acc of batch 3: 48.00194549560547, 0.984375\n",
      "Train loss and acc of batch 4: 47.78517150878906, 1.0\n",
      "Train loss and acc of batch 5: 49.13408660888672, 0.96875\n",
      "Train loss and acc of batch 6: 48.28777313232422, 0.96875\n",
      "Train loss and acc of batch 7: 47.78514099121094, 1.0\n",
      "Train loss and acc of batch 8: 48.380836486816406, 0.984375\n",
      "Train loss and acc of batch 9: 48.07097625732422, 0.984375\n",
      "Train loss and acc of batch 10: 47.78511428833008, 1.0\n",
      "Train loss and acc of batch 11: 47.78510665893555, 1.0\n",
      "Train loss and acc of batch 12: 48.53832244873047, 0.984375\n",
      "Train loss and acc of batch 13: 48.001853942871094, 0.984375\n",
      "Train loss and acc of batch 14: 48.00184631347656, 0.984375\n",
      "Train loss and acc of batch 15: 48.380775451660156, 0.984375\n",
      "Train loss and acc of batch 16: 48.380767822265625, 0.984375\n",
      "Train loss and acc of batch 17: 48.53828048706055, 0.984375\n",
      "Train loss and acc of batch 18: 48.66659927368164, 0.96875\n",
      "Train loss and acc of batch 19: 47.7850341796875, 1.0\n",
      "Train loss and acc of batch 20: 47.785030364990234, 1.0\n",
      "Train loss and acc of batch 21: 48.38072204589844, 0.984375\n",
      "Train loss and acc of batch 22: 48.380714416503906, 0.984375\n",
      "Train loss and acc of batch 23: 47.785003662109375, 1.0\n",
      "Train loss and acc of batch 24: 48.38069152832031, 0.984375\n",
      "Train loss and acc of batch 25: 47.78498458862305, 1.0\n",
      "Train loss and acc of batch 26: 47.784976959228516, 1.0\n",
      "Train loss and acc of batch 27: 47.78496170043945, 1.0\n",
      "Train loss and acc of batch 28: 47.78495788574219, 1.0\n",
      "Train loss and acc of batch 29: 48.380645751953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.78493881225586, 1.0\n",
      "Train loss and acc of batch 31: 48.00170135498047, 0.984375\n",
      "Train loss and acc of batch 32: 47.78491973876953, 1.0\n",
      "Train loss and acc of batch 33: 47.784908294677734, 1.0\n",
      "Train loss and acc of batch 34: 48.38060760498047, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 35: 48.21842575073242, 0.96875\n",
      "Train loss and acc of batch 36: 47.78488540649414, 1.0\n",
      "Train loss and acc of batch 37: 48.53810501098633, 0.984375\n",
      "Train loss and acc of batch 38: 49.1337890625, 0.96875\n",
      "Train loss and acc of batch 39: 48.001625061035156, 0.984375\n",
      "Train loss and acc of batch 40: 47.78485107421875, 1.0\n",
      "Train loss and acc of batch 41: 49.13376235961914, 0.96875\n",
      "Train loss and acc of batch 42: 47.78483200073242, 1.0\n",
      "Train loss and acc of batch 43: 48.380531311035156, 0.984375\n",
      "Train loss and acc of batch 44: 47.784812927246094, 1.0\n",
      "Train loss and acc of batch 45: 48.380516052246094, 0.984375\n",
      "Train loss and acc of batch 46: 48.070648193359375, 0.984375\n",
      "Train loss and acc of batch 47: 47.7847900390625, 1.0\n",
      "Train loss and acc of batch 48: 47.7847785949707, 1.0\n",
      "Train loss and acc of batch 49: 47.78477096557617, 1.0\n",
      "Train loss and acc of batch 50: 48.380462646484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.13368225097656, 0.96875\n",
      "Train loss and acc of batch 52: 49.040584564208984, 0.953125\n",
      "Train loss and acc of batch 53: 47.78473663330078, 1.0\n",
      "Train loss and acc of batch 54: 48.001495361328125, 0.984375\n",
      "Train loss and acc of batch 55: 47.78470993041992, 1.0\n",
      "Train loss and acc of batch 56: 47.78470993041992, 1.0\n",
      "Train loss and acc of batch 57: 48.380401611328125, 0.984375\n",
      "Train loss and acc of batch 58: 47.784690856933594, 1.0\n",
      "Train loss and acc of batch 59: 47.78468704223633, 1.0\n",
      "Train loss and acc of batch 60: 47.78467559814453, 1.0\n",
      "Train loss and acc of batch 61: 47.784664154052734, 1.0\n",
      "Train loss and acc of batch 62: 47.7846565246582, 1.0\n",
      "Train loss and acc of batch 63: 48.97604751586914, 0.96875\n",
      "Train loss and acc of batch 64: 48.00140380859375, 0.984375\n",
      "Train loss and acc of batch 65: 47.78463363647461, 1.0\n",
      "Train loss and acc of batch 66: 47.78462219238281, 1.0\n",
      "Train loss and acc of batch 67: 48.597076416015625, 0.96875\n",
      "Train loss and acc of batch 68: 48.38030242919922, 0.984375\n",
      "Train loss and acc of batch 69: 48.00135803222656, 0.984375\n",
      "Train loss and acc of batch 70: 47.784584045410156, 1.0\n",
      "Training accuracy and loss of epoch #433: 0.9897, 48.1058\n",
      "Saved model by train loss 48.10577881504113\n",
      "Train loss and acc of batch 0: 47.784576416015625, 1.0\n",
      "Train loss and acc of batch 1: 47.78456497192383, 1.0\n",
      "Train loss and acc of batch 2: 47.78456115722656, 1.0\n",
      "Train loss and acc of batch 3: 48.001312255859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.78453826904297, 1.0\n",
      "Train loss and acc of batch 5: 49.133460998535156, 0.96875\n",
      "Train loss and acc of batch 6: 48.28713607788086, 0.96875\n",
      "Train loss and acc of batch 7: 47.784515380859375, 1.0\n",
      "Train loss and acc of batch 8: 48.380210876464844, 0.984375\n",
      "Train loss and acc of batch 9: 48.070350646972656, 0.984375\n",
      "Train loss and acc of batch 10: 47.784488677978516, 1.0\n",
      "Train loss and acc of batch 11: 47.784481048583984, 1.0\n",
      "Train loss and acc of batch 12: 48.537696838378906, 0.984375\n",
      "Train loss and acc of batch 13: 48.001220703125, 0.984375\n",
      "Train loss and acc of batch 14: 48.00121307373047, 0.984375\n",
      "Train loss and acc of batch 15: 48.38014221191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.38013458251953, 0.984375\n",
      "Train loss and acc of batch 17: 48.53764724731445, 0.984375\n",
      "Train loss and acc of batch 18: 48.66596984863281, 0.96875\n",
      "Train loss and acc of batch 19: 47.78440856933594, 1.0\n",
      "Train loss and acc of batch 20: 47.784400939941406, 1.0\n",
      "Train loss and acc of batch 21: 48.380088806152344, 0.984375\n",
      "Train loss and acc of batch 22: 48.38008117675781, 0.984375\n",
      "Train loss and acc of batch 23: 47.78437042236328, 1.0\n",
      "Train loss and acc of batch 24: 48.38006591796875, 0.984375\n",
      "Train loss and acc of batch 25: 47.78435134887695, 1.0\n",
      "Train loss and acc of batch 26: 47.78434753417969, 1.0\n",
      "Train loss and acc of batch 27: 47.784332275390625, 1.0\n",
      "Train loss and acc of batch 28: 47.78432846069336, 1.0\n",
      "Train loss and acc of batch 29: 48.38002014160156, 0.984375\n",
      "Train loss and acc of batch 30: 47.78430938720703, 1.0\n",
      "Train loss and acc of batch 31: 48.001060485839844, 0.984375\n",
      "Train loss and acc of batch 32: 47.7842903137207, 1.0\n",
      "Train loss and acc of batch 33: 47.78428649902344, 1.0\n",
      "Train loss and acc of batch 34: 48.379974365234375, 0.984375\n",
      "Train loss and acc of batch 35: 48.21779251098633, 0.96875\n",
      "Train loss and acc of batch 36: 47.78425598144531, 1.0\n",
      "Train loss and acc of batch 37: 48.53746795654297, 0.984375\n",
      "Train loss and acc of batch 38: 49.13316345214844, 0.96875\n",
      "Train loss and acc of batch 39: 48.00099182128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.78422164916992, 1.0\n",
      "Train loss and acc of batch 41: 49.13313674926758, 0.96875\n",
      "Train loss and acc of batch 42: 47.784202575683594, 1.0\n",
      "Train loss and acc of batch 43: 48.37989044189453, 0.984375\n",
      "Train loss and acc of batch 44: 47.78418731689453, 1.0\n",
      "Train loss and acc of batch 45: 48.37987518310547, 0.984375\n",
      "Train loss and acc of batch 46: 48.07001495361328, 0.984375\n",
      "Train loss and acc of batch 47: 47.78416061401367, 1.0\n",
      "Train loss and acc of batch 48: 47.78415298461914, 1.0\n",
      "Train loss and acc of batch 49: 47.78413772583008, 1.0\n",
      "Train loss and acc of batch 50: 48.37983703613281, 0.984375\n",
      "Train loss and acc of batch 51: 49.13304901123047, 0.96875\n",
      "Train loss and acc of batch 52: 49.039955139160156, 0.953125\n",
      "Train loss and acc of batch 53: 47.78410720825195, 1.0\n",
      "Train loss and acc of batch 54: 48.00086212158203, 0.984375\n",
      "Train loss and acc of batch 55: 47.784088134765625, 1.0\n",
      "Train loss and acc of batch 56: 47.78407669067383, 1.0\n",
      "Train loss and acc of batch 57: 48.37976837158203, 0.984375\n",
      "Train loss and acc of batch 58: 47.784061431884766, 1.0\n",
      "Train loss and acc of batch 59: 47.78404998779297, 1.0\n",
      "Train loss and acc of batch 60: 47.78403854370117, 1.0\n",
      "Train loss and acc of batch 61: 47.784034729003906, 1.0\n",
      "Train loss and acc of batch 62: 47.784027099609375, 1.0\n",
      "Train loss and acc of batch 63: 48.97541809082031, 0.96875\n",
      "Train loss and acc of batch 64: 48.000770568847656, 0.984375\n",
      "Train loss and acc of batch 65: 47.784000396728516, 1.0\n",
      "Train loss and acc of batch 66: 47.78398895263672, 1.0\n",
      "Train loss and acc of batch 67: 48.59645080566406, 0.96875\n",
      "Train loss and acc of batch 68: 48.379669189453125, 0.984375\n",
      "Train loss and acc of batch 69: 48.00072479248047, 0.984375\n",
      "Train loss and acc of batch 70: 47.783958435058594, 1.0\n",
      "Training accuracy and loss of epoch #434: 0.9897, 48.1051\n",
      "Saved model by train loss 48.10514826170156\n",
      "Train loss and acc of batch 0: 47.7839469909668, 1.0\n",
      "Train loss and acc of batch 1: 47.783935546875, 1.0\n",
      "Train loss and acc of batch 2: 47.783931732177734, 1.0\n",
      "Train loss and acc of batch 3: 48.00067901611328, 0.984375\n",
      "Train loss and acc of batch 4: 47.783912658691406, 1.0\n",
      "Train loss and acc of batch 5: 49.13282775878906, 0.96875\n",
      "Train loss and acc of batch 6: 48.2865104675293, 0.96875\n",
      "Train loss and acc of batch 7: 47.78388214111328, 1.0\n",
      "Train loss and acc of batch 8: 48.37957000732422, 0.984375\n",
      "Train loss and acc of batch 9: 48.06971740722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.78385925292969, 1.0\n",
      "Train loss and acc of batch 11: 47.783843994140625, 1.0\n",
      "Train loss and acc of batch 12: 48.53706359863281, 0.984375\n",
      "Train loss and acc of batch 13: 48.00059509277344, 0.984375\n",
      "Train loss and acc of batch 14: 48.000587463378906, 0.984375\n",
      "Train loss and acc of batch 15: 48.3795166015625, 0.984375\n",
      "Train loss and acc of batch 16: 48.37950897216797, 0.984375\n",
      "Train loss and acc of batch 17: 48.537017822265625, 0.984375\n",
      "Train loss and acc of batch 18: 48.665340423583984, 0.96875\n",
      "Train loss and acc of batch 19: 47.78377914428711, 1.0\n",
      "Train loss and acc of batch 20: 47.78376770019531, 1.0\n",
      "Train loss and acc of batch 21: 48.37946319580078, 0.984375\n",
      "Train loss and acc of batch 22: 48.37944793701172, 0.984375\n",
      "Train loss and acc of batch 23: 47.78374099731445, 1.0\n",
      "Train loss and acc of batch 24: 48.37944030761719, 0.984375\n",
      "Train loss and acc of batch 25: 47.783721923828125, 1.0\n",
      "Train loss and acc of batch 26: 47.783714294433594, 1.0\n",
      "Train loss and acc of batch 27: 47.78370666503906, 1.0\n",
      "Train loss and acc of batch 28: 47.78369903564453, 1.0\n",
      "Train loss and acc of batch 29: 48.37938690185547, 0.984375\n",
      "Train loss and acc of batch 30: 47.7836799621582, 1.0\n",
      "Train loss and acc of batch 31: 48.00043487548828, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 32: 47.78366470336914, 1.0\n",
      "Train loss and acc of batch 33: 47.783653259277344, 1.0\n",
      "Train loss and acc of batch 34: 48.37934112548828, 0.984375\n",
      "Train loss and acc of batch 35: 48.217166900634766, 0.96875\n",
      "Train loss and acc of batch 36: 47.783626556396484, 1.0\n",
      "Train loss and acc of batch 37: 48.53683853149414, 0.984375\n",
      "Train loss and acc of batch 38: 49.132530212402344, 0.96875\n",
      "Train loss and acc of batch 39: 48.00035858154297, 0.984375\n",
      "Train loss and acc of batch 40: 47.78358840942383, 1.0\n",
      "Train loss and acc of batch 41: 49.132511138916016, 0.96875\n",
      "Train loss and acc of batch 42: 47.7835693359375, 1.0\n",
      "Train loss and acc of batch 43: 48.37926483154297, 0.984375\n",
      "Train loss and acc of batch 44: 47.78355407714844, 1.0\n",
      "Train loss and acc of batch 45: 48.379241943359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.06938934326172, 0.984375\n",
      "Train loss and acc of batch 47: 47.783531188964844, 1.0\n",
      "Train loss and acc of batch 48: 47.78351593017578, 1.0\n",
      "Train loss and acc of batch 49: 47.78351593017578, 1.0\n",
      "Train loss and acc of batch 50: 48.37920379638672, 0.984375\n",
      "Train loss and acc of batch 51: 49.132415771484375, 0.96875\n",
      "Train loss and acc of batch 52: 49.03932571411133, 0.953125\n",
      "Train loss and acc of batch 53: 47.783477783203125, 1.0\n",
      "Train loss and acc of batch 54: 48.00022888183594, 0.984375\n",
      "Train loss and acc of batch 55: 47.7834587097168, 1.0\n",
      "Train loss and acc of batch 56: 47.783447265625, 1.0\n",
      "Train loss and acc of batch 57: 48.37914276123047, 0.984375\n",
      "Train loss and acc of batch 58: 47.78343200683594, 1.0\n",
      "Train loss and acc of batch 59: 47.783416748046875, 1.0\n",
      "Train loss and acc of batch 60: 47.78341293334961, 1.0\n",
      "Train loss and acc of batch 61: 47.78340530395508, 1.0\n",
      "Train loss and acc of batch 62: 47.78339385986328, 1.0\n",
      "Train loss and acc of batch 63: 48.974788665771484, 0.96875\n",
      "Train loss and acc of batch 64: 48.000144958496094, 0.984375\n",
      "Train loss and acc of batch 65: 47.78337097167969, 1.0\n",
      "Train loss and acc of batch 66: 47.78335952758789, 1.0\n",
      "Train loss and acc of batch 67: 48.59581756591797, 0.96875\n",
      "Train loss and acc of batch 68: 48.37904357910156, 0.984375\n",
      "Train loss and acc of batch 69: 48.000099182128906, 0.984375\n",
      "Train loss and acc of batch 70: 47.7833251953125, 1.0\n",
      "Training accuracy and loss of epoch #435: 0.9897, 48.1045\n",
      "Saved model by train loss 48.10451835309956\n",
      "Train loss and acc of batch 0: 47.78331756591797, 1.0\n",
      "Train loss and acc of batch 1: 47.78330993652344, 1.0\n",
      "Train loss and acc of batch 2: 47.78329086303711, 1.0\n",
      "Train loss and acc of batch 3: 48.00005340576172, 0.984375\n",
      "Train loss and acc of batch 4: 47.78327941894531, 1.0\n",
      "Train loss and acc of batch 5: 49.13219451904297, 0.96875\n",
      "Train loss and acc of batch 6: 48.2858772277832, 0.96875\n",
      "Train loss and acc of batch 7: 47.78325653076172, 1.0\n",
      "Train loss and acc of batch 8: 48.378944396972656, 0.984375\n",
      "Train loss and acc of batch 9: 48.069091796875, 0.984375\n",
      "Train loss and acc of batch 10: 47.783226013183594, 1.0\n",
      "Train loss and acc of batch 11: 47.78321838378906, 1.0\n",
      "Train loss and acc of batch 12: 48.53643035888672, 0.984375\n",
      "Train loss and acc of batch 13: 47.999961853027344, 0.984375\n",
      "Train loss and acc of batch 14: 47.99995422363281, 0.984375\n",
      "Train loss and acc of batch 15: 48.378883361816406, 0.984375\n",
      "Train loss and acc of batch 16: 48.378868103027344, 0.984375\n",
      "Train loss and acc of batch 17: 48.5363883972168, 0.984375\n",
      "Train loss and acc of batch 18: 48.66470718383789, 0.96875\n",
      "Train loss and acc of batch 19: 47.783145904541016, 1.0\n",
      "Train loss and acc of batch 20: 47.783138275146484, 1.0\n",
      "Train loss and acc of batch 21: 48.37882995605469, 0.984375\n",
      "Train loss and acc of batch 22: 48.378822326660156, 0.984375\n",
      "Train loss and acc of batch 23: 47.78311538696289, 1.0\n",
      "Train loss and acc of batch 24: 48.37879943847656, 0.984375\n",
      "Train loss and acc of batch 25: 47.7830924987793, 1.0\n",
      "Train loss and acc of batch 26: 47.783084869384766, 1.0\n",
      "Train loss and acc of batch 27: 47.7830810546875, 1.0\n",
      "Train loss and acc of batch 28: 47.78306579589844, 1.0\n",
      "Train loss and acc of batch 29: 48.378761291503906, 0.984375\n",
      "Train loss and acc of batch 30: 47.783050537109375, 1.0\n",
      "Train loss and acc of batch 31: 47.99980163574219, 0.984375\n",
      "Train loss and acc of batch 32: 47.78303146362305, 1.0\n",
      "Train loss and acc of batch 33: 47.78302001953125, 1.0\n",
      "Train loss and acc of batch 34: 48.37871551513672, 0.984375\n",
      "Train loss and acc of batch 35: 48.21653366088867, 0.96875\n",
      "Train loss and acc of batch 36: 47.782997131347656, 1.0\n",
      "Train loss and acc of batch 37: 48.53621292114258, 0.984375\n",
      "Train loss and acc of batch 38: 49.13190460205078, 0.96875\n",
      "Train loss and acc of batch 39: 47.999732971191406, 0.984375\n",
      "Train loss and acc of batch 40: 47.782958984375, 1.0\n",
      "Train loss and acc of batch 41: 49.131874084472656, 0.96875\n",
      "Train loss and acc of batch 42: 47.7829475402832, 1.0\n",
      "Train loss and acc of batch 43: 48.378639221191406, 0.984375\n",
      "Train loss and acc of batch 44: 47.78292465209961, 1.0\n",
      "Train loss and acc of batch 45: 48.37861633300781, 0.984375\n",
      "Train loss and acc of batch 46: 48.068756103515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.78289794921875, 1.0\n",
      "Train loss and acc of batch 48: 47.78289031982422, 1.0\n",
      "Train loss and acc of batch 49: 47.78287887573242, 1.0\n",
      "Train loss and acc of batch 50: 48.378570556640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.13179016113281, 0.96875\n",
      "Train loss and acc of batch 52: 49.0386962890625, 0.953125\n",
      "Train loss and acc of batch 53: 47.782840728759766, 1.0\n",
      "Train loss and acc of batch 54: 47.999603271484375, 0.984375\n",
      "Train loss and acc of batch 55: 47.7828254699707, 1.0\n",
      "Train loss and acc of batch 56: 47.78282165527344, 1.0\n",
      "Train loss and acc of batch 57: 48.378509521484375, 0.984375\n",
      "Train loss and acc of batch 58: 47.782798767089844, 1.0\n",
      "Train loss and acc of batch 59: 47.78279113769531, 1.0\n",
      "Train loss and acc of batch 60: 47.782779693603516, 1.0\n",
      "Train loss and acc of batch 61: 47.782772064208984, 1.0\n",
      "Train loss and acc of batch 62: 47.78276443481445, 1.0\n",
      "Train loss and acc of batch 63: 48.974159240722656, 0.96875\n",
      "Train loss and acc of batch 64: 47.99951171875, 0.984375\n",
      "Train loss and acc of batch 65: 47.782737731933594, 1.0\n",
      "Train loss and acc of batch 66: 47.78273010253906, 1.0\n",
      "Train loss and acc of batch 67: 48.59518814086914, 0.96875\n",
      "Train loss and acc of batch 68: 48.37841796875, 0.984375\n",
      "Train loss and acc of batch 69: 47.99946594238281, 0.984375\n",
      "Train loss and acc of batch 70: 47.78269577026367, 1.0\n",
      "Training accuracy and loss of epoch #436: 0.9897, 48.1039\n",
      "Saved model by train loss 48.10388796094438\n",
      "Train loss and acc of batch 0: 47.78268814086914, 1.0\n",
      "Train loss and acc of batch 1: 47.782676696777344, 1.0\n",
      "Train loss and acc of batch 2: 47.78266906738281, 1.0\n",
      "Train loss and acc of batch 3: 47.999420166015625, 0.984375\n",
      "Train loss and acc of batch 4: 47.782649993896484, 1.0\n",
      "Train loss and acc of batch 5: 49.131561279296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.285247802734375, 0.96875\n",
      "Train loss and acc of batch 7: 47.78261947631836, 1.0\n",
      "Train loss and acc of batch 8: 48.378318786621094, 0.984375\n",
      "Train loss and acc of batch 9: 48.068458557128906, 0.984375\n",
      "Train loss and acc of batch 10: 47.782596588134766, 1.0\n",
      "Train loss and acc of batch 11: 47.78258514404297, 1.0\n",
      "Train loss and acc of batch 12: 48.535804748535156, 0.984375\n",
      "Train loss and acc of batch 13: 47.99933624267578, 0.984375\n",
      "Train loss and acc of batch 14: 47.99932861328125, 0.984375\n",
      "Train loss and acc of batch 15: 48.37825012207031, 0.984375\n",
      "Train loss and acc of batch 16: 48.37824249267578, 0.984375\n",
      "Train loss and acc of batch 17: 48.53575897216797, 0.984375\n",
      "Train loss and acc of batch 18: 48.66407775878906, 0.96875\n",
      "Train loss and acc of batch 19: 47.78251266479492, 1.0\n",
      "Train loss and acc of batch 20: 47.78250503540039, 1.0\n",
      "Train loss and acc of batch 21: 48.378196716308594, 0.984375\n",
      "Train loss and acc of batch 22: 48.37818908691406, 0.984375\n",
      "Train loss and acc of batch 23: 47.78247833251953, 1.0\n",
      "Train loss and acc of batch 24: 48.378173828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.78246307373047, 1.0\n",
      "Train loss and acc of batch 26: 47.78245544433594, 1.0\n",
      "Train loss and acc of batch 27: 47.78244400024414, 1.0\n",
      "Train loss and acc of batch 28: 47.78243637084961, 1.0\n",
      "Train loss and acc of batch 29: 48.37812805175781, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 30: 47.78242111206055, 1.0\n",
      "Train loss and acc of batch 31: 47.999176025390625, 0.984375\n",
      "Train loss and acc of batch 32: 47.78240203857422, 1.0\n",
      "Train loss and acc of batch 33: 47.782386779785156, 1.0\n",
      "Train loss and acc of batch 34: 48.378082275390625, 0.984375\n",
      "Train loss and acc of batch 35: 48.215904235839844, 0.96875\n",
      "Train loss and acc of batch 36: 47.78236770629883, 1.0\n",
      "Train loss and acc of batch 37: 48.535579681396484, 0.984375\n",
      "Train loss and acc of batch 38: 49.13127136230469, 0.96875\n",
      "Train loss and acc of batch 39: 47.999107360839844, 0.984375\n",
      "Train loss and acc of batch 40: 47.78232955932617, 1.0\n",
      "Train loss and acc of batch 41: 49.131248474121094, 0.96875\n",
      "Train loss and acc of batch 42: 47.78231430053711, 1.0\n",
      "Train loss and acc of batch 43: 48.37800598144531, 0.984375\n",
      "Train loss and acc of batch 44: 47.78229522705078, 1.0\n",
      "Train loss and acc of batch 45: 48.37799072265625, 0.984375\n",
      "Train loss and acc of batch 46: 48.06813049316406, 0.984375\n",
      "Train loss and acc of batch 47: 47.78227233886719, 1.0\n",
      "Train loss and acc of batch 48: 47.782257080078125, 1.0\n",
      "Train loss and acc of batch 49: 47.782249450683594, 1.0\n",
      "Train loss and acc of batch 50: 48.37793731689453, 0.984375\n",
      "Train loss and acc of batch 51: 49.13115692138672, 0.96875\n",
      "Train loss and acc of batch 52: 49.038063049316406, 0.953125\n",
      "Train loss and acc of batch 53: 47.78221893310547, 1.0\n",
      "Train loss and acc of batch 54: 47.99897003173828, 0.984375\n",
      "Train loss and acc of batch 55: 47.782196044921875, 1.0\n",
      "Train loss and acc of batch 56: 47.78218460083008, 1.0\n",
      "Train loss and acc of batch 57: 48.37788391113281, 0.984375\n",
      "Train loss and acc of batch 58: 47.782169342041016, 1.0\n",
      "Train loss and acc of batch 59: 47.782161712646484, 1.0\n",
      "Train loss and acc of batch 60: 47.78215026855469, 1.0\n",
      "Train loss and acc of batch 61: 47.78214645385742, 1.0\n",
      "Train loss and acc of batch 62: 47.782135009765625, 1.0\n",
      "Train loss and acc of batch 63: 48.97352600097656, 0.96875\n",
      "Train loss and acc of batch 64: 47.998878479003906, 0.984375\n",
      "Train loss and acc of batch 65: 47.7821044921875, 1.0\n",
      "Train loss and acc of batch 66: 47.78209686279297, 1.0\n",
      "Train loss and acc of batch 67: 48.59455490112305, 0.96875\n",
      "Train loss and acc of batch 68: 48.377784729003906, 0.984375\n",
      "Train loss and acc of batch 69: 47.99883270263672, 0.984375\n",
      "Train loss and acc of batch 70: 47.78206253051758, 1.0\n",
      "Training accuracy and loss of epoch #437: 0.9897, 48.1033\n",
      "Saved model by train loss 48.10325746133294\n",
      "Train loss and acc of batch 0: 47.78205490112305, 1.0\n",
      "Train loss and acc of batch 1: 47.782047271728516, 1.0\n",
      "Train loss and acc of batch 2: 47.782039642333984, 1.0\n",
      "Train loss and acc of batch 3: 47.99879455566406, 0.984375\n",
      "Train loss and acc of batch 4: 47.782020568847656, 1.0\n",
      "Train loss and acc of batch 5: 49.13093566894531, 0.96875\n",
      "Train loss and acc of batch 6: 48.28461456298828, 0.96875\n",
      "Train loss and acc of batch 7: 47.7819938659668, 1.0\n",
      "Train loss and acc of batch 8: 48.377685546875, 0.984375\n",
      "Train loss and acc of batch 9: 48.06782531738281, 0.984375\n",
      "Train loss and acc of batch 10: 47.78196716308594, 1.0\n",
      "Train loss and acc of batch 11: 47.781959533691406, 1.0\n",
      "Train loss and acc of batch 12: 48.5351676940918, 0.984375\n",
      "Train loss and acc of batch 13: 47.99870300292969, 0.984375\n",
      "Train loss and acc of batch 14: 47.998695373535156, 0.984375\n",
      "Train loss and acc of batch 15: 48.37762451171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.37761688232422, 0.984375\n",
      "Train loss and acc of batch 17: 48.535125732421875, 0.984375\n",
      "Train loss and acc of batch 18: 48.663448333740234, 0.96875\n",
      "Train loss and acc of batch 19: 47.781883239746094, 1.0\n",
      "Train loss and acc of batch 20: 47.78187561035156, 1.0\n",
      "Train loss and acc of batch 21: 48.37757110595703, 0.984375\n",
      "Train loss and acc of batch 22: 48.3775634765625, 0.984375\n",
      "Train loss and acc of batch 23: 47.7818489074707, 1.0\n",
      "Train loss and acc of batch 24: 48.377540588378906, 0.984375\n",
      "Train loss and acc of batch 25: 47.78183364868164, 1.0\n",
      "Train loss and acc of batch 26: 47.781822204589844, 1.0\n",
      "Train loss and acc of batch 27: 47.78181457519531, 1.0\n",
      "Train loss and acc of batch 28: 47.78180694580078, 1.0\n",
      "Train loss and acc of batch 29: 48.37749481201172, 0.984375\n",
      "Train loss and acc of batch 30: 47.78178787231445, 1.0\n",
      "Train loss and acc of batch 31: 47.99854278564453, 0.984375\n",
      "Train loss and acc of batch 32: 47.781768798828125, 1.0\n",
      "Train loss and acc of batch 33: 47.78176498413086, 1.0\n",
      "Train loss and acc of batch 34: 48.37745666503906, 0.984375\n",
      "Train loss and acc of batch 35: 48.215274810791016, 0.96875\n",
      "Train loss and acc of batch 36: 47.781734466552734, 1.0\n",
      "Train loss and acc of batch 37: 48.534950256347656, 0.984375\n",
      "Train loss and acc of batch 38: 49.130645751953125, 0.96875\n",
      "Train loss and acc of batch 39: 47.99847412109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.781700134277344, 1.0\n",
      "Train loss and acc of batch 41: 49.130615234375, 0.96875\n",
      "Train loss and acc of batch 42: 47.781681060791016, 1.0\n",
      "Train loss and acc of batch 43: 48.37737274169922, 0.984375\n",
      "Train loss and acc of batch 44: 47.78166580200195, 1.0\n",
      "Train loss and acc of batch 45: 48.377357482910156, 0.984375\n",
      "Train loss and acc of batch 46: 48.06749725341797, 0.984375\n",
      "Train loss and acc of batch 47: 47.781639099121094, 1.0\n",
      "Train loss and acc of batch 48: 47.78163146972656, 1.0\n",
      "Train loss and acc of batch 49: 47.7816162109375, 1.0\n",
      "Train loss and acc of batch 50: 48.37731170654297, 0.984375\n",
      "Train loss and acc of batch 51: 49.130523681640625, 0.96875\n",
      "Train loss and acc of batch 52: 49.037437438964844, 0.953125\n",
      "Train loss and acc of batch 53: 47.781585693359375, 1.0\n",
      "Train loss and acc of batch 54: 47.99834442138672, 0.984375\n",
      "Train loss and acc of batch 55: 47.78156280517578, 1.0\n",
      "Train loss and acc of batch 56: 47.78155517578125, 1.0\n",
      "Train loss and acc of batch 57: 48.37725067138672, 0.984375\n",
      "Train loss and acc of batch 58: 47.78153991699219, 1.0\n",
      "Train loss and acc of batch 59: 47.781532287597656, 1.0\n",
      "Train loss and acc of batch 60: 47.78152084350586, 1.0\n",
      "Train loss and acc of batch 61: 47.78151321411133, 1.0\n",
      "Train loss and acc of batch 62: 47.78150939941406, 1.0\n",
      "Train loss and acc of batch 63: 48.972896575927734, 0.96875\n",
      "Train loss and acc of batch 64: 47.998252868652344, 0.984375\n",
      "Train loss and acc of batch 65: 47.78147506713867, 1.0\n",
      "Train loss and acc of batch 66: 47.78146743774414, 1.0\n",
      "Train loss and acc of batch 67: 48.59392547607422, 0.96875\n",
      "Train loss and acc of batch 68: 48.37715148925781, 0.984375\n",
      "Train loss and acc of batch 69: 47.998207092285156, 0.984375\n",
      "Train loss and acc of batch 70: 47.78143310546875, 1.0\n",
      "Training accuracy and loss of epoch #438: 0.9897, 48.1026\n",
      "Saved model by train loss 48.10262744527468\n",
      "Train loss and acc of batch 0: 47.78142547607422, 1.0\n",
      "Train loss and acc of batch 1: 47.78141403198242, 1.0\n",
      "Train loss and acc of batch 2: 47.78140640258789, 1.0\n",
      "Train loss and acc of batch 3: 47.99816131591797, 0.984375\n",
      "Train loss and acc of batch 4: 47.78139114379883, 1.0\n",
      "Train loss and acc of batch 5: 49.13031005859375, 0.96875\n",
      "Train loss and acc of batch 6: 48.28398895263672, 0.96875\n",
      "Train loss and acc of batch 7: 47.7813606262207, 1.0\n",
      "Train loss and acc of batch 8: 48.377052307128906, 0.984375\n",
      "Train loss and acc of batch 9: 48.06719970703125, 0.984375\n",
      "Train loss and acc of batch 10: 47.78133773803711, 1.0\n",
      "Train loss and acc of batch 11: 47.78133010864258, 1.0\n",
      "Train loss and acc of batch 12: 48.534542083740234, 0.984375\n",
      "Train loss and acc of batch 13: 47.998069763183594, 0.984375\n",
      "Train loss and acc of batch 14: 47.998069763183594, 0.984375\n",
      "Train loss and acc of batch 15: 48.376991271972656, 0.984375\n",
      "Train loss and acc of batch 16: 48.376983642578125, 0.984375\n",
      "Train loss and acc of batch 17: 48.53449249267578, 0.984375\n",
      "Train loss and acc of batch 18: 48.662818908691406, 0.96875\n",
      "Train loss and acc of batch 19: 47.781253814697266, 1.0\n",
      "Train loss and acc of batch 20: 47.78125, 1.0\n",
      "Train loss and acc of batch 21: 48.37693786621094, 0.984375\n",
      "Train loss and acc of batch 22: 48.376930236816406, 0.984375\n",
      "Train loss and acc of batch 23: 47.781219482421875, 1.0\n",
      "Train loss and acc of batch 24: 48.376914978027344, 0.984375\n",
      "Train loss and acc of batch 25: 47.78120422363281, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 26: 47.781192779541016, 1.0\n",
      "Train loss and acc of batch 27: 47.781185150146484, 1.0\n",
      "Train loss and acc of batch 28: 47.78117752075195, 1.0\n",
      "Train loss and acc of batch 29: 48.376869201660156, 0.984375\n",
      "Train loss and acc of batch 30: 47.781158447265625, 1.0\n",
      "Train loss and acc of batch 31: 47.99790954589844, 0.984375\n",
      "Train loss and acc of batch 32: 47.7811393737793, 1.0\n",
      "Train loss and acc of batch 33: 47.781131744384766, 1.0\n",
      "Train loss and acc of batch 34: 48.37682342529297, 0.984375\n",
      "Train loss and acc of batch 35: 48.21464157104492, 0.96875\n",
      "Train loss and acc of batch 36: 47.78110122680664, 1.0\n",
      "Train loss and acc of batch 37: 48.53432083129883, 0.984375\n",
      "Train loss and acc of batch 38: 49.13001251220703, 0.96875\n",
      "Train loss and acc of batch 39: 47.997840881347656, 0.984375\n",
      "Train loss and acc of batch 40: 47.78106689453125, 1.0\n",
      "Train loss and acc of batch 41: 49.12998580932617, 0.96875\n",
      "Train loss and acc of batch 42: 47.78105163574219, 1.0\n",
      "Train loss and acc of batch 43: 48.376747131347656, 0.984375\n",
      "Train loss and acc of batch 44: 47.78103256225586, 1.0\n",
      "Train loss and acc of batch 45: 48.37672424316406, 0.984375\n",
      "Train loss and acc of batch 46: 48.066864013671875, 0.984375\n",
      "Train loss and acc of batch 47: 47.781009674072266, 1.0\n",
      "Train loss and acc of batch 48: 47.78099822998047, 1.0\n",
      "Train loss and acc of batch 49: 47.78099060058594, 1.0\n",
      "Train loss and acc of batch 50: 48.376678466796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.12989807128906, 0.96875\n",
      "Train loss and acc of batch 52: 49.03680419921875, 0.953125\n",
      "Train loss and acc of batch 53: 47.78095626831055, 1.0\n",
      "Train loss and acc of batch 54: 47.997711181640625, 0.984375\n",
      "Train loss and acc of batch 55: 47.78093338012695, 1.0\n",
      "Train loss and acc of batch 56: 47.78092956542969, 1.0\n",
      "Train loss and acc of batch 57: 48.376625061035156, 0.984375\n",
      "Train loss and acc of batch 58: 47.780906677246094, 1.0\n",
      "Train loss and acc of batch 59: 47.78090286254883, 1.0\n",
      "Train loss and acc of batch 60: 47.780887603759766, 1.0\n",
      "Train loss and acc of batch 61: 47.7808837890625, 1.0\n",
      "Train loss and acc of batch 62: 47.78087615966797, 1.0\n",
      "Train loss and acc of batch 63: 48.972267150878906, 0.96875\n",
      "Train loss and acc of batch 64: 47.99761962890625, 0.984375\n",
      "Train loss and acc of batch 65: 47.780845642089844, 1.0\n",
      "Train loss and acc of batch 66: 47.78083801269531, 1.0\n",
      "Train loss and acc of batch 67: 48.59329605102539, 0.96875\n",
      "Train loss and acc of batch 68: 48.37651824951172, 0.984375\n",
      "Train loss and acc of batch 69: 47.99757385253906, 0.984375\n",
      "Train loss and acc of batch 70: 47.78080368041992, 1.0\n",
      "Training accuracy and loss of epoch #439: 0.9897, 48.1020\n",
      "Saved model by train loss 48.10199699939137\n",
      "Train loss and acc of batch 0: 47.780799865722656, 1.0\n",
      "Train loss and acc of batch 1: 47.780784606933594, 1.0\n",
      "Train loss and acc of batch 2: 47.78077697753906, 1.0\n",
      "Train loss and acc of batch 3: 47.997528076171875, 0.984375\n",
      "Train loss and acc of batch 4: 47.780757904052734, 1.0\n",
      "Train loss and acc of batch 5: 49.129676818847656, 0.96875\n",
      "Train loss and acc of batch 6: 48.283355712890625, 0.96875\n",
      "Train loss and acc of batch 7: 47.780731201171875, 1.0\n",
      "Train loss and acc of batch 8: 48.37641906738281, 0.984375\n",
      "Train loss and acc of batch 9: 48.066566467285156, 0.984375\n",
      "Train loss and acc of batch 10: 47.780704498291016, 1.0\n",
      "Train loss and acc of batch 11: 47.780696868896484, 1.0\n",
      "Train loss and acc of batch 12: 48.533912658691406, 0.984375\n",
      "Train loss and acc of batch 13: 47.99744415283203, 0.984375\n",
      "Train loss and acc of batch 14: 47.9974365234375, 0.984375\n",
      "Train loss and acc of batch 15: 48.376365661621094, 0.984375\n",
      "Train loss and acc of batch 16: 48.37635040283203, 0.984375\n",
      "Train loss and acc of batch 17: 48.53386306762695, 0.984375\n",
      "Train loss and acc of batch 18: 48.66218566894531, 0.96875\n",
      "Train loss and acc of batch 19: 47.7806282043457, 1.0\n",
      "Train loss and acc of batch 20: 47.78061294555664, 1.0\n",
      "Train loss and acc of batch 21: 48.376312255859375, 0.984375\n",
      "Train loss and acc of batch 22: 48.37629699707031, 0.984375\n",
      "Train loss and acc of batch 23: 47.78059005737305, 1.0\n",
      "Train loss and acc of batch 24: 48.37628173828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.78056716918945, 1.0\n",
      "Train loss and acc of batch 26: 47.78056335449219, 1.0\n",
      "Train loss and acc of batch 27: 47.780555725097656, 1.0\n",
      "Train loss and acc of batch 28: 47.780548095703125, 1.0\n",
      "Train loss and acc of batch 29: 48.37623596191406, 0.984375\n",
      "Train loss and acc of batch 30: 47.78052520751953, 1.0\n",
      "Train loss and acc of batch 31: 47.997283935546875, 0.984375\n",
      "Train loss and acc of batch 32: 47.78050994873047, 1.0\n",
      "Train loss and acc of batch 33: 47.78050231933594, 1.0\n",
      "Train loss and acc of batch 34: 48.376190185546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.214012145996094, 0.96875\n",
      "Train loss and acc of batch 36: 47.78047180175781, 1.0\n",
      "Train loss and acc of batch 37: 48.533687591552734, 0.984375\n",
      "Train loss and acc of batch 38: 49.12937927246094, 0.96875\n",
      "Train loss and acc of batch 39: 47.99720764160156, 0.984375\n",
      "Train loss and acc of batch 40: 47.78044128417969, 1.0\n",
      "Train loss and acc of batch 41: 49.129356384277344, 0.96875\n",
      "Train loss and acc of batch 42: 47.78042221069336, 1.0\n",
      "Train loss and acc of batch 43: 48.376121520996094, 0.984375\n",
      "Train loss and acc of batch 44: 47.78040313720703, 1.0\n",
      "Train loss and acc of batch 45: 48.37609100341797, 0.984375\n",
      "Train loss and acc of batch 46: 48.06623840332031, 0.984375\n",
      "Train loss and acc of batch 47: 47.78038024902344, 1.0\n",
      "Train loss and acc of batch 48: 47.78036880493164, 1.0\n",
      "Train loss and acc of batch 49: 47.780357360839844, 1.0\n",
      "Train loss and acc of batch 50: 48.37605285644531, 0.984375\n",
      "Train loss and acc of batch 51: 49.12926483154297, 0.96875\n",
      "Train loss and acc of batch 52: 49.036170959472656, 0.953125\n",
      "Train loss and acc of batch 53: 47.78031921386719, 1.0\n",
      "Train loss and acc of batch 54: 47.99707794189453, 0.984375\n",
      "Train loss and acc of batch 55: 47.780303955078125, 1.0\n",
      "Train loss and acc of batch 56: 47.78030014038086, 1.0\n",
      "Train loss and acc of batch 57: 48.37599182128906, 0.984375\n",
      "Train loss and acc of batch 58: 47.78028106689453, 1.0\n",
      "Train loss and acc of batch 59: 47.780269622802734, 1.0\n",
      "Train loss and acc of batch 60: 47.78026580810547, 1.0\n",
      "Train loss and acc of batch 61: 47.780250549316406, 1.0\n",
      "Train loss and acc of batch 62: 47.78024673461914, 1.0\n",
      "Train loss and acc of batch 63: 48.97163391113281, 0.96875\n",
      "Train loss and acc of batch 64: 47.99699401855469, 0.984375\n",
      "Train loss and acc of batch 65: 47.780216217041016, 1.0\n",
      "Train loss and acc of batch 66: 47.780208587646484, 1.0\n",
      "Train loss and acc of batch 67: 48.5926628112793, 0.96875\n",
      "Train loss and acc of batch 68: 48.375892639160156, 0.984375\n",
      "Train loss and acc of batch 69: 47.9969482421875, 0.984375\n",
      "Train loss and acc of batch 70: 47.78017044067383, 1.0\n",
      "Training accuracy and loss of epoch #440: 0.9897, 48.1014\n",
      "Saved model by train loss 48.10136649977993\n",
      "Train loss and acc of batch 0: 47.78016662597656, 1.0\n",
      "Train loss and acc of batch 1: 47.780155181884766, 1.0\n",
      "Train loss and acc of batch 2: 47.780147552490234, 1.0\n",
      "Train loss and acc of batch 3: 47.99690246582031, 0.984375\n",
      "Train loss and acc of batch 4: 47.780128479003906, 1.0\n",
      "Train loss and acc of batch 5: 49.12904357910156, 0.96875\n",
      "Train loss and acc of batch 6: 48.2827262878418, 0.96875\n",
      "Train loss and acc of batch 7: 47.78010177612305, 1.0\n",
      "Train loss and acc of batch 8: 48.37579345703125, 0.984375\n",
      "Train loss and acc of batch 9: 48.06593322753906, 0.984375\n",
      "Train loss and acc of batch 10: 47.78007507324219, 1.0\n",
      "Train loss and acc of batch 11: 47.78006362915039, 1.0\n",
      "Train loss and acc of batch 12: 48.53327941894531, 0.984375\n",
      "Train loss and acc of batch 13: 47.99681091308594, 0.984375\n",
      "Train loss and acc of batch 14: 47.996803283691406, 0.984375\n",
      "Train loss and acc of batch 15: 48.375732421875, 0.984375\n",
      "Train loss and acc of batch 16: 48.37572479248047, 0.984375\n",
      "Train loss and acc of batch 17: 48.53323745727539, 0.984375\n",
      "Train loss and acc of batch 18: 48.66156005859375, 0.96875\n",
      "Train loss and acc of batch 19: 47.77999496459961, 1.0\n",
      "Train loss and acc of batch 20: 47.77998352050781, 1.0\n",
      "Train loss and acc of batch 21: 48.37567901611328, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 22: 48.37567138671875, 0.984375\n",
      "Train loss and acc of batch 23: 47.77995681762695, 1.0\n",
      "Train loss and acc of batch 24: 48.37565612792969, 0.984375\n",
      "Train loss and acc of batch 25: 47.77994155883789, 1.0\n",
      "Train loss and acc of batch 26: 47.77993392944336, 1.0\n",
      "Train loss and acc of batch 27: 47.77992248535156, 1.0\n",
      "Train loss and acc of batch 28: 47.7799186706543, 1.0\n",
      "Train loss and acc of batch 29: 48.37560272216797, 0.984375\n",
      "Train loss and acc of batch 30: 47.77989959716797, 1.0\n",
      "Train loss and acc of batch 31: 47.99665069580078, 0.984375\n",
      "Train loss and acc of batch 32: 47.77988052368164, 1.0\n",
      "Train loss and acc of batch 33: 47.779869079589844, 1.0\n",
      "Train loss and acc of batch 34: 48.37555694580078, 0.984375\n",
      "Train loss and acc of batch 35: 48.213382720947266, 0.96875\n",
      "Train loss and acc of batch 36: 47.77984619140625, 1.0\n",
      "Train loss and acc of batch 37: 48.533058166503906, 0.984375\n",
      "Train loss and acc of batch 38: 49.128753662109375, 0.96875\n",
      "Train loss and acc of batch 39: 47.99658203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.779808044433594, 1.0\n",
      "Train loss and acc of batch 41: 49.128726959228516, 0.96875\n",
      "Train loss and acc of batch 42: 47.77979278564453, 1.0\n",
      "Train loss and acc of batch 43: 48.37548065185547, 0.984375\n",
      "Train loss and acc of batch 44: 47.77976989746094, 1.0\n",
      "Train loss and acc of batch 45: 48.375465393066406, 0.984375\n",
      "Train loss and acc of batch 46: 48.06561279296875, 0.984375\n",
      "Train loss and acc of batch 47: 47.779747009277344, 1.0\n",
      "Train loss and acc of batch 48: 47.77973937988281, 1.0\n",
      "Train loss and acc of batch 49: 47.77973175048828, 1.0\n",
      "Train loss and acc of batch 50: 48.37541961669922, 0.984375\n",
      "Train loss and acc of batch 51: 49.128631591796875, 0.96875\n",
      "Train loss and acc of batch 52: 49.035545349121094, 0.953125\n",
      "Train loss and acc of batch 53: 47.77969741821289, 1.0\n",
      "Train loss and acc of batch 54: 47.99644470214844, 0.984375\n",
      "Train loss and acc of batch 55: 47.77967834472656, 1.0\n",
      "Train loss and acc of batch 56: 47.779666900634766, 1.0\n",
      "Train loss and acc of batch 57: 48.37535858154297, 0.984375\n",
      "Train loss and acc of batch 58: 47.77964782714844, 1.0\n",
      "Train loss and acc of batch 59: 47.77964401245117, 1.0\n",
      "Train loss and acc of batch 60: 47.779632568359375, 1.0\n",
      "Train loss and acc of batch 61: 47.77961730957031, 1.0\n",
      "Train loss and acc of batch 62: 47.77961349487305, 1.0\n",
      "Train loss and acc of batch 63: 48.97100830078125, 0.96875\n",
      "Train loss and acc of batch 64: 47.996360778808594, 0.984375\n",
      "Train loss and acc of batch 65: 47.77958297729492, 1.0\n",
      "Train loss and acc of batch 66: 47.77957534790039, 1.0\n",
      "Train loss and acc of batch 67: 48.592037200927734, 0.96875\n",
      "Train loss and acc of batch 68: 48.37525939941406, 0.984375\n",
      "Train loss and acc of batch 69: 47.996315002441406, 0.984375\n",
      "Train loss and acc of batch 70: 47.779541015625, 1.0\n",
      "Training accuracy and loss of epoch #441: 0.9897, 48.1007\n",
      "Saved model by train loss 48.10073632253727\n",
      "Train loss and acc of batch 0: 47.77953338623047, 1.0\n",
      "Train loss and acc of batch 1: 47.77952575683594, 1.0\n",
      "Train loss and acc of batch 2: 47.779518127441406, 1.0\n",
      "Train loss and acc of batch 3: 47.99626922607422, 0.984375\n",
      "Train loss and acc of batch 4: 47.77949905395508, 1.0\n",
      "Train loss and acc of batch 5: 49.12841033935547, 0.96875\n",
      "Train loss and acc of batch 6: 48.282100677490234, 0.96875\n",
      "Train loss and acc of batch 7: 47.77947235107422, 1.0\n",
      "Train loss and acc of batch 8: 48.37516784667969, 0.984375\n",
      "Train loss and acc of batch 9: 48.0653076171875, 0.984375\n",
      "Train loss and acc of batch 10: 47.77944564819336, 1.0\n",
      "Train loss and acc of batch 11: 47.77943801879883, 1.0\n",
      "Train loss and acc of batch 12: 48.532649993896484, 0.984375\n",
      "Train loss and acc of batch 13: 47.996185302734375, 0.984375\n",
      "Train loss and acc of batch 14: 47.99617004394531, 0.984375\n",
      "Train loss and acc of batch 15: 48.37510681152344, 0.984375\n",
      "Train loss and acc of batch 16: 48.375091552734375, 0.984375\n",
      "Train loss and acc of batch 17: 48.53260803222656, 0.984375\n",
      "Train loss and acc of batch 18: 48.66093063354492, 0.96875\n",
      "Train loss and acc of batch 19: 47.77936935424805, 1.0\n",
      "Train loss and acc of batch 20: 47.77935791015625, 1.0\n",
      "Train loss and acc of batch 21: 48.37504577636719, 0.984375\n",
      "Train loss and acc of batch 22: 48.375038146972656, 0.984375\n",
      "Train loss and acc of batch 23: 47.779327392578125, 1.0\n",
      "Train loss and acc of batch 24: 48.375022888183594, 0.984375\n",
      "Train loss and acc of batch 25: 47.77931594848633, 1.0\n",
      "Train loss and acc of batch 26: 47.779300689697266, 1.0\n",
      "Train loss and acc of batch 27: 47.779296875, 1.0\n",
      "Train loss and acc of batch 28: 47.7792854309082, 1.0\n",
      "Train loss and acc of batch 29: 48.374977111816406, 0.984375\n",
      "Train loss and acc of batch 30: 47.779266357421875, 1.0\n",
      "Train loss and acc of batch 31: 47.99602508544922, 0.984375\n",
      "Train loss and acc of batch 32: 47.77925109863281, 1.0\n",
      "Train loss and acc of batch 33: 47.77924346923828, 1.0\n",
      "Train loss and acc of batch 34: 48.37493133544922, 0.984375\n",
      "Train loss and acc of batch 35: 48.21274948120117, 0.96875\n",
      "Train loss and acc of batch 36: 47.779212951660156, 1.0\n",
      "Train loss and acc of batch 37: 48.53242874145508, 0.984375\n",
      "Train loss and acc of batch 38: 49.12812042236328, 0.96875\n",
      "Train loss and acc of batch 39: 47.99595642089844, 0.984375\n",
      "Train loss and acc of batch 40: 47.779178619384766, 1.0\n",
      "Train loss and acc of batch 41: 49.12809753417969, 0.96875\n",
      "Train loss and acc of batch 42: 47.77915954589844, 1.0\n",
      "Train loss and acc of batch 43: 48.374855041503906, 0.984375\n",
      "Train loss and acc of batch 44: 47.779144287109375, 1.0\n",
      "Train loss and acc of batch 45: 48.374839782714844, 0.984375\n",
      "Train loss and acc of batch 46: 48.064979553222656, 0.984375\n",
      "Train loss and acc of batch 47: 47.77912139892578, 1.0\n",
      "Train loss and acc of batch 48: 47.779109954833984, 1.0\n",
      "Train loss and acc of batch 49: 47.77909469604492, 1.0\n",
      "Train loss and acc of batch 50: 48.374794006347656, 0.984375\n",
      "Train loss and acc of batch 51: 49.12800598144531, 0.96875\n",
      "Train loss and acc of batch 52: 49.034915924072266, 0.953125\n",
      "Train loss and acc of batch 53: 47.77906799316406, 1.0\n",
      "Train loss and acc of batch 54: 47.995819091796875, 0.984375\n",
      "Train loss and acc of batch 55: 47.779048919677734, 1.0\n",
      "Train loss and acc of batch 56: 47.7790412902832, 1.0\n",
      "Train loss and acc of batch 57: 48.374725341796875, 0.984375\n",
      "Train loss and acc of batch 58: 47.77901840209961, 1.0\n",
      "Train loss and acc of batch 59: 47.77900695800781, 1.0\n",
      "Train loss and acc of batch 60: 47.77900314331055, 1.0\n",
      "Train loss and acc of batch 61: 47.778995513916016, 1.0\n",
      "Train loss and acc of batch 62: 47.778987884521484, 1.0\n",
      "Train loss and acc of batch 63: 48.97037887573242, 0.96875\n",
      "Train loss and acc of batch 64: 47.9957275390625, 0.984375\n",
      "Train loss and acc of batch 65: 47.778953552246094, 1.0\n",
      "Train loss and acc of batch 66: 47.77894973754883, 1.0\n",
      "Train loss and acc of batch 67: 48.591407775878906, 0.96875\n",
      "Train loss and acc of batch 68: 48.37462615966797, 0.984375\n",
      "Train loss and acc of batch 69: 47.995689392089844, 0.984375\n",
      "Train loss and acc of batch 70: 47.77891540527344, 1.0\n",
      "Training accuracy and loss of epoch #442: 0.9897, 48.1001\n",
      "Saved model by train loss 48.10010721985723\n",
      "Train loss and acc of batch 0: 47.778900146484375, 1.0\n",
      "Train loss and acc of batch 1: 47.778900146484375, 1.0\n",
      "Train loss and acc of batch 2: 47.77888488769531, 1.0\n",
      "Train loss and acc of batch 3: 47.995635986328125, 0.984375\n",
      "Train loss and acc of batch 4: 47.778865814208984, 1.0\n",
      "Train loss and acc of batch 5: 49.127777099609375, 0.96875\n",
      "Train loss and acc of batch 6: 48.281463623046875, 0.96875\n",
      "Train loss and acc of batch 7: 47.77884292602539, 1.0\n",
      "Train loss and acc of batch 8: 48.37452697753906, 0.984375\n",
      "Train loss and acc of batch 9: 48.064674377441406, 0.984375\n",
      "Train loss and acc of batch 10: 47.77881622314453, 1.0\n",
      "Train loss and acc of batch 11: 47.778804779052734, 1.0\n",
      "Train loss and acc of batch 12: 48.532020568847656, 0.984375\n",
      "Train loss and acc of batch 13: 47.99555206298828, 0.984375\n",
      "Train loss and acc of batch 14: 47.99553680419922, 0.984375\n",
      "Train loss and acc of batch 15: 48.374473571777344, 0.984375\n",
      "Train loss and acc of batch 16: 48.37445068359375, 0.984375\n",
      "Train loss and acc of batch 17: 48.5319709777832, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 18: 48.66029739379883, 0.96875\n",
      "Train loss and acc of batch 19: 47.77873229980469, 1.0\n",
      "Train loss and acc of batch 20: 47.77872848510742, 1.0\n",
      "Train loss and acc of batch 21: 48.374412536621094, 0.984375\n",
      "Train loss and acc of batch 22: 48.37440490722656, 0.984375\n",
      "Train loss and acc of batch 23: 47.77869415283203, 1.0\n",
      "Train loss and acc of batch 24: 48.3743896484375, 0.984375\n",
      "Train loss and acc of batch 25: 47.77867889404297, 1.0\n",
      "Train loss and acc of batch 26: 47.77867126464844, 1.0\n",
      "Train loss and acc of batch 27: 47.77865982055664, 1.0\n",
      "Train loss and acc of batch 28: 47.778656005859375, 1.0\n",
      "Train loss and acc of batch 29: 48.374351501464844, 0.984375\n",
      "Train loss and acc of batch 30: 47.77863693237305, 1.0\n",
      "Train loss and acc of batch 31: 47.995391845703125, 0.984375\n",
      "Train loss and acc of batch 32: 47.77861785888672, 1.0\n",
      "Train loss and acc of batch 33: 47.77860641479492, 1.0\n",
      "Train loss and acc of batch 34: 48.374298095703125, 0.984375\n",
      "Train loss and acc of batch 35: 48.212120056152344, 0.96875\n",
      "Train loss and acc of batch 36: 47.77857971191406, 1.0\n",
      "Train loss and acc of batch 37: 48.531795501708984, 0.984375\n",
      "Train loss and acc of batch 38: 49.12748718261719, 0.96875\n",
      "Train loss and acc of batch 39: 47.99531555175781, 0.984375\n",
      "Train loss and acc of batch 40: 47.77854537963867, 1.0\n",
      "Train loss and acc of batch 41: 49.127464294433594, 0.96875\n",
      "Train loss and acc of batch 42: 47.77853012084961, 1.0\n",
      "Train loss and acc of batch 43: 48.37422180175781, 0.984375\n",
      "Train loss and acc of batch 44: 47.77851104736328, 1.0\n",
      "Train loss and acc of batch 45: 48.37420654296875, 0.984375\n",
      "Train loss and acc of batch 46: 48.06434631347656, 0.984375\n",
      "Train loss and acc of batch 47: 47.77848815917969, 1.0\n",
      "Train loss and acc of batch 48: 47.77847671508789, 1.0\n",
      "Train loss and acc of batch 49: 47.77846908569336, 1.0\n",
      "Train loss and acc of batch 50: 48.37415313720703, 0.984375\n",
      "Train loss and acc of batch 51: 49.12737274169922, 0.96875\n",
      "Train loss and acc of batch 52: 49.034278869628906, 0.953125\n",
      "Train loss and acc of batch 53: 47.7784309387207, 1.0\n",
      "Train loss and acc of batch 54: 47.99518585205078, 0.984375\n",
      "Train loss and acc of batch 55: 47.778411865234375, 1.0\n",
      "Train loss and acc of batch 56: 47.778404235839844, 1.0\n",
      "Train loss and acc of batch 57: 48.37409973144531, 0.984375\n",
      "Train loss and acc of batch 58: 47.778385162353516, 1.0\n",
      "Train loss and acc of batch 59: 47.778377532958984, 1.0\n",
      "Train loss and acc of batch 60: 47.77836608886719, 1.0\n",
      "Train loss and acc of batch 61: 47.77835464477539, 1.0\n",
      "Train loss and acc of batch 62: 47.778350830078125, 1.0\n",
      "Train loss and acc of batch 63: 48.96974563598633, 0.96875\n",
      "Train loss and acc of batch 64: 47.995094299316406, 0.984375\n",
      "Train loss and acc of batch 65: 47.778324127197266, 1.0\n",
      "Train loss and acc of batch 66: 47.778316497802734, 1.0\n",
      "Train loss and acc of batch 67: 48.59077072143555, 0.96875\n",
      "Train loss and acc of batch 68: 48.374000549316406, 0.984375\n",
      "Train loss and acc of batch 69: 47.99505615234375, 0.984375\n",
      "Train loss and acc of batch 70: 47.77827835083008, 1.0\n",
      "Training accuracy and loss of epoch #443: 0.9897, 48.0995\n",
      "Saved model by train loss 48.09947381892675\n",
      "Train loss and acc of batch 0: 47.77827453613281, 1.0\n",
      "Train loss and acc of batch 1: 47.778263092041016, 1.0\n",
      "Train loss and acc of batch 2: 47.77825164794922, 1.0\n",
      "Train loss and acc of batch 3: 47.99501037597656, 0.984375\n",
      "Train loss and acc of batch 4: 47.77824020385742, 1.0\n",
      "Train loss and acc of batch 5: 49.12715148925781, 0.96875\n",
      "Train loss and acc of batch 6: 48.28083419799805, 0.96875\n",
      "Train loss and acc of batch 7: 47.77820587158203, 1.0\n",
      "Train loss and acc of batch 8: 48.3739013671875, 0.984375\n",
      "Train loss and acc of batch 9: 48.064048767089844, 0.984375\n",
      "Train loss and acc of batch 10: 47.77817916870117, 1.0\n",
      "Train loss and acc of batch 11: 47.778175354003906, 1.0\n",
      "Train loss and acc of batch 12: 48.53138732910156, 0.984375\n",
      "Train loss and acc of batch 13: 47.99491882324219, 0.984375\n",
      "Train loss and acc of batch 14: 47.994911193847656, 0.984375\n",
      "Train loss and acc of batch 15: 48.37384033203125, 0.984375\n",
      "Train loss and acc of batch 16: 48.37383270263672, 0.984375\n",
      "Train loss and acc of batch 17: 48.53134536743164, 0.984375\n",
      "Train loss and acc of batch 18: 48.659664154052734, 0.96875\n",
      "Train loss and acc of batch 19: 47.77810287475586, 1.0\n",
      "Train loss and acc of batch 20: 47.77809524536133, 1.0\n",
      "Train loss and acc of batch 21: 48.37378692626953, 0.984375\n",
      "Train loss and acc of batch 22: 48.373779296875, 0.984375\n",
      "Train loss and acc of batch 23: 47.77806854248047, 1.0\n",
      "Train loss and acc of batch 24: 48.373756408691406, 0.984375\n",
      "Train loss and acc of batch 25: 47.778045654296875, 1.0\n",
      "Train loss and acc of batch 26: 47.778038024902344, 1.0\n",
      "Train loss and acc of batch 27: 47.77803039550781, 1.0\n",
      "Train loss and acc of batch 28: 47.77802658081055, 1.0\n",
      "Train loss and acc of batch 29: 48.37371826171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.77800369262695, 1.0\n",
      "Train loss and acc of batch 31: 47.99475860595703, 0.984375\n",
      "Train loss and acc of batch 32: 47.77798843383789, 1.0\n",
      "Train loss and acc of batch 33: 47.777976989746094, 1.0\n",
      "Train loss and acc of batch 34: 48.37367248535156, 0.984375\n",
      "Train loss and acc of batch 35: 48.211490631103516, 0.96875\n",
      "Train loss and acc of batch 36: 47.777950286865234, 1.0\n",
      "Train loss and acc of batch 37: 48.53116989135742, 0.984375\n",
      "Train loss and acc of batch 38: 49.126853942871094, 0.96875\n",
      "Train loss and acc of batch 39: 47.99468994140625, 0.984375\n",
      "Train loss and acc of batch 40: 47.777915954589844, 1.0\n",
      "Train loss and acc of batch 41: 49.1268310546875, 0.96875\n",
      "Train loss and acc of batch 42: 47.77790069580078, 1.0\n",
      "Train loss and acc of batch 43: 48.37358856201172, 0.984375\n",
      "Train loss and acc of batch 44: 47.77788162231445, 1.0\n",
      "Train loss and acc of batch 45: 48.373573303222656, 0.984375\n",
      "Train loss and acc of batch 46: 48.06371307373047, 0.984375\n",
      "Train loss and acc of batch 47: 47.77785110473633, 1.0\n",
      "Train loss and acc of batch 48: 47.77784729003906, 1.0\n",
      "Train loss and acc of batch 49: 47.77783966064453, 1.0\n",
      "Train loss and acc of batch 50: 48.37352752685547, 0.984375\n",
      "Train loss and acc of batch 51: 49.126747131347656, 0.96875\n",
      "Train loss and acc of batch 52: 49.03364944458008, 0.953125\n",
      "Train loss and acc of batch 53: 47.77779769897461, 1.0\n",
      "Train loss and acc of batch 54: 47.99456024169922, 0.984375\n",
      "Train loss and acc of batch 55: 47.77778244018555, 1.0\n",
      "Train loss and acc of batch 56: 47.777774810791016, 1.0\n",
      "Train loss and acc of batch 57: 48.37345886230469, 0.984375\n",
      "Train loss and acc of batch 58: 47.77775573730469, 1.0\n",
      "Train loss and acc of batch 59: 47.777748107910156, 1.0\n",
      "Train loss and acc of batch 60: 47.777740478515625, 1.0\n",
      "Train loss and acc of batch 61: 47.77772521972656, 1.0\n",
      "Train loss and acc of batch 62: 47.7777214050293, 1.0\n",
      "Train loss and acc of batch 63: 48.969112396240234, 0.96875\n",
      "Train loss and acc of batch 64: 47.994468688964844, 0.984375\n",
      "Train loss and acc of batch 65: 47.7776985168457, 1.0\n",
      "Train loss and acc of batch 66: 47.77768325805664, 1.0\n",
      "Train loss and acc of batch 67: 48.59014129638672, 0.96875\n",
      "Train loss and acc of batch 68: 48.37336730957031, 0.984375\n",
      "Train loss and acc of batch 69: 47.994422912597656, 0.984375\n",
      "Train loss and acc of batch 70: 47.77764892578125, 1.0\n",
      "Training accuracy and loss of epoch #444: 0.9897, 48.0988\n",
      "Saved model by train loss 48.09884385659661\n",
      "Train loss and acc of batch 0: 47.77764129638672, 1.0\n",
      "Train loss and acc of batch 1: 47.77762985229492, 1.0\n",
      "Train loss and acc of batch 2: 47.77762222290039, 1.0\n",
      "Train loss and acc of batch 3: 47.99437713623047, 0.984375\n",
      "Train loss and acc of batch 4: 47.77760314941406, 1.0\n",
      "Train loss and acc of batch 5: 49.12651824951172, 0.96875\n",
      "Train loss and acc of batch 6: 48.28020477294922, 0.96875\n",
      "Train loss and acc of batch 7: 47.7775764465332, 1.0\n",
      "Train loss and acc of batch 8: 48.37327575683594, 0.984375\n",
      "Train loss and acc of batch 9: 48.06341552734375, 0.984375\n",
      "Train loss and acc of batch 10: 47.77755355834961, 1.0\n",
      "Train loss and acc of batch 11: 47.77754592895508, 1.0\n",
      "Train loss and acc of batch 12: 48.530757904052734, 0.984375\n",
      "Train loss and acc of batch 13: 47.994293212890625, 0.984375\n",
      "Train loss and acc of batch 14: 47.994285583496094, 0.984375\n",
      "Train loss and acc of batch 15: 48.373207092285156, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 16: 48.373199462890625, 0.984375\n",
      "Train loss and acc of batch 17: 48.53071594238281, 0.984375\n",
      "Train loss and acc of batch 18: 48.659034729003906, 0.96875\n",
      "Train loss and acc of batch 19: 47.777469635009766, 1.0\n",
      "Train loss and acc of batch 20: 47.777462005615234, 1.0\n",
      "Train loss and acc of batch 21: 48.37315368652344, 0.984375\n",
      "Train loss and acc of batch 22: 48.37315368652344, 0.984375\n",
      "Train loss and acc of batch 23: 47.77743911743164, 1.0\n",
      "Train loss and acc of batch 24: 48.373130798339844, 0.984375\n",
      "Train loss and acc of batch 25: 47.77741622924805, 1.0\n",
      "Train loss and acc of batch 26: 47.777408599853516, 1.0\n",
      "Train loss and acc of batch 27: 47.777400970458984, 1.0\n",
      "Train loss and acc of batch 28: 47.77739334106445, 1.0\n",
      "Train loss and acc of batch 29: 48.373085021972656, 0.984375\n",
      "Train loss and acc of batch 30: 47.77737808227539, 1.0\n",
      "Train loss and acc of batch 31: 47.99412536621094, 0.984375\n",
      "Train loss and acc of batch 32: 47.77735900878906, 1.0\n",
      "Train loss and acc of batch 33: 47.777347564697266, 1.0\n",
      "Train loss and acc of batch 34: 48.37303924560547, 0.984375\n",
      "Train loss and acc of batch 35: 48.21085739135742, 0.96875\n",
      "Train loss and acc of batch 36: 47.77732467651367, 1.0\n",
      "Train loss and acc of batch 37: 48.53053665161133, 0.984375\n",
      "Train loss and acc of batch 38: 49.12622833251953, 0.96875\n",
      "Train loss and acc of batch 39: 47.99406433105469, 0.984375\n",
      "Train loss and acc of batch 40: 47.777286529541016, 1.0\n",
      "Train loss and acc of batch 41: 49.12620162963867, 0.96875\n",
      "Train loss and acc of batch 42: 47.77726745605469, 1.0\n",
      "Train loss and acc of batch 43: 48.372962951660156, 0.984375\n",
      "Train loss and acc of batch 44: 47.777252197265625, 1.0\n",
      "Train loss and acc of batch 45: 48.37294006347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.063087463378906, 0.984375\n",
      "Train loss and acc of batch 47: 47.777225494384766, 1.0\n",
      "Train loss and acc of batch 48: 47.7772102355957, 1.0\n",
      "Train loss and acc of batch 49: 47.77720642089844, 1.0\n",
      "Train loss and acc of batch 50: 48.372901916503906, 0.984375\n",
      "Train loss and acc of batch 51: 49.12611389160156, 0.96875\n",
      "Train loss and acc of batch 52: 49.033016204833984, 0.953125\n",
      "Train loss and acc of batch 53: 47.77717208862305, 1.0\n",
      "Train loss and acc of batch 54: 47.993927001953125, 0.984375\n",
      "Train loss and acc of batch 55: 47.77715301513672, 1.0\n",
      "Train loss and acc of batch 56: 47.77714538574219, 1.0\n",
      "Train loss and acc of batch 57: 48.372833251953125, 0.984375\n",
      "Train loss and acc of batch 58: 47.77712631225586, 1.0\n",
      "Train loss and acc of batch 59: 47.777122497558594, 1.0\n",
      "Train loss and acc of batch 60: 47.77710723876953, 1.0\n",
      "Train loss and acc of batch 61: 47.777103424072266, 1.0\n",
      "Train loss and acc of batch 62: 47.7770881652832, 1.0\n",
      "Train loss and acc of batch 63: 48.968482971191406, 0.96875\n",
      "Train loss and acc of batch 64: 47.99383544921875, 0.984375\n",
      "Train loss and acc of batch 65: 47.77706527709961, 1.0\n",
      "Train loss and acc of batch 66: 47.77705383300781, 1.0\n",
      "Train loss and acc of batch 67: 48.589515686035156, 0.96875\n",
      "Train loss and acc of batch 68: 48.37274169921875, 0.984375\n",
      "Train loss and acc of batch 69: 47.993797302246094, 0.984375\n",
      "Train loss and acc of batch 70: 47.777015686035156, 1.0\n",
      "Training accuracy and loss of epoch #445: 0.9897, 48.0982\n",
      "Saved model by train loss 48.09821394799461\n",
      "Train loss and acc of batch 0: 47.777008056640625, 1.0\n",
      "Train loss and acc of batch 1: 47.777000427246094, 1.0\n",
      "Train loss and acc of batch 2: 47.777000427246094, 1.0\n",
      "Train loss and acc of batch 3: 47.993751525878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.7769775390625, 1.0\n",
      "Train loss and acc of batch 5: 49.125885009765625, 0.96875\n",
      "Train loss and acc of batch 6: 48.279571533203125, 0.96875\n",
      "Train loss and acc of batch 7: 47.77695083618164, 1.0\n",
      "Train loss and acc of batch 8: 48.372642517089844, 0.984375\n",
      "Train loss and acc of batch 9: 48.062782287597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.77692413330078, 1.0\n",
      "Train loss and acc of batch 11: 47.776912689208984, 1.0\n",
      "Train loss and acc of batch 12: 48.530128479003906, 0.984375\n",
      "Train loss and acc of batch 13: 47.99365997314453, 0.984375\n",
      "Train loss and acc of batch 14: 47.99364471435547, 0.984375\n",
      "Train loss and acc of batch 15: 48.372581481933594, 0.984375\n",
      "Train loss and acc of batch 16: 48.37257385253906, 0.984375\n",
      "Train loss and acc of batch 17: 48.530086517333984, 0.984375\n",
      "Train loss and acc of batch 18: 48.65840530395508, 0.96875\n",
      "Train loss and acc of batch 19: 47.77684783935547, 1.0\n",
      "Train loss and acc of batch 20: 47.776832580566406, 1.0\n",
      "Train loss and acc of batch 21: 48.372528076171875, 0.984375\n",
      "Train loss and acc of batch 22: 48.37251281738281, 0.984375\n",
      "Train loss and acc of batch 23: 47.77680587768555, 1.0\n",
      "Train loss and acc of batch 24: 48.37250518798828, 0.984375\n",
      "Train loss and acc of batch 25: 47.776790618896484, 1.0\n",
      "Train loss and acc of batch 26: 47.77678298950195, 1.0\n",
      "Train loss and acc of batch 27: 47.77677536010742, 1.0\n",
      "Train loss and acc of batch 28: 47.776756286621094, 1.0\n",
      "Train loss and acc of batch 29: 48.372459411621094, 0.984375\n",
      "Train loss and acc of batch 30: 47.77674865722656, 1.0\n",
      "Train loss and acc of batch 31: 47.993499755859375, 0.984375\n",
      "Train loss and acc of batch 32: 47.77672576904297, 1.0\n",
      "Train loss and acc of batch 33: 47.7767219543457, 1.0\n",
      "Train loss and acc of batch 34: 48.372413635253906, 0.984375\n",
      "Train loss and acc of batch 35: 48.21023178100586, 0.96875\n",
      "Train loss and acc of batch 36: 47.776695251464844, 1.0\n",
      "Train loss and acc of batch 37: 48.529903411865234, 0.984375\n",
      "Train loss and acc of batch 38: 49.12560272216797, 0.96875\n",
      "Train loss and acc of batch 39: 47.993431091308594, 0.984375\n",
      "Train loss and acc of batch 40: 47.77665710449219, 1.0\n",
      "Train loss and acc of batch 41: 49.12557601928711, 0.96875\n",
      "Train loss and acc of batch 42: 47.77663803100586, 1.0\n",
      "Train loss and acc of batch 43: 48.37232971191406, 0.984375\n",
      "Train loss and acc of batch 44: 47.7766227722168, 1.0\n",
      "Train loss and acc of batch 45: 48.372314453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.06245422363281, 0.984375\n",
      "Train loss and acc of batch 47: 47.7765998840332, 1.0\n",
      "Train loss and acc of batch 48: 47.77658462524414, 1.0\n",
      "Train loss and acc of batch 49: 47.776580810546875, 1.0\n",
      "Train loss and acc of batch 50: 48.37226867675781, 0.984375\n",
      "Train loss and acc of batch 51: 49.12548065185547, 0.96875\n",
      "Train loss and acc of batch 52: 49.03239059448242, 0.953125\n",
      "Train loss and acc of batch 53: 47.77654266357422, 1.0\n",
      "Train loss and acc of batch 54: 47.99330139160156, 0.984375\n",
      "Train loss and acc of batch 55: 47.77652359008789, 1.0\n",
      "Train loss and acc of batch 56: 47.776512145996094, 1.0\n",
      "Train loss and acc of batch 57: 48.37220764160156, 0.984375\n",
      "Train loss and acc of batch 58: 47.77649688720703, 1.0\n",
      "Train loss and acc of batch 59: 47.776485443115234, 1.0\n",
      "Train loss and acc of batch 60: 47.7764778137207, 1.0\n",
      "Train loss and acc of batch 61: 47.77647018432617, 1.0\n",
      "Train loss and acc of batch 62: 47.77646255493164, 1.0\n",
      "Train loss and acc of batch 63: 48.967857360839844, 0.96875\n",
      "Train loss and acc of batch 64: 47.99320983886719, 0.984375\n",
      "Train loss and acc of batch 65: 47.776432037353516, 1.0\n",
      "Train loss and acc of batch 66: 47.776424407958984, 1.0\n",
      "Train loss and acc of batch 67: 48.5888786315918, 0.96875\n",
      "Train loss and acc of batch 68: 48.37211608886719, 0.984375\n",
      "Train loss and acc of batch 69: 47.9931640625, 0.984375\n",
      "Train loss and acc of batch 70: 47.776390075683594, 1.0\n",
      "Training accuracy and loss of epoch #446: 0.9897, 48.0976\n",
      "Saved model by train loss 48.09758463040204\n",
      "Train loss and acc of batch 0: 47.7763786315918, 1.0\n",
      "Train loss and acc of batch 1: 47.77637481689453, 1.0\n",
      "Train loss and acc of batch 2: 47.77635955810547, 1.0\n",
      "Train loss and acc of batch 3: 47.99311828613281, 0.984375\n",
      "Train loss and acc of batch 4: 47.77634811401367, 1.0\n",
      "Train loss and acc of batch 5: 49.12525939941406, 0.96875\n",
      "Train loss and acc of batch 6: 48.27894592285156, 0.96875\n",
      "Train loss and acc of batch 7: 47.77632522583008, 1.0\n",
      "Train loss and acc of batch 8: 48.37200927734375, 0.984375\n",
      "Train loss and acc of batch 9: 48.062156677246094, 0.984375\n",
      "Train loss and acc of batch 10: 47.77629470825195, 1.0\n",
      "Train loss and acc of batch 11: 47.77628707885742, 1.0\n",
      "Train loss and acc of batch 12: 48.52949905395508, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 13: 47.99302673339844, 0.984375\n",
      "Train loss and acc of batch 14: 47.993019104003906, 0.984375\n",
      "Train loss and acc of batch 15: 48.3719482421875, 0.984375\n",
      "Train loss and acc of batch 16: 48.37194061279297, 0.984375\n",
      "Train loss and acc of batch 17: 48.529449462890625, 0.984375\n",
      "Train loss and acc of batch 18: 48.65777587890625, 0.96875\n",
      "Train loss and acc of batch 19: 47.77621078491211, 1.0\n",
      "Train loss and acc of batch 20: 47.77620315551758, 1.0\n",
      "Train loss and acc of batch 21: 48.37190246582031, 0.984375\n",
      "Train loss and acc of batch 22: 48.37188720703125, 0.984375\n",
      "Train loss and acc of batch 23: 47.77617645263672, 1.0\n",
      "Train loss and acc of batch 24: 48.371864318847656, 0.984375\n",
      "Train loss and acc of batch 25: 47.776161193847656, 1.0\n",
      "Train loss and acc of batch 26: 47.776153564453125, 1.0\n",
      "Train loss and acc of batch 27: 47.776145935058594, 1.0\n",
      "Train loss and acc of batch 28: 47.7761344909668, 1.0\n",
      "Train loss and acc of batch 29: 48.371826171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.77611541748047, 1.0\n",
      "Train loss and acc of batch 31: 47.99286651611328, 0.984375\n",
      "Train loss and acc of batch 32: 47.776100158691406, 1.0\n",
      "Train loss and acc of batch 33: 47.776084899902344, 1.0\n",
      "Train loss and acc of batch 34: 48.37178039550781, 0.984375\n",
      "Train loss and acc of batch 35: 48.20960235595703, 0.96875\n",
      "Train loss and acc of batch 36: 47.77606201171875, 1.0\n",
      "Train loss and acc of batch 37: 48.529273986816406, 0.984375\n",
      "Train loss and acc of batch 38: 49.124969482421875, 0.96875\n",
      "Train loss and acc of batch 39: 47.9927978515625, 0.984375\n",
      "Train loss and acc of batch 40: 47.77602767944336, 1.0\n",
      "Train loss and acc of batch 41: 49.124942779541016, 0.96875\n",
      "Train loss and acc of batch 42: 47.7760124206543, 1.0\n",
      "Train loss and acc of batch 43: 48.37169647216797, 0.984375\n",
      "Train loss and acc of batch 44: 47.7759895324707, 1.0\n",
      "Train loss and acc of batch 45: 48.371681213378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.06182861328125, 0.984375\n",
      "Train loss and acc of batch 47: 47.775962829589844, 1.0\n",
      "Train loss and acc of batch 48: 47.77595520019531, 1.0\n",
      "Train loss and acc of batch 49: 47.77594757080078, 1.0\n",
      "Train loss and acc of batch 50: 48.37163543701172, 0.984375\n",
      "Train loss and acc of batch 51: 49.124855041503906, 0.96875\n",
      "Train loss and acc of batch 52: 49.03175354003906, 0.953125\n",
      "Train loss and acc of batch 53: 47.775909423828125, 1.0\n",
      "Train loss and acc of batch 54: 47.99266815185547, 0.984375\n",
      "Train loss and acc of batch 55: 47.77589416503906, 1.0\n",
      "Train loss and acc of batch 56: 47.77588653564453, 1.0\n",
      "Train loss and acc of batch 57: 48.37158203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.7758674621582, 1.0\n",
      "Train loss and acc of batch 59: 47.775856018066406, 1.0\n",
      "Train loss and acc of batch 60: 47.775848388671875, 1.0\n",
      "Train loss and acc of batch 61: 47.77583694458008, 1.0\n",
      "Train loss and acc of batch 62: 47.77583312988281, 1.0\n",
      "Train loss and acc of batch 63: 48.967227935791016, 0.96875\n",
      "Train loss and acc of batch 64: 47.992576599121094, 0.984375\n",
      "Train loss and acc of batch 65: 47.77580642700195, 1.0\n",
      "Train loss and acc of batch 66: 47.77579879760742, 1.0\n",
      "Train loss and acc of batch 67: 48.588253021240234, 0.96875\n",
      "Train loss and acc of batch 68: 48.37147521972656, 0.984375\n",
      "Train loss and acc of batch 69: 47.992530822753906, 0.984375\n",
      "Train loss and acc of batch 70: 47.775760650634766, 1.0\n",
      "Training accuracy and loss of epoch #447: 0.9897, 48.0970\n",
      "Saved model by train loss 48.09695402333434\n",
      "Train loss and acc of batch 0: 47.7757568359375, 1.0\n",
      "Train loss and acc of batch 1: 47.77574920654297, 1.0\n",
      "Train loss and acc of batch 2: 47.775733947753906, 1.0\n",
      "Train loss and acc of batch 3: 47.99249267578125, 0.984375\n",
      "Train loss and acc of batch 4: 47.77571487426758, 1.0\n",
      "Train loss and acc of batch 5: 49.1246337890625, 0.96875\n",
      "Train loss and acc of batch 6: 48.278316497802734, 0.96875\n",
      "Train loss and acc of batch 7: 47.77568817138672, 1.0\n",
      "Train loss and acc of batch 8: 48.37138366699219, 0.984375\n",
      "Train loss and acc of batch 9: 48.0615234375, 0.984375\n",
      "Train loss and acc of batch 10: 47.775657653808594, 1.0\n",
      "Train loss and acc of batch 11: 47.77565002441406, 1.0\n",
      "Train loss and acc of batch 12: 48.52886962890625, 0.984375\n",
      "Train loss and acc of batch 13: 47.992401123046875, 0.984375\n",
      "Train loss and acc of batch 14: 47.992393493652344, 0.984375\n",
      "Train loss and acc of batch 15: 48.371315002441406, 0.984375\n",
      "Train loss and acc of batch 16: 48.371315002441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.52882385253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.65714645385742, 0.96875\n",
      "Train loss and acc of batch 19: 47.77558135986328, 1.0\n",
      "Train loss and acc of batch 20: 47.775569915771484, 1.0\n",
      "Train loss and acc of batch 21: 48.37126159667969, 0.984375\n",
      "Train loss and acc of batch 22: 48.37126159667969, 0.984375\n",
      "Train loss and acc of batch 23: 47.77554702758789, 1.0\n",
      "Train loss and acc of batch 24: 48.371238708496094, 0.984375\n",
      "Train loss and acc of batch 25: 47.77552795410156, 1.0\n",
      "Train loss and acc of batch 26: 47.7755126953125, 1.0\n",
      "Train loss and acc of batch 27: 47.7755126953125, 1.0\n",
      "Train loss and acc of batch 28: 47.77550506591797, 1.0\n",
      "Train loss and acc of batch 29: 48.37120056152344, 0.984375\n",
      "Train loss and acc of batch 30: 47.77548599243164, 1.0\n",
      "Train loss and acc of batch 31: 47.99224090576172, 0.984375\n",
      "Train loss and acc of batch 32: 47.77546310424805, 1.0\n",
      "Train loss and acc of batch 33: 47.77545928955078, 1.0\n",
      "Train loss and acc of batch 34: 48.37114715576172, 0.984375\n",
      "Train loss and acc of batch 35: 48.20896911621094, 0.96875\n",
      "Train loss and acc of batch 36: 47.77543258666992, 1.0\n",
      "Train loss and acc of batch 37: 48.528648376464844, 0.984375\n",
      "Train loss and acc of batch 38: 49.12433624267578, 0.96875\n",
      "Train loss and acc of batch 39: 47.992164611816406, 0.984375\n",
      "Train loss and acc of batch 40: 47.775394439697266, 1.0\n",
      "Train loss and acc of batch 41: 49.12431335449219, 0.96875\n",
      "Train loss and acc of batch 42: 47.7753791809082, 1.0\n",
      "Train loss and acc of batch 43: 48.371063232421875, 0.984375\n",
      "Train loss and acc of batch 44: 47.775360107421875, 1.0\n",
      "Train loss and acc of batch 45: 48.37104797363281, 0.984375\n",
      "Train loss and acc of batch 46: 48.061195373535156, 0.984375\n",
      "Train loss and acc of batch 47: 47.77533721923828, 1.0\n",
      "Train loss and acc of batch 48: 47.77532958984375, 1.0\n",
      "Train loss and acc of batch 49: 47.77531433105469, 1.0\n",
      "Train loss and acc of batch 50: 48.371009826660156, 0.984375\n",
      "Train loss and acc of batch 51: 49.124229431152344, 0.96875\n",
      "Train loss and acc of batch 52: 49.031131744384766, 0.953125\n",
      "Train loss and acc of batch 53: 47.7752799987793, 1.0\n",
      "Train loss and acc of batch 54: 47.992034912109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.77526092529297, 1.0\n",
      "Train loss and acc of batch 56: 47.77525329589844, 1.0\n",
      "Train loss and acc of batch 57: 48.370948791503906, 0.984375\n",
      "Train loss and acc of batch 58: 47.775238037109375, 1.0\n",
      "Train loss and acc of batch 59: 47.775230407714844, 1.0\n",
      "Train loss and acc of batch 60: 47.77521514892578, 1.0\n",
      "Train loss and acc of batch 61: 47.775211334228516, 1.0\n",
      "Train loss and acc of batch 62: 47.77519989013672, 1.0\n",
      "Train loss and acc of batch 63: 48.96659469604492, 0.96875\n",
      "Train loss and acc of batch 64: 47.99195098876953, 0.984375\n",
      "Train loss and acc of batch 65: 47.77517318725586, 1.0\n",
      "Train loss and acc of batch 66: 47.775169372558594, 1.0\n",
      "Train loss and acc of batch 67: 48.587623596191406, 0.96875\n",
      "Train loss and acc of batch 68: 48.370849609375, 0.984375\n",
      "Train loss and acc of batch 69: 47.99189758300781, 0.984375\n",
      "Train loss and acc of batch 70: 47.77513122558594, 1.0\n",
      "Training accuracy and loss of epoch #448: 0.9897, 48.0963\n",
      "Saved model by train loss 48.096323953547945\n",
      "Train loss and acc of batch 0: 47.77511978149414, 1.0\n",
      "Train loss and acc of batch 1: 47.77511215209961, 1.0\n",
      "Train loss and acc of batch 2: 47.77510070800781, 1.0\n",
      "Train loss and acc of batch 3: 47.991859436035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.77508544921875, 1.0\n",
      "Train loss and acc of batch 5: 49.12400817871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.277679443359375, 0.96875\n",
      "Train loss and acc of batch 7: 47.77505874633789, 1.0\n",
      "Train loss and acc of batch 8: 48.370750427246094, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 9: 48.060890197753906, 0.984375\n",
      "Train loss and acc of batch 10: 47.77503204345703, 1.0\n",
      "Train loss and acc of batch 11: 47.775020599365234, 1.0\n",
      "Train loss and acc of batch 12: 48.528236389160156, 0.984375\n",
      "Train loss and acc of batch 13: 47.99177551269531, 0.984375\n",
      "Train loss and acc of batch 14: 47.99176025390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.370689392089844, 0.984375\n",
      "Train loss and acc of batch 16: 48.37068176269531, 0.984375\n",
      "Train loss and acc of batch 17: 48.5281982421875, 0.984375\n",
      "Train loss and acc of batch 18: 48.65651321411133, 0.96875\n",
      "Train loss and acc of batch 19: 47.77494812011719, 1.0\n",
      "Train loss and acc of batch 20: 47.77494430541992, 1.0\n",
      "Train loss and acc of batch 21: 48.370635986328125, 0.984375\n",
      "Train loss and acc of batch 22: 48.370628356933594, 0.984375\n",
      "Train loss and acc of batch 23: 47.77491760253906, 1.0\n",
      "Train loss and acc of batch 24: 48.37061309814453, 0.984375\n",
      "Train loss and acc of batch 25: 47.774898529052734, 1.0\n",
      "Train loss and acc of batch 26: 47.77488708496094, 1.0\n",
      "Train loss and acc of batch 27: 47.77488327026367, 1.0\n",
      "Train loss and acc of batch 28: 47.77487564086914, 1.0\n",
      "Train loss and acc of batch 29: 48.37055969238281, 0.984375\n",
      "Train loss and acc of batch 30: 47.77485656738281, 1.0\n",
      "Train loss and acc of batch 31: 47.991607666015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.774837493896484, 1.0\n",
      "Train loss and acc of batch 33: 47.77482604980469, 1.0\n",
      "Train loss and acc of batch 34: 48.370513916015625, 0.984375\n",
      "Train loss and acc of batch 35: 48.20833969116211, 0.96875\n",
      "Train loss and acc of batch 36: 47.774803161621094, 1.0\n",
      "Train loss and acc of batch 37: 48.528018951416016, 0.984375\n",
      "Train loss and acc of batch 38: 49.12371063232422, 0.96875\n",
      "Train loss and acc of batch 39: 47.991539001464844, 0.984375\n",
      "Train loss and acc of batch 40: 47.7747688293457, 1.0\n",
      "Train loss and acc of batch 41: 49.12368392944336, 0.96875\n",
      "Train loss and acc of batch 42: 47.77474594116211, 1.0\n",
      "Train loss and acc of batch 43: 48.37043762207031, 0.984375\n",
      "Train loss and acc of batch 44: 47.77473449707031, 1.0\n",
      "Train loss and acc of batch 45: 48.37042236328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.060569763183594, 0.984375\n",
      "Train loss and acc of batch 47: 47.77470397949219, 1.0\n",
      "Train loss and acc of batch 48: 47.77469253540039, 1.0\n",
      "Train loss and acc of batch 49: 47.77468490600586, 1.0\n",
      "Train loss and acc of batch 50: 48.37037658691406, 0.984375\n",
      "Train loss and acc of batch 51: 49.12358856201172, 0.96875\n",
      "Train loss and acc of batch 52: 49.03049850463867, 0.953125\n",
      "Train loss and acc of batch 53: 47.77465057373047, 1.0\n",
      "Train loss and acc of batch 54: 47.99140930175781, 0.984375\n",
      "Train loss and acc of batch 55: 47.77463150024414, 1.0\n",
      "Train loss and acc of batch 56: 47.774620056152344, 1.0\n",
      "Train loss and acc of batch 57: 48.37031555175781, 0.984375\n",
      "Train loss and acc of batch 58: 47.77460861206055, 1.0\n",
      "Train loss and acc of batch 59: 47.77459716796875, 1.0\n",
      "Train loss and acc of batch 60: 47.77458953857422, 1.0\n",
      "Train loss and acc of batch 61: 47.77458190917969, 1.0\n",
      "Train loss and acc of batch 62: 47.774566650390625, 1.0\n",
      "Train loss and acc of batch 63: 48.965965270996094, 0.96875\n",
      "Train loss and acc of batch 64: 47.99131774902344, 0.984375\n",
      "Train loss and acc of batch 65: 47.77454376220703, 1.0\n",
      "Train loss and acc of batch 66: 47.7745361328125, 1.0\n",
      "Train loss and acc of batch 67: 48.58699035644531, 0.96875\n",
      "Train loss and acc of batch 68: 48.370216369628906, 0.984375\n",
      "Train loss and acc of batch 69: 47.99127197265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.77450180053711, 1.0\n",
      "Training accuracy and loss of epoch #449: 0.9897, 48.0957\n",
      "Saved model by train loss 48.09569350766464\n",
      "Train loss and acc of batch 0: 47.77449035644531, 1.0\n",
      "Train loss and acc of batch 1: 47.77448272705078, 1.0\n",
      "Train loss and acc of batch 2: 47.77447509765625, 1.0\n",
      "Train loss and acc of batch 3: 47.99122619628906, 0.984375\n",
      "Train loss and acc of batch 4: 47.77445983886719, 1.0\n",
      "Train loss and acc of batch 5: 49.12336730957031, 0.96875\n",
      "Train loss and acc of batch 6: 48.27705383300781, 0.96875\n",
      "Train loss and acc of batch 7: 47.7744255065918, 1.0\n",
      "Train loss and acc of batch 8: 48.3701171875, 0.984375\n",
      "Train loss and acc of batch 9: 48.060264587402344, 0.984375\n",
      "Train loss and acc of batch 10: 47.7744026184082, 1.0\n",
      "Train loss and acc of batch 11: 47.774391174316406, 1.0\n",
      "Train loss and acc of batch 12: 48.527610778808594, 0.984375\n",
      "Train loss and acc of batch 13: 47.99113464355469, 0.984375\n",
      "Train loss and acc of batch 14: 47.991127014160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.37005615234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.37004852294922, 0.984375\n",
      "Train loss and acc of batch 17: 48.52756118774414, 0.984375\n",
      "Train loss and acc of batch 18: 48.655887603759766, 0.96875\n",
      "Train loss and acc of batch 19: 47.774322509765625, 1.0\n",
      "Train loss and acc of batch 20: 47.77431106567383, 1.0\n",
      "Train loss and acc of batch 21: 48.37001037597656, 0.984375\n",
      "Train loss and acc of batch 22: 48.3699951171875, 0.984375\n",
      "Train loss and acc of batch 23: 47.774288177490234, 1.0\n",
      "Train loss and acc of batch 24: 48.369972229003906, 0.984375\n",
      "Train loss and acc of batch 25: 47.774269104003906, 1.0\n",
      "Train loss and acc of batch 26: 47.77426528930664, 1.0\n",
      "Train loss and acc of batch 27: 47.774253845214844, 1.0\n",
      "Train loss and acc of batch 28: 47.77423858642578, 1.0\n",
      "Train loss and acc of batch 29: 48.36993408203125, 0.984375\n",
      "Train loss and acc of batch 30: 47.77422332763672, 1.0\n",
      "Train loss and acc of batch 31: 47.99098205566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.774208068847656, 1.0\n",
      "Train loss and acc of batch 33: 47.77419662475586, 1.0\n",
      "Train loss and acc of batch 34: 48.36988830566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.20771026611328, 0.96875\n",
      "Train loss and acc of batch 36: 47.774169921875, 1.0\n",
      "Train loss and acc of batch 37: 48.52738571166992, 0.984375\n",
      "Train loss and acc of batch 38: 49.123077392578125, 0.96875\n",
      "Train loss and acc of batch 39: 47.99090576171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.774139404296875, 1.0\n",
      "Train loss and acc of batch 41: 49.123050689697266, 0.96875\n",
      "Train loss and acc of batch 42: 47.774112701416016, 1.0\n",
      "Train loss and acc of batch 43: 48.36981201171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.77409744262695, 1.0\n",
      "Train loss and acc of batch 45: 48.36979675292969, 0.984375\n",
      "Train loss and acc of batch 46: 48.0599365234375, 0.984375\n",
      "Train loss and acc of batch 47: 47.77407455444336, 1.0\n",
      "Train loss and acc of batch 48: 47.77406692504883, 1.0\n",
      "Train loss and acc of batch 49: 47.77406311035156, 1.0\n",
      "Train loss and acc of batch 50: 48.36974334716797, 0.984375\n",
      "Train loss and acc of batch 51: 49.122962951660156, 0.96875\n",
      "Train loss and acc of batch 52: 49.02986526489258, 0.953125\n",
      "Train loss and acc of batch 53: 47.774017333984375, 1.0\n",
      "Train loss and acc of batch 54: 47.99077606201172, 0.984375\n",
      "Train loss and acc of batch 55: 47.77400588989258, 1.0\n",
      "Train loss and acc of batch 56: 47.77399444580078, 1.0\n",
      "Train loss and acc of batch 57: 48.36968994140625, 0.984375\n",
      "Train loss and acc of batch 58: 47.77397537231445, 1.0\n",
      "Train loss and acc of batch 59: 47.77396774291992, 1.0\n",
      "Train loss and acc of batch 60: 47.773956298828125, 1.0\n",
      "Train loss and acc of batch 61: 47.773948669433594, 1.0\n",
      "Train loss and acc of batch 62: 47.77394104003906, 1.0\n",
      "Train loss and acc of batch 63: 48.96533966064453, 0.96875\n",
      "Train loss and acc of batch 64: 47.990684509277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.7739143371582, 1.0\n",
      "Train loss and acc of batch 66: 47.77390670776367, 1.0\n",
      "Train loss and acc of batch 67: 48.586360931396484, 0.96875\n",
      "Train loss and acc of batch 68: 48.369590759277344, 0.984375\n",
      "Train loss and acc of batch 69: 47.990638732910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.773868560791016, 1.0\n",
      "Training accuracy and loss of epoch #450: 0.9897, 48.0951\n",
      "Saved model by train loss 48.09506322296573\n",
      "Train loss and acc of batch 0: 47.77385711669922, 1.0\n",
      "Train loss and acc of batch 1: 47.77385330200195, 1.0\n",
      "Train loss and acc of batch 2: 47.773841857910156, 1.0\n",
      "Train loss and acc of batch 3: 47.9906005859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.77382278442383, 1.0\n",
      "Train loss and acc of batch 5: 49.12274169921875, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 6: 48.27642822265625, 0.96875\n",
      "Train loss and acc of batch 7: 47.773799896240234, 1.0\n",
      "Train loss and acc of batch 8: 48.369483947753906, 0.984375\n",
      "Train loss and acc of batch 9: 48.05963897705078, 0.984375\n",
      "Train loss and acc of batch 10: 47.77376937866211, 1.0\n",
      "Train loss and acc of batch 11: 47.773765563964844, 1.0\n",
      "Train loss and acc of batch 12: 48.52698516845703, 0.984375\n",
      "Train loss and acc of batch 13: 47.990509033203125, 0.984375\n",
      "Train loss and acc of batch 14: 47.990501403808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.369422912597656, 0.984375\n",
      "Train loss and acc of batch 16: 48.369415283203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.52693176269531, 0.984375\n",
      "Train loss and acc of batch 18: 48.655250549316406, 0.96875\n",
      "Train loss and acc of batch 19: 47.7736930847168, 1.0\n",
      "Train loss and acc of batch 20: 47.773685455322266, 1.0\n",
      "Train loss and acc of batch 21: 48.36937713623047, 0.984375\n",
      "Train loss and acc of batch 22: 48.369361877441406, 0.984375\n",
      "Train loss and acc of batch 23: 47.773658752441406, 1.0\n",
      "Train loss and acc of batch 24: 48.369346618652344, 0.984375\n",
      "Train loss and acc of batch 25: 47.77363967895508, 1.0\n",
      "Train loss and acc of batch 26: 47.77362823486328, 1.0\n",
      "Train loss and acc of batch 27: 47.77362060546875, 1.0\n",
      "Train loss and acc of batch 28: 47.77361297607422, 1.0\n",
      "Train loss and acc of batch 29: 48.36930847167969, 0.984375\n",
      "Train loss and acc of batch 30: 47.77359390258789, 1.0\n",
      "Train loss and acc of batch 31: 47.99034881591797, 0.984375\n",
      "Train loss and acc of batch 32: 47.77357482910156, 1.0\n",
      "Train loss and acc of batch 33: 47.77356719970703, 1.0\n",
      "Train loss and acc of batch 34: 48.3692626953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.20707702636719, 0.96875\n",
      "Train loss and acc of batch 36: 47.77354431152344, 1.0\n",
      "Train loss and acc of batch 37: 48.526756286621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.12244415283203, 0.96875\n",
      "Train loss and acc of batch 39: 47.99028015136719, 0.984375\n",
      "Train loss and acc of batch 40: 47.77350997924805, 1.0\n",
      "Train loss and acc of batch 41: 49.12242126464844, 0.96875\n",
      "Train loss and acc of batch 42: 47.77349090576172, 1.0\n",
      "Train loss and acc of batch 43: 48.36918640136719, 0.984375\n",
      "Train loss and acc of batch 44: 47.77347183227539, 1.0\n",
      "Train loss and acc of batch 45: 48.36915588378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.059303283691406, 0.984375\n",
      "Train loss and acc of batch 47: 47.773441314697266, 1.0\n",
      "Train loss and acc of batch 48: 47.7734375, 1.0\n",
      "Train loss and acc of batch 49: 47.7734260559082, 1.0\n",
      "Train loss and acc of batch 50: 48.369117736816406, 0.984375\n",
      "Train loss and acc of batch 51: 49.122337341308594, 0.96875\n",
      "Train loss and acc of batch 52: 49.02923583984375, 0.953125\n",
      "Train loss and acc of batch 53: 47.77339172363281, 1.0\n",
      "Train loss and acc of batch 54: 47.990150451660156, 0.984375\n",
      "Train loss and acc of batch 55: 47.77336883544922, 1.0\n",
      "Train loss and acc of batch 56: 47.77336883544922, 1.0\n",
      "Train loss and acc of batch 57: 48.369056701660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.77334976196289, 1.0\n",
      "Train loss and acc of batch 59: 47.773338317871094, 1.0\n",
      "Train loss and acc of batch 60: 47.77332305908203, 1.0\n",
      "Train loss and acc of batch 61: 47.773319244384766, 1.0\n",
      "Train loss and acc of batch 62: 47.773311614990234, 1.0\n",
      "Train loss and acc of batch 63: 48.96470260620117, 0.96875\n",
      "Train loss and acc of batch 64: 47.99005889892578, 0.984375\n",
      "Train loss and acc of batch 65: 47.773284912109375, 1.0\n",
      "Train loss and acc of batch 66: 47.77327346801758, 1.0\n",
      "Train loss and acc of batch 67: 48.585731506347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.36896514892578, 0.984375\n",
      "Train loss and acc of batch 69: 47.990013122558594, 0.984375\n",
      "Train loss and acc of batch 70: 47.77324295043945, 1.0\n",
      "Training accuracy and loss of epoch #451: 0.9897, 48.0944\n",
      "Saved model by train loss 48.094433636732504\n",
      "Train loss and acc of batch 0: 47.773231506347656, 1.0\n",
      "Train loss and acc of batch 1: 47.773223876953125, 1.0\n",
      "Train loss and acc of batch 2: 47.77321243286133, 1.0\n",
      "Train loss and acc of batch 3: 47.989967346191406, 0.984375\n",
      "Train loss and acc of batch 4: 47.773197174072266, 1.0\n",
      "Train loss and acc of batch 5: 49.12211608886719, 0.96875\n",
      "Train loss and acc of batch 6: 48.275794982910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.77316665649414, 1.0\n",
      "Train loss and acc of batch 8: 48.368865966796875, 0.984375\n",
      "Train loss and acc of batch 9: 48.058998107910156, 0.984375\n",
      "Train loss and acc of batch 10: 47.77314376831055, 1.0\n",
      "Train loss and acc of batch 11: 47.773136138916016, 1.0\n",
      "Train loss and acc of batch 12: 48.52634811401367, 0.984375\n",
      "Train loss and acc of batch 13: 47.98988342285156, 0.984375\n",
      "Train loss and acc of batch 14: 47.98987579345703, 0.984375\n",
      "Train loss and acc of batch 15: 48.368797302246094, 0.984375\n",
      "Train loss and acc of batch 16: 48.368797302246094, 0.984375\n",
      "Train loss and acc of batch 17: 48.52629852294922, 0.984375\n",
      "Train loss and acc of batch 18: 48.654624938964844, 0.96875\n",
      "Train loss and acc of batch 19: 47.7730598449707, 1.0\n",
      "Train loss and acc of batch 20: 47.77305221557617, 1.0\n",
      "Train loss and acc of batch 21: 48.368743896484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.368736267089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.77302551269531, 1.0\n",
      "Train loss and acc of batch 24: 48.36872100830078, 0.984375\n",
      "Train loss and acc of batch 25: 47.77301025390625, 1.0\n",
      "Train loss and acc of batch 26: 47.77299499511719, 1.0\n",
      "Train loss and acc of batch 27: 47.77299118041992, 1.0\n",
      "Train loss and acc of batch 28: 47.77298355102539, 1.0\n",
      "Train loss and acc of batch 29: 48.368675231933594, 0.984375\n",
      "Train loss and acc of batch 30: 47.77296447753906, 1.0\n",
      "Train loss and acc of batch 31: 47.989723205566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.772945404052734, 1.0\n",
      "Train loss and acc of batch 33: 47.7729377746582, 1.0\n",
      "Train loss and acc of batch 34: 48.368629455566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.20644760131836, 0.96875\n",
      "Train loss and acc of batch 36: 47.772911071777344, 1.0\n",
      "Train loss and acc of batch 37: 48.526126861572266, 0.984375\n",
      "Train loss and acc of batch 38: 49.12181854248047, 0.96875\n",
      "Train loss and acc of batch 39: 47.989654541015625, 0.984375\n",
      "Train loss and acc of batch 40: 47.77287292480469, 1.0\n",
      "Train loss and acc of batch 41: 49.121795654296875, 0.96875\n",
      "Train loss and acc of batch 42: 47.77286148071289, 1.0\n",
      "Train loss and acc of batch 43: 48.368553161621094, 0.984375\n",
      "Train loss and acc of batch 44: 47.77284240722656, 1.0\n",
      "Train loss and acc of batch 45: 48.3685302734375, 0.984375\n",
      "Train loss and acc of batch 46: 48.05867004394531, 0.984375\n",
      "Train loss and acc of batch 47: 47.7728157043457, 1.0\n",
      "Train loss and acc of batch 48: 47.772804260253906, 1.0\n",
      "Train loss and acc of batch 49: 47.772796630859375, 1.0\n",
      "Train loss and acc of batch 50: 48.36848449707031, 0.984375\n",
      "Train loss and acc of batch 51: 49.1217041015625, 0.96875\n",
      "Train loss and acc of batch 52: 49.02860641479492, 0.953125\n",
      "Train loss and acc of batch 53: 47.772762298583984, 1.0\n",
      "Train loss and acc of batch 54: 47.98950958251953, 0.984375\n",
      "Train loss and acc of batch 55: 47.772743225097656, 1.0\n",
      "Train loss and acc of batch 56: 47.77273178100586, 1.0\n",
      "Train loss and acc of batch 57: 48.368431091308594, 0.984375\n",
      "Train loss and acc of batch 58: 47.7727165222168, 1.0\n",
      "Train loss and acc of batch 59: 47.77271270751953, 1.0\n",
      "Train loss and acc of batch 60: 47.77269744873047, 1.0\n",
      "Train loss and acc of batch 61: 47.77268981933594, 1.0\n",
      "Train loss and acc of batch 62: 47.772682189941406, 1.0\n",
      "Train loss and acc of batch 63: 48.964073181152344, 0.96875\n",
      "Train loss and acc of batch 64: 47.98942565917969, 0.984375\n",
      "Train loss and acc of batch 65: 47.77265548706055, 1.0\n",
      "Train loss and acc of batch 66: 47.77264404296875, 1.0\n",
      "Train loss and acc of batch 67: 48.58510208129883, 0.96875\n",
      "Train loss and acc of batch 68: 48.368324279785156, 0.984375\n",
      "Train loss and acc of batch 69: 47.9893798828125, 0.984375\n",
      "Train loss and acc of batch 70: 47.77260971069336, 1.0\n",
      "Training accuracy and loss of epoch #452: 0.9897, 48.0938\n",
      "Saved model by train loss 48.09380367440237\n",
      "Train loss and acc of batch 0: 47.77260208129883, 1.0\n",
      "Train loss and acc of batch 1: 47.77259063720703, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 2: 47.7725830078125, 1.0\n",
      "Train loss and acc of batch 3: 47.989341735839844, 0.984375\n",
      "Train loss and acc of batch 4: 47.77256774902344, 1.0\n",
      "Train loss and acc of batch 5: 49.121482849121094, 0.96875\n",
      "Train loss and acc of batch 6: 48.27516174316406, 0.96875\n",
      "Train loss and acc of batch 7: 47.77254104614258, 1.0\n",
      "Train loss and acc of batch 8: 48.36823272705078, 0.984375\n",
      "Train loss and acc of batch 9: 48.058372497558594, 0.984375\n",
      "Train loss and acc of batch 10: 47.77251052856445, 1.0\n",
      "Train loss and acc of batch 11: 47.772499084472656, 1.0\n",
      "Train loss and acc of batch 12: 48.52571487426758, 0.984375\n",
      "Train loss and acc of batch 13: 47.98925018310547, 0.984375\n",
      "Train loss and acc of batch 14: 47.98924255371094, 0.984375\n",
      "Train loss and acc of batch 15: 48.36817169189453, 0.984375\n",
      "Train loss and acc of batch 16: 48.3681640625, 0.984375\n",
      "Train loss and acc of batch 17: 48.52567672729492, 0.984375\n",
      "Train loss and acc of batch 18: 48.653995513916016, 0.96875\n",
      "Train loss and acc of batch 19: 47.77243423461914, 1.0\n",
      "Train loss and acc of batch 20: 47.77241897583008, 1.0\n",
      "Train loss and acc of batch 21: 48.36811828613281, 0.984375\n",
      "Train loss and acc of batch 22: 48.36810302734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.77239990234375, 1.0\n",
      "Train loss and acc of batch 24: 48.36808776855469, 0.984375\n",
      "Train loss and acc of batch 25: 47.77237319946289, 1.0\n",
      "Train loss and acc of batch 26: 47.772369384765625, 1.0\n",
      "Train loss and acc of batch 27: 47.772361755371094, 1.0\n",
      "Train loss and acc of batch 28: 47.7723503112793, 1.0\n",
      "Train loss and acc of batch 29: 48.3680419921875, 0.984375\n",
      "Train loss and acc of batch 30: 47.772335052490234, 1.0\n",
      "Train loss and acc of batch 31: 47.98908996582031, 0.984375\n",
      "Train loss and acc of batch 32: 47.772315979003906, 1.0\n",
      "Train loss and acc of batch 33: 47.772300720214844, 1.0\n",
      "Train loss and acc of batch 34: 48.36799621582031, 0.984375\n",
      "Train loss and acc of batch 35: 48.2058219909668, 0.96875\n",
      "Train loss and acc of batch 36: 47.772281646728516, 1.0\n",
      "Train loss and acc of batch 37: 48.52549743652344, 0.984375\n",
      "Train loss and acc of batch 38: 49.121185302734375, 0.96875\n",
      "Train loss and acc of batch 39: 47.989013671875, 0.984375\n",
      "Train loss and acc of batch 40: 47.772247314453125, 1.0\n",
      "Train loss and acc of batch 41: 49.12116241455078, 0.96875\n",
      "Train loss and acc of batch 42: 47.7722282409668, 1.0\n",
      "Train loss and acc of batch 43: 48.367919921875, 0.984375\n",
      "Train loss and acc of batch 44: 47.772212982177734, 1.0\n",
      "Train loss and acc of batch 45: 48.36790466308594, 0.984375\n",
      "Train loss and acc of batch 46: 48.05804443359375, 0.984375\n",
      "Train loss and acc of batch 47: 47.77218246459961, 1.0\n",
      "Train loss and acc of batch 48: 47.77217483520508, 1.0\n",
      "Train loss and acc of batch 49: 47.77216720581055, 1.0\n",
      "Train loss and acc of batch 50: 48.36785888671875, 0.984375\n",
      "Train loss and acc of batch 51: 49.121070861816406, 0.96875\n",
      "Train loss and acc of batch 52: 49.027984619140625, 0.953125\n",
      "Train loss and acc of batch 53: 47.77212905883789, 1.0\n",
      "Train loss and acc of batch 54: 47.9888916015625, 0.984375\n",
      "Train loss and acc of batch 55: 47.77210998535156, 1.0\n",
      "Train loss and acc of batch 56: 47.77210235595703, 1.0\n",
      "Train loss and acc of batch 57: 48.3677978515625, 0.984375\n",
      "Train loss and acc of batch 58: 47.7720832824707, 1.0\n",
      "Train loss and acc of batch 59: 47.77207565307617, 1.0\n",
      "Train loss and acc of batch 60: 47.772071838378906, 1.0\n",
      "Train loss and acc of batch 61: 47.772056579589844, 1.0\n",
      "Train loss and acc of batch 62: 47.77204513549805, 1.0\n",
      "Train loss and acc of batch 63: 48.963443756103516, 0.96875\n",
      "Train loss and acc of batch 64: 47.988800048828125, 0.984375\n",
      "Train loss and acc of batch 65: 47.77202606201172, 1.0\n",
      "Train loss and acc of batch 66: 47.77202224731445, 1.0\n",
      "Train loss and acc of batch 67: 48.584468841552734, 0.96875\n",
      "Train loss and acc of batch 68: 48.367698669433594, 0.984375\n",
      "Train loss and acc of batch 69: 47.98875427246094, 0.984375\n",
      "Train loss and acc of batch 70: 47.771976470947266, 1.0\n",
      "Training accuracy and loss of epoch #453: 0.9897, 48.0932\n",
      "Saved model by train loss 48.09317338970345\n",
      "Train loss and acc of batch 0: 47.771968841552734, 1.0\n",
      "Train loss and acc of batch 1: 47.7719612121582, 1.0\n",
      "Train loss and acc of batch 2: 47.77195358276367, 1.0\n",
      "Train loss and acc of batch 3: 47.98870849609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.771934509277344, 1.0\n",
      "Train loss and acc of batch 5: 49.120849609375, 0.96875\n",
      "Train loss and acc of batch 6: 48.2745361328125, 0.96875\n",
      "Train loss and acc of batch 7: 47.77190399169922, 1.0\n",
      "Train loss and acc of batch 8: 48.36759948730469, 0.984375\n",
      "Train loss and acc of batch 9: 48.0577392578125, 0.984375\n",
      "Train loss and acc of batch 10: 47.77188491821289, 1.0\n",
      "Train loss and acc of batch 11: 47.77187728881836, 1.0\n",
      "Train loss and acc of batch 12: 48.52508544921875, 0.984375\n",
      "Train loss and acc of batch 13: 47.988616943359375, 0.984375\n",
      "Train loss and acc of batch 14: 47.988609313964844, 0.984375\n",
      "Train loss and acc of batch 15: 48.36753845214844, 0.984375\n",
      "Train loss and acc of batch 16: 48.367530822753906, 0.984375\n",
      "Train loss and acc of batch 17: 48.52504348754883, 0.984375\n",
      "Train loss and acc of batch 18: 48.65336227416992, 0.96875\n",
      "Train loss and acc of batch 19: 47.77180099487305, 1.0\n",
      "Train loss and acc of batch 20: 47.771793365478516, 1.0\n",
      "Train loss and acc of batch 21: 48.36748504638672, 0.984375\n",
      "Train loss and acc of batch 22: 48.36747741699219, 0.984375\n",
      "Train loss and acc of batch 23: 47.77177047729492, 1.0\n",
      "Train loss and acc of batch 24: 48.367454528808594, 0.984375\n",
      "Train loss and acc of batch 25: 47.77174758911133, 1.0\n",
      "Train loss and acc of batch 26: 47.77174377441406, 1.0\n",
      "Train loss and acc of batch 27: 47.771728515625, 1.0\n",
      "Train loss and acc of batch 28: 47.771724700927734, 1.0\n",
      "Train loss and acc of batch 29: 48.367408752441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.771705627441406, 1.0\n",
      "Train loss and acc of batch 31: 47.98845672607422, 0.984375\n",
      "Train loss and acc of batch 32: 47.77168655395508, 1.0\n",
      "Train loss and acc of batch 33: 47.77167510986328, 1.0\n",
      "Train loss and acc of batch 34: 48.36737060546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.20518493652344, 0.96875\n",
      "Train loss and acc of batch 36: 47.77165222167969, 1.0\n",
      "Train loss and acc of batch 37: 48.524864196777344, 0.984375\n",
      "Train loss and acc of batch 38: 49.12055206298828, 0.96875\n",
      "Train loss and acc of batch 39: 47.98838806152344, 0.984375\n",
      "Train loss and acc of batch 40: 47.77162170410156, 1.0\n",
      "Train loss and acc of batch 41: 49.12053298950195, 0.96875\n",
      "Train loss and acc of batch 42: 47.7715950012207, 1.0\n",
      "Train loss and acc of batch 43: 48.367286682128906, 0.984375\n",
      "Train loss and acc of batch 44: 47.77157974243164, 1.0\n",
      "Train loss and acc of batch 45: 48.367271423339844, 0.984375\n",
      "Train loss and acc of batch 46: 48.057411193847656, 0.984375\n",
      "Train loss and acc of batch 47: 47.77155685424805, 1.0\n",
      "Train loss and acc of batch 48: 47.77154541015625, 1.0\n",
      "Train loss and acc of batch 49: 47.77153396606445, 1.0\n",
      "Train loss and acc of batch 50: 48.367225646972656, 0.984375\n",
      "Train loss and acc of batch 51: 49.120445251464844, 0.96875\n",
      "Train loss and acc of batch 52: 49.02734375, 0.953125\n",
      "Train loss and acc of batch 53: 47.77149963378906, 1.0\n",
      "Train loss and acc of batch 54: 47.988258361816406, 0.984375\n",
      "Train loss and acc of batch 55: 47.771484375, 1.0\n",
      "Train loss and acc of batch 56: 47.7714729309082, 1.0\n",
      "Train loss and acc of batch 57: 48.367164611816406, 0.984375\n",
      "Train loss and acc of batch 58: 47.771453857421875, 1.0\n",
      "Train loss and acc of batch 59: 47.77145004272461, 1.0\n",
      "Train loss and acc of batch 60: 47.77143478393555, 1.0\n",
      "Train loss and acc of batch 61: 47.77143096923828, 1.0\n",
      "Train loss and acc of batch 62: 47.771419525146484, 1.0\n",
      "Train loss and acc of batch 63: 48.96281433105469, 0.96875\n",
      "Train loss and acc of batch 64: 47.98816680908203, 0.984375\n",
      "Train loss and acc of batch 65: 47.77139663696289, 1.0\n",
      "Train loss and acc of batch 66: 47.77138137817383, 1.0\n",
      "Train loss and acc of batch 67: 48.583839416503906, 0.96875\n",
      "Train loss and acc of batch 68: 48.36707305908203, 0.984375\n",
      "Train loss and acc of batch 69: 47.988121032714844, 0.984375\n",
      "Train loss and acc of batch 70: 47.7713508605957, 1.0\n",
      "Training accuracy and loss of epoch #454: 0.9897, 48.0925\n",
      "Saved model by train loss 48.09254278263575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.771339416503906, 1.0\n",
      "Train loss and acc of batch 1: 47.771331787109375, 1.0\n",
      "Train loss and acc of batch 2: 47.771324157714844, 1.0\n",
      "Train loss and acc of batch 3: 47.988075256347656, 0.984375\n",
      "Train loss and acc of batch 4: 47.771305084228516, 1.0\n",
      "Train loss and acc of batch 5: 49.12022399902344, 0.96875\n",
      "Train loss and acc of batch 6: 48.273902893066406, 0.96875\n",
      "Train loss and acc of batch 7: 47.771278381347656, 1.0\n",
      "Train loss and acc of batch 8: 48.366973876953125, 0.984375\n",
      "Train loss and acc of batch 9: 48.05711364746094, 0.984375\n",
      "Train loss and acc of batch 10: 47.77124786376953, 1.0\n",
      "Train loss and acc of batch 11: 47.771244049072266, 1.0\n",
      "Train loss and acc of batch 12: 48.52445602416992, 0.984375\n",
      "Train loss and acc of batch 13: 47.98799133300781, 0.984375\n",
      "Train loss and acc of batch 14: 47.98798370361328, 0.984375\n",
      "Train loss and acc of batch 15: 48.366905212402344, 0.984375\n",
      "Train loss and acc of batch 16: 48.36689758300781, 0.984375\n",
      "Train loss and acc of batch 17: 48.5244140625, 0.984375\n",
      "Train loss and acc of batch 18: 48.65272903442383, 0.96875\n",
      "Train loss and acc of batch 19: 47.77117156982422, 1.0\n",
      "Train loss and acc of batch 20: 47.771156311035156, 1.0\n",
      "Train loss and acc of batch 21: 48.366851806640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.366844177246094, 0.984375\n",
      "Train loss and acc of batch 23: 47.7711296081543, 1.0\n",
      "Train loss and acc of batch 24: 48.3668212890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.7711181640625, 1.0\n",
      "Train loss and acc of batch 26: 47.7711067199707, 1.0\n",
      "Train loss and acc of batch 27: 47.77109909057617, 1.0\n",
      "Train loss and acc of batch 28: 47.771087646484375, 1.0\n",
      "Train loss and acc of batch 29: 48.36677551269531, 0.984375\n",
      "Train loss and acc of batch 30: 47.77107238769531, 1.0\n",
      "Train loss and acc of batch 31: 47.987831115722656, 0.984375\n",
      "Train loss and acc of batch 32: 47.771053314208984, 1.0\n",
      "Train loss and acc of batch 33: 47.77104568481445, 1.0\n",
      "Train loss and acc of batch 34: 48.366737365722656, 0.984375\n",
      "Train loss and acc of batch 35: 48.204559326171875, 0.96875\n",
      "Train loss and acc of batch 36: 47.771018981933594, 1.0\n",
      "Train loss and acc of batch 37: 48.524227142333984, 0.984375\n",
      "Train loss and acc of batch 38: 49.11991882324219, 0.96875\n",
      "Train loss and acc of batch 39: 47.987762451171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.7709846496582, 1.0\n",
      "Train loss and acc of batch 41: 49.11989974975586, 0.96875\n",
      "Train loss and acc of batch 42: 47.77096939086914, 1.0\n",
      "Train loss and acc of batch 43: 48.36665344238281, 0.984375\n",
      "Train loss and acc of batch 44: 47.77094650268555, 1.0\n",
      "Train loss and acc of batch 45: 48.36663818359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.05677795410156, 0.984375\n",
      "Train loss and acc of batch 47: 47.77091979980469, 1.0\n",
      "Train loss and acc of batch 48: 47.77091598510742, 1.0\n",
      "Train loss and acc of batch 49: 47.770904541015625, 1.0\n",
      "Train loss and acc of batch 50: 48.366600036621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.11980438232422, 0.96875\n",
      "Train loss and acc of batch 52: 49.02671813964844, 0.953125\n",
      "Train loss and acc of batch 53: 47.77086639404297, 1.0\n",
      "Train loss and acc of batch 54: 47.98762512207031, 0.984375\n",
      "Train loss and acc of batch 55: 47.77084732055664, 1.0\n",
      "Train loss and acc of batch 56: 47.77083969116211, 1.0\n",
      "Train loss and acc of batch 57: 48.36653137207031, 0.984375\n",
      "Train loss and acc of batch 58: 47.77082443237305, 1.0\n",
      "Train loss and acc of batch 59: 47.77081298828125, 1.0\n",
      "Train loss and acc of batch 60: 47.77080154418945, 1.0\n",
      "Train loss and acc of batch 61: 47.77079391479492, 1.0\n",
      "Train loss and acc of batch 62: 47.770782470703125, 1.0\n",
      "Train loss and acc of batch 63: 48.962181091308594, 0.96875\n",
      "Train loss and acc of batch 64: 47.98753356933594, 0.984375\n",
      "Train loss and acc of batch 65: 47.7707633972168, 1.0\n",
      "Train loss and acc of batch 66: 47.770751953125, 1.0\n",
      "Train loss and acc of batch 67: 48.58320999145508, 0.96875\n",
      "Train loss and acc of batch 68: 48.366432189941406, 0.984375\n",
      "Train loss and acc of batch 69: 47.98748779296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.77071762084961, 1.0\n",
      "Training accuracy and loss of epoch #455: 0.9897, 48.0919\n",
      "Saved model by train loss 48.09191072490853\n",
      "Train loss and acc of batch 0: 47.77070617675781, 1.0\n",
      "Train loss and acc of batch 1: 47.770694732666016, 1.0\n",
      "Train loss and acc of batch 2: 47.77069091796875, 1.0\n",
      "Train loss and acc of batch 3: 47.98744201660156, 0.984375\n",
      "Train loss and acc of batch 4: 47.77067565917969, 1.0\n",
      "Train loss and acc of batch 5: 49.119590759277344, 0.96875\n",
      "Train loss and acc of batch 6: 48.27327346801758, 0.96875\n",
      "Train loss and acc of batch 7: 47.77064514160156, 1.0\n",
      "Train loss and acc of batch 8: 48.3663330078125, 0.984375\n",
      "Train loss and acc of batch 9: 48.056480407714844, 0.984375\n",
      "Train loss and acc of batch 10: 47.77062225341797, 1.0\n",
      "Train loss and acc of batch 11: 47.770606994628906, 1.0\n",
      "Train loss and acc of batch 12: 48.523826599121094, 0.984375\n",
      "Train loss and acc of batch 13: 47.98735809326172, 0.984375\n",
      "Train loss and acc of batch 14: 47.987342834472656, 0.984375\n",
      "Train loss and acc of batch 15: 48.36627960205078, 0.984375\n",
      "Train loss and acc of batch 16: 48.36627197265625, 0.984375\n",
      "Train loss and acc of batch 17: 48.52377700805664, 0.984375\n",
      "Train loss and acc of batch 18: 48.652099609375, 0.96875\n",
      "Train loss and acc of batch 19: 47.770538330078125, 1.0\n",
      "Train loss and acc of batch 20: 47.770530700683594, 1.0\n",
      "Train loss and acc of batch 21: 48.36621856689453, 0.984375\n",
      "Train loss and acc of batch 22: 48.36621856689453, 0.984375\n",
      "Train loss and acc of batch 23: 47.77050018310547, 1.0\n",
      "Train loss and acc of batch 24: 48.36619567871094, 0.984375\n",
      "Train loss and acc of batch 25: 47.770484924316406, 1.0\n",
      "Train loss and acc of batch 26: 47.77047348022461, 1.0\n",
      "Train loss and acc of batch 27: 47.77046585083008, 1.0\n",
      "Train loss and acc of batch 28: 47.77045822143555, 1.0\n",
      "Train loss and acc of batch 29: 48.36615753173828, 0.984375\n",
      "Train loss and acc of batch 30: 47.77043914794922, 1.0\n",
      "Train loss and acc of batch 31: 47.98719024658203, 0.984375\n",
      "Train loss and acc of batch 32: 47.770423889160156, 1.0\n",
      "Train loss and acc of batch 33: 47.770416259765625, 1.0\n",
      "Train loss and acc of batch 34: 48.36610412597656, 0.984375\n",
      "Train loss and acc of batch 35: 48.20392608642578, 0.96875\n",
      "Train loss and acc of batch 36: 47.770389556884766, 1.0\n",
      "Train loss and acc of batch 37: 48.52360534667969, 0.984375\n",
      "Train loss and acc of batch 38: 49.119293212890625, 0.96875\n",
      "Train loss and acc of batch 39: 47.98712158203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.770355224609375, 1.0\n",
      "Train loss and acc of batch 41: 49.11927032470703, 0.96875\n",
      "Train loss and acc of batch 42: 47.77033233642578, 1.0\n",
      "Train loss and acc of batch 43: 48.36602783203125, 0.984375\n",
      "Train loss and acc of batch 44: 47.770320892333984, 1.0\n",
      "Train loss and acc of batch 45: 48.366004943847656, 0.984375\n",
      "Train loss and acc of batch 46: 48.05614471435547, 0.984375\n",
      "Train loss and acc of batch 47: 47.77029037475586, 1.0\n",
      "Train loss and acc of batch 48: 47.77027893066406, 1.0\n",
      "Train loss and acc of batch 49: 47.7702751159668, 1.0\n",
      "Train loss and acc of batch 50: 48.365966796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.119178771972656, 0.96875\n",
      "Train loss and acc of batch 52: 49.026084899902344, 0.953125\n",
      "Train loss and acc of batch 53: 47.770233154296875, 1.0\n",
      "Train loss and acc of batch 54: 47.98699188232422, 0.984375\n",
      "Train loss and acc of batch 55: 47.77022171020508, 1.0\n",
      "Train loss and acc of batch 56: 47.77021408081055, 1.0\n",
      "Train loss and acc of batch 57: 48.36590576171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.770198822021484, 1.0\n",
      "Train loss and acc of batch 59: 47.77018356323242, 1.0\n",
      "Train loss and acc of batch 60: 47.770172119140625, 1.0\n",
      "Train loss and acc of batch 61: 47.77016830444336, 1.0\n",
      "Train loss and acc of batch 62: 47.77015686035156, 1.0\n",
      "Train loss and acc of batch 63: 48.9615478515625, 0.96875\n",
      "Train loss and acc of batch 64: 47.986900329589844, 0.984375\n",
      "Train loss and acc of batch 65: 47.7701301574707, 1.0\n",
      "Train loss and acc of batch 66: 47.77012634277344, 1.0\n",
      "Train loss and acc of batch 67: 48.58258056640625, 0.96875\n",
      "Train loss and acc of batch 68: 48.365806579589844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 47.98686218261719, 0.984375\n",
      "Train loss and acc of batch 70: 47.77008819580078, 1.0\n",
      "Training accuracy and loss of epoch #456: 0.9897, 48.0913\n",
      "Saved model by train loss 48.09128011784083\n",
      "Train loss and acc of batch 0: 47.770076751708984, 1.0\n",
      "Train loss and acc of batch 1: 47.77006912231445, 1.0\n",
      "Train loss and acc of batch 2: 47.77006149291992, 1.0\n",
      "Train loss and acc of batch 3: 47.98681640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.77003860473633, 1.0\n",
      "Train loss and acc of batch 5: 49.11895751953125, 0.96875\n",
      "Train loss and acc of batch 6: 48.27264404296875, 0.96875\n",
      "Train loss and acc of batch 7: 47.770015716552734, 1.0\n",
      "Train loss and acc of batch 8: 48.36570739746094, 0.984375\n",
      "Train loss and acc of batch 9: 48.05585479736328, 0.984375\n",
      "Train loss and acc of batch 10: 47.769989013671875, 1.0\n",
      "Train loss and acc of batch 11: 47.769981384277344, 1.0\n",
      "Train loss and acc of batch 12: 48.523189544677734, 0.984375\n",
      "Train loss and acc of batch 13: 47.986724853515625, 0.984375\n",
      "Train loss and acc of batch 14: 47.986717224121094, 0.984375\n",
      "Train loss and acc of batch 15: 48.36564636230469, 0.984375\n",
      "Train loss and acc of batch 16: 48.365638732910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.52315139770508, 0.984375\n",
      "Train loss and acc of batch 18: 48.65147399902344, 0.96875\n",
      "Train loss and acc of batch 19: 47.7699089050293, 1.0\n",
      "Train loss and acc of batch 20: 47.769901275634766, 1.0\n",
      "Train loss and acc of batch 21: 48.36559295654297, 0.984375\n",
      "Train loss and acc of batch 22: 48.36558532714844, 0.984375\n",
      "Train loss and acc of batch 23: 47.76987838745117, 1.0\n",
      "Train loss and acc of batch 24: 48.365562438964844, 0.984375\n",
      "Train loss and acc of batch 25: 47.769859313964844, 1.0\n",
      "Train loss and acc of batch 26: 47.76984405517578, 1.0\n",
      "Train loss and acc of batch 27: 47.76983642578125, 1.0\n",
      "Train loss and acc of batch 28: 47.76982879638672, 1.0\n",
      "Train loss and acc of batch 29: 48.365516662597656, 0.984375\n",
      "Train loss and acc of batch 30: 47.76980972290039, 1.0\n",
      "Train loss and acc of batch 31: 47.986572265625, 0.984375\n",
      "Train loss and acc of batch 32: 47.76979064941406, 1.0\n",
      "Train loss and acc of batch 33: 47.76978302001953, 1.0\n",
      "Train loss and acc of batch 34: 48.365478515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.20329284667969, 0.96875\n",
      "Train loss and acc of batch 36: 47.76975631713867, 1.0\n",
      "Train loss and acc of batch 37: 48.52297592163086, 0.984375\n",
      "Train loss and acc of batch 38: 49.11866760253906, 0.96875\n",
      "Train loss and acc of batch 39: 47.98649597167969, 0.984375\n",
      "Train loss and acc of batch 40: 47.76972198486328, 1.0\n",
      "Train loss and acc of batch 41: 49.11863708496094, 0.96875\n",
      "Train loss and acc of batch 42: 47.76970672607422, 1.0\n",
      "Train loss and acc of batch 43: 48.36540222167969, 0.984375\n",
      "Train loss and acc of batch 44: 47.76968765258789, 1.0\n",
      "Train loss and acc of batch 45: 48.365379333496094, 0.984375\n",
      "Train loss and acc of batch 46: 48.05552673339844, 0.984375\n",
      "Train loss and acc of batch 47: 47.769657135009766, 1.0\n",
      "Train loss and acc of batch 48: 47.7696533203125, 1.0\n",
      "Train loss and acc of batch 49: 47.76963806152344, 1.0\n",
      "Train loss and acc of batch 50: 48.365333557128906, 0.984375\n",
      "Train loss and acc of batch 51: 49.118553161621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.025455474853516, 0.953125\n",
      "Train loss and acc of batch 53: 47.76960754394531, 1.0\n",
      "Train loss and acc of batch 54: 47.986366271972656, 0.984375\n",
      "Train loss and acc of batch 55: 47.76958465576172, 1.0\n",
      "Train loss and acc of batch 56: 47.76958084106445, 1.0\n",
      "Train loss and acc of batch 57: 48.365272521972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.769561767578125, 1.0\n",
      "Train loss and acc of batch 59: 47.769554138183594, 1.0\n",
      "Train loss and acc of batch 60: 47.7695426940918, 1.0\n",
      "Train loss and acc of batch 61: 47.769535064697266, 1.0\n",
      "Train loss and acc of batch 62: 47.769527435302734, 1.0\n",
      "Train loss and acc of batch 63: 48.96091842651367, 0.96875\n",
      "Train loss and acc of batch 64: 47.98627471923828, 0.984375\n",
      "Train loss and acc of batch 65: 47.76950454711914, 1.0\n",
      "Train loss and acc of batch 66: 47.769493103027344, 1.0\n",
      "Train loss and acc of batch 67: 48.581947326660156, 0.96875\n",
      "Train loss and acc of batch 68: 48.36518096923828, 0.984375\n",
      "Train loss and acc of batch 69: 47.986228942871094, 0.984375\n",
      "Train loss and acc of batch 70: 47.76945495605469, 1.0\n",
      "Training accuracy and loss of epoch #457: 0.9897, 48.0907\n",
      "Saved model by train loss 48.090650424151356\n",
      "Train loss and acc of batch 0: 47.769447326660156, 1.0\n",
      "Train loss and acc of batch 1: 47.76943588256836, 1.0\n",
      "Train loss and acc of batch 2: 47.76942825317383, 1.0\n",
      "Train loss and acc of batch 3: 47.986183166503906, 0.984375\n",
      "Train loss and acc of batch 4: 47.769412994384766, 1.0\n",
      "Train loss and acc of batch 5: 49.118324279785156, 0.96875\n",
      "Train loss and acc of batch 6: 48.27200698852539, 0.96875\n",
      "Train loss and acc of batch 7: 47.76938247680664, 1.0\n",
      "Train loss and acc of batch 8: 48.365081787109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.05522155761719, 0.984375\n",
      "Train loss and acc of batch 10: 47.76935958862305, 1.0\n",
      "Train loss and acc of batch 11: 47.769351959228516, 1.0\n",
      "Train loss and acc of batch 12: 48.52256774902344, 0.984375\n",
      "Train loss and acc of batch 13: 47.98609924316406, 0.984375\n",
      "Train loss and acc of batch 14: 47.98609161376953, 0.984375\n",
      "Train loss and acc of batch 15: 48.365013122558594, 0.984375\n",
      "Train loss and acc of batch 16: 48.36500549316406, 0.984375\n",
      "Train loss and acc of batch 17: 48.52251434326172, 0.984375\n",
      "Train loss and acc of batch 18: 48.65084457397461, 0.96875\n",
      "Train loss and acc of batch 19: 47.76927947998047, 1.0\n",
      "Train loss and acc of batch 20: 47.76926803588867, 1.0\n",
      "Train loss and acc of batch 21: 48.364959716796875, 0.984375\n",
      "Train loss and acc of batch 22: 48.364959716796875, 0.984375\n",
      "Train loss and acc of batch 23: 47.76924133300781, 1.0\n",
      "Train loss and acc of batch 24: 48.36493682861328, 0.984375\n",
      "Train loss and acc of batch 25: 47.76922607421875, 1.0\n",
      "Train loss and acc of batch 26: 47.76921463012695, 1.0\n",
      "Train loss and acc of batch 27: 47.76920700073242, 1.0\n",
      "Train loss and acc of batch 28: 47.76919937133789, 1.0\n",
      "Train loss and acc of batch 29: 48.364891052246094, 0.984375\n",
      "Train loss and acc of batch 30: 47.76918411254883, 1.0\n",
      "Train loss and acc of batch 31: 47.985931396484375, 0.984375\n",
      "Train loss and acc of batch 32: 47.7691650390625, 1.0\n",
      "Train loss and acc of batch 33: 47.7691535949707, 1.0\n",
      "Train loss and acc of batch 34: 48.364845275878906, 0.984375\n",
      "Train loss and acc of batch 35: 48.20266342163086, 0.96875\n",
      "Train loss and acc of batch 36: 47.76913070678711, 1.0\n",
      "Train loss and acc of batch 37: 48.522342681884766, 0.984375\n",
      "Train loss and acc of batch 38: 49.11803436279297, 0.96875\n",
      "Train loss and acc of batch 39: 47.985870361328125, 0.984375\n",
      "Train loss and acc of batch 40: 47.76909255981445, 1.0\n",
      "Train loss and acc of batch 41: 49.118011474609375, 0.96875\n",
      "Train loss and acc of batch 42: 47.769073486328125, 1.0\n",
      "Train loss and acc of batch 43: 48.36476135253906, 0.984375\n",
      "Train loss and acc of batch 44: 47.76905822753906, 1.0\n",
      "Train loss and acc of batch 45: 48.36475372314453, 0.984375\n",
      "Train loss and acc of batch 46: 48.054893493652344, 0.984375\n",
      "Train loss and acc of batch 47: 47.76903533935547, 1.0\n",
      "Train loss and acc of batch 48: 47.76901626586914, 1.0\n",
      "Train loss and acc of batch 49: 47.76901626586914, 1.0\n",
      "Train loss and acc of batch 50: 48.364707946777344, 0.984375\n",
      "Train loss and acc of batch 51: 49.117919921875, 0.96875\n",
      "Train loss and acc of batch 52: 49.02482986450195, 0.953125\n",
      "Train loss and acc of batch 53: 47.768978118896484, 1.0\n",
      "Train loss and acc of batch 54: 47.98573303222656, 0.984375\n",
      "Train loss and acc of batch 55: 47.76896286010742, 1.0\n",
      "Train loss and acc of batch 56: 47.768959045410156, 1.0\n",
      "Train loss and acc of batch 57: 48.36463928222656, 0.984375\n",
      "Train loss and acc of batch 58: 47.7689323425293, 1.0\n",
      "Train loss and acc of batch 59: 47.76892852783203, 1.0\n",
      "Train loss and acc of batch 60: 47.76891326904297, 1.0\n",
      "Train loss and acc of batch 61: 47.7689094543457, 1.0\n",
      "Train loss and acc of batch 62: 47.76889419555664, 1.0\n",
      "Train loss and acc of batch 63: 48.96029281616211, 0.96875\n",
      "Train loss and acc of batch 64: 47.98564910888672, 0.984375\n",
      "Train loss and acc of batch 65: 47.76886749267578, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 66: 47.768863677978516, 1.0\n",
      "Train loss and acc of batch 67: 48.581321716308594, 0.96875\n",
      "Train loss and acc of batch 68: 48.364540100097656, 0.984375\n",
      "Train loss and acc of batch 69: 47.98560333251953, 0.984375\n",
      "Train loss and acc of batch 70: 47.76882553100586, 1.0\n",
      "Training accuracy and loss of epoch #458: 0.9897, 48.0900\n",
      "Saved model by train loss 48.090020569277485\n",
      "Train loss and acc of batch 0: 47.76881408691406, 1.0\n",
      "Train loss and acc of batch 1: 47.76880645751953, 1.0\n",
      "Train loss and acc of batch 2: 47.768798828125, 1.0\n",
      "Train loss and acc of batch 3: 47.985557556152344, 0.984375\n",
      "Train loss and acc of batch 4: 47.7687873840332, 1.0\n",
      "Train loss and acc of batch 5: 49.117698669433594, 0.96875\n",
      "Train loss and acc of batch 6: 48.27138137817383, 0.96875\n",
      "Train loss and acc of batch 7: 47.76875686645508, 1.0\n",
      "Train loss and acc of batch 8: 48.36444854736328, 0.984375\n",
      "Train loss and acc of batch 9: 48.054588317871094, 0.984375\n",
      "Train loss and acc of batch 10: 47.768733978271484, 1.0\n",
      "Train loss and acc of batch 11: 47.76872253417969, 1.0\n",
      "Train loss and acc of batch 12: 48.521934509277344, 0.984375\n",
      "Train loss and acc of batch 13: 47.9854736328125, 0.984375\n",
      "Train loss and acc of batch 14: 47.98545837402344, 0.984375\n",
      "Train loss and acc of batch 15: 48.36438751220703, 0.984375\n",
      "Train loss and acc of batch 16: 48.3643798828125, 0.984375\n",
      "Train loss and acc of batch 17: 48.521888732910156, 0.984375\n",
      "Train loss and acc of batch 18: 48.650211334228516, 0.96875\n",
      "Train loss and acc of batch 19: 47.76865005493164, 1.0\n",
      "Train loss and acc of batch 20: 47.768638610839844, 1.0\n",
      "Train loss and acc of batch 21: 48.36433410644531, 0.984375\n",
      "Train loss and acc of batch 22: 48.36432647705078, 0.984375\n",
      "Train loss and acc of batch 23: 47.76860809326172, 1.0\n",
      "Train loss and acc of batch 24: 48.36430358886719, 0.984375\n",
      "Train loss and acc of batch 25: 47.76859664916992, 1.0\n",
      "Train loss and acc of batch 26: 47.768585205078125, 1.0\n",
      "Train loss and acc of batch 27: 47.76858139038086, 1.0\n",
      "Train loss and acc of batch 28: 47.7685661315918, 1.0\n",
      "Train loss and acc of batch 29: 48.3642578125, 0.984375\n",
      "Train loss and acc of batch 30: 47.7685546875, 1.0\n",
      "Train loss and acc of batch 31: 47.98530578613281, 0.984375\n",
      "Train loss and acc of batch 32: 47.76853561401367, 1.0\n",
      "Train loss and acc of batch 33: 47.76852798461914, 1.0\n",
      "Train loss and acc of batch 34: 48.36421203613281, 0.984375\n",
      "Train loss and acc of batch 35: 48.20204162597656, 0.96875\n",
      "Train loss and acc of batch 36: 47.76850128173828, 1.0\n",
      "Train loss and acc of batch 37: 48.52170944213867, 0.984375\n",
      "Train loss and acc of batch 38: 49.117408752441406, 0.96875\n",
      "Train loss and acc of batch 39: 47.9852294921875, 0.984375\n",
      "Train loss and acc of batch 40: 47.768463134765625, 1.0\n",
      "Train loss and acc of batch 41: 49.11738586425781, 0.96875\n",
      "Train loss and acc of batch 42: 47.7684440612793, 1.0\n",
      "Train loss and acc of batch 43: 48.3641357421875, 0.984375\n",
      "Train loss and acc of batch 44: 47.768428802490234, 1.0\n",
      "Train loss and acc of batch 45: 48.36412048339844, 0.984375\n",
      "Train loss and acc of batch 46: 48.05426025390625, 0.984375\n",
      "Train loss and acc of batch 47: 47.76839828491211, 1.0\n",
      "Train loss and acc of batch 48: 47.76839065551758, 1.0\n",
      "Train loss and acc of batch 49: 47.76838684082031, 1.0\n",
      "Train loss and acc of batch 50: 48.36407470703125, 0.984375\n",
      "Train loss and acc of batch 51: 49.117286682128906, 0.96875\n",
      "Train loss and acc of batch 52: 49.02419662475586, 0.953125\n",
      "Train loss and acc of batch 53: 47.768348693847656, 1.0\n",
      "Train loss and acc of batch 54: 47.98509979248047, 0.984375\n",
      "Train loss and acc of batch 55: 47.768333435058594, 1.0\n",
      "Train loss and acc of batch 56: 47.76831817626953, 1.0\n",
      "Train loss and acc of batch 57: 48.364013671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.768306732177734, 1.0\n",
      "Train loss and acc of batch 59: 47.76829147338867, 1.0\n",
      "Train loss and acc of batch 60: 47.76828384399414, 1.0\n",
      "Train loss and acc of batch 61: 47.76827621459961, 1.0\n",
      "Train loss and acc of batch 62: 47.76826858520508, 1.0\n",
      "Train loss and acc of batch 63: 48.95966339111328, 0.96875\n",
      "Train loss and acc of batch 64: 47.985015869140625, 0.984375\n",
      "Train loss and acc of batch 65: 47.76824188232422, 1.0\n",
      "Train loss and acc of batch 66: 47.76823425292969, 1.0\n",
      "Train loss and acc of batch 67: 48.5806884765625, 0.96875\n",
      "Train loss and acc of batch 68: 48.363914489746094, 0.984375\n",
      "Train loss and acc of batch 69: 47.98497009277344, 0.984375\n",
      "Train loss and acc of batch 70: 47.768192291259766, 1.0\n",
      "Training accuracy and loss of epoch #459: 0.9897, 48.0894\n",
      "Saved model by train loss 48.08939066067548\n",
      "Train loss and acc of batch 0: 47.7681884765625, 1.0\n",
      "Train loss and acc of batch 1: 47.76818084716797, 1.0\n",
      "Train loss and acc of batch 2: 47.76816940307617, 1.0\n",
      "Train loss and acc of batch 3: 47.98492431640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.76815414428711, 1.0\n",
      "Train loss and acc of batch 5: 49.1170654296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.270751953125, 0.96875\n",
      "Train loss and acc of batch 7: 47.768131256103516, 1.0\n",
      "Train loss and acc of batch 8: 48.36381530761719, 0.984375\n",
      "Train loss and acc of batch 9: 48.05396270751953, 0.984375\n",
      "Train loss and acc of batch 10: 47.768096923828125, 1.0\n",
      "Train loss and acc of batch 11: 47.768089294433594, 1.0\n",
      "Train loss and acc of batch 12: 48.521305084228516, 0.984375\n",
      "Train loss and acc of batch 13: 47.984832763671875, 0.984375\n",
      "Train loss and acc of batch 14: 47.984825134277344, 0.984375\n",
      "Train loss and acc of batch 15: 48.36376190185547, 0.984375\n",
      "Train loss and acc of batch 16: 48.363746643066406, 0.984375\n",
      "Train loss and acc of batch 17: 48.52125930786133, 0.984375\n",
      "Train loss and acc of batch 18: 48.64958190917969, 0.96875\n",
      "Train loss and acc of batch 19: 47.76801681518555, 1.0\n",
      "Train loss and acc of batch 20: 47.76801300048828, 1.0\n",
      "Train loss and acc of batch 21: 48.36370086669922, 0.984375\n",
      "Train loss and acc of batch 22: 48.36369323730469, 0.984375\n",
      "Train loss and acc of batch 23: 47.76798629760742, 1.0\n",
      "Train loss and acc of batch 24: 48.363677978515625, 0.984375\n",
      "Train loss and acc of batch 25: 47.76796340942383, 1.0\n",
      "Train loss and acc of batch 26: 47.76795959472656, 1.0\n",
      "Train loss and acc of batch 27: 47.767948150634766, 1.0\n",
      "Train loss and acc of batch 28: 47.7679443359375, 1.0\n",
      "Train loss and acc of batch 29: 48.36363983154297, 0.984375\n",
      "Train loss and acc of batch 30: 47.76792526245117, 1.0\n",
      "Train loss and acc of batch 31: 47.98468017578125, 0.984375\n",
      "Train loss and acc of batch 32: 47.767906188964844, 1.0\n",
      "Train loss and acc of batch 33: 47.76789093017578, 1.0\n",
      "Train loss and acc of batch 34: 48.36358642578125, 0.984375\n",
      "Train loss and acc of batch 35: 48.2014045715332, 0.96875\n",
      "Train loss and acc of batch 36: 47.76786804199219, 1.0\n",
      "Train loss and acc of batch 37: 48.52108383178711, 0.984375\n",
      "Train loss and acc of batch 38: 49.11677551269531, 0.96875\n",
      "Train loss and acc of batch 39: 47.98460388183594, 0.984375\n",
      "Train loss and acc of batch 40: 47.7678337097168, 1.0\n",
      "Train loss and acc of batch 41: 49.11674880981445, 0.96875\n",
      "Train loss and acc of batch 42: 47.76781463623047, 1.0\n",
      "Train loss and acc of batch 43: 48.36351013183594, 0.984375\n",
      "Train loss and acc of batch 44: 47.767799377441406, 1.0\n",
      "Train loss and acc of batch 45: 48.363487243652344, 0.984375\n",
      "Train loss and acc of batch 46: 48.053627014160156, 0.984375\n",
      "Train loss and acc of batch 47: 47.76776885986328, 1.0\n",
      "Train loss and acc of batch 48: 47.76776123046875, 1.0\n",
      "Train loss and acc of batch 49: 47.767757415771484, 1.0\n",
      "Train loss and acc of batch 50: 48.363441467285156, 0.984375\n",
      "Train loss and acc of batch 51: 49.116661071777344, 0.96875\n",
      "Train loss and acc of batch 52: 49.02356719970703, 0.953125\n",
      "Train loss and acc of batch 53: 47.76771926879883, 1.0\n",
      "Train loss and acc of batch 54: 47.984474182128906, 0.984375\n",
      "Train loss and acc of batch 55: 47.7677001953125, 1.0\n",
      "Train loss and acc of batch 56: 47.76769256591797, 1.0\n",
      "Train loss and acc of batch 57: 48.36338806152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.767677307128906, 1.0\n",
      "Train loss and acc of batch 59: 47.76766586303711, 1.0\n",
      "Train loss and acc of batch 60: 47.76765823364258, 1.0\n",
      "Train loss and acc of batch 61: 47.76764678955078, 1.0\n",
      "Train loss and acc of batch 62: 47.76763916015625, 1.0\n",
      "Train loss and acc of batch 63: 48.95903396606445, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 64: 47.98438262939453, 0.984375\n",
      "Train loss and acc of batch 65: 47.76761245727539, 1.0\n",
      "Train loss and acc of batch 66: 47.767601013183594, 1.0\n",
      "Train loss and acc of batch 67: 48.58006286621094, 0.96875\n",
      "Train loss and acc of batch 68: 48.36328125, 0.984375\n",
      "Train loss and acc of batch 69: 47.984336853027344, 0.984375\n",
      "Train loss and acc of batch 70: 47.7675666809082, 1.0\n",
      "Training accuracy and loss of epoch #460: 0.9897, 48.0888\n",
      "Saved model by train loss 48.088760966986\n",
      "Train loss and acc of batch 0: 47.76756286621094, 1.0\n",
      "Train loss and acc of batch 1: 47.767547607421875, 1.0\n",
      "Train loss and acc of batch 2: 47.76754379272461, 1.0\n",
      "Train loss and acc of batch 3: 47.98429870605469, 0.984375\n",
      "Train loss and acc of batch 4: 47.767520904541016, 1.0\n",
      "Train loss and acc of batch 5: 49.11643981933594, 0.96875\n",
      "Train loss and acc of batch 6: 48.27012634277344, 0.96875\n",
      "Train loss and acc of batch 7: 47.767494201660156, 1.0\n",
      "Train loss and acc of batch 8: 48.363189697265625, 0.984375\n",
      "Train loss and acc of batch 9: 48.05332946777344, 0.984375\n",
      "Train loss and acc of batch 10: 47.76747131347656, 1.0\n",
      "Train loss and acc of batch 11: 47.767459869384766, 1.0\n",
      "Train loss and acc of batch 12: 48.52067184448242, 0.984375\n",
      "Train loss and acc of batch 13: 47.98420715332031, 0.984375\n",
      "Train loss and acc of batch 14: 47.98419952392578, 0.984375\n",
      "Train loss and acc of batch 15: 48.363128662109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.36311340332031, 0.984375\n",
      "Train loss and acc of batch 17: 48.5206298828125, 0.984375\n",
      "Train loss and acc of batch 18: 48.648948669433594, 0.96875\n",
      "Train loss and acc of batch 19: 47.767391204833984, 1.0\n",
      "Train loss and acc of batch 20: 47.76738739013672, 1.0\n",
      "Train loss and acc of batch 21: 48.363075256347656, 0.984375\n",
      "Train loss and acc of batch 22: 48.363067626953125, 0.984375\n",
      "Train loss and acc of batch 23: 47.76735305786133, 1.0\n",
      "Train loss and acc of batch 24: 48.36304473876953, 0.984375\n",
      "Train loss and acc of batch 25: 47.767333984375, 1.0\n",
      "Train loss and acc of batch 26: 47.7673225402832, 1.0\n",
      "Train loss and acc of batch 27: 47.76731872558594, 1.0\n",
      "Train loss and acc of batch 28: 47.767311096191406, 1.0\n",
      "Train loss and acc of batch 29: 48.363006591796875, 0.984375\n",
      "Train loss and acc of batch 30: 47.767295837402344, 1.0\n",
      "Train loss and acc of batch 31: 47.984046936035156, 0.984375\n",
      "Train loss and acc of batch 32: 47.76727294921875, 1.0\n",
      "Train loss and acc of batch 33: 47.76726531982422, 1.0\n",
      "Train loss and acc of batch 34: 48.36296081542969, 0.984375\n",
      "Train loss and acc of batch 35: 48.200775146484375, 0.96875\n",
      "Train loss and acc of batch 36: 47.76723861694336, 1.0\n",
      "Train loss and acc of batch 37: 48.52045822143555, 0.984375\n",
      "Train loss and acc of batch 38: 49.11614227294922, 0.96875\n",
      "Train loss and acc of batch 39: 47.983978271484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.7672004699707, 1.0\n",
      "Train loss and acc of batch 41: 49.116119384765625, 0.96875\n",
      "Train loss and acc of batch 42: 47.76718521118164, 1.0\n",
      "Train loss and acc of batch 43: 48.362876892089844, 0.984375\n",
      "Train loss and acc of batch 44: 47.76716995239258, 1.0\n",
      "Train loss and acc of batch 45: 48.36286163330078, 0.984375\n",
      "Train loss and acc of batch 46: 48.053001403808594, 0.984375\n",
      "Train loss and acc of batch 47: 47.76713943481445, 1.0\n",
      "Train loss and acc of batch 48: 47.76713562011719, 1.0\n",
      "Train loss and acc of batch 49: 47.76712417602539, 1.0\n",
      "Train loss and acc of batch 50: 48.362815856933594, 0.984375\n",
      "Train loss and acc of batch 51: 49.11603546142578, 0.96875\n",
      "Train loss and acc of batch 52: 49.0229377746582, 0.953125\n",
      "Train loss and acc of batch 53: 47.767093658447266, 1.0\n",
      "Train loss and acc of batch 54: 47.98384094238281, 0.984375\n",
      "Train loss and acc of batch 55: 47.767066955566406, 1.0\n",
      "Train loss and acc of batch 56: 47.76706314086914, 1.0\n",
      "Train loss and acc of batch 57: 48.362754821777344, 0.984375\n",
      "Train loss and acc of batch 58: 47.76704406738281, 1.0\n",
      "Train loss and acc of batch 59: 47.76703643798828, 1.0\n",
      "Train loss and acc of batch 60: 47.76702880859375, 1.0\n",
      "Train loss and acc of batch 61: 47.76702117919922, 1.0\n",
      "Train loss and acc of batch 62: 47.76700973510742, 1.0\n",
      "Train loss and acc of batch 63: 48.95840072631836, 0.96875\n",
      "Train loss and acc of batch 64: 47.98375701904297, 0.984375\n",
      "Train loss and acc of batch 65: 47.76698684692383, 1.0\n",
      "Train loss and acc of batch 66: 47.76697540283203, 1.0\n",
      "Train loss and acc of batch 67: 48.57943344116211, 0.96875\n",
      "Train loss and acc of batch 68: 48.36265563964844, 0.984375\n",
      "Train loss and acc of batch 69: 47.98371124267578, 0.984375\n",
      "Train loss and acc of batch 70: 47.76694107055664, 1.0\n",
      "Training accuracy and loss of epoch #461: 0.9897, 48.0881\n",
      "Saved model by train loss 48.08813175684969\n",
      "Train loss and acc of batch 0: 47.76692581176758, 1.0\n",
      "Train loss and acc of batch 1: 47.76692199707031, 1.0\n",
      "Train loss and acc of batch 2: 47.76690673828125, 1.0\n",
      "Train loss and acc of batch 3: 47.983665466308594, 0.984375\n",
      "Train loss and acc of batch 4: 47.76689529418945, 1.0\n",
      "Train loss and acc of batch 5: 49.115814208984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.26948928833008, 0.96875\n",
      "Train loss and acc of batch 7: 47.76686477661133, 1.0\n",
      "Train loss and acc of batch 8: 48.36255645751953, 0.984375\n",
      "Train loss and acc of batch 9: 48.052696228027344, 0.984375\n",
      "Train loss and acc of batch 10: 47.766841888427734, 1.0\n",
      "Train loss and acc of batch 11: 47.7668342590332, 1.0\n",
      "Train loss and acc of batch 12: 48.520042419433594, 0.984375\n",
      "Train loss and acc of batch 13: 47.98358154296875, 0.984375\n",
      "Train loss and acc of batch 14: 47.98356628417969, 0.984375\n",
      "Train loss and acc of batch 15: 48.36249542236328, 0.984375\n",
      "Train loss and acc of batch 16: 48.36248779296875, 0.984375\n",
      "Train loss and acc of batch 17: 48.52000045776367, 0.984375\n",
      "Train loss and acc of batch 18: 48.64832305908203, 0.96875\n",
      "Train loss and acc of batch 19: 47.76676559448242, 1.0\n",
      "Train loss and acc of batch 20: 47.76675033569336, 1.0\n",
      "Train loss and acc of batch 21: 48.36244201660156, 0.984375\n",
      "Train loss and acc of batch 22: 48.36243438720703, 0.984375\n",
      "Train loss and acc of batch 23: 47.766719818115234, 1.0\n",
      "Train loss and acc of batch 24: 48.36241912841797, 0.984375\n",
      "Train loss and acc of batch 25: 47.766700744628906, 1.0\n",
      "Train loss and acc of batch 26: 47.76669692993164, 1.0\n",
      "Train loss and acc of batch 27: 47.76668930053711, 1.0\n",
      "Train loss and acc of batch 28: 47.76667785644531, 1.0\n",
      "Train loss and acc of batch 29: 48.36237335205078, 0.984375\n",
      "Train loss and acc of batch 30: 47.76666259765625, 1.0\n",
      "Train loss and acc of batch 31: 47.98341369628906, 0.984375\n",
      "Train loss and acc of batch 32: 47.76664733886719, 1.0\n",
      "Train loss and acc of batch 33: 47.766639709472656, 1.0\n",
      "Train loss and acc of batch 34: 48.36231994628906, 0.984375\n",
      "Train loss and acc of batch 35: 48.20014572143555, 0.96875\n",
      "Train loss and acc of batch 36: 47.76660919189453, 1.0\n",
      "Train loss and acc of batch 37: 48.51982116699219, 0.984375\n",
      "Train loss and acc of batch 38: 49.115516662597656, 0.96875\n",
      "Train loss and acc of batch 39: 47.98335266113281, 0.984375\n",
      "Train loss and acc of batch 40: 47.76657485961914, 1.0\n",
      "Train loss and acc of batch 41: 49.11549377441406, 0.96875\n",
      "Train loss and acc of batch 42: 47.76655960083008, 1.0\n",
      "Train loss and acc of batch 43: 48.36224365234375, 0.984375\n",
      "Train loss and acc of batch 44: 47.766536712646484, 1.0\n",
      "Train loss and acc of batch 45: 48.36222839355469, 0.984375\n",
      "Train loss and acc of batch 46: 48.05237579345703, 0.984375\n",
      "Train loss and acc of batch 47: 47.76651382446289, 1.0\n",
      "Train loss and acc of batch 48: 47.76649856567383, 1.0\n",
      "Train loss and acc of batch 49: 47.76649475097656, 1.0\n",
      "Train loss and acc of batch 50: 48.36219024658203, 0.984375\n",
      "Train loss and acc of batch 51: 49.11540222167969, 0.96875\n",
      "Train loss and acc of batch 52: 49.022308349609375, 0.953125\n",
      "Train loss and acc of batch 53: 47.766456604003906, 1.0\n",
      "Train loss and acc of batch 54: 47.98321533203125, 0.984375\n",
      "Train loss and acc of batch 55: 47.766441345214844, 1.0\n",
      "Train loss and acc of batch 56: 47.76643753051758, 1.0\n",
      "Train loss and acc of batch 57: 48.36212158203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.76641082763672, 1.0\n",
      "Train loss and acc of batch 59: 47.76640319824219, 1.0\n",
      "Train loss and acc of batch 60: 47.766395568847656, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 61: 47.766387939453125, 1.0\n",
      "Train loss and acc of batch 62: 47.76637268066406, 1.0\n",
      "Train loss and acc of batch 63: 48.95777130126953, 0.96875\n",
      "Train loss and acc of batch 64: 47.983123779296875, 0.984375\n",
      "Train loss and acc of batch 65: 47.76634979248047, 1.0\n",
      "Train loss and acc of batch 66: 47.76634216308594, 1.0\n",
      "Train loss and acc of batch 67: 48.578800201416016, 0.96875\n",
      "Train loss and acc of batch 68: 48.362022399902344, 0.984375\n",
      "Train loss and acc of batch 69: 47.98308563232422, 0.984375\n",
      "Train loss and acc of batch 70: 47.766300201416016, 1.0\n",
      "Training accuracy and loss of epoch #462: 0.9897, 48.0875\n",
      "Saved model by train loss 48.08750093486947\n",
      "Train loss and acc of batch 0: 47.76629638671875, 1.0\n",
      "Train loss and acc of batch 1: 47.76628494262695, 1.0\n",
      "Train loss and acc of batch 2: 47.76628494262695, 1.0\n",
      "Train loss and acc of batch 3: 47.9830322265625, 0.984375\n",
      "Train loss and acc of batch 4: 47.766265869140625, 1.0\n",
      "Train loss and acc of batch 5: 49.11517333984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.268863677978516, 0.96875\n",
      "Train loss and acc of batch 7: 47.7662353515625, 1.0\n",
      "Train loss and acc of batch 8: 48.36192321777344, 0.984375\n",
      "Train loss and acc of batch 9: 48.05207061767578, 0.984375\n",
      "Train loss and acc of batch 10: 47.76620864868164, 1.0\n",
      "Train loss and acc of batch 11: 47.766197204589844, 1.0\n",
      "Train loss and acc of batch 12: 48.5194206237793, 0.984375\n",
      "Train loss and acc of batch 13: 47.98295593261719, 0.984375\n",
      "Train loss and acc of batch 14: 47.982933044433594, 0.984375\n",
      "Train loss and acc of batch 15: 48.36186218261719, 0.984375\n",
      "Train loss and acc of batch 16: 48.36186218261719, 0.984375\n",
      "Train loss and acc of batch 17: 48.519371032714844, 0.984375\n",
      "Train loss and acc of batch 18: 48.6476936340332, 0.96875\n",
      "Train loss and acc of batch 19: 47.76612854003906, 1.0\n",
      "Train loss and acc of batch 20: 47.76612091064453, 1.0\n",
      "Train loss and acc of batch 21: 48.36180877685547, 0.984375\n",
      "Train loss and acc of batch 22: 48.36180114746094, 0.984375\n",
      "Train loss and acc of batch 23: 47.76609420776367, 1.0\n",
      "Train loss and acc of batch 24: 48.361785888671875, 0.984375\n",
      "Train loss and acc of batch 25: 47.766075134277344, 1.0\n",
      "Train loss and acc of batch 26: 47.76607131958008, 1.0\n",
      "Train loss and acc of batch 27: 47.76605987548828, 1.0\n",
      "Train loss and acc of batch 28: 47.766048431396484, 1.0\n",
      "Train loss and acc of batch 29: 48.36174011230469, 0.984375\n",
      "Train loss and acc of batch 30: 47.76603317260742, 1.0\n",
      "Train loss and acc of batch 31: 47.9827880859375, 0.984375\n",
      "Train loss and acc of batch 32: 47.76601791381836, 1.0\n",
      "Train loss and acc of batch 33: 47.7660026550293, 1.0\n",
      "Train loss and acc of batch 34: 48.3616943359375, 0.984375\n",
      "Train loss and acc of batch 35: 48.199520111083984, 0.96875\n",
      "Train loss and acc of batch 36: 47.76597595214844, 1.0\n",
      "Train loss and acc of batch 37: 48.51919174194336, 0.984375\n",
      "Train loss and acc of batch 38: 49.11488342285156, 0.96875\n",
      "Train loss and acc of batch 39: 47.98271179199219, 0.984375\n",
      "Train loss and acc of batch 40: 47.76594543457031, 1.0\n",
      "Train loss and acc of batch 41: 49.114864349365234, 0.96875\n",
      "Train loss and acc of batch 42: 47.76592254638672, 1.0\n",
      "Train loss and acc of batch 43: 48.36161804199219, 0.984375\n",
      "Train loss and acc of batch 44: 47.76590347290039, 1.0\n",
      "Train loss and acc of batch 45: 48.361602783203125, 0.984375\n",
      "Train loss and acc of batch 46: 48.05174255371094, 0.984375\n",
      "Train loss and acc of batch 47: 47.76588439941406, 1.0\n",
      "Train loss and acc of batch 48: 47.765872955322266, 1.0\n",
      "Train loss and acc of batch 49: 47.76586151123047, 1.0\n",
      "Train loss and acc of batch 50: 48.361549377441406, 0.984375\n",
      "Train loss and acc of batch 51: 49.114768981933594, 0.96875\n",
      "Train loss and acc of batch 52: 49.02167510986328, 0.953125\n",
      "Train loss and acc of batch 53: 47.76582336425781, 1.0\n",
      "Train loss and acc of batch 54: 47.982582092285156, 0.984375\n",
      "Train loss and acc of batch 55: 47.765811920166016, 1.0\n",
      "Train loss and acc of batch 56: 47.76580047607422, 1.0\n",
      "Train loss and acc of batch 57: 48.36149597167969, 0.984375\n",
      "Train loss and acc of batch 58: 47.765785217285156, 1.0\n",
      "Train loss and acc of batch 59: 47.76577377319336, 1.0\n",
      "Train loss and acc of batch 60: 47.76576614379883, 1.0\n",
      "Train loss and acc of batch 61: 47.7657585144043, 1.0\n",
      "Train loss and acc of batch 62: 47.7657470703125, 1.0\n",
      "Train loss and acc of batch 63: 48.9571418762207, 0.96875\n",
      "Train loss and acc of batch 64: 47.98249053955078, 0.984375\n",
      "Train loss and acc of batch 65: 47.76572036743164, 1.0\n",
      "Train loss and acc of batch 66: 47.765708923339844, 1.0\n",
      "Train loss and acc of batch 67: 48.578163146972656, 0.96875\n",
      "Train loss and acc of batch 68: 48.36139678955078, 0.984375\n",
      "Train loss and acc of batch 69: 47.982452392578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.76567459106445, 1.0\n",
      "Training accuracy and loss of epoch #463: 0.9897, 48.0869\n",
      "Saved model by train loss 48.08687032780177\n",
      "Train loss and acc of batch 0: 47.76567077636719, 1.0\n",
      "Train loss and acc of batch 1: 47.76565933227539, 1.0\n",
      "Train loss and acc of batch 2: 47.765647888183594, 1.0\n",
      "Train loss and acc of batch 3: 47.98240661621094, 0.984375\n",
      "Train loss and acc of batch 4: 47.7656364440918, 1.0\n",
      "Train loss and acc of batch 5: 49.11454772949219, 0.96875\n",
      "Train loss and acc of batch 6: 48.26823425292969, 0.96875\n",
      "Train loss and acc of batch 7: 47.76560974121094, 1.0\n",
      "Train loss and acc of batch 8: 48.361305236816406, 0.984375\n",
      "Train loss and acc of batch 9: 48.05143737792969, 0.984375\n",
      "Train loss and acc of batch 10: 47.76557540893555, 1.0\n",
      "Train loss and acc of batch 11: 47.76557159423828, 1.0\n",
      "Train loss and acc of batch 12: 48.51878356933594, 0.984375\n",
      "Train loss and acc of batch 13: 47.982322692871094, 0.984375\n",
      "Train loss and acc of batch 14: 47.98230743408203, 0.984375\n",
      "Train loss and acc of batch 15: 48.361244201660156, 0.984375\n",
      "Train loss and acc of batch 16: 48.361228942871094, 0.984375\n",
      "Train loss and acc of batch 17: 48.51874542236328, 0.984375\n",
      "Train loss and acc of batch 18: 48.64706039428711, 0.96875\n",
      "Train loss and acc of batch 19: 47.765499114990234, 1.0\n",
      "Train loss and acc of batch 20: 47.76549530029297, 1.0\n",
      "Train loss and acc of batch 21: 48.361183166503906, 0.984375\n",
      "Train loss and acc of batch 22: 48.361175537109375, 0.984375\n",
      "Train loss and acc of batch 23: 47.765464782714844, 1.0\n",
      "Train loss and acc of batch 24: 48.36115264892578, 0.984375\n",
      "Train loss and acc of batch 25: 47.765445709228516, 1.0\n",
      "Train loss and acc of batch 26: 47.765438079833984, 1.0\n",
      "Train loss and acc of batch 27: 47.76542282104492, 1.0\n",
      "Train loss and acc of batch 28: 47.765419006347656, 1.0\n",
      "Train loss and acc of batch 29: 48.361114501953125, 0.984375\n",
      "Train loss and acc of batch 30: 47.765403747558594, 1.0\n",
      "Train loss and acc of batch 31: 47.98216247558594, 0.984375\n",
      "Train loss and acc of batch 32: 47.765384674072266, 1.0\n",
      "Train loss and acc of batch 33: 47.76537322998047, 1.0\n",
      "Train loss and acc of batch 34: 48.36106872558594, 0.984375\n",
      "Train loss and acc of batch 35: 48.19888687133789, 0.96875\n",
      "Train loss and acc of batch 36: 47.765350341796875, 1.0\n",
      "Train loss and acc of batch 37: 48.51856231689453, 0.984375\n",
      "Train loss and acc of batch 38: 49.1142578125, 0.96875\n",
      "Train loss and acc of batch 39: 47.982086181640625, 0.984375\n",
      "Train loss and acc of batch 40: 47.76531219482422, 1.0\n",
      "Train loss and acc of batch 41: 49.11423110961914, 0.96875\n",
      "Train loss and acc of batch 42: 47.765296936035156, 1.0\n",
      "Train loss and acc of batch 43: 48.360984802246094, 0.984375\n",
      "Train loss and acc of batch 44: 47.76527786254883, 1.0\n",
      "Train loss and acc of batch 45: 48.36096954345703, 0.984375\n",
      "Train loss and acc of batch 46: 48.051109313964844, 0.984375\n",
      "Train loss and acc of batch 47: 47.7652473449707, 1.0\n",
      "Train loss and acc of batch 48: 47.7652473449707, 1.0\n",
      "Train loss and acc of batch 49: 47.765235900878906, 1.0\n",
      "Train loss and acc of batch 50: 48.360931396484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.11414337158203, 0.96875\n",
      "Train loss and acc of batch 52: 49.02104187011719, 0.953125\n",
      "Train loss and acc of batch 53: 47.76519775390625, 1.0\n",
      "Train loss and acc of batch 54: 47.981956481933594, 0.984375\n",
      "Train loss and acc of batch 55: 47.765174865722656, 1.0\n",
      "Train loss and acc of batch 56: 47.765174865722656, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 57: 48.360862731933594, 0.984375\n",
      "Train loss and acc of batch 58: 47.76515579223633, 1.0\n",
      "Train loss and acc of batch 59: 47.7651481628418, 1.0\n",
      "Train loss and acc of batch 60: 47.765132904052734, 1.0\n",
      "Train loss and acc of batch 61: 47.7651252746582, 1.0\n",
      "Train loss and acc of batch 62: 47.76512145996094, 1.0\n",
      "Train loss and acc of batch 63: 48.956512451171875, 0.96875\n",
      "Train loss and acc of batch 64: 47.98186492919922, 0.984375\n",
      "Train loss and acc of batch 65: 47.76509475708008, 1.0\n",
      "Train loss and acc of batch 66: 47.76508712768555, 1.0\n",
      "Train loss and acc of batch 67: 48.57754135131836, 0.96875\n",
      "Train loss and acc of batch 68: 48.36077117919922, 0.984375\n",
      "Train loss and acc of batch 69: 47.98181915283203, 0.984375\n",
      "Train loss and acc of batch 70: 47.765045166015625, 1.0\n",
      "Training accuracy and loss of epoch #464: 0.9897, 48.0862\n",
      "Saved model by train loss 48.08624165494677\n",
      "Train loss and acc of batch 0: 47.765037536621094, 1.0\n",
      "Train loss and acc of batch 1: 47.7650260925293, 1.0\n",
      "Train loss and acc of batch 2: 47.76502227783203, 1.0\n",
      "Train loss and acc of batch 3: 47.981773376464844, 0.984375\n",
      "Train loss and acc of batch 4: 47.7650032043457, 1.0\n",
      "Train loss and acc of batch 5: 49.113922119140625, 0.96875\n",
      "Train loss and acc of batch 6: 48.26760482788086, 0.96875\n",
      "Train loss and acc of batch 7: 47.764976501464844, 1.0\n",
      "Train loss and acc of batch 8: 48.36067199707031, 0.984375\n",
      "Train loss and acc of batch 9: 48.050811767578125, 0.984375\n",
      "Train loss and acc of batch 10: 47.76495361328125, 1.0\n",
      "Train loss and acc of batch 11: 47.76494216918945, 1.0\n",
      "Train loss and acc of batch 12: 48.518150329589844, 0.984375\n",
      "Train loss and acc of batch 13: 47.981689453125, 0.984375\n",
      "Train loss and acc of batch 14: 47.98168182373047, 0.984375\n",
      "Train loss and acc of batch 15: 48.36060333251953, 0.984375\n",
      "Train loss and acc of batch 16: 48.36060333251953, 0.984375\n",
      "Train loss and acc of batch 17: 48.51810836791992, 0.984375\n",
      "Train loss and acc of batch 18: 48.64643478393555, 0.96875\n",
      "Train loss and acc of batch 19: 47.764869689941406, 1.0\n",
      "Train loss and acc of batch 20: 47.76486587524414, 1.0\n",
      "Train loss and acc of batch 21: 48.36054992675781, 0.984375\n",
      "Train loss and acc of batch 22: 48.36054992675781, 0.984375\n",
      "Train loss and acc of batch 23: 47.764835357666016, 1.0\n",
      "Train loss and acc of batch 24: 48.36053466796875, 0.984375\n",
      "Train loss and acc of batch 25: 47.76482009887695, 1.0\n",
      "Train loss and acc of batch 26: 47.764808654785156, 1.0\n",
      "Train loss and acc of batch 27: 47.764801025390625, 1.0\n",
      "Train loss and acc of batch 28: 47.76478958129883, 1.0\n",
      "Train loss and acc of batch 29: 48.36048126220703, 0.984375\n",
      "Train loss and acc of batch 30: 47.76477813720703, 1.0\n",
      "Train loss and acc of batch 31: 47.981529235839844, 0.984375\n",
      "Train loss and acc of batch 32: 47.76475524902344, 1.0\n",
      "Train loss and acc of batch 33: 47.764747619628906, 1.0\n",
      "Train loss and acc of batch 34: 48.360443115234375, 0.984375\n",
      "Train loss and acc of batch 35: 48.19825744628906, 0.96875\n",
      "Train loss and acc of batch 36: 47.76471710205078, 1.0\n",
      "Train loss and acc of batch 37: 48.5179328918457, 0.984375\n",
      "Train loss and acc of batch 38: 49.11363220214844, 0.96875\n",
      "Train loss and acc of batch 39: 47.98146057128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.76469039916992, 1.0\n",
      "Train loss and acc of batch 41: 49.11360168457031, 0.96875\n",
      "Train loss and acc of batch 42: 47.76466369628906, 1.0\n",
      "Train loss and acc of batch 43: 48.36035919189453, 0.984375\n",
      "Train loss and acc of batch 44: 47.7646484375, 1.0\n",
      "Train loss and acc of batch 45: 48.36033630371094, 0.984375\n",
      "Train loss and acc of batch 46: 48.05048370361328, 0.984375\n",
      "Train loss and acc of batch 47: 47.76462173461914, 1.0\n",
      "Train loss and acc of batch 48: 47.76461410522461, 1.0\n",
      "Train loss and acc of batch 49: 47.76460266113281, 1.0\n",
      "Train loss and acc of batch 50: 48.36029052734375, 0.984375\n",
      "Train loss and acc of batch 51: 49.11351013183594, 0.96875\n",
      "Train loss and acc of batch 52: 49.02042007446289, 0.953125\n",
      "Train loss and acc of batch 53: 47.76457214355469, 1.0\n",
      "Train loss and acc of batch 54: 47.98133087158203, 0.984375\n",
      "Train loss and acc of batch 55: 47.764556884765625, 1.0\n",
      "Train loss and acc of batch 56: 47.7645378112793, 1.0\n",
      "Train loss and acc of batch 57: 48.36023712158203, 0.984375\n",
      "Train loss and acc of batch 58: 47.7645263671875, 1.0\n",
      "Train loss and acc of batch 59: 47.76451110839844, 1.0\n",
      "Train loss and acc of batch 60: 47.764503479003906, 1.0\n",
      "Train loss and acc of batch 61: 47.76449966430664, 1.0\n",
      "Train loss and acc of batch 62: 47.764488220214844, 1.0\n",
      "Train loss and acc of batch 63: 48.95587921142578, 0.96875\n",
      "Train loss and acc of batch 64: 47.981231689453125, 0.984375\n",
      "Train loss and acc of batch 65: 47.764461517333984, 1.0\n",
      "Train loss and acc of batch 66: 47.76445388793945, 1.0\n",
      "Train loss and acc of batch 67: 48.57691192626953, 0.96875\n",
      "Train loss and acc of batch 68: 48.360137939453125, 0.984375\n",
      "Train loss and acc of batch 69: 47.98119354248047, 0.984375\n",
      "Train loss and acc of batch 70: 47.76441955566406, 1.0\n",
      "Training accuracy and loss of epoch #465: 0.9897, 48.0856\n",
      "Saved model by train loss 48.08561228362607\n",
      "Train loss and acc of batch 0: 47.7644157409668, 1.0\n",
      "Train loss and acc of batch 1: 47.764404296875, 1.0\n",
      "Train loss and acc of batch 2: 47.76438903808594, 1.0\n",
      "Train loss and acc of batch 3: 47.98114776611328, 0.984375\n",
      "Train loss and acc of batch 4: 47.76436996459961, 1.0\n",
      "Train loss and acc of batch 5: 49.11328887939453, 0.96875\n",
      "Train loss and acc of batch 6: 48.266971588134766, 0.96875\n",
      "Train loss and acc of batch 7: 47.764347076416016, 1.0\n",
      "Train loss and acc of batch 8: 48.36003875732422, 0.984375\n",
      "Train loss and acc of batch 9: 48.05018615722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.764320373535156, 1.0\n",
      "Train loss and acc of batch 11: 47.764312744140625, 1.0\n",
      "Train loss and acc of batch 12: 48.51752853393555, 0.984375\n",
      "Train loss and acc of batch 13: 47.98106384277344, 0.984375\n",
      "Train loss and acc of batch 14: 47.981056213378906, 0.984375\n",
      "Train loss and acc of batch 15: 48.35997772216797, 0.984375\n",
      "Train loss and acc of batch 16: 48.359962463378906, 0.984375\n",
      "Train loss and acc of batch 17: 48.51748275756836, 0.984375\n",
      "Train loss and acc of batch 18: 48.64580154418945, 0.96875\n",
      "Train loss and acc of batch 19: 47.764244079589844, 1.0\n",
      "Train loss and acc of batch 20: 47.76422882080078, 1.0\n",
      "Train loss and acc of batch 21: 48.35992431640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.35990905761719, 0.984375\n",
      "Train loss and acc of batch 23: 47.76420593261719, 1.0\n",
      "Train loss and acc of batch 24: 48.359893798828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.764190673828125, 1.0\n",
      "Train loss and acc of batch 26: 47.76417922973633, 1.0\n",
      "Train loss and acc of batch 27: 47.7641716003418, 1.0\n",
      "Train loss and acc of batch 28: 47.764163970947266, 1.0\n",
      "Train loss and acc of batch 29: 48.35984802246094, 0.984375\n",
      "Train loss and acc of batch 30: 47.76414108276367, 1.0\n",
      "Train loss and acc of batch 31: 47.98090362548828, 0.984375\n",
      "Train loss and acc of batch 32: 47.764122009277344, 1.0\n",
      "Train loss and acc of batch 33: 47.76411819458008, 1.0\n",
      "Train loss and acc of batch 34: 48.35980987548828, 0.984375\n",
      "Train loss and acc of batch 35: 48.197628021240234, 0.96875\n",
      "Train loss and acc of batch 36: 47.76408767700195, 1.0\n",
      "Train loss and acc of batch 37: 48.517303466796875, 0.984375\n",
      "Train loss and acc of batch 38: 49.112998962402344, 0.96875\n",
      "Train loss and acc of batch 39: 47.98082733154297, 0.984375\n",
      "Train loss and acc of batch 40: 47.76405334472656, 1.0\n",
      "Train loss and acc of batch 41: 49.112972259521484, 0.96875\n",
      "Train loss and acc of batch 42: 47.7640380859375, 1.0\n",
      "Train loss and acc of batch 43: 48.35972595214844, 0.984375\n",
      "Train loss and acc of batch 44: 47.76401901245117, 1.0\n",
      "Train loss and acc of batch 45: 48.359710693359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.04985046386719, 0.984375\n",
      "Train loss and acc of batch 47: 47.76399230957031, 1.0\n",
      "Train loss and acc of batch 48: 47.76398468017578, 1.0\n",
      "Train loss and acc of batch 49: 47.76396942138672, 1.0\n",
      "Train loss and acc of batch 50: 48.35967254638672, 0.984375\n",
      "Train loss and acc of batch 51: 49.112876892089844, 0.96875\n",
      "Train loss and acc of batch 52: 49.01979064941406, 0.953125\n",
      "Train loss and acc of batch 53: 47.763938903808594, 1.0\n",
      "Train loss and acc of batch 54: 47.98069763183594, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 55: 47.763916015625, 1.0\n",
      "Train loss and acc of batch 56: 47.763916015625, 1.0\n",
      "Train loss and acc of batch 57: 48.35960388183594, 0.984375\n",
      "Train loss and acc of batch 58: 47.763893127441406, 1.0\n",
      "Train loss and acc of batch 59: 47.763885498046875, 1.0\n",
      "Train loss and acc of batch 60: 47.763877868652344, 1.0\n",
      "Train loss and acc of batch 61: 47.76386642456055, 1.0\n",
      "Train loss and acc of batch 62: 47.76386260986328, 1.0\n",
      "Train loss and acc of batch 63: 48.95524978637695, 0.96875\n",
      "Train loss and acc of batch 64: 47.98060607910156, 0.984375\n",
      "Train loss and acc of batch 65: 47.76383972167969, 1.0\n",
      "Train loss and acc of batch 66: 47.76382064819336, 1.0\n",
      "Train loss and acc of batch 67: 48.57627868652344, 0.96875\n",
      "Train loss and acc of batch 68: 48.35950469970703, 0.984375\n",
      "Train loss and acc of batch 69: 47.980560302734375, 0.984375\n",
      "Train loss and acc of batch 70: 47.763790130615234, 1.0\n",
      "Training accuracy and loss of epoch #466: 0.9897, 48.0850\n",
      "Saved model by train loss 48.084982106383414\n",
      "Train loss and acc of batch 0: 47.76377868652344, 1.0\n",
      "Train loss and acc of batch 1: 47.763771057128906, 1.0\n",
      "Train loss and acc of batch 2: 47.76375961303711, 1.0\n",
      "Train loss and acc of batch 3: 47.98051452636719, 0.984375\n",
      "Train loss and acc of batch 4: 47.76374435424805, 1.0\n",
      "Train loss and acc of batch 5: 49.11266326904297, 0.96875\n",
      "Train loss and acc of batch 6: 48.26634216308594, 0.96875\n",
      "Train loss and acc of batch 7: 47.76371765136719, 1.0\n",
      "Train loss and acc of batch 8: 48.359413146972656, 0.984375\n",
      "Train loss and acc of batch 9: 48.04955291748047, 0.984375\n",
      "Train loss and acc of batch 10: 47.76369094848633, 1.0\n",
      "Train loss and acc of batch 11: 47.76367950439453, 1.0\n",
      "Train loss and acc of batch 12: 48.51689529418945, 0.984375\n",
      "Train loss and acc of batch 13: 47.980430603027344, 0.984375\n",
      "Train loss and acc of batch 14: 47.98042297363281, 0.984375\n",
      "Train loss and acc of batch 15: 48.359344482421875, 0.984375\n",
      "Train loss and acc of batch 16: 48.359336853027344, 0.984375\n",
      "Train loss and acc of batch 17: 48.516849517822266, 0.984375\n",
      "Train loss and acc of batch 18: 48.64517593383789, 0.96875\n",
      "Train loss and acc of batch 19: 47.76361083984375, 1.0\n",
      "Train loss and acc of batch 20: 47.76359939575195, 1.0\n",
      "Train loss and acc of batch 21: 48.359291076660156, 0.984375\n",
      "Train loss and acc of batch 22: 48.359291076660156, 0.984375\n",
      "Train loss and acc of batch 23: 47.76356887817383, 1.0\n",
      "Train loss and acc of batch 24: 48.35926818847656, 0.984375\n",
      "Train loss and acc of batch 25: 47.763553619384766, 1.0\n",
      "Train loss and acc of batch 26: 47.763545989990234, 1.0\n",
      "Train loss and acc of batch 27: 47.7635383605957, 1.0\n",
      "Train loss and acc of batch 28: 47.76353073120117, 1.0\n",
      "Train loss and acc of batch 29: 48.359222412109375, 0.984375\n",
      "Train loss and acc of batch 30: 47.76351547241211, 1.0\n",
      "Train loss and acc of batch 31: 47.98027038574219, 0.984375\n",
      "Train loss and acc of batch 32: 47.76349639892578, 1.0\n",
      "Train loss and acc of batch 33: 47.76348876953125, 1.0\n",
      "Train loss and acc of batch 34: 48.35918426513672, 0.984375\n",
      "Train loss and acc of batch 35: 48.19699478149414, 0.96875\n",
      "Train loss and acc of batch 36: 47.76346206665039, 1.0\n",
      "Train loss and acc of batch 37: 48.51667404174805, 0.984375\n",
      "Train loss and acc of batch 38: 49.11236572265625, 0.96875\n",
      "Train loss and acc of batch 39: 47.980194091796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.76342010498047, 1.0\n",
      "Train loss and acc of batch 41: 49.112342834472656, 0.96875\n",
      "Train loss and acc of batch 42: 47.76340866088867, 1.0\n",
      "Train loss and acc of batch 43: 48.359100341796875, 0.984375\n",
      "Train loss and acc of batch 44: 47.763389587402344, 1.0\n",
      "Train loss and acc of batch 45: 48.35907745361328, 0.984375\n",
      "Train loss and acc of batch 46: 48.049224853515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.763362884521484, 1.0\n",
      "Train loss and acc of batch 48: 47.76334762573242, 1.0\n",
      "Train loss and acc of batch 49: 47.763343811035156, 1.0\n",
      "Train loss and acc of batch 50: 48.359039306640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.11225128173828, 0.96875\n",
      "Train loss and acc of batch 52: 49.0191535949707, 0.953125\n",
      "Train loss and acc of batch 53: 47.7633056640625, 1.0\n",
      "Train loss and acc of batch 54: 47.98005676269531, 0.984375\n",
      "Train loss and acc of batch 55: 47.76329040527344, 1.0\n",
      "Train loss and acc of batch 56: 47.763275146484375, 1.0\n",
      "Train loss and acc of batch 57: 48.358970642089844, 0.984375\n",
      "Train loss and acc of batch 58: 47.76326370239258, 1.0\n",
      "Train loss and acc of batch 59: 47.76325607299805, 1.0\n",
      "Train loss and acc of batch 60: 47.763240814208984, 1.0\n",
      "Train loss and acc of batch 61: 47.76323699951172, 1.0\n",
      "Train loss and acc of batch 62: 47.76322555541992, 1.0\n",
      "Train loss and acc of batch 63: 48.954620361328125, 0.96875\n",
      "Train loss and acc of batch 64: 47.97997283935547, 0.984375\n",
      "Train loss and acc of batch 65: 47.76319885253906, 1.0\n",
      "Train loss and acc of batch 66: 47.76319122314453, 1.0\n",
      "Train loss and acc of batch 67: 48.575645446777344, 0.96875\n",
      "Train loss and acc of batch 68: 48.35887145996094, 0.984375\n",
      "Train loss and acc of batch 69: 47.97992706298828, 0.984375\n",
      "Train loss and acc of batch 70: 47.76315689086914, 1.0\n",
      "Training accuracy and loss of epoch #467: 0.9897, 48.0844\n",
      "Saved model by train loss 48.084350962034414\n",
      "Train loss and acc of batch 0: 47.76314163208008, 1.0\n",
      "Train loss and acc of batch 1: 47.76313781738281, 1.0\n",
      "Train loss and acc of batch 2: 47.763126373291016, 1.0\n",
      "Train loss and acc of batch 3: 47.979881286621094, 0.984375\n",
      "Train loss and acc of batch 4: 47.76311111450195, 1.0\n",
      "Train loss and acc of batch 5: 49.112030029296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.265708923339844, 0.96875\n",
      "Train loss and acc of batch 7: 47.763084411621094, 1.0\n",
      "Train loss and acc of batch 8: 48.35877227783203, 0.984375\n",
      "Train loss and acc of batch 9: 48.048919677734375, 0.984375\n",
      "Train loss and acc of batch 10: 47.7630615234375, 1.0\n",
      "Train loss and acc of batch 11: 47.76304626464844, 1.0\n",
      "Train loss and acc of batch 12: 48.51626205444336, 0.984375\n",
      "Train loss and acc of batch 13: 47.97978973388672, 0.984375\n",
      "Train loss and acc of batch 14: 47.97978973388672, 0.984375\n",
      "Train loss and acc of batch 15: 48.35871887207031, 0.984375\n",
      "Train loss and acc of batch 16: 48.35870361328125, 0.984375\n",
      "Train loss and acc of batch 17: 48.51622009277344, 0.984375\n",
      "Train loss and acc of batch 18: 48.6445426940918, 0.96875\n",
      "Train loss and acc of batch 19: 47.762977600097656, 1.0\n",
      "Train loss and acc of batch 20: 47.76296615600586, 1.0\n",
      "Train loss and acc of batch 21: 48.358665466308594, 0.984375\n",
      "Train loss and acc of batch 22: 48.35865020751953, 0.984375\n",
      "Train loss and acc of batch 23: 47.76294708251953, 1.0\n",
      "Train loss and acc of batch 24: 48.35863494873047, 0.984375\n",
      "Train loss and acc of batch 25: 47.76292419433594, 1.0\n",
      "Train loss and acc of batch 26: 47.76291275024414, 1.0\n",
      "Train loss and acc of batch 27: 47.76290512084961, 1.0\n",
      "Train loss and acc of batch 28: 47.76289749145508, 1.0\n",
      "Train loss and acc of batch 29: 48.35858917236328, 0.984375\n",
      "Train loss and acc of batch 30: 47.76287841796875, 1.0\n",
      "Train loss and acc of batch 31: 47.979637145996094, 0.984375\n",
      "Train loss and acc of batch 32: 47.76286697387695, 1.0\n",
      "Train loss and acc of batch 33: 47.76285171508789, 1.0\n",
      "Train loss and acc of batch 34: 48.358543395996094, 0.984375\n",
      "Train loss and acc of batch 35: 48.19636535644531, 0.96875\n",
      "Train loss and acc of batch 36: 47.76282501220703, 1.0\n",
      "Train loss and acc of batch 37: 48.51604461669922, 0.984375\n",
      "Train loss and acc of batch 38: 49.111732482910156, 0.96875\n",
      "Train loss and acc of batch 39: 47.97956085205078, 0.984375\n",
      "Train loss and acc of batch 40: 47.76279067993164, 1.0\n",
      "Train loss and acc of batch 41: 49.1117057800293, 0.96875\n",
      "Train loss and acc of batch 42: 47.76277542114258, 1.0\n",
      "Train loss and acc of batch 43: 48.35846710205078, 0.984375\n",
      "Train loss and acc of batch 44: 47.76275634765625, 1.0\n",
      "Train loss and acc of batch 45: 48.35844421386719, 0.984375\n",
      "Train loss and acc of batch 46: 48.04859161376953, 0.984375\n",
      "Train loss and acc of batch 47: 47.762725830078125, 1.0\n",
      "Train loss and acc of batch 48: 47.762718200683594, 1.0\n",
      "Train loss and acc of batch 49: 47.76271438598633, 1.0\n",
      "Train loss and acc of batch 50: 48.35840606689453, 0.984375\n",
      "Train loss and acc of batch 51: 49.11161804199219, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 52: 49.01852798461914, 0.953125\n",
      "Train loss and acc of batch 53: 47.76267623901367, 1.0\n",
      "Train loss and acc of batch 54: 47.97943115234375, 0.984375\n",
      "Train loss and acc of batch 55: 47.76266098022461, 1.0\n",
      "Train loss and acc of batch 56: 47.76264953613281, 1.0\n",
      "Train loss and acc of batch 57: 48.35833740234375, 0.984375\n",
      "Train loss and acc of batch 58: 47.76263427734375, 1.0\n",
      "Train loss and acc of batch 59: 47.76262283325195, 1.0\n",
      "Train loss and acc of batch 60: 47.76261901855469, 1.0\n",
      "Train loss and acc of batch 61: 47.762603759765625, 1.0\n",
      "Train loss and acc of batch 62: 47.76259231567383, 1.0\n",
      "Train loss and acc of batch 63: 48.95398712158203, 0.96875\n",
      "Train loss and acc of batch 64: 47.979339599609375, 0.984375\n",
      "Train loss and acc of batch 65: 47.762569427490234, 1.0\n",
      "Train loss and acc of batch 66: 47.7625617980957, 1.0\n",
      "Train loss and acc of batch 67: 48.575016021728516, 0.96875\n",
      "Train loss and acc of batch 68: 48.358245849609375, 0.984375\n",
      "Train loss and acc of batch 69: 47.97929382324219, 0.984375\n",
      "Train loss and acc of batch 70: 47.76252365112305, 1.0\n",
      "Training accuracy and loss of epoch #468: 0.9897, 48.0837\n",
      "Saved model by train loss 48.0837187431228\n",
      "Train loss and acc of batch 0: 47.762516021728516, 1.0\n",
      "Train loss and acc of batch 1: 47.76251220703125, 1.0\n",
      "Train loss and acc of batch 2: 47.76249694824219, 1.0\n",
      "Train loss and acc of batch 3: 47.97925567626953, 0.984375\n",
      "Train loss and acc of batch 4: 47.76247787475586, 1.0\n",
      "Train loss and acc of batch 5: 49.11139678955078, 0.96875\n",
      "Train loss and acc of batch 6: 48.265079498291016, 0.96875\n",
      "Train loss and acc of batch 7: 47.762451171875, 1.0\n",
      "Train loss and acc of batch 8: 48.35814666748047, 0.984375\n",
      "Train loss and acc of batch 9: 48.04828643798828, 0.984375\n",
      "Train loss and acc of batch 10: 47.762428283691406, 1.0\n",
      "Train loss and acc of batch 11: 47.762420654296875, 1.0\n",
      "Train loss and acc of batch 12: 48.5156364440918, 0.984375\n",
      "Train loss and acc of batch 13: 47.979164123535156, 0.984375\n",
      "Train loss and acc of batch 14: 47.979156494140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.35808563232422, 0.984375\n",
      "Train loss and acc of batch 16: 48.35807800292969, 0.984375\n",
      "Train loss and acc of batch 17: 48.515594482421875, 0.984375\n",
      "Train loss and acc of batch 18: 48.6439094543457, 0.96875\n",
      "Train loss and acc of batch 19: 47.76234817504883, 1.0\n",
      "Train loss and acc of batch 20: 47.7623405456543, 1.0\n",
      "Train loss and acc of batch 21: 48.35802459716797, 0.984375\n",
      "Train loss and acc of batch 22: 48.35802459716797, 0.984375\n",
      "Train loss and acc of batch 23: 47.76231002807617, 1.0\n",
      "Train loss and acc of batch 24: 48.358001708984375, 0.984375\n",
      "Train loss and acc of batch 25: 47.76229476928711, 1.0\n",
      "Train loss and acc of batch 26: 47.762290954589844, 1.0\n",
      "Train loss and acc of batch 27: 47.76227569580078, 1.0\n",
      "Train loss and acc of batch 28: 47.76226806640625, 1.0\n",
      "Train loss and acc of batch 29: 48.35796356201172, 0.984375\n",
      "Train loss and acc of batch 30: 47.76224899291992, 1.0\n",
      "Train loss and acc of batch 31: 47.97901153564453, 0.984375\n",
      "Train loss and acc of batch 32: 47.762237548828125, 1.0\n",
      "Train loss and acc of batch 33: 47.76222229003906, 1.0\n",
      "Train loss and acc of batch 34: 48.35791778564453, 0.984375\n",
      "Train loss and acc of batch 35: 48.19573211669922, 0.96875\n",
      "Train loss and acc of batch 36: 47.7621955871582, 1.0\n",
      "Train loss and acc of batch 37: 48.515411376953125, 0.984375\n",
      "Train loss and acc of batch 38: 49.11109924316406, 0.96875\n",
      "Train loss and acc of batch 39: 47.97893524169922, 0.984375\n",
      "Train loss and acc of batch 40: 47.76216506958008, 1.0\n",
      "Train loss and acc of batch 41: 49.11107635498047, 0.96875\n",
      "Train loss and acc of batch 42: 47.762142181396484, 1.0\n",
      "Train loss and acc of batch 43: 48.35783386230469, 0.984375\n",
      "Train loss and acc of batch 44: 47.762123107910156, 1.0\n",
      "Train loss and acc of batch 45: 48.357818603515625, 0.984375\n",
      "Train loss and acc of batch 46: 48.04796600341797, 0.984375\n",
      "Train loss and acc of batch 47: 47.76210021972656, 1.0\n",
      "Train loss and acc of batch 48: 47.76209259033203, 1.0\n",
      "Train loss and acc of batch 49: 47.762081146240234, 1.0\n",
      "Train loss and acc of batch 50: 48.35777282714844, 0.984375\n",
      "Train loss and acc of batch 51: 49.110992431640625, 0.96875\n",
      "Train loss and acc of batch 52: 49.01789093017578, 0.953125\n",
      "Train loss and acc of batch 53: 47.762046813964844, 1.0\n",
      "Train loss and acc of batch 54: 47.97880554199219, 0.984375\n",
      "Train loss and acc of batch 55: 47.762027740478516, 1.0\n",
      "Train loss and acc of batch 56: 47.76201629638672, 1.0\n",
      "Train loss and acc of batch 57: 48.35771179199219, 0.984375\n",
      "Train loss and acc of batch 58: 47.76199722290039, 1.0\n",
      "Train loss and acc of batch 59: 47.76199722290039, 1.0\n",
      "Train loss and acc of batch 60: 47.76198196411133, 1.0\n",
      "Train loss and acc of batch 61: 47.7619743347168, 1.0\n",
      "Train loss and acc of batch 62: 47.76197052001953, 1.0\n",
      "Train loss and acc of batch 63: 48.9533576965332, 0.96875\n",
      "Train loss and acc of batch 64: 47.97871398925781, 0.984375\n",
      "Train loss and acc of batch 65: 47.76194381713867, 1.0\n",
      "Train loss and acc of batch 66: 47.76192855834961, 1.0\n",
      "Train loss and acc of batch 67: 48.57439041137695, 0.96875\n",
      "Train loss and acc of batch 68: 48.35762023925781, 0.984375\n",
      "Train loss and acc of batch 69: 47.978668212890625, 0.984375\n",
      "Train loss and acc of batch 70: 47.76189422607422, 1.0\n",
      "Training accuracy and loss of epoch #469: 0.9897, 48.0831\n",
      "Saved model by train loss 48.08308942553023\n",
      "Train loss and acc of batch 0: 47.76188278198242, 1.0\n",
      "Train loss and acc of batch 1: 47.76187515258789, 1.0\n",
      "Train loss and acc of batch 2: 47.761871337890625, 1.0\n",
      "Train loss and acc of batch 3: 47.97862243652344, 0.984375\n",
      "Train loss and acc of batch 4: 47.76184844970703, 1.0\n",
      "Train loss and acc of batch 5: 49.11077117919922, 0.96875\n",
      "Train loss and acc of batch 6: 48.26445388793945, 0.96875\n",
      "Train loss and acc of batch 7: 47.76182556152344, 1.0\n",
      "Train loss and acc of batch 8: 48.357521057128906, 0.984375\n",
      "Train loss and acc of batch 9: 48.04765319824219, 0.984375\n",
      "Train loss and acc of batch 10: 47.76179885864258, 1.0\n",
      "Train loss and acc of batch 11: 47.76179122924805, 1.0\n",
      "Train loss and acc of batch 12: 48.5150032043457, 0.984375\n",
      "Train loss and acc of batch 13: 47.978538513183594, 0.984375\n",
      "Train loss and acc of batch 14: 47.97852325439453, 0.984375\n",
      "Train loss and acc of batch 15: 48.357452392578125, 0.984375\n",
      "Train loss and acc of batch 16: 48.357444763183594, 0.984375\n",
      "Train loss and acc of batch 17: 48.51496124267578, 0.984375\n",
      "Train loss and acc of batch 18: 48.64327621459961, 0.96875\n",
      "Train loss and acc of batch 19: 47.761722564697266, 1.0\n",
      "Train loss and acc of batch 20: 47.761714935302734, 1.0\n",
      "Train loss and acc of batch 21: 48.357398986816406, 0.984375\n",
      "Train loss and acc of batch 22: 48.357391357421875, 0.984375\n",
      "Train loss and acc of batch 23: 47.76167678833008, 1.0\n",
      "Train loss and acc of batch 24: 48.35737609863281, 0.984375\n",
      "Train loss and acc of batch 25: 47.76166534423828, 1.0\n",
      "Train loss and acc of batch 26: 47.76165008544922, 1.0\n",
      "Train loss and acc of batch 27: 47.76164627075195, 1.0\n",
      "Train loss and acc of batch 28: 47.76164245605469, 1.0\n",
      "Train loss and acc of batch 29: 48.357330322265625, 0.984375\n",
      "Train loss and acc of batch 30: 47.761619567871094, 1.0\n",
      "Train loss and acc of batch 31: 47.97837829589844, 0.984375\n",
      "Train loss and acc of batch 32: 47.761600494384766, 1.0\n",
      "Train loss and acc of batch 33: 47.7615966796875, 1.0\n",
      "Train loss and acc of batch 34: 48.35728454589844, 0.984375\n",
      "Train loss and acc of batch 35: 48.195106506347656, 0.96875\n",
      "Train loss and acc of batch 36: 47.761566162109375, 1.0\n",
      "Train loss and acc of batch 37: 48.51477813720703, 0.984375\n",
      "Train loss and acc of batch 38: 49.1104736328125, 0.96875\n",
      "Train loss and acc of batch 39: 47.978309631347656, 0.984375\n",
      "Train loss and acc of batch 40: 47.76152801513672, 1.0\n",
      "Train loss and acc of batch 41: 49.110450744628906, 0.96875\n",
      "Train loss and acc of batch 42: 47.761512756347656, 1.0\n",
      "Train loss and acc of batch 43: 48.357208251953125, 0.984375\n",
      "Train loss and acc of batch 44: 47.761497497558594, 1.0\n",
      "Train loss and acc of batch 45: 48.35718536376953, 0.984375\n",
      "Train loss and acc of batch 46: 48.047332763671875, 0.984375\n",
      "Train loss and acc of batch 47: 47.761470794677734, 1.0\n",
      "Train loss and acc of batch 48: 47.7614631652832, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 49: 47.761451721191406, 1.0\n",
      "Train loss and acc of batch 50: 48.357147216796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.11035919189453, 0.96875\n",
      "Train loss and acc of batch 52: 49.01726531982422, 0.953125\n",
      "Train loss and acc of batch 53: 47.76142120361328, 1.0\n",
      "Train loss and acc of batch 54: 47.978172302246094, 0.984375\n",
      "Train loss and acc of batch 55: 47.76139831542969, 1.0\n",
      "Train loss and acc of batch 56: 47.761390686035156, 1.0\n",
      "Train loss and acc of batch 57: 48.357078552246094, 0.984375\n",
      "Train loss and acc of batch 58: 47.761375427246094, 1.0\n",
      "Train loss and acc of batch 59: 47.76136016845703, 1.0\n",
      "Train loss and acc of batch 60: 47.7613525390625, 1.0\n",
      "Train loss and acc of batch 61: 47.76134490966797, 1.0\n",
      "Train loss and acc of batch 62: 47.76133728027344, 1.0\n",
      "Train loss and acc of batch 63: 48.95273208618164, 0.96875\n",
      "Train loss and acc of batch 64: 47.97808837890625, 0.984375\n",
      "Train loss and acc of batch 65: 47.76131057739258, 1.0\n",
      "Train loss and acc of batch 66: 47.76129913330078, 1.0\n",
      "Train loss and acc of batch 67: 48.573760986328125, 0.96875\n",
      "Train loss and acc of batch 68: 48.35698699951172, 0.984375\n",
      "Train loss and acc of batch 69: 47.97803497314453, 0.984375\n",
      "Train loss and acc of batch 70: 47.76127243041992, 1.0\n",
      "Training accuracy and loss of epoch #470: 0.9897, 48.0825\n",
      "Saved model by train loss 48.08245962438449\n",
      "Train loss and acc of batch 0: 47.761253356933594, 1.0\n",
      "Train loss and acc of batch 1: 47.76124954223633, 1.0\n",
      "Train loss and acc of batch 2: 47.761234283447266, 1.0\n",
      "Train loss and acc of batch 3: 47.977989196777344, 0.984375\n",
      "Train loss and acc of batch 4: 47.7612190246582, 1.0\n",
      "Train loss and acc of batch 5: 49.110137939453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.26382064819336, 0.96875\n",
      "Train loss and acc of batch 7: 47.76119613647461, 1.0\n",
      "Train loss and acc of batch 8: 48.35688781738281, 0.984375\n",
      "Train loss and acc of batch 9: 48.047027587890625, 0.984375\n",
      "Train loss and acc of batch 10: 47.76116943359375, 1.0\n",
      "Train loss and acc of batch 11: 47.76115798950195, 1.0\n",
      "Train loss and acc of batch 12: 48.514373779296875, 0.984375\n",
      "Train loss and acc of batch 13: 47.97791290283203, 0.984375\n",
      "Train loss and acc of batch 14: 47.97789764404297, 0.984375\n",
      "Train loss and acc of batch 15: 48.35682678222656, 0.984375\n",
      "Train loss and acc of batch 16: 48.3568115234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.51432418823242, 0.984375\n",
      "Train loss and acc of batch 18: 48.64265060424805, 0.96875\n",
      "Train loss and acc of batch 19: 47.761085510253906, 1.0\n",
      "Train loss and acc of batch 20: 47.76108169555664, 1.0\n",
      "Train loss and acc of batch 21: 48.356773376464844, 0.984375\n",
      "Train loss and acc of batch 22: 48.35676574707031, 0.984375\n",
      "Train loss and acc of batch 23: 47.76104736328125, 1.0\n",
      "Train loss and acc of batch 24: 48.35675048828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.76103210449219, 1.0\n",
      "Train loss and acc of batch 26: 47.761024475097656, 1.0\n",
      "Train loss and acc of batch 27: 47.76102066040039, 1.0\n",
      "Train loss and acc of batch 28: 47.761009216308594, 1.0\n",
      "Train loss and acc of batch 29: 48.35669708251953, 0.984375\n",
      "Train loss and acc of batch 30: 47.76099395751953, 1.0\n",
      "Train loss and acc of batch 31: 47.977745056152344, 0.984375\n",
      "Train loss and acc of batch 32: 47.7609748840332, 1.0\n",
      "Train loss and acc of batch 33: 47.760963439941406, 1.0\n",
      "Train loss and acc of batch 34: 48.356658935546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.19447326660156, 0.96875\n",
      "Train loss and acc of batch 36: 47.76093673706055, 1.0\n",
      "Train loss and acc of batch 37: 48.51415252685547, 0.984375\n",
      "Train loss and acc of batch 38: 49.10984802246094, 0.96875\n",
      "Train loss and acc of batch 39: 47.97767639160156, 0.984375\n",
      "Train loss and acc of batch 40: 47.76089859008789, 1.0\n",
      "Train loss and acc of batch 41: 49.10982131958008, 0.96875\n",
      "Train loss and acc of batch 42: 47.76088333129883, 1.0\n",
      "Train loss and acc of batch 43: 48.35657501220703, 0.984375\n",
      "Train loss and acc of batch 44: 47.76087188720703, 1.0\n",
      "Train loss and acc of batch 45: 48.35655212402344, 0.984375\n",
      "Train loss and acc of batch 46: 48.04669952392578, 0.984375\n",
      "Train loss and acc of batch 47: 47.76083755493164, 1.0\n",
      "Train loss and acc of batch 48: 47.76082992553711, 1.0\n",
      "Train loss and acc of batch 49: 47.76082229614258, 1.0\n",
      "Train loss and acc of batch 50: 48.35651397705078, 0.984375\n",
      "Train loss and acc of batch 51: 49.10972595214844, 0.96875\n",
      "Train loss and acc of batch 52: 49.016639709472656, 0.953125\n",
      "Train loss and acc of batch 53: 47.76078414916992, 1.0\n",
      "Train loss and acc of batch 54: 47.9775390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.76076889038086, 1.0\n",
      "Train loss and acc of batch 56: 47.76075744628906, 1.0\n",
      "Train loss and acc of batch 57: 48.35645294189453, 0.984375\n",
      "Train loss and acc of batch 58: 47.760746002197266, 1.0\n",
      "Train loss and acc of batch 59: 47.7607307434082, 1.0\n",
      "Train loss and acc of batch 60: 47.76072311401367, 1.0\n",
      "Train loss and acc of batch 61: 47.760719299316406, 1.0\n",
      "Train loss and acc of batch 62: 47.760704040527344, 1.0\n",
      "Train loss and acc of batch 63: 48.95209884643555, 0.96875\n",
      "Train loss and acc of batch 64: 47.977447509765625, 0.984375\n",
      "Train loss and acc of batch 65: 47.76068115234375, 1.0\n",
      "Train loss and acc of batch 66: 47.76067352294922, 1.0\n",
      "Train loss and acc of batch 67: 48.5731315612793, 0.96875\n",
      "Train loss and acc of batch 68: 48.356353759765625, 0.984375\n",
      "Train loss and acc of batch 69: 47.97740936279297, 0.984375\n",
      "Train loss and acc of batch 70: 47.7606315612793, 1.0\n",
      "Training accuracy and loss of epoch #471: 0.9897, 48.0818\n",
      "Saved model by train loss 48.08182923222931\n",
      "Train loss and acc of batch 0: 47.76062774658203, 1.0\n",
      "Train loss and acc of batch 1: 47.7606201171875, 1.0\n",
      "Train loss and acc of batch 2: 47.7606086730957, 1.0\n",
      "Train loss and acc of batch 3: 47.97736358642578, 0.984375\n",
      "Train loss and acc of batch 4: 47.76059341430664, 1.0\n",
      "Train loss and acc of batch 5: 49.10950469970703, 0.96875\n",
      "Train loss and acc of batch 6: 48.26319122314453, 0.96875\n",
      "Train loss and acc of batch 7: 47.760562896728516, 1.0\n",
      "Train loss and acc of batch 8: 48.35625457763672, 0.984375\n",
      "Train loss and acc of batch 9: 48.04640197753906, 0.984375\n",
      "Train loss and acc of batch 10: 47.760536193847656, 1.0\n",
      "Train loss and acc of batch 11: 47.760528564453125, 1.0\n",
      "Train loss and acc of batch 12: 48.51374435424805, 0.984375\n",
      "Train loss and acc of batch 13: 47.977272033691406, 0.984375\n",
      "Train loss and acc of batch 14: 47.977264404296875, 0.984375\n",
      "Train loss and acc of batch 15: 48.35619354248047, 0.984375\n",
      "Train loss and acc of batch 16: 48.35618591308594, 0.984375\n",
      "Train loss and acc of batch 17: 48.51369857788086, 0.984375\n",
      "Train loss and acc of batch 18: 48.642024993896484, 0.96875\n",
      "Train loss and acc of batch 19: 47.760459899902344, 1.0\n",
      "Train loss and acc of batch 20: 47.76044845581055, 1.0\n",
      "Train loss and acc of batch 21: 48.35614013671875, 0.984375\n",
      "Train loss and acc of batch 22: 48.35613250732422, 0.984375\n",
      "Train loss and acc of batch 23: 47.76042556762695, 1.0\n",
      "Train loss and acc of batch 24: 48.356117248535156, 0.984375\n",
      "Train loss and acc of batch 25: 47.76040267944336, 1.0\n",
      "Train loss and acc of batch 26: 47.76039505004883, 1.0\n",
      "Train loss and acc of batch 27: 47.7603874206543, 1.0\n",
      "Train loss and acc of batch 28: 47.760379791259766, 1.0\n",
      "Train loss and acc of batch 29: 48.35607147216797, 0.984375\n",
      "Train loss and acc of batch 30: 47.76035690307617, 1.0\n",
      "Train loss and acc of batch 31: 47.97711944580078, 0.984375\n",
      "Train loss and acc of batch 32: 47.76034164428711, 1.0\n",
      "Train loss and acc of batch 33: 47.76033401489258, 1.0\n",
      "Train loss and acc of batch 34: 48.35602569580078, 0.984375\n",
      "Train loss and acc of batch 35: 48.193843841552734, 0.96875\n",
      "Train loss and acc of batch 36: 47.76030731201172, 1.0\n",
      "Train loss and acc of batch 37: 48.51352310180664, 0.984375\n",
      "Train loss and acc of batch 38: 49.10920715332031, 0.96875\n",
      "Train loss and acc of batch 39: 47.97704315185547, 0.984375\n",
      "Train loss and acc of batch 40: 47.76026916503906, 1.0\n",
      "Train loss and acc of batch 41: 49.109188079833984, 0.96875\n",
      "Train loss and acc of batch 42: 47.76025390625, 1.0\n",
      "Train loss and acc of batch 43: 48.35594940185547, 0.984375\n",
      "Train loss and acc of batch 44: 47.76023483276367, 1.0\n",
      "Train loss and acc of batch 45: 48.355926513671875, 0.984375\n",
      "Train loss and acc of batch 46: 48.04607391357422, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 47.76020812988281, 1.0\n",
      "Train loss and acc of batch 48: 47.76020050048828, 1.0\n",
      "Train loss and acc of batch 49: 47.76019287109375, 1.0\n",
      "Train loss and acc of batch 50: 48.35588073730469, 0.984375\n",
      "Train loss and acc of batch 51: 49.109100341796875, 0.96875\n",
      "Train loss and acc of batch 52: 49.01600646972656, 0.953125\n",
      "Train loss and acc of batch 53: 47.760154724121094, 1.0\n",
      "Train loss and acc of batch 54: 47.97691345214844, 0.984375\n",
      "Train loss and acc of batch 55: 47.760135650634766, 1.0\n",
      "Train loss and acc of batch 56: 47.7601318359375, 1.0\n",
      "Train loss and acc of batch 57: 48.35581970214844, 0.984375\n",
      "Train loss and acc of batch 58: 47.76011276245117, 1.0\n",
      "Train loss and acc of batch 59: 47.760101318359375, 1.0\n",
      "Train loss and acc of batch 60: 47.76009750366211, 1.0\n",
      "Train loss and acc of batch 61: 47.76008224487305, 1.0\n",
      "Train loss and acc of batch 62: 47.760074615478516, 1.0\n",
      "Train loss and acc of batch 63: 48.951473236083984, 0.96875\n",
      "Train loss and acc of batch 64: 47.97682189941406, 0.984375\n",
      "Train loss and acc of batch 65: 47.76005172729492, 1.0\n",
      "Train loss and acc of batch 66: 47.76004409790039, 1.0\n",
      "Train loss and acc of batch 67: 48.5724983215332, 0.96875\n",
      "Train loss and acc of batch 68: 48.35572814941406, 0.984375\n",
      "Train loss and acc of batch 69: 47.976776123046875, 0.984375\n",
      "Train loss and acc of batch 70: 47.760005950927734, 1.0\n",
      "Training accuracy and loss of epoch #472: 0.9897, 48.0812\n",
      "Saved model by train loss 48.08119926989918\n",
      "Train loss and acc of batch 0: 47.75999450683594, 1.0\n",
      "Train loss and acc of batch 1: 47.75998306274414, 1.0\n",
      "Train loss and acc of batch 2: 47.759979248046875, 1.0\n",
      "Train loss and acc of batch 3: 47.97673797607422, 0.984375\n",
      "Train loss and acc of batch 4: 47.75996398925781, 1.0\n",
      "Train loss and acc of batch 5: 49.10887145996094, 0.96875\n",
      "Train loss and acc of batch 6: 48.2625617980957, 0.96875\n",
      "Train loss and acc of batch 7: 47.75993347167969, 1.0\n",
      "Train loss and acc of batch 8: 48.355628967285156, 0.984375\n",
      "Train loss and acc of batch 9: 48.0457763671875, 0.984375\n",
      "Train loss and acc of batch 10: 47.75990676879883, 1.0\n",
      "Train loss and acc of batch 11: 47.7598991394043, 1.0\n",
      "Train loss and acc of batch 12: 48.51311492919922, 0.984375\n",
      "Train loss and acc of batch 13: 47.976646423339844, 0.984375\n",
      "Train loss and acc of batch 14: 47.97663879394531, 0.984375\n",
      "Train loss and acc of batch 15: 48.355560302734375, 0.984375\n",
      "Train loss and acc of batch 16: 48.355552673339844, 0.984375\n",
      "Train loss and acc of batch 17: 48.5130729675293, 0.984375\n",
      "Train loss and acc of batch 18: 48.64139175415039, 0.96875\n",
      "Train loss and acc of batch 19: 47.759822845458984, 1.0\n",
      "Train loss and acc of batch 20: 47.75981903076172, 1.0\n",
      "Train loss and acc of batch 21: 48.35551452636719, 0.984375\n",
      "Train loss and acc of batch 22: 48.355506896972656, 0.984375\n",
      "Train loss and acc of batch 23: 47.75979232788086, 1.0\n",
      "Train loss and acc of batch 24: 48.35548400878906, 0.984375\n",
      "Train loss and acc of batch 25: 47.7597770690918, 1.0\n",
      "Train loss and acc of batch 26: 47.759769439697266, 1.0\n",
      "Train loss and acc of batch 27: 47.75975799560547, 1.0\n",
      "Train loss and acc of batch 28: 47.75975036621094, 1.0\n",
      "Train loss and acc of batch 29: 48.355438232421875, 0.984375\n",
      "Train loss and acc of batch 30: 47.75973129272461, 1.0\n",
      "Train loss and acc of batch 31: 47.97649383544922, 0.984375\n",
      "Train loss and acc of batch 32: 47.75971221923828, 1.0\n",
      "Train loss and acc of batch 33: 47.75970458984375, 1.0\n",
      "Train loss and acc of batch 34: 48.35539245605469, 0.984375\n",
      "Train loss and acc of batch 35: 48.19321060180664, 0.96875\n",
      "Train loss and acc of batch 36: 47.75967788696289, 1.0\n",
      "Train loss and acc of batch 37: 48.51289749145508, 0.984375\n",
      "Train loss and acc of batch 38: 49.10858154296875, 0.96875\n",
      "Train loss and acc of batch 39: 47.976417541503906, 0.984375\n",
      "Train loss and acc of batch 40: 47.759647369384766, 1.0\n",
      "Train loss and acc of batch 41: 49.10856246948242, 0.96875\n",
      "Train loss and acc of batch 42: 47.75962829589844, 1.0\n",
      "Train loss and acc of batch 43: 48.355316162109375, 0.984375\n",
      "Train loss and acc of batch 44: 47.759605407714844, 1.0\n",
      "Train loss and acc of batch 45: 48.35530090332031, 0.984375\n",
      "Train loss and acc of batch 46: 48.045448303222656, 0.984375\n",
      "Train loss and acc of batch 47: 47.759578704833984, 1.0\n",
      "Train loss and acc of batch 48: 47.75957489013672, 1.0\n",
      "Train loss and acc of batch 49: 47.759559631347656, 1.0\n",
      "Train loss and acc of batch 50: 48.355255126953125, 0.984375\n",
      "Train loss and acc of batch 51: 49.10846710205078, 0.96875\n",
      "Train loss and acc of batch 52: 49.01537322998047, 0.953125\n",
      "Train loss and acc of batch 53: 47.75952911376953, 1.0\n",
      "Train loss and acc of batch 54: 47.976287841796875, 0.984375\n",
      "Train loss and acc of batch 55: 47.7595100402832, 1.0\n",
      "Train loss and acc of batch 56: 47.75950241088867, 1.0\n",
      "Train loss and acc of batch 57: 48.355194091796875, 0.984375\n",
      "Train loss and acc of batch 58: 47.75947952270508, 1.0\n",
      "Train loss and acc of batch 59: 47.75947570800781, 1.0\n",
      "Train loss and acc of batch 60: 47.75946807861328, 1.0\n",
      "Train loss and acc of batch 61: 47.759456634521484, 1.0\n",
      "Train loss and acc of batch 62: 47.75945281982422, 1.0\n",
      "Train loss and acc of batch 63: 48.950836181640625, 0.96875\n",
      "Train loss and acc of batch 64: 47.9761962890625, 0.984375\n",
      "Train loss and acc of batch 65: 47.759422302246094, 1.0\n",
      "Train loss and acc of batch 66: 47.75940704345703, 1.0\n",
      "Train loss and acc of batch 67: 48.571868896484375, 0.96875\n",
      "Train loss and acc of batch 68: 48.35509490966797, 0.984375\n",
      "Train loss and acc of batch 69: 47.97615051269531, 0.984375\n",
      "Train loss and acc of batch 70: 47.75938034057617, 1.0\n",
      "Training accuracy and loss of epoch #473: 0.9897, 48.0806\n",
      "Saved model by train loss 48.080570382131654\n",
      "Train loss and acc of batch 0: 47.759368896484375, 1.0\n",
      "Train loss and acc of batch 1: 47.75935745239258, 1.0\n",
      "Train loss and acc of batch 2: 47.75935363769531, 1.0\n",
      "Train loss and acc of batch 3: 47.976104736328125, 0.984375\n",
      "Train loss and acc of batch 4: 47.759334564208984, 1.0\n",
      "Train loss and acc of batch 5: 49.108253479003906, 0.96875\n",
      "Train loss and acc of batch 6: 48.26192855834961, 0.96875\n",
      "Train loss and acc of batch 7: 47.75930404663086, 1.0\n",
      "Train loss and acc of batch 8: 48.35499572753906, 0.984375\n",
      "Train loss and acc of batch 9: 48.045135498046875, 0.984375\n",
      "Train loss and acc of batch 10: 47.759281158447266, 1.0\n",
      "Train loss and acc of batch 11: 47.759273529052734, 1.0\n",
      "Train loss and acc of batch 12: 48.51248550415039, 0.984375\n",
      "Train loss and acc of batch 13: 47.97602081298828, 0.984375\n",
      "Train loss and acc of batch 14: 47.97600555419922, 0.984375\n",
      "Train loss and acc of batch 15: 48.35493469238281, 0.984375\n",
      "Train loss and acc of batch 16: 48.35492706298828, 0.984375\n",
      "Train loss and acc of batch 17: 48.51244354248047, 0.984375\n",
      "Train loss and acc of batch 18: 48.64076232910156, 0.96875\n",
      "Train loss and acc of batch 19: 47.75920104980469, 1.0\n",
      "Train loss and acc of batch 20: 47.759193420410156, 1.0\n",
      "Train loss and acc of batch 21: 48.354881286621094, 0.984375\n",
      "Train loss and acc of batch 22: 48.35487365722656, 0.984375\n",
      "Train loss and acc of batch 23: 47.759159088134766, 1.0\n",
      "Train loss and acc of batch 24: 48.3548583984375, 0.984375\n",
      "Train loss and acc of batch 25: 47.7591438293457, 1.0\n",
      "Train loss and acc of batch 26: 47.75913619995117, 1.0\n",
      "Train loss and acc of batch 27: 47.75912857055664, 1.0\n",
      "Train loss and acc of batch 28: 47.759124755859375, 1.0\n",
      "Train loss and acc of batch 29: 48.35481262207031, 0.984375\n",
      "Train loss and acc of batch 30: 47.75910186767578, 1.0\n",
      "Train loss and acc of batch 31: 47.975860595703125, 0.984375\n",
      "Train loss and acc of batch 32: 47.75908279418945, 1.0\n",
      "Train loss and acc of batch 33: 47.75907516479492, 1.0\n",
      "Train loss and acc of batch 34: 48.354766845703125, 0.984375\n",
      "Train loss and acc of batch 35: 48.19258499145508, 0.96875\n",
      "Train loss and acc of batch 36: 47.7590446472168, 1.0\n",
      "Train loss and acc of batch 37: 48.51226043701172, 0.984375\n",
      "Train loss and acc of batch 38: 49.10795593261719, 0.96875\n",
      "Train loss and acc of batch 39: 47.975791931152344, 0.984375\n",
      "Train loss and acc of batch 40: 47.75901412963867, 1.0\n",
      "Train loss and acc of batch 41: 49.107933044433594, 0.96875\n",
      "Train loss and acc of batch 42: 47.758995056152344, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 43: 48.35468292236328, 0.984375\n",
      "Train loss and acc of batch 44: 47.75897979736328, 1.0\n",
      "Train loss and acc of batch 45: 48.35466766357422, 0.984375\n",
      "Train loss and acc of batch 46: 48.04480743408203, 0.984375\n",
      "Train loss and acc of batch 47: 47.75895309448242, 1.0\n",
      "Train loss and acc of batch 48: 47.758941650390625, 1.0\n",
      "Train loss and acc of batch 49: 47.758934020996094, 1.0\n",
      "Train loss and acc of batch 50: 48.35462188720703, 0.984375\n",
      "Train loss and acc of batch 51: 49.10784149169922, 0.96875\n",
      "Train loss and acc of batch 52: 49.01474380493164, 0.953125\n",
      "Train loss and acc of batch 53: 47.75889587402344, 1.0\n",
      "Train loss and acc of batch 54: 47.97565460205078, 0.984375\n",
      "Train loss and acc of batch 55: 47.758880615234375, 1.0\n",
      "Train loss and acc of batch 56: 47.75886917114258, 1.0\n",
      "Train loss and acc of batch 57: 48.35456085205078, 0.984375\n",
      "Train loss and acc of batch 58: 47.75885009765625, 1.0\n",
      "Train loss and acc of batch 59: 47.75884246826172, 1.0\n",
      "Train loss and acc of batch 60: 47.75883483886719, 1.0\n",
      "Train loss and acc of batch 61: 47.758827209472656, 1.0\n",
      "Train loss and acc of batch 62: 47.75881576538086, 1.0\n",
      "Train loss and acc of batch 63: 48.95021438598633, 0.96875\n",
      "Train loss and acc of batch 64: 47.97557067871094, 0.984375\n",
      "Train loss and acc of batch 65: 47.7587890625, 1.0\n",
      "Train loss and acc of batch 66: 47.75878143310547, 1.0\n",
      "Train loss and acc of batch 67: 48.57123947143555, 0.96875\n",
      "Train loss and acc of batch 68: 48.354469299316406, 0.984375\n",
      "Train loss and acc of batch 69: 47.97551727294922, 0.984375\n",
      "Train loss and acc of batch 70: 47.75874710083008, 1.0\n",
      "Training accuracy and loss of epoch #474: 0.9897, 48.0799\n",
      "Saved model by train loss 48.07994063471405\n",
      "Train loss and acc of batch 0: 47.75873565673828, 1.0\n",
      "Train loss and acc of batch 1: 47.75872802734375, 1.0\n",
      "Train loss and acc of batch 2: 47.75872039794922, 1.0\n",
      "Train loss and acc of batch 3: 47.97547149658203, 0.984375\n",
      "Train loss and acc of batch 4: 47.75870132446289, 1.0\n",
      "Train loss and acc of batch 5: 49.10762023925781, 0.96875\n",
      "Train loss and acc of batch 6: 48.26130294799805, 0.96875\n",
      "Train loss and acc of batch 7: 47.7586784362793, 1.0\n",
      "Train loss and acc of batch 8: 48.3543701171875, 0.984375\n",
      "Train loss and acc of batch 9: 48.04450988769531, 0.984375\n",
      "Train loss and acc of batch 10: 47.75865173339844, 1.0\n",
      "Train loss and acc of batch 11: 47.758644104003906, 1.0\n",
      "Train loss and acc of batch 12: 48.5118522644043, 0.984375\n",
      "Train loss and acc of batch 13: 47.97538757324219, 0.984375\n",
      "Train loss and acc of batch 14: 47.975379943847656, 0.984375\n",
      "Train loss and acc of batch 15: 48.35430908203125, 0.984375\n",
      "Train loss and acc of batch 16: 48.35429382324219, 0.984375\n",
      "Train loss and acc of batch 17: 48.51180648803711, 0.984375\n",
      "Train loss and acc of batch 18: 48.64012908935547, 0.96875\n",
      "Train loss and acc of batch 19: 47.758567810058594, 1.0\n",
      "Train loss and acc of batch 20: 47.75856018066406, 1.0\n",
      "Train loss and acc of batch 21: 48.35425567626953, 0.984375\n",
      "Train loss and acc of batch 22: 48.35424041748047, 0.984375\n",
      "Train loss and acc of batch 23: 47.75852966308594, 1.0\n",
      "Train loss and acc of batch 24: 48.354225158691406, 0.984375\n",
      "Train loss and acc of batch 25: 47.75851821899414, 1.0\n",
      "Train loss and acc of batch 26: 47.758506774902344, 1.0\n",
      "Train loss and acc of batch 27: 47.75849533081055, 1.0\n",
      "Train loss and acc of batch 28: 47.758487701416016, 1.0\n",
      "Train loss and acc of batch 29: 48.35418701171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.75846862792969, 1.0\n",
      "Train loss and acc of batch 31: 47.97522735595703, 0.984375\n",
      "Train loss and acc of batch 32: 47.758453369140625, 1.0\n",
      "Train loss and acc of batch 33: 47.75844192504883, 1.0\n",
      "Train loss and acc of batch 34: 48.35414123535156, 0.984375\n",
      "Train loss and acc of batch 35: 48.19195556640625, 0.96875\n",
      "Train loss and acc of batch 36: 47.758419036865234, 1.0\n",
      "Train loss and acc of batch 37: 48.51163101196289, 0.984375\n",
      "Train loss and acc of batch 38: 49.107330322265625, 0.96875\n",
      "Train loss and acc of batch 39: 47.97515869140625, 0.984375\n",
      "Train loss and acc of batch 40: 47.758384704589844, 1.0\n",
      "Train loss and acc of batch 41: 49.1072998046875, 0.96875\n",
      "Train loss and acc of batch 42: 47.758365631103516, 1.0\n",
      "Train loss and acc of batch 43: 48.35405731201172, 0.984375\n",
      "Train loss and acc of batch 44: 47.75835037231445, 1.0\n",
      "Train loss and acc of batch 45: 48.354034423828125, 0.984375\n",
      "Train loss and acc of batch 46: 48.04418182373047, 0.984375\n",
      "Train loss and acc of batch 47: 47.75831985473633, 1.0\n",
      "Train loss and acc of batch 48: 47.7583122253418, 1.0\n",
      "Train loss and acc of batch 49: 47.75830078125, 1.0\n",
      "Train loss and acc of batch 50: 48.35399627685547, 0.984375\n",
      "Train loss and acc of batch 51: 49.107208251953125, 0.96875\n",
      "Train loss and acc of batch 52: 49.01411819458008, 0.953125\n",
      "Train loss and acc of batch 53: 47.75826644897461, 1.0\n",
      "Train loss and acc of batch 54: 47.97502136230469, 0.984375\n",
      "Train loss and acc of batch 55: 47.75824737548828, 1.0\n",
      "Train loss and acc of batch 56: 47.75823974609375, 1.0\n",
      "Train loss and acc of batch 57: 48.35393524169922, 0.984375\n",
      "Train loss and acc of batch 58: 47.75822448730469, 1.0\n",
      "Train loss and acc of batch 59: 47.75821304321289, 1.0\n",
      "Train loss and acc of batch 60: 47.75820541381836, 1.0\n",
      "Train loss and acc of batch 61: 47.75819396972656, 1.0\n",
      "Train loss and acc of batch 62: 47.7581901550293, 1.0\n",
      "Train loss and acc of batch 63: 48.9495849609375, 0.96875\n",
      "Train loss and acc of batch 64: 47.97492980957031, 0.984375\n",
      "Train loss and acc of batch 65: 47.75815963745117, 1.0\n",
      "Train loss and acc of batch 66: 47.758155822753906, 1.0\n",
      "Train loss and acc of batch 67: 48.57061004638672, 0.96875\n",
      "Train loss and acc of batch 68: 48.35383605957031, 0.984375\n",
      "Train loss and acc of batch 69: 47.974891662597656, 0.984375\n",
      "Train loss and acc of batch 70: 47.75811767578125, 1.0\n",
      "Training accuracy and loss of epoch #475: 0.9897, 48.0793\n",
      "Saved model by train loss 48.07931051119952\n",
      "Train loss and acc of batch 0: 47.75811004638672, 1.0\n",
      "Train loss and acc of batch 1: 47.75809860229492, 1.0\n",
      "Train loss and acc of batch 2: 47.758087158203125, 1.0\n",
      "Train loss and acc of batch 3: 47.97484588623047, 0.984375\n",
      "Train loss and acc of batch 4: 47.75807189941406, 1.0\n",
      "Train loss and acc of batch 5: 49.10698699951172, 0.96875\n",
      "Train loss and acc of batch 6: 48.26067352294922, 0.96875\n",
      "Train loss and acc of batch 7: 47.7580451965332, 1.0\n",
      "Train loss and acc of batch 8: 48.353736877441406, 0.984375\n",
      "Train loss and acc of batch 9: 48.04387664794922, 0.984375\n",
      "Train loss and acc of batch 10: 47.758018493652344, 1.0\n",
      "Train loss and acc of batch 11: 47.75800704956055, 1.0\n",
      "Train loss and acc of batch 12: 48.51122283935547, 0.984375\n",
      "Train loss and acc of batch 13: 47.974754333496094, 0.984375\n",
      "Train loss and acc of batch 14: 47.974754333496094, 0.984375\n",
      "Train loss and acc of batch 15: 48.353675842285156, 0.984375\n",
      "Train loss and acc of batch 16: 48.353668212890625, 0.984375\n",
      "Train loss and acc of batch 17: 48.51117706298828, 0.984375\n",
      "Train loss and acc of batch 18: 48.63949966430664, 0.96875\n",
      "Train loss and acc of batch 19: 47.757938385009766, 1.0\n",
      "Train loss and acc of batch 20: 47.7579345703125, 1.0\n",
      "Train loss and acc of batch 21: 48.35362243652344, 0.984375\n",
      "Train loss and acc of batch 22: 48.353614807128906, 0.984375\n",
      "Train loss and acc of batch 23: 47.757904052734375, 1.0\n",
      "Train loss and acc of batch 24: 48.35359191894531, 0.984375\n",
      "Train loss and acc of batch 25: 47.75788497924805, 1.0\n",
      "Train loss and acc of batch 26: 47.75787353515625, 1.0\n",
      "Train loss and acc of batch 27: 47.75786590576172, 1.0\n",
      "Train loss and acc of batch 28: 47.75786209106445, 1.0\n",
      "Train loss and acc of batch 29: 48.353553771972656, 0.984375\n",
      "Train loss and acc of batch 30: 47.757843017578125, 1.0\n",
      "Train loss and acc of batch 31: 47.97460174560547, 0.984375\n",
      "Train loss and acc of batch 32: 47.75782012939453, 1.0\n",
      "Train loss and acc of batch 33: 47.757816314697266, 1.0\n",
      "Train loss and acc of batch 34: 48.35350799560547, 0.984375\n",
      "Train loss and acc of batch 35: 48.19132614135742, 0.96875\n",
      "Train loss and acc of batch 36: 47.757789611816406, 1.0\n",
      "Train loss and acc of batch 37: 48.51100540161133, 0.984375\n",
      "Train loss and acc of batch 38: 49.106689453125, 0.96875\n",
      "Train loss and acc of batch 39: 47.974525451660156, 0.984375\n",
      "Train loss and acc of batch 40: 47.75775146484375, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.10667037963867, 0.96875\n",
      "Train loss and acc of batch 42: 47.75773620605469, 1.0\n",
      "Train loss and acc of batch 43: 48.353424072265625, 0.984375\n",
      "Train loss and acc of batch 44: 47.757713317871094, 1.0\n",
      "Train loss and acc of batch 45: 48.35340881347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.043548583984375, 0.984375\n",
      "Train loss and acc of batch 47: 47.7576904296875, 1.0\n",
      "Train loss and acc of batch 48: 47.75768280029297, 1.0\n",
      "Train loss and acc of batch 49: 47.75767135620117, 1.0\n",
      "Train loss and acc of batch 50: 48.353363037109375, 0.984375\n",
      "Train loss and acc of batch 51: 49.10658264160156, 0.96875\n",
      "Train loss and acc of batch 52: 49.013484954833984, 0.953125\n",
      "Train loss and acc of batch 53: 47.75763702392578, 1.0\n",
      "Train loss and acc of batch 54: 47.974395751953125, 0.984375\n",
      "Train loss and acc of batch 55: 47.75761795043945, 1.0\n",
      "Train loss and acc of batch 56: 47.75761032104492, 1.0\n",
      "Train loss and acc of batch 57: 48.353302001953125, 0.984375\n",
      "Train loss and acc of batch 58: 47.757591247558594, 1.0\n",
      "Train loss and acc of batch 59: 47.75758743286133, 1.0\n",
      "Train loss and acc of batch 60: 47.757572174072266, 1.0\n",
      "Train loss and acc of batch 61: 47.757564544677734, 1.0\n",
      "Train loss and acc of batch 62: 47.7575569152832, 1.0\n",
      "Train loss and acc of batch 63: 48.94894790649414, 0.96875\n",
      "Train loss and acc of batch 64: 47.97430419921875, 0.984375\n",
      "Train loss and acc of batch 65: 47.75753402709961, 1.0\n",
      "Train loss and acc of batch 66: 47.75752258300781, 1.0\n",
      "Train loss and acc of batch 67: 48.56998062133789, 0.96875\n",
      "Train loss and acc of batch 68: 48.35320281982422, 0.984375\n",
      "Train loss and acc of batch 69: 47.97425842285156, 0.984375\n",
      "Train loss and acc of batch 70: 47.757484436035156, 1.0\n",
      "Training accuracy and loss of epoch #476: 0.9897, 48.0787\n",
      "Saved model by train loss 48.078680011588084\n",
      "Train loss and acc of batch 0: 47.75748062133789, 1.0\n",
      "Train loss and acc of batch 1: 47.757469177246094, 1.0\n",
      "Train loss and acc of batch 2: 47.75746154785156, 1.0\n",
      "Train loss and acc of batch 3: 47.974220275878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.757442474365234, 1.0\n",
      "Train loss and acc of batch 5: 49.106361389160156, 0.96875\n",
      "Train loss and acc of batch 6: 48.26003646850586, 0.96875\n",
      "Train loss and acc of batch 7: 47.757415771484375, 1.0\n",
      "Train loss and acc of batch 8: 48.35310363769531, 0.984375\n",
      "Train loss and acc of batch 9: 48.043251037597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.757389068603516, 1.0\n",
      "Train loss and acc of batch 11: 47.757381439208984, 1.0\n",
      "Train loss and acc of batch 12: 48.510589599609375, 0.984375\n",
      "Train loss and acc of batch 13: 47.97412872314453, 0.984375\n",
      "Train loss and acc of batch 14: 47.97412109375, 0.984375\n",
      "Train loss and acc of batch 15: 48.35304260253906, 0.984375\n",
      "Train loss and acc of batch 16: 48.35303497314453, 0.984375\n",
      "Train loss and acc of batch 17: 48.51054763793945, 0.984375\n",
      "Train loss and acc of batch 18: 48.63887023925781, 0.96875\n",
      "Train loss and acc of batch 19: 47.75730895996094, 1.0\n",
      "Train loss and acc of batch 20: 47.75729751586914, 1.0\n",
      "Train loss and acc of batch 21: 48.352996826171875, 0.984375\n",
      "Train loss and acc of batch 22: 48.35298156738281, 0.984375\n",
      "Train loss and acc of batch 23: 47.75727462768555, 1.0\n",
      "Train loss and acc of batch 24: 48.35296630859375, 0.984375\n",
      "Train loss and acc of batch 25: 47.75725555419922, 1.0\n",
      "Train loss and acc of batch 26: 47.75724411010742, 1.0\n",
      "Train loss and acc of batch 27: 47.75723648071289, 1.0\n",
      "Train loss and acc of batch 28: 47.757225036621094, 1.0\n",
      "Train loss and acc of batch 29: 48.35292053222656, 0.984375\n",
      "Train loss and acc of batch 30: 47.75720977783203, 1.0\n",
      "Train loss and acc of batch 31: 47.973968505859375, 0.984375\n",
      "Train loss and acc of batch 32: 47.75719451904297, 1.0\n",
      "Train loss and acc of batch 33: 47.75718688964844, 1.0\n",
      "Train loss and acc of batch 34: 48.352874755859375, 0.984375\n",
      "Train loss and acc of batch 35: 48.19069290161133, 0.96875\n",
      "Train loss and acc of batch 36: 47.75715637207031, 1.0\n",
      "Train loss and acc of batch 37: 48.510372161865234, 0.984375\n",
      "Train loss and acc of batch 38: 49.10606384277344, 0.96875\n",
      "Train loss and acc of batch 39: 47.973899841308594, 0.984375\n",
      "Train loss and acc of batch 40: 47.75712585449219, 1.0\n",
      "Train loss and acc of batch 41: 49.10604476928711, 0.96875\n",
      "Train loss and acc of batch 42: 47.75710678100586, 1.0\n",
      "Train loss and acc of batch 43: 48.35279846191406, 0.984375\n",
      "Train loss and acc of batch 44: 47.75708770751953, 1.0\n",
      "Train loss and acc of batch 45: 48.35277557373047, 0.984375\n",
      "Train loss and acc of batch 46: 48.04292297363281, 0.984375\n",
      "Train loss and acc of batch 47: 47.75706100463867, 1.0\n",
      "Train loss and acc of batch 48: 47.75705337524414, 1.0\n",
      "Train loss and acc of batch 49: 47.75703811645508, 1.0\n",
      "Train loss and acc of batch 50: 48.35273742675781, 0.984375\n",
      "Train loss and acc of batch 51: 49.10594940185547, 0.96875\n",
      "Train loss and acc of batch 52: 49.012855529785156, 0.953125\n",
      "Train loss and acc of batch 53: 47.75700759887695, 1.0\n",
      "Train loss and acc of batch 54: 47.97377014160156, 0.984375\n",
      "Train loss and acc of batch 55: 47.75699234008789, 1.0\n",
      "Train loss and acc of batch 56: 47.756980895996094, 1.0\n",
      "Train loss and acc of batch 57: 48.35266876220703, 0.984375\n",
      "Train loss and acc of batch 58: 47.75696563720703, 1.0\n",
      "Train loss and acc of batch 59: 47.756954193115234, 1.0\n",
      "Train loss and acc of batch 60: 47.75695037841797, 1.0\n",
      "Train loss and acc of batch 61: 47.756935119628906, 1.0\n",
      "Train loss and acc of batch 62: 47.756927490234375, 1.0\n",
      "Train loss and acc of batch 63: 48.94831848144531, 0.96875\n",
      "Train loss and acc of batch 64: 47.973670959472656, 0.984375\n",
      "Train loss and acc of batch 65: 47.756900787353516, 1.0\n",
      "Train loss and acc of batch 66: 47.75689697265625, 1.0\n",
      "Train loss and acc of batch 67: 48.5693473815918, 0.96875\n",
      "Train loss and acc of batch 68: 48.352577209472656, 0.984375\n",
      "Train loss and acc of batch 69: 47.9736328125, 0.984375\n",
      "Train loss and acc of batch 70: 47.75685501098633, 1.0\n",
      "Training accuracy and loss of epoch #477: 0.9897, 48.0781\n",
      "Saved model by train loss 48.078050479083\n",
      "Train loss and acc of batch 0: 47.7568473815918, 1.0\n",
      "Train loss and acc of batch 1: 47.756839752197266, 1.0\n",
      "Train loss and acc of batch 2: 47.75682830810547, 1.0\n",
      "Train loss and acc of batch 3: 47.97358703613281, 0.984375\n",
      "Train loss and acc of batch 4: 47.756813049316406, 1.0\n",
      "Train loss and acc of batch 5: 49.10572814941406, 0.96875\n",
      "Train loss and acc of batch 6: 48.25941467285156, 0.96875\n",
      "Train loss and acc of batch 7: 47.75678634643555, 1.0\n",
      "Train loss and acc of batch 8: 48.35247802734375, 0.984375\n",
      "Train loss and acc of batch 9: 48.042625427246094, 0.984375\n",
      "Train loss and acc of batch 10: 47.75675964355469, 1.0\n",
      "Train loss and acc of batch 11: 47.756752014160156, 1.0\n",
      "Train loss and acc of batch 12: 48.50996780395508, 0.984375\n",
      "Train loss and acc of batch 13: 47.97350311279297, 0.984375\n",
      "Train loss and acc of batch 14: 47.973487854003906, 0.984375\n",
      "Train loss and acc of batch 15: 48.35240936279297, 0.984375\n",
      "Train loss and acc of batch 16: 48.35240936279297, 0.984375\n",
      "Train loss and acc of batch 17: 48.50992202758789, 0.984375\n",
      "Train loss and acc of batch 18: 48.63824462890625, 0.96875\n",
      "Train loss and acc of batch 19: 47.75667953491211, 1.0\n",
      "Train loss and acc of batch 20: 47.75666809082031, 1.0\n",
      "Train loss and acc of batch 21: 48.35236358642578, 0.984375\n",
      "Train loss and acc of batch 22: 48.35235595703125, 0.984375\n",
      "Train loss and acc of batch 23: 47.75663757324219, 1.0\n",
      "Train loss and acc of batch 24: 48.35234069824219, 0.984375\n",
      "Train loss and acc of batch 25: 47.75662612915039, 1.0\n",
      "Train loss and acc of batch 26: 47.75661849975586, 1.0\n",
      "Train loss and acc of batch 27: 47.75661087036133, 1.0\n",
      "Train loss and acc of batch 28: 47.7566032409668, 1.0\n",
      "Train loss and acc of batch 29: 48.352294921875, 0.984375\n",
      "Train loss and acc of batch 30: 47.7565803527832, 1.0\n",
      "Train loss and acc of batch 31: 47.97333526611328, 0.984375\n",
      "Train loss and acc of batch 32: 47.756568908691406, 1.0\n",
      "Train loss and acc of batch 33: 47.756553649902344, 1.0\n",
      "Train loss and acc of batch 34: 48.35224914550781, 0.984375\n",
      "Train loss and acc of batch 35: 48.190067291259766, 0.96875\n",
      "Train loss and acc of batch 36: 47.75653076171875, 1.0\n",
      "Train loss and acc of batch 37: 48.509742736816406, 0.984375\n",
      "Train loss and acc of batch 38: 49.105430603027344, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 39: 47.9732666015625, 0.984375\n",
      "Train loss and acc of batch 40: 47.756492614746094, 1.0\n",
      "Train loss and acc of batch 41: 49.105411529541016, 0.96875\n",
      "Train loss and acc of batch 42: 47.75647735595703, 1.0\n",
      "Train loss and acc of batch 43: 48.35216522216797, 0.984375\n",
      "Train loss and acc of batch 44: 47.75646209716797, 1.0\n",
      "Train loss and acc of batch 45: 48.352149963378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.04229736328125, 0.984375\n",
      "Train loss and acc of batch 47: 47.756431579589844, 1.0\n",
      "Train loss and acc of batch 48: 47.75641632080078, 1.0\n",
      "Train loss and acc of batch 49: 47.75641632080078, 1.0\n",
      "Train loss and acc of batch 50: 48.35211181640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.105323791503906, 0.96875\n",
      "Train loss and acc of batch 52: 49.01222610473633, 0.953125\n",
      "Train loss and acc of batch 53: 47.756378173828125, 1.0\n",
      "Train loss and acc of batch 54: 47.97312927246094, 0.984375\n",
      "Train loss and acc of batch 55: 47.75636291503906, 1.0\n",
      "Train loss and acc of batch 56: 47.7563591003418, 1.0\n",
      "Train loss and acc of batch 57: 48.35204315185547, 0.984375\n",
      "Train loss and acc of batch 58: 47.7563362121582, 1.0\n",
      "Train loss and acc of batch 59: 47.75632858276367, 1.0\n",
      "Train loss and acc of batch 60: 47.756317138671875, 1.0\n",
      "Train loss and acc of batch 61: 47.756309509277344, 1.0\n",
      "Train loss and acc of batch 62: 47.75629806518555, 1.0\n",
      "Train loss and acc of batch 63: 48.94769287109375, 0.96875\n",
      "Train loss and acc of batch 64: 47.973052978515625, 0.984375\n",
      "Train loss and acc of batch 65: 47.75627517700195, 1.0\n",
      "Train loss and acc of batch 66: 47.75625991821289, 1.0\n",
      "Train loss and acc of batch 67: 48.568721771240234, 0.96875\n",
      "Train loss and acc of batch 68: 48.35194396972656, 0.984375\n",
      "Train loss and acc of batch 69: 47.97300720214844, 0.984375\n",
      "Train loss and acc of batch 70: 47.7562255859375, 1.0\n",
      "Training accuracy and loss of epoch #478: 0.9897, 48.0774\n",
      "Saved model by train loss 48.077421859956125\n",
      "Train loss and acc of batch 0: 47.75621795654297, 1.0\n",
      "Train loss and acc of batch 1: 47.75621032714844, 1.0\n",
      "Train loss and acc of batch 2: 47.75619888305664, 1.0\n",
      "Train loss and acc of batch 3: 47.97295379638672, 0.984375\n",
      "Train loss and acc of batch 4: 47.75618362426758, 1.0\n",
      "Train loss and acc of batch 5: 49.10509490966797, 0.96875\n",
      "Train loss and acc of batch 6: 48.25878143310547, 0.96875\n",
      "Train loss and acc of batch 7: 47.75615692138672, 1.0\n",
      "Train loss and acc of batch 8: 48.35185241699219, 0.984375\n",
      "Train loss and acc of batch 9: 48.0419921875, 0.984375\n",
      "Train loss and acc of batch 10: 47.756126403808594, 1.0\n",
      "Train loss and acc of batch 11: 47.75611877441406, 1.0\n",
      "Train loss and acc of batch 12: 48.50933837890625, 0.984375\n",
      "Train loss and acc of batch 13: 47.972869873046875, 0.984375\n",
      "Train loss and acc of batch 14: 47.97285461425781, 0.984375\n",
      "Train loss and acc of batch 15: 48.35179138183594, 0.984375\n",
      "Train loss and acc of batch 16: 48.351783752441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.50929260253906, 0.984375\n",
      "Train loss and acc of batch 18: 48.63761520385742, 0.96875\n",
      "Train loss and acc of batch 19: 47.75605010986328, 1.0\n",
      "Train loss and acc of batch 20: 47.75604248046875, 1.0\n",
      "Train loss and acc of batch 21: 48.35173797607422, 0.984375\n",
      "Train loss and acc of batch 22: 48.351722717285156, 0.984375\n",
      "Train loss and acc of batch 23: 47.75601577758789, 1.0\n",
      "Train loss and acc of batch 24: 48.351707458496094, 0.984375\n",
      "Train loss and acc of batch 25: 47.75599670410156, 1.0\n",
      "Train loss and acc of batch 26: 47.75598907470703, 1.0\n",
      "Train loss and acc of batch 27: 47.755977630615234, 1.0\n",
      "Train loss and acc of batch 28: 47.75596618652344, 1.0\n",
      "Train loss and acc of batch 29: 48.351661682128906, 0.984375\n",
      "Train loss and acc of batch 30: 47.75595474243164, 1.0\n",
      "Train loss and acc of batch 31: 47.97270965576172, 0.984375\n",
      "Train loss and acc of batch 32: 47.75593566894531, 1.0\n",
      "Train loss and acc of batch 33: 47.755924224853516, 1.0\n",
      "Train loss and acc of batch 34: 48.35161590576172, 0.984375\n",
      "Train loss and acc of batch 35: 48.18943786621094, 0.96875\n",
      "Train loss and acc of batch 36: 47.75590133666992, 1.0\n",
      "Train loss and acc of batch 37: 48.50911331176758, 0.984375\n",
      "Train loss and acc of batch 38: 49.10480499267578, 0.96875\n",
      "Train loss and acc of batch 39: 47.972633361816406, 0.984375\n",
      "Train loss and acc of batch 40: 47.755863189697266, 1.0\n",
      "Train loss and acc of batch 41: 49.10478591918945, 0.96875\n",
      "Train loss and acc of batch 42: 47.75584411621094, 1.0\n",
      "Train loss and acc of batch 43: 48.351539611816406, 0.984375\n",
      "Train loss and acc of batch 44: 47.755828857421875, 1.0\n",
      "Train loss and acc of batch 45: 48.351524353027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.041664123535156, 0.984375\n",
      "Train loss and acc of batch 47: 47.755802154541016, 1.0\n",
      "Train loss and acc of batch 48: 47.75579071044922, 1.0\n",
      "Train loss and acc of batch 49: 47.75578689575195, 1.0\n",
      "Train loss and acc of batch 50: 48.351478576660156, 0.984375\n",
      "Train loss and acc of batch 51: 49.10469055175781, 0.96875\n",
      "Train loss and acc of batch 52: 49.0115966796875, 0.953125\n",
      "Train loss and acc of batch 53: 47.7557487487793, 1.0\n",
      "Train loss and acc of batch 54: 47.972503662109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.75572967529297, 1.0\n",
      "Train loss and acc of batch 56: 47.75572204589844, 1.0\n",
      "Train loss and acc of batch 57: 48.351417541503906, 0.984375\n",
      "Train loss and acc of batch 58: 47.755706787109375, 1.0\n",
      "Train loss and acc of batch 59: 47.75569534301758, 1.0\n",
      "Train loss and acc of batch 60: 47.75568771362305, 1.0\n",
      "Train loss and acc of batch 61: 47.75567626953125, 1.0\n",
      "Train loss and acc of batch 62: 47.75566864013672, 1.0\n",
      "Train loss and acc of batch 63: 48.94706344604492, 0.96875\n",
      "Train loss and acc of batch 64: 47.97241973876953, 0.984375\n",
      "Train loss and acc of batch 65: 47.75564193725586, 1.0\n",
      "Train loss and acc of batch 66: 47.755638122558594, 1.0\n",
      "Train loss and acc of batch 67: 48.568092346191406, 0.96875\n",
      "Train loss and acc of batch 68: 48.351318359375, 0.984375\n",
      "Train loss and acc of batch 69: 47.972373962402344, 0.984375\n",
      "Train loss and acc of batch 70: 47.75559616088867, 1.0\n",
      "Training accuracy and loss of epoch #479: 0.9897, 48.0768\n",
      "Saved model by train loss 48.07679195135412\n",
      "Train loss and acc of batch 0: 47.75558853149414, 1.0\n",
      "Train loss and acc of batch 1: 47.75558090209961, 1.0\n",
      "Train loss and acc of batch 2: 47.75556945800781, 1.0\n",
      "Train loss and acc of batch 3: 47.972328186035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.755550384521484, 1.0\n",
      "Train loss and acc of batch 5: 49.104469299316406, 0.96875\n",
      "Train loss and acc of batch 6: 48.258155822753906, 0.96875\n",
      "Train loss and acc of batch 7: 47.75552749633789, 1.0\n",
      "Train loss and acc of batch 8: 48.351219177246094, 0.984375\n",
      "Train loss and acc of batch 9: 48.041358947753906, 0.984375\n",
      "Train loss and acc of batch 10: 47.75550079345703, 1.0\n",
      "Train loss and acc of batch 11: 47.7554931640625, 1.0\n",
      "Train loss and acc of batch 12: 48.508705139160156, 0.984375\n",
      "Train loss and acc of batch 13: 47.97223663330078, 0.984375\n",
      "Train loss and acc of batch 14: 47.97222900390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.351158142089844, 0.984375\n",
      "Train loss and acc of batch 16: 48.35115051269531, 0.984375\n",
      "Train loss and acc of batch 17: 48.508663177490234, 0.984375\n",
      "Train loss and acc of batch 18: 48.63698196411133, 0.96875\n",
      "Train loss and acc of batch 19: 47.75541687011719, 1.0\n",
      "Train loss and acc of batch 20: 47.75541305541992, 1.0\n",
      "Train loss and acc of batch 21: 48.351097106933594, 0.984375\n",
      "Train loss and acc of batch 22: 48.35108947753906, 0.984375\n",
      "Train loss and acc of batch 23: 47.7553825378418, 1.0\n",
      "Train loss and acc of batch 24: 48.35107421875, 0.984375\n",
      "Train loss and acc of batch 25: 47.755367279052734, 1.0\n",
      "Train loss and acc of batch 26: 47.75535583496094, 1.0\n",
      "Train loss and acc of batch 27: 47.75534439086914, 1.0\n",
      "Train loss and acc of batch 28: 47.75533676147461, 1.0\n",
      "Train loss and acc of batch 29: 48.35102844238281, 0.984375\n",
      "Train loss and acc of batch 30: 47.75532150268555, 1.0\n",
      "Train loss and acc of batch 31: 47.972076416015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.75530242919922, 1.0\n",
      "Train loss and acc of batch 33: 47.75529098510742, 1.0\n",
      "Train loss and acc of batch 34: 48.350990295410156, 0.984375\n",
      "Train loss and acc of batch 35: 48.18880081176758, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 36: 47.75526428222656, 1.0\n",
      "Train loss and acc of batch 37: 48.508480072021484, 0.984375\n",
      "Train loss and acc of batch 38: 49.10417175292969, 0.96875\n",
      "Train loss and acc of batch 39: 47.972007751464844, 0.984375\n",
      "Train loss and acc of batch 40: 47.75523376464844, 1.0\n",
      "Train loss and acc of batch 41: 49.104148864746094, 0.96875\n",
      "Train loss and acc of batch 42: 47.75521469116211, 1.0\n",
      "Train loss and acc of batch 43: 48.35090637207031, 0.984375\n",
      "Train loss and acc of batch 44: 47.75519561767578, 1.0\n",
      "Train loss and acc of batch 45: 48.35089111328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.04103088378906, 0.984375\n",
      "Train loss and acc of batch 47: 47.755165100097656, 1.0\n",
      "Train loss and acc of batch 48: 47.75516128540039, 1.0\n",
      "Train loss and acc of batch 49: 47.75515365600586, 1.0\n",
      "Train loss and acc of batch 50: 48.35084533691406, 0.984375\n",
      "Train loss and acc of batch 51: 49.10405731201172, 0.96875\n",
      "Train loss and acc of batch 52: 49.010963439941406, 0.953125\n",
      "Train loss and acc of batch 53: 47.75511932373047, 1.0\n",
      "Train loss and acc of batch 54: 47.97187042236328, 0.984375\n",
      "Train loss and acc of batch 55: 47.755096435546875, 1.0\n",
      "Train loss and acc of batch 56: 47.755088806152344, 1.0\n",
      "Train loss and acc of batch 57: 48.35078430175781, 0.984375\n",
      "Train loss and acc of batch 58: 47.755069732666016, 1.0\n",
      "Train loss and acc of batch 59: 47.755062103271484, 1.0\n",
      "Train loss and acc of batch 60: 47.75505065917969, 1.0\n",
      "Train loss and acc of batch 61: 47.75504684448242, 1.0\n",
      "Train loss and acc of batch 62: 47.75503921508789, 1.0\n",
      "Train loss and acc of batch 63: 48.94643020629883, 0.96875\n",
      "Train loss and acc of batch 64: 47.971778869628906, 0.984375\n",
      "Train loss and acc of batch 65: 47.75501251220703, 1.0\n",
      "Train loss and acc of batch 66: 47.75499725341797, 1.0\n",
      "Train loss and acc of batch 67: 48.56745910644531, 0.96875\n",
      "Train loss and acc of batch 68: 48.350685119628906, 0.984375\n",
      "Train loss and acc of batch 69: 47.97173309326172, 0.984375\n",
      "Train loss and acc of batch 70: 47.75496292114258, 1.0\n",
      "Training accuracy and loss of epoch #480: 0.9897, 48.0762\n",
      "Saved model by train loss 48.076159624986246\n",
      "Train loss and acc of batch 0: 47.75495529174805, 1.0\n",
      "Train loss and acc of batch 1: 47.754947662353516, 1.0\n",
      "Train loss and acc of batch 2: 47.75493621826172, 1.0\n",
      "Train loss and acc of batch 3: 47.97169494628906, 0.984375\n",
      "Train loss and acc of batch 4: 47.754920959472656, 1.0\n",
      "Train loss and acc of batch 5: 49.10383605957031, 0.96875\n",
      "Train loss and acc of batch 6: 48.25752258300781, 0.96875\n",
      "Train loss and acc of batch 7: 47.7548942565918, 1.0\n",
      "Train loss and acc of batch 8: 48.3505859375, 0.984375\n",
      "Train loss and acc of batch 9: 48.04072570800781, 0.984375\n",
      "Train loss and acc of batch 10: 47.75486755371094, 1.0\n",
      "Train loss and acc of batch 11: 47.754859924316406, 1.0\n",
      "Train loss and acc of batch 12: 48.50807189941406, 0.984375\n",
      "Train loss and acc of batch 13: 47.97161102294922, 0.984375\n",
      "Train loss and acc of batch 14: 47.971595764160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.35052490234375, 0.984375\n",
      "Train loss and acc of batch 16: 48.35051727294922, 0.984375\n",
      "Train loss and acc of batch 17: 48.50802993774414, 0.984375\n",
      "Train loss and acc of batch 18: 48.636348724365234, 0.96875\n",
      "Train loss and acc of batch 19: 47.754791259765625, 1.0\n",
      "Train loss and acc of batch 20: 47.75477600097656, 1.0\n",
      "Train loss and acc of batch 21: 48.3504638671875, 0.984375\n",
      "Train loss and acc of batch 22: 48.3504638671875, 0.984375\n",
      "Train loss and acc of batch 23: 47.7547492980957, 1.0\n",
      "Train loss and acc of batch 24: 48.35044860839844, 0.984375\n",
      "Train loss and acc of batch 25: 47.75473403930664, 1.0\n",
      "Train loss and acc of batch 26: 47.754722595214844, 1.0\n",
      "Train loss and acc of batch 27: 47.75471878051758, 1.0\n",
      "Train loss and acc of batch 28: 47.75471115112305, 1.0\n",
      "Train loss and acc of batch 29: 48.35040283203125, 0.984375\n",
      "Train loss and acc of batch 30: 47.75469207763672, 1.0\n",
      "Train loss and acc of batch 31: 47.97144317626953, 0.984375\n",
      "Train loss and acc of batch 32: 47.754669189453125, 1.0\n",
      "Train loss and acc of batch 33: 47.754669189453125, 1.0\n",
      "Train loss and acc of batch 34: 48.35035705566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.188175201416016, 0.96875\n",
      "Train loss and acc of batch 36: 47.754634857177734, 1.0\n",
      "Train loss and acc of batch 37: 48.50784683227539, 0.984375\n",
      "Train loss and acc of batch 38: 49.103538513183594, 0.96875\n",
      "Train loss and acc of batch 39: 47.97138214111328, 0.984375\n",
      "Train loss and acc of batch 40: 47.754600524902344, 1.0\n",
      "Train loss and acc of batch 41: 49.10352325439453, 0.96875\n",
      "Train loss and acc of batch 42: 47.754581451416016, 1.0\n",
      "Train loss and acc of batch 43: 48.35027313232422, 0.984375\n",
      "Train loss and acc of batch 44: 47.75456619262695, 1.0\n",
      "Train loss and acc of batch 45: 48.350257873535156, 0.984375\n",
      "Train loss and acc of batch 46: 48.04039764404297, 0.984375\n",
      "Train loss and acc of batch 47: 47.75454330444336, 1.0\n",
      "Train loss and acc of batch 48: 47.7545280456543, 1.0\n",
      "Train loss and acc of batch 49: 47.75452423095703, 1.0\n",
      "Train loss and acc of batch 50: 48.35021209716797, 0.984375\n",
      "Train loss and acc of batch 51: 49.103431701660156, 0.96875\n",
      "Train loss and acc of batch 52: 49.010337829589844, 0.953125\n",
      "Train loss and acc of batch 53: 47.75448226928711, 1.0\n",
      "Train loss and acc of batch 54: 47.97123718261719, 0.984375\n",
      "Train loss and acc of batch 55: 47.75446701049805, 1.0\n",
      "Train loss and acc of batch 56: 47.75446319580078, 1.0\n",
      "Train loss and acc of batch 57: 48.35015106201172, 0.984375\n",
      "Train loss and acc of batch 58: 47.75444412231445, 1.0\n",
      "Train loss and acc of batch 59: 47.754432678222656, 1.0\n",
      "Train loss and acc of batch 60: 47.754425048828125, 1.0\n",
      "Train loss and acc of batch 61: 47.754417419433594, 1.0\n",
      "Train loss and acc of batch 62: 47.75440979003906, 1.0\n",
      "Train loss and acc of batch 63: 48.945796966552734, 0.96875\n",
      "Train loss and acc of batch 64: 47.971153259277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.75437545776367, 1.0\n",
      "Train loss and acc of batch 66: 47.754371643066406, 1.0\n",
      "Train loss and acc of batch 67: 48.566829681396484, 0.96875\n",
      "Train loss and acc of batch 68: 48.35005187988281, 0.984375\n",
      "Train loss and acc of batch 69: 47.971107482910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.754337310791016, 1.0\n",
      "Training accuracy and loss of epoch #481: 0.9897, 48.0755\n",
      "Saved model by train loss 48.07552912537481\n",
      "Train loss and acc of batch 0: 47.75432586669922, 1.0\n",
      "Train loss and acc of batch 1: 47.75431823730469, 1.0\n",
      "Train loss and acc of batch 2: 47.754310607910156, 1.0\n",
      "Train loss and acc of batch 3: 47.97106170654297, 0.984375\n",
      "Train loss and acc of batch 4: 47.754295349121094, 1.0\n",
      "Train loss and acc of batch 5: 49.10321044921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.25688934326172, 0.96875\n",
      "Train loss and acc of batch 7: 47.75426483154297, 1.0\n",
      "Train loss and acc of batch 8: 48.349952697753906, 0.984375\n",
      "Train loss and acc of batch 9: 48.04010009765625, 0.984375\n",
      "Train loss and acc of batch 10: 47.754234313964844, 1.0\n",
      "Train loss and acc of batch 11: 47.75422668457031, 1.0\n",
      "Train loss and acc of batch 12: 48.507442474365234, 0.984375\n",
      "Train loss and acc of batch 13: 47.970977783203125, 0.984375\n",
      "Train loss and acc of batch 14: 47.970970153808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.349891662597656, 0.984375\n",
      "Train loss and acc of batch 16: 48.349884033203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.50739669799805, 0.984375\n",
      "Train loss and acc of batch 18: 48.635719299316406, 0.96875\n",
      "Train loss and acc of batch 19: 47.75416564941406, 1.0\n",
      "Train loss and acc of batch 20: 47.754150390625, 1.0\n",
      "Train loss and acc of batch 21: 48.34984588623047, 0.984375\n",
      "Train loss and acc of batch 22: 48.349830627441406, 0.984375\n",
      "Train loss and acc of batch 23: 47.75412368774414, 1.0\n",
      "Train loss and acc of batch 24: 48.349815368652344, 0.984375\n",
      "Train loss and acc of batch 25: 47.75410461425781, 1.0\n",
      "Train loss and acc of batch 26: 47.75409698486328, 1.0\n",
      "Train loss and acc of batch 27: 47.754085540771484, 1.0\n",
      "Train loss and acc of batch 28: 47.75408172607422, 1.0\n",
      "Train loss and acc of batch 29: 48.349769592285156, 0.984375\n",
      "Train loss and acc of batch 30: 47.75406265258789, 1.0\n",
      "Train loss and acc of batch 31: 47.97080993652344, 0.984375\n",
      "Train loss and acc of batch 32: 47.75404739379883, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.75403594970703, 1.0\n",
      "Train loss and acc of batch 34: 48.34972381591797, 0.984375\n",
      "Train loss and acc of batch 35: 48.18754577636719, 0.96875\n",
      "Train loss and acc of batch 36: 47.75401306152344, 1.0\n",
      "Train loss and acc of batch 37: 48.50722122192383, 0.984375\n",
      "Train loss and acc of batch 38: 49.10291290283203, 0.96875\n",
      "Train loss and acc of batch 39: 47.970741271972656, 0.984375\n",
      "Train loss and acc of batch 40: 47.753971099853516, 1.0\n",
      "Train loss and acc of batch 41: 49.10289001464844, 0.96875\n",
      "Train loss and acc of batch 42: 47.75395965576172, 1.0\n",
      "Train loss and acc of batch 43: 48.349647521972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.75393295288086, 1.0\n",
      "Train loss and acc of batch 45: 48.34962463378906, 0.984375\n",
      "Train loss and acc of batch 46: 48.039772033691406, 0.984375\n",
      "Train loss and acc of batch 47: 47.75391387939453, 1.0\n",
      "Train loss and acc of batch 48: 47.75389862060547, 1.0\n",
      "Train loss and acc of batch 49: 47.7538948059082, 1.0\n",
      "Train loss and acc of batch 50: 48.349586486816406, 0.984375\n",
      "Train loss and acc of batch 51: 49.10279846191406, 0.96875\n",
      "Train loss and acc of batch 52: 49.00970458984375, 0.953125\n",
      "Train loss and acc of batch 53: 47.75385665893555, 1.0\n",
      "Train loss and acc of batch 54: 47.970611572265625, 0.984375\n",
      "Train loss and acc of batch 55: 47.753841400146484, 1.0\n",
      "Train loss and acc of batch 56: 47.75383377075195, 1.0\n",
      "Train loss and acc of batch 57: 48.349525451660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.753814697265625, 1.0\n",
      "Train loss and acc of batch 59: 47.75380325317383, 1.0\n",
      "Train loss and acc of batch 60: 47.7537956237793, 1.0\n",
      "Train loss and acc of batch 61: 47.753787994384766, 1.0\n",
      "Train loss and acc of batch 62: 47.7537727355957, 1.0\n",
      "Train loss and acc of batch 63: 48.94517135620117, 0.96875\n",
      "Train loss and acc of batch 64: 47.97052764892578, 0.984375\n",
      "Train loss and acc of batch 65: 47.753753662109375, 1.0\n",
      "Train loss and acc of batch 66: 47.75373840332031, 1.0\n",
      "Train loss and acc of batch 67: 48.566200256347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.34942626953125, 0.984375\n",
      "Train loss and acc of batch 69: 47.970481872558594, 0.984375\n",
      "Train loss and acc of batch 70: 47.75370788574219, 1.0\n",
      "Training accuracy and loss of epoch #482: 0.9897, 48.0749\n",
      "Saved model by train loss 48.07490002269476\n",
      "Train loss and acc of batch 0: 47.75369644165039, 1.0\n",
      "Train loss and acc of batch 1: 47.753692626953125, 1.0\n",
      "Train loss and acc of batch 2: 47.75367736816406, 1.0\n",
      "Train loss and acc of batch 3: 47.970436096191406, 0.984375\n",
      "Train loss and acc of batch 4: 47.753665924072266, 1.0\n",
      "Train loss and acc of batch 5: 49.102577209472656, 0.96875\n",
      "Train loss and acc of batch 6: 48.256263732910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.75363540649414, 1.0\n",
      "Train loss and acc of batch 8: 48.349327087402344, 0.984375\n",
      "Train loss and acc of batch 9: 48.039466857910156, 0.984375\n",
      "Train loss and acc of batch 10: 47.75360870361328, 1.0\n",
      "Train loss and acc of batch 11: 47.753597259521484, 1.0\n",
      "Train loss and acc of batch 12: 48.50681686401367, 0.984375\n",
      "Train loss and acc of batch 13: 47.97034454345703, 0.984375\n",
      "Train loss and acc of batch 14: 47.9703369140625, 0.984375\n",
      "Train loss and acc of batch 15: 48.349266052246094, 0.984375\n",
      "Train loss and acc of batch 16: 48.34925842285156, 0.984375\n",
      "Train loss and acc of batch 17: 48.50676727294922, 0.984375\n",
      "Train loss and acc of batch 18: 48.63509750366211, 0.96875\n",
      "Train loss and acc of batch 19: 47.75352478027344, 1.0\n",
      "Train loss and acc of batch 20: 47.75352096557617, 1.0\n",
      "Train loss and acc of batch 21: 48.349212646484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.349205017089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.75349807739258, 1.0\n",
      "Train loss and acc of batch 24: 48.34918212890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.753475189208984, 1.0\n",
      "Train loss and acc of batch 26: 47.75346374511719, 1.0\n",
      "Train loss and acc of batch 27: 47.75345993041992, 1.0\n",
      "Train loss and acc of batch 28: 47.75344467163086, 1.0\n",
      "Train loss and acc of batch 29: 48.349143981933594, 0.984375\n",
      "Train loss and acc of batch 30: 47.75343322753906, 1.0\n",
      "Train loss and acc of batch 31: 47.970184326171875, 0.984375\n",
      "Train loss and acc of batch 32: 47.753414154052734, 1.0\n",
      "Train loss and acc of batch 33: 47.75340270996094, 1.0\n",
      "Train loss and acc of batch 34: 48.349098205566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.186920166015625, 0.96875\n",
      "Train loss and acc of batch 36: 47.75337600708008, 1.0\n",
      "Train loss and acc of batch 37: 48.506591796875, 0.984375\n",
      "Train loss and acc of batch 38: 49.10227966308594, 0.96875\n",
      "Train loss and acc of batch 39: 47.970115661621094, 0.984375\n",
      "Train loss and acc of batch 40: 47.75334548950195, 1.0\n",
      "Train loss and acc of batch 41: 49.102264404296875, 0.96875\n",
      "Train loss and acc of batch 42: 47.753326416015625, 1.0\n",
      "Train loss and acc of batch 43: 48.34901428222656, 0.984375\n",
      "Train loss and acc of batch 44: 47.7533073425293, 1.0\n",
      "Train loss and acc of batch 45: 48.3489990234375, 0.984375\n",
      "Train loss and acc of batch 46: 48.03913879394531, 0.984375\n",
      "Train loss and acc of batch 47: 47.75328063964844, 1.0\n",
      "Train loss and acc of batch 48: 47.75326919555664, 1.0\n",
      "Train loss and acc of batch 49: 47.75326156616211, 1.0\n",
      "Train loss and acc of batch 50: 48.34895324707031, 0.984375\n",
      "Train loss and acc of batch 51: 49.1021728515625, 0.96875\n",
      "Train loss and acc of batch 52: 49.00907516479492, 0.953125\n",
      "Train loss and acc of batch 53: 47.75322341918945, 1.0\n",
      "Train loss and acc of batch 54: 47.96998596191406, 0.984375\n",
      "Train loss and acc of batch 55: 47.753211975097656, 1.0\n",
      "Train loss and acc of batch 56: 47.75320053100586, 1.0\n",
      "Train loss and acc of batch 57: 48.34889221191406, 0.984375\n",
      "Train loss and acc of batch 58: 47.75318145751953, 1.0\n",
      "Train loss and acc of batch 59: 47.753177642822266, 1.0\n",
      "Train loss and acc of batch 60: 47.75316619873047, 1.0\n",
      "Train loss and acc of batch 61: 47.75315475463867, 1.0\n",
      "Train loss and acc of batch 62: 47.75314712524414, 1.0\n",
      "Train loss and acc of batch 63: 48.944541931152344, 0.96875\n",
      "Train loss and acc of batch 64: 47.96989440917969, 0.984375\n",
      "Train loss and acc of batch 65: 47.75312423706055, 1.0\n",
      "Train loss and acc of batch 66: 47.75311279296875, 1.0\n",
      "Train loss and acc of batch 67: 48.56556701660156, 0.96875\n",
      "Train loss and acc of batch 68: 48.34880065917969, 0.984375\n",
      "Train loss and acc of batch 69: 47.9698486328125, 0.984375\n",
      "Train loss and acc of batch 70: 47.75307846069336, 1.0\n",
      "Training accuracy and loss of epoch #483: 0.9897, 48.0743\n",
      "Saved model by train loss 48.07427038273341\n",
      "Train loss and acc of batch 0: 47.75306701660156, 1.0\n",
      "Train loss and acc of batch 1: 47.75305938720703, 1.0\n",
      "Train loss and acc of batch 2: 47.7530517578125, 1.0\n",
      "Train loss and acc of batch 3: 47.969810485839844, 0.984375\n",
      "Train loss and acc of batch 4: 47.753028869628906, 1.0\n",
      "Train loss and acc of batch 5: 49.101951599121094, 0.96875\n",
      "Train loss and acc of batch 6: 48.25563049316406, 0.96875\n",
      "Train loss and acc of batch 7: 47.75300598144531, 1.0\n",
      "Train loss and acc of batch 8: 48.34870147705078, 0.984375\n",
      "Train loss and acc of batch 9: 48.038841247558594, 0.984375\n",
      "Train loss and acc of batch 10: 47.75297927856445, 1.0\n",
      "Train loss and acc of batch 11: 47.75297164916992, 1.0\n",
      "Train loss and acc of batch 12: 48.50618362426758, 0.984375\n",
      "Train loss and acc of batch 13: 47.96971893310547, 0.984375\n",
      "Train loss and acc of batch 14: 47.96971130371094, 0.984375\n",
      "Train loss and acc of batch 15: 48.3486328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.34862518310547, 0.984375\n",
      "Train loss and acc of batch 17: 48.506141662597656, 0.984375\n",
      "Train loss and acc of batch 18: 48.63446044921875, 0.96875\n",
      "Train loss and acc of batch 19: 47.752899169921875, 1.0\n",
      "Train loss and acc of batch 20: 47.752891540527344, 1.0\n",
      "Train loss and acc of batch 21: 48.34858703613281, 0.984375\n",
      "Train loss and acc of batch 22: 48.34857177734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.75286102294922, 1.0\n",
      "Train loss and acc of batch 24: 48.34855651855469, 0.984375\n",
      "Train loss and acc of batch 25: 47.752845764160156, 1.0\n",
      "Train loss and acc of batch 26: 47.752838134765625, 1.0\n",
      "Train loss and acc of batch 27: 47.75282669067383, 1.0\n",
      "Train loss and acc of batch 28: 47.7528190612793, 1.0\n",
      "Train loss and acc of batch 29: 48.3485107421875, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 30: 47.752803802490234, 1.0\n",
      "Train loss and acc of batch 31: 47.96955871582031, 0.984375\n",
      "Train loss and acc of batch 32: 47.752784729003906, 1.0\n",
      "Train loss and acc of batch 33: 47.752769470214844, 1.0\n",
      "Train loss and acc of batch 34: 48.34846496582031, 0.984375\n",
      "Train loss and acc of batch 35: 48.18628692626953, 0.96875\n",
      "Train loss and acc of batch 36: 47.752750396728516, 1.0\n",
      "Train loss and acc of batch 37: 48.50596237182617, 0.984375\n",
      "Train loss and acc of batch 38: 49.101654052734375, 0.96875\n",
      "Train loss and acc of batch 39: 47.96949005126953, 0.984375\n",
      "Train loss and acc of batch 40: 47.752716064453125, 1.0\n",
      "Train loss and acc of batch 41: 49.101627349853516, 0.96875\n",
      "Train loss and acc of batch 42: 47.75269317626953, 1.0\n",
      "Train loss and acc of batch 43: 48.348388671875, 0.984375\n",
      "Train loss and acc of batch 44: 47.75267791748047, 1.0\n",
      "Train loss and acc of batch 45: 48.34837341308594, 0.984375\n",
      "Train loss and acc of batch 46: 48.03851318359375, 0.984375\n",
      "Train loss and acc of batch 47: 47.752647399902344, 1.0\n",
      "Train loss and acc of batch 48: 47.75264358520508, 1.0\n",
      "Train loss and acc of batch 49: 47.75263214111328, 1.0\n",
      "Train loss and acc of batch 50: 48.34832763671875, 0.984375\n",
      "Train loss and acc of batch 51: 49.101539611816406, 0.96875\n",
      "Train loss and acc of batch 52: 49.008445739746094, 0.953125\n",
      "Train loss and acc of batch 53: 47.752593994140625, 1.0\n",
      "Train loss and acc of batch 54: 47.96935272216797, 0.984375\n",
      "Train loss and acc of batch 55: 47.75257873535156, 1.0\n",
      "Train loss and acc of batch 56: 47.752567291259766, 1.0\n",
      "Train loss and acc of batch 57: 48.34825897216797, 0.984375\n",
      "Train loss and acc of batch 58: 47.75255584716797, 1.0\n",
      "Train loss and acc of batch 59: 47.75254440307617, 1.0\n",
      "Train loss and acc of batch 60: 47.752532958984375, 1.0\n",
      "Train loss and acc of batch 61: 47.752525329589844, 1.0\n",
      "Train loss and acc of batch 62: 47.75252151489258, 1.0\n",
      "Train loss and acc of batch 63: 48.943912506103516, 0.96875\n",
      "Train loss and acc of batch 64: 47.969261169433594, 0.984375\n",
      "Train loss and acc of batch 65: 47.75249099731445, 1.0\n",
      "Train loss and acc of batch 66: 47.75248336791992, 1.0\n",
      "Train loss and acc of batch 67: 48.564937591552734, 0.96875\n",
      "Train loss and acc of batch 68: 48.348167419433594, 0.984375\n",
      "Train loss and acc of batch 69: 47.969215393066406, 0.984375\n",
      "Train loss and acc of batch 70: 47.75244140625, 1.0\n",
      "Training accuracy and loss of epoch #484: 0.9897, 48.0736\n",
      "Saved model by train loss 48.07364047413141\n",
      "Train loss and acc of batch 0: 47.752437591552734, 1.0\n",
      "Train loss and acc of batch 1: 47.75242614746094, 1.0\n",
      "Train loss and acc of batch 2: 47.75242233276367, 1.0\n",
      "Train loss and acc of batch 3: 47.96916961669922, 0.984375\n",
      "Train loss and acc of batch 4: 47.752403259277344, 1.0\n",
      "Train loss and acc of batch 5: 49.101318359375, 0.96875\n",
      "Train loss and acc of batch 6: 48.255001068115234, 0.96875\n",
      "Train loss and acc of batch 7: 47.752376556396484, 1.0\n",
      "Train loss and acc of batch 8: 48.34806823730469, 0.984375\n",
      "Train loss and acc of batch 9: 48.0382080078125, 0.984375\n",
      "Train loss and acc of batch 10: 47.75234603881836, 1.0\n",
      "Train loss and acc of batch 11: 47.752342224121094, 1.0\n",
      "Train loss and acc of batch 12: 48.505558013916016, 0.984375\n",
      "Train loss and acc of batch 13: 47.969085693359375, 0.984375\n",
      "Train loss and acc of batch 14: 47.969078063964844, 0.984375\n",
      "Train loss and acc of batch 15: 48.34800720214844, 0.984375\n",
      "Train loss and acc of batch 16: 48.347999572753906, 0.984375\n",
      "Train loss and acc of batch 17: 48.50550842285156, 0.984375\n",
      "Train loss and acc of batch 18: 48.63383102416992, 0.96875\n",
      "Train loss and acc of batch 19: 47.75226974487305, 1.0\n",
      "Train loss and acc of batch 20: 47.752262115478516, 1.0\n",
      "Train loss and acc of batch 21: 48.34795379638672, 0.984375\n",
      "Train loss and acc of batch 22: 48.34794616699219, 0.984375\n",
      "Train loss and acc of batch 23: 47.75223159790039, 1.0\n",
      "Train loss and acc of batch 24: 48.347930908203125, 0.984375\n",
      "Train loss and acc of batch 25: 47.75221633911133, 1.0\n",
      "Train loss and acc of batch 26: 47.75220489501953, 1.0\n",
      "Train loss and acc of batch 27: 47.752197265625, 1.0\n",
      "Train loss and acc of batch 28: 47.75218963623047, 1.0\n",
      "Train loss and acc of batch 29: 48.347877502441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.75217056274414, 1.0\n",
      "Train loss and acc of batch 31: 47.96892547607422, 0.984375\n",
      "Train loss and acc of batch 32: 47.75215530395508, 1.0\n",
      "Train loss and acc of batch 33: 47.75214385986328, 1.0\n",
      "Train loss and acc of batch 34: 48.34783935546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.1856575012207, 0.96875\n",
      "Train loss and acc of batch 36: 47.75211715698242, 1.0\n",
      "Train loss and acc of batch 37: 48.505332946777344, 0.984375\n",
      "Train loss and acc of batch 38: 49.10102844238281, 0.96875\n",
      "Train loss and acc of batch 39: 47.96885681152344, 0.984375\n",
      "Train loss and acc of batch 40: 47.7520866394043, 1.0\n",
      "Train loss and acc of batch 41: 49.10099792480469, 0.96875\n",
      "Train loss and acc of batch 42: 47.7520637512207, 1.0\n",
      "Train loss and acc of batch 43: 48.347755432128906, 0.984375\n",
      "Train loss and acc of batch 44: 47.752044677734375, 1.0\n",
      "Train loss and acc of batch 45: 48.347740173339844, 0.984375\n",
      "Train loss and acc of batch 46: 48.037879943847656, 0.984375\n",
      "Train loss and acc of batch 47: 47.75202178955078, 1.0\n",
      "Train loss and acc of batch 48: 47.752010345458984, 1.0\n",
      "Train loss and acc of batch 49: 47.75200653076172, 1.0\n",
      "Train loss and acc of batch 50: 48.347694396972656, 0.984375\n",
      "Train loss and acc of batch 51: 49.10090637207031, 0.96875\n",
      "Train loss and acc of batch 52: 49.0078125, 0.953125\n",
      "Train loss and acc of batch 53: 47.75197219848633, 1.0\n",
      "Train loss and acc of batch 54: 47.968727111816406, 0.984375\n",
      "Train loss and acc of batch 55: 47.751953125, 1.0\n",
      "Train loss and acc of batch 56: 47.7519416809082, 1.0\n",
      "Train loss and acc of batch 57: 48.347633361816406, 0.984375\n",
      "Train loss and acc of batch 58: 47.75191879272461, 1.0\n",
      "Train loss and acc of batch 59: 47.751914978027344, 1.0\n",
      "Train loss and acc of batch 60: 47.75190353393555, 1.0\n",
      "Train loss and acc of batch 61: 47.751895904541016, 1.0\n",
      "Train loss and acc of batch 62: 47.75188446044922, 1.0\n",
      "Train loss and acc of batch 63: 48.94328308105469, 0.96875\n",
      "Train loss and acc of batch 64: 47.96863555908203, 0.984375\n",
      "Train loss and acc of batch 65: 47.75185775756836, 1.0\n",
      "Train loss and acc of batch 66: 47.75185012817383, 1.0\n",
      "Train loss and acc of batch 67: 48.56431198120117, 0.96875\n",
      "Train loss and acc of batch 68: 48.3475341796875, 0.984375\n",
      "Train loss and acc of batch 69: 47.968589782714844, 0.984375\n",
      "Train loss and acc of batch 70: 47.75181579589844, 1.0\n",
      "Training accuracy and loss of epoch #485: 0.9897, 48.0730\n",
      "Saved model by train loss 48.07301040434501\n",
      "Train loss and acc of batch 0: 47.751808166503906, 1.0\n",
      "Train loss and acc of batch 1: 47.75179672241211, 1.0\n",
      "Train loss and acc of batch 2: 47.75178909301758, 1.0\n",
      "Train loss and acc of batch 3: 47.968544006347656, 0.984375\n",
      "Train loss and acc of batch 4: 47.75177001953125, 1.0\n",
      "Train loss and acc of batch 5: 49.10069274902344, 0.96875\n",
      "Train loss and acc of batch 6: 48.25437545776367, 0.96875\n",
      "Train loss and acc of batch 7: 47.751747131347656, 1.0\n",
      "Train loss and acc of batch 8: 48.347434997558594, 0.984375\n",
      "Train loss and acc of batch 9: 48.037574768066406, 0.984375\n",
      "Train loss and acc of batch 10: 47.7517204284668, 1.0\n",
      "Train loss and acc of batch 11: 47.751712799072266, 1.0\n",
      "Train loss and acc of batch 12: 48.504920959472656, 0.984375\n",
      "Train loss and acc of batch 13: 47.96846008300781, 0.984375\n",
      "Train loss and acc of batch 14: 47.96845245361328, 0.984375\n",
      "Train loss and acc of batch 15: 48.347373962402344, 0.984375\n",
      "Train loss and acc of batch 16: 48.34736633300781, 0.984375\n",
      "Train loss and acc of batch 17: 48.504878997802734, 0.984375\n",
      "Train loss and acc of batch 18: 48.63319778442383, 0.96875\n",
      "Train loss and acc of batch 19: 47.751644134521484, 1.0\n",
      "Train loss and acc of batch 20: 47.75163269042969, 1.0\n",
      "Train loss and acc of batch 21: 48.347320556640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.347312927246094, 0.984375\n",
      "Train loss and acc of batch 23: 47.75160217285156, 1.0\n",
      "Train loss and acc of batch 24: 48.34729766845703, 0.984375\n",
      "Train loss and acc of batch 25: 47.7515869140625, 1.0\n",
      "Train loss and acc of batch 26: 47.7515754699707, 1.0\n",
      "Train loss and acc of batch 27: 47.75157165527344, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 28: 47.75156021118164, 1.0\n",
      "Train loss and acc of batch 29: 48.347251892089844, 0.984375\n",
      "Train loss and acc of batch 30: 47.75154495239258, 1.0\n",
      "Train loss and acc of batch 31: 47.968292236328125, 0.984375\n",
      "Train loss and acc of batch 32: 47.751522064208984, 1.0\n",
      "Train loss and acc of batch 33: 47.75151824951172, 1.0\n",
      "Train loss and acc of batch 34: 48.347206115722656, 0.984375\n",
      "Train loss and acc of batch 35: 48.18502426147461, 0.96875\n",
      "Train loss and acc of batch 36: 47.75148391723633, 1.0\n",
      "Train loss and acc of batch 37: 48.504703521728516, 0.984375\n",
      "Train loss and acc of batch 38: 49.10039520263672, 0.96875\n",
      "Train loss and acc of batch 39: 47.968223571777344, 0.984375\n",
      "Train loss and acc of batch 40: 47.7514533996582, 1.0\n",
      "Train loss and acc of batch 41: 49.100372314453125, 0.96875\n",
      "Train loss and acc of batch 42: 47.75143814086914, 1.0\n",
      "Train loss and acc of batch 43: 48.347129821777344, 0.984375\n",
      "Train loss and acc of batch 44: 47.75141906738281, 1.0\n",
      "Train loss and acc of batch 45: 48.34710693359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.037254333496094, 0.984375\n",
      "Train loss and acc of batch 47: 47.75139236450195, 1.0\n",
      "Train loss and acc of batch 48: 47.75138473510742, 1.0\n",
      "Train loss and acc of batch 49: 47.751373291015625, 1.0\n",
      "Train loss and acc of batch 50: 48.347068786621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.10028076171875, 0.96875\n",
      "Train loss and acc of batch 52: 49.00718688964844, 0.953125\n",
      "Train loss and acc of batch 53: 47.75133514404297, 1.0\n",
      "Train loss and acc of batch 54: 47.96809387207031, 0.984375\n",
      "Train loss and acc of batch 55: 47.751319885253906, 1.0\n",
      "Train loss and acc of batch 56: 47.751312255859375, 1.0\n",
      "Train loss and acc of batch 57: 48.347007751464844, 0.984375\n",
      "Train loss and acc of batch 58: 47.75129699707031, 1.0\n",
      "Train loss and acc of batch 59: 47.75128173828125, 1.0\n",
      "Train loss and acc of batch 60: 47.75127410888672, 1.0\n",
      "Train loss and acc of batch 61: 47.75126647949219, 1.0\n",
      "Train loss and acc of batch 62: 47.75126266479492, 1.0\n",
      "Train loss and acc of batch 63: 48.94265365600586, 0.96875\n",
      "Train loss and acc of batch 64: 47.96800994873047, 0.984375\n",
      "Train loss and acc of batch 65: 47.7512321472168, 1.0\n",
      "Train loss and acc of batch 66: 47.751220703125, 1.0\n",
      "Train loss and acc of batch 67: 48.563682556152344, 0.96875\n",
      "Train loss and acc of batch 68: 48.346900939941406, 0.984375\n",
      "Train loss and acc of batch 69: 47.96795654296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.75118637084961, 1.0\n",
      "Training accuracy and loss of epoch #486: 0.9897, 48.0724\n",
      "Saved model by train loss 48.072380871839925\n",
      "Train loss and acc of batch 0: 47.75117874145508, 1.0\n",
      "Train loss and acc of batch 1: 47.75117492675781, 1.0\n",
      "Train loss and acc of batch 2: 47.75115966796875, 1.0\n",
      "Train loss and acc of batch 3: 47.967918395996094, 0.984375\n",
      "Train loss and acc of batch 4: 47.75114440917969, 1.0\n",
      "Train loss and acc of batch 5: 49.100059509277344, 0.96875\n",
      "Train loss and acc of batch 6: 48.25374221801758, 0.96875\n",
      "Train loss and acc of batch 7: 47.75111770629883, 1.0\n",
      "Train loss and acc of batch 8: 48.34680938720703, 0.984375\n",
      "Train loss and acc of batch 9: 48.036949157714844, 0.984375\n",
      "Train loss and acc of batch 10: 47.75109100341797, 1.0\n",
      "Train loss and acc of batch 11: 47.75107955932617, 1.0\n",
      "Train loss and acc of batch 12: 48.504295349121094, 0.984375\n",
      "Train loss and acc of batch 13: 47.96782684326172, 0.984375\n",
      "Train loss and acc of batch 14: 47.96781921386719, 0.984375\n",
      "Train loss and acc of batch 15: 48.34674835205078, 0.984375\n",
      "Train loss and acc of batch 16: 48.34674072265625, 0.984375\n",
      "Train loss and acc of batch 17: 48.50424575805664, 0.984375\n",
      "Train loss and acc of batch 18: 48.63257598876953, 0.96875\n",
      "Train loss and acc of batch 19: 47.751007080078125, 1.0\n",
      "Train loss and acc of batch 20: 47.75100326538086, 1.0\n",
      "Train loss and acc of batch 21: 48.34669494628906, 0.984375\n",
      "Train loss and acc of batch 22: 48.34668731689453, 0.984375\n",
      "Train loss and acc of batch 23: 47.7509765625, 1.0\n",
      "Train loss and acc of batch 24: 48.34667205810547, 0.984375\n",
      "Train loss and acc of batch 25: 47.750953674316406, 1.0\n",
      "Train loss and acc of batch 26: 47.750946044921875, 1.0\n",
      "Train loss and acc of batch 27: 47.750938415527344, 1.0\n",
      "Train loss and acc of batch 28: 47.75092697143555, 1.0\n",
      "Train loss and acc of batch 29: 48.34662628173828, 0.984375\n",
      "Train loss and acc of batch 30: 47.750911712646484, 1.0\n",
      "Train loss and acc of batch 31: 47.96766662597656, 0.984375\n",
      "Train loss and acc of batch 32: 47.750892639160156, 1.0\n",
      "Train loss and acc of batch 33: 47.750885009765625, 1.0\n",
      "Train loss and acc of batch 34: 48.34657287597656, 0.984375\n",
      "Train loss and acc of batch 35: 48.18439483642578, 0.96875\n",
      "Train loss and acc of batch 36: 47.75086212158203, 1.0\n",
      "Train loss and acc of batch 37: 48.50407791137695, 0.984375\n",
      "Train loss and acc of batch 38: 49.099769592285156, 0.96875\n",
      "Train loss and acc of batch 39: 47.96759796142578, 0.984375\n",
      "Train loss and acc of batch 40: 47.750823974609375, 1.0\n",
      "Train loss and acc of batch 41: 49.09973907470703, 0.96875\n",
      "Train loss and acc of batch 42: 47.75080490112305, 1.0\n",
      "Train loss and acc of batch 43: 48.34649658203125, 0.984375\n",
      "Train loss and acc of batch 44: 47.75078582763672, 1.0\n",
      "Train loss and acc of batch 45: 48.34648132324219, 0.984375\n",
      "Train loss and acc of batch 46: 48.03662109375, 0.984375\n",
      "Train loss and acc of batch 47: 47.750762939453125, 1.0\n",
      "Train loss and acc of batch 48: 47.75075149536133, 1.0\n",
      "Train loss and acc of batch 49: 47.7507438659668, 1.0\n",
      "Train loss and acc of batch 50: 48.346435546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.09965515136719, 0.96875\n",
      "Train loss and acc of batch 52: 49.006561279296875, 0.953125\n",
      "Train loss and acc of batch 53: 47.750709533691406, 1.0\n",
      "Train loss and acc of batch 54: 47.96746063232422, 0.984375\n",
      "Train loss and acc of batch 55: 47.750694274902344, 1.0\n",
      "Train loss and acc of batch 56: 47.75068283081055, 1.0\n",
      "Train loss and acc of batch 57: 48.34637451171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.75066375732422, 1.0\n",
      "Train loss and acc of batch 59: 47.75065612792969, 1.0\n",
      "Train loss and acc of batch 60: 47.75064468383789, 1.0\n",
      "Train loss and acc of batch 61: 47.750633239746094, 1.0\n",
      "Train loss and acc of batch 62: 47.75062942504883, 1.0\n",
      "Train loss and acc of batch 63: 48.942020416259766, 0.96875\n",
      "Train loss and acc of batch 64: 47.967376708984375, 0.984375\n",
      "Train loss and acc of batch 65: 47.750606536865234, 1.0\n",
      "Train loss and acc of batch 66: 47.75059509277344, 1.0\n",
      "Train loss and acc of batch 67: 48.56304931640625, 0.96875\n",
      "Train loss and acc of batch 68: 48.346275329589844, 0.984375\n",
      "Train loss and acc of batch 69: 47.96733093261719, 0.984375\n",
      "Train loss and acc of batch 70: 47.75055694580078, 1.0\n",
      "Training accuracy and loss of epoch #487: 0.9897, 48.0718\n",
      "Saved model by train loss 48.07175160797549\n",
      "Train loss and acc of batch 0: 47.75054931640625, 1.0\n",
      "Train loss and acc of batch 1: 47.75053787231445, 1.0\n",
      "Train loss and acc of batch 2: 47.75053405761719, 1.0\n",
      "Train loss and acc of batch 3: 47.96728515625, 0.984375\n",
      "Train loss and acc of batch 4: 47.75051498413086, 1.0\n",
      "Train loss and acc of batch 5: 49.09942626953125, 0.96875\n",
      "Train loss and acc of batch 6: 48.253108978271484, 0.96875\n",
      "Train loss and acc of batch 7: 47.750484466552734, 1.0\n",
      "Train loss and acc of batch 8: 48.34617614746094, 0.984375\n",
      "Train loss and acc of batch 9: 48.03632354736328, 0.984375\n",
      "Train loss and acc of batch 10: 47.75046157836914, 1.0\n",
      "Train loss and acc of batch 11: 47.750450134277344, 1.0\n",
      "Train loss and acc of batch 12: 48.503665924072266, 0.984375\n",
      "Train loss and acc of batch 13: 47.967201232910156, 0.984375\n",
      "Train loss and acc of batch 14: 47.967185974121094, 0.984375\n",
      "Train loss and acc of batch 15: 48.34611511230469, 0.984375\n",
      "Train loss and acc of batch 16: 48.346107482910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.503623962402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.631935119628906, 0.96875\n",
      "Train loss and acc of batch 19: 47.75038146972656, 1.0\n",
      "Train loss and acc of batch 20: 47.750370025634766, 1.0\n",
      "Train loss and acc of batch 21: 48.34606170654297, 0.984375\n",
      "Train loss and acc of batch 22: 48.34605407714844, 0.984375\n",
      "Train loss and acc of batch 23: 47.75034713745117, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 24: 48.346038818359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.750328063964844, 1.0\n",
      "Train loss and acc of batch 26: 47.75031661987305, 1.0\n",
      "Train loss and acc of batch 27: 47.75031280517578, 1.0\n",
      "Train loss and acc of batch 28: 47.75029754638672, 1.0\n",
      "Train loss and acc of batch 29: 48.34599304199219, 0.984375\n",
      "Train loss and acc of batch 30: 47.750282287597656, 1.0\n",
      "Train loss and acc of batch 31: 47.967041015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.750267028808594, 1.0\n",
      "Train loss and acc of batch 33: 47.75025177001953, 1.0\n",
      "Train loss and acc of batch 34: 48.345947265625, 0.984375\n",
      "Train loss and acc of batch 35: 48.18376541137695, 0.96875\n",
      "Train loss and acc of batch 36: 47.7502326965332, 1.0\n",
      "Train loss and acc of batch 37: 48.50344467163086, 0.984375\n",
      "Train loss and acc of batch 38: 49.09913635253906, 0.96875\n",
      "Train loss and acc of batch 39: 47.96697235107422, 0.984375\n",
      "Train loss and acc of batch 40: 47.75019454956055, 1.0\n",
      "Train loss and acc of batch 41: 49.09911346435547, 0.96875\n",
      "Train loss and acc of batch 42: 47.75017547607422, 1.0\n",
      "Train loss and acc of batch 43: 48.34587097167969, 0.984375\n",
      "Train loss and acc of batch 44: 47.750160217285156, 1.0\n",
      "Train loss and acc of batch 45: 48.345848083496094, 0.984375\n",
      "Train loss and acc of batch 46: 48.03599548339844, 0.984375\n",
      "Train loss and acc of batch 47: 47.7501335144043, 1.0\n",
      "Train loss and acc of batch 48: 47.750118255615234, 1.0\n",
      "Train loss and acc of batch 49: 47.75011444091797, 1.0\n",
      "Train loss and acc of batch 50: 48.34580993652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.099021911621094, 0.96875\n",
      "Train loss and acc of batch 52: 49.00592803955078, 0.953125\n",
      "Train loss and acc of batch 53: 47.75008010864258, 1.0\n",
      "Train loss and acc of batch 54: 47.966835021972656, 0.984375\n",
      "Train loss and acc of batch 55: 47.75006103515625, 1.0\n",
      "Train loss and acc of batch 56: 47.75005340576172, 1.0\n",
      "Train loss and acc of batch 57: 48.345741271972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.75003433227539, 1.0\n",
      "Train loss and acc of batch 59: 47.75002670288086, 1.0\n",
      "Train loss and acc of batch 60: 47.75001907348633, 1.0\n",
      "Train loss and acc of batch 61: 47.750003814697266, 1.0\n",
      "Train loss and acc of batch 62: 47.749996185302734, 1.0\n",
      "Train loss and acc of batch 63: 48.94139099121094, 0.96875\n",
      "Train loss and acc of batch 64: 47.96674346923828, 0.984375\n",
      "Train loss and acc of batch 65: 47.749969482421875, 1.0\n",
      "Train loss and acc of batch 66: 47.74996566772461, 1.0\n",
      "Train loss and acc of batch 67: 48.56241989135742, 0.96875\n",
      "Train loss and acc of batch 68: 48.34564971923828, 0.984375\n",
      "Train loss and acc of batch 69: 47.966705322265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.74992370605469, 1.0\n",
      "Training accuracy and loss of epoch #488: 0.9897, 48.0711\n",
      "Saved model by train loss 48.071121591917226\n",
      "Train loss and acc of batch 0: 47.749916076660156, 1.0\n",
      "Train loss and acc of batch 1: 47.74991226196289, 1.0\n",
      "Train loss and acc of batch 2: 47.74990463256836, 1.0\n",
      "Train loss and acc of batch 3: 47.96665954589844, 0.984375\n",
      "Train loss and acc of batch 4: 47.74988555908203, 1.0\n",
      "Train loss and acc of batch 5: 49.09880065917969, 0.96875\n",
      "Train loss and acc of batch 6: 48.252479553222656, 0.96875\n",
      "Train loss and acc of batch 7: 47.749855041503906, 1.0\n",
      "Train loss and acc of batch 8: 48.345550537109375, 0.984375\n",
      "Train loss and acc of batch 9: 48.03569030761719, 0.984375\n",
      "Train loss and acc of batch 10: 47.74983215332031, 1.0\n",
      "Train loss and acc of batch 11: 47.749820709228516, 1.0\n",
      "Train loss and acc of batch 12: 48.50303649902344, 0.984375\n",
      "Train loss and acc of batch 13: 47.96656799316406, 0.984375\n",
      "Train loss and acc of batch 14: 47.96656036376953, 0.984375\n",
      "Train loss and acc of batch 15: 48.345481872558594, 0.984375\n",
      "Train loss and acc of batch 16: 48.345481872558594, 0.984375\n",
      "Train loss and acc of batch 17: 48.502994537353516, 0.984375\n",
      "Train loss and acc of batch 18: 48.63131332397461, 0.96875\n",
      "Train loss and acc of batch 19: 47.74974822998047, 1.0\n",
      "Train loss and acc of batch 20: 47.74974060058594, 1.0\n",
      "Train loss and acc of batch 21: 48.345436096191406, 0.984375\n",
      "Train loss and acc of batch 22: 48.345420837402344, 0.984375\n",
      "Train loss and acc of batch 23: 47.74971389770508, 1.0\n",
      "Train loss and acc of batch 24: 48.34540557861328, 0.984375\n",
      "Train loss and acc of batch 25: 47.74969482421875, 1.0\n",
      "Train loss and acc of batch 26: 47.749691009521484, 1.0\n",
      "Train loss and acc of batch 27: 47.74968338012695, 1.0\n",
      "Train loss and acc of batch 28: 47.74966812133789, 1.0\n",
      "Train loss and acc of batch 29: 48.345359802246094, 0.984375\n",
      "Train loss and acc of batch 30: 47.749656677246094, 1.0\n",
      "Train loss and acc of batch 31: 47.966407775878906, 0.984375\n",
      "Train loss and acc of batch 32: 47.7496337890625, 1.0\n",
      "Train loss and acc of batch 33: 47.749629974365234, 1.0\n",
      "Train loss and acc of batch 34: 48.34532165527344, 0.984375\n",
      "Train loss and acc of batch 35: 48.18313980102539, 0.96875\n",
      "Train loss and acc of batch 36: 47.74959945678711, 1.0\n",
      "Train loss and acc of batch 37: 48.502811431884766, 0.984375\n",
      "Train loss and acc of batch 38: 49.09850311279297, 0.96875\n",
      "Train loss and acc of batch 39: 47.966339111328125, 0.984375\n",
      "Train loss and acc of batch 40: 47.749568939208984, 1.0\n",
      "Train loss and acc of batch 41: 49.09848403930664, 0.96875\n",
      "Train loss and acc of batch 42: 47.749542236328125, 1.0\n",
      "Train loss and acc of batch 43: 48.345237731933594, 0.984375\n",
      "Train loss and acc of batch 44: 47.74953079223633, 1.0\n",
      "Train loss and acc of batch 45: 48.34522247314453, 0.984375\n",
      "Train loss and acc of batch 46: 48.035362243652344, 0.984375\n",
      "Train loss and acc of batch 47: 47.74950408935547, 1.0\n",
      "Train loss and acc of batch 48: 47.74949645996094, 1.0\n",
      "Train loss and acc of batch 49: 47.74948501586914, 1.0\n",
      "Train loss and acc of batch 50: 48.345176696777344, 0.984375\n",
      "Train loss and acc of batch 51: 49.098388671875, 0.96875\n",
      "Train loss and acc of batch 52: 49.00529861450195, 0.953125\n",
      "Train loss and acc of batch 53: 47.74945068359375, 1.0\n",
      "Train loss and acc of batch 54: 47.966209411621094, 0.984375\n",
      "Train loss and acc of batch 55: 47.74943161010742, 1.0\n",
      "Train loss and acc of batch 56: 47.749420166015625, 1.0\n",
      "Train loss and acc of batch 57: 48.345115661621094, 0.984375\n",
      "Train loss and acc of batch 58: 47.74940490722656, 1.0\n",
      "Train loss and acc of batch 59: 47.74939727783203, 1.0\n",
      "Train loss and acc of batch 60: 47.74938201904297, 1.0\n",
      "Train loss and acc of batch 61: 47.7493782043457, 1.0\n",
      "Train loss and acc of batch 62: 47.74937057495117, 1.0\n",
      "Train loss and acc of batch 63: 48.940765380859375, 0.96875\n",
      "Train loss and acc of batch 64: 47.96611785888672, 0.984375\n",
      "Train loss and acc of batch 65: 47.74934387207031, 1.0\n",
      "Train loss and acc of batch 66: 47.749332427978516, 1.0\n",
      "Train loss and acc of batch 67: 48.56179428100586, 0.96875\n",
      "Train loss and acc of batch 68: 48.34501647949219, 0.984375\n",
      "Train loss and acc of batch 69: 47.96607208251953, 0.984375\n",
      "Train loss and acc of batch 70: 47.749298095703125, 1.0\n",
      "Training accuracy and loss of epoch #489: 0.9897, 48.0705\n",
      "Saved model by train loss 48.07049222059653\n",
      "Train loss and acc of batch 0: 47.749290466308594, 1.0\n",
      "Train loss and acc of batch 1: 47.7492790222168, 1.0\n",
      "Train loss and acc of batch 2: 47.74927520751953, 1.0\n",
      "Train loss and acc of batch 3: 47.966026306152344, 0.984375\n",
      "Train loss and acc of batch 4: 47.7492561340332, 1.0\n",
      "Train loss and acc of batch 5: 49.098167419433594, 0.96875\n",
      "Train loss and acc of batch 6: 48.251853942871094, 0.96875\n",
      "Train loss and acc of batch 7: 47.74922561645508, 1.0\n",
      "Train loss and acc of batch 8: 48.34491729736328, 0.984375\n",
      "Train loss and acc of batch 9: 48.035057067871094, 0.984375\n",
      "Train loss and acc of batch 10: 47.74920654296875, 1.0\n",
      "Train loss and acc of batch 11: 47.74919128417969, 1.0\n",
      "Train loss and acc of batch 12: 48.50240707397461, 0.984375\n",
      "Train loss and acc of batch 13: 47.9659423828125, 0.984375\n",
      "Train loss and acc of batch 14: 47.96592712402344, 0.984375\n",
      "Train loss and acc of batch 15: 48.34485626220703, 0.984375\n",
      "Train loss and acc of batch 16: 48.3448486328125, 0.984375\n",
      "Train loss and acc of batch 17: 48.502357482910156, 0.984375\n",
      "Train loss and acc of batch 18: 48.63068389892578, 0.96875\n",
      "Train loss and acc of batch 19: 47.74911880493164, 1.0\n",
      "Train loss and acc of batch 20: 47.74911117553711, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 21: 48.344810485839844, 0.984375\n",
      "Train loss and acc of batch 22: 48.34478759765625, 0.984375\n",
      "Train loss and acc of batch 23: 47.74908447265625, 1.0\n",
      "Train loss and acc of batch 24: 48.34477996826172, 0.984375\n",
      "Train loss and acc of batch 25: 47.74906921386719, 1.0\n",
      "Train loss and acc of batch 26: 47.74905776977539, 1.0\n",
      "Train loss and acc of batch 27: 47.749053955078125, 1.0\n",
      "Train loss and acc of batch 28: 47.74903869628906, 1.0\n",
      "Train loss and acc of batch 29: 48.34473419189453, 0.984375\n",
      "Train loss and acc of batch 30: 47.749027252197266, 1.0\n",
      "Train loss and acc of batch 31: 47.96577453613281, 0.984375\n",
      "Train loss and acc of batch 32: 47.74900436401367, 1.0\n",
      "Train loss and acc of batch 33: 47.748992919921875, 1.0\n",
      "Train loss and acc of batch 34: 48.344688415527344, 0.984375\n",
      "Train loss and acc of batch 35: 48.18251037597656, 0.96875\n",
      "Train loss and acc of batch 36: 47.74897384643555, 1.0\n",
      "Train loss and acc of batch 37: 48.50218200683594, 0.984375\n",
      "Train loss and acc of batch 38: 49.097877502441406, 0.96875\n",
      "Train loss and acc of batch 39: 47.96570587158203, 0.984375\n",
      "Train loss and acc of batch 40: 47.748931884765625, 1.0\n",
      "Train loss and acc of batch 41: 49.09785461425781, 0.96875\n",
      "Train loss and acc of batch 42: 47.7489128112793, 1.0\n",
      "Train loss and acc of batch 43: 48.34461212158203, 0.984375\n",
      "Train loss and acc of batch 44: 47.748905181884766, 1.0\n",
      "Train loss and acc of batch 45: 48.34458923339844, 0.984375\n",
      "Train loss and acc of batch 46: 48.03472900390625, 0.984375\n",
      "Train loss and acc of batch 47: 47.748878479003906, 1.0\n",
      "Train loss and acc of batch 48: 47.748863220214844, 1.0\n",
      "Train loss and acc of batch 49: 47.74885940551758, 1.0\n",
      "Train loss and acc of batch 50: 48.34454345703125, 0.984375\n",
      "Train loss and acc of batch 51: 49.097755432128906, 0.96875\n",
      "Train loss and acc of batch 52: 49.004669189453125, 0.953125\n",
      "Train loss and acc of batch 53: 47.74882125854492, 1.0\n",
      "Train loss and acc of batch 54: 47.965576171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.74880599975586, 1.0\n",
      "Train loss and acc of batch 56: 47.7487907409668, 1.0\n",
      "Train loss and acc of batch 57: 48.34449005126953, 0.984375\n",
      "Train loss and acc of batch 58: 47.748779296875, 1.0\n",
      "Train loss and acc of batch 59: 47.74876022338867, 1.0\n",
      "Train loss and acc of batch 60: 47.748756408691406, 1.0\n",
      "Train loss and acc of batch 61: 47.748741149902344, 1.0\n",
      "Train loss and acc of batch 62: 47.748741149902344, 1.0\n",
      "Train loss and acc of batch 63: 48.94013214111328, 0.96875\n",
      "Train loss and acc of batch 64: 47.965484619140625, 0.984375\n",
      "Train loss and acc of batch 65: 47.748714447021484, 1.0\n",
      "Train loss and acc of batch 66: 47.74870681762695, 1.0\n",
      "Train loss and acc of batch 67: 48.5611572265625, 0.96875\n",
      "Train loss and acc of batch 68: 48.344383239746094, 0.984375\n",
      "Train loss and acc of batch 69: 47.96543884277344, 0.984375\n",
      "Train loss and acc of batch 70: 47.74867248535156, 1.0\n",
      "Training accuracy and loss of epoch #490: 0.9897, 48.0699\n",
      "Saved model by train loss 48.069862097082\n",
      "Train loss and acc of batch 0: 47.748661041259766, 1.0\n",
      "Train loss and acc of batch 1: 47.7486572265625, 1.0\n",
      "Train loss and acc of batch 2: 47.7486457824707, 1.0\n",
      "Train loss and acc of batch 3: 47.96539306640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.748626708984375, 1.0\n",
      "Train loss and acc of batch 5: 49.09754180908203, 0.96875\n",
      "Train loss and acc of batch 6: 48.251220703125, 0.96875\n",
      "Train loss and acc of batch 7: 47.748592376708984, 1.0\n",
      "Train loss and acc of batch 8: 48.34429168701172, 0.984375\n",
      "Train loss and acc of batch 9: 48.03443908691406, 0.984375\n",
      "Train loss and acc of batch 10: 47.74856948852539, 1.0\n",
      "Train loss and acc of batch 11: 47.748558044433594, 1.0\n",
      "Train loss and acc of batch 12: 48.50177764892578, 0.984375\n",
      "Train loss and acc of batch 13: 47.965309143066406, 0.984375\n",
      "Train loss and acc of batch 14: 47.965301513671875, 0.984375\n",
      "Train loss and acc of batch 15: 48.34423065185547, 0.984375\n",
      "Train loss and acc of batch 16: 48.344215393066406, 0.984375\n",
      "Train loss and acc of batch 17: 48.501731872558594, 0.984375\n",
      "Train loss and acc of batch 18: 48.63005828857422, 0.96875\n",
      "Train loss and acc of batch 19: 47.74848937988281, 1.0\n",
      "Train loss and acc of batch 20: 47.74848556518555, 1.0\n",
      "Train loss and acc of batch 21: 48.34416961669922, 0.984375\n",
      "Train loss and acc of batch 22: 48.34416198730469, 0.984375\n",
      "Train loss and acc of batch 23: 47.74845886230469, 1.0\n",
      "Train loss and acc of batch 24: 48.344146728515625, 0.984375\n",
      "Train loss and acc of batch 25: 47.74843215942383, 1.0\n",
      "Train loss and acc of batch 26: 47.74842834472656, 1.0\n",
      "Train loss and acc of batch 27: 47.74842071533203, 1.0\n",
      "Train loss and acc of batch 28: 47.7484130859375, 1.0\n",
      "Train loss and acc of batch 29: 48.34410858154297, 0.984375\n",
      "Train loss and acc of batch 30: 47.74839401245117, 1.0\n",
      "Train loss and acc of batch 31: 47.96514892578125, 0.984375\n",
      "Train loss and acc of batch 32: 47.74837875366211, 1.0\n",
      "Train loss and acc of batch 33: 47.74836730957031, 1.0\n",
      "Train loss and acc of batch 34: 48.34406280517578, 0.984375\n",
      "Train loss and acc of batch 35: 48.18187713623047, 0.96875\n",
      "Train loss and acc of batch 36: 47.74834060668945, 1.0\n",
      "Train loss and acc of batch 37: 48.501556396484375, 0.984375\n",
      "Train loss and acc of batch 38: 49.09724426269531, 0.96875\n",
      "Train loss and acc of batch 39: 47.96508026123047, 0.984375\n",
      "Train loss and acc of batch 40: 47.74830627441406, 1.0\n",
      "Train loss and acc of batch 41: 49.09721755981445, 0.96875\n",
      "Train loss and acc of batch 42: 47.748287200927734, 1.0\n",
      "Train loss and acc of batch 43: 48.34398651123047, 0.984375\n",
      "Train loss and acc of batch 44: 47.748268127441406, 1.0\n",
      "Train loss and acc of batch 45: 48.343963623046875, 0.984375\n",
      "Train loss and acc of batch 46: 48.03411102294922, 0.984375\n",
      "Train loss and acc of batch 47: 47.74824142456055, 1.0\n",
      "Train loss and acc of batch 48: 47.74823760986328, 1.0\n",
      "Train loss and acc of batch 49: 47.748226165771484, 1.0\n",
      "Train loss and acc of batch 50: 48.34391784667969, 0.984375\n",
      "Train loss and acc of batch 51: 49.097137451171875, 0.96875\n",
      "Train loss and acc of batch 52: 49.00403594970703, 0.953125\n",
      "Train loss and acc of batch 53: 47.74818801879883, 1.0\n",
      "Train loss and acc of batch 54: 47.964942932128906, 0.984375\n",
      "Train loss and acc of batch 55: 47.7481689453125, 1.0\n",
      "Train loss and acc of batch 56: 47.748165130615234, 1.0\n",
      "Train loss and acc of batch 57: 48.34385681152344, 0.984375\n",
      "Train loss and acc of batch 58: 47.748146057128906, 1.0\n",
      "Train loss and acc of batch 59: 47.74813461303711, 1.0\n",
      "Train loss and acc of batch 60: 47.74812698364258, 1.0\n",
      "Train loss and acc of batch 61: 47.74811935424805, 1.0\n",
      "Train loss and acc of batch 62: 47.748111724853516, 1.0\n",
      "Train loss and acc of batch 63: 48.93950653076172, 0.96875\n",
      "Train loss and acc of batch 64: 47.96485137939453, 0.984375\n",
      "Train loss and acc of batch 65: 47.748085021972656, 1.0\n",
      "Train loss and acc of batch 66: 47.74808120727539, 1.0\n",
      "Train loss and acc of batch 67: 48.56053161621094, 0.96875\n",
      "Train loss and acc of batch 68: 48.34375762939453, 0.984375\n",
      "Train loss and acc of batch 69: 47.964805603027344, 0.984375\n",
      "Train loss and acc of batch 70: 47.74803924560547, 1.0\n",
      "Training accuracy and loss of epoch #491: 0.9897, 48.0692\n",
      "Saved model by train loss 48.06923299440196\n",
      "Train loss and acc of batch 0: 47.74803161621094, 1.0\n",
      "Train loss and acc of batch 1: 47.74802017211914, 1.0\n",
      "Train loss and acc of batch 2: 47.74801254272461, 1.0\n",
      "Train loss and acc of batch 3: 47.96477508544922, 0.984375\n",
      "Train loss and acc of batch 4: 47.74799346923828, 1.0\n",
      "Train loss and acc of batch 5: 49.09690856933594, 0.96875\n",
      "Train loss and acc of batch 6: 48.25059509277344, 0.96875\n",
      "Train loss and acc of batch 7: 47.747962951660156, 1.0\n",
      "Train loss and acc of batch 8: 48.343666076660156, 0.984375\n",
      "Train loss and acc of batch 9: 48.03380584716797, 0.984375\n",
      "Train loss and acc of batch 10: 47.74794387817383, 1.0\n",
      "Train loss and acc of batch 11: 47.74793243408203, 1.0\n",
      "Train loss and acc of batch 12: 48.50115203857422, 0.984375\n",
      "Train loss and acc of batch 13: 47.96467590332031, 0.984375\n",
      "Train loss and acc of batch 14: 47.96467590332031, 0.984375\n",
      "Train loss and acc of batch 15: 48.343597412109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.343589782714844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 17: 48.50110626220703, 0.984375\n",
      "Train loss and acc of batch 18: 48.629425048828125, 0.96875\n",
      "Train loss and acc of batch 19: 47.747859954833984, 1.0\n",
      "Train loss and acc of batch 20: 47.74785614013672, 1.0\n",
      "Train loss and acc of batch 21: 48.343544006347656, 0.984375\n",
      "Train loss and acc of batch 22: 48.343536376953125, 0.984375\n",
      "Train loss and acc of batch 23: 47.74782943725586, 1.0\n",
      "Train loss and acc of batch 24: 48.34352111816406, 0.984375\n",
      "Train loss and acc of batch 25: 47.747806549072266, 1.0\n",
      "Train loss and acc of batch 26: 47.747798919677734, 1.0\n",
      "Train loss and acc of batch 27: 47.7477912902832, 1.0\n",
      "Train loss and acc of batch 28: 47.74778366088867, 1.0\n",
      "Train loss and acc of batch 29: 48.343475341796875, 0.984375\n",
      "Train loss and acc of batch 30: 47.74776077270508, 1.0\n",
      "Train loss and acc of batch 31: 47.96452331542969, 0.984375\n",
      "Train loss and acc of batch 32: 47.747745513916016, 1.0\n",
      "Train loss and acc of batch 33: 47.747737884521484, 1.0\n",
      "Train loss and acc of batch 34: 48.34342956542969, 0.984375\n",
      "Train loss and acc of batch 35: 48.18124771118164, 0.96875\n",
      "Train loss and acc of batch 36: 47.747711181640625, 1.0\n",
      "Train loss and acc of batch 37: 48.50093078613281, 0.984375\n",
      "Train loss and acc of batch 38: 49.09661865234375, 0.96875\n",
      "Train loss and acc of batch 39: 47.964447021484375, 0.984375\n",
      "Train loss and acc of batch 40: 47.747676849365234, 1.0\n",
      "Train loss and acc of batch 41: 49.096588134765625, 0.96875\n",
      "Train loss and acc of batch 42: 47.74765396118164, 1.0\n",
      "Train loss and acc of batch 43: 48.343345642089844, 0.984375\n",
      "Train loss and acc of batch 44: 47.74763488769531, 1.0\n",
      "Train loss and acc of batch 45: 48.34333038330078, 0.984375\n",
      "Train loss and acc of batch 46: 48.033470153808594, 0.984375\n",
      "Train loss and acc of batch 47: 47.74761199951172, 1.0\n",
      "Train loss and acc of batch 48: 47.74760055541992, 1.0\n",
      "Train loss and acc of batch 49: 47.747589111328125, 1.0\n",
      "Train loss and acc of batch 50: 48.343284606933594, 0.984375\n",
      "Train loss and acc of batch 51: 49.09650421142578, 0.96875\n",
      "Train loss and acc of batch 52: 49.0034065246582, 0.953125\n",
      "Train loss and acc of batch 53: 47.74755859375, 1.0\n",
      "Train loss and acc of batch 54: 47.964317321777344, 0.984375\n",
      "Train loss and acc of batch 55: 47.74754333496094, 1.0\n",
      "Train loss and acc of batch 56: 47.74753189086914, 1.0\n",
      "Train loss and acc of batch 57: 48.343223571777344, 0.984375\n",
      "Train loss and acc of batch 58: 47.74751281738281, 1.0\n",
      "Train loss and acc of batch 59: 47.74750518798828, 1.0\n",
      "Train loss and acc of batch 60: 47.747493743896484, 1.0\n",
      "Train loss and acc of batch 61: 47.74748611450195, 1.0\n",
      "Train loss and acc of batch 62: 47.74747848510742, 1.0\n",
      "Train loss and acc of batch 63: 48.938865661621094, 0.96875\n",
      "Train loss and acc of batch 64: 47.96422576904297, 0.984375\n",
      "Train loss and acc of batch 65: 47.74745559692383, 1.0\n",
      "Train loss and acc of batch 66: 47.74744415283203, 1.0\n",
      "Train loss and acc of batch 67: 48.559898376464844, 0.96875\n",
      "Train loss and acc of batch 68: 48.34312438964844, 0.984375\n",
      "Train loss and acc of batch 69: 47.96417999267578, 0.984375\n",
      "Train loss and acc of batch 70: 47.747406005859375, 1.0\n",
      "Training accuracy and loss of epoch #492: 0.9897, 48.0686\n",
      "Saved model by train loss 48.06860244106239\n",
      "Train loss and acc of batch 0: 47.747406005859375, 1.0\n",
      "Train loss and acc of batch 1: 47.74738693237305, 1.0\n",
      "Train loss and acc of batch 2: 47.747379302978516, 1.0\n",
      "Train loss and acc of batch 3: 47.964141845703125, 0.984375\n",
      "Train loss and acc of batch 4: 47.74736022949219, 1.0\n",
      "Train loss and acc of batch 5: 49.096282958984375, 0.96875\n",
      "Train loss and acc of batch 6: 48.24995803833008, 0.96875\n",
      "Train loss and acc of batch 7: 47.74733352661133, 1.0\n",
      "Train loss and acc of batch 8: 48.34303283691406, 0.984375\n",
      "Train loss and acc of batch 9: 48.033172607421875, 0.984375\n",
      "Train loss and acc of batch 10: 47.74730682373047, 1.0\n",
      "Train loss and acc of batch 11: 47.74730682373047, 1.0\n",
      "Train loss and acc of batch 12: 48.50051498413086, 0.984375\n",
      "Train loss and acc of batch 13: 47.96405029296875, 0.984375\n",
      "Train loss and acc of batch 14: 47.96403503417969, 0.984375\n",
      "Train loss and acc of batch 15: 48.34296417236328, 0.984375\n",
      "Train loss and acc of batch 16: 48.34295654296875, 0.984375\n",
      "Train loss and acc of batch 17: 48.50047302246094, 0.984375\n",
      "Train loss and acc of batch 18: 48.62879180908203, 0.96875\n",
      "Train loss and acc of batch 19: 47.747230529785156, 1.0\n",
      "Train loss and acc of batch 20: 47.747222900390625, 1.0\n",
      "Train loss and acc of batch 21: 48.34291076660156, 0.984375\n",
      "Train loss and acc of batch 22: 48.34290313720703, 0.984375\n",
      "Train loss and acc of batch 23: 47.747188568115234, 1.0\n",
      "Train loss and acc of batch 24: 48.34288787841797, 0.984375\n",
      "Train loss and acc of batch 25: 47.74717712402344, 1.0\n",
      "Train loss and acc of batch 26: 47.74716567993164, 1.0\n",
      "Train loss and acc of batch 27: 47.747161865234375, 1.0\n",
      "Train loss and acc of batch 28: 47.747154235839844, 1.0\n",
      "Train loss and acc of batch 29: 48.34283447265625, 0.984375\n",
      "Train loss and acc of batch 30: 47.74713134765625, 1.0\n",
      "Train loss and acc of batch 31: 47.963890075683594, 0.984375\n",
      "Train loss and acc of batch 32: 47.74711608886719, 1.0\n",
      "Train loss and acc of batch 33: 47.74710464477539, 1.0\n",
      "Train loss and acc of batch 34: 48.342796325683594, 0.984375\n",
      "Train loss and acc of batch 35: 48.18061447143555, 0.96875\n",
      "Train loss and acc of batch 36: 47.7470817565918, 1.0\n",
      "Train loss and acc of batch 37: 48.50028991699219, 0.984375\n",
      "Train loss and acc of batch 38: 49.095985412597656, 0.96875\n",
      "Train loss and acc of batch 39: 47.96382141113281, 0.984375\n",
      "Train loss and acc of batch 40: 47.74704360961914, 1.0\n",
      "Train loss and acc of batch 41: 49.09596252441406, 0.96875\n",
      "Train loss and acc of batch 42: 47.74702453613281, 1.0\n",
      "Train loss and acc of batch 43: 48.34271240234375, 0.984375\n",
      "Train loss and acc of batch 44: 47.74700927734375, 1.0\n",
      "Train loss and acc of batch 45: 48.34269714355469, 0.984375\n",
      "Train loss and acc of batch 46: 48.03284454345703, 0.984375\n",
      "Train loss and acc of batch 47: 47.746978759765625, 1.0\n",
      "Train loss and acc of batch 48: 47.74697494506836, 1.0\n",
      "Train loss and acc of batch 49: 47.7469596862793, 1.0\n",
      "Train loss and acc of batch 50: 48.34265899658203, 0.984375\n",
      "Train loss and acc of batch 51: 49.095863342285156, 0.96875\n",
      "Train loss and acc of batch 52: 49.00277328491211, 0.953125\n",
      "Train loss and acc of batch 53: 47.74692916870117, 1.0\n",
      "Train loss and acc of batch 54: 47.96368408203125, 0.984375\n",
      "Train loss and acc of batch 55: 47.746910095214844, 1.0\n",
      "Train loss and acc of batch 56: 47.74690628051758, 1.0\n",
      "Train loss and acc of batch 57: 48.34259033203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.746883392333984, 1.0\n",
      "Train loss and acc of batch 59: 47.74687194824219, 1.0\n",
      "Train loss and acc of batch 60: 47.74686813354492, 1.0\n",
      "Train loss and acc of batch 61: 47.746856689453125, 1.0\n",
      "Train loss and acc of batch 62: 47.74684143066406, 1.0\n",
      "Train loss and acc of batch 63: 48.9382438659668, 0.96875\n",
      "Train loss and acc of batch 64: 47.963592529296875, 0.984375\n",
      "Train loss and acc of batch 65: 47.746822357177734, 1.0\n",
      "Train loss and acc of batch 66: 47.74681091308594, 1.0\n",
      "Train loss and acc of batch 67: 48.559268951416016, 0.96875\n",
      "Train loss and acc of batch 68: 48.342491149902344, 0.984375\n",
      "Train loss and acc of batch 69: 47.96355438232422, 0.984375\n",
      "Train loss and acc of batch 70: 47.74678039550781, 1.0\n",
      "Training accuracy and loss of epoch #493: 0.9897, 48.0680\n",
      "Saved model by train loss 48.067970866888345\n",
      "Train loss and acc of batch 0: 47.746768951416016, 1.0\n",
      "Train loss and acc of batch 1: 47.74675750732422, 1.0\n",
      "Train loss and acc of batch 2: 47.74675369262695, 1.0\n",
      "Train loss and acc of batch 3: 47.96350860595703, 0.984375\n",
      "Train loss and acc of batch 4: 47.746734619140625, 1.0\n",
      "Train loss and acc of batch 5: 49.09564971923828, 0.96875\n",
      "Train loss and acc of batch 6: 48.24933624267578, 0.96875\n",
      "Train loss and acc of batch 7: 47.7467041015625, 1.0\n",
      "Train loss and acc of batch 8: 48.34239196777344, 0.984375\n",
      "Train loss and acc of batch 9: 48.03253936767578, 0.984375\n",
      "Train loss and acc of batch 10: 47.746681213378906, 1.0\n",
      "Train loss and acc of batch 11: 47.746665954589844, 1.0\n",
      "Train loss and acc of batch 12: 48.49988555908203, 0.984375\n",
      "Train loss and acc of batch 13: 47.96342468261719, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 14: 47.963409423828125, 0.984375\n",
      "Train loss and acc of batch 15: 48.34233093261719, 0.984375\n",
      "Train loss and acc of batch 16: 48.34233093261719, 0.984375\n",
      "Train loss and acc of batch 17: 48.499839782714844, 0.984375\n",
      "Train loss and acc of batch 18: 48.6281623840332, 0.96875\n",
      "Train loss and acc of batch 19: 47.74659729003906, 1.0\n",
      "Train loss and acc of batch 20: 47.7465934753418, 1.0\n",
      "Train loss and acc of batch 21: 48.34228515625, 0.984375\n",
      "Train loss and acc of batch 22: 48.34227752685547, 0.984375\n",
      "Train loss and acc of batch 23: 47.74656295776367, 1.0\n",
      "Train loss and acc of batch 24: 48.342254638671875, 0.984375\n",
      "Train loss and acc of batch 25: 47.746543884277344, 1.0\n",
      "Train loss and acc of batch 26: 47.74654006958008, 1.0\n",
      "Train loss and acc of batch 27: 47.74652862548828, 1.0\n",
      "Train loss and acc of batch 28: 47.746517181396484, 1.0\n",
      "Train loss and acc of batch 29: 48.34220886230469, 0.984375\n",
      "Train loss and acc of batch 30: 47.74650573730469, 1.0\n",
      "Train loss and acc of batch 31: 47.9632568359375, 0.984375\n",
      "Train loss and acc of batch 32: 47.74648666381836, 1.0\n",
      "Train loss and acc of batch 33: 47.74647521972656, 1.0\n",
      "Train loss and acc of batch 34: 48.34217071533203, 0.984375\n",
      "Train loss and acc of batch 35: 48.179988861083984, 0.96875\n",
      "Train loss and acc of batch 36: 47.746456146240234, 1.0\n",
      "Train loss and acc of batch 37: 48.499664306640625, 0.984375\n",
      "Train loss and acc of batch 38: 49.09535217285156, 0.96875\n",
      "Train loss and acc of batch 39: 47.96318817138672, 0.984375\n",
      "Train loss and acc of batch 40: 47.74641418457031, 1.0\n",
      "Train loss and acc of batch 41: 49.095333099365234, 0.96875\n",
      "Train loss and acc of batch 42: 47.74639129638672, 1.0\n",
      "Train loss and acc of batch 43: 48.34208679199219, 0.984375\n",
      "Train loss and acc of batch 44: 47.746376037597656, 1.0\n",
      "Train loss and acc of batch 45: 48.342071533203125, 0.984375\n",
      "Train loss and acc of batch 46: 48.03221130371094, 0.984375\n",
      "Train loss and acc of batch 47: 47.74635314941406, 1.0\n",
      "Train loss and acc of batch 48: 47.746341705322266, 1.0\n",
      "Train loss and acc of batch 49: 47.746337890625, 1.0\n",
      "Train loss and acc of batch 50: 48.34202575683594, 0.984375\n",
      "Train loss and acc of batch 51: 49.095245361328125, 0.96875\n",
      "Train loss and acc of batch 52: 49.00214385986328, 0.953125\n",
      "Train loss and acc of batch 53: 47.746299743652344, 1.0\n",
      "Train loss and acc of batch 54: 47.963050842285156, 0.984375\n",
      "Train loss and acc of batch 55: 47.74627685546875, 1.0\n",
      "Train loss and acc of batch 56: 47.74626922607422, 1.0\n",
      "Train loss and acc of batch 57: 48.34196472167969, 0.984375\n",
      "Train loss and acc of batch 58: 47.746253967285156, 1.0\n",
      "Train loss and acc of batch 59: 47.74624252319336, 1.0\n",
      "Train loss and acc of batch 60: 47.74623489379883, 1.0\n",
      "Train loss and acc of batch 61: 47.7462272644043, 1.0\n",
      "Train loss and acc of batch 62: 47.7462158203125, 1.0\n",
      "Train loss and acc of batch 63: 48.93761444091797, 0.96875\n",
      "Train loss and acc of batch 64: 47.962974548339844, 0.984375\n",
      "Train loss and acc of batch 65: 47.746192932128906, 1.0\n",
      "Train loss and acc of batch 66: 47.74618148803711, 1.0\n",
      "Train loss and acc of batch 67: 48.55863952636719, 0.96875\n",
      "Train loss and acc of batch 68: 48.34186553955078, 0.984375\n",
      "Train loss and acc of batch 69: 47.962921142578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.74614715576172, 1.0\n",
      "Training accuracy and loss of epoch #494: 0.9897, 48.0673\n",
      "Saved model by train loss 48.06734133438325\n",
      "Train loss and acc of batch 0: 47.74613952636719, 1.0\n",
      "Train loss and acc of batch 1: 47.746131896972656, 1.0\n",
      "Train loss and acc of batch 2: 47.746116638183594, 1.0\n",
      "Train loss and acc of batch 3: 47.96287536621094, 0.984375\n",
      "Train loss and acc of batch 4: 47.7461051940918, 1.0\n",
      "Train loss and acc of batch 5: 49.09501647949219, 0.96875\n",
      "Train loss and acc of batch 6: 48.24870300292969, 0.96875\n",
      "Train loss and acc of batch 7: 47.74607849121094, 1.0\n",
      "Train loss and acc of batch 8: 48.341766357421875, 0.984375\n",
      "Train loss and acc of batch 9: 48.03191375732422, 0.984375\n",
      "Train loss and acc of batch 10: 47.74604797363281, 1.0\n",
      "Train loss and acc of batch 11: 47.74604415893555, 1.0\n",
      "Train loss and acc of batch 12: 48.4992561340332, 0.984375\n",
      "Train loss and acc of batch 13: 47.96278381347656, 0.984375\n",
      "Train loss and acc of batch 14: 47.96277618408203, 0.984375\n",
      "Train loss and acc of batch 15: 48.341712951660156, 0.984375\n",
      "Train loss and acc of batch 16: 48.34169006347656, 0.984375\n",
      "Train loss and acc of batch 17: 48.499210357666016, 0.984375\n",
      "Train loss and acc of batch 18: 48.62752914428711, 0.96875\n",
      "Train loss and acc of batch 19: 47.745967864990234, 1.0\n",
      "Train loss and acc of batch 20: 47.74596405029297, 1.0\n",
      "Train loss and acc of batch 21: 48.34165954589844, 0.984375\n",
      "Train loss and acc of batch 22: 48.341644287109375, 0.984375\n",
      "Train loss and acc of batch 23: 47.74593734741211, 1.0\n",
      "Train loss and acc of batch 24: 48.34162139892578, 0.984375\n",
      "Train loss and acc of batch 25: 47.74591827392578, 1.0\n",
      "Train loss and acc of batch 26: 47.745906829833984, 1.0\n",
      "Train loss and acc of batch 27: 47.74589920043945, 1.0\n",
      "Train loss and acc of batch 28: 47.745887756347656, 1.0\n",
      "Train loss and acc of batch 29: 48.341590881347656, 0.984375\n",
      "Train loss and acc of batch 30: 47.745872497558594, 1.0\n",
      "Train loss and acc of batch 31: 47.962623596191406, 0.984375\n",
      "Train loss and acc of batch 32: 47.745853424072266, 1.0\n",
      "Train loss and acc of batch 33: 47.74584197998047, 1.0\n",
      "Train loss and acc of batch 34: 48.34153747558594, 0.984375\n",
      "Train loss and acc of batch 35: 48.179359436035156, 0.96875\n",
      "Train loss and acc of batch 36: 47.745819091796875, 1.0\n",
      "Train loss and acc of batch 37: 48.49903869628906, 0.984375\n",
      "Train loss and acc of batch 38: 49.0947265625, 0.96875\n",
      "Train loss and acc of batch 39: 47.962554931640625, 0.984375\n",
      "Train loss and acc of batch 40: 47.745784759521484, 1.0\n",
      "Train loss and acc of batch 41: 49.09469985961914, 0.96875\n",
      "Train loss and acc of batch 42: 47.745765686035156, 1.0\n",
      "Train loss and acc of batch 43: 48.341461181640625, 0.984375\n",
      "Train loss and acc of batch 44: 47.74574661254883, 1.0\n",
      "Train loss and acc of batch 45: 48.34144592285156, 0.984375\n",
      "Train loss and acc of batch 46: 48.031578063964844, 0.984375\n",
      "Train loss and acc of batch 47: 47.7457160949707, 1.0\n",
      "Train loss and acc of batch 48: 47.7457160949707, 1.0\n",
      "Train loss and acc of batch 49: 47.745697021484375, 1.0\n",
      "Train loss and acc of batch 50: 48.341392517089844, 0.984375\n",
      "Train loss and acc of batch 51: 49.09461212158203, 0.96875\n",
      "Train loss and acc of batch 52: 49.00151824951172, 0.953125\n",
      "Train loss and acc of batch 53: 47.74566650390625, 1.0\n",
      "Train loss and acc of batch 54: 47.962425231933594, 0.984375\n",
      "Train loss and acc of batch 55: 47.74564743041992, 1.0\n",
      "Train loss and acc of batch 56: 47.745643615722656, 1.0\n",
      "Train loss and acc of batch 57: 48.341339111328125, 0.984375\n",
      "Train loss and acc of batch 58: 47.74562454223633, 1.0\n",
      "Train loss and acc of batch 59: 47.74561309814453, 1.0\n",
      "Train loss and acc of batch 60: 47.74560546875, 1.0\n",
      "Train loss and acc of batch 61: 47.7455940246582, 1.0\n",
      "Train loss and acc of batch 62: 47.74559020996094, 1.0\n",
      "Train loss and acc of batch 63: 48.936981201171875, 0.96875\n",
      "Train loss and acc of batch 64: 47.96233367919922, 0.984375\n",
      "Train loss and acc of batch 65: 47.74555969238281, 1.0\n",
      "Train loss and acc of batch 66: 47.74555206298828, 1.0\n",
      "Train loss and acc of batch 67: 48.55801010131836, 0.96875\n",
      "Train loss and acc of batch 68: 48.34123229980469, 0.984375\n",
      "Train loss and acc of batch 69: 47.96228790283203, 0.984375\n",
      "Train loss and acc of batch 70: 47.74551773071289, 1.0\n",
      "Training accuracy and loss of epoch #495: 0.9897, 48.0667\n",
      "Saved model by train loss 48.06671099595621\n",
      "Train loss and acc of batch 0: 47.745506286621094, 1.0\n",
      "Train loss and acc of batch 1: 47.74550247192383, 1.0\n",
      "Train loss and acc of batch 2: 47.7454948425293, 1.0\n",
      "Train loss and acc of batch 3: 47.962249755859375, 0.984375\n",
      "Train loss and acc of batch 4: 47.7454719543457, 1.0\n",
      "Train loss and acc of batch 5: 49.094390869140625, 0.96875\n",
      "Train loss and acc of batch 6: 48.24807357788086, 0.96875\n",
      "Train loss and acc of batch 7: 47.74544143676758, 1.0\n",
      "Train loss and acc of batch 8: 48.34114074707031, 0.984375\n",
      "Train loss and acc of batch 9: 48.031280517578125, 0.984375\n",
      "Train loss and acc of batch 10: 47.74542236328125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 11: 47.74541091918945, 1.0\n",
      "Train loss and acc of batch 12: 48.49862289428711, 0.984375\n",
      "Train loss and acc of batch 13: 47.962158203125, 0.984375\n",
      "Train loss and acc of batch 14: 47.96215057373047, 0.984375\n",
      "Train loss and acc of batch 15: 48.34107971191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.34107208251953, 0.984375\n",
      "Train loss and acc of batch 17: 48.49858093261719, 0.984375\n",
      "Train loss and acc of batch 18: 48.62690353393555, 0.96875\n",
      "Train loss and acc of batch 19: 47.74534225463867, 1.0\n",
      "Train loss and acc of batch 20: 47.745330810546875, 1.0\n",
      "Train loss and acc of batch 21: 48.34101867675781, 0.984375\n",
      "Train loss and acc of batch 22: 48.34101867675781, 0.984375\n",
      "Train loss and acc of batch 23: 47.74530029296875, 1.0\n",
      "Train loss and acc of batch 24: 48.34099578857422, 0.984375\n",
      "Train loss and acc of batch 25: 47.74529266357422, 1.0\n",
      "Train loss and acc of batch 26: 47.74527359008789, 1.0\n",
      "Train loss and acc of batch 27: 47.74526596069336, 1.0\n",
      "Train loss and acc of batch 28: 47.745262145996094, 1.0\n",
      "Train loss and acc of batch 29: 48.34095001220703, 0.984375\n",
      "Train loss and acc of batch 30: 47.74524688720703, 1.0\n",
      "Train loss and acc of batch 31: 47.961997985839844, 0.984375\n",
      "Train loss and acc of batch 32: 47.7452278137207, 1.0\n",
      "Train loss and acc of batch 33: 47.745216369628906, 1.0\n",
      "Train loss and acc of batch 34: 48.340904235839844, 0.984375\n",
      "Train loss and acc of batch 35: 48.17872619628906, 0.96875\n",
      "Train loss and acc of batch 36: 47.74519348144531, 1.0\n",
      "Train loss and acc of batch 37: 48.49840545654297, 0.984375\n",
      "Train loss and acc of batch 38: 49.09410095214844, 0.96875\n",
      "Train loss and acc of batch 39: 47.96192932128906, 0.984375\n",
      "Train loss and acc of batch 40: 47.745147705078125, 1.0\n",
      "Train loss and acc of batch 41: 49.09407043457031, 0.96875\n",
      "Train loss and acc of batch 42: 47.745140075683594, 1.0\n",
      "Train loss and acc of batch 43: 48.34082794189453, 0.984375\n",
      "Train loss and acc of batch 44: 47.745121002197266, 1.0\n",
      "Train loss and acc of batch 45: 48.34081268310547, 0.984375\n",
      "Train loss and acc of batch 46: 48.03095245361328, 0.984375\n",
      "Train loss and acc of batch 47: 47.745094299316406, 1.0\n",
      "Train loss and acc of batch 48: 47.745086669921875, 1.0\n",
      "Train loss and acc of batch 49: 47.74507141113281, 1.0\n",
      "Train loss and acc of batch 50: 48.34076690673828, 0.984375\n",
      "Train loss and acc of batch 51: 49.09398651123047, 0.96875\n",
      "Train loss and acc of batch 52: 49.000885009765625, 0.953125\n",
      "Train loss and acc of batch 53: 47.74504089355469, 1.0\n",
      "Train loss and acc of batch 54: 47.9617919921875, 0.984375\n",
      "Train loss and acc of batch 55: 47.74502182006836, 1.0\n",
      "Train loss and acc of batch 56: 47.74501037597656, 1.0\n",
      "Train loss and acc of batch 57: 48.34070587158203, 0.984375\n",
      "Train loss and acc of batch 58: 47.7449951171875, 1.0\n",
      "Train loss and acc of batch 59: 47.74498748779297, 1.0\n",
      "Train loss and acc of batch 60: 47.74497604370117, 1.0\n",
      "Train loss and acc of batch 61: 47.744972229003906, 1.0\n",
      "Train loss and acc of batch 62: 47.74495315551758, 1.0\n",
      "Train loss and acc of batch 63: 48.93635177612305, 0.96875\n",
      "Train loss and acc of batch 64: 47.961708068847656, 0.984375\n",
      "Train loss and acc of batch 65: 47.744937896728516, 1.0\n",
      "Train loss and acc of batch 66: 47.74492263793945, 1.0\n",
      "Train loss and acc of batch 67: 48.5573844909668, 0.96875\n",
      "Train loss and acc of batch 68: 48.340606689453125, 0.984375\n",
      "Train loss and acc of batch 69: 47.96165466308594, 0.984375\n",
      "Train loss and acc of batch 70: 47.74488830566406, 1.0\n",
      "Training accuracy and loss of epoch #496: 0.9897, 48.0661\n",
      "Saved model by train loss 48.06608205446055\n",
      "Train loss and acc of batch 0: 47.744876861572266, 1.0\n",
      "Train loss and acc of batch 1: 47.744869232177734, 1.0\n",
      "Train loss and acc of batch 2: 47.74486541748047, 1.0\n",
      "Train loss and acc of batch 3: 47.96161651611328, 0.984375\n",
      "Train loss and acc of batch 4: 47.74484634399414, 1.0\n",
      "Train loss and acc of batch 5: 49.09375762939453, 0.96875\n",
      "Train loss and acc of batch 6: 48.247440338134766, 0.96875\n",
      "Train loss and acc of batch 7: 47.744815826416016, 1.0\n",
      "Train loss and acc of batch 8: 48.34050750732422, 0.984375\n",
      "Train loss and acc of batch 9: 48.03065490722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.74479293823242, 1.0\n",
      "Train loss and acc of batch 11: 47.744781494140625, 1.0\n",
      "Train loss and acc of batch 12: 48.49799728393555, 0.984375\n",
      "Train loss and acc of batch 13: 47.96153259277344, 0.984375\n",
      "Train loss and acc of batch 14: 47.961524963378906, 0.984375\n",
      "Train loss and acc of batch 15: 48.34044647216797, 0.984375\n",
      "Train loss and acc of batch 16: 48.34043884277344, 0.984375\n",
      "Train loss and acc of batch 17: 48.49795150756836, 0.984375\n",
      "Train loss and acc of batch 18: 48.62627410888672, 0.96875\n",
      "Train loss and acc of batch 19: 47.74470901489258, 1.0\n",
      "Train loss and acc of batch 20: 47.74469757080078, 1.0\n",
      "Train loss and acc of batch 21: 48.34039306640625, 0.984375\n",
      "Train loss and acc of batch 22: 48.34038543701172, 0.984375\n",
      "Train loss and acc of batch 23: 47.74467849731445, 1.0\n",
      "Train loss and acc of batch 24: 48.340370178222656, 0.984375\n",
      "Train loss and acc of batch 25: 47.744659423828125, 1.0\n",
      "Train loss and acc of batch 26: 47.74464797973633, 1.0\n",
      "Train loss and acc of batch 27: 47.74464416503906, 1.0\n",
      "Train loss and acc of batch 28: 47.744625091552734, 1.0\n",
      "Train loss and acc of batch 29: 48.34032440185547, 0.984375\n",
      "Train loss and acc of batch 30: 47.74461364746094, 1.0\n",
      "Train loss and acc of batch 31: 47.96136474609375, 0.984375\n",
      "Train loss and acc of batch 32: 47.74459457397461, 1.0\n",
      "Train loss and acc of batch 33: 47.744590759277344, 1.0\n",
      "Train loss and acc of batch 34: 48.34027862548828, 0.984375\n",
      "Train loss and acc of batch 35: 48.178096771240234, 0.96875\n",
      "Train loss and acc of batch 36: 47.74455642700195, 1.0\n",
      "Train loss and acc of batch 37: 48.49777603149414, 0.984375\n",
      "Train loss and acc of batch 38: 49.093467712402344, 0.96875\n",
      "Train loss and acc of batch 39: 47.96129608154297, 0.984375\n",
      "Train loss and acc of batch 40: 47.74452590942383, 1.0\n",
      "Train loss and acc of batch 41: 49.093448638916016, 0.96875\n",
      "Train loss and acc of batch 42: 47.744510650634766, 1.0\n",
      "Train loss and acc of batch 43: 48.34019470214844, 0.984375\n",
      "Train loss and acc of batch 44: 47.74449157714844, 1.0\n",
      "Train loss and acc of batch 45: 48.340179443359375, 0.984375\n",
      "Train loss and acc of batch 46: 48.03032684326172, 0.984375\n",
      "Train loss and acc of batch 47: 47.744468688964844, 1.0\n",
      "Train loss and acc of batch 48: 47.74445343017578, 1.0\n",
      "Train loss and acc of batch 49: 47.744441986083984, 1.0\n",
      "Train loss and acc of batch 50: 48.34014129638672, 0.984375\n",
      "Train loss and acc of batch 51: 49.093353271484375, 0.96875\n",
      "Train loss and acc of batch 52: 49.00025939941406, 0.953125\n",
      "Train loss and acc of batch 53: 47.744407653808594, 1.0\n",
      "Train loss and acc of batch 54: 47.96116638183594, 0.984375\n",
      "Train loss and acc of batch 55: 47.7443962097168, 1.0\n",
      "Train loss and acc of batch 56: 47.744384765625, 1.0\n",
      "Train loss and acc of batch 57: 48.34007263183594, 0.984375\n",
      "Train loss and acc of batch 58: 47.74436569213867, 1.0\n",
      "Train loss and acc of batch 59: 47.74435043334961, 1.0\n",
      "Train loss and acc of batch 60: 47.744346618652344, 1.0\n",
      "Train loss and acc of batch 61: 47.74434280395508, 1.0\n",
      "Train loss and acc of batch 62: 47.744327545166016, 1.0\n",
      "Train loss and acc of batch 63: 48.93572235107422, 0.96875\n",
      "Train loss and acc of batch 64: 47.961082458496094, 0.984375\n",
      "Train loss and acc of batch 65: 47.744300842285156, 1.0\n",
      "Train loss and acc of batch 66: 47.744293212890625, 1.0\n",
      "Train loss and acc of batch 67: 48.5567512512207, 0.96875\n",
      "Train loss and acc of batch 68: 48.33998107910156, 0.984375\n",
      "Train loss and acc of batch 69: 47.961036682128906, 0.984375\n",
      "Train loss and acc of batch 70: 47.7442626953125, 1.0\n",
      "Training accuracy and loss of epoch #497: 0.9897, 48.0655\n",
      "Saved model by train loss 48.06545279059612\n",
      "Train loss and acc of batch 0: 47.7442512512207, 1.0\n",
      "Train loss and acc of batch 1: 47.74424362182617, 1.0\n",
      "Train loss and acc of batch 2: 47.744232177734375, 1.0\n",
      "Train loss and acc of batch 3: 47.96099090576172, 0.984375\n",
      "Train loss and acc of batch 4: 47.74421691894531, 1.0\n",
      "Train loss and acc of batch 5: 49.09313201904297, 0.96875\n",
      "Train loss and acc of batch 6: 48.24681091308594, 0.96875\n",
      "Train loss and acc of batch 7: 47.74418640136719, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 8: 48.339881896972656, 0.984375\n",
      "Train loss and acc of batch 9: 48.03002166748047, 0.984375\n",
      "Train loss and acc of batch 10: 47.74415969848633, 1.0\n",
      "Train loss and acc of batch 11: 47.7441520690918, 1.0\n",
      "Train loss and acc of batch 12: 48.49736785888672, 0.984375\n",
      "Train loss and acc of batch 13: 47.960899353027344, 0.984375\n",
      "Train loss and acc of batch 14: 47.96089172363281, 0.984375\n",
      "Train loss and acc of batch 15: 48.339820861816406, 0.984375\n",
      "Train loss and acc of batch 16: 48.339805603027344, 0.984375\n",
      "Train loss and acc of batch 17: 48.49732208251953, 0.984375\n",
      "Train loss and acc of batch 18: 48.62564468383789, 0.96875\n",
      "Train loss and acc of batch 19: 47.744083404541016, 1.0\n",
      "Train loss and acc of batch 20: 47.74407196044922, 1.0\n",
      "Train loss and acc of batch 21: 48.33976745605469, 0.984375\n",
      "Train loss and acc of batch 22: 48.339759826660156, 0.984375\n",
      "Train loss and acc of batch 23: 47.744049072265625, 1.0\n",
      "Train loss and acc of batch 24: 48.33973693847656, 0.984375\n",
      "Train loss and acc of batch 25: 47.74402618408203, 1.0\n",
      "Train loss and acc of batch 26: 47.744022369384766, 1.0\n",
      "Train loss and acc of batch 27: 47.744014739990234, 1.0\n",
      "Train loss and acc of batch 28: 47.74400329589844, 1.0\n",
      "Train loss and acc of batch 29: 48.339698791503906, 0.984375\n",
      "Train loss and acc of batch 30: 47.743988037109375, 1.0\n",
      "Train loss and acc of batch 31: 47.96073913574219, 0.984375\n",
      "Train loss and acc of batch 32: 47.74396896362305, 1.0\n",
      "Train loss and acc of batch 33: 47.743953704833984, 1.0\n",
      "Train loss and acc of batch 34: 48.33965301513672, 0.984375\n",
      "Train loss and acc of batch 35: 48.177467346191406, 0.96875\n",
      "Train loss and acc of batch 36: 47.74393081665039, 1.0\n",
      "Train loss and acc of batch 37: 48.49714660644531, 0.984375\n",
      "Train loss and acc of batch 38: 49.09284210205078, 0.96875\n",
      "Train loss and acc of batch 39: 47.960662841796875, 0.984375\n",
      "Train loss and acc of batch 40: 47.743896484375, 1.0\n",
      "Train loss and acc of batch 41: 49.092811584472656, 0.96875\n",
      "Train loss and acc of batch 42: 47.74388122558594, 1.0\n",
      "Train loss and acc of batch 43: 48.339576721191406, 0.984375\n",
      "Train loss and acc of batch 44: 47.74386215209961, 1.0\n",
      "Train loss and acc of batch 45: 48.33954620361328, 0.984375\n",
      "Train loss and acc of batch 46: 48.029693603515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.743831634521484, 1.0\n",
      "Train loss and acc of batch 48: 47.74382400512695, 1.0\n",
      "Train loss and acc of batch 49: 47.74381637573242, 1.0\n",
      "Train loss and acc of batch 50: 48.339508056640625, 0.984375\n",
      "Train loss and acc of batch 51: 49.09272003173828, 0.96875\n",
      "Train loss and acc of batch 52: 48.999629974365234, 0.953125\n",
      "Train loss and acc of batch 53: 47.743778228759766, 1.0\n",
      "Train loss and acc of batch 54: 47.960533142089844, 0.984375\n",
      "Train loss and acc of batch 55: 47.7437629699707, 1.0\n",
      "Train loss and acc of batch 56: 47.743751525878906, 1.0\n",
      "Train loss and acc of batch 57: 48.339447021484375, 0.984375\n",
      "Train loss and acc of batch 58: 47.743736267089844, 1.0\n",
      "Train loss and acc of batch 59: 47.74372863769531, 1.0\n",
      "Train loss and acc of batch 60: 47.743717193603516, 1.0\n",
      "Train loss and acc of batch 61: 47.743709564208984, 1.0\n",
      "Train loss and acc of batch 62: 47.74369812011719, 1.0\n",
      "Train loss and acc of batch 63: 48.935096740722656, 0.96875\n",
      "Train loss and acc of batch 64: 47.96044921875, 0.984375\n",
      "Train loss and acc of batch 65: 47.743675231933594, 1.0\n",
      "Train loss and acc of batch 66: 47.7436637878418, 1.0\n",
      "Train loss and acc of batch 67: 48.556121826171875, 0.96875\n",
      "Train loss and acc of batch 68: 48.33934783935547, 0.984375\n",
      "Train loss and acc of batch 69: 47.96040344238281, 0.984375\n",
      "Train loss and acc of batch 70: 47.74362564086914, 1.0\n",
      "Training accuracy and loss of epoch #498: 0.9897, 48.0648\n",
      "Saved model by train loss 48.06482341927542\n",
      "Train loss and acc of batch 0: 47.74361801147461, 1.0\n",
      "Train loss and acc of batch 1: 47.743614196777344, 1.0\n",
      "Train loss and acc of batch 2: 47.74360656738281, 1.0\n",
      "Train loss and acc of batch 3: 47.960365295410156, 0.984375\n",
      "Train loss and acc of batch 4: 47.74358367919922, 1.0\n",
      "Train loss and acc of batch 5: 49.092498779296875, 0.96875\n",
      "Train loss and acc of batch 6: 48.246185302734375, 0.96875\n",
      "Train loss and acc of batch 7: 47.743560791015625, 1.0\n",
      "Train loss and acc of batch 8: 48.339256286621094, 0.984375\n",
      "Train loss and acc of batch 9: 48.029396057128906, 0.984375\n",
      "Train loss and acc of batch 10: 47.743534088134766, 1.0\n",
      "Train loss and acc of batch 11: 47.74352264404297, 1.0\n",
      "Train loss and acc of batch 12: 48.49673843383789, 0.984375\n",
      "Train loss and acc of batch 13: 47.96026611328125, 0.984375\n",
      "Train loss and acc of batch 14: 47.96025848388672, 0.984375\n",
      "Train loss and acc of batch 15: 48.33918762207031, 0.984375\n",
      "Train loss and acc of batch 16: 48.33917999267578, 0.984375\n",
      "Train loss and acc of batch 17: 48.4966926574707, 0.984375\n",
      "Train loss and acc of batch 18: 48.62501525878906, 0.96875\n",
      "Train loss and acc of batch 19: 47.74345016479492, 1.0\n",
      "Train loss and acc of batch 20: 47.743446350097656, 1.0\n",
      "Train loss and acc of batch 21: 48.339134216308594, 0.984375\n",
      "Train loss and acc of batch 22: 48.33912658691406, 0.984375\n",
      "Train loss and acc of batch 23: 47.74341583251953, 1.0\n",
      "Train loss and acc of batch 24: 48.339111328125, 0.984375\n",
      "Train loss and acc of batch 25: 47.74340057373047, 1.0\n",
      "Train loss and acc of batch 26: 47.74339294433594, 1.0\n",
      "Train loss and acc of batch 27: 47.74338150024414, 1.0\n",
      "Train loss and acc of batch 28: 47.74337387084961, 1.0\n",
      "Train loss and acc of batch 29: 48.33906555175781, 0.984375\n",
      "Train loss and acc of batch 30: 47.74335479736328, 1.0\n",
      "Train loss and acc of batch 31: 47.960113525390625, 0.984375\n",
      "Train loss and acc of batch 32: 47.74333572387695, 1.0\n",
      "Train loss and acc of batch 33: 47.74332809448242, 1.0\n",
      "Train loss and acc of batch 34: 48.339019775390625, 0.984375\n",
      "Train loss and acc of batch 35: 48.176841735839844, 0.96875\n",
      "Train loss and acc of batch 36: 47.74330139160156, 1.0\n",
      "Train loss and acc of batch 37: 48.496517181396484, 0.984375\n",
      "Train loss and acc of batch 38: 49.09220886230469, 0.96875\n",
      "Train loss and acc of batch 39: 47.960044860839844, 0.984375\n",
      "Train loss and acc of batch 40: 47.74326705932617, 1.0\n",
      "Train loss and acc of batch 41: 49.09217834472656, 0.96875\n",
      "Train loss and acc of batch 42: 47.74324417114258, 1.0\n",
      "Train loss and acc of batch 43: 48.33894348144531, 0.984375\n",
      "Train loss and acc of batch 44: 47.743228912353516, 1.0\n",
      "Train loss and acc of batch 45: 48.33892059326172, 0.984375\n",
      "Train loss and acc of batch 46: 48.02906799316406, 0.984375\n",
      "Train loss and acc of batch 47: 47.74320602416992, 1.0\n",
      "Train loss and acc of batch 48: 47.74319076538086, 1.0\n",
      "Train loss and acc of batch 49: 47.743186950683594, 1.0\n",
      "Train loss and acc of batch 50: 48.33887481689453, 0.984375\n",
      "Train loss and acc of batch 51: 49.09209442138672, 0.96875\n",
      "Train loss and acc of batch 52: 48.999000549316406, 0.953125\n",
      "Train loss and acc of batch 53: 47.74315643310547, 1.0\n",
      "Train loss and acc of batch 54: 47.95990753173828, 0.984375\n",
      "Train loss and acc of batch 55: 47.743133544921875, 1.0\n",
      "Train loss and acc of batch 56: 47.74312210083008, 1.0\n",
      "Train loss and acc of batch 57: 48.33881378173828, 0.984375\n",
      "Train loss and acc of batch 58: 47.74311065673828, 1.0\n",
      "Train loss and acc of batch 59: 47.743099212646484, 1.0\n",
      "Train loss and acc of batch 60: 47.74308776855469, 1.0\n",
      "Train loss and acc of batch 61: 47.743080139160156, 1.0\n",
      "Train loss and acc of batch 62: 47.743072509765625, 1.0\n",
      "Train loss and acc of batch 63: 48.93446731567383, 0.96875\n",
      "Train loss and acc of batch 64: 47.959815979003906, 0.984375\n",
      "Train loss and acc of batch 65: 47.7430419921875, 1.0\n",
      "Train loss and acc of batch 66: 47.743038177490234, 1.0\n",
      "Train loss and acc of batch 67: 48.55549240112305, 0.96875\n",
      "Train loss and acc of batch 68: 48.338722229003906, 0.984375\n",
      "Train loss and acc of batch 69: 47.95977783203125, 0.984375\n",
      "Train loss and acc of batch 70: 47.74299621582031, 1.0\n",
      "Training accuracy and loss of epoch #499: 0.9897, 48.0642\n",
      "Saved model by train loss 48.06419415541098\n",
      "Train loss and acc of batch 0: 47.74299240112305, 1.0\n",
      "Train loss and acc of batch 1: 47.742984771728516, 1.0\n",
      "Train loss and acc of batch 2: 47.74297332763672, 1.0\n",
      "Train loss and acc of batch 3: 47.95973205566406, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 4: 47.74296188354492, 1.0\n",
      "Train loss and acc of batch 5: 49.09187316894531, 0.96875\n",
      "Train loss and acc of batch 6: 48.24555206298828, 0.96875\n",
      "Train loss and acc of batch 7: 47.74292755126953, 1.0\n",
      "Train loss and acc of batch 8: 48.338623046875, 0.984375\n",
      "Train loss and acc of batch 9: 48.028770446777344, 0.984375\n",
      "Train loss and acc of batch 10: 47.74290466308594, 1.0\n",
      "Train loss and acc of batch 11: 47.742897033691406, 1.0\n",
      "Train loss and acc of batch 12: 48.49610900878906, 0.984375\n",
      "Train loss and acc of batch 13: 47.95964050292969, 0.984375\n",
      "Train loss and acc of batch 14: 47.959632873535156, 0.984375\n",
      "Train loss and acc of batch 15: 48.33856201171875, 0.984375\n",
      "Train loss and acc of batch 16: 48.33854675292969, 0.984375\n",
      "Train loss and acc of batch 17: 48.496063232421875, 0.984375\n",
      "Train loss and acc of batch 18: 48.62438201904297, 0.96875\n",
      "Train loss and acc of batch 19: 47.74282455444336, 1.0\n",
      "Train loss and acc of batch 20: 47.74281692504883, 1.0\n",
      "Train loss and acc of batch 21: 48.3385009765625, 0.984375\n",
      "Train loss and acc of batch 22: 48.33849334716797, 0.984375\n",
      "Train loss and acc of batch 23: 47.74279022216797, 1.0\n",
      "Train loss and acc of batch 24: 48.338478088378906, 0.984375\n",
      "Train loss and acc of batch 25: 47.74277114868164, 1.0\n",
      "Train loss and acc of batch 26: 47.74276351928711, 1.0\n",
      "Train loss and acc of batch 27: 47.74275588989258, 1.0\n",
      "Train loss and acc of batch 28: 47.74274444580078, 1.0\n",
      "Train loss and acc of batch 29: 48.33843994140625, 0.984375\n",
      "Train loss and acc of batch 30: 47.74272537231445, 1.0\n",
      "Train loss and acc of batch 31: 47.95948028564453, 0.984375\n",
      "Train loss and acc of batch 32: 47.74271011352539, 1.0\n",
      "Train loss and acc of batch 33: 47.74269485473633, 1.0\n",
      "Train loss and acc of batch 34: 48.33839416503906, 0.984375\n",
      "Train loss and acc of batch 35: 48.17620849609375, 0.96875\n",
      "Train loss and acc of batch 36: 47.742671966552734, 1.0\n",
      "Train loss and acc of batch 37: 48.495887756347656, 0.984375\n",
      "Train loss and acc of batch 38: 49.091583251953125, 0.96875\n",
      "Train loss and acc of batch 39: 47.95941162109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.742637634277344, 1.0\n",
      "Train loss and acc of batch 41: 49.091552734375, 0.96875\n",
      "Train loss and acc of batch 42: 47.742618560791016, 1.0\n",
      "Train loss and acc of batch 43: 48.33831787109375, 0.984375\n",
      "Train loss and acc of batch 44: 47.74259948730469, 1.0\n",
      "Train loss and acc of batch 45: 48.338294982910156, 0.984375\n",
      "Train loss and acc of batch 46: 48.0284423828125, 0.984375\n",
      "Train loss and acc of batch 47: 47.74257278442383, 1.0\n",
      "Train loss and acc of batch 48: 47.74256896972656, 1.0\n",
      "Train loss and acc of batch 49: 47.7425537109375, 1.0\n",
      "Train loss and acc of batch 50: 48.33824157714844, 0.984375\n",
      "Train loss and acc of batch 51: 49.091461181640625, 0.96875\n",
      "Train loss and acc of batch 52: 48.99837112426758, 0.953125\n",
      "Train loss and acc of batch 53: 47.74251937866211, 1.0\n",
      "Train loss and acc of batch 54: 47.95928192138672, 0.984375\n",
      "Train loss and acc of batch 55: 47.74250411987305, 1.0\n",
      "Train loss and acc of batch 56: 47.742496490478516, 1.0\n",
      "Train loss and acc of batch 57: 48.33818817138672, 0.984375\n",
      "Train loss and acc of batch 58: 47.74247360229492, 1.0\n",
      "Train loss and acc of batch 59: 47.74246597290039, 1.0\n",
      "Train loss and acc of batch 60: 47.742462158203125, 1.0\n",
      "Train loss and acc of batch 61: 47.74244689941406, 1.0\n",
      "Train loss and acc of batch 62: 47.7424430847168, 1.0\n",
      "Train loss and acc of batch 63: 48.933837890625, 0.96875\n",
      "Train loss and acc of batch 64: 47.959190368652344, 0.984375\n",
      "Train loss and acc of batch 65: 47.74241256713867, 1.0\n",
      "Train loss and acc of batch 66: 47.74240493774414, 1.0\n",
      "Train loss and acc of batch 67: 48.55486297607422, 0.96875\n",
      "Train loss and acc of batch 68: 48.33808898925781, 0.984375\n",
      "Train loss and acc of batch 69: 47.959144592285156, 0.984375\n",
      "Train loss and acc of batch 70: 47.74237060546875, 1.0\n",
      "Training accuracy and loss of epoch #500: 0.9897, 48.0636\n",
      "Saved model by train loss 48.06356483781841\n",
      "Train loss and acc of batch 0: 47.742366790771484, 1.0\n",
      "Train loss and acc of batch 1: 47.74235534667969, 1.0\n",
      "Train loss and acc of batch 2: 47.74234390258789, 1.0\n",
      "Train loss and acc of batch 3: 47.95909881591797, 0.984375\n",
      "Train loss and acc of batch 4: 47.74232482910156, 1.0\n",
      "Train loss and acc of batch 5: 49.09124755859375, 0.96875\n",
      "Train loss and acc of batch 6: 48.24492645263672, 0.96875\n",
      "Train loss and acc of batch 7: 47.7422981262207, 1.0\n",
      "Train loss and acc of batch 8: 48.33799743652344, 0.984375\n",
      "Train loss and acc of batch 9: 48.02813720703125, 0.984375\n",
      "Train loss and acc of batch 10: 47.74227523803711, 1.0\n",
      "Train loss and acc of batch 11: 47.74226379394531, 1.0\n",
      "Train loss and acc of batch 12: 48.49547576904297, 0.984375\n",
      "Train loss and acc of batch 13: 47.959014892578125, 0.984375\n",
      "Train loss and acc of batch 14: 47.959007263183594, 0.984375\n",
      "Train loss and acc of batch 15: 48.337928771972656, 0.984375\n",
      "Train loss and acc of batch 16: 48.337928771972656, 0.984375\n",
      "Train loss and acc of batch 17: 48.49543380737305, 0.984375\n",
      "Train loss and acc of batch 18: 48.623756408691406, 0.96875\n",
      "Train loss and acc of batch 19: 47.742191314697266, 1.0\n",
      "Train loss and acc of batch 20: 47.7421875, 1.0\n",
      "Train loss and acc of batch 21: 48.33787536621094, 0.984375\n",
      "Train loss and acc of batch 22: 48.33787536621094, 0.984375\n",
      "Train loss and acc of batch 23: 47.74216079711914, 1.0\n",
      "Train loss and acc of batch 24: 48.337852478027344, 0.984375\n",
      "Train loss and acc of batch 25: 47.74214172363281, 1.0\n",
      "Train loss and acc of batch 26: 47.74212646484375, 1.0\n",
      "Train loss and acc of batch 27: 47.742122650146484, 1.0\n",
      "Train loss and acc of batch 28: 47.74211502075195, 1.0\n",
      "Train loss and acc of batch 29: 48.337806701660156, 0.984375\n",
      "Train loss and acc of batch 30: 47.74209976196289, 1.0\n",
      "Train loss and acc of batch 31: 47.95884704589844, 0.984375\n",
      "Train loss and acc of batch 32: 47.7420768737793, 1.0\n",
      "Train loss and acc of batch 33: 47.742069244384766, 1.0\n",
      "Train loss and acc of batch 34: 48.3377685546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.17558288574219, 0.96875\n",
      "Train loss and acc of batch 36: 47.742042541503906, 1.0\n",
      "Train loss and acc of batch 37: 48.49525833129883, 0.984375\n",
      "Train loss and acc of batch 38: 49.09095001220703, 0.96875\n",
      "Train loss and acc of batch 39: 47.95878601074219, 0.984375\n",
      "Train loss and acc of batch 40: 47.742000579833984, 1.0\n",
      "Train loss and acc of batch 41: 49.09092712402344, 0.96875\n",
      "Train loss and acc of batch 42: 47.74199295043945, 1.0\n",
      "Train loss and acc of batch 43: 48.337684631347656, 0.984375\n",
      "Train loss and acc of batch 44: 47.74197769165039, 1.0\n",
      "Train loss and acc of batch 45: 48.337669372558594, 0.984375\n",
      "Train loss and acc of batch 46: 48.027809143066406, 0.984375\n",
      "Train loss and acc of batch 47: 47.741943359375, 1.0\n",
      "Train loss and acc of batch 48: 47.74193572998047, 1.0\n",
      "Train loss and acc of batch 49: 47.7419319152832, 1.0\n",
      "Train loss and acc of batch 50: 48.337623596191406, 0.984375\n",
      "Train loss and acc of batch 51: 49.09083557128906, 0.96875\n",
      "Train loss and acc of batch 52: 48.997745513916016, 0.953125\n",
      "Train loss and acc of batch 53: 47.74189376831055, 1.0\n",
      "Train loss and acc of batch 54: 47.958648681640625, 0.984375\n",
      "Train loss and acc of batch 55: 47.74187469482422, 1.0\n",
      "Train loss and acc of batch 56: 47.74186325073242, 1.0\n",
      "Train loss and acc of batch 57: 48.337554931640625, 0.984375\n",
      "Train loss and acc of batch 58: 47.74184799194336, 1.0\n",
      "Train loss and acc of batch 59: 47.74184036254883, 1.0\n",
      "Train loss and acc of batch 60: 47.74182891845703, 1.0\n",
      "Train loss and acc of batch 61: 47.7418212890625, 1.0\n",
      "Train loss and acc of batch 62: 47.74181365966797, 1.0\n",
      "Train loss and acc of batch 63: 48.93320846557617, 0.96875\n",
      "Train loss and acc of batch 64: 47.95855712890625, 0.984375\n",
      "Train loss and acc of batch 65: 47.74178695678711, 1.0\n",
      "Train loss and acc of batch 66: 47.74177551269531, 1.0\n",
      "Train loss and acc of batch 67: 48.55424118041992, 0.96875\n",
      "Train loss and acc of batch 68: 48.33746337890625, 0.984375\n",
      "Train loss and acc of batch 69: 47.958518981933594, 0.984375\n",
      "Train loss and acc of batch 70: 47.74174118041992, 1.0\n",
      "Training accuracy and loss of epoch #501: 0.9897, 48.0629\n",
      "Saved model by train loss 48.06293627241968\n",
      "Train loss and acc of batch 0: 47.741729736328125, 1.0\n",
      "Train loss and acc of batch 1: 47.74172592163086, 1.0\n",
      "Train loss and acc of batch 2: 47.74171447753906, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 3: 47.958473205566406, 0.984375\n",
      "Train loss and acc of batch 4: 47.74169921875, 1.0\n",
      "Train loss and acc of batch 5: 49.090614318847656, 0.96875\n",
      "Train loss and acc of batch 6: 48.24429702758789, 0.96875\n",
      "Train loss and acc of batch 7: 47.74167251586914, 1.0\n",
      "Train loss and acc of batch 8: 48.337364196777344, 0.984375\n",
      "Train loss and acc of batch 9: 48.027503967285156, 0.984375\n",
      "Train loss and acc of batch 10: 47.74164581298828, 1.0\n",
      "Train loss and acc of batch 11: 47.74163818359375, 1.0\n",
      "Train loss and acc of batch 12: 48.494850158691406, 0.984375\n",
      "Train loss and acc of batch 13: 47.95838165283203, 0.984375\n",
      "Train loss and acc of batch 14: 47.9583740234375, 0.984375\n",
      "Train loss and acc of batch 15: 48.337303161621094, 0.984375\n",
      "Train loss and acc of batch 16: 48.33729553222656, 0.984375\n",
      "Train loss and acc of batch 17: 48.494808197021484, 0.984375\n",
      "Train loss and acc of batch 18: 48.623130798339844, 0.96875\n",
      "Train loss and acc of batch 19: 47.7415657043457, 1.0\n",
      "Train loss and acc of batch 20: 47.741554260253906, 1.0\n",
      "Train loss and acc of batch 21: 48.337249755859375, 0.984375\n",
      "Train loss and acc of batch 22: 48.33723449707031, 0.984375\n",
      "Train loss and acc of batch 23: 47.74153137207031, 1.0\n",
      "Train loss and acc of batch 24: 48.33722686767578, 0.984375\n",
      "Train loss and acc of batch 25: 47.74151611328125, 1.0\n",
      "Train loss and acc of batch 26: 47.74150466918945, 1.0\n",
      "Train loss and acc of batch 27: 47.741493225097656, 1.0\n",
      "Train loss and acc of batch 28: 47.741485595703125, 1.0\n",
      "Train loss and acc of batch 29: 48.337181091308594, 0.984375\n",
      "Train loss and acc of batch 30: 47.74146270751953, 1.0\n",
      "Train loss and acc of batch 31: 47.958221435546875, 0.984375\n",
      "Train loss and acc of batch 32: 47.741451263427734, 1.0\n",
      "Train loss and acc of batch 33: 47.7414436340332, 1.0\n",
      "Train loss and acc of batch 34: 48.337127685546875, 0.984375\n",
      "Train loss and acc of batch 35: 48.174949645996094, 0.96875\n",
      "Train loss and acc of batch 36: 47.74141311645508, 1.0\n",
      "Train loss and acc of batch 37: 48.49462890625, 0.984375\n",
      "Train loss and acc of batch 38: 49.09031677246094, 0.96875\n",
      "Train loss and acc of batch 39: 47.958152770996094, 0.984375\n",
      "Train loss and acc of batch 40: 47.74137878417969, 1.0\n",
      "Train loss and acc of batch 41: 49.090293884277344, 0.96875\n",
      "Train loss and acc of batch 42: 47.74135971069336, 1.0\n",
      "Train loss and acc of batch 43: 48.337059020996094, 0.984375\n",
      "Train loss and acc of batch 44: 47.74134063720703, 1.0\n",
      "Train loss and acc of batch 45: 48.3370361328125, 0.984375\n",
      "Train loss and acc of batch 46: 48.02717590332031, 0.984375\n",
      "Train loss and acc of batch 47: 47.74131774902344, 1.0\n",
      "Train loss and acc of batch 48: 47.74130630493164, 1.0\n",
      "Train loss and acc of batch 49: 47.74129867553711, 1.0\n",
      "Train loss and acc of batch 50: 48.33699035644531, 0.984375\n",
      "Train loss and acc of batch 51: 49.09020233154297, 0.96875\n",
      "Train loss and acc of batch 52: 48.99711227416992, 0.953125\n",
      "Train loss and acc of batch 53: 47.741268157958984, 1.0\n",
      "Train loss and acc of batch 54: 47.95802307128906, 0.984375\n",
      "Train loss and acc of batch 55: 47.741241455078125, 1.0\n",
      "Train loss and acc of batch 56: 47.74123764038086, 1.0\n",
      "Train loss and acc of batch 57: 48.33692932128906, 0.984375\n",
      "Train loss and acc of batch 58: 47.74121856689453, 1.0\n",
      "Train loss and acc of batch 59: 47.7412109375, 1.0\n",
      "Train loss and acc of batch 60: 47.74120330810547, 1.0\n",
      "Train loss and acc of batch 61: 47.74119186401367, 1.0\n",
      "Train loss and acc of batch 62: 47.741188049316406, 1.0\n",
      "Train loss and acc of batch 63: 48.93257141113281, 0.96875\n",
      "Train loss and acc of batch 64: 47.95793151855469, 0.984375\n",
      "Train loss and acc of batch 65: 47.741153717041016, 1.0\n",
      "Train loss and acc of batch 66: 47.741153717041016, 1.0\n",
      "Train loss and acc of batch 67: 48.55360794067383, 0.96875\n",
      "Train loss and acc of batch 68: 48.336830139160156, 0.984375\n",
      "Train loss and acc of batch 69: 47.9578857421875, 0.984375\n",
      "Train loss and acc of batch 70: 47.741111755371094, 1.0\n",
      "Training accuracy and loss of epoch #502: 0.9897, 48.0623\n",
      "Saved model by train loss 48.062306525002064\n",
      "Train loss and acc of batch 0: 47.74110412597656, 1.0\n",
      "Train loss and acc of batch 1: 47.741092681884766, 1.0\n",
      "Train loss and acc of batch 2: 47.741085052490234, 1.0\n",
      "Train loss and acc of batch 3: 47.957847595214844, 0.984375\n",
      "Train loss and acc of batch 4: 47.74106979370117, 1.0\n",
      "Train loss and acc of batch 5: 49.08998107910156, 0.96875\n",
      "Train loss and acc of batch 6: 48.2436637878418, 0.96875\n",
      "Train loss and acc of batch 7: 47.74103927612305, 1.0\n",
      "Train loss and acc of batch 8: 48.33673095703125, 0.984375\n",
      "Train loss and acc of batch 9: 48.026878356933594, 0.984375\n",
      "Train loss and acc of batch 10: 47.74101638793945, 1.0\n",
      "Train loss and acc of batch 11: 47.741004943847656, 1.0\n",
      "Train loss and acc of batch 12: 48.494224548339844, 0.984375\n",
      "Train loss and acc of batch 13: 47.95775604248047, 0.984375\n",
      "Train loss and acc of batch 14: 47.957740783691406, 0.984375\n",
      "Train loss and acc of batch 15: 48.336669921875, 0.984375\n",
      "Train loss and acc of batch 16: 48.33666229248047, 0.984375\n",
      "Train loss and acc of batch 17: 48.494178771972656, 0.984375\n",
      "Train loss and acc of batch 18: 48.62249755859375, 0.96875\n",
      "Train loss and acc of batch 19: 47.74094009399414, 1.0\n",
      "Train loss and acc of batch 20: 47.740928649902344, 1.0\n",
      "Train loss and acc of batch 21: 48.33661651611328, 0.984375\n",
      "Train loss and acc of batch 22: 48.33660888671875, 0.984375\n",
      "Train loss and acc of batch 23: 47.740901947021484, 1.0\n",
      "Train loss and acc of batch 24: 48.33659362792969, 0.984375\n",
      "Train loss and acc of batch 25: 47.74087905883789, 1.0\n",
      "Train loss and acc of batch 26: 47.740875244140625, 1.0\n",
      "Train loss and acc of batch 27: 47.740867614746094, 1.0\n",
      "Train loss and acc of batch 28: 47.7408561706543, 1.0\n",
      "Train loss and acc of batch 29: 48.3365478515625, 0.984375\n",
      "Train loss and acc of batch 30: 47.74083709716797, 1.0\n",
      "Train loss and acc of batch 31: 47.95759582519531, 0.984375\n",
      "Train loss and acc of batch 32: 47.740821838378906, 1.0\n",
      "Train loss and acc of batch 33: 47.740814208984375, 1.0\n",
      "Train loss and acc of batch 34: 48.336509704589844, 0.984375\n",
      "Train loss and acc of batch 35: 48.174320220947266, 0.96875\n",
      "Train loss and acc of batch 36: 47.740779876708984, 1.0\n",
      "Train loss and acc of batch 37: 48.493995666503906, 0.984375\n",
      "Train loss and acc of batch 38: 49.089691162109375, 0.96875\n",
      "Train loss and acc of batch 39: 47.95751953125, 0.984375\n",
      "Train loss and acc of batch 40: 47.740753173828125, 1.0\n",
      "Train loss and acc of batch 41: 49.08966827392578, 0.96875\n",
      "Train loss and acc of batch 42: 47.7407341003418, 1.0\n",
      "Train loss and acc of batch 43: 48.33641815185547, 0.984375\n",
      "Train loss and acc of batch 44: 47.7407112121582, 1.0\n",
      "Train loss and acc of batch 45: 48.336402893066406, 0.984375\n",
      "Train loss and acc of batch 46: 48.02655029296875, 0.984375\n",
      "Train loss and acc of batch 47: 47.74068832397461, 1.0\n",
      "Train loss and acc of batch 48: 47.74068069458008, 1.0\n",
      "Train loss and acc of batch 49: 47.74066925048828, 1.0\n",
      "Train loss and acc of batch 50: 48.33636474609375, 0.984375\n",
      "Train loss and acc of batch 51: 49.089576721191406, 0.96875\n",
      "Train loss and acc of batch 52: 48.996482849121094, 0.953125\n",
      "Train loss and acc of batch 53: 47.74063491821289, 1.0\n",
      "Train loss and acc of batch 54: 47.95738983154297, 0.984375\n",
      "Train loss and acc of batch 55: 47.74061584472656, 1.0\n",
      "Train loss and acc of batch 56: 47.74060821533203, 1.0\n",
      "Train loss and acc of batch 57: 48.3363037109375, 0.984375\n",
      "Train loss and acc of batch 58: 47.7405891418457, 1.0\n",
      "Train loss and acc of batch 59: 47.74058151245117, 1.0\n",
      "Train loss and acc of batch 60: 47.74057388305664, 1.0\n",
      "Train loss and acc of batch 61: 47.74056625366211, 1.0\n",
      "Train loss and acc of batch 62: 47.74055480957031, 1.0\n",
      "Train loss and acc of batch 63: 48.931949615478516, 0.96875\n",
      "Train loss and acc of batch 64: 47.957298278808594, 0.984375\n",
      "Train loss and acc of batch 65: 47.74053192138672, 1.0\n",
      "Train loss and acc of batch 66: 47.740516662597656, 1.0\n",
      "Train loss and acc of batch 67: 48.552978515625, 0.96875\n",
      "Train loss and acc of batch 68: 48.336204528808594, 0.984375\n",
      "Train loss and acc of batch 69: 47.95726013183594, 0.984375\n",
      "Train loss and acc of batch 70: 47.74048614501953, 1.0\n",
      "Training accuracy and loss of epoch #503: 0.9897, 48.0617\n",
      "Saved model by train loss 48.061677314865754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.740474700927734, 1.0\n",
      "Train loss and acc of batch 1: 47.74046325683594, 1.0\n",
      "Train loss and acc of batch 2: 47.740455627441406, 1.0\n",
      "Train loss and acc of batch 3: 47.95721435546875, 0.984375\n",
      "Train loss and acc of batch 4: 47.740440368652344, 1.0\n",
      "Train loss and acc of batch 5: 49.08935546875, 0.96875\n",
      "Train loss and acc of batch 6: 48.243038177490234, 0.96875\n",
      "Train loss and acc of batch 7: 47.740413665771484, 1.0\n",
      "Train loss and acc of batch 8: 48.33610534667969, 0.984375\n",
      "Train loss and acc of batch 9: 48.0262451171875, 0.984375\n",
      "Train loss and acc of batch 10: 47.74038314819336, 1.0\n",
      "Train loss and acc of batch 11: 47.74037551879883, 1.0\n",
      "Train loss and acc of batch 12: 48.493595123291016, 0.984375\n",
      "Train loss and acc of batch 13: 47.957130432128906, 0.984375\n",
      "Train loss and acc of batch 14: 47.957122802734375, 0.984375\n",
      "Train loss and acc of batch 15: 48.336036682128906, 0.984375\n",
      "Train loss and acc of batch 16: 48.336029052734375, 0.984375\n",
      "Train loss and acc of batch 17: 48.49354553222656, 0.984375\n",
      "Train loss and acc of batch 18: 48.62186813354492, 0.96875\n",
      "Train loss and acc of batch 19: 47.74030685424805, 1.0\n",
      "Train loss and acc of batch 20: 47.740299224853516, 1.0\n",
      "Train loss and acc of batch 21: 48.33599090576172, 0.984375\n",
      "Train loss and acc of batch 22: 48.33598327636719, 0.984375\n",
      "Train loss and acc of batch 23: 47.740272521972656, 1.0\n",
      "Train loss and acc of batch 24: 48.335960388183594, 0.984375\n",
      "Train loss and acc of batch 25: 47.74025344848633, 1.0\n",
      "Train loss and acc of batch 26: 47.7402458190918, 1.0\n",
      "Train loss and acc of batch 27: 47.740238189697266, 1.0\n",
      "Train loss and acc of batch 28: 47.740230560302734, 1.0\n",
      "Train loss and acc of batch 29: 48.33592224121094, 0.984375\n",
      "Train loss and acc of batch 30: 47.740211486816406, 1.0\n",
      "Train loss and acc of batch 31: 47.95696258544922, 0.984375\n",
      "Train loss and acc of batch 32: 47.74019241333008, 1.0\n",
      "Train loss and acc of batch 33: 47.74018478393555, 1.0\n",
      "Train loss and acc of batch 34: 48.33587646484375, 0.984375\n",
      "Train loss and acc of batch 35: 48.1736946105957, 0.96875\n",
      "Train loss and acc of batch 36: 47.74015426635742, 1.0\n",
      "Train loss and acc of batch 37: 48.49337387084961, 0.984375\n",
      "Train loss and acc of batch 38: 49.08905792236328, 0.96875\n",
      "Train loss and acc of batch 39: 47.95689392089844, 0.984375\n",
      "Train loss and acc of batch 40: 47.74011993408203, 1.0\n",
      "Train loss and acc of batch 41: 49.08904266357422, 0.96875\n",
      "Train loss and acc of batch 42: 47.74010467529297, 1.0\n",
      "Train loss and acc of batch 43: 48.33580017089844, 0.984375\n",
      "Train loss and acc of batch 44: 47.740081787109375, 1.0\n",
      "Train loss and acc of batch 45: 48.33576965332031, 0.984375\n",
      "Train loss and acc of batch 46: 48.025917053222656, 0.984375\n",
      "Train loss and acc of batch 47: 47.740055084228516, 1.0\n",
      "Train loss and acc of batch 48: 47.74004364013672, 1.0\n",
      "Train loss and acc of batch 49: 47.74003601074219, 1.0\n",
      "Train loss and acc of batch 50: 48.335731506347656, 0.984375\n",
      "Train loss and acc of batch 51: 49.08894348144531, 0.96875\n",
      "Train loss and acc of batch 52: 48.995849609375, 0.953125\n",
      "Train loss and acc of batch 53: 47.73999786376953, 1.0\n",
      "Train loss and acc of batch 54: 47.956756591796875, 0.984375\n",
      "Train loss and acc of batch 55: 47.73998260498047, 1.0\n",
      "Train loss and acc of batch 56: 47.7399787902832, 1.0\n",
      "Train loss and acc of batch 57: 48.335670471191406, 0.984375\n",
      "Train loss and acc of batch 58: 47.739959716796875, 1.0\n",
      "Train loss and acc of batch 59: 47.739952087402344, 1.0\n",
      "Train loss and acc of batch 60: 47.73994064331055, 1.0\n",
      "Train loss and acc of batch 61: 47.73992919921875, 1.0\n",
      "Train loss and acc of batch 62: 47.73991775512695, 1.0\n",
      "Train loss and acc of batch 63: 48.931312561035156, 0.96875\n",
      "Train loss and acc of batch 64: 47.9566650390625, 0.984375\n",
      "Train loss and acc of batch 65: 47.73989486694336, 1.0\n",
      "Train loss and acc of batch 66: 47.73988342285156, 1.0\n",
      "Train loss and acc of batch 67: 48.552337646484375, 0.96875\n",
      "Train loss and acc of batch 68: 48.3355712890625, 0.984375\n",
      "Train loss and acc of batch 69: 47.956626892089844, 0.984375\n",
      "Train loss and acc of batch 70: 47.73985290527344, 1.0\n",
      "Training accuracy and loss of epoch #504: 0.9897, 48.0610\n",
      "Saved model by train loss 48.06104681525432\n",
      "Train loss and acc of batch 0: 47.73984146118164, 1.0\n",
      "Train loss and acc of batch 1: 47.73983383178711, 1.0\n",
      "Train loss and acc of batch 2: 47.73982620239258, 1.0\n",
      "Train loss and acc of batch 3: 47.956581115722656, 0.984375\n",
      "Train loss and acc of batch 4: 47.739803314208984, 1.0\n",
      "Train loss and acc of batch 5: 49.088722229003906, 0.96875\n",
      "Train loss and acc of batch 6: 48.24240493774414, 0.96875\n",
      "Train loss and acc of batch 7: 47.73978042602539, 1.0\n",
      "Train loss and acc of batch 8: 48.335472106933594, 0.984375\n",
      "Train loss and acc of batch 9: 48.025611877441406, 0.984375\n",
      "Train loss and acc of batch 10: 47.73975372314453, 1.0\n",
      "Train loss and acc of batch 11: 47.739742279052734, 1.0\n",
      "Train loss and acc of batch 12: 48.492958068847656, 0.984375\n",
      "Train loss and acc of batch 13: 47.95648956298828, 0.984375\n",
      "Train loss and acc of batch 14: 47.95648193359375, 0.984375\n",
      "Train loss and acc of batch 15: 48.335411071777344, 0.984375\n",
      "Train loss and acc of batch 16: 48.33540344238281, 0.984375\n",
      "Train loss and acc of batch 17: 48.49291229248047, 0.984375\n",
      "Train loss and acc of batch 18: 48.62123489379883, 0.96875\n",
      "Train loss and acc of batch 19: 47.73967361450195, 1.0\n",
      "Train loss and acc of batch 20: 47.73966598510742, 1.0\n",
      "Train loss and acc of batch 21: 48.335357666015625, 0.984375\n",
      "Train loss and acc of batch 22: 48.335350036621094, 0.984375\n",
      "Train loss and acc of batch 23: 47.73963928222656, 1.0\n",
      "Train loss and acc of batch 24: 48.33533477783203, 0.984375\n",
      "Train loss and acc of batch 25: 47.73961639404297, 1.0\n",
      "Train loss and acc of batch 26: 47.7396125793457, 1.0\n",
      "Train loss and acc of batch 27: 47.739601135253906, 1.0\n",
      "Train loss and acc of batch 28: 47.739593505859375, 1.0\n",
      "Train loss and acc of batch 29: 48.335289001464844, 0.984375\n",
      "Train loss and acc of batch 30: 47.73957824707031, 1.0\n",
      "Train loss and acc of batch 31: 47.956329345703125, 0.984375\n",
      "Train loss and acc of batch 32: 47.73955535888672, 1.0\n",
      "Train loss and acc of batch 33: 47.73954772949219, 1.0\n",
      "Train loss and acc of batch 34: 48.335243225097656, 0.984375\n",
      "Train loss and acc of batch 35: 48.173057556152344, 0.96875\n",
      "Train loss and acc of batch 36: 47.73952865600586, 1.0\n",
      "Train loss and acc of batch 37: 48.49273681640625, 0.984375\n",
      "Train loss and acc of batch 38: 49.08843231201172, 0.96875\n",
      "Train loss and acc of batch 39: 47.956268310546875, 0.984375\n",
      "Train loss and acc of batch 40: 47.73948669433594, 1.0\n",
      "Train loss and acc of batch 41: 49.088401794433594, 0.96875\n",
      "Train loss and acc of batch 42: 47.739463806152344, 1.0\n",
      "Train loss and acc of batch 43: 48.33515930175781, 0.984375\n",
      "Train loss and acc of batch 44: 47.73945236206055, 1.0\n",
      "Train loss and acc of batch 45: 48.33514404296875, 0.984375\n",
      "Train loss and acc of batch 46: 48.025291442871094, 0.984375\n",
      "Train loss and acc of batch 47: 47.73942565917969, 1.0\n",
      "Train loss and acc of batch 48: 47.73941421508789, 1.0\n",
      "Train loss and acc of batch 49: 47.73940658569336, 1.0\n",
      "Train loss and acc of batch 50: 48.335105895996094, 0.984375\n",
      "Train loss and acc of batch 51: 49.08831024169922, 0.96875\n",
      "Train loss and acc of batch 52: 48.99522018432617, 0.953125\n",
      "Train loss and acc of batch 53: 47.73937225341797, 1.0\n",
      "Train loss and acc of batch 54: 47.95612335205078, 0.984375\n",
      "Train loss and acc of batch 55: 47.739356994628906, 1.0\n",
      "Train loss and acc of batch 56: 47.739341735839844, 1.0\n",
      "Train loss and acc of batch 57: 48.33503723144531, 0.984375\n",
      "Train loss and acc of batch 58: 47.73932647705078, 1.0\n",
      "Train loss and acc of batch 59: 47.73931884765625, 1.0\n",
      "Train loss and acc of batch 60: 47.73930740356445, 1.0\n",
      "Train loss and acc of batch 61: 47.73930358886719, 1.0\n",
      "Train loss and acc of batch 62: 47.739288330078125, 1.0\n",
      "Train loss and acc of batch 63: 48.930686950683594, 0.96875\n",
      "Train loss and acc of batch 64: 47.95603942871094, 0.984375\n",
      "Train loss and acc of batch 65: 47.7392692565918, 1.0\n",
      "Train loss and acc of batch 66: 47.7392578125, 1.0\n",
      "Train loss and acc of batch 67: 48.55171585083008, 0.96875\n",
      "Train loss and acc of batch 68: 48.334938049316406, 0.984375\n",
      "Train loss and acc of batch 69: 47.95599365234375, 0.984375\n",
      "Train loss and acc of batch 70: 47.73922348022461, 1.0\n",
      "Training accuracy and loss of epoch #505: 0.9897, 48.0604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.06041491871149\n",
      "Train loss and acc of batch 0: 47.73921203613281, 1.0\n",
      "Train loss and acc of batch 1: 47.739200592041016, 1.0\n",
      "Train loss and acc of batch 2: 47.73919677734375, 1.0\n",
      "Train loss and acc of batch 3: 47.955955505371094, 0.984375\n",
      "Train loss and acc of batch 4: 47.73917770385742, 1.0\n",
      "Train loss and acc of batch 5: 49.08808898925781, 0.96875\n",
      "Train loss and acc of batch 6: 48.24177551269531, 0.96875\n",
      "Train loss and acc of batch 7: 47.73915100097656, 1.0\n",
      "Train loss and acc of batch 8: 48.33484649658203, 0.984375\n",
      "Train loss and acc of batch 9: 48.024986267089844, 0.984375\n",
      "Train loss and acc of batch 10: 47.73912811279297, 1.0\n",
      "Train loss and acc of batch 11: 47.73911666870117, 1.0\n",
      "Train loss and acc of batch 12: 48.492332458496094, 0.984375\n",
      "Train loss and acc of batch 13: 47.95586395263672, 0.984375\n",
      "Train loss and acc of batch 14: 47.955848693847656, 0.984375\n",
      "Train loss and acc of batch 15: 48.33477783203125, 0.984375\n",
      "Train loss and acc of batch 16: 48.33477020263672, 0.984375\n",
      "Train loss and acc of batch 17: 48.49228286743164, 0.984375\n",
      "Train loss and acc of batch 18: 48.62060546875, 0.96875\n",
      "Train loss and acc of batch 19: 47.73904037475586, 1.0\n",
      "Train loss and acc of batch 20: 47.739036560058594, 1.0\n",
      "Train loss and acc of batch 21: 48.33472442626953, 0.984375\n",
      "Train loss and acc of batch 22: 48.334716796875, 0.984375\n",
      "Train loss and acc of batch 23: 47.739009857177734, 1.0\n",
      "Train loss and acc of batch 24: 48.33470153808594, 0.984375\n",
      "Train loss and acc of batch 25: 47.738990783691406, 1.0\n",
      "Train loss and acc of batch 26: 47.738975524902344, 1.0\n",
      "Train loss and acc of batch 27: 47.738975524902344, 1.0\n",
      "Train loss and acc of batch 28: 47.73896408081055, 1.0\n",
      "Train loss and acc of batch 29: 48.33465576171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.73894500732422, 1.0\n",
      "Train loss and acc of batch 31: 47.95570373535156, 0.984375\n",
      "Train loss and acc of batch 32: 47.738929748535156, 1.0\n",
      "Train loss and acc of batch 33: 47.738922119140625, 1.0\n",
      "Train loss and acc of batch 34: 48.33460998535156, 0.984375\n",
      "Train loss and acc of batch 35: 48.17243194580078, 0.96875\n",
      "Train loss and acc of batch 36: 47.7388916015625, 1.0\n",
      "Train loss and acc of batch 37: 48.49211120605469, 0.984375\n",
      "Train loss and acc of batch 38: 49.087799072265625, 0.96875\n",
      "Train loss and acc of batch 39: 47.95563507080078, 0.984375\n",
      "Train loss and acc of batch 40: 47.738861083984375, 1.0\n",
      "Train loss and acc of batch 41: 49.0877799987793, 0.96875\n",
      "Train loss and acc of batch 42: 47.73883819580078, 1.0\n",
      "Train loss and acc of batch 43: 48.33453369140625, 0.984375\n",
      "Train loss and acc of batch 44: 47.73881912231445, 1.0\n",
      "Train loss and acc of batch 45: 48.33451843261719, 0.984375\n",
      "Train loss and acc of batch 46: 48.024658203125, 0.984375\n",
      "Train loss and acc of batch 47: 47.73879623413086, 1.0\n",
      "Train loss and acc of batch 48: 47.73878860473633, 1.0\n",
      "Train loss and acc of batch 49: 47.73877716064453, 1.0\n",
      "Train loss and acc of batch 50: 48.33446502685547, 0.984375\n",
      "Train loss and acc of batch 51: 49.087684631347656, 0.96875\n",
      "Train loss and acc of batch 52: 48.994590759277344, 0.953125\n",
      "Train loss and acc of batch 53: 47.73874282836914, 1.0\n",
      "Train loss and acc of batch 54: 47.95549774169922, 0.984375\n",
      "Train loss and acc of batch 55: 47.73872756958008, 1.0\n",
      "Train loss and acc of batch 56: 47.73871612548828, 1.0\n",
      "Train loss and acc of batch 57: 48.33441162109375, 0.984375\n",
      "Train loss and acc of batch 58: 47.73869705200195, 1.0\n",
      "Train loss and acc of batch 59: 47.73868942260742, 1.0\n",
      "Train loss and acc of batch 60: 47.73868179321289, 1.0\n",
      "Train loss and acc of batch 61: 47.73867416381836, 1.0\n",
      "Train loss and acc of batch 62: 47.73866653442383, 1.0\n",
      "Train loss and acc of batch 63: 48.9300537109375, 0.96875\n",
      "Train loss and acc of batch 64: 47.955406188964844, 0.984375\n",
      "Train loss and acc of batch 65: 47.73863220214844, 1.0\n",
      "Train loss and acc of batch 66: 47.73862838745117, 1.0\n",
      "Train loss and acc of batch 67: 48.551082611083984, 0.96875\n",
      "Train loss and acc of batch 68: 48.334312438964844, 0.984375\n",
      "Train loss and acc of batch 69: 47.95536804199219, 0.984375\n",
      "Train loss and acc of batch 70: 47.738590240478516, 1.0\n",
      "Training accuracy and loss of epoch #506: 0.9897, 48.0598\n",
      "Saved model by train loss 48.05978560111892\n",
      "Train loss and acc of batch 0: 47.73857879638672, 1.0\n",
      "Train loss and acc of batch 1: 47.73857879638672, 1.0\n",
      "Train loss and acc of batch 2: 47.738563537597656, 1.0\n",
      "Train loss and acc of batch 3: 47.955322265625, 0.984375\n",
      "Train loss and acc of batch 4: 47.738548278808594, 1.0\n",
      "Train loss and acc of batch 5: 49.08746337890625, 0.96875\n",
      "Train loss and acc of batch 6: 48.24114990234375, 0.96875\n",
      "Train loss and acc of batch 7: 47.73851776123047, 1.0\n",
      "Train loss and acc of batch 8: 48.33421325683594, 0.984375\n",
      "Train loss and acc of batch 9: 48.02435302734375, 0.984375\n",
      "Train loss and acc of batch 10: 47.738494873046875, 1.0\n",
      "Train loss and acc of batch 11: 47.738487243652344, 1.0\n",
      "Train loss and acc of batch 12: 48.49169921875, 0.984375\n",
      "Train loss and acc of batch 13: 47.955230712890625, 0.984375\n",
      "Train loss and acc of batch 14: 47.955223083496094, 0.984375\n",
      "Train loss and acc of batch 15: 48.33415222167969, 0.984375\n",
      "Train loss and acc of batch 16: 48.334136962890625, 0.984375\n",
      "Train loss and acc of batch 17: 48.49165725708008, 0.984375\n",
      "Train loss and acc of batch 18: 48.61997985839844, 0.96875\n",
      "Train loss and acc of batch 19: 47.73841857910156, 1.0\n",
      "Train loss and acc of batch 20: 47.7384033203125, 1.0\n",
      "Train loss and acc of batch 21: 48.33409881591797, 0.984375\n",
      "Train loss and acc of batch 22: 48.334083557128906, 0.984375\n",
      "Train loss and acc of batch 23: 47.738380432128906, 1.0\n",
      "Train loss and acc of batch 24: 48.334068298339844, 0.984375\n",
      "Train loss and acc of batch 25: 47.73836135864258, 1.0\n",
      "Train loss and acc of batch 26: 47.73835372924805, 1.0\n",
      "Train loss and acc of batch 27: 47.73834228515625, 1.0\n",
      "Train loss and acc of batch 28: 47.73833465576172, 1.0\n",
      "Train loss and acc of batch 29: 48.33403015136719, 0.984375\n",
      "Train loss and acc of batch 30: 47.73831558227539, 1.0\n",
      "Train loss and acc of batch 31: 47.95507049560547, 0.984375\n",
      "Train loss and acc of batch 32: 47.73830032348633, 1.0\n",
      "Train loss and acc of batch 33: 47.7382926940918, 1.0\n",
      "Train loss and acc of batch 34: 48.333984375, 0.984375\n",
      "Train loss and acc of batch 35: 48.17180252075195, 0.96875\n",
      "Train loss and acc of batch 36: 47.73826599121094, 1.0\n",
      "Train loss and acc of batch 37: 48.49148178100586, 0.984375\n",
      "Train loss and acc of batch 38: 49.08717346191406, 0.96875\n",
      "Train loss and acc of batch 39: 47.95500183105469, 0.984375\n",
      "Train loss and acc of batch 40: 47.73823165893555, 1.0\n",
      "Train loss and acc of batch 41: 49.0871467590332, 0.96875\n",
      "Train loss and acc of batch 42: 47.73821258544922, 1.0\n",
      "Train loss and acc of batch 43: 48.33390808105469, 0.984375\n",
      "Train loss and acc of batch 44: 47.73819351196289, 1.0\n",
      "Train loss and acc of batch 45: 48.33387756347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.02403259277344, 0.984375\n",
      "Train loss and acc of batch 47: 47.73816680908203, 1.0\n",
      "Train loss and acc of batch 48: 47.738162994384766, 1.0\n",
      "Train loss and acc of batch 49: 47.73815155029297, 1.0\n",
      "Train loss and acc of batch 50: 48.333839416503906, 0.984375\n",
      "Train loss and acc of batch 51: 49.087059020996094, 0.96875\n",
      "Train loss and acc of batch 52: 48.993961334228516, 0.953125\n",
      "Train loss and acc of batch 53: 47.73811721801758, 1.0\n",
      "Train loss and acc of batch 54: 47.954872131347656, 0.984375\n",
      "Train loss and acc of batch 55: 47.738094329833984, 1.0\n",
      "Train loss and acc of batch 56: 47.73809051513672, 1.0\n",
      "Train loss and acc of batch 57: 48.333778381347656, 0.984375\n",
      "Train loss and acc of batch 58: 47.738067626953125, 1.0\n",
      "Train loss and acc of batch 59: 47.738059997558594, 1.0\n",
      "Train loss and acc of batch 60: 47.73805236816406, 1.0\n",
      "Train loss and acc of batch 61: 47.738040924072266, 1.0\n",
      "Train loss and acc of batch 62: 47.738037109375, 1.0\n",
      "Train loss and acc of batch 63: 48.92942428588867, 0.96875\n",
      "Train loss and acc of batch 64: 47.95478057861328, 0.984375\n",
      "Train loss and acc of batch 65: 47.738006591796875, 1.0\n",
      "Train loss and acc of batch 66: 47.73799514770508, 1.0\n",
      "Train loss and acc of batch 67: 48.550453186035156, 0.96875\n",
      "Train loss and acc of batch 68: 48.33367919921875, 0.984375\n",
      "Train loss and acc of batch 69: 47.954734802246094, 0.984375\n",
      "Train loss and acc of batch 70: 47.73796463012695, 1.0\n",
      "Training accuracy and loss of epoch #507: 0.9897, 48.0592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model by train loss 48.059156444710744\n",
      "Train loss and acc of batch 0: 47.737953186035156, 1.0\n",
      "Train loss and acc of batch 1: 47.73794174194336, 1.0\n",
      "Train loss and acc of batch 2: 47.737937927246094, 1.0\n",
      "Train loss and acc of batch 3: 47.954689025878906, 0.984375\n",
      "Train loss and acc of batch 4: 47.737918853759766, 1.0\n",
      "Train loss and acc of batch 5: 49.08683776855469, 0.96875\n",
      "Train loss and acc of batch 6: 48.24052047729492, 0.96875\n",
      "Train loss and acc of batch 7: 47.73788833618164, 1.0\n",
      "Train loss and acc of batch 8: 48.333587646484375, 0.984375\n",
      "Train loss and acc of batch 9: 48.02372741699219, 0.984375\n",
      "Train loss and acc of batch 10: 47.73786926269531, 1.0\n",
      "Train loss and acc of batch 11: 47.73785400390625, 1.0\n",
      "Train loss and acc of batch 12: 48.49106979370117, 0.984375\n",
      "Train loss and acc of batch 13: 47.95459747314453, 0.984375\n",
      "Train loss and acc of batch 14: 47.95459747314453, 0.984375\n",
      "Train loss and acc of batch 15: 48.333526611328125, 0.984375\n",
      "Train loss and acc of batch 16: 48.33351135253906, 0.984375\n",
      "Train loss and acc of batch 17: 48.491024017333984, 0.984375\n",
      "Train loss and acc of batch 18: 48.61935043334961, 0.96875\n",
      "Train loss and acc of batch 19: 47.73778533935547, 1.0\n",
      "Train loss and acc of batch 20: 47.73777770996094, 1.0\n",
      "Train loss and acc of batch 21: 48.333465576171875, 0.984375\n",
      "Train loss and acc of batch 22: 48.333465576171875, 0.984375\n",
      "Train loss and acc of batch 23: 47.737754821777344, 1.0\n",
      "Train loss and acc of batch 24: 48.33344268798828, 0.984375\n",
      "Train loss and acc of batch 25: 47.73773193359375, 1.0\n",
      "Train loss and acc of batch 26: 47.73772048950195, 1.0\n",
      "Train loss and acc of batch 27: 47.73771286010742, 1.0\n",
      "Train loss and acc of batch 28: 47.737709045410156, 1.0\n",
      "Train loss and acc of batch 29: 48.333396911621094, 0.984375\n",
      "Train loss and acc of batch 30: 47.73768615722656, 1.0\n",
      "Train loss and acc of batch 31: 47.954444885253906, 0.984375\n",
      "Train loss and acc of batch 32: 47.737667083740234, 1.0\n",
      "Train loss and acc of batch 33: 47.7376594543457, 1.0\n",
      "Train loss and acc of batch 34: 48.333351135253906, 0.984375\n",
      "Train loss and acc of batch 35: 48.17116928100586, 0.96875\n",
      "Train loss and acc of batch 36: 47.73763656616211, 1.0\n",
      "Train loss and acc of batch 37: 48.49085235595703, 0.984375\n",
      "Train loss and acc of batch 38: 49.0865478515625, 0.96875\n",
      "Train loss and acc of batch 39: 47.954368591308594, 0.984375\n",
      "Train loss and acc of batch 40: 47.73760223388672, 1.0\n",
      "Train loss and acc of batch 41: 49.086517333984375, 0.96875\n",
      "Train loss and acc of batch 42: 47.73758316040039, 1.0\n",
      "Train loss and acc of batch 43: 48.333274841308594, 0.984375\n",
      "Train loss and acc of batch 44: 47.7375602722168, 1.0\n",
      "Train loss and acc of batch 45: 48.33325958251953, 0.984375\n",
      "Train loss and acc of batch 46: 48.023399353027344, 0.984375\n",
      "Train loss and acc of batch 47: 47.7375373840332, 1.0\n",
      "Train loss and acc of batch 48: 47.737525939941406, 1.0\n",
      "Train loss and acc of batch 49: 47.737518310546875, 1.0\n",
      "Train loss and acc of batch 50: 48.333213806152344, 0.984375\n",
      "Train loss and acc of batch 51: 49.08643341064453, 0.96875\n",
      "Train loss and acc of batch 52: 48.99332809448242, 0.953125\n",
      "Train loss and acc of batch 53: 47.737483978271484, 1.0\n",
      "Train loss and acc of batch 54: 47.95423889160156, 0.984375\n",
      "Train loss and acc of batch 55: 47.737464904785156, 1.0\n",
      "Train loss and acc of batch 56: 47.73746109008789, 1.0\n",
      "Train loss and acc of batch 57: 48.333152770996094, 0.984375\n",
      "Train loss and acc of batch 58: 47.7374382019043, 1.0\n",
      "Train loss and acc of batch 59: 47.73743438720703, 1.0\n",
      "Train loss and acc of batch 60: 47.737422943115234, 1.0\n",
      "Train loss and acc of batch 61: 47.73741149902344, 1.0\n",
      "Train loss and acc of batch 62: 47.73740005493164, 1.0\n",
      "Train loss and acc of batch 63: 48.92879867553711, 0.96875\n",
      "Train loss and acc of batch 64: 47.95414733886719, 0.984375\n",
      "Train loss and acc of batch 65: 47.73738098144531, 1.0\n",
      "Train loss and acc of batch 66: 47.737369537353516, 1.0\n",
      "Train loss and acc of batch 67: 48.549827575683594, 0.96875\n",
      "Train loss and acc of batch 68: 48.33305358886719, 0.984375\n",
      "Train loss and acc of batch 69: 47.9541015625, 0.984375\n",
      "Train loss and acc of batch 70: 47.73733139038086, 1.0\n",
      "Training accuracy and loss of epoch #508: 0.9897, 48.0585\n",
      "Saved model by train loss 48.058527073390046\n",
      "Train loss and acc of batch 0: 47.73732376098633, 1.0\n",
      "Train loss and acc of batch 1: 47.7373161315918, 1.0\n",
      "Train loss and acc of batch 2: 47.73731231689453, 1.0\n",
      "Train loss and acc of batch 3: 47.954063415527344, 0.984375\n",
      "Train loss and acc of batch 4: 47.73728942871094, 1.0\n",
      "Train loss and acc of batch 5: 49.086204528808594, 0.96875\n",
      "Train loss and acc of batch 6: 48.23988723754883, 0.96875\n",
      "Train loss and acc of batch 7: 47.73726272583008, 1.0\n",
      "Train loss and acc of batch 8: 48.33295440673828, 0.984375\n",
      "Train loss and acc of batch 9: 48.023101806640625, 0.984375\n",
      "Train loss and acc of batch 10: 47.73723602294922, 1.0\n",
      "Train loss and acc of batch 11: 47.73722839355469, 1.0\n",
      "Train loss and acc of batch 12: 48.49043655395508, 0.984375\n",
      "Train loss and acc of batch 13: 47.9539794921875, 0.984375\n",
      "Train loss and acc of batch 14: 47.95396423339844, 0.984375\n",
      "Train loss and acc of batch 15: 48.33289337158203, 0.984375\n",
      "Train loss and acc of batch 16: 48.3328857421875, 0.984375\n",
      "Train loss and acc of batch 17: 48.49039840698242, 0.984375\n",
      "Train loss and acc of batch 18: 48.61872100830078, 0.96875\n",
      "Train loss and acc of batch 19: 47.737152099609375, 1.0\n",
      "Train loss and acc of batch 20: 47.737144470214844, 1.0\n",
      "Train loss and acc of batch 21: 48.33283996582031, 0.984375\n",
      "Train loss and acc of batch 22: 48.33283233642578, 0.984375\n",
      "Train loss and acc of batch 23: 47.73712158203125, 1.0\n",
      "Train loss and acc of batch 24: 48.33280944824219, 0.984375\n",
      "Train loss and acc of batch 25: 47.73710632324219, 1.0\n",
      "Train loss and acc of batch 26: 47.73709487915039, 1.0\n",
      "Train loss and acc of batch 27: 47.73708724975586, 1.0\n",
      "Train loss and acc of batch 28: 47.73707962036133, 1.0\n",
      "Train loss and acc of batch 29: 48.332763671875, 0.984375\n",
      "Train loss and acc of batch 30: 47.737060546875, 1.0\n",
      "Train loss and acc of batch 31: 47.953819274902344, 0.984375\n",
      "Train loss and acc of batch 32: 47.73704147338867, 1.0\n",
      "Train loss and acc of batch 33: 47.737037658691406, 1.0\n",
      "Train loss and acc of batch 34: 48.332725524902344, 0.984375\n",
      "Train loss and acc of batch 35: 48.1705436706543, 0.96875\n",
      "Train loss and acc of batch 36: 47.737003326416016, 1.0\n",
      "Train loss and acc of batch 37: 48.49021911621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.085914611816406, 0.96875\n",
      "Train loss and acc of batch 39: 47.95374298095703, 0.984375\n",
      "Train loss and acc of batch 40: 47.736968994140625, 1.0\n",
      "Train loss and acc of batch 41: 49.08588790893555, 0.96875\n",
      "Train loss and acc of batch 42: 47.73695373535156, 1.0\n",
      "Train loss and acc of batch 43: 48.3326416015625, 0.984375\n",
      "Train loss and acc of batch 44: 47.736934661865234, 1.0\n",
      "Train loss and acc of batch 45: 48.33262634277344, 0.984375\n",
      "Train loss and acc of batch 46: 48.02277374267578, 0.984375\n",
      "Train loss and acc of batch 47: 47.73691177368164, 1.0\n",
      "Train loss and acc of batch 48: 47.736900329589844, 1.0\n",
      "Train loss and acc of batch 49: 47.73688888549805, 1.0\n",
      "Train loss and acc of batch 50: 48.33258819580078, 0.984375\n",
      "Train loss and acc of batch 51: 49.085792541503906, 0.96875\n",
      "Train loss and acc of batch 52: 48.99270248413086, 0.953125\n",
      "Train loss and acc of batch 53: 47.736854553222656, 1.0\n",
      "Train loss and acc of batch 54: 47.95361328125, 0.984375\n",
      "Train loss and acc of batch 55: 47.736839294433594, 1.0\n",
      "Train loss and acc of batch 56: 47.73683166503906, 1.0\n",
      "Train loss and acc of batch 57: 48.33251953125, 0.984375\n",
      "Train loss and acc of batch 58: 47.736812591552734, 1.0\n",
      "Train loss and acc of batch 59: 47.73680114746094, 1.0\n",
      "Train loss and acc of batch 60: 47.73679733276367, 1.0\n",
      "Train loss and acc of batch 61: 47.73678207397461, 1.0\n",
      "Train loss and acc of batch 62: 47.736778259277344, 1.0\n",
      "Train loss and acc of batch 63: 48.928165435791016, 0.96875\n",
      "Train loss and acc of batch 64: 47.953529357910156, 0.984375\n",
      "Train loss and acc of batch 65: 47.73674774169922, 1.0\n",
      "Train loss and acc of batch 66: 47.73674011230469, 1.0\n",
      "Train loss and acc of batch 67: 48.5491943359375, 0.96875\n",
      "Train loss and acc of batch 68: 48.332420349121094, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 69: 47.95347595214844, 0.984375\n",
      "Train loss and acc of batch 70: 47.7367057800293, 1.0\n",
      "Training accuracy and loss of epoch #509: 0.9897, 48.0579\n",
      "Saved model by train loss 48.057898293078786\n",
      "Train loss and acc of batch 0: 47.7366943359375, 1.0\n",
      "Train loss and acc of batch 1: 47.73668670654297, 1.0\n",
      "Train loss and acc of batch 2: 47.73667907714844, 1.0\n",
      "Train loss and acc of batch 3: 47.95343780517578, 0.984375\n",
      "Train loss and acc of batch 4: 47.73666000366211, 1.0\n",
      "Train loss and acc of batch 5: 49.08557891845703, 0.96875\n",
      "Train loss and acc of batch 6: 48.2392578125, 0.96875\n",
      "Train loss and acc of batch 7: 47.73663330078125, 1.0\n",
      "Train loss and acc of batch 8: 48.33232116699219, 0.984375\n",
      "Train loss and acc of batch 9: 48.02246856689453, 0.984375\n",
      "Train loss and acc of batch 10: 47.73660659790039, 1.0\n",
      "Train loss and acc of batch 11: 47.73659896850586, 1.0\n",
      "Train loss and acc of batch 12: 48.489810943603516, 0.984375\n",
      "Train loss and acc of batch 13: 47.953346252441406, 0.984375\n",
      "Train loss and acc of batch 14: 47.953330993652344, 0.984375\n",
      "Train loss and acc of batch 15: 48.33226013183594, 0.984375\n",
      "Train loss and acc of batch 16: 48.332252502441406, 0.984375\n",
      "Train loss and acc of batch 17: 48.489768981933594, 0.984375\n",
      "Train loss and acc of batch 18: 48.61809158325195, 0.96875\n",
      "Train loss and acc of batch 19: 47.73652648925781, 1.0\n",
      "Train loss and acc of batch 20: 47.73651885986328, 1.0\n",
      "Train loss and acc of batch 21: 48.33221435546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.33219909667969, 0.984375\n",
      "Train loss and acc of batch 23: 47.736488342285156, 1.0\n",
      "Train loss and acc of batch 24: 48.332183837890625, 0.984375\n",
      "Train loss and acc of batch 25: 47.73646926879883, 1.0\n",
      "Train loss and acc of batch 26: 47.73646545410156, 1.0\n",
      "Train loss and acc of batch 27: 47.73645782470703, 1.0\n",
      "Train loss and acc of batch 28: 47.736446380615234, 1.0\n",
      "Train loss and acc of batch 29: 48.33213806152344, 0.984375\n",
      "Train loss and acc of batch 30: 47.73643112182617, 1.0\n",
      "Train loss and acc of batch 31: 47.95318603515625, 0.984375\n",
      "Train loss and acc of batch 32: 47.736412048339844, 1.0\n",
      "Train loss and acc of batch 33: 47.73640060424805, 1.0\n",
      "Train loss and acc of batch 34: 48.33209991455078, 0.984375\n",
      "Train loss and acc of batch 35: 48.169918060302734, 0.96875\n",
      "Train loss and acc of batch 36: 47.73637771606445, 1.0\n",
      "Train loss and acc of batch 37: 48.48958969116211, 0.984375\n",
      "Train loss and acc of batch 38: 49.085289001464844, 0.96875\n",
      "Train loss and acc of batch 39: 47.95310974121094, 0.984375\n",
      "Train loss and acc of batch 40: 47.7363395690918, 1.0\n",
      "Train loss and acc of batch 41: 49.08525848388672, 0.96875\n",
      "Train loss and acc of batch 42: 47.73632049560547, 1.0\n",
      "Train loss and acc of batch 43: 48.33201599121094, 0.984375\n",
      "Train loss and acc of batch 44: 47.736305236816406, 1.0\n",
      "Train loss and acc of batch 45: 48.331993103027344, 0.984375\n",
      "Train loss and acc of batch 46: 48.02214050292969, 0.984375\n",
      "Train loss and acc of batch 47: 47.73627853393555, 1.0\n",
      "Train loss and acc of batch 48: 47.736270904541016, 1.0\n",
      "Train loss and acc of batch 49: 47.736263275146484, 1.0\n",
      "Train loss and acc of batch 50: 48.331947326660156, 0.984375\n",
      "Train loss and acc of batch 51: 49.085166931152344, 0.96875\n",
      "Train loss and acc of batch 52: 48.99207305908203, 0.953125\n",
      "Train loss and acc of batch 53: 47.73622512817383, 1.0\n",
      "Train loss and acc of batch 54: 47.952980041503906, 0.984375\n",
      "Train loss and acc of batch 55: 47.73621368408203, 1.0\n",
      "Train loss and acc of batch 56: 47.73619842529297, 1.0\n",
      "Train loss and acc of batch 57: 48.33189392089844, 0.984375\n",
      "Train loss and acc of batch 58: 47.73617935180664, 1.0\n",
      "Train loss and acc of batch 59: 47.73617172241211, 1.0\n",
      "Train loss and acc of batch 60: 47.73616027832031, 1.0\n",
      "Train loss and acc of batch 61: 47.73615646362305, 1.0\n",
      "Train loss and acc of batch 62: 47.73614501953125, 1.0\n",
      "Train loss and acc of batch 63: 48.92754364013672, 0.96875\n",
      "Train loss and acc of batch 64: 47.95288848876953, 0.984375\n",
      "Train loss and acc of batch 65: 47.73611831665039, 1.0\n",
      "Train loss and acc of batch 66: 47.73611068725586, 1.0\n",
      "Train loss and acc of batch 67: 48.54856491088867, 0.96875\n",
      "Train loss and acc of batch 68: 48.33179473876953, 0.984375\n",
      "Train loss and acc of batch 69: 47.952850341796875, 0.984375\n",
      "Train loss and acc of batch 70: 47.73607635498047, 1.0\n",
      "Training accuracy and loss of epoch #510: 0.9897, 48.0573\n",
      "Saved model by train loss 48.05726833074865\n",
      "Train loss and acc of batch 0: 47.73606491088867, 1.0\n",
      "Train loss and acc of batch 1: 47.736061096191406, 1.0\n",
      "Train loss and acc of batch 2: 47.73604965209961, 1.0\n",
      "Train loss and acc of batch 3: 47.952796936035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.73603057861328, 1.0\n",
      "Train loss and acc of batch 5: 49.08494567871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.23863220214844, 0.96875\n",
      "Train loss and acc of batch 7: 47.736000061035156, 1.0\n",
      "Train loss and acc of batch 8: 48.331695556640625, 0.984375\n",
      "Train loss and acc of batch 9: 48.02183532714844, 0.984375\n",
      "Train loss and acc of batch 10: 47.73597717285156, 1.0\n",
      "Train loss and acc of batch 11: 47.73596954345703, 1.0\n",
      "Train loss and acc of batch 12: 48.48918914794922, 0.984375\n",
      "Train loss and acc of batch 13: 47.95271301269531, 0.984375\n",
      "Train loss and acc of batch 14: 47.95271301269531, 0.984375\n",
      "Train loss and acc of batch 15: 48.331634521484375, 0.984375\n",
      "Train loss and acc of batch 16: 48.331626892089844, 0.984375\n",
      "Train loss and acc of batch 17: 48.489139556884766, 0.984375\n",
      "Train loss and acc of batch 18: 48.61745834350586, 0.96875\n",
      "Train loss and acc of batch 19: 47.735897064208984, 1.0\n",
      "Train loss and acc of batch 20: 47.73588943481445, 1.0\n",
      "Train loss and acc of batch 21: 48.331581115722656, 0.984375\n",
      "Train loss and acc of batch 22: 48.331573486328125, 0.984375\n",
      "Train loss and acc of batch 23: 47.735862731933594, 1.0\n",
      "Train loss and acc of batch 24: 48.33155059814453, 0.984375\n",
      "Train loss and acc of batch 25: 47.73584747314453, 1.0\n",
      "Train loss and acc of batch 26: 47.73583984375, 1.0\n",
      "Train loss and acc of batch 27: 47.7358283996582, 1.0\n",
      "Train loss and acc of batch 28: 47.73582077026367, 1.0\n",
      "Train loss and acc of batch 29: 48.331512451171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.73579788208008, 1.0\n",
      "Train loss and acc of batch 31: 47.952552795410156, 0.984375\n",
      "Train loss and acc of batch 32: 47.73577880859375, 1.0\n",
      "Train loss and acc of batch 33: 47.735774993896484, 1.0\n",
      "Train loss and acc of batch 34: 48.33146667480469, 0.984375\n",
      "Train loss and acc of batch 35: 48.169288635253906, 0.96875\n",
      "Train loss and acc of batch 36: 47.735748291015625, 1.0\n",
      "Train loss and acc of batch 37: 48.48896408081055, 0.984375\n",
      "Train loss and acc of batch 38: 49.08464813232422, 0.96875\n",
      "Train loss and acc of batch 39: 47.952484130859375, 0.984375\n",
      "Train loss and acc of batch 40: 47.735713958740234, 1.0\n",
      "Train loss and acc of batch 41: 49.084625244140625, 0.96875\n",
      "Train loss and acc of batch 42: 47.735694885253906, 1.0\n",
      "Train loss and acc of batch 43: 48.331390380859375, 0.984375\n",
      "Train loss and acc of batch 44: 47.73567581176758, 1.0\n",
      "Train loss and acc of batch 45: 48.33136749267578, 0.984375\n",
      "Train loss and acc of batch 46: 48.021514892578125, 0.984375\n",
      "Train loss and acc of batch 47: 47.73564910888672, 1.0\n",
      "Train loss and acc of batch 48: 47.73563766479492, 1.0\n",
      "Train loss and acc of batch 49: 47.735633850097656, 1.0\n",
      "Train loss and acc of batch 50: 48.331321716308594, 0.984375\n",
      "Train loss and acc of batch 51: 49.08454132080078, 0.96875\n",
      "Train loss and acc of batch 52: 48.9914436340332, 0.953125\n",
      "Train loss and acc of batch 53: 47.735595703125, 1.0\n",
      "Train loss and acc of batch 54: 47.952354431152344, 0.984375\n",
      "Train loss and acc of batch 55: 47.73557662963867, 1.0\n",
      "Train loss and acc of batch 56: 47.73556900024414, 1.0\n",
      "Train loss and acc of batch 57: 48.331268310546875, 0.984375\n",
      "Train loss and acc of batch 58: 47.73555374145508, 1.0\n",
      "Train loss and acc of batch 59: 47.73554611206055, 1.0\n",
      "Train loss and acc of batch 60: 47.735530853271484, 1.0\n",
      "Train loss and acc of batch 61: 47.73552322387695, 1.0\n",
      "Train loss and acc of batch 62: 47.73551940917969, 1.0\n",
      "Train loss and acc of batch 63: 48.926910400390625, 0.96875\n",
      "Train loss and acc of batch 64: 47.95226287841797, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 47.73549270629883, 1.0\n",
      "Train loss and acc of batch 66: 47.735477447509766, 1.0\n",
      "Train loss and acc of batch 67: 48.547935485839844, 0.96875\n",
      "Train loss and acc of batch 68: 48.33116912841797, 0.984375\n",
      "Train loss and acc of batch 69: 47.95220947265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.73544692993164, 1.0\n",
      "Training accuracy and loss of epoch #511: 0.9897, 48.0566\n",
      "Saved model by train loss 48.05663933552487\n",
      "Train loss and acc of batch 0: 47.73543930053711, 1.0\n",
      "Train loss and acc of batch 1: 47.73543167114258, 1.0\n",
      "Train loss and acc of batch 2: 47.73542022705078, 1.0\n",
      "Train loss and acc of batch 3: 47.952178955078125, 0.984375\n",
      "Train loss and acc of batch 4: 47.73540115356445, 1.0\n",
      "Train loss and acc of batch 5: 49.084320068359375, 0.96875\n",
      "Train loss and acc of batch 6: 48.23799514770508, 0.96875\n",
      "Train loss and acc of batch 7: 47.735374450683594, 1.0\n",
      "Train loss and acc of batch 8: 48.33106994628906, 0.984375\n",
      "Train loss and acc of batch 9: 48.021209716796875, 0.984375\n",
      "Train loss and acc of batch 10: 47.7353515625, 1.0\n",
      "Train loss and acc of batch 11: 47.73534393310547, 1.0\n",
      "Train loss and acc of batch 12: 48.488555908203125, 0.984375\n",
      "Train loss and acc of batch 13: 47.95208740234375, 0.984375\n",
      "Train loss and acc of batch 14: 47.95207977294922, 0.984375\n",
      "Train loss and acc of batch 15: 48.33100891113281, 0.984375\n",
      "Train loss and acc of batch 16: 48.33099365234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.4885139465332, 0.984375\n",
      "Train loss and acc of batch 18: 48.6168327331543, 0.96875\n",
      "Train loss and acc of batch 19: 47.73527145385742, 1.0\n",
      "Train loss and acc of batch 20: 47.735260009765625, 1.0\n",
      "Train loss and acc of batch 21: 48.33094787597656, 0.984375\n",
      "Train loss and acc of batch 22: 48.33094024658203, 0.984375\n",
      "Train loss and acc of batch 23: 47.735233306884766, 1.0\n",
      "Train loss and acc of batch 24: 48.33092498779297, 0.984375\n",
      "Train loss and acc of batch 25: 47.7352180480957, 1.0\n",
      "Train loss and acc of batch 26: 47.735206604003906, 1.0\n",
      "Train loss and acc of batch 27: 47.73519515991211, 1.0\n",
      "Train loss and acc of batch 28: 47.73518753051758, 1.0\n",
      "Train loss and acc of batch 29: 48.33087921142578, 0.984375\n",
      "Train loss and acc of batch 30: 47.735172271728516, 1.0\n",
      "Train loss and acc of batch 31: 47.951927185058594, 0.984375\n",
      "Train loss and acc of batch 32: 47.73515701293945, 1.0\n",
      "Train loss and acc of batch 33: 47.73514938354492, 1.0\n",
      "Train loss and acc of batch 34: 48.330841064453125, 0.984375\n",
      "Train loss and acc of batch 35: 48.16865539550781, 0.96875\n",
      "Train loss and acc of batch 36: 47.7351188659668, 1.0\n",
      "Train loss and acc of batch 37: 48.48833465576172, 0.984375\n",
      "Train loss and acc of batch 38: 49.08403015136719, 0.96875\n",
      "Train loss and acc of batch 39: 47.95185852050781, 0.984375\n",
      "Train loss and acc of batch 40: 47.735084533691406, 1.0\n",
      "Train loss and acc of batch 41: 49.0839958190918, 0.96875\n",
      "Train loss and acc of batch 42: 47.73506546020508, 1.0\n",
      "Train loss and acc of batch 43: 48.33075714111328, 0.984375\n",
      "Train loss and acc of batch 44: 47.73504638671875, 1.0\n",
      "Train loss and acc of batch 45: 48.33074188232422, 0.984375\n",
      "Train loss and acc of batch 46: 48.02088165283203, 0.984375\n",
      "Train loss and acc of batch 47: 47.735023498535156, 1.0\n",
      "Train loss and acc of batch 48: 47.735015869140625, 1.0\n",
      "Train loss and acc of batch 49: 47.73500061035156, 1.0\n",
      "Train loss and acc of batch 50: 48.33069610595703, 0.984375\n",
      "Train loss and acc of batch 51: 49.08391571044922, 0.96875\n",
      "Train loss and acc of batch 52: 48.99081802368164, 0.953125\n",
      "Train loss and acc of batch 53: 47.73496627807617, 1.0\n",
      "Train loss and acc of batch 54: 47.95172119140625, 0.984375\n",
      "Train loss and acc of batch 55: 47.734947204589844, 1.0\n",
      "Train loss and acc of batch 56: 47.73494338989258, 1.0\n",
      "Train loss and acc of batch 57: 48.33063507080078, 0.984375\n",
      "Train loss and acc of batch 58: 47.734920501708984, 1.0\n",
      "Train loss and acc of batch 59: 47.73491287231445, 1.0\n",
      "Train loss and acc of batch 60: 47.73490905761719, 1.0\n",
      "Train loss and acc of batch 61: 47.73489761352539, 1.0\n",
      "Train loss and acc of batch 62: 47.73488998413086, 1.0\n",
      "Train loss and acc of batch 63: 48.9262809753418, 0.96875\n",
      "Train loss and acc of batch 64: 47.951637268066406, 0.984375\n",
      "Train loss and acc of batch 65: 47.73486328125, 1.0\n",
      "Train loss and acc of batch 66: 47.7348518371582, 1.0\n",
      "Train loss and acc of batch 67: 48.54730987548828, 0.96875\n",
      "Train loss and acc of batch 68: 48.330535888671875, 0.984375\n",
      "Train loss and acc of batch 69: 47.95159149169922, 0.984375\n",
      "Train loss and acc of batch 70: 47.73481750488281, 1.0\n",
      "Training accuracy and loss of epoch #512: 0.9897, 48.0560\n",
      "Saved model by train loss 48.05601114622304\n",
      "Train loss and acc of batch 0: 47.73480987548828, 1.0\n",
      "Train loss and acc of batch 1: 47.73479461669922, 1.0\n",
      "Train loss and acc of batch 2: 47.73479080200195, 1.0\n",
      "Train loss and acc of batch 3: 47.95154571533203, 0.984375\n",
      "Train loss and acc of batch 4: 47.73477554321289, 1.0\n",
      "Train loss and acc of batch 5: 49.08368682861328, 0.96875\n",
      "Train loss and acc of batch 6: 48.23737335205078, 0.96875\n",
      "Train loss and acc of batch 7: 47.734745025634766, 1.0\n",
      "Train loss and acc of batch 8: 48.3304443359375, 0.984375\n",
      "Train loss and acc of batch 9: 48.02057647705078, 0.984375\n",
      "Train loss and acc of batch 10: 47.73472213745117, 1.0\n",
      "Train loss and acc of batch 11: 47.73470687866211, 1.0\n",
      "Train loss and acc of batch 12: 48.4879264831543, 0.984375\n",
      "Train loss and acc of batch 13: 47.95146179199219, 0.984375\n",
      "Train loss and acc of batch 14: 47.951446533203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.33037567138672, 0.984375\n",
      "Train loss and acc of batch 16: 48.33036804199219, 0.984375\n",
      "Train loss and acc of batch 17: 48.48788070678711, 0.984375\n",
      "Train loss and acc of batch 18: 48.61620330810547, 0.96875\n",
      "Train loss and acc of batch 19: 47.73463821411133, 1.0\n",
      "Train loss and acc of batch 20: 47.7346305847168, 1.0\n",
      "Train loss and acc of batch 21: 48.330322265625, 0.984375\n",
      "Train loss and acc of batch 22: 48.33031463623047, 0.984375\n",
      "Train loss and acc of batch 23: 47.73460388183594, 1.0\n",
      "Train loss and acc of batch 24: 48.330299377441406, 0.984375\n",
      "Train loss and acc of batch 25: 47.734588623046875, 1.0\n",
      "Train loss and acc of batch 26: 47.73457717895508, 1.0\n",
      "Train loss and acc of batch 27: 47.73457336425781, 1.0\n",
      "Train loss and acc of batch 28: 47.73455810546875, 1.0\n",
      "Train loss and acc of batch 29: 48.33025360107422, 0.984375\n",
      "Train loss and acc of batch 30: 47.73453903198242, 1.0\n",
      "Train loss and acc of batch 31: 47.9512939453125, 0.984375\n",
      "Train loss and acc of batch 32: 47.734527587890625, 1.0\n",
      "Train loss and acc of batch 33: 47.73451614379883, 1.0\n",
      "Train loss and acc of batch 34: 48.33020782470703, 0.984375\n",
      "Train loss and acc of batch 35: 48.168025970458984, 0.96875\n",
      "Train loss and acc of batch 36: 47.73448944091797, 1.0\n",
      "Train loss and acc of batch 37: 48.48770523071289, 0.984375\n",
      "Train loss and acc of batch 38: 49.083396911621094, 0.96875\n",
      "Train loss and acc of batch 39: 47.95122528076172, 0.984375\n",
      "Train loss and acc of batch 40: 47.73445510864258, 1.0\n",
      "Train loss and acc of batch 41: 49.0833740234375, 0.96875\n",
      "Train loss and acc of batch 42: 47.73443603515625, 1.0\n",
      "Train loss and acc of batch 43: 48.33013153076172, 0.984375\n",
      "Train loss and acc of batch 44: 47.734413146972656, 1.0\n",
      "Train loss and acc of batch 45: 48.330108642578125, 0.984375\n",
      "Train loss and acc of batch 46: 48.02025604248047, 0.984375\n",
      "Train loss and acc of batch 47: 47.73439025878906, 1.0\n",
      "Train loss and acc of batch 48: 47.734378814697266, 1.0\n",
      "Train loss and acc of batch 49: 47.734375, 1.0\n",
      "Train loss and acc of batch 50: 48.33006286621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.083282470703125, 0.96875\n",
      "Train loss and acc of batch 52: 48.99018859863281, 0.953125\n",
      "Train loss and acc of batch 53: 47.73434066772461, 1.0\n",
      "Train loss and acc of batch 54: 47.95109558105469, 0.984375\n",
      "Train loss and acc of batch 55: 47.73432540893555, 1.0\n",
      "Train loss and acc of batch 56: 47.734317779541016, 1.0\n",
      "Train loss and acc of batch 57: 48.33000183105469, 0.984375\n",
      "Train loss and acc of batch 58: 47.734291076660156, 1.0\n",
      "Train loss and acc of batch 59: 47.73427963256836, 1.0\n",
      "Train loss and acc of batch 60: 47.734275817871094, 1.0\n",
      "Train loss and acc of batch 61: 47.7342643737793, 1.0\n",
      "Train loss and acc of batch 62: 47.734256744384766, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 63: 48.92565155029297, 0.96875\n",
      "Train loss and acc of batch 64: 47.95100402832031, 0.984375\n",
      "Train loss and acc of batch 65: 47.734230041503906, 1.0\n",
      "Train loss and acc of batch 66: 47.734222412109375, 1.0\n",
      "Train loss and acc of batch 67: 48.54668045043945, 0.96875\n",
      "Train loss and acc of batch 68: 48.32990264892578, 0.984375\n",
      "Train loss and acc of batch 69: 47.950965881347656, 0.984375\n",
      "Train loss and acc of batch 70: 47.73419189453125, 1.0\n",
      "Training accuracy and loss of epoch #513: 0.9897, 48.0554\n",
      "Saved model by train loss 48.05538129134917\n",
      "Train loss and acc of batch 0: 47.73418045043945, 1.0\n",
      "Train loss and acc of batch 1: 47.734169006347656, 1.0\n",
      "Train loss and acc of batch 2: 47.73415756225586, 1.0\n",
      "Train loss and acc of batch 3: 47.95092010498047, 0.984375\n",
      "Train loss and acc of batch 4: 47.73413848876953, 1.0\n",
      "Train loss and acc of batch 5: 49.08306121826172, 0.96875\n",
      "Train loss and acc of batch 6: 48.23674392700195, 0.96875\n",
      "Train loss and acc of batch 7: 47.7341194152832, 1.0\n",
      "Train loss and acc of batch 8: 48.329811096191406, 0.984375\n",
      "Train loss and acc of batch 9: 48.01995086669922, 0.984375\n",
      "Train loss and acc of batch 10: 47.73408889770508, 1.0\n",
      "Train loss and acc of batch 11: 47.73408126831055, 1.0\n",
      "Train loss and acc of batch 12: 48.48729705810547, 0.984375\n",
      "Train loss and acc of batch 13: 47.950828552246094, 0.984375\n",
      "Train loss and acc of batch 14: 47.95082092285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.329750061035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.329742431640625, 0.984375\n",
      "Train loss and acc of batch 17: 48.48725509643555, 0.984375\n",
      "Train loss and acc of batch 18: 48.61557388305664, 0.96875\n",
      "Train loss and acc of batch 19: 47.7340087890625, 1.0\n",
      "Train loss and acc of batch 20: 47.734004974365234, 1.0\n",
      "Train loss and acc of batch 21: 48.32969665527344, 0.984375\n",
      "Train loss and acc of batch 22: 48.329689025878906, 0.984375\n",
      "Train loss and acc of batch 23: 47.733978271484375, 1.0\n",
      "Train loss and acc of batch 24: 48.32966613769531, 0.984375\n",
      "Train loss and acc of batch 25: 47.73395919799805, 1.0\n",
      "Train loss and acc of batch 26: 47.73394775390625, 1.0\n",
      "Train loss and acc of batch 27: 47.733943939208984, 1.0\n",
      "Train loss and acc of batch 28: 47.73392868041992, 1.0\n",
      "Train loss and acc of batch 29: 48.329627990722656, 0.984375\n",
      "Train loss and acc of batch 30: 47.73391342163086, 1.0\n",
      "Train loss and acc of batch 31: 47.95066833496094, 0.984375\n",
      "Train loss and acc of batch 32: 47.73389434814453, 1.0\n",
      "Train loss and acc of batch 33: 47.733890533447266, 1.0\n",
      "Train loss and acc of batch 34: 48.32958221435547, 0.984375\n",
      "Train loss and acc of batch 35: 48.167396545410156, 0.96875\n",
      "Train loss and acc of batch 36: 47.73386001586914, 1.0\n",
      "Train loss and acc of batch 37: 48.48707580566406, 0.984375\n",
      "Train loss and acc of batch 38: 49.082763671875, 0.96875\n",
      "Train loss and acc of batch 39: 47.950592041015625, 0.984375\n",
      "Train loss and acc of batch 40: 47.73382568359375, 1.0\n",
      "Train loss and acc of batch 41: 49.08274459838867, 0.96875\n",
      "Train loss and acc of batch 42: 47.73380661010742, 1.0\n",
      "Train loss and acc of batch 43: 48.329498291015625, 0.984375\n",
      "Train loss and acc of batch 44: 47.73379135131836, 1.0\n",
      "Train loss and acc of batch 45: 48.32948303222656, 0.984375\n",
      "Train loss and acc of batch 46: 48.019622802734375, 0.984375\n",
      "Train loss and acc of batch 47: 47.733760833740234, 1.0\n",
      "Train loss and acc of batch 48: 47.7337532043457, 1.0\n",
      "Train loss and acc of batch 49: 47.733741760253906, 1.0\n",
      "Train loss and acc of batch 50: 48.329437255859375, 0.984375\n",
      "Train loss and acc of batch 51: 49.08265686035156, 0.96875\n",
      "Train loss and acc of batch 52: 48.98955535888672, 0.953125\n",
      "Train loss and acc of batch 53: 47.733707427978516, 1.0\n",
      "Train loss and acc of batch 54: 47.950462341308594, 0.984375\n",
      "Train loss and acc of batch 55: 47.73369216918945, 1.0\n",
      "Train loss and acc of batch 56: 47.733680725097656, 1.0\n",
      "Train loss and acc of batch 57: 48.329376220703125, 0.984375\n",
      "Train loss and acc of batch 58: 47.73366928100586, 1.0\n",
      "Train loss and acc of batch 59: 47.73365783691406, 1.0\n",
      "Train loss and acc of batch 60: 47.733646392822266, 1.0\n",
      "Train loss and acc of batch 61: 47.733638763427734, 1.0\n",
      "Train loss and acc of batch 62: 47.7336311340332, 1.0\n",
      "Train loss and acc of batch 63: 48.925025939941406, 0.96875\n",
      "Train loss and acc of batch 64: 47.95037841796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.733604431152344, 1.0\n",
      "Train loss and acc of batch 66: 47.73359298706055, 1.0\n",
      "Train loss and acc of batch 67: 48.546051025390625, 0.96875\n",
      "Train loss and acc of batch 68: 48.32927703857422, 0.984375\n",
      "Train loss and acc of batch 69: 47.95033264160156, 0.984375\n",
      "Train loss and acc of batch 70: 47.733558654785156, 1.0\n",
      "Training accuracy and loss of epoch #514: 0.9897, 48.0548\n",
      "Saved model by train loss 48.0547526722223\n",
      "Train loss and acc of batch 0: 47.73354721069336, 1.0\n",
      "Train loss and acc of batch 1: 47.733543395996094, 1.0\n",
      "Train loss and acc of batch 2: 47.7335319519043, 1.0\n",
      "Train loss and acc of batch 3: 47.950286865234375, 0.984375\n",
      "Train loss and acc of batch 4: 47.73351287841797, 1.0\n",
      "Train loss and acc of batch 5: 49.082427978515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.236114501953125, 0.96875\n",
      "Train loss and acc of batch 7: 47.733489990234375, 1.0\n",
      "Train loss and acc of batch 8: 48.32917785644531, 0.984375\n",
      "Train loss and acc of batch 9: 48.019325256347656, 0.984375\n",
      "Train loss and acc of batch 10: 47.73345947265625, 1.0\n",
      "Train loss and acc of batch 11: 47.733455657958984, 1.0\n",
      "Train loss and acc of batch 12: 48.48666763305664, 0.984375\n",
      "Train loss and acc of batch 13: 47.9501953125, 0.984375\n",
      "Train loss and acc of batch 14: 47.95018768310547, 0.984375\n",
      "Train loss and acc of batch 15: 48.32911682128906, 0.984375\n",
      "Train loss and acc of batch 16: 48.32910919189453, 0.984375\n",
      "Train loss and acc of batch 17: 48.48661804199219, 0.984375\n",
      "Train loss and acc of batch 18: 48.61494445800781, 0.96875\n",
      "Train loss and acc of batch 19: 47.73337936401367, 1.0\n",
      "Train loss and acc of batch 20: 47.733375549316406, 1.0\n",
      "Train loss and acc of batch 21: 48.329071044921875, 0.984375\n",
      "Train loss and acc of batch 22: 48.32905578613281, 0.984375\n",
      "Train loss and acc of batch 23: 47.73334503173828, 1.0\n",
      "Train loss and acc of batch 24: 48.32904052734375, 0.984375\n",
      "Train loss and acc of batch 25: 47.73332977294922, 1.0\n",
      "Train loss and acc of batch 26: 47.73331832885742, 1.0\n",
      "Train loss and acc of batch 27: 47.733306884765625, 1.0\n",
      "Train loss and acc of batch 28: 47.733299255371094, 1.0\n",
      "Train loss and acc of batch 29: 48.32899475097656, 0.984375\n",
      "Train loss and acc of batch 30: 47.73328399658203, 1.0\n",
      "Train loss and acc of batch 31: 47.950035095214844, 0.984375\n",
      "Train loss and acc of batch 32: 47.7332649230957, 1.0\n",
      "Train loss and acc of batch 33: 47.73325729370117, 1.0\n",
      "Train loss and acc of batch 34: 48.328948974609375, 0.984375\n",
      "Train loss and acc of batch 35: 48.16676712036133, 0.96875\n",
      "Train loss and acc of batch 36: 47.73323059082031, 1.0\n",
      "Train loss and acc of batch 37: 48.486446380615234, 0.984375\n",
      "Train loss and acc of batch 38: 49.08214569091797, 0.96875\n",
      "Train loss and acc of batch 39: 47.949974060058594, 0.984375\n",
      "Train loss and acc of batch 40: 47.733192443847656, 1.0\n",
      "Train loss and acc of batch 41: 49.08211135864258, 0.96875\n",
      "Train loss and acc of batch 42: 47.73318099975586, 1.0\n",
      "Train loss and acc of batch 43: 48.32887268066406, 0.984375\n",
      "Train loss and acc of batch 44: 47.73316192626953, 1.0\n",
      "Train loss and acc of batch 45: 48.32884979248047, 0.984375\n",
      "Train loss and acc of batch 46: 48.01899719238281, 0.984375\n",
      "Train loss and acc of batch 47: 47.733131408691406, 1.0\n",
      "Train loss and acc of batch 48: 47.733123779296875, 1.0\n",
      "Train loss and acc of batch 49: 47.733116149902344, 1.0\n",
      "Train loss and acc of batch 50: 48.32880401611328, 0.984375\n",
      "Train loss and acc of batch 51: 49.08202362060547, 0.96875\n",
      "Train loss and acc of batch 52: 48.988929748535156, 0.953125\n",
      "Train loss and acc of batch 53: 47.73308181762695, 1.0\n",
      "Train loss and acc of batch 54: 47.9498291015625, 0.984375\n",
      "Train loss and acc of batch 55: 47.733062744140625, 1.0\n",
      "Train loss and acc of batch 56: 47.733055114746094, 1.0\n",
      "Train loss and acc of batch 57: 48.32875061035156, 0.984375\n",
      "Train loss and acc of batch 58: 47.73303985595703, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 59: 47.73302459716797, 1.0\n",
      "Train loss and acc of batch 60: 47.73301696777344, 1.0\n",
      "Train loss and acc of batch 61: 47.733009338378906, 1.0\n",
      "Train loss and acc of batch 62: 47.73299789428711, 1.0\n",
      "Train loss and acc of batch 63: 48.92439270019531, 0.96875\n",
      "Train loss and acc of batch 64: 47.949745178222656, 0.984375\n",
      "Train loss and acc of batch 65: 47.732975006103516, 1.0\n",
      "Train loss and acc of batch 66: 47.732967376708984, 1.0\n",
      "Train loss and acc of batch 67: 48.54542541503906, 0.96875\n",
      "Train loss and acc of batch 68: 48.328643798828125, 0.984375\n",
      "Train loss and acc of batch 69: 47.94969940185547, 0.984375\n",
      "Train loss and acc of batch 70: 47.73292922973633, 1.0\n",
      "Training accuracy and loss of epoch #515: 0.9897, 48.0541\n",
      "Saved model by train loss 48.05412287107656\n",
      "Train loss and acc of batch 0: 47.7329216003418, 1.0\n",
      "Train loss and acc of batch 1: 47.732913970947266, 1.0\n",
      "Train loss and acc of batch 2: 47.7328987121582, 1.0\n",
      "Train loss and acc of batch 3: 47.94966125488281, 0.984375\n",
      "Train loss and acc of batch 4: 47.732887268066406, 1.0\n",
      "Train loss and acc of batch 5: 49.08180236816406, 0.96875\n",
      "Train loss and acc of batch 6: 48.2354850769043, 0.96875\n",
      "Train loss and acc of batch 7: 47.73285675048828, 1.0\n",
      "Train loss and acc of batch 8: 48.32855224609375, 0.984375\n",
      "Train loss and acc of batch 9: 48.01869201660156, 0.984375\n",
      "Train loss and acc of batch 10: 47.73283767700195, 1.0\n",
      "Train loss and acc of batch 11: 47.732826232910156, 1.0\n",
      "Train loss and acc of batch 12: 48.48603820800781, 0.984375\n",
      "Train loss and acc of batch 13: 47.94956970214844, 0.984375\n",
      "Train loss and acc of batch 14: 47.949562072753906, 0.984375\n",
      "Train loss and acc of batch 15: 48.3284912109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.32848358154297, 0.984375\n",
      "Train loss and acc of batch 17: 48.485992431640625, 0.984375\n",
      "Train loss and acc of batch 18: 48.614315032958984, 0.96875\n",
      "Train loss and acc of batch 19: 47.73275375366211, 1.0\n",
      "Train loss and acc of batch 20: 47.73274612426758, 1.0\n",
      "Train loss and acc of batch 21: 48.32843780517578, 0.984375\n",
      "Train loss and acc of batch 22: 48.32842254638672, 0.984375\n",
      "Train loss and acc of batch 23: 47.73271560668945, 1.0\n",
      "Train loss and acc of batch 24: 48.32841491699219, 0.984375\n",
      "Train loss and acc of batch 25: 47.73270034790039, 1.0\n",
      "Train loss and acc of batch 26: 47.732688903808594, 1.0\n",
      "Train loss and acc of batch 27: 47.73268127441406, 1.0\n",
      "Train loss and acc of batch 28: 47.732669830322266, 1.0\n",
      "Train loss and acc of batch 29: 48.328369140625, 0.984375\n",
      "Train loss and acc of batch 30: 47.73265075683594, 1.0\n",
      "Train loss and acc of batch 31: 47.94940948486328, 0.984375\n",
      "Train loss and acc of batch 32: 47.732635498046875, 1.0\n",
      "Train loss and acc of batch 33: 47.73263168334961, 1.0\n",
      "Train loss and acc of batch 34: 48.32832336425781, 0.984375\n",
      "Train loss and acc of batch 35: 48.1661376953125, 0.96875\n",
      "Train loss and acc of batch 36: 47.732601165771484, 1.0\n",
      "Train loss and acc of batch 37: 48.48581314086914, 0.984375\n",
      "Train loss and acc of batch 38: 49.081512451171875, 0.96875\n",
      "Train loss and acc of batch 39: 47.9493408203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.732566833496094, 1.0\n",
      "Train loss and acc of batch 41: 49.081485748291016, 0.96875\n",
      "Train loss and acc of batch 42: 47.732547760009766, 1.0\n",
      "Train loss and acc of batch 43: 48.32823944091797, 0.984375\n",
      "Train loss and acc of batch 44: 47.73252868652344, 1.0\n",
      "Train loss and acc of batch 45: 48.328224182128906, 0.984375\n",
      "Train loss and acc of batch 46: 48.01836395263672, 0.984375\n",
      "Train loss and acc of batch 47: 47.732505798339844, 1.0\n",
      "Train loss and acc of batch 48: 47.73249816894531, 1.0\n",
      "Train loss and acc of batch 49: 47.73248291015625, 1.0\n",
      "Train loss and acc of batch 50: 48.32817840576172, 0.984375\n",
      "Train loss and acc of batch 51: 49.081390380859375, 0.96875\n",
      "Train loss and acc of batch 52: 48.98830032348633, 0.953125\n",
      "Train loss and acc of batch 53: 47.732452392578125, 1.0\n",
      "Train loss and acc of batch 54: 47.94920349121094, 0.984375\n",
      "Train loss and acc of batch 55: 47.73243713378906, 1.0\n",
      "Train loss and acc of batch 56: 47.732425689697266, 1.0\n",
      "Train loss and acc of batch 57: 48.32811737060547, 0.984375\n",
      "Train loss and acc of batch 58: 47.73240661621094, 1.0\n",
      "Train loss and acc of batch 59: 47.73239517211914, 1.0\n",
      "Train loss and acc of batch 60: 47.732383728027344, 1.0\n",
      "Train loss and acc of batch 61: 47.73237991333008, 1.0\n",
      "Train loss and acc of batch 62: 47.732364654541016, 1.0\n",
      "Train loss and acc of batch 63: 48.92375564575195, 0.96875\n",
      "Train loss and acc of batch 64: 47.94911193847656, 0.984375\n",
      "Train loss and acc of batch 65: 47.73234176635742, 1.0\n",
      "Train loss and acc of batch 66: 47.73233413696289, 1.0\n",
      "Train loss and acc of batch 67: 48.5447883605957, 0.96875\n",
      "Train loss and acc of batch 68: 48.32801818847656, 0.984375\n",
      "Train loss and acc of batch 69: 47.949073791503906, 0.984375\n",
      "Train loss and acc of batch 70: 47.7322998046875, 1.0\n",
      "Training accuracy and loss of epoch #516: 0.9897, 48.0535\n",
      "Saved model by train loss 48.05349360721212\n",
      "Train loss and acc of batch 0: 47.73228454589844, 1.0\n",
      "Train loss and acc of batch 1: 47.73228073120117, 1.0\n",
      "Train loss and acc of batch 2: 47.732269287109375, 1.0\n",
      "Train loss and acc of batch 3: 47.94902801513672, 0.984375\n",
      "Train loss and acc of batch 4: 47.73225402832031, 1.0\n",
      "Train loss and acc of batch 5: 49.08116912841797, 0.96875\n",
      "Train loss and acc of batch 6: 48.2348518371582, 0.96875\n",
      "Train loss and acc of batch 7: 47.73223114013672, 1.0\n",
      "Train loss and acc of batch 8: 48.327919006347656, 0.984375\n",
      "Train loss and acc of batch 9: 48.01805877685547, 0.984375\n",
      "Train loss and acc of batch 10: 47.732200622558594, 1.0\n",
      "Train loss and acc of batch 11: 47.73218536376953, 1.0\n",
      "Train loss and acc of batch 12: 48.48540496826172, 0.984375\n",
      "Train loss and acc of batch 13: 47.948936462402344, 0.984375\n",
      "Train loss and acc of batch 14: 47.94892883300781, 0.984375\n",
      "Train loss and acc of batch 15: 48.327857971191406, 0.984375\n",
      "Train loss and acc of batch 16: 48.327850341796875, 0.984375\n",
      "Train loss and acc of batch 17: 48.48535919189453, 0.984375\n",
      "Train loss and acc of batch 18: 48.61368179321289, 0.96875\n",
      "Train loss and acc of batch 19: 47.732120513916016, 1.0\n",
      "Train loss and acc of batch 20: 47.732112884521484, 1.0\n",
      "Train loss and acc of batch 21: 48.32780456542969, 0.984375\n",
      "Train loss and acc of batch 22: 48.327796936035156, 0.984375\n",
      "Train loss and acc of batch 23: 47.732086181640625, 1.0\n",
      "Train loss and acc of batch 24: 48.327781677246094, 0.984375\n",
      "Train loss and acc of batch 25: 47.73206329345703, 1.0\n",
      "Train loss and acc of batch 26: 47.732059478759766, 1.0\n",
      "Train loss and acc of batch 27: 47.73204803466797, 1.0\n",
      "Train loss and acc of batch 28: 47.73204040527344, 1.0\n",
      "Train loss and acc of batch 29: 48.327728271484375, 0.984375\n",
      "Train loss and acc of batch 30: 47.73202133178711, 1.0\n",
      "Train loss and acc of batch 31: 47.94877624511719, 0.984375\n",
      "Train loss and acc of batch 32: 47.73200988769531, 1.0\n",
      "Train loss and acc of batch 33: 47.73199462890625, 1.0\n",
      "Train loss and acc of batch 34: 48.32769012451172, 0.984375\n",
      "Train loss and acc of batch 35: 48.16550827026367, 0.96875\n",
      "Train loss and acc of batch 36: 47.73196792602539, 1.0\n",
      "Train loss and acc of batch 37: 48.48517990112305, 0.984375\n",
      "Train loss and acc of batch 38: 49.08087921142578, 0.96875\n",
      "Train loss and acc of batch 39: 47.948707580566406, 0.984375\n",
      "Train loss and acc of batch 40: 47.731937408447266, 1.0\n",
      "Train loss and acc of batch 41: 49.080848693847656, 0.96875\n",
      "Train loss and acc of batch 42: 47.73191452026367, 1.0\n",
      "Train loss and acc of batch 43: 48.327606201171875, 0.984375\n",
      "Train loss and acc of batch 44: 47.73189163208008, 1.0\n",
      "Train loss and acc of batch 45: 48.32759094238281, 0.984375\n",
      "Train loss and acc of batch 46: 48.017738342285156, 0.984375\n",
      "Train loss and acc of batch 47: 47.73187255859375, 1.0\n",
      "Train loss and acc of batch 48: 47.73186111450195, 1.0\n",
      "Train loss and acc of batch 49: 47.73185348510742, 1.0\n",
      "Train loss and acc of batch 50: 48.327545166015625, 0.984375\n",
      "Train loss and acc of batch 51: 49.08075714111328, 0.96875\n",
      "Train loss and acc of batch 52: 48.9876708984375, 0.953125\n",
      "Train loss and acc of batch 53: 47.73181915283203, 1.0\n",
      "Train loss and acc of batch 54: 47.948570251464844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 55: 47.73180389404297, 1.0\n",
      "Train loss and acc of batch 56: 47.731788635253906, 1.0\n",
      "Train loss and acc of batch 57: 48.327484130859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.731773376464844, 1.0\n",
      "Train loss and acc of batch 59: 47.73176193237305, 1.0\n",
      "Train loss and acc of batch 60: 47.73175811767578, 1.0\n",
      "Train loss and acc of batch 61: 47.731746673583984, 1.0\n",
      "Train loss and acc of batch 62: 47.73173522949219, 1.0\n",
      "Train loss and acc of batch 63: 48.923133850097656, 0.96875\n",
      "Train loss and acc of batch 64: 47.948486328125, 0.984375\n",
      "Train loss and acc of batch 65: 47.731712341308594, 1.0\n",
      "Train loss and acc of batch 66: 47.73170471191406, 1.0\n",
      "Train loss and acc of batch 67: 48.54416275024414, 0.96875\n",
      "Train loss and acc of batch 68: 48.32738494873047, 0.984375\n",
      "Train loss and acc of batch 69: 47.94844055175781, 0.984375\n",
      "Train loss and acc of batch 70: 47.731666564941406, 1.0\n",
      "Training accuracy and loss of epoch #517: 0.9897, 48.0529\n",
      "Saved model by train loss 48.05286128084425\n",
      "Train loss and acc of batch 0: 47.73165512084961, 1.0\n",
      "Train loss and acc of batch 1: 47.73164749145508, 1.0\n",
      "Train loss and acc of batch 2: 47.73164367675781, 1.0\n",
      "Train loss and acc of batch 3: 47.948394775390625, 0.984375\n",
      "Train loss and acc of batch 4: 47.73162078857422, 1.0\n",
      "Train loss and acc of batch 5: 49.080535888671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.234222412109375, 0.96875\n",
      "Train loss and acc of batch 7: 47.731597900390625, 1.0\n",
      "Train loss and acc of batch 8: 48.327293395996094, 0.984375\n",
      "Train loss and acc of batch 9: 48.017433166503906, 0.984375\n",
      "Train loss and acc of batch 10: 47.73157501220703, 1.0\n",
      "Train loss and acc of batch 11: 47.73155975341797, 1.0\n",
      "Train loss and acc of batch 12: 48.48477554321289, 0.984375\n",
      "Train loss and acc of batch 13: 47.94830322265625, 0.984375\n",
      "Train loss and acc of batch 14: 47.94830322265625, 0.984375\n",
      "Train loss and acc of batch 15: 48.32722473144531, 0.984375\n",
      "Train loss and acc of batch 16: 48.32721710205078, 0.984375\n",
      "Train loss and acc of batch 17: 48.4847297668457, 0.984375\n",
      "Train loss and acc of batch 18: 48.61305236816406, 0.96875\n",
      "Train loss and acc of batch 19: 47.73149108886719, 1.0\n",
      "Train loss and acc of batch 20: 47.73147964477539, 1.0\n",
      "Train loss and acc of batch 21: 48.327171325683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.32716369628906, 0.984375\n",
      "Train loss and acc of batch 23: 47.7314567565918, 1.0\n",
      "Train loss and acc of batch 24: 48.3271484375, 0.984375\n",
      "Train loss and acc of batch 25: 47.73143768310547, 1.0\n",
      "Train loss and acc of batch 26: 47.73143005371094, 1.0\n",
      "Train loss and acc of batch 27: 47.731422424316406, 1.0\n",
      "Train loss and acc of batch 28: 47.73141098022461, 1.0\n",
      "Train loss and acc of batch 29: 48.32710266113281, 0.984375\n",
      "Train loss and acc of batch 30: 47.73139572143555, 1.0\n",
      "Train loss and acc of batch 31: 47.948150634765625, 0.984375\n",
      "Train loss and acc of batch 32: 47.731380462646484, 1.0\n",
      "Train loss and acc of batch 33: 47.73136901855469, 1.0\n",
      "Train loss and acc of batch 34: 48.327056884765625, 0.984375\n",
      "Train loss and acc of batch 35: 48.164878845214844, 0.96875\n",
      "Train loss and acc of batch 36: 47.73133850097656, 1.0\n",
      "Train loss and acc of batch 37: 48.484554290771484, 0.984375\n",
      "Train loss and acc of batch 38: 49.08024597167969, 0.96875\n",
      "Train loss and acc of batch 39: 47.948081970214844, 0.984375\n",
      "Train loss and acc of batch 40: 47.73130416870117, 1.0\n",
      "Train loss and acc of batch 41: 49.08021926879883, 0.96875\n",
      "Train loss and acc of batch 42: 47.731285095214844, 1.0\n",
      "Train loss and acc of batch 43: 48.32698059082031, 0.984375\n",
      "Train loss and acc of batch 44: 47.731266021728516, 1.0\n",
      "Train loss and acc of batch 45: 48.32695770263672, 0.984375\n",
      "Train loss and acc of batch 46: 48.01710510253906, 0.984375\n",
      "Train loss and acc of batch 47: 47.73124313354492, 1.0\n",
      "Train loss and acc of batch 48: 47.731231689453125, 1.0\n",
      "Train loss and acc of batch 49: 47.73122787475586, 1.0\n",
      "Train loss and acc of batch 50: 48.32691192626953, 0.984375\n",
      "Train loss and acc of batch 51: 49.08013153076172, 0.96875\n",
      "Train loss and acc of batch 52: 48.987037658691406, 0.953125\n",
      "Train loss and acc of batch 53: 47.7311897277832, 1.0\n",
      "Train loss and acc of batch 54: 47.94794464111328, 0.984375\n",
      "Train loss and acc of batch 55: 47.73117446899414, 1.0\n",
      "Train loss and acc of batch 56: 47.731163024902344, 1.0\n",
      "Train loss and acc of batch 57: 48.32685852050781, 0.984375\n",
      "Train loss and acc of batch 58: 47.731143951416016, 1.0\n",
      "Train loss and acc of batch 59: 47.73114013671875, 1.0\n",
      "Train loss and acc of batch 60: 47.73112869262695, 1.0\n",
      "Train loss and acc of batch 61: 47.731117248535156, 1.0\n",
      "Train loss and acc of batch 62: 47.73110580444336, 1.0\n",
      "Train loss and acc of batch 63: 48.92250061035156, 0.96875\n",
      "Train loss and acc of batch 64: 47.94786071777344, 0.984375\n",
      "Train loss and acc of batch 65: 47.7310791015625, 1.0\n",
      "Train loss and acc of batch 66: 47.731075286865234, 1.0\n",
      "Train loss and acc of batch 67: 48.54352951049805, 0.96875\n",
      "Train loss and acc of batch 68: 48.326759338378906, 0.984375\n",
      "Train loss and acc of batch 69: 47.94781494140625, 0.984375\n",
      "Train loss and acc of batch 70: 47.73103713989258, 1.0\n",
      "Training accuracy and loss of epoch #518: 0.9897, 48.0522\n",
      "Saved model by train loss 48.05223207070794\n",
      "Train loss and acc of batch 0: 47.73102951049805, 1.0\n",
      "Train loss and acc of batch 1: 47.73102569580078, 1.0\n",
      "Train loss and acc of batch 2: 47.731014251708984, 1.0\n",
      "Train loss and acc of batch 3: 47.94776916503906, 0.984375\n",
      "Train loss and acc of batch 4: 47.730995178222656, 1.0\n",
      "Train loss and acc of batch 5: 49.07991027832031, 0.96875\n",
      "Train loss and acc of batch 6: 48.23359298706055, 0.96875\n",
      "Train loss and acc of batch 7: 47.7309684753418, 1.0\n",
      "Train loss and acc of batch 8: 48.32665252685547, 0.984375\n",
      "Train loss and acc of batch 9: 48.01679992675781, 0.984375\n",
      "Train loss and acc of batch 10: 47.73094177246094, 1.0\n",
      "Train loss and acc of batch 11: 47.730934143066406, 1.0\n",
      "Train loss and acc of batch 12: 48.48414993286133, 0.984375\n",
      "Train loss and acc of batch 13: 47.94767761230469, 0.984375\n",
      "Train loss and acc of batch 14: 47.947669982910156, 0.984375\n",
      "Train loss and acc of batch 15: 48.32659912109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.32659149169922, 0.984375\n",
      "Train loss and acc of batch 17: 48.48410415649414, 0.984375\n",
      "Train loss and acc of batch 18: 48.6124267578125, 0.96875\n",
      "Train loss and acc of batch 19: 47.730865478515625, 1.0\n",
      "Train loss and acc of batch 20: 47.73085403442383, 1.0\n",
      "Train loss and acc of batch 21: 48.32654571533203, 0.984375\n",
      "Train loss and acc of batch 22: 48.3265380859375, 0.984375\n",
      "Train loss and acc of batch 23: 47.73082733154297, 1.0\n",
      "Train loss and acc of batch 24: 48.326515197753906, 0.984375\n",
      "Train loss and acc of batch 25: 47.73080825805664, 1.0\n",
      "Train loss and acc of batch 26: 47.73080062866211, 1.0\n",
      "Train loss and acc of batch 27: 47.73079299926758, 1.0\n",
      "Train loss and acc of batch 28: 47.73078155517578, 1.0\n",
      "Train loss and acc of batch 29: 48.32647705078125, 0.984375\n",
      "Train loss and acc of batch 30: 47.73076629638672, 1.0\n",
      "Train loss and acc of batch 31: 47.94751739501953, 0.984375\n",
      "Train loss and acc of batch 32: 47.73074722290039, 1.0\n",
      "Train loss and acc of batch 33: 47.73073959350586, 1.0\n",
      "Train loss and acc of batch 34: 48.32643127441406, 0.984375\n",
      "Train loss and acc of batch 35: 48.16424560546875, 0.96875\n",
      "Train loss and acc of batch 36: 47.730712890625, 1.0\n",
      "Train loss and acc of batch 37: 48.483924865722656, 0.984375\n",
      "Train loss and acc of batch 38: 49.079620361328125, 0.96875\n",
      "Train loss and acc of batch 39: 47.94744873046875, 0.984375\n",
      "Train loss and acc of batch 40: 47.73067855834961, 1.0\n",
      "Train loss and acc of batch 41: 49.079593658447266, 0.96875\n",
      "Train loss and acc of batch 42: 47.730655670166016, 1.0\n",
      "Train loss and acc of batch 43: 48.32634735107422, 0.984375\n",
      "Train loss and acc of batch 44: 47.73064041137695, 1.0\n",
      "Train loss and acc of batch 45: 48.326332092285156, 0.984375\n",
      "Train loss and acc of batch 46: 48.0164794921875, 0.984375\n",
      "Train loss and acc of batch 47: 47.730613708496094, 1.0\n",
      "Train loss and acc of batch 48: 47.73060989379883, 1.0\n",
      "Train loss and acc of batch 49: 47.73059844970703, 1.0\n",
      "Train loss and acc of batch 50: 48.32628631591797, 0.984375\n",
      "Train loss and acc of batch 51: 49.079505920410156, 0.96875\n",
      "Train loss and acc of batch 52: 48.98640823364258, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.730560302734375, 1.0\n",
      "Train loss and acc of batch 54: 47.94731903076172, 0.984375\n",
      "Train loss and acc of batch 55: 47.73054122924805, 1.0\n",
      "Train loss and acc of batch 56: 47.73053741455078, 1.0\n",
      "Train loss and acc of batch 57: 48.32622528076172, 0.984375\n",
      "Train loss and acc of batch 58: 47.73051452636719, 1.0\n",
      "Train loss and acc of batch 59: 47.730506896972656, 1.0\n",
      "Train loss and acc of batch 60: 47.73049545288086, 1.0\n",
      "Train loss and acc of batch 61: 47.73048782348633, 1.0\n",
      "Train loss and acc of batch 62: 47.73048400878906, 1.0\n",
      "Train loss and acc of batch 63: 48.921875, 0.96875\n",
      "Train loss and acc of batch 64: 47.947227478027344, 0.984375\n",
      "Train loss and acc of batch 65: 47.73045349121094, 1.0\n",
      "Train loss and acc of batch 66: 47.730445861816406, 1.0\n",
      "Train loss and acc of batch 67: 48.54290008544922, 0.96875\n",
      "Train loss and acc of batch 68: 48.326133728027344, 0.984375\n",
      "Train loss and acc of batch 69: 47.947181701660156, 0.984375\n",
      "Train loss and acc of batch 70: 47.73040771484375, 1.0\n",
      "Training accuracy and loss of epoch #519: 0.9897, 48.0516\n",
      "Saved model by train loss 48.05160366649359\n",
      "Train loss and acc of batch 0: 47.73040008544922, 1.0\n",
      "Train loss and acc of batch 1: 47.73039245605469, 1.0\n",
      "Train loss and acc of batch 2: 47.730384826660156, 1.0\n",
      "Train loss and acc of batch 3: 47.94713592529297, 0.984375\n",
      "Train loss and acc of batch 4: 47.73036575317383, 1.0\n",
      "Train loss and acc of batch 5: 49.07928466796875, 0.96875\n",
      "Train loss and acc of batch 6: 48.232967376708984, 0.96875\n",
      "Train loss and acc of batch 7: 47.7303352355957, 1.0\n",
      "Train loss and acc of batch 8: 48.32603454589844, 0.984375\n",
      "Train loss and acc of batch 9: 48.01617431640625, 0.984375\n",
      "Train loss and acc of batch 10: 47.730316162109375, 1.0\n",
      "Train loss and acc of batch 11: 47.730308532714844, 1.0\n",
      "Train loss and acc of batch 12: 48.483516693115234, 0.984375\n",
      "Train loss and acc of batch 13: 47.947052001953125, 0.984375\n",
      "Train loss and acc of batch 14: 47.947044372558594, 0.984375\n",
      "Train loss and acc of batch 15: 48.325965881347656, 0.984375\n",
      "Train loss and acc of batch 16: 48.325958251953125, 0.984375\n",
      "Train loss and acc of batch 17: 48.48347091674805, 0.984375\n",
      "Train loss and acc of batch 18: 48.61179733276367, 0.96875\n",
      "Train loss and acc of batch 19: 47.73023223876953, 1.0\n",
      "Train loss and acc of batch 20: 47.730224609375, 1.0\n",
      "Train loss and acc of batch 21: 48.32591247558594, 0.984375\n",
      "Train loss and acc of batch 22: 48.325904846191406, 0.984375\n",
      "Train loss and acc of batch 23: 47.730194091796875, 1.0\n",
      "Train loss and acc of batch 24: 48.325889587402344, 0.984375\n",
      "Train loss and acc of batch 25: 47.73018264770508, 1.0\n",
      "Train loss and acc of batch 26: 47.73017120361328, 1.0\n",
      "Train loss and acc of batch 27: 47.73016357421875, 1.0\n",
      "Train loss and acc of batch 28: 47.730159759521484, 1.0\n",
      "Train loss and acc of batch 29: 48.325843811035156, 0.984375\n",
      "Train loss and acc of batch 30: 47.73013687133789, 1.0\n",
      "Train loss and acc of batch 31: 47.94689178466797, 0.984375\n",
      "Train loss and acc of batch 32: 47.73011779785156, 1.0\n",
      "Train loss and acc of batch 33: 47.730106353759766, 1.0\n",
      "Train loss and acc of batch 34: 48.32579803466797, 0.984375\n",
      "Train loss and acc of batch 35: 48.16361999511719, 0.96875\n",
      "Train loss and acc of batch 36: 47.730079650878906, 1.0\n",
      "Train loss and acc of batch 37: 48.48329544067383, 0.984375\n",
      "Train loss and acc of batch 38: 49.07898712158203, 0.96875\n",
      "Train loss and acc of batch 39: 47.94682312011719, 0.984375\n",
      "Train loss and acc of batch 40: 47.730045318603516, 1.0\n",
      "Train loss and acc of batch 41: 49.07896423339844, 0.96875\n",
      "Train loss and acc of batch 42: 47.73003387451172, 1.0\n",
      "Train loss and acc of batch 43: 48.325721740722656, 0.984375\n",
      "Train loss and acc of batch 44: 47.730003356933594, 1.0\n",
      "Train loss and acc of batch 45: 48.325706481933594, 0.984375\n",
      "Train loss and acc of batch 46: 48.015846252441406, 0.984375\n",
      "Train loss and acc of batch 47: 47.729984283447266, 1.0\n",
      "Train loss and acc of batch 48: 47.72997283935547, 1.0\n",
      "Train loss and acc of batch 49: 47.72996520996094, 1.0\n",
      "Train loss and acc of batch 50: 48.325660705566406, 0.984375\n",
      "Train loss and acc of batch 51: 49.07887268066406, 0.96875\n",
      "Train loss and acc of batch 52: 48.98577880859375, 0.953125\n",
      "Train loss and acc of batch 53: 47.72993469238281, 1.0\n",
      "Train loss and acc of batch 54: 47.946685791015625, 0.984375\n",
      "Train loss and acc of batch 55: 47.729915618896484, 1.0\n",
      "Train loss and acc of batch 56: 47.72990798950195, 1.0\n",
      "Train loss and acc of batch 57: 48.325599670410156, 0.984375\n",
      "Train loss and acc of batch 58: 47.72988510131836, 1.0\n",
      "Train loss and acc of batch 59: 47.72987365722656, 1.0\n",
      "Train loss and acc of batch 60: 47.72986602783203, 1.0\n",
      "Train loss and acc of batch 61: 47.7298583984375, 1.0\n",
      "Train loss and acc of batch 62: 47.7298469543457, 1.0\n",
      "Train loss and acc of batch 63: 48.92124557495117, 0.96875\n",
      "Train loss and acc of batch 64: 47.94659423828125, 0.984375\n",
      "Train loss and acc of batch 65: 47.729827880859375, 1.0\n",
      "Train loss and acc of batch 66: 47.72981262207031, 1.0\n",
      "Train loss and acc of batch 67: 48.542274475097656, 0.96875\n",
      "Train loss and acc of batch 68: 48.32550048828125, 0.984375\n",
      "Train loss and acc of batch 69: 47.946556091308594, 0.984375\n",
      "Train loss and acc of batch 70: 47.72978210449219, 1.0\n",
      "Training accuracy and loss of epoch #520: 0.9897, 48.0510\n",
      "Saved model by train loss 48.050974133988504\n",
      "Train loss and acc of batch 0: 47.729774475097656, 1.0\n",
      "Train loss and acc of batch 1: 47.72976303100586, 1.0\n",
      "Train loss and acc of batch 2: 47.72975540161133, 1.0\n",
      "Train loss and acc of batch 3: 47.946510314941406, 0.984375\n",
      "Train loss and acc of batch 4: 47.729736328125, 1.0\n",
      "Train loss and acc of batch 5: 49.078651428222656, 0.96875\n",
      "Train loss and acc of batch 6: 48.23233413696289, 0.96875\n",
      "Train loss and acc of batch 7: 47.72970962524414, 1.0\n",
      "Train loss and acc of batch 8: 48.325401306152344, 0.984375\n",
      "Train loss and acc of batch 9: 48.01554870605469, 0.984375\n",
      "Train loss and acc of batch 10: 47.72968292236328, 1.0\n",
      "Train loss and acc of batch 11: 47.72967529296875, 1.0\n",
      "Train loss and acc of batch 12: 48.482887268066406, 0.984375\n",
      "Train loss and acc of batch 13: 47.94642639160156, 0.984375\n",
      "Train loss and acc of batch 14: 47.9464111328125, 0.984375\n",
      "Train loss and acc of batch 15: 48.325340270996094, 0.984375\n",
      "Train loss and acc of batch 16: 48.32533264160156, 0.984375\n",
      "Train loss and acc of batch 17: 48.482845306396484, 0.984375\n",
      "Train loss and acc of batch 18: 48.61116027832031, 0.96875\n",
      "Train loss and acc of batch 19: 47.72960662841797, 1.0\n",
      "Train loss and acc of batch 20: 47.729591369628906, 1.0\n",
      "Train loss and acc of batch 21: 48.325286865234375, 0.984375\n",
      "Train loss and acc of batch 22: 48.325279235839844, 0.984375\n",
      "Train loss and acc of batch 23: 47.72956848144531, 1.0\n",
      "Train loss and acc of batch 24: 48.32525634765625, 0.984375\n",
      "Train loss and acc of batch 25: 47.72954559326172, 1.0\n",
      "Train loss and acc of batch 26: 47.72953796386719, 1.0\n",
      "Train loss and acc of batch 27: 47.72953414916992, 1.0\n",
      "Train loss and acc of batch 28: 47.729522705078125, 1.0\n",
      "Train loss and acc of batch 29: 48.325218200683594, 0.984375\n",
      "Train loss and acc of batch 30: 47.72950744628906, 1.0\n",
      "Train loss and acc of batch 31: 47.946266174316406, 0.984375\n",
      "Train loss and acc of batch 32: 47.72948455810547, 1.0\n",
      "Train loss and acc of batch 33: 47.72948455810547, 1.0\n",
      "Train loss and acc of batch 34: 48.325172424316406, 0.984375\n",
      "Train loss and acc of batch 35: 48.16299057006836, 0.96875\n",
      "Train loss and acc of batch 36: 47.729454040527344, 1.0\n",
      "Train loss and acc of batch 37: 48.482666015625, 0.984375\n",
      "Train loss and acc of batch 38: 49.07836151123047, 0.96875\n",
      "Train loss and acc of batch 39: 47.946189880371094, 0.984375\n",
      "Train loss and acc of batch 40: 47.72941589355469, 1.0\n",
      "Train loss and acc of batch 41: 49.07833480834961, 0.96875\n",
      "Train loss and acc of batch 42: 47.729400634765625, 1.0\n",
      "Train loss and acc of batch 43: 48.32508850097656, 0.984375\n",
      "Train loss and acc of batch 44: 47.7293815612793, 1.0\n",
      "Train loss and acc of batch 45: 48.3250732421875, 0.984375\n",
      "Train loss and acc of batch 46: 48.01521301269531, 0.984375\n",
      "Train loss and acc of batch 47: 47.72935485839844, 1.0\n",
      "Train loss and acc of batch 48: 47.729347229003906, 1.0\n",
      "Train loss and acc of batch 49: 47.72933578491211, 1.0\n",
      "Train loss and acc of batch 50: 48.325035095214844, 0.984375\n",
      "Train loss and acc of batch 51: 49.07823944091797, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 52: 48.98515319824219, 0.953125\n",
      "Train loss and acc of batch 53: 47.72930145263672, 1.0\n",
      "Train loss and acc of batch 54: 47.94605255126953, 0.984375\n",
      "Train loss and acc of batch 55: 47.72928237915039, 1.0\n",
      "Train loss and acc of batch 56: 47.729278564453125, 1.0\n",
      "Train loss and acc of batch 57: 48.32496643066406, 0.984375\n",
      "Train loss and acc of batch 58: 47.72925567626953, 1.0\n",
      "Train loss and acc of batch 59: 47.729248046875, 1.0\n",
      "Train loss and acc of batch 60: 47.729244232177734, 1.0\n",
      "Train loss and acc of batch 61: 47.72923278808594, 1.0\n",
      "Train loss and acc of batch 62: 47.72922134399414, 1.0\n",
      "Train loss and acc of batch 63: 48.920616149902344, 0.96875\n",
      "Train loss and acc of batch 64: 47.94596862792969, 0.984375\n",
      "Train loss and acc of batch 65: 47.72919845581055, 1.0\n",
      "Train loss and acc of batch 66: 47.729190826416016, 1.0\n",
      "Train loss and acc of batch 67: 48.54164123535156, 0.96875\n",
      "Train loss and acc of batch 68: 48.324867248535156, 0.984375\n",
      "Train loss and acc of batch 69: 47.9459228515625, 0.984375\n",
      "Train loss and acc of batch 70: 47.729148864746094, 1.0\n",
      "Training accuracy and loss of epoch #521: 0.9897, 48.0503\n",
      "Saved model by train loss 48.050344816395935\n",
      "Train loss and acc of batch 0: 47.72914123535156, 1.0\n",
      "Train loss and acc of batch 1: 47.72913360595703, 1.0\n",
      "Train loss and acc of batch 2: 47.7291259765625, 1.0\n",
      "Train loss and acc of batch 3: 47.945884704589844, 0.984375\n",
      "Train loss and acc of batch 4: 47.72910690307617, 1.0\n",
      "Train loss and acc of batch 5: 49.078025817871094, 0.96875\n",
      "Train loss and acc of batch 6: 48.23170471191406, 0.96875\n",
      "Train loss and acc of batch 7: 47.72908401489258, 1.0\n",
      "Train loss and acc of batch 8: 48.32477569580078, 0.984375\n",
      "Train loss and acc of batch 9: 48.014915466308594, 0.984375\n",
      "Train loss and acc of batch 10: 47.72905349731445, 1.0\n",
      "Train loss and acc of batch 11: 47.72904968261719, 1.0\n",
      "Train loss and acc of batch 12: 48.48225784301758, 0.984375\n",
      "Train loss and acc of batch 13: 47.94579315185547, 0.984375\n",
      "Train loss and acc of batch 14: 47.945777893066406, 0.984375\n",
      "Train loss and acc of batch 15: 48.32470703125, 0.984375\n",
      "Train loss and acc of batch 16: 48.32469940185547, 0.984375\n",
      "Train loss and acc of batch 17: 48.482215881347656, 0.984375\n",
      "Train loss and acc of batch 18: 48.610538482666016, 0.96875\n",
      "Train loss and acc of batch 19: 47.728973388671875, 1.0\n",
      "Train loss and acc of batch 20: 47.728965759277344, 1.0\n",
      "Train loss and acc of batch 21: 48.32465362548828, 0.984375\n",
      "Train loss and acc of batch 22: 48.32465362548828, 0.984375\n",
      "Train loss and acc of batch 23: 47.728939056396484, 1.0\n",
      "Train loss and acc of batch 24: 48.32463073730469, 0.984375\n",
      "Train loss and acc of batch 25: 47.72892379760742, 1.0\n",
      "Train loss and acc of batch 26: 47.728912353515625, 1.0\n",
      "Train loss and acc of batch 27: 47.72890090942383, 1.0\n",
      "Train loss and acc of batch 28: 47.72889709472656, 1.0\n",
      "Train loss and acc of batch 29: 48.3245849609375, 0.984375\n",
      "Train loss and acc of batch 30: 47.728878021240234, 1.0\n",
      "Train loss and acc of batch 31: 47.94563293457031, 0.984375\n",
      "Train loss and acc of batch 32: 47.728858947753906, 1.0\n",
      "Train loss and acc of batch 33: 47.72884750366211, 1.0\n",
      "Train loss and acc of batch 34: 48.32453918457031, 0.984375\n",
      "Train loss and acc of batch 35: 48.162357330322266, 0.96875\n",
      "Train loss and acc of batch 36: 47.728824615478516, 1.0\n",
      "Train loss and acc of batch 37: 48.48204040527344, 0.984375\n",
      "Train loss and acc of batch 38: 49.077728271484375, 0.96875\n",
      "Train loss and acc of batch 39: 47.94556427001953, 0.984375\n",
      "Train loss and acc of batch 40: 47.728790283203125, 1.0\n",
      "Train loss and acc of batch 41: 49.077701568603516, 0.96875\n",
      "Train loss and acc of batch 42: 47.7287712097168, 1.0\n",
      "Train loss and acc of batch 43: 48.324462890625, 0.984375\n",
      "Train loss and acc of batch 44: 47.72875213623047, 1.0\n",
      "Train loss and acc of batch 45: 48.32444763183594, 0.984375\n",
      "Train loss and acc of batch 46: 48.01458740234375, 0.984375\n",
      "Train loss and acc of batch 47: 47.72872543334961, 1.0\n",
      "Train loss and acc of batch 48: 47.72871398925781, 1.0\n",
      "Train loss and acc of batch 49: 47.72870635986328, 1.0\n",
      "Train loss and acc of batch 50: 48.32440185546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.077613830566406, 0.96875\n",
      "Train loss and acc of batch 52: 48.984527587890625, 0.953125\n",
      "Train loss and acc of batch 53: 47.72867202758789, 1.0\n",
      "Train loss and acc of batch 54: 47.94542694091797, 0.984375\n",
      "Train loss and acc of batch 55: 47.72865676879883, 1.0\n",
      "Train loss and acc of batch 56: 47.72864532470703, 1.0\n",
      "Train loss and acc of batch 57: 48.3243408203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.7286262512207, 1.0\n",
      "Train loss and acc of batch 59: 47.72861862182617, 1.0\n",
      "Train loss and acc of batch 60: 47.728607177734375, 1.0\n",
      "Train loss and acc of batch 61: 47.72860336303711, 1.0\n",
      "Train loss and acc of batch 62: 47.72859191894531, 1.0\n",
      "Train loss and acc of batch 63: 48.919986724853516, 0.96875\n",
      "Train loss and acc of batch 64: 47.945343017578125, 0.984375\n",
      "Train loss and acc of batch 65: 47.72856903076172, 1.0\n",
      "Train loss and acc of batch 66: 47.728553771972656, 1.0\n",
      "Train loss and acc of batch 67: 48.541015625, 0.96875\n",
      "Train loss and acc of batch 68: 48.324241638183594, 0.984375\n",
      "Train loss and acc of batch 69: 47.94529724121094, 0.984375\n",
      "Train loss and acc of batch 70: 47.72852325439453, 1.0\n",
      "Training accuracy and loss of epoch #522: 0.9897, 48.0497\n",
      "Saved model by train loss 48.04971576744402\n",
      "Train loss and acc of batch 0: 47.728515625, 1.0\n",
      "Train loss and acc of batch 1: 47.7285041809082, 1.0\n",
      "Train loss and acc of batch 2: 47.72850036621094, 1.0\n",
      "Train loss and acc of batch 3: 47.94525146484375, 0.984375\n",
      "Train loss and acc of batch 4: 47.728477478027344, 1.0\n",
      "Train loss and acc of batch 5: 49.077392578125, 0.96875\n",
      "Train loss and acc of batch 6: 48.2310791015625, 0.96875\n",
      "Train loss and acc of batch 7: 47.72844696044922, 1.0\n",
      "Train loss and acc of batch 8: 48.32415008544922, 0.984375\n",
      "Train loss and acc of batch 9: 48.0142822265625, 0.984375\n",
      "Train loss and acc of batch 10: 47.728424072265625, 1.0\n",
      "Train loss and acc of batch 11: 47.728416442871094, 1.0\n",
      "Train loss and acc of batch 12: 48.48162841796875, 0.984375\n",
      "Train loss and acc of batch 13: 47.945167541503906, 0.984375\n",
      "Train loss and acc of batch 14: 47.945159912109375, 0.984375\n",
      "Train loss and acc of batch 15: 48.32408142089844, 0.984375\n",
      "Train loss and acc of batch 16: 48.324073791503906, 0.984375\n",
      "Train loss and acc of batch 17: 48.48158645629883, 0.984375\n",
      "Train loss and acc of batch 18: 48.60990905761719, 0.96875\n",
      "Train loss and acc of batch 19: 47.72834777832031, 1.0\n",
      "Train loss and acc of batch 20: 47.728336334228516, 1.0\n",
      "Train loss and acc of batch 21: 48.32402801513672, 0.984375\n",
      "Train loss and acc of batch 22: 48.32402038574219, 0.984375\n",
      "Train loss and acc of batch 23: 47.72830581665039, 1.0\n",
      "Train loss and acc of batch 24: 48.323997497558594, 0.984375\n",
      "Train loss and acc of batch 25: 47.728294372558594, 1.0\n",
      "Train loss and acc of batch 26: 47.72827911376953, 1.0\n",
      "Train loss and acc of batch 27: 47.728275299072266, 1.0\n",
      "Train loss and acc of batch 28: 47.728267669677734, 1.0\n",
      "Train loss and acc of batch 29: 48.32395935058594, 0.984375\n",
      "Train loss and acc of batch 30: 47.728248596191406, 1.0\n",
      "Train loss and acc of batch 31: 47.94500732421875, 0.984375\n",
      "Train loss and acc of batch 32: 47.72822952270508, 1.0\n",
      "Train loss and acc of batch 33: 47.72822189331055, 1.0\n",
      "Train loss and acc of batch 34: 48.32390594482422, 0.984375\n",
      "Train loss and acc of batch 35: 48.16173553466797, 0.96875\n",
      "Train loss and acc of batch 36: 47.72819137573242, 1.0\n",
      "Train loss and acc of batch 37: 48.48140335083008, 0.984375\n",
      "Train loss and acc of batch 38: 49.07710266113281, 0.96875\n",
      "Train loss and acc of batch 39: 47.94493103027344, 0.984375\n",
      "Train loss and acc of batch 40: 47.72815704345703, 1.0\n",
      "Train loss and acc of batch 41: 49.07707595825195, 0.96875\n",
      "Train loss and acc of batch 42: 47.72814178466797, 1.0\n",
      "Train loss and acc of batch 43: 48.323829650878906, 0.984375\n",
      "Train loss and acc of batch 44: 47.72812271118164, 1.0\n",
      "Train loss and acc of batch 45: 48.323814392089844, 0.984375\n",
      "Train loss and acc of batch 46: 48.013954162597656, 0.984375\n",
      "Train loss and acc of batch 47: 47.72809982299805, 1.0\n",
      "Train loss and acc of batch 48: 47.72808837890625, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 49: 47.72808074951172, 1.0\n",
      "Train loss and acc of batch 50: 48.323768615722656, 0.984375\n",
      "Train loss and acc of batch 51: 49.07698059082031, 0.96875\n",
      "Train loss and acc of batch 52: 48.983890533447266, 0.953125\n",
      "Train loss and acc of batch 53: 47.72804260253906, 1.0\n",
      "Train loss and acc of batch 54: 47.944793701171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.728023529052734, 1.0\n",
      "Train loss and acc of batch 56: 47.7280158996582, 1.0\n",
      "Train loss and acc of batch 57: 48.323707580566406, 0.984375\n",
      "Train loss and acc of batch 58: 47.72800064086914, 1.0\n",
      "Train loss and acc of batch 59: 47.727989196777344, 1.0\n",
      "Train loss and acc of batch 60: 47.72797775268555, 1.0\n",
      "Train loss and acc of batch 61: 47.72797393798828, 1.0\n",
      "Train loss and acc of batch 62: 47.72796630859375, 1.0\n",
      "Train loss and acc of batch 63: 48.91935729980469, 0.96875\n",
      "Train loss and acc of batch 64: 47.94470977783203, 0.984375\n",
      "Train loss and acc of batch 65: 47.727935791015625, 1.0\n",
      "Train loss and acc of batch 66: 47.727928161621094, 1.0\n",
      "Train loss and acc of batch 67: 48.540382385253906, 0.96875\n",
      "Train loss and acc of batch 68: 48.3236083984375, 0.984375\n",
      "Train loss and acc of batch 69: 47.944664001464844, 0.984375\n",
      "Train loss and acc of batch 70: 47.7278938293457, 1.0\n",
      "Training accuracy and loss of epoch #523: 0.9897, 48.0491\n",
      "Saved model by train loss 48.04908607375454\n",
      "Train loss and acc of batch 0: 47.72788619995117, 1.0\n",
      "Train loss and acc of batch 1: 47.72787857055664, 1.0\n",
      "Train loss and acc of batch 2: 47.727867126464844, 1.0\n",
      "Train loss and acc of batch 3: 47.94462585449219, 0.984375\n",
      "Train loss and acc of batch 4: 47.727848052978516, 1.0\n",
      "Train loss and acc of batch 5: 49.07676696777344, 0.96875\n",
      "Train loss and acc of batch 6: 48.230445861816406, 0.96875\n",
      "Train loss and acc of batch 7: 47.72782516479492, 1.0\n",
      "Train loss and acc of batch 8: 48.323516845703125, 0.984375\n",
      "Train loss and acc of batch 9: 48.01365661621094, 0.984375\n",
      "Train loss and acc of batch 10: 47.72779846191406, 1.0\n",
      "Train loss and acc of batch 11: 47.727787017822266, 1.0\n",
      "Train loss and acc of batch 12: 48.48100280761719, 0.984375\n",
      "Train loss and acc of batch 13: 47.94453430175781, 0.984375\n",
      "Train loss and acc of batch 14: 47.94452667236328, 0.984375\n",
      "Train loss and acc of batch 15: 48.323455810546875, 0.984375\n",
      "Train loss and acc of batch 16: 48.32344055175781, 0.984375\n",
      "Train loss and acc of batch 17: 48.48094940185547, 0.984375\n",
      "Train loss and acc of batch 18: 48.609275817871094, 0.96875\n",
      "Train loss and acc of batch 19: 47.727718353271484, 1.0\n",
      "Train loss and acc of batch 20: 47.72770690917969, 1.0\n",
      "Train loss and acc of batch 21: 48.323402404785156, 0.984375\n",
      "Train loss and acc of batch 22: 48.323387145996094, 0.984375\n",
      "Train loss and acc of batch 23: 47.72768020629883, 1.0\n",
      "Train loss and acc of batch 24: 48.32337188720703, 0.984375\n",
      "Train loss and acc of batch 25: 47.727664947509766, 1.0\n",
      "Train loss and acc of batch 26: 47.72765350341797, 1.0\n",
      "Train loss and acc of batch 27: 47.72764205932617, 1.0\n",
      "Train loss and acc of batch 28: 47.72763442993164, 1.0\n",
      "Train loss and acc of batch 29: 48.323333740234375, 0.984375\n",
      "Train loss and acc of batch 30: 47.72761917114258, 1.0\n",
      "Train loss and acc of batch 31: 47.944374084472656, 0.984375\n",
      "Train loss and acc of batch 32: 47.72760009765625, 1.0\n",
      "Train loss and acc of batch 33: 47.72758865356445, 1.0\n",
      "Train loss and acc of batch 34: 48.323280334472656, 0.984375\n",
      "Train loss and acc of batch 35: 48.16110610961914, 0.96875\n",
      "Train loss and acc of batch 36: 47.72756576538086, 1.0\n",
      "Train loss and acc of batch 37: 48.480777740478516, 0.984375\n",
      "Train loss and acc of batch 38: 49.07647705078125, 0.96875\n",
      "Train loss and acc of batch 39: 47.944297790527344, 0.984375\n",
      "Train loss and acc of batch 40: 47.72753143310547, 1.0\n",
      "Train loss and acc of batch 41: 49.07644271850586, 0.96875\n",
      "Train loss and acc of batch 42: 47.727516174316406, 1.0\n",
      "Train loss and acc of batch 43: 48.323204040527344, 0.984375\n",
      "Train loss and acc of batch 44: 47.72749710083008, 1.0\n",
      "Train loss and acc of batch 45: 48.32318878173828, 0.984375\n",
      "Train loss and acc of batch 46: 48.013328552246094, 0.984375\n",
      "Train loss and acc of batch 47: 47.72746276855469, 1.0\n",
      "Train loss and acc of batch 48: 47.72745895385742, 1.0\n",
      "Train loss and acc of batch 49: 47.72745132446289, 1.0\n",
      "Train loss and acc of batch 50: 48.323143005371094, 0.984375\n",
      "Train loss and acc of batch 51: 49.07635498046875, 0.96875\n",
      "Train loss and acc of batch 52: 48.98326873779297, 0.953125\n",
      "Train loss and acc of batch 53: 47.727413177490234, 1.0\n",
      "Train loss and acc of batch 54: 47.94416809082031, 0.984375\n",
      "Train loss and acc of batch 55: 47.72739791870117, 1.0\n",
      "Train loss and acc of batch 56: 47.727386474609375, 1.0\n",
      "Train loss and acc of batch 57: 48.323081970214844, 0.984375\n",
      "Train loss and acc of batch 58: 47.72737503051758, 1.0\n",
      "Train loss and acc of batch 59: 47.72736740112305, 1.0\n",
      "Train loss and acc of batch 60: 47.72735595703125, 1.0\n",
      "Train loss and acc of batch 61: 47.72734069824219, 1.0\n",
      "Train loss and acc of batch 62: 47.72733688354492, 1.0\n",
      "Train loss and acc of batch 63: 48.918731689453125, 0.96875\n",
      "Train loss and acc of batch 64: 47.94407653808594, 0.984375\n",
      "Train loss and acc of batch 65: 47.7273063659668, 1.0\n",
      "Train loss and acc of batch 66: 47.72730255126953, 1.0\n",
      "Train loss and acc of batch 67: 48.53975296020508, 0.96875\n",
      "Train loss and acc of batch 68: 48.32298278808594, 0.984375\n",
      "Train loss and acc of batch 69: 47.94403839111328, 0.984375\n",
      "Train loss and acc of batch 70: 47.727264404296875, 1.0\n",
      "Training accuracy and loss of epoch #524: 0.9897, 48.0485\n",
      "Saved model by train loss 48.04845772326832\n",
      "Train loss and acc of batch 0: 47.727256774902344, 1.0\n",
      "Train loss and acc of batch 1: 47.72725296020508, 1.0\n",
      "Train loss and acc of batch 2: 47.727237701416016, 1.0\n",
      "Train loss and acc of batch 3: 47.943992614746094, 0.984375\n",
      "Train loss and acc of batch 4: 47.72721862792969, 1.0\n",
      "Train loss and acc of batch 5: 49.076141357421875, 0.96875\n",
      "Train loss and acc of batch 6: 48.229820251464844, 0.96875\n",
      "Train loss and acc of batch 7: 47.72718811035156, 1.0\n",
      "Train loss and acc of batch 8: 48.32288360595703, 0.984375\n",
      "Train loss and acc of batch 9: 48.013031005859375, 0.984375\n",
      "Train loss and acc of batch 10: 47.727169036865234, 1.0\n",
      "Train loss and acc of batch 11: 47.7271614074707, 1.0\n",
      "Train loss and acc of batch 12: 48.48037338256836, 0.984375\n",
      "Train loss and acc of batch 13: 47.94390106201172, 0.984375\n",
      "Train loss and acc of batch 14: 47.94389343261719, 0.984375\n",
      "Train loss and acc of batch 15: 48.32283020019531, 0.984375\n",
      "Train loss and acc of batch 16: 48.32282257080078, 0.984375\n",
      "Train loss and acc of batch 17: 48.48032760620117, 0.984375\n",
      "Train loss and acc of batch 18: 48.6086540222168, 0.96875\n",
      "Train loss and acc of batch 19: 47.72708511352539, 1.0\n",
      "Train loss and acc of batch 20: 47.727081298828125, 1.0\n",
      "Train loss and acc of batch 21: 48.32276916503906, 0.984375\n",
      "Train loss and acc of batch 22: 48.32276153564453, 0.984375\n",
      "Train loss and acc of batch 23: 47.72705078125, 1.0\n",
      "Train loss and acc of batch 24: 48.32273864746094, 0.984375\n",
      "Train loss and acc of batch 25: 47.72703552246094, 1.0\n",
      "Train loss and acc of batch 26: 47.72702407836914, 1.0\n",
      "Train loss and acc of batch 27: 47.727012634277344, 1.0\n",
      "Train loss and acc of batch 28: 47.72700881958008, 1.0\n",
      "Train loss and acc of batch 29: 48.32270050048828, 0.984375\n",
      "Train loss and acc of batch 30: 47.72698974609375, 1.0\n",
      "Train loss and acc of batch 31: 47.94374084472656, 0.984375\n",
      "Train loss and acc of batch 32: 47.72697067260742, 1.0\n",
      "Train loss and acc of batch 33: 47.72696304321289, 1.0\n",
      "Train loss and acc of batch 34: 48.322654724121094, 0.984375\n",
      "Train loss and acc of batch 35: 48.16047286987305, 0.96875\n",
      "Train loss and acc of batch 36: 47.726932525634766, 1.0\n",
      "Train loss and acc of batch 37: 48.48015213012695, 0.984375\n",
      "Train loss and acc of batch 38: 49.075843811035156, 0.96875\n",
      "Train loss and acc of batch 39: 47.94367218017578, 0.984375\n",
      "Train loss and acc of batch 40: 47.726898193359375, 1.0\n",
      "Train loss and acc of batch 41: 49.07581329345703, 0.96875\n",
      "Train loss and acc of batch 42: 47.72687911987305, 1.0\n",
      "Train loss and acc of batch 43: 48.32257843017578, 0.984375\n",
      "Train loss and acc of batch 44: 47.72686767578125, 1.0\n",
      "Train loss and acc of batch 45: 48.32255554199219, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 46: 48.01270294189453, 0.984375\n",
      "Train loss and acc of batch 47: 47.726837158203125, 1.0\n",
      "Train loss and acc of batch 48: 47.726829528808594, 1.0\n",
      "Train loss and acc of batch 49: 47.72682189941406, 1.0\n",
      "Train loss and acc of batch 50: 48.322509765625, 0.984375\n",
      "Train loss and acc of batch 51: 49.07572937011719, 0.96875\n",
      "Train loss and acc of batch 52: 48.98263168334961, 0.953125\n",
      "Train loss and acc of batch 53: 47.72678756713867, 1.0\n",
      "Train loss and acc of batch 54: 47.94354248046875, 0.984375\n",
      "Train loss and acc of batch 55: 47.72676467895508, 1.0\n",
      "Train loss and acc of batch 56: 47.72675704956055, 1.0\n",
      "Train loss and acc of batch 57: 48.32245635986328, 0.984375\n",
      "Train loss and acc of batch 58: 47.72673797607422, 1.0\n",
      "Train loss and acc of batch 59: 47.72673034667969, 1.0\n",
      "Train loss and acc of batch 60: 47.72672653198242, 1.0\n",
      "Train loss and acc of batch 61: 47.72671890258789, 1.0\n",
      "Train loss and acc of batch 62: 47.726707458496094, 1.0\n",
      "Train loss and acc of batch 63: 48.91809844970703, 0.96875\n",
      "Train loss and acc of batch 64: 47.943450927734375, 0.984375\n",
      "Train loss and acc of batch 65: 47.726680755615234, 1.0\n",
      "Train loss and acc of batch 66: 47.72666931152344, 1.0\n",
      "Train loss and acc of batch 67: 48.53913116455078, 0.96875\n",
      "Train loss and acc of batch 68: 48.322357177734375, 0.984375\n",
      "Train loss and acc of batch 69: 47.94340515136719, 0.984375\n",
      "Train loss and acc of batch 70: 47.72663497924805, 1.0\n",
      "Training accuracy and loss of epoch #525: 0.9897, 48.0478\n",
      "Saved model by train loss 48.04782856686015\n",
      "Train loss and acc of batch 0: 47.726627349853516, 1.0\n",
      "Train loss and acc of batch 1: 47.72661590576172, 1.0\n",
      "Train loss and acc of batch 2: 47.72661209106445, 1.0\n",
      "Train loss and acc of batch 3: 47.94336700439453, 0.984375\n",
      "Train loss and acc of batch 4: 47.72658920288086, 1.0\n",
      "Train loss and acc of batch 5: 49.07550811767578, 0.96875\n",
      "Train loss and acc of batch 6: 48.22918701171875, 0.96875\n",
      "Train loss and acc of batch 7: 47.7265625, 1.0\n",
      "Train loss and acc of batch 8: 48.32225799560547, 0.984375\n",
      "Train loss and acc of batch 9: 48.01239776611328, 0.984375\n",
      "Train loss and acc of batch 10: 47.726539611816406, 1.0\n",
      "Train loss and acc of batch 11: 47.726531982421875, 1.0\n",
      "Train loss and acc of batch 12: 48.47974395751953, 0.984375\n",
      "Train loss and acc of batch 13: 47.943275451660156, 0.984375\n",
      "Train loss and acc of batch 14: 47.943267822265625, 0.984375\n",
      "Train loss and acc of batch 15: 48.32218933105469, 0.984375\n",
      "Train loss and acc of batch 16: 48.32218933105469, 0.984375\n",
      "Train loss and acc of batch 17: 48.47970199584961, 0.984375\n",
      "Train loss and acc of batch 18: 48.6080207824707, 0.96875\n",
      "Train loss and acc of batch 19: 47.72645950317383, 1.0\n",
      "Train loss and acc of batch 20: 47.72645568847656, 1.0\n",
      "Train loss and acc of batch 21: 48.32213592529297, 0.984375\n",
      "Train loss and acc of batch 22: 48.32212829589844, 0.984375\n",
      "Train loss and acc of batch 23: 47.72642517089844, 1.0\n",
      "Train loss and acc of batch 24: 48.322113037109375, 0.984375\n",
      "Train loss and acc of batch 25: 47.726409912109375, 1.0\n",
      "Train loss and acc of batch 26: 47.72639846801758, 1.0\n",
      "Train loss and acc of batch 27: 47.72638702392578, 1.0\n",
      "Train loss and acc of batch 28: 47.726375579833984, 1.0\n",
      "Train loss and acc of batch 29: 48.32206726074219, 0.984375\n",
      "Train loss and acc of batch 30: 47.726356506347656, 1.0\n",
      "Train loss and acc of batch 31: 47.943115234375, 0.984375\n",
      "Train loss and acc of batch 32: 47.726341247558594, 1.0\n",
      "Train loss and acc of batch 33: 47.72633361816406, 1.0\n",
      "Train loss and acc of batch 34: 48.32202911376953, 0.984375\n",
      "Train loss and acc of batch 35: 48.15984344482422, 0.96875\n",
      "Train loss and acc of batch 36: 47.7263069152832, 1.0\n",
      "Train loss and acc of batch 37: 48.47952651977539, 0.984375\n",
      "Train loss and acc of batch 38: 49.07521057128906, 0.96875\n",
      "Train loss and acc of batch 39: 47.94304656982422, 0.984375\n",
      "Train loss and acc of batch 40: 47.72626876831055, 1.0\n",
      "Train loss and acc of batch 41: 49.07518768310547, 0.96875\n",
      "Train loss and acc of batch 42: 47.726253509521484, 1.0\n",
      "Train loss and acc of batch 43: 48.32194519042969, 0.984375\n",
      "Train loss and acc of batch 44: 47.726234436035156, 1.0\n",
      "Train loss and acc of batch 45: 48.321929931640625, 0.984375\n",
      "Train loss and acc of batch 46: 48.01206970214844, 0.984375\n",
      "Train loss and acc of batch 47: 47.72621154785156, 1.0\n",
      "Train loss and acc of batch 48: 47.72620391845703, 1.0\n",
      "Train loss and acc of batch 49: 47.7261848449707, 1.0\n",
      "Train loss and acc of batch 50: 48.32188415527344, 0.984375\n",
      "Train loss and acc of batch 51: 49.075103759765625, 0.96875\n",
      "Train loss and acc of batch 52: 48.98200607299805, 0.953125\n",
      "Train loss and acc of batch 53: 47.726158142089844, 1.0\n",
      "Train loss and acc of batch 54: 47.94291687011719, 0.984375\n",
      "Train loss and acc of batch 55: 47.726139068603516, 1.0\n",
      "Train loss and acc of batch 56: 47.726131439208984, 1.0\n",
      "Train loss and acc of batch 57: 48.321815490722656, 0.984375\n",
      "Train loss and acc of batch 58: 47.726112365722656, 1.0\n",
      "Train loss and acc of batch 59: 47.72610092163086, 1.0\n",
      "Train loss and acc of batch 60: 47.72609329223633, 1.0\n",
      "Train loss and acc of batch 61: 47.72608947753906, 1.0\n",
      "Train loss and acc of batch 62: 47.72608184814453, 1.0\n",
      "Train loss and acc of batch 63: 48.91746520996094, 0.96875\n",
      "Train loss and acc of batch 64: 47.94282531738281, 0.984375\n",
      "Train loss and acc of batch 65: 47.726051330566406, 1.0\n",
      "Train loss and acc of batch 66: 47.72603988647461, 1.0\n",
      "Train loss and acc of batch 67: 48.53849792480469, 0.96875\n",
      "Train loss and acc of batch 68: 48.32172393798828, 0.984375\n",
      "Train loss and acc of batch 69: 47.942779541015625, 0.984375\n",
      "Train loss and acc of batch 70: 47.726009368896484, 1.0\n",
      "Training accuracy and loss of epoch #526: 0.9897, 48.0472\n",
      "Saved model by train loss 48.04719951790823\n",
      "Train loss and acc of batch 0: 47.72599792480469, 1.0\n",
      "Train loss and acc of batch 1: 47.72598648071289, 1.0\n",
      "Train loss and acc of batch 2: 47.725975036621094, 1.0\n",
      "Train loss and acc of batch 3: 47.94273376464844, 0.984375\n",
      "Train loss and acc of batch 4: 47.72595977783203, 1.0\n",
      "Train loss and acc of batch 5: 49.07488250732422, 0.96875\n",
      "Train loss and acc of batch 6: 48.22855758666992, 0.96875\n",
      "Train loss and acc of batch 7: 47.72593688964844, 1.0\n",
      "Train loss and acc of batch 8: 48.321624755859375, 0.984375\n",
      "Train loss and acc of batch 9: 48.01177215576172, 0.984375\n",
      "Train loss and acc of batch 10: 47.72590637207031, 1.0\n",
      "Train loss and acc of batch 11: 47.72589874267578, 1.0\n",
      "Train loss and acc of batch 12: 48.4791145324707, 0.984375\n",
      "Train loss and acc of batch 13: 47.942649841308594, 0.984375\n",
      "Train loss and acc of batch 14: 47.94263458251953, 0.984375\n",
      "Train loss and acc of batch 15: 48.321563720703125, 0.984375\n",
      "Train loss and acc of batch 16: 48.321556091308594, 0.984375\n",
      "Train loss and acc of batch 17: 48.479068756103516, 0.984375\n",
      "Train loss and acc of batch 18: 48.607391357421875, 0.96875\n",
      "Train loss and acc of batch 19: 47.725830078125, 1.0\n",
      "Train loss and acc of batch 20: 47.7258186340332, 1.0\n",
      "Train loss and acc of batch 21: 48.321510314941406, 0.984375\n",
      "Train loss and acc of batch 22: 48.321502685546875, 0.984375\n",
      "Train loss and acc of batch 23: 47.725791931152344, 1.0\n",
      "Train loss and acc of batch 24: 48.32148742675781, 0.984375\n",
      "Train loss and acc of batch 25: 47.72577667236328, 1.0\n",
      "Train loss and acc of batch 26: 47.72576904296875, 1.0\n",
      "Train loss and acc of batch 27: 47.72576141357422, 1.0\n",
      "Train loss and acc of batch 28: 47.72574996948242, 1.0\n",
      "Train loss and acc of batch 29: 48.321434020996094, 0.984375\n",
      "Train loss and acc of batch 30: 47.725730895996094, 1.0\n",
      "Train loss and acc of batch 31: 47.942481994628906, 0.984375\n",
      "Train loss and acc of batch 32: 47.72571563720703, 1.0\n",
      "Train loss and acc of batch 33: 47.725704193115234, 1.0\n",
      "Train loss and acc of batch 34: 48.32139587402344, 0.984375\n",
      "Train loss and acc of batch 35: 48.15921401977539, 0.96875\n",
      "Train loss and acc of batch 36: 47.72568130493164, 1.0\n",
      "Train loss and acc of batch 37: 48.47888946533203, 0.984375\n",
      "Train loss and acc of batch 38: 49.0745849609375, 0.96875\n",
      "Train loss and acc of batch 39: 47.942413330078125, 0.984375\n",
      "Train loss and acc of batch 40: 47.725643157958984, 1.0\n",
      "Train loss and acc of batch 41: 49.07455825805664, 0.96875\n",
      "Train loss and acc of batch 42: 47.72562026977539, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 43: 48.321311950683594, 0.984375\n",
      "Train loss and acc of batch 44: 47.72560501098633, 1.0\n",
      "Train loss and acc of batch 45: 48.32129669189453, 0.984375\n",
      "Train loss and acc of batch 46: 48.011444091796875, 0.984375\n",
      "Train loss and acc of batch 47: 47.72557830810547, 1.0\n",
      "Train loss and acc of batch 48: 47.72556686401367, 1.0\n",
      "Train loss and acc of batch 49: 47.725563049316406, 1.0\n",
      "Train loss and acc of batch 50: 48.321258544921875, 0.984375\n",
      "Train loss and acc of batch 51: 49.07447052001953, 0.96875\n",
      "Train loss and acc of batch 52: 48.98137283325195, 0.953125\n",
      "Train loss and acc of batch 53: 47.725528717041016, 1.0\n",
      "Train loss and acc of batch 54: 47.942283630371094, 0.984375\n",
      "Train loss and acc of batch 55: 47.72550964355469, 1.0\n",
      "Train loss and acc of batch 56: 47.72549819946289, 1.0\n",
      "Train loss and acc of batch 57: 48.321197509765625, 0.984375\n",
      "Train loss and acc of batch 58: 47.72547912597656, 1.0\n",
      "Train loss and acc of batch 59: 47.725467681884766, 1.0\n",
      "Train loss and acc of batch 60: 47.7254638671875, 1.0\n",
      "Train loss and acc of batch 61: 47.725460052490234, 1.0\n",
      "Train loss and acc of batch 62: 47.72544479370117, 1.0\n",
      "Train loss and acc of batch 63: 48.91684341430664, 0.96875\n",
      "Train loss and acc of batch 64: 47.94219207763672, 0.984375\n",
      "Train loss and acc of batch 65: 47.72542190551758, 1.0\n",
      "Train loss and acc of batch 66: 47.72541046142578, 1.0\n",
      "Train loss and acc of batch 67: 48.53786849975586, 0.96875\n",
      "Train loss and acc of batch 68: 48.32109069824219, 0.984375\n",
      "Train loss and acc of batch 69: 47.94214630126953, 0.984375\n",
      "Train loss and acc of batch 70: 47.72537612915039, 1.0\n",
      "Training accuracy and loss of epoch #527: 0.9897, 48.0466\n",
      "Saved model by train loss 48.04656939439371\n",
      "Train loss and acc of batch 0: 47.725364685058594, 1.0\n",
      "Train loss and acc of batch 1: 47.72536087036133, 1.0\n",
      "Train loss and acc of batch 2: 47.7253532409668, 1.0\n",
      "Train loss and acc of batch 3: 47.942100524902344, 0.984375\n",
      "Train loss and acc of batch 4: 47.72533416748047, 1.0\n",
      "Train loss and acc of batch 5: 49.074249267578125, 0.96875\n",
      "Train loss and acc of batch 6: 48.22793197631836, 0.96875\n",
      "Train loss and acc of batch 7: 47.72530746459961, 1.0\n",
      "Train loss and acc of batch 8: 48.32099914550781, 0.984375\n",
      "Train loss and acc of batch 9: 48.011146545410156, 0.984375\n",
      "Train loss and acc of batch 10: 47.725276947021484, 1.0\n",
      "Train loss and acc of batch 11: 47.72526931762695, 1.0\n",
      "Train loss and acc of batch 12: 48.478485107421875, 0.984375\n",
      "Train loss and acc of batch 13: 47.9420166015625, 0.984375\n",
      "Train loss and acc of batch 14: 47.94200897216797, 0.984375\n",
      "Train loss and acc of batch 15: 48.32093811035156, 0.984375\n",
      "Train loss and acc of batch 16: 48.32093048095703, 0.984375\n",
      "Train loss and acc of batch 17: 48.47843933105469, 0.984375\n",
      "Train loss and acc of batch 18: 48.60676574707031, 0.96875\n",
      "Train loss and acc of batch 19: 47.72520065307617, 1.0\n",
      "Train loss and acc of batch 20: 47.725189208984375, 1.0\n",
      "Train loss and acc of batch 21: 48.320884704589844, 0.984375\n",
      "Train loss and acc of batch 22: 48.32086944580078, 0.984375\n",
      "Train loss and acc of batch 23: 47.72516632080078, 1.0\n",
      "Train loss and acc of batch 24: 48.32085418701172, 0.984375\n",
      "Train loss and acc of batch 25: 47.72513961791992, 1.0\n",
      "Train loss and acc of batch 26: 47.72513961791992, 1.0\n",
      "Train loss and acc of batch 27: 47.725128173828125, 1.0\n",
      "Train loss and acc of batch 28: 47.725120544433594, 1.0\n",
      "Train loss and acc of batch 29: 48.32081604003906, 0.984375\n",
      "Train loss and acc of batch 30: 47.725101470947266, 1.0\n",
      "Train loss and acc of batch 31: 47.941856384277344, 0.984375\n",
      "Train loss and acc of batch 32: 47.7250862121582, 1.0\n",
      "Train loss and acc of batch 33: 47.725074768066406, 1.0\n",
      "Train loss and acc of batch 34: 48.320762634277344, 0.984375\n",
      "Train loss and acc of batch 35: 48.15858840942383, 0.96875\n",
      "Train loss and acc of batch 36: 47.72504806518555, 1.0\n",
      "Train loss and acc of batch 37: 48.478267669677734, 0.984375\n",
      "Train loss and acc of batch 38: 49.073951721191406, 0.96875\n",
      "Train loss and acc of batch 39: 47.94178009033203, 0.984375\n",
      "Train loss and acc of batch 40: 47.72500991821289, 1.0\n",
      "Train loss and acc of batch 41: 49.07393264770508, 0.96875\n",
      "Train loss and acc of batch 42: 47.72499084472656, 1.0\n",
      "Train loss and acc of batch 43: 48.32068634033203, 0.984375\n",
      "Train loss and acc of batch 44: 47.7249755859375, 1.0\n",
      "Train loss and acc of batch 45: 48.32067108154297, 0.984375\n",
      "Train loss and acc of batch 46: 48.01081085205078, 0.984375\n",
      "Train loss and acc of batch 47: 47.72494888305664, 1.0\n",
      "Train loss and acc of batch 48: 47.72494125366211, 1.0\n",
      "Train loss and acc of batch 49: 47.72493362426758, 1.0\n",
      "Train loss and acc of batch 50: 48.32062530517578, 0.984375\n",
      "Train loss and acc of batch 51: 49.07384490966797, 0.96875\n",
      "Train loss and acc of batch 52: 48.980751037597656, 0.953125\n",
      "Train loss and acc of batch 53: 47.72489929199219, 1.0\n",
      "Train loss and acc of batch 54: 47.941650390625, 0.984375\n",
      "Train loss and acc of batch 55: 47.72488021850586, 1.0\n",
      "Train loss and acc of batch 56: 47.72486877441406, 1.0\n",
      "Train loss and acc of batch 57: 48.32056427001953, 0.984375\n",
      "Train loss and acc of batch 58: 47.724853515625, 1.0\n",
      "Train loss and acc of batch 59: 47.72484588623047, 1.0\n",
      "Train loss and acc of batch 60: 47.72483444213867, 1.0\n",
      "Train loss and acc of batch 61: 47.724822998046875, 1.0\n",
      "Train loss and acc of batch 62: 47.72481918334961, 1.0\n",
      "Train loss and acc of batch 63: 48.91621398925781, 0.96875\n",
      "Train loss and acc of batch 64: 47.941566467285156, 0.984375\n",
      "Train loss and acc of batch 65: 47.72479248046875, 1.0\n",
      "Train loss and acc of batch 66: 47.72478485107422, 1.0\n",
      "Train loss and acc of batch 67: 48.53723907470703, 0.96875\n",
      "Train loss and acc of batch 68: 48.320465087890625, 0.984375\n",
      "Train loss and acc of batch 69: 47.94152069091797, 0.984375\n",
      "Train loss and acc of batch 70: 47.72474670410156, 1.0\n",
      "Training accuracy and loss of epoch #528: 0.9897, 48.0459\n",
      "Saved model by train loss 48.045940775266835\n",
      "Train loss and acc of batch 0: 47.724735260009766, 1.0\n",
      "Train loss and acc of batch 1: 47.724727630615234, 1.0\n",
      "Train loss and acc of batch 2: 47.7247200012207, 1.0\n",
      "Train loss and acc of batch 3: 47.94148254394531, 0.984375\n",
      "Train loss and acc of batch 4: 47.72470474243164, 1.0\n",
      "Train loss and acc of batch 5: 49.07361602783203, 0.96875\n",
      "Train loss and acc of batch 6: 48.22730255126953, 0.96875\n",
      "Train loss and acc of batch 7: 47.724674224853516, 1.0\n",
      "Train loss and acc of batch 8: 48.32036590576172, 0.984375\n",
      "Train loss and acc of batch 9: 48.01051330566406, 0.984375\n",
      "Train loss and acc of batch 10: 47.724647521972656, 1.0\n",
      "Train loss and acc of batch 11: 47.724639892578125, 1.0\n",
      "Train loss and acc of batch 12: 48.47785186767578, 0.984375\n",
      "Train loss and acc of batch 13: 47.941383361816406, 0.984375\n",
      "Train loss and acc of batch 14: 47.941375732421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.32030487060547, 0.984375\n",
      "Train loss and acc of batch 16: 48.32029724121094, 0.984375\n",
      "Train loss and acc of batch 17: 48.47780990600586, 0.984375\n",
      "Train loss and acc of batch 18: 48.60612487792969, 0.96875\n",
      "Train loss and acc of batch 19: 47.72456359863281, 1.0\n",
      "Train loss and acc of batch 20: 47.72455978393555, 1.0\n",
      "Train loss and acc of batch 21: 48.32025146484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.32024383544922, 0.984375\n",
      "Train loss and acc of batch 23: 47.72453308105469, 1.0\n",
      "Train loss and acc of batch 24: 48.320220947265625, 0.984375\n",
      "Train loss and acc of batch 25: 47.72451400756836, 1.0\n",
      "Train loss and acc of batch 26: 47.72450637817383, 1.0\n",
      "Train loss and acc of batch 27: 47.72449493408203, 1.0\n",
      "Train loss and acc of batch 28: 47.7244873046875, 1.0\n",
      "Train loss and acc of batch 29: 48.32017517089844, 0.984375\n",
      "Train loss and acc of batch 30: 47.72446823120117, 1.0\n",
      "Train loss and acc of batch 31: 47.94123077392578, 0.984375\n",
      "Train loss and acc of batch 32: 47.724456787109375, 1.0\n",
      "Train loss and acc of batch 33: 47.72443771362305, 1.0\n",
      "Train loss and acc of batch 34: 48.32013702392578, 0.984375\n",
      "Train loss and acc of batch 35: 48.15795135498047, 0.96875\n",
      "Train loss and acc of batch 36: 47.72441864013672, 1.0\n",
      "Train loss and acc of batch 37: 48.477630615234375, 0.984375\n",
      "Train loss and acc of batch 38: 49.07331848144531, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 39: 47.94115447998047, 0.984375\n",
      "Train loss and acc of batch 40: 47.72438430786133, 1.0\n",
      "Train loss and acc of batch 41: 49.07329559326172, 0.96875\n",
      "Train loss and acc of batch 42: 47.724361419677734, 1.0\n",
      "Train loss and acc of batch 43: 48.32006072998047, 0.984375\n",
      "Train loss and acc of batch 44: 47.72434616088867, 1.0\n",
      "Train loss and acc of batch 45: 48.320037841796875, 0.984375\n",
      "Train loss and acc of batch 46: 48.01017761230469, 0.984375\n",
      "Train loss and acc of batch 47: 47.72431564331055, 1.0\n",
      "Train loss and acc of batch 48: 47.724308013916016, 1.0\n",
      "Train loss and acc of batch 49: 47.72429656982422, 1.0\n",
      "Train loss and acc of batch 50: 48.31999206542969, 0.984375\n",
      "Train loss and acc of batch 51: 49.073204040527344, 0.96875\n",
      "Train loss and acc of batch 52: 48.98011016845703, 0.953125\n",
      "Train loss and acc of batch 53: 47.724266052246094, 1.0\n",
      "Train loss and acc of batch 54: 47.94102478027344, 0.984375\n",
      "Train loss and acc of batch 55: 47.724246978759766, 1.0\n",
      "Train loss and acc of batch 56: 47.72423553466797, 1.0\n",
      "Train loss and acc of batch 57: 48.31993103027344, 0.984375\n",
      "Train loss and acc of batch 58: 47.724220275878906, 1.0\n",
      "Train loss and acc of batch 59: 47.724212646484375, 1.0\n",
      "Train loss and acc of batch 60: 47.724205017089844, 1.0\n",
      "Train loss and acc of batch 61: 47.72419357299805, 1.0\n",
      "Train loss and acc of batch 62: 47.72418212890625, 1.0\n",
      "Train loss and acc of batch 63: 48.91557693481445, 0.96875\n",
      "Train loss and acc of batch 64: 47.94093322753906, 0.984375\n",
      "Train loss and acc of batch 65: 47.724159240722656, 1.0\n",
      "Train loss and acc of batch 66: 47.724143981933594, 1.0\n",
      "Train loss and acc of batch 67: 48.5366096496582, 0.96875\n",
      "Train loss and acc of batch 68: 48.31983947753906, 0.984375\n",
      "Train loss and acc of batch 69: 47.940887451171875, 0.984375\n",
      "Train loss and acc of batch 70: 47.7241096496582, 1.0\n",
      "Training accuracy and loss of epoch #529: 0.9897, 48.0453\n",
      "Saved model by train loss 48.04530844889896\n",
      "Train loss and acc of batch 0: 47.7241096496582, 1.0\n",
      "Train loss and acc of batch 1: 47.72409439086914, 1.0\n",
      "Train loss and acc of batch 2: 47.724090576171875, 1.0\n",
      "Train loss and acc of batch 3: 47.94084167480469, 0.984375\n",
      "Train loss and acc of batch 4: 47.72407150268555, 1.0\n",
      "Train loss and acc of batch 5: 49.07299041748047, 0.96875\n",
      "Train loss and acc of batch 6: 48.226661682128906, 0.96875\n",
      "Train loss and acc of batch 7: 47.72404098510742, 1.0\n",
      "Train loss and acc of batch 8: 48.319732666015625, 0.984375\n",
      "Train loss and acc of batch 9: 48.00987243652344, 0.984375\n",
      "Train loss and acc of batch 10: 47.72401809692383, 1.0\n",
      "Train loss and acc of batch 11: 47.7240104675293, 1.0\n",
      "Train loss and acc of batch 12: 48.47722244262695, 0.984375\n",
      "Train loss and acc of batch 13: 47.94075012207031, 0.984375\n",
      "Train loss and acc of batch 14: 47.94074249267578, 0.984375\n",
      "Train loss and acc of batch 15: 48.319671630859375, 0.984375\n",
      "Train loss and acc of batch 16: 48.319664001464844, 0.984375\n",
      "Train loss and acc of batch 17: 48.4771842956543, 0.984375\n",
      "Train loss and acc of batch 18: 48.605499267578125, 0.96875\n",
      "Train loss and acc of batch 19: 47.72393798828125, 1.0\n",
      "Train loss and acc of batch 20: 47.72392654418945, 1.0\n",
      "Train loss and acc of batch 21: 48.319618225097656, 0.984375\n",
      "Train loss and acc of batch 22: 48.319618225097656, 0.984375\n",
      "Train loss and acc of batch 23: 47.72390365600586, 1.0\n",
      "Train loss and acc of batch 24: 48.31959533691406, 0.984375\n",
      "Train loss and acc of batch 25: 47.72388458251953, 1.0\n",
      "Train loss and acc of batch 26: 47.723876953125, 1.0\n",
      "Train loss and acc of batch 27: 47.7238655090332, 1.0\n",
      "Train loss and acc of batch 28: 47.72385787963867, 1.0\n",
      "Train loss and acc of batch 29: 48.319549560546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.72384262084961, 1.0\n",
      "Train loss and acc of batch 31: 47.94059753417969, 0.984375\n",
      "Train loss and acc of batch 32: 47.723819732666016, 1.0\n",
      "Train loss and acc of batch 33: 47.72381591796875, 1.0\n",
      "Train loss and acc of batch 34: 48.31951141357422, 0.984375\n",
      "Train loss and acc of batch 35: 48.157325744628906, 0.96875\n",
      "Train loss and acc of batch 36: 47.72378921508789, 1.0\n",
      "Train loss and acc of batch 37: 48.47699737548828, 0.984375\n",
      "Train loss and acc of batch 38: 49.07269287109375, 0.96875\n",
      "Train loss and acc of batch 39: 47.940528869628906, 0.984375\n",
      "Train loss and acc of batch 40: 47.72374725341797, 1.0\n",
      "Train loss and acc of batch 41: 49.072669982910156, 0.96875\n",
      "Train loss and acc of batch 42: 47.723731994628906, 1.0\n",
      "Train loss and acc of batch 43: 48.319427490234375, 0.984375\n",
      "Train loss and acc of batch 44: 47.723716735839844, 1.0\n",
      "Train loss and acc of batch 45: 48.31941223144531, 0.984375\n",
      "Train loss and acc of batch 46: 48.009544372558594, 0.984375\n",
      "Train loss and acc of batch 47: 47.723690032958984, 1.0\n",
      "Train loss and acc of batch 48: 47.72368240356445, 1.0\n",
      "Train loss and acc of batch 49: 47.723670959472656, 1.0\n",
      "Train loss and acc of batch 50: 48.319366455078125, 0.984375\n",
      "Train loss and acc of batch 51: 49.07257843017578, 0.96875\n",
      "Train loss and acc of batch 52: 48.97948455810547, 0.953125\n",
      "Train loss and acc of batch 53: 47.72364044189453, 1.0\n",
      "Train loss and acc of batch 54: 47.940391540527344, 0.984375\n",
      "Train loss and acc of batch 55: 47.72361755371094, 1.0\n",
      "Train loss and acc of batch 56: 47.723609924316406, 1.0\n",
      "Train loss and acc of batch 57: 48.319297790527344, 0.984375\n",
      "Train loss and acc of batch 58: 47.72359085083008, 1.0\n",
      "Train loss and acc of batch 59: 47.72357940673828, 1.0\n",
      "Train loss and acc of batch 60: 47.72357177734375, 1.0\n",
      "Train loss and acc of batch 61: 47.72356414794922, 1.0\n",
      "Train loss and acc of batch 62: 47.72356033325195, 1.0\n",
      "Train loss and acc of batch 63: 48.91495132446289, 0.96875\n",
      "Train loss and acc of batch 64: 47.9403076171875, 0.984375\n",
      "Train loss and acc of batch 65: 47.72352981567383, 1.0\n",
      "Train loss and acc of batch 66: 47.7235221862793, 1.0\n",
      "Train loss and acc of batch 67: 48.535980224609375, 0.96875\n",
      "Train loss and acc of batch 68: 48.31920623779297, 0.984375\n",
      "Train loss and acc of batch 69: 47.94025421142578, 0.984375\n",
      "Train loss and acc of batch 70: 47.723487854003906, 1.0\n",
      "Training accuracy and loss of epoch #530: 0.9897, 48.0447\n",
      "Saved model by train loss 48.04467902385013\n",
      "Train loss and acc of batch 0: 47.72347640991211, 1.0\n",
      "Train loss and acc of batch 1: 47.72346878051758, 1.0\n",
      "Train loss and acc of batch 2: 47.72346115112305, 1.0\n",
      "Train loss and acc of batch 3: 47.940208435058594, 0.984375\n",
      "Train loss and acc of batch 4: 47.72343826293945, 1.0\n",
      "Train loss and acc of batch 5: 49.072357177734375, 0.96875\n",
      "Train loss and acc of batch 6: 48.226043701171875, 0.96875\n",
      "Train loss and acc of batch 7: 47.723419189453125, 1.0\n",
      "Train loss and acc of batch 8: 48.31909942626953, 0.984375\n",
      "Train loss and acc of batch 9: 48.009246826171875, 0.984375\n",
      "Train loss and acc of batch 10: 47.723388671875, 1.0\n",
      "Train loss and acc of batch 11: 47.72338104248047, 1.0\n",
      "Train loss and acc of batch 12: 48.47658920288086, 0.984375\n",
      "Train loss and acc of batch 13: 47.94012451171875, 0.984375\n",
      "Train loss and acc of batch 14: 47.94011688232422, 0.984375\n",
      "Train loss and acc of batch 15: 48.31904602050781, 0.984375\n",
      "Train loss and acc of batch 16: 48.31903839111328, 0.984375\n",
      "Train loss and acc of batch 17: 48.47654724121094, 0.984375\n",
      "Train loss and acc of batch 18: 48.6048698425293, 0.96875\n",
      "Train loss and acc of batch 19: 47.72331237792969, 1.0\n",
      "Train loss and acc of batch 20: 47.723297119140625, 1.0\n",
      "Train loss and acc of batch 21: 48.318992614746094, 0.984375\n",
      "Train loss and acc of batch 22: 48.31898498535156, 0.984375\n",
      "Train loss and acc of batch 23: 47.723270416259766, 1.0\n",
      "Train loss and acc of batch 24: 48.31896209716797, 0.984375\n",
      "Train loss and acc of batch 25: 47.7232551574707, 1.0\n",
      "Train loss and acc of batch 26: 47.72324752807617, 1.0\n",
      "Train loss and acc of batch 27: 47.72323989868164, 1.0\n",
      "Train loss and acc of batch 28: 47.723228454589844, 1.0\n",
      "Train loss and acc of batch 29: 48.31892395019531, 0.984375\n",
      "Train loss and acc of batch 30: 47.72321319580078, 1.0\n",
      "Train loss and acc of batch 31: 47.93995666503906, 0.984375\n",
      "Train loss and acc of batch 32: 47.72319412231445, 1.0\n",
      "Train loss and acc of batch 33: 47.723182678222656, 1.0\n",
      "Train loss and acc of batch 34: 48.318878173828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.15669631958008, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 36: 47.72315979003906, 1.0\n",
      "Train loss and acc of batch 37: 48.47636795043945, 0.984375\n",
      "Train loss and acc of batch 38: 49.07206726074219, 0.96875\n",
      "Train loss and acc of batch 39: 47.93989562988281, 0.984375\n",
      "Train loss and acc of batch 40: 47.723121643066406, 1.0\n",
      "Train loss and acc of batch 41: 49.07204055786133, 0.96875\n",
      "Train loss and acc of batch 42: 47.723106384277344, 1.0\n",
      "Train loss and acc of batch 43: 48.31880187988281, 0.984375\n",
      "Train loss and acc of batch 44: 47.72309112548828, 1.0\n",
      "Train loss and acc of batch 45: 48.31877136230469, 0.984375\n",
      "Train loss and acc of batch 46: 48.00891876220703, 0.984375\n",
      "Train loss and acc of batch 47: 47.723060607910156, 1.0\n",
      "Train loss and acc of batch 48: 47.72304916381836, 1.0\n",
      "Train loss and acc of batch 49: 47.72304153442383, 1.0\n",
      "Train loss and acc of batch 50: 48.31873321533203, 0.984375\n",
      "Train loss and acc of batch 51: 49.07195281982422, 0.96875\n",
      "Train loss and acc of batch 52: 48.97885513305664, 0.953125\n",
      "Train loss and acc of batch 53: 47.72300338745117, 1.0\n",
      "Train loss and acc of batch 54: 47.93975830078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.72298812866211, 1.0\n",
      "Train loss and acc of batch 56: 47.72298049926758, 1.0\n",
      "Train loss and acc of batch 57: 48.31867218017578, 0.984375\n",
      "Train loss and acc of batch 58: 47.722965240478516, 1.0\n",
      "Train loss and acc of batch 59: 47.72295379638672, 1.0\n",
      "Train loss and acc of batch 60: 47.72294616699219, 1.0\n",
      "Train loss and acc of batch 61: 47.72293472290039, 1.0\n",
      "Train loss and acc of batch 62: 47.72292709350586, 1.0\n",
      "Train loss and acc of batch 63: 48.91432571411133, 0.96875\n",
      "Train loss and acc of batch 64: 47.939674377441406, 0.984375\n",
      "Train loss and acc of batch 65: 47.722896575927734, 1.0\n",
      "Train loss and acc of batch 66: 47.7228889465332, 1.0\n",
      "Train loss and acc of batch 67: 48.53534698486328, 0.96875\n",
      "Train loss and acc of batch 68: 48.318572998046875, 0.984375\n",
      "Train loss and acc of batch 69: 47.93962860107422, 0.984375\n",
      "Train loss and acc of batch 70: 47.72285461425781, 1.0\n",
      "Training accuracy and loss of epoch #531: 0.9897, 48.0440\n",
      "Saved model by train loss 48.04404943761691\n",
      "Train loss and acc of batch 0: 47.72284698486328, 1.0\n",
      "Train loss and acc of batch 1: 47.722843170166016, 1.0\n",
      "Train loss and acc of batch 2: 47.72283172607422, 1.0\n",
      "Train loss and acc of batch 3: 47.93958282470703, 0.984375\n",
      "Train loss and acc of batch 4: 47.72281265258789, 1.0\n",
      "Train loss and acc of batch 5: 49.07172393798828, 0.96875\n",
      "Train loss and acc of batch 6: 48.22541046142578, 0.96875\n",
      "Train loss and acc of batch 7: 47.722782135009766, 1.0\n",
      "Train loss and acc of batch 8: 48.3184814453125, 0.984375\n",
      "Train loss and acc of batch 9: 48.00862121582031, 0.984375\n",
      "Train loss and acc of batch 10: 47.72275924682617, 1.0\n",
      "Train loss and acc of batch 11: 47.72274398803711, 1.0\n",
      "Train loss and acc of batch 12: 48.47596740722656, 0.984375\n",
      "Train loss and acc of batch 13: 47.93949890136719, 0.984375\n",
      "Train loss and acc of batch 14: 47.939491271972656, 0.984375\n",
      "Train loss and acc of batch 15: 48.31842041015625, 0.984375\n",
      "Train loss and acc of batch 16: 48.31840515136719, 0.984375\n",
      "Train loss and acc of batch 17: 48.47591781616211, 0.984375\n",
      "Train loss and acc of batch 18: 48.60424041748047, 0.96875\n",
      "Train loss and acc of batch 19: 47.722679138183594, 1.0\n",
      "Train loss and acc of batch 20: 47.72267532348633, 1.0\n",
      "Train loss and acc of batch 21: 48.318359375, 0.984375\n",
      "Train loss and acc of batch 22: 48.318359375, 0.984375\n",
      "Train loss and acc of batch 23: 47.7226448059082, 1.0\n",
      "Train loss and acc of batch 24: 48.318336486816406, 0.984375\n",
      "Train loss and acc of batch 25: 47.72262191772461, 1.0\n",
      "Train loss and acc of batch 26: 47.722618103027344, 1.0\n",
      "Train loss and acc of batch 27: 47.72260665893555, 1.0\n",
      "Train loss and acc of batch 28: 47.722599029541016, 1.0\n",
      "Train loss and acc of batch 29: 48.31829071044922, 0.984375\n",
      "Train loss and acc of batch 30: 47.72257995605469, 1.0\n",
      "Train loss and acc of batch 31: 47.93933868408203, 0.984375\n",
      "Train loss and acc of batch 32: 47.72256088256836, 1.0\n",
      "Train loss and acc of batch 33: 47.72255325317383, 1.0\n",
      "Train loss and acc of batch 34: 48.31825256347656, 0.984375\n",
      "Train loss and acc of batch 35: 48.15606689453125, 0.96875\n",
      "Train loss and acc of batch 36: 47.722530364990234, 1.0\n",
      "Train loss and acc of batch 37: 48.47574234008789, 0.984375\n",
      "Train loss and acc of batch 38: 49.071434020996094, 0.96875\n",
      "Train loss and acc of batch 39: 47.93926239013672, 0.984375\n",
      "Train loss and acc of batch 40: 47.72249221801758, 1.0\n",
      "Train loss and acc of batch 41: 49.0714111328125, 0.96875\n",
      "Train loss and acc of batch 42: 47.722476959228516, 1.0\n",
      "Train loss and acc of batch 43: 48.31816864013672, 0.984375\n",
      "Train loss and acc of batch 44: 47.72245407104492, 1.0\n",
      "Train loss and acc of batch 45: 48.318153381347656, 0.984375\n",
      "Train loss and acc of batch 46: 48.00829315185547, 0.984375\n",
      "Train loss and acc of batch 47: 47.72243118286133, 1.0\n",
      "Train loss and acc of batch 48: 47.7224235534668, 1.0\n",
      "Train loss and acc of batch 49: 47.722412109375, 1.0\n",
      "Train loss and acc of batch 50: 48.31810760498047, 0.984375\n",
      "Train loss and acc of batch 51: 49.071327209472656, 0.96875\n",
      "Train loss and acc of batch 52: 48.97822570800781, 0.953125\n",
      "Train loss and acc of batch 53: 47.72237777709961, 1.0\n",
      "Train loss and acc of batch 54: 47.93913269042969, 0.984375\n",
      "Train loss and acc of batch 55: 47.72235870361328, 1.0\n",
      "Train loss and acc of batch 56: 47.722347259521484, 1.0\n",
      "Train loss and acc of batch 57: 48.31804656982422, 0.984375\n",
      "Train loss and acc of batch 58: 47.72233200073242, 1.0\n",
      "Train loss and acc of batch 59: 47.722328186035156, 1.0\n",
      "Train loss and acc of batch 60: 47.722320556640625, 1.0\n",
      "Train loss and acc of batch 61: 47.72230529785156, 1.0\n",
      "Train loss and acc of batch 62: 47.72229766845703, 1.0\n",
      "Train loss and acc of batch 63: 48.9136848449707, 0.96875\n",
      "Train loss and acc of batch 64: 47.93904113769531, 0.984375\n",
      "Train loss and acc of batch 65: 47.72227478027344, 1.0\n",
      "Train loss and acc of batch 66: 47.72226333618164, 1.0\n",
      "Train loss and acc of batch 67: 48.53471755981445, 0.96875\n",
      "Train loss and acc of batch 68: 48.31794738769531, 0.984375\n",
      "Train loss and acc of batch 69: 47.938995361328125, 0.984375\n",
      "Train loss and acc of batch 70: 47.722225189208984, 1.0\n",
      "Training accuracy and loss of epoch #532: 0.9897, 48.0434\n",
      "Saved model by train loss 48.04342065730565\n",
      "Train loss and acc of batch 0: 47.72222137451172, 1.0\n",
      "Train loss and acc of batch 1: 47.72220993041992, 1.0\n",
      "Train loss and acc of batch 2: 47.722198486328125, 1.0\n",
      "Train loss and acc of batch 3: 47.93895721435547, 0.984375\n",
      "Train loss and acc of batch 4: 47.72218322753906, 1.0\n",
      "Train loss and acc of batch 5: 49.07109832763672, 0.96875\n",
      "Train loss and acc of batch 6: 48.22477722167969, 0.96875\n",
      "Train loss and acc of batch 7: 47.7221565246582, 1.0\n",
      "Train loss and acc of batch 8: 48.317848205566406, 0.984375\n",
      "Train loss and acc of batch 9: 48.00798797607422, 0.984375\n",
      "Train loss and acc of batch 10: 47.722129821777344, 1.0\n",
      "Train loss and acc of batch 11: 47.72212219238281, 1.0\n",
      "Train loss and acc of batch 12: 48.4753303527832, 0.984375\n",
      "Train loss and acc of batch 13: 47.938865661621094, 0.984375\n",
      "Train loss and acc of batch 14: 47.93885803222656, 0.984375\n",
      "Train loss and acc of batch 15: 48.317787170410156, 0.984375\n",
      "Train loss and acc of batch 16: 48.317779541015625, 0.984375\n",
      "Train loss and acc of batch 17: 48.47529220581055, 0.984375\n",
      "Train loss and acc of batch 18: 48.60361099243164, 0.96875\n",
      "Train loss and acc of batch 19: 47.722049713134766, 1.0\n",
      "Train loss and acc of batch 20: 47.72203826904297, 1.0\n",
      "Train loss and acc of batch 21: 48.31773376464844, 0.984375\n",
      "Train loss and acc of batch 22: 48.317726135253906, 0.984375\n",
      "Train loss and acc of batch 23: 47.722015380859375, 1.0\n",
      "Train loss and acc of batch 24: 48.31770324707031, 0.984375\n",
      "Train loss and acc of batch 25: 47.72200012207031, 1.0\n",
      "Train loss and acc of batch 26: 47.72198486328125, 1.0\n",
      "Train loss and acc of batch 27: 47.721981048583984, 1.0\n",
      "Train loss and acc of batch 28: 47.72196960449219, 1.0\n",
      "Train loss and acc of batch 29: 48.317657470703125, 0.984375\n",
      "Train loss and acc of batch 30: 47.721954345703125, 1.0\n",
      "Train loss and acc of batch 31: 47.93871307373047, 0.984375\n",
      "Train loss and acc of batch 32: 47.72193145751953, 1.0\n",
      "Train loss and acc of batch 33: 47.721927642822266, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 34: 48.31761932373047, 0.984375\n",
      "Train loss and acc of batch 35: 48.155433654785156, 0.96875\n",
      "Train loss and acc of batch 36: 47.72189712524414, 1.0\n",
      "Train loss and acc of batch 37: 48.47511672973633, 0.984375\n",
      "Train loss and acc of batch 38: 49.07080841064453, 0.96875\n",
      "Train loss and acc of batch 39: 47.938636779785156, 0.984375\n",
      "Train loss and acc of batch 40: 47.72186279296875, 1.0\n",
      "Train loss and acc of batch 41: 49.07078170776367, 0.96875\n",
      "Train loss and acc of batch 42: 47.72184753417969, 1.0\n",
      "Train loss and acc of batch 43: 48.317535400390625, 0.984375\n",
      "Train loss and acc of batch 44: 47.72182846069336, 1.0\n",
      "Train loss and acc of batch 45: 48.31752014160156, 0.984375\n",
      "Train loss and acc of batch 46: 48.007659912109375, 0.984375\n",
      "Train loss and acc of batch 47: 47.721805572509766, 1.0\n",
      "Train loss and acc of batch 48: 47.7217903137207, 1.0\n",
      "Train loss and acc of batch 49: 47.721778869628906, 1.0\n",
      "Train loss and acc of batch 50: 48.317474365234375, 0.984375\n",
      "Train loss and acc of batch 51: 49.07069396972656, 0.96875\n",
      "Train loss and acc of batch 52: 48.977596282958984, 0.953125\n",
      "Train loss and acc of batch 53: 47.72174835205078, 1.0\n",
      "Train loss and acc of batch 54: 47.938507080078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.72173309326172, 1.0\n",
      "Train loss and acc of batch 56: 47.72172546386719, 1.0\n",
      "Train loss and acc of batch 57: 48.317405700683594, 0.984375\n",
      "Train loss and acc of batch 58: 47.72170639038086, 1.0\n",
      "Train loss and acc of batch 59: 47.72169876098633, 1.0\n",
      "Train loss and acc of batch 60: 47.72168731689453, 1.0\n",
      "Train loss and acc of batch 61: 47.7216796875, 1.0\n",
      "Train loss and acc of batch 62: 47.72167205810547, 1.0\n",
      "Train loss and acc of batch 63: 48.91305923461914, 0.96875\n",
      "Train loss and acc of batch 64: 47.93841552734375, 0.984375\n",
      "Train loss and acc of batch 65: 47.721641540527344, 1.0\n",
      "Train loss and acc of batch 66: 47.72163009643555, 1.0\n",
      "Train loss and acc of batch 67: 48.53409194946289, 0.96875\n",
      "Train loss and acc of batch 68: 48.31732177734375, 0.984375\n",
      "Train loss and acc of batch 69: 47.93836975097656, 0.984375\n",
      "Train loss and acc of batch 70: 47.72159957885742, 1.0\n",
      "Training accuracy and loss of epoch #533: 0.9897, 48.0428\n",
      "Saved model by train loss 48.042791285984954\n",
      "Train loss and acc of batch 0: 47.72158432006836, 1.0\n",
      "Train loss and acc of batch 1: 47.721580505371094, 1.0\n",
      "Train loss and acc of batch 2: 47.72157287597656, 1.0\n",
      "Train loss and acc of batch 3: 47.938323974609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.721553802490234, 1.0\n",
      "Train loss and acc of batch 5: 49.070472717285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.224151611328125, 0.96875\n",
      "Train loss and acc of batch 7: 47.721527099609375, 1.0\n",
      "Train loss and acc of batch 8: 48.317222595214844, 0.984375\n",
      "Train loss and acc of batch 9: 48.007362365722656, 0.984375\n",
      "Train loss and acc of batch 10: 47.721500396728516, 1.0\n",
      "Train loss and acc of batch 11: 47.721492767333984, 1.0\n",
      "Train loss and acc of batch 12: 48.47470474243164, 0.984375\n",
      "Train loss and acc of batch 13: 47.93824005126953, 0.984375\n",
      "Train loss and acc of batch 14: 47.938232421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.31715393066406, 0.984375\n",
      "Train loss and acc of batch 16: 48.31714630126953, 0.984375\n",
      "Train loss and acc of batch 17: 48.474666595458984, 0.984375\n",
      "Train loss and acc of batch 18: 48.60298538208008, 0.96875\n",
      "Train loss and acc of batch 19: 47.72142028808594, 1.0\n",
      "Train loss and acc of batch 20: 47.721412658691406, 1.0\n",
      "Train loss and acc of batch 21: 48.317108154296875, 0.984375\n",
      "Train loss and acc of batch 22: 48.317100524902344, 0.984375\n",
      "Train loss and acc of batch 23: 47.72138595581055, 1.0\n",
      "Train loss and acc of batch 24: 48.31707763671875, 0.984375\n",
      "Train loss and acc of batch 25: 47.721370697021484, 1.0\n",
      "Train loss and acc of batch 26: 47.72135925292969, 1.0\n",
      "Train loss and acc of batch 27: 47.721351623535156, 1.0\n",
      "Train loss and acc of batch 28: 47.72134017944336, 1.0\n",
      "Train loss and acc of batch 29: 48.31703186035156, 0.984375\n",
      "Train loss and acc of batch 30: 47.7213249206543, 1.0\n",
      "Train loss and acc of batch 31: 47.938072204589844, 0.984375\n",
      "Train loss and acc of batch 32: 47.721309661865234, 1.0\n",
      "Train loss and acc of batch 33: 47.72129821777344, 1.0\n",
      "Train loss and acc of batch 34: 48.316986083984375, 0.984375\n",
      "Train loss and acc of batch 35: 48.15481185913086, 0.96875\n",
      "Train loss and acc of batch 36: 47.72127151489258, 1.0\n",
      "Train loss and acc of batch 37: 48.474483489990234, 0.984375\n",
      "Train loss and acc of batch 38: 49.07018280029297, 0.96875\n",
      "Train loss and acc of batch 39: 47.93800354003906, 0.984375\n",
      "Train loss and acc of batch 40: 47.72123718261719, 1.0\n",
      "Train loss and acc of batch 41: 49.07015609741211, 0.96875\n",
      "Train loss and acc of batch 42: 47.721221923828125, 1.0\n",
      "Train loss and acc of batch 43: 48.31690979003906, 0.984375\n",
      "Train loss and acc of batch 44: 47.72119903564453, 1.0\n",
      "Train loss and acc of batch 45: 48.31689453125, 0.984375\n",
      "Train loss and acc of batch 46: 48.00703430175781, 0.984375\n",
      "Train loss and acc of batch 47: 47.72117233276367, 1.0\n",
      "Train loss and acc of batch 48: 47.721160888671875, 1.0\n",
      "Train loss and acc of batch 49: 47.72115707397461, 1.0\n",
      "Train loss and acc of batch 50: 48.31684875488281, 0.984375\n",
      "Train loss and acc of batch 51: 49.07006072998047, 0.96875\n",
      "Train loss and acc of batch 52: 48.97697067260742, 0.953125\n",
      "Train loss and acc of batch 53: 47.72111892700195, 1.0\n",
      "Train loss and acc of batch 54: 47.93787384033203, 0.984375\n",
      "Train loss and acc of batch 55: 47.721107482910156, 1.0\n",
      "Train loss and acc of batch 56: 47.721092224121094, 1.0\n",
      "Train loss and acc of batch 57: 48.31678771972656, 0.984375\n",
      "Train loss and acc of batch 58: 47.72107696533203, 1.0\n",
      "Train loss and acc of batch 59: 47.7210693359375, 1.0\n",
      "Train loss and acc of batch 60: 47.7210578918457, 1.0\n",
      "Train loss and acc of batch 61: 47.72105026245117, 1.0\n",
      "Train loss and acc of batch 62: 47.72103500366211, 1.0\n",
      "Train loss and acc of batch 63: 48.912437438964844, 0.96875\n",
      "Train loss and acc of batch 64: 47.93778991699219, 0.984375\n",
      "Train loss and acc of batch 65: 47.721012115478516, 1.0\n",
      "Train loss and acc of batch 66: 47.721004486083984, 1.0\n",
      "Train loss and acc of batch 67: 48.53346633911133, 0.96875\n",
      "Train loss and acc of batch 68: 48.316688537597656, 0.984375\n",
      "Train loss and acc of batch 69: 47.937744140625, 0.984375\n",
      "Train loss and acc of batch 70: 47.72097396850586, 1.0\n",
      "Training accuracy and loss of epoch #534: 0.9897, 48.0422\n",
      "Saved model by train loss 48.042163204139385\n",
      "Train loss and acc of batch 0: 47.7209587097168, 1.0\n",
      "Train loss and acc of batch 1: 47.72095489501953, 1.0\n",
      "Train loss and acc of batch 2: 47.720943450927734, 1.0\n",
      "Train loss and acc of batch 3: 47.93769836425781, 0.984375\n",
      "Train loss and acc of batch 4: 47.72092819213867, 1.0\n",
      "Train loss and acc of batch 5: 49.06983947753906, 0.96875\n",
      "Train loss and acc of batch 6: 48.22352600097656, 0.96875\n",
      "Train loss and acc of batch 7: 47.72090148925781, 1.0\n",
      "Train loss and acc of batch 8: 48.31658935546875, 0.984375\n",
      "Train loss and acc of batch 9: 48.00672912597656, 0.984375\n",
      "Train loss and acc of batch 10: 47.72087478637695, 1.0\n",
      "Train loss and acc of batch 11: 47.72085952758789, 1.0\n",
      "Train loss and acc of batch 12: 48.474082946777344, 0.984375\n",
      "Train loss and acc of batch 13: 47.93761444091797, 0.984375\n",
      "Train loss and acc of batch 14: 47.937599182128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.31653594970703, 0.984375\n",
      "Train loss and acc of batch 16: 48.31652069091797, 0.984375\n",
      "Train loss and acc of batch 17: 48.47403335571289, 0.984375\n",
      "Train loss and acc of batch 18: 48.60235595703125, 0.96875\n",
      "Train loss and acc of batch 19: 47.72079086303711, 1.0\n",
      "Train loss and acc of batch 20: 47.72078323364258, 1.0\n",
      "Train loss and acc of batch 21: 48.31647491455078, 0.984375\n",
      "Train loss and acc of batch 22: 48.31646728515625, 0.984375\n",
      "Train loss and acc of batch 23: 47.72075653076172, 1.0\n",
      "Train loss and acc of batch 24: 48.31645202636719, 0.984375\n",
      "Train loss and acc of batch 25: 47.72073745727539, 1.0\n",
      "Train loss and acc of batch 26: 47.720733642578125, 1.0\n",
      "Train loss and acc of batch 27: 47.72072219848633, 1.0\n",
      "Train loss and acc of batch 28: 47.72071075439453, 1.0\n",
      "Train loss and acc of batch 29: 48.31640625, 0.984375\n",
      "Train loss and acc of batch 30: 47.72069549560547, 1.0\n",
      "Train loss and acc of batch 31: 47.93744659423828, 0.984375\n",
      "Train loss and acc of batch 32: 47.72067642211914, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.72066879272461, 1.0\n",
      "Train loss and acc of batch 34: 48.31636047363281, 0.984375\n",
      "Train loss and acc of batch 35: 48.15418243408203, 0.96875\n",
      "Train loss and acc of batch 36: 47.720645904541016, 1.0\n",
      "Train loss and acc of batch 37: 48.47385787963867, 0.984375\n",
      "Train loss and acc of batch 38: 49.069549560546875, 0.96875\n",
      "Train loss and acc of batch 39: 47.9373779296875, 0.984375\n",
      "Train loss and acc of batch 40: 47.72060775756836, 1.0\n",
      "Train loss and acc of batch 41: 49.06952667236328, 0.96875\n",
      "Train loss and acc of batch 42: 47.720584869384766, 1.0\n",
      "Train loss and acc of batch 43: 48.3162841796875, 0.984375\n",
      "Train loss and acc of batch 44: 47.7205696105957, 1.0\n",
      "Train loss and acc of batch 45: 48.316261291503906, 0.984375\n",
      "Train loss and acc of batch 46: 48.00640869140625, 0.984375\n",
      "Train loss and acc of batch 47: 47.720542907714844, 1.0\n",
      "Train loss and acc of batch 48: 47.72053146362305, 1.0\n",
      "Train loss and acc of batch 49: 47.72053146362305, 1.0\n",
      "Train loss and acc of batch 50: 48.31622314453125, 0.984375\n",
      "Train loss and acc of batch 51: 49.069435119628906, 0.96875\n",
      "Train loss and acc of batch 52: 48.97633743286133, 0.953125\n",
      "Train loss and acc of batch 53: 47.720489501953125, 1.0\n",
      "Train loss and acc of batch 54: 47.93724822998047, 0.984375\n",
      "Train loss and acc of batch 55: 47.72047424316406, 1.0\n",
      "Train loss and acc of batch 56: 47.720462799072266, 1.0\n",
      "Train loss and acc of batch 57: 48.316162109375, 0.984375\n",
      "Train loss and acc of batch 58: 47.7204475402832, 1.0\n",
      "Train loss and acc of batch 59: 47.72043228149414, 1.0\n",
      "Train loss and acc of batch 60: 47.720428466796875, 1.0\n",
      "Train loss and acc of batch 61: 47.72041702270508, 1.0\n",
      "Train loss and acc of batch 62: 47.72040939331055, 1.0\n",
      "Train loss and acc of batch 63: 48.911808013916016, 0.96875\n",
      "Train loss and acc of batch 64: 47.937156677246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.72038269042969, 1.0\n",
      "Train loss and acc of batch 66: 47.720375061035156, 1.0\n",
      "Train loss and acc of batch 67: 48.53282928466797, 0.96875\n",
      "Train loss and acc of batch 68: 48.316062927246094, 0.984375\n",
      "Train loss and acc of batch 69: 47.937110900878906, 0.984375\n",
      "Train loss and acc of batch 70: 47.7203369140625, 1.0\n",
      "Training accuracy and loss of epoch #535: 0.9897, 48.0415\n",
      "Saved model by train loss 48.04153410145934\n",
      "Train loss and acc of batch 0: 47.720333099365234, 1.0\n",
      "Train loss and acc of batch 1: 47.7203254699707, 1.0\n",
      "Train loss and acc of batch 2: 47.720314025878906, 1.0\n",
      "Train loss and acc of batch 3: 47.93707275390625, 0.984375\n",
      "Train loss and acc of batch 4: 47.720298767089844, 1.0\n",
      "Train loss and acc of batch 5: 49.0692138671875, 0.96875\n",
      "Train loss and acc of batch 6: 48.222896575927734, 0.96875\n",
      "Train loss and acc of batch 7: 47.720272064208984, 1.0\n",
      "Train loss and acc of batch 8: 48.315956115722656, 0.984375\n",
      "Train loss and acc of batch 9: 48.00611114501953, 0.984375\n",
      "Train loss and acc of batch 10: 47.720237731933594, 1.0\n",
      "Train loss and acc of batch 11: 47.72023391723633, 1.0\n",
      "Train loss and acc of batch 12: 48.473453521728516, 0.984375\n",
      "Train loss and acc of batch 13: 47.936973571777344, 0.984375\n",
      "Train loss and acc of batch 14: 47.936973571777344, 0.984375\n",
      "Train loss and acc of batch 15: 48.31590270996094, 0.984375\n",
      "Train loss and acc of batch 16: 48.315887451171875, 0.984375\n",
      "Train loss and acc of batch 17: 48.47340774536133, 0.984375\n",
      "Train loss and acc of batch 18: 48.601722717285156, 0.96875\n",
      "Train loss and acc of batch 19: 47.72016143798828, 1.0\n",
      "Train loss and acc of batch 20: 47.720157623291016, 1.0\n",
      "Train loss and acc of batch 21: 48.31584930419922, 0.984375\n",
      "Train loss and acc of batch 22: 48.315834045410156, 0.984375\n",
      "Train loss and acc of batch 23: 47.720130920410156, 1.0\n",
      "Train loss and acc of batch 24: 48.315818786621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.72010803222656, 1.0\n",
      "Train loss and acc of batch 26: 47.72010040283203, 1.0\n",
      "Train loss and acc of batch 27: 47.720088958740234, 1.0\n",
      "Train loss and acc of batch 28: 47.7200813293457, 1.0\n",
      "Train loss and acc of batch 29: 48.31578063964844, 0.984375\n",
      "Train loss and acc of batch 30: 47.72006607055664, 1.0\n",
      "Train loss and acc of batch 31: 47.93682098388672, 0.984375\n",
      "Train loss and acc of batch 32: 47.72004699707031, 1.0\n",
      "Train loss and acc of batch 33: 47.720035552978516, 1.0\n",
      "Train loss and acc of batch 34: 48.31573486328125, 0.984375\n",
      "Train loss and acc of batch 35: 48.15354919433594, 0.96875\n",
      "Train loss and acc of batch 36: 47.72001266479492, 1.0\n",
      "Train loss and acc of batch 37: 48.47323226928711, 0.984375\n",
      "Train loss and acc of batch 38: 49.06892395019531, 0.96875\n",
      "Train loss and acc of batch 39: 47.93675231933594, 0.984375\n",
      "Train loss and acc of batch 40: 47.71997833251953, 1.0\n",
      "Train loss and acc of batch 41: 49.06889343261719, 0.96875\n",
      "Train loss and acc of batch 42: 47.7199592590332, 1.0\n",
      "Train loss and acc of batch 43: 48.315650939941406, 0.984375\n",
      "Train loss and acc of batch 44: 47.71994400024414, 1.0\n",
      "Train loss and acc of batch 45: 48.315635681152344, 0.984375\n",
      "Train loss and acc of batch 46: 48.005775451660156, 0.984375\n",
      "Train loss and acc of batch 47: 47.71990966796875, 1.0\n",
      "Train loss and acc of batch 48: 47.71990966796875, 1.0\n",
      "Train loss and acc of batch 49: 47.71989440917969, 1.0\n",
      "Train loss and acc of batch 50: 48.315589904785156, 0.984375\n",
      "Train loss and acc of batch 51: 49.068809509277344, 0.96875\n",
      "Train loss and acc of batch 52: 48.975711822509766, 0.953125\n",
      "Train loss and acc of batch 53: 47.71986389160156, 1.0\n",
      "Train loss and acc of batch 54: 47.936622619628906, 0.984375\n",
      "Train loss and acc of batch 55: 47.71984100341797, 1.0\n",
      "Train loss and acc of batch 56: 47.7198371887207, 1.0\n",
      "Train loss and acc of batch 57: 48.315528869628906, 0.984375\n",
      "Train loss and acc of batch 58: 47.719818115234375, 1.0\n",
      "Train loss and acc of batch 59: 47.719810485839844, 1.0\n",
      "Train loss and acc of batch 60: 47.71980285644531, 1.0\n",
      "Train loss and acc of batch 61: 47.71978759765625, 1.0\n",
      "Train loss and acc of batch 62: 47.719783782958984, 1.0\n",
      "Train loss and acc of batch 63: 48.91117477416992, 0.96875\n",
      "Train loss and acc of batch 64: 47.9365234375, 0.984375\n",
      "Train loss and acc of batch 65: 47.719757080078125, 1.0\n",
      "Train loss and acc of batch 66: 47.71974563598633, 1.0\n",
      "Train loss and acc of batch 67: 48.532203674316406, 0.96875\n",
      "Train loss and acc of batch 68: 48.31543731689453, 0.984375\n",
      "Train loss and acc of batch 69: 47.936485290527344, 0.984375\n",
      "Train loss and acc of batch 70: 47.71971130371094, 1.0\n",
      "Training accuracy and loss of epoch #536: 0.9897, 48.0409\n",
      "Saved model by train loss 48.04090521369182\n",
      "Train loss and acc of batch 0: 47.719703674316406, 1.0\n",
      "Train loss and acc of batch 1: 47.719696044921875, 1.0\n",
      "Train loss and acc of batch 2: 47.71968460083008, 1.0\n",
      "Train loss and acc of batch 3: 47.93644714355469, 0.984375\n",
      "Train loss and acc of batch 4: 47.71966552734375, 1.0\n",
      "Train loss and acc of batch 5: 49.068580627441406, 0.96875\n",
      "Train loss and acc of batch 6: 48.222267150878906, 0.96875\n",
      "Train loss and acc of batch 7: 47.71963882446289, 1.0\n",
      "Train loss and acc of batch 8: 48.315338134765625, 0.984375\n",
      "Train loss and acc of batch 9: 48.00547790527344, 0.984375\n",
      "Train loss and acc of batch 10: 47.7196159362793, 1.0\n",
      "Train loss and acc of batch 11: 47.719608306884766, 1.0\n",
      "Train loss and acc of batch 12: 48.472816467285156, 0.984375\n",
      "Train loss and acc of batch 13: 47.93634796142578, 0.984375\n",
      "Train loss and acc of batch 14: 47.93634796142578, 0.984375\n",
      "Train loss and acc of batch 15: 48.315269470214844, 0.984375\n",
      "Train loss and acc of batch 16: 48.31526184082031, 0.984375\n",
      "Train loss and acc of batch 17: 48.472774505615234, 0.984375\n",
      "Train loss and acc of batch 18: 48.60110092163086, 0.96875\n",
      "Train loss and acc of batch 19: 47.71953201293945, 1.0\n",
      "Train loss and acc of batch 20: 47.719520568847656, 1.0\n",
      "Train loss and acc of batch 21: 48.315216064453125, 0.984375\n",
      "Train loss and acc of batch 22: 48.315208435058594, 0.984375\n",
      "Train loss and acc of batch 23: 47.71949768066406, 1.0\n",
      "Train loss and acc of batch 24: 48.31519317626953, 0.984375\n",
      "Train loss and acc of batch 25: 47.719482421875, 1.0\n",
      "Train loss and acc of batch 26: 47.7194709777832, 1.0\n",
      "Train loss and acc of batch 27: 47.719459533691406, 1.0\n",
      "Train loss and acc of batch 28: 47.719459533691406, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 29: 48.315147399902344, 0.984375\n",
      "Train loss and acc of batch 30: 47.71943664550781, 1.0\n",
      "Train loss and acc of batch 31: 47.936195373535156, 0.984375\n",
      "Train loss and acc of batch 32: 47.71942138671875, 1.0\n",
      "Train loss and acc of batch 33: 47.71940994262695, 1.0\n",
      "Train loss and acc of batch 34: 48.315093994140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.15291976928711, 0.96875\n",
      "Train loss and acc of batch 36: 47.719383239746094, 1.0\n",
      "Train loss and acc of batch 37: 48.472599029541016, 0.984375\n",
      "Train loss and acc of batch 38: 49.06829071044922, 0.96875\n",
      "Train loss and acc of batch 39: 47.936119079589844, 0.984375\n",
      "Train loss and acc of batch 40: 47.7193489074707, 1.0\n",
      "Train loss and acc of batch 41: 49.06826400756836, 0.96875\n",
      "Train loss and acc of batch 42: 47.719329833984375, 1.0\n",
      "Train loss and acc of batch 43: 48.315025329589844, 0.984375\n",
      "Train loss and acc of batch 44: 47.71931076049805, 1.0\n",
      "Train loss and acc of batch 45: 48.31501007080078, 0.984375\n",
      "Train loss and acc of batch 46: 48.005149841308594, 0.984375\n",
      "Train loss and acc of batch 47: 47.71928787231445, 1.0\n",
      "Train loss and acc of batch 48: 47.719276428222656, 1.0\n",
      "Train loss and acc of batch 49: 47.71926498413086, 1.0\n",
      "Train loss and acc of batch 50: 48.31495666503906, 0.984375\n",
      "Train loss and acc of batch 51: 49.06817626953125, 0.96875\n",
      "Train loss and acc of batch 52: 48.97508239746094, 0.953125\n",
      "Train loss and acc of batch 53: 47.719234466552734, 1.0\n",
      "Train loss and acc of batch 54: 47.93598937988281, 0.984375\n",
      "Train loss and acc of batch 55: 47.719215393066406, 1.0\n",
      "Train loss and acc of batch 56: 47.719207763671875, 1.0\n",
      "Train loss and acc of batch 57: 48.314903259277344, 0.984375\n",
      "Train loss and acc of batch 58: 47.71918487548828, 1.0\n",
      "Train loss and acc of batch 59: 47.719181060791016, 1.0\n",
      "Train loss and acc of batch 60: 47.71916961669922, 1.0\n",
      "Train loss and acc of batch 61: 47.71916198730469, 1.0\n",
      "Train loss and acc of batch 62: 47.719154357910156, 1.0\n",
      "Train loss and acc of batch 63: 48.910545349121094, 0.96875\n",
      "Train loss and acc of batch 64: 47.93589782714844, 0.984375\n",
      "Train loss and acc of batch 65: 47.7191276550293, 1.0\n",
      "Train loss and acc of batch 66: 47.7191162109375, 1.0\n",
      "Train loss and acc of batch 67: 48.53157424926758, 0.96875\n",
      "Train loss and acc of batch 68: 48.314796447753906, 0.984375\n",
      "Train loss and acc of batch 69: 47.93585205078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.71908187866211, 1.0\n",
      "Training accuracy and loss of epoch #537: 0.9897, 48.0403\n",
      "Saved model by train loss 48.04027573491486\n",
      "Train loss and acc of batch 0: 47.71907424926758, 1.0\n",
      "Train loss and acc of batch 1: 47.71906280517578, 1.0\n",
      "Train loss and acc of batch 2: 47.719058990478516, 1.0\n",
      "Train loss and acc of batch 3: 47.935813903808594, 0.984375\n",
      "Train loss and acc of batch 4: 47.71903991699219, 1.0\n",
      "Train loss and acc of batch 5: 49.067955017089844, 0.96875\n",
      "Train loss and acc of batch 6: 48.22163772583008, 0.96875\n",
      "Train loss and acc of batch 7: 47.71900939941406, 1.0\n",
      "Train loss and acc of batch 8: 48.31470489501953, 0.984375\n",
      "Train loss and acc of batch 9: 48.004844665527344, 0.984375\n",
      "Train loss and acc of batch 10: 47.718990325927734, 1.0\n",
      "Train loss and acc of batch 11: 47.71897506713867, 1.0\n",
      "Train loss and acc of batch 12: 48.47218704223633, 0.984375\n",
      "Train loss and acc of batch 13: 47.93572235107422, 0.984375\n",
      "Train loss and acc of batch 14: 47.935707092285156, 0.984375\n",
      "Train loss and acc of batch 15: 48.31463623046875, 0.984375\n",
      "Train loss and acc of batch 16: 48.31462860107422, 0.984375\n",
      "Train loss and acc of batch 17: 48.472145080566406, 0.984375\n",
      "Train loss and acc of batch 18: 48.600467681884766, 0.96875\n",
      "Train loss and acc of batch 19: 47.718910217285156, 1.0\n",
      "Train loss and acc of batch 20: 47.718894958496094, 1.0\n",
      "Train loss and acc of batch 21: 48.31459045410156, 0.984375\n",
      "Train loss and acc of batch 22: 48.31458282470703, 0.984375\n",
      "Train loss and acc of batch 23: 47.7188720703125, 1.0\n",
      "Train loss and acc of batch 24: 48.31456756591797, 0.984375\n",
      "Train loss and acc of batch 25: 47.718849182128906, 1.0\n",
      "Train loss and acc of batch 26: 47.718841552734375, 1.0\n",
      "Train loss and acc of batch 27: 47.71883773803711, 1.0\n",
      "Train loss and acc of batch 28: 47.71882629394531, 1.0\n",
      "Train loss and acc of batch 29: 48.31451416015625, 0.984375\n",
      "Train loss and acc of batch 30: 47.718807220458984, 1.0\n",
      "Train loss and acc of batch 31: 47.93556213378906, 0.984375\n",
      "Train loss and acc of batch 32: 47.718788146972656, 1.0\n",
      "Train loss and acc of batch 33: 47.71878433227539, 1.0\n",
      "Train loss and acc of batch 34: 48.31446838378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.15229415893555, 0.96875\n",
      "Train loss and acc of batch 36: 47.718753814697266, 1.0\n",
      "Train loss and acc of batch 37: 48.47196960449219, 0.984375\n",
      "Train loss and acc of batch 38: 49.067665100097656, 0.96875\n",
      "Train loss and acc of batch 39: 47.93549346923828, 0.984375\n",
      "Train loss and acc of batch 40: 47.71871566772461, 1.0\n",
      "Train loss and acc of batch 41: 49.0676383972168, 0.96875\n",
      "Train loss and acc of batch 42: 47.71870040893555, 1.0\n",
      "Train loss and acc of batch 43: 48.31439208984375, 0.984375\n",
      "Train loss and acc of batch 44: 47.71868133544922, 1.0\n",
      "Train loss and acc of batch 45: 48.31437683105469, 0.984375\n",
      "Train loss and acc of batch 46: 48.0045166015625, 0.984375\n",
      "Train loss and acc of batch 47: 47.71866226196289, 1.0\n",
      "Train loss and acc of batch 48: 47.71864700317383, 1.0\n",
      "Train loss and acc of batch 49: 47.7186393737793, 1.0\n",
      "Train loss and acc of batch 50: 48.3143310546875, 0.984375\n",
      "Train loss and acc of batch 51: 49.067543029785156, 0.96875\n",
      "Train loss and acc of batch 52: 48.97445297241211, 0.953125\n",
      "Train loss and acc of batch 53: 47.718605041503906, 1.0\n",
      "Train loss and acc of batch 54: 47.93536376953125, 0.984375\n",
      "Train loss and acc of batch 55: 47.718589782714844, 1.0\n",
      "Train loss and acc of batch 56: 47.71857833862305, 1.0\n",
      "Train loss and acc of batch 57: 48.31426239013672, 0.984375\n",
      "Train loss and acc of batch 58: 47.71855926513672, 1.0\n",
      "Train loss and acc of batch 59: 47.71854782104492, 1.0\n",
      "Train loss and acc of batch 60: 47.718544006347656, 1.0\n",
      "Train loss and acc of batch 61: 47.718528747558594, 1.0\n",
      "Train loss and acc of batch 62: 47.71852111816406, 1.0\n",
      "Train loss and acc of batch 63: 48.909915924072266, 0.96875\n",
      "Train loss and acc of batch 64: 47.935272216796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.7184944152832, 1.0\n",
      "Train loss and acc of batch 66: 47.71849060058594, 1.0\n",
      "Train loss and acc of batch 67: 48.53094482421875, 0.96875\n",
      "Train loss and acc of batch 68: 48.314170837402344, 0.984375\n",
      "Train loss and acc of batch 69: 47.93522644042969, 0.984375\n",
      "Train loss and acc of batch 70: 47.71845626831055, 1.0\n",
      "Training accuracy and loss of epoch #538: 0.9897, 48.0396\n",
      "Saved model by train loss 48.039646524778554\n",
      "Train loss and acc of batch 0: 47.71844482421875, 1.0\n",
      "Train loss and acc of batch 1: 47.71843719482422, 1.0\n",
      "Train loss and acc of batch 2: 47.71842575073242, 1.0\n",
      "Train loss and acc of batch 3: 47.9351806640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.71841049194336, 1.0\n",
      "Train loss and acc of batch 5: 49.06732177734375, 0.96875\n",
      "Train loss and acc of batch 6: 48.22100830078125, 0.96875\n",
      "Train loss and acc of batch 7: 47.7183837890625, 1.0\n",
      "Train loss and acc of batch 8: 48.31407165527344, 0.984375\n",
      "Train loss and acc of batch 9: 48.00421905517578, 0.984375\n",
      "Train loss and acc of batch 10: 47.718353271484375, 1.0\n",
      "Train loss and acc of batch 11: 47.718345642089844, 1.0\n",
      "Train loss and acc of batch 12: 48.471561431884766, 0.984375\n",
      "Train loss and acc of batch 13: 47.935096740722656, 0.984375\n",
      "Train loss and acc of batch 14: 47.935081481933594, 0.984375\n",
      "Train loss and acc of batch 15: 48.31401824951172, 0.984375\n",
      "Train loss and acc of batch 16: 48.314002990722656, 0.984375\n",
      "Train loss and acc of batch 17: 48.471519470214844, 0.984375\n",
      "Train loss and acc of batch 18: 48.59983825683594, 0.96875\n",
      "Train loss and acc of batch 19: 47.71827697753906, 1.0\n",
      "Train loss and acc of batch 20: 47.71826934814453, 1.0\n",
      "Train loss and acc of batch 21: 48.31395721435547, 0.984375\n",
      "Train loss and acc of batch 22: 48.31394958496094, 0.984375\n",
      "Train loss and acc of batch 23: 47.718238830566406, 1.0\n",
      "Train loss and acc of batch 24: 48.313934326171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.71821975708008, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 26: 47.71821594238281, 1.0\n",
      "Train loss and acc of batch 27: 47.71820831298828, 1.0\n",
      "Train loss and acc of batch 28: 47.718196868896484, 1.0\n",
      "Train loss and acc of batch 29: 48.31388854980469, 0.984375\n",
      "Train loss and acc of batch 30: 47.71818161010742, 1.0\n",
      "Train loss and acc of batch 31: 47.9349365234375, 0.984375\n",
      "Train loss and acc of batch 32: 47.718162536621094, 1.0\n",
      "Train loss and acc of batch 33: 47.71815490722656, 1.0\n",
      "Train loss and acc of batch 34: 48.3138427734375, 0.984375\n",
      "Train loss and acc of batch 35: 48.151668548583984, 0.96875\n",
      "Train loss and acc of batch 36: 47.7181282043457, 1.0\n",
      "Train loss and acc of batch 37: 48.471336364746094, 0.984375\n",
      "Train loss and acc of batch 38: 49.06703186035156, 0.96875\n",
      "Train loss and acc of batch 39: 47.93486022949219, 0.984375\n",
      "Train loss and acc of batch 40: 47.71809005737305, 1.0\n",
      "Train loss and acc of batch 41: 49.06700897216797, 0.96875\n",
      "Train loss and acc of batch 42: 47.71807098388672, 1.0\n",
      "Train loss and acc of batch 43: 48.31376647949219, 0.984375\n",
      "Train loss and acc of batch 44: 47.71805953979492, 1.0\n",
      "Train loss and acc of batch 45: 48.313743591308594, 0.984375\n",
      "Train loss and acc of batch 46: 48.00389099121094, 0.984375\n",
      "Train loss and acc of batch 47: 47.71802520751953, 1.0\n",
      "Train loss and acc of batch 48: 47.718017578125, 1.0\n",
      "Train loss and acc of batch 49: 47.71800994873047, 1.0\n",
      "Train loss and acc of batch 50: 48.313697814941406, 0.984375\n",
      "Train loss and acc of batch 51: 49.066917419433594, 0.96875\n",
      "Train loss and acc of batch 52: 48.973819732666016, 0.953125\n",
      "Train loss and acc of batch 53: 47.71797180175781, 1.0\n",
      "Train loss and acc of batch 54: 47.934730529785156, 0.984375\n",
      "Train loss and acc of batch 55: 47.71795654296875, 1.0\n",
      "Train loss and acc of batch 56: 47.71794509887695, 1.0\n",
      "Train loss and acc of batch 57: 48.31364440917969, 0.984375\n",
      "Train loss and acc of batch 58: 47.717933654785156, 1.0\n",
      "Train loss and acc of batch 59: 47.71792221069336, 1.0\n",
      "Train loss and acc of batch 60: 47.71791076660156, 1.0\n",
      "Train loss and acc of batch 61: 47.71790313720703, 1.0\n",
      "Train loss and acc of batch 62: 47.7178955078125, 1.0\n",
      "Train loss and acc of batch 63: 48.9092903137207, 0.96875\n",
      "Train loss and acc of batch 64: 47.93464660644531, 0.984375\n",
      "Train loss and acc of batch 65: 47.71786880493164, 1.0\n",
      "Train loss and acc of batch 66: 47.717857360839844, 1.0\n",
      "Train loss and acc of batch 67: 48.53031921386719, 0.96875\n",
      "Train loss and acc of batch 68: 48.31354522705078, 0.984375\n",
      "Train loss and acc of batch 69: 47.934600830078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.71781921386719, 1.0\n",
      "Training accuracy and loss of epoch #539: 0.9897, 48.0390\n",
      "Saved model by train loss 48.039017744467294\n",
      "Train loss and acc of batch 0: 47.71781539916992, 1.0\n",
      "Train loss and acc of batch 1: 47.71780776977539, 1.0\n",
      "Train loss and acc of batch 2: 47.717796325683594, 1.0\n",
      "Train loss and acc of batch 3: 47.93455505371094, 0.984375\n",
      "Train loss and acc of batch 4: 47.71778106689453, 1.0\n",
      "Train loss and acc of batch 5: 49.06669616699219, 0.96875\n",
      "Train loss and acc of batch 6: 48.22037887573242, 0.96875\n",
      "Train loss and acc of batch 7: 47.71775436401367, 1.0\n",
      "Train loss and acc of batch 8: 48.313446044921875, 0.984375\n",
      "Train loss and acc of batch 9: 48.00358581542969, 0.984375\n",
      "Train loss and acc of batch 10: 47.71772766113281, 1.0\n",
      "Train loss and acc of batch 11: 47.717716217041016, 1.0\n",
      "Train loss and acc of batch 12: 48.4709358215332, 0.984375\n",
      "Train loss and acc of batch 13: 47.93446350097656, 0.984375\n",
      "Train loss and acc of batch 14: 47.93445587158203, 0.984375\n",
      "Train loss and acc of batch 15: 48.313385009765625, 0.984375\n",
      "Train loss and acc of batch 16: 48.313377380371094, 0.984375\n",
      "Train loss and acc of batch 17: 48.47088623046875, 0.984375\n",
      "Train loss and acc of batch 18: 48.59920883178711, 0.96875\n",
      "Train loss and acc of batch 19: 47.717647552490234, 1.0\n",
      "Train loss and acc of batch 20: 47.7176399230957, 1.0\n",
      "Train loss and acc of batch 21: 48.313331604003906, 0.984375\n",
      "Train loss and acc of batch 22: 48.313323974609375, 0.984375\n",
      "Train loss and acc of batch 23: 47.71760940551758, 1.0\n",
      "Train loss and acc of batch 24: 48.31330108642578, 0.984375\n",
      "Train loss and acc of batch 25: 47.717594146728516, 1.0\n",
      "Train loss and acc of batch 26: 47.717586517333984, 1.0\n",
      "Train loss and acc of batch 27: 47.71757125854492, 1.0\n",
      "Train loss and acc of batch 28: 47.717567443847656, 1.0\n",
      "Train loss and acc of batch 29: 48.313262939453125, 0.984375\n",
      "Train loss and acc of batch 30: 47.71754837036133, 1.0\n",
      "Train loss and acc of batch 31: 47.934303283691406, 0.984375\n",
      "Train loss and acc of batch 32: 47.717529296875, 1.0\n",
      "Train loss and acc of batch 33: 47.71752166748047, 1.0\n",
      "Train loss and acc of batch 34: 48.313209533691406, 0.984375\n",
      "Train loss and acc of batch 35: 48.15103530883789, 0.96875\n",
      "Train loss and acc of batch 36: 47.717498779296875, 1.0\n",
      "Train loss and acc of batch 37: 48.4707145690918, 0.984375\n",
      "Train loss and acc of batch 38: 49.06640625, 0.96875\n",
      "Train loss and acc of batch 39: 47.934234619140625, 0.984375\n",
      "Train loss and acc of batch 40: 47.71746063232422, 1.0\n",
      "Train loss and acc of batch 41: 49.06637954711914, 0.96875\n",
      "Train loss and acc of batch 42: 47.71744155883789, 1.0\n",
      "Train loss and acc of batch 43: 48.313140869140625, 0.984375\n",
      "Train loss and acc of batch 44: 47.71742248535156, 1.0\n",
      "Train loss and acc of batch 45: 48.31312561035156, 0.984375\n",
      "Train loss and acc of batch 46: 48.003257751464844, 0.984375\n",
      "Train loss and acc of batch 47: 47.7173957824707, 1.0\n",
      "Train loss and acc of batch 48: 47.71738815307617, 1.0\n",
      "Train loss and acc of batch 49: 47.717384338378906, 1.0\n",
      "Train loss and acc of batch 50: 48.313072204589844, 0.984375\n",
      "Train loss and acc of batch 51: 49.0662841796875, 0.96875\n",
      "Train loss and acc of batch 52: 48.97319412231445, 0.953125\n",
      "Train loss and acc of batch 53: 47.717350006103516, 1.0\n",
      "Train loss and acc of batch 54: 47.934104919433594, 0.984375\n",
      "Train loss and acc of batch 55: 47.71732711791992, 1.0\n",
      "Train loss and acc of batch 56: 47.717315673828125, 1.0\n",
      "Train loss and acc of batch 57: 48.313011169433594, 0.984375\n",
      "Train loss and acc of batch 58: 47.71730041503906, 1.0\n",
      "Train loss and acc of batch 59: 47.7172966003418, 1.0\n",
      "Train loss and acc of batch 60: 47.717281341552734, 1.0\n",
      "Train loss and acc of batch 61: 47.71726989746094, 1.0\n",
      "Train loss and acc of batch 62: 47.71726608276367, 1.0\n",
      "Train loss and acc of batch 63: 48.908660888671875, 0.96875\n",
      "Train loss and acc of batch 64: 47.93401336669922, 0.984375\n",
      "Train loss and acc of batch 65: 47.71723937988281, 1.0\n",
      "Train loss and acc of batch 66: 47.71723175048828, 1.0\n",
      "Train loss and acc of batch 67: 48.52968978881836, 0.96875\n",
      "Train loss and acc of batch 68: 48.31291198730469, 0.984375\n",
      "Train loss and acc of batch 69: 47.93396759033203, 0.984375\n",
      "Train loss and acc of batch 70: 47.71719741821289, 1.0\n",
      "Training accuracy and loss of epoch #540: 0.9897, 48.0384\n",
      "Saved model by train loss 48.03838864178725\n",
      "Train loss and acc of batch 0: 47.717185974121094, 1.0\n",
      "Train loss and acc of batch 1: 47.71717834472656, 1.0\n",
      "Train loss and acc of batch 2: 47.71717071533203, 1.0\n",
      "Train loss and acc of batch 3: 47.933921813964844, 0.984375\n",
      "Train loss and acc of batch 4: 47.71714401245117, 1.0\n",
      "Train loss and acc of batch 5: 49.066062927246094, 0.96875\n",
      "Train loss and acc of batch 6: 48.219749450683594, 0.96875\n",
      "Train loss and acc of batch 7: 47.717124938964844, 1.0\n",
      "Train loss and acc of batch 8: 48.31281280517578, 0.984375\n",
      "Train loss and acc of batch 9: 48.002960205078125, 0.984375\n",
      "Train loss and acc of batch 10: 47.717098236083984, 1.0\n",
      "Train loss and acc of batch 11: 47.71709060668945, 1.0\n",
      "Train loss and acc of batch 12: 48.470298767089844, 0.984375\n",
      "Train loss and acc of batch 13: 47.933837890625, 0.984375\n",
      "Train loss and acc of batch 14: 47.93382263183594, 0.984375\n",
      "Train loss and acc of batch 15: 48.31275939941406, 0.984375\n",
      "Train loss and acc of batch 16: 48.312744140625, 0.984375\n",
      "Train loss and acc of batch 17: 48.47026443481445, 0.984375\n",
      "Train loss and acc of batch 18: 48.59858322143555, 0.96875\n",
      "Train loss and acc of batch 19: 47.71702194213867, 1.0\n",
      "Train loss and acc of batch 20: 47.71700668334961, 1.0\n",
      "Train loss and acc of batch 21: 48.31269836425781, 0.984375\n",
      "Train loss and acc of batch 22: 48.31269073486328, 0.984375\n",
      "Train loss and acc of batch 23: 47.71697998046875, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 24: 48.31267547607422, 0.984375\n",
      "Train loss and acc of batch 25: 47.71696472167969, 1.0\n",
      "Train loss and acc of batch 26: 47.716957092285156, 1.0\n",
      "Train loss and acc of batch 27: 47.71694564819336, 1.0\n",
      "Train loss and acc of batch 28: 47.71693801879883, 1.0\n",
      "Train loss and acc of batch 29: 48.31262969970703, 0.984375\n",
      "Train loss and acc of batch 30: 47.7169189453125, 1.0\n",
      "Train loss and acc of batch 31: 47.933677673339844, 0.984375\n",
      "Train loss and acc of batch 32: 47.71690368652344, 1.0\n",
      "Train loss and acc of batch 33: 47.71689224243164, 1.0\n",
      "Train loss and acc of batch 34: 48.312583923339844, 0.984375\n",
      "Train loss and acc of batch 35: 48.15040969848633, 0.96875\n",
      "Train loss and acc of batch 36: 47.71686553955078, 1.0\n",
      "Train loss and acc of batch 37: 48.4700813293457, 0.984375\n",
      "Train loss and acc of batch 38: 49.065773010253906, 0.96875\n",
      "Train loss and acc of batch 39: 47.93360137939453, 0.984375\n",
      "Train loss and acc of batch 40: 47.716835021972656, 1.0\n",
      "Train loss and acc of batch 41: 49.06574249267578, 0.96875\n",
      "Train loss and acc of batch 42: 47.71681213378906, 1.0\n",
      "Train loss and acc of batch 43: 48.31250762939453, 0.984375\n",
      "Train loss and acc of batch 44: 47.716793060302734, 1.0\n",
      "Train loss and acc of batch 45: 48.31248474121094, 0.984375\n",
      "Train loss and acc of batch 46: 48.00263214111328, 0.984375\n",
      "Train loss and acc of batch 47: 47.716766357421875, 1.0\n",
      "Train loss and acc of batch 48: 47.71676254272461, 1.0\n",
      "Train loss and acc of batch 49: 47.71675491333008, 1.0\n",
      "Train loss and acc of batch 50: 48.31243896484375, 0.984375\n",
      "Train loss and acc of batch 51: 49.06565856933594, 0.96875\n",
      "Train loss and acc of batch 52: 48.97256851196289, 0.953125\n",
      "Train loss and acc of batch 53: 47.71671676635742, 1.0\n",
      "Train loss and acc of batch 54: 47.9334716796875, 0.984375\n",
      "Train loss and acc of batch 55: 47.71669387817383, 1.0\n",
      "Train loss and acc of batch 56: 47.71669006347656, 1.0\n",
      "Train loss and acc of batch 57: 48.3123779296875, 0.984375\n",
      "Train loss and acc of batch 58: 47.71666717529297, 1.0\n",
      "Train loss and acc of batch 59: 47.71665954589844, 1.0\n",
      "Train loss and acc of batch 60: 47.716651916503906, 1.0\n",
      "Train loss and acc of batch 61: 47.716644287109375, 1.0\n",
      "Train loss and acc of batch 62: 47.716636657714844, 1.0\n",
      "Train loss and acc of batch 63: 48.90803146362305, 0.96875\n",
      "Train loss and acc of batch 64: 47.933380126953125, 0.984375\n",
      "Train loss and acc of batch 65: 47.716609954833984, 1.0\n",
      "Train loss and acc of batch 66: 47.71660232543945, 1.0\n",
      "Train loss and acc of batch 67: 48.529056549072266, 0.96875\n",
      "Train loss and acc of batch 68: 48.312286376953125, 0.984375\n",
      "Train loss and acc of batch 69: 47.93334197998047, 0.984375\n",
      "Train loss and acc of batch 70: 47.71656799316406, 1.0\n",
      "Training accuracy and loss of epoch #541: 0.9897, 48.0378\n",
      "Saved model by train loss 48.03775873318524\n",
      "Train loss and acc of batch 0: 47.716556549072266, 1.0\n",
      "Train loss and acc of batch 1: 47.71654510498047, 1.0\n",
      "Train loss and acc of batch 2: 47.71653747558594, 1.0\n",
      "Train loss and acc of batch 3: 47.93328857421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.71651840209961, 1.0\n",
      "Train loss and acc of batch 5: 49.06543731689453, 0.96875\n",
      "Train loss and acc of batch 6: 48.219120025634766, 0.96875\n",
      "Train loss and acc of batch 7: 47.71649169921875, 1.0\n",
      "Train loss and acc of batch 8: 48.31218719482422, 0.984375\n",
      "Train loss and acc of batch 9: 48.00232696533203, 0.984375\n",
      "Train loss and acc of batch 10: 47.716468811035156, 1.0\n",
      "Train loss and acc of batch 11: 47.71645736694336, 1.0\n",
      "Train loss and acc of batch 12: 48.46967697143555, 0.984375\n",
      "Train loss and acc of batch 13: 47.933204650878906, 0.984375\n",
      "Train loss and acc of batch 14: 47.933197021484375, 0.984375\n",
      "Train loss and acc of batch 15: 48.31212615966797, 0.984375\n",
      "Train loss and acc of batch 16: 48.312110900878906, 0.984375\n",
      "Train loss and acc of batch 17: 48.46962356567383, 0.984375\n",
      "Train loss and acc of batch 18: 48.59794998168945, 0.96875\n",
      "Train loss and acc of batch 19: 47.71638488769531, 1.0\n",
      "Train loss and acc of batch 20: 47.71638107299805, 1.0\n",
      "Train loss and acc of batch 21: 48.31206512451172, 0.984375\n",
      "Train loss and acc of batch 22: 48.31206512451172, 0.984375\n",
      "Train loss and acc of batch 23: 47.71635055541992, 1.0\n",
      "Train loss and acc of batch 24: 48.312042236328125, 0.984375\n",
      "Train loss and acc of batch 25: 47.716331481933594, 1.0\n",
      "Train loss and acc of batch 26: 47.71632766723633, 1.0\n",
      "Train loss and acc of batch 27: 47.71631622314453, 1.0\n",
      "Train loss and acc of batch 28: 47.71630859375, 1.0\n",
      "Train loss and acc of batch 29: 48.31200408935547, 0.984375\n",
      "Train loss and acc of batch 30: 47.716285705566406, 1.0\n",
      "Train loss and acc of batch 31: 47.93304443359375, 0.984375\n",
      "Train loss and acc of batch 32: 47.716270446777344, 1.0\n",
      "Train loss and acc of batch 33: 47.71626281738281, 1.0\n",
      "Train loss and acc of batch 34: 48.31195831298828, 0.984375\n",
      "Train loss and acc of batch 35: 48.149776458740234, 0.96875\n",
      "Train loss and acc of batch 36: 47.71623611450195, 1.0\n",
      "Train loss and acc of batch 37: 48.469451904296875, 0.984375\n",
      "Train loss and acc of batch 38: 49.06513977050781, 0.96875\n",
      "Train loss and acc of batch 39: 47.93297576904297, 0.984375\n",
      "Train loss and acc of batch 40: 47.71620178222656, 1.0\n",
      "Train loss and acc of batch 41: 49.06511688232422, 0.96875\n",
      "Train loss and acc of batch 42: 47.7161865234375, 1.0\n",
      "Train loss and acc of batch 43: 48.31187438964844, 0.984375\n",
      "Train loss and acc of batch 44: 47.71616744995117, 1.0\n",
      "Train loss and acc of batch 45: 48.311859130859375, 0.984375\n",
      "Train loss and acc of batch 46: 48.00199890136719, 0.984375\n",
      "Train loss and acc of batch 47: 47.71613693237305, 1.0\n",
      "Train loss and acc of batch 48: 47.716129302978516, 1.0\n",
      "Train loss and acc of batch 49: 47.71612548828125, 1.0\n",
      "Train loss and acc of batch 50: 48.31181335449219, 0.984375\n",
      "Train loss and acc of batch 51: 49.065032958984375, 0.96875\n",
      "Train loss and acc of batch 52: 48.97193145751953, 0.953125\n",
      "Train loss and acc of batch 53: 47.71608352661133, 1.0\n",
      "Train loss and acc of batch 54: 47.932838439941406, 0.984375\n",
      "Train loss and acc of batch 55: 47.716068267822266, 1.0\n",
      "Train loss and acc of batch 56: 47.716060638427734, 1.0\n",
      "Train loss and acc of batch 57: 48.31175231933594, 0.984375\n",
      "Train loss and acc of batch 58: 47.71603775024414, 1.0\n",
      "Train loss and acc of batch 59: 47.716033935546875, 1.0\n",
      "Train loss and acc of batch 60: 47.71602249145508, 1.0\n",
      "Train loss and acc of batch 61: 47.71601486206055, 1.0\n",
      "Train loss and acc of batch 62: 47.71600341796875, 1.0\n",
      "Train loss and acc of batch 63: 48.90739822387695, 0.96875\n",
      "Train loss and acc of batch 64: 47.93275451660156, 0.984375\n",
      "Train loss and acc of batch 65: 47.715980529785156, 1.0\n",
      "Train loss and acc of batch 66: 47.71596908569336, 1.0\n",
      "Train loss and acc of batch 67: 48.52842330932617, 0.96875\n",
      "Train loss and acc of batch 68: 48.31165313720703, 0.984375\n",
      "Train loss and acc of batch 69: 47.932701110839844, 0.984375\n",
      "Train loss and acc of batch 70: 47.71593475341797, 1.0\n",
      "Training accuracy and loss of epoch #542: 0.9897, 48.0371\n",
      "Saved model by train loss 48.03712828730194\n",
      "Train loss and acc of batch 0: 47.7159309387207, 1.0\n",
      "Train loss and acc of batch 1: 47.715919494628906, 1.0\n",
      "Train loss and acc of batch 2: 47.715911865234375, 1.0\n",
      "Train loss and acc of batch 3: 47.93266296386719, 0.984375\n",
      "Train loss and acc of batch 4: 47.71588897705078, 1.0\n",
      "Train loss and acc of batch 5: 49.06481170654297, 0.96875\n",
      "Train loss and acc of batch 6: 48.21848678588867, 0.96875\n",
      "Train loss and acc of batch 7: 47.71586608886719, 1.0\n",
      "Train loss and acc of batch 8: 48.311553955078125, 0.984375\n",
      "Train loss and acc of batch 9: 48.00170135498047, 0.984375\n",
      "Train loss and acc of batch 10: 47.7158317565918, 1.0\n",
      "Train loss and acc of batch 11: 47.71582794189453, 1.0\n",
      "Train loss and acc of batch 12: 48.46903991699219, 0.984375\n",
      "Train loss and acc of batch 13: 47.932579040527344, 0.984375\n",
      "Train loss and acc of batch 14: 47.93256378173828, 0.984375\n",
      "Train loss and acc of batch 15: 48.311492919921875, 0.984375\n",
      "Train loss and acc of batch 16: 48.311485290527344, 0.984375\n",
      "Train loss and acc of batch 17: 48.468997955322266, 0.984375\n",
      "Train loss and acc of batch 18: 48.597320556640625, 0.96875\n",
      "Train loss and acc of batch 19: 47.715763092041016, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 20: 47.71574783325195, 1.0\n",
      "Train loss and acc of batch 21: 48.311439514160156, 0.984375\n",
      "Train loss and acc of batch 22: 48.311431884765625, 0.984375\n",
      "Train loss and acc of batch 23: 47.715721130371094, 1.0\n",
      "Train loss and acc of batch 24: 48.31141662597656, 0.984375\n",
      "Train loss and acc of batch 25: 47.71570587158203, 1.0\n",
      "Train loss and acc of batch 26: 47.715694427490234, 1.0\n",
      "Train loss and acc of batch 27: 47.7156867980957, 1.0\n",
      "Train loss and acc of batch 28: 47.71567916870117, 1.0\n",
      "Train loss and acc of batch 29: 48.311370849609375, 0.984375\n",
      "Train loss and acc of batch 30: 47.715660095214844, 1.0\n",
      "Train loss and acc of batch 31: 47.93241882324219, 0.984375\n",
      "Train loss and acc of batch 32: 47.715641021728516, 1.0\n",
      "Train loss and acc of batch 33: 47.71563720703125, 1.0\n",
      "Train loss and acc of batch 34: 48.31132507324219, 0.984375\n",
      "Train loss and acc of batch 35: 48.14914321899414, 0.96875\n",
      "Train loss and acc of batch 36: 47.715606689453125, 1.0\n",
      "Train loss and acc of batch 37: 48.46882247924805, 0.984375\n",
      "Train loss and acc of batch 38: 49.06451416015625, 0.96875\n",
      "Train loss and acc of batch 39: 47.932342529296875, 0.984375\n",
      "Train loss and acc of batch 40: 47.71556854248047, 1.0\n",
      "Train loss and acc of batch 41: 49.06448745727539, 0.96875\n",
      "Train loss and acc of batch 42: 47.715553283691406, 1.0\n",
      "Train loss and acc of batch 43: 48.311241149902344, 0.984375\n",
      "Train loss and acc of batch 44: 47.715538024902344, 1.0\n",
      "Train loss and acc of batch 45: 48.31123352050781, 0.984375\n",
      "Train loss and acc of batch 46: 48.001373291015625, 0.984375\n",
      "Train loss and acc of batch 47: 47.715511322021484, 1.0\n",
      "Train loss and acc of batch 48: 47.71550369262695, 1.0\n",
      "Train loss and acc of batch 49: 47.71548843383789, 1.0\n",
      "Train loss and acc of batch 50: 48.311187744140625, 0.984375\n",
      "Train loss and acc of batch 51: 49.06439208984375, 0.96875\n",
      "Train loss and acc of batch 52: 48.971309661865234, 0.953125\n",
      "Train loss and acc of batch 53: 47.7154541015625, 1.0\n",
      "Train loss and acc of batch 54: 47.932212829589844, 0.984375\n",
      "Train loss and acc of batch 55: 47.71543884277344, 1.0\n",
      "Train loss and acc of batch 56: 47.715431213378906, 1.0\n",
      "Train loss and acc of batch 57: 48.311119079589844, 0.984375\n",
      "Train loss and acc of batch 58: 47.71541213989258, 1.0\n",
      "Train loss and acc of batch 59: 47.71540451049805, 1.0\n",
      "Train loss and acc of batch 60: 47.715396881103516, 1.0\n",
      "Train loss and acc of batch 61: 47.71538543701172, 1.0\n",
      "Train loss and acc of batch 62: 47.71537780761719, 1.0\n",
      "Train loss and acc of batch 63: 48.90676498413086, 0.96875\n",
      "Train loss and acc of batch 64: 47.93212890625, 0.984375\n",
      "Train loss and acc of batch 65: 47.715354919433594, 1.0\n",
      "Train loss and acc of batch 66: 47.7153434753418, 1.0\n",
      "Train loss and acc of batch 67: 48.527801513671875, 0.96875\n",
      "Train loss and acc of batch 68: 48.31101989746094, 0.984375\n",
      "Train loss and acc of batch 69: 47.93207550048828, 0.984375\n",
      "Train loss and acc of batch 70: 47.715309143066406, 1.0\n",
      "Training accuracy and loss of epoch #543: 0.9897, 48.0365\n",
      "Saved model by train loss 48.03649945326254\n",
      "Train loss and acc of batch 0: 47.71529769897461, 1.0\n",
      "Train loss and acc of batch 1: 47.71528625488281, 1.0\n",
      "Train loss and acc of batch 2: 47.71527862548828, 1.0\n",
      "Train loss and acc of batch 3: 47.932037353515625, 0.984375\n",
      "Train loss and acc of batch 4: 47.71525955200195, 1.0\n",
      "Train loss and acc of batch 5: 49.064170837402344, 0.96875\n",
      "Train loss and acc of batch 6: 48.217857360839844, 0.96875\n",
      "Train loss and acc of batch 7: 47.71523666381836, 1.0\n",
      "Train loss and acc of batch 8: 48.31092834472656, 0.984375\n",
      "Train loss and acc of batch 9: 48.001068115234375, 0.984375\n",
      "Train loss and acc of batch 10: 47.7152099609375, 1.0\n",
      "Train loss and acc of batch 11: 47.7151985168457, 1.0\n",
      "Train loss and acc of batch 12: 48.468414306640625, 0.984375\n",
      "Train loss and acc of batch 13: 47.93194580078125, 0.984375\n",
      "Train loss and acc of batch 14: 47.93193817138672, 0.984375\n",
      "Train loss and acc of batch 15: 48.31085968017578, 0.984375\n",
      "Train loss and acc of batch 16: 48.31085968017578, 0.984375\n",
      "Train loss and acc of batch 17: 48.4683723449707, 0.984375\n",
      "Train loss and acc of batch 18: 48.59669494628906, 0.96875\n",
      "Train loss and acc of batch 19: 47.71512222290039, 1.0\n",
      "Train loss and acc of batch 20: 47.715118408203125, 1.0\n",
      "Train loss and acc of batch 21: 48.310813903808594, 0.984375\n",
      "Train loss and acc of batch 22: 48.31080627441406, 0.984375\n",
      "Train loss and acc of batch 23: 47.715091705322266, 1.0\n",
      "Train loss and acc of batch 24: 48.310791015625, 0.984375\n",
      "Train loss and acc of batch 25: 47.7150764465332, 1.0\n",
      "Train loss and acc of batch 26: 47.71506881713867, 1.0\n",
      "Train loss and acc of batch 27: 47.715057373046875, 1.0\n",
      "Train loss and acc of batch 28: 47.715049743652344, 1.0\n",
      "Train loss and acc of batch 29: 48.31073760986328, 0.984375\n",
      "Train loss and acc of batch 30: 47.715030670166016, 1.0\n",
      "Train loss and acc of batch 31: 47.931785583496094, 0.984375\n",
      "Train loss and acc of batch 32: 47.71501541137695, 1.0\n",
      "Train loss and acc of batch 33: 47.715003967285156, 1.0\n",
      "Train loss and acc of batch 34: 48.310699462890625, 0.984375\n",
      "Train loss and acc of batch 35: 48.14851379394531, 0.96875\n",
      "Train loss and acc of batch 36: 47.7149772644043, 1.0\n",
      "Train loss and acc of batch 37: 48.46819305419922, 0.984375\n",
      "Train loss and acc of batch 38: 49.06388854980469, 0.96875\n",
      "Train loss and acc of batch 39: 47.93171691894531, 0.984375\n",
      "Train loss and acc of batch 40: 47.714942932128906, 1.0\n",
      "Train loss and acc of batch 41: 49.06386184692383, 0.96875\n",
      "Train loss and acc of batch 42: 47.714927673339844, 1.0\n",
      "Train loss and acc of batch 43: 48.31061553955078, 0.984375\n",
      "Train loss and acc of batch 44: 47.71490478515625, 1.0\n",
      "Train loss and acc of batch 45: 48.31060028076172, 0.984375\n",
      "Train loss and acc of batch 46: 48.00074005126953, 0.984375\n",
      "Train loss and acc of batch 47: 47.714881896972656, 1.0\n",
      "Train loss and acc of batch 48: 47.714866638183594, 1.0\n",
      "Train loss and acc of batch 49: 47.71486282348633, 1.0\n",
      "Train loss and acc of batch 50: 48.31055450439453, 0.984375\n",
      "Train loss and acc of batch 51: 49.06376647949219, 0.96875\n",
      "Train loss and acc of batch 52: 48.97067642211914, 0.953125\n",
      "Train loss and acc of batch 53: 47.71482849121094, 1.0\n",
      "Train loss and acc of batch 54: 47.93157958984375, 0.984375\n",
      "Train loss and acc of batch 55: 47.71480941772461, 1.0\n",
      "Train loss and acc of batch 56: 47.71480178833008, 1.0\n",
      "Train loss and acc of batch 57: 48.31049346923828, 0.984375\n",
      "Train loss and acc of batch 58: 47.714786529541016, 1.0\n",
      "Train loss and acc of batch 59: 47.71477508544922, 1.0\n",
      "Train loss and acc of batch 60: 47.71476364135742, 1.0\n",
      "Train loss and acc of batch 61: 47.714759826660156, 1.0\n",
      "Train loss and acc of batch 62: 47.71474838256836, 1.0\n",
      "Train loss and acc of batch 63: 48.9061393737793, 0.96875\n",
      "Train loss and acc of batch 64: 47.931495666503906, 0.984375\n",
      "Train loss and acc of batch 65: 47.714717864990234, 1.0\n",
      "Train loss and acc of batch 66: 47.7147102355957, 1.0\n",
      "Train loss and acc of batch 67: 48.52717208862305, 0.96875\n",
      "Train loss and acc of batch 68: 48.310394287109375, 0.984375\n",
      "Train loss and acc of batch 69: 47.93145751953125, 0.984375\n",
      "Train loss and acc of batch 70: 47.71467590332031, 1.0\n",
      "Training accuracy and loss of epoch #544: 0.9897, 48.0359\n",
      "Saved model by train loss 48.03587018939811\n",
      "Train loss and acc of batch 0: 47.714664459228516, 1.0\n",
      "Train loss and acc of batch 1: 47.71466064453125, 1.0\n",
      "Train loss and acc of batch 2: 47.71465301513672, 1.0\n",
      "Train loss and acc of batch 3: 47.93140411376953, 0.984375\n",
      "Train loss and acc of batch 4: 47.714637756347656, 1.0\n",
      "Train loss and acc of batch 5: 49.06354522705078, 0.96875\n",
      "Train loss and acc of batch 6: 48.217227935791016, 0.96875\n",
      "Train loss and acc of batch 7: 47.714603424072266, 1.0\n",
      "Train loss and acc of batch 8: 48.31029510498047, 0.984375\n",
      "Train loss and acc of batch 9: 48.00044250488281, 0.984375\n",
      "Train loss and acc of batch 10: 47.714576721191406, 1.0\n",
      "Train loss and acc of batch 11: 47.714569091796875, 1.0\n",
      "Train loss and acc of batch 12: 48.46778869628906, 0.984375\n",
      "Train loss and acc of batch 13: 47.93132019042969, 0.984375\n",
      "Train loss and acc of batch 14: 47.931304931640625, 0.984375\n",
      "Train loss and acc of batch 15: 48.31023406982422, 0.984375\n",
      "Train loss and acc of batch 16: 48.31022644042969, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 17: 48.46773910522461, 0.984375\n",
      "Train loss and acc of batch 18: 48.59606170654297, 0.96875\n",
      "Train loss and acc of batch 19: 47.714500427246094, 1.0\n",
      "Train loss and acc of batch 20: 47.71449279785156, 1.0\n",
      "Train loss and acc of batch 21: 48.31018829345703, 0.984375\n",
      "Train loss and acc of batch 22: 48.31017303466797, 0.984375\n",
      "Train loss and acc of batch 23: 47.71446228027344, 1.0\n",
      "Train loss and acc of batch 24: 48.310157775878906, 0.984375\n",
      "Train loss and acc of batch 25: 47.714447021484375, 1.0\n",
      "Train loss and acc of batch 26: 47.714439392089844, 1.0\n",
      "Train loss and acc of batch 27: 47.71443176269531, 1.0\n",
      "Train loss and acc of batch 28: 47.71441650390625, 1.0\n",
      "Train loss and acc of batch 29: 48.31011199951172, 0.984375\n",
      "Train loss and acc of batch 30: 47.71439743041992, 1.0\n",
      "Train loss and acc of batch 31: 47.93115997314453, 0.984375\n",
      "Train loss and acc of batch 32: 47.71438980102539, 1.0\n",
      "Train loss and acc of batch 33: 47.714378356933594, 1.0\n",
      "Train loss and acc of batch 34: 48.31006622314453, 0.984375\n",
      "Train loss and acc of batch 35: 48.147891998291016, 0.96875\n",
      "Train loss and acc of batch 36: 47.7143440246582, 1.0\n",
      "Train loss and acc of batch 37: 48.467559814453125, 0.984375\n",
      "Train loss and acc of batch 38: 49.063255310058594, 0.96875\n",
      "Train loss and acc of batch 39: 47.93108367919922, 0.984375\n",
      "Train loss and acc of batch 40: 47.71431350708008, 1.0\n",
      "Train loss and acc of batch 41: 49.063236236572266, 0.96875\n",
      "Train loss and acc of batch 42: 47.71429443359375, 1.0\n",
      "Train loss and acc of batch 43: 48.30998992919922, 0.984375\n",
      "Train loss and acc of batch 44: 47.71427536010742, 1.0\n",
      "Train loss and acc of batch 45: 48.309967041015625, 0.984375\n",
      "Train loss and acc of batch 46: 48.00011444091797, 0.984375\n",
      "Train loss and acc of batch 47: 47.71424865722656, 1.0\n",
      "Train loss and acc of batch 48: 47.71424102783203, 1.0\n",
      "Train loss and acc of batch 49: 47.71424102783203, 1.0\n",
      "Train loss and acc of batch 50: 48.30992889404297, 0.984375\n",
      "Train loss and acc of batch 51: 49.063140869140625, 0.96875\n",
      "Train loss and acc of batch 52: 48.97004699707031, 0.953125\n",
      "Train loss and acc of batch 53: 47.714195251464844, 1.0\n",
      "Train loss and acc of batch 54: 47.93095397949219, 0.984375\n",
      "Train loss and acc of batch 55: 47.71417999267578, 1.0\n",
      "Train loss and acc of batch 56: 47.714168548583984, 1.0\n",
      "Train loss and acc of batch 57: 48.30986022949219, 0.984375\n",
      "Train loss and acc of batch 58: 47.71415328979492, 1.0\n",
      "Train loss and acc of batch 59: 47.714141845703125, 1.0\n",
      "Train loss and acc of batch 60: 47.71413803100586, 1.0\n",
      "Train loss and acc of batch 61: 47.71412658691406, 1.0\n",
      "Train loss and acc of batch 62: 47.71411895751953, 1.0\n",
      "Train loss and acc of batch 63: 48.905513763427734, 0.96875\n",
      "Train loss and acc of batch 64: 47.93086242675781, 0.984375\n",
      "Train loss and acc of batch 65: 47.71409225463867, 1.0\n",
      "Train loss and acc of batch 66: 47.714080810546875, 1.0\n",
      "Train loss and acc of batch 67: 48.52653884887695, 0.96875\n",
      "Train loss and acc of batch 68: 48.30976867675781, 0.984375\n",
      "Train loss and acc of batch 69: 47.930824279785156, 0.984375\n",
      "Train loss and acc of batch 70: 47.71405029296875, 1.0\n",
      "Training accuracy and loss of epoch #545: 0.9897, 48.0352\n",
      "Saved model by train loss 48.0352409792618\n",
      "Train loss and acc of batch 0: 47.71403884887695, 1.0\n",
      "Train loss and acc of batch 1: 47.714027404785156, 1.0\n",
      "Train loss and acc of batch 2: 47.71401596069336, 1.0\n",
      "Train loss and acc of batch 3: 47.93077850341797, 0.984375\n",
      "Train loss and acc of batch 4: 47.7140007019043, 1.0\n",
      "Train loss and acc of batch 5: 49.06291961669922, 0.96875\n",
      "Train loss and acc of batch 6: 48.21659851074219, 0.96875\n",
      "Train loss and acc of batch 7: 47.7139778137207, 1.0\n",
      "Train loss and acc of batch 8: 48.30967712402344, 0.984375\n",
      "Train loss and acc of batch 9: 47.99980926513672, 0.984375\n",
      "Train loss and acc of batch 10: 47.71394729614258, 1.0\n",
      "Train loss and acc of batch 11: 47.71393966674805, 1.0\n",
      "Train loss and acc of batch 12: 48.4671516418457, 0.984375\n",
      "Train loss and acc of batch 13: 47.930686950683594, 0.984375\n",
      "Train loss and acc of batch 14: 47.93067932128906, 0.984375\n",
      "Train loss and acc of batch 15: 48.309608459472656, 0.984375\n",
      "Train loss and acc of batch 16: 48.309600830078125, 0.984375\n",
      "Train loss and acc of batch 17: 48.46710968017578, 0.984375\n",
      "Train loss and acc of batch 18: 48.59543228149414, 0.96875\n",
      "Train loss and acc of batch 19: 47.713871002197266, 1.0\n",
      "Train loss and acc of batch 20: 47.71385955810547, 1.0\n",
      "Train loss and acc of batch 21: 48.30955505371094, 0.984375\n",
      "Train loss and acc of batch 22: 48.309547424316406, 0.984375\n",
      "Train loss and acc of batch 23: 47.71383285522461, 1.0\n",
      "Train loss and acc of batch 24: 48.309532165527344, 0.984375\n",
      "Train loss and acc of batch 25: 47.71381759643555, 1.0\n",
      "Train loss and acc of batch 26: 47.713809967041016, 1.0\n",
      "Train loss and acc of batch 27: 47.71379852294922, 1.0\n",
      "Train loss and acc of batch 28: 47.71379089355469, 1.0\n",
      "Train loss and acc of batch 29: 48.309478759765625, 0.984375\n",
      "Train loss and acc of batch 30: 47.713775634765625, 1.0\n",
      "Train loss and acc of batch 31: 47.93053436279297, 0.984375\n",
      "Train loss and acc of batch 32: 47.7137565612793, 1.0\n",
      "Train loss and acc of batch 33: 47.7137451171875, 1.0\n",
      "Train loss and acc of batch 34: 48.30943298339844, 0.984375\n",
      "Train loss and acc of batch 35: 48.14725875854492, 0.96875\n",
      "Train loss and acc of batch 36: 47.713722229003906, 1.0\n",
      "Train loss and acc of batch 37: 48.4669303894043, 0.984375\n",
      "Train loss and acc of batch 38: 49.06262969970703, 0.96875\n",
      "Train loss and acc of batch 39: 47.930458068847656, 0.984375\n",
      "Train loss and acc of batch 40: 47.71368408203125, 1.0\n",
      "Train loss and acc of batch 41: 49.062599182128906, 0.96875\n",
      "Train loss and acc of batch 42: 47.71366500854492, 1.0\n",
      "Train loss and acc of batch 43: 48.309356689453125, 0.984375\n",
      "Train loss and acc of batch 44: 47.713653564453125, 1.0\n",
      "Train loss and acc of batch 45: 48.30934143066406, 0.984375\n",
      "Train loss and acc of batch 46: 47.999481201171875, 0.984375\n",
      "Train loss and acc of batch 47: 47.713619232177734, 1.0\n",
      "Train loss and acc of batch 48: 47.71360778808594, 1.0\n",
      "Train loss and acc of batch 49: 47.713600158691406, 1.0\n",
      "Train loss and acc of batch 50: 48.309295654296875, 0.984375\n",
      "Train loss and acc of batch 51: 49.06250762939453, 0.96875\n",
      "Train loss and acc of batch 52: 48.96942138671875, 0.953125\n",
      "Train loss and acc of batch 53: 47.71357345581055, 1.0\n",
      "Train loss and acc of batch 54: 47.930328369140625, 0.984375\n",
      "Train loss and acc of batch 55: 47.71355056762695, 1.0\n",
      "Train loss and acc of batch 56: 47.713539123535156, 1.0\n",
      "Train loss and acc of batch 57: 48.309234619140625, 0.984375\n",
      "Train loss and acc of batch 58: 47.713523864746094, 1.0\n",
      "Train loss and acc of batch 59: 47.71351623535156, 1.0\n",
      "Train loss and acc of batch 60: 47.713504791259766, 1.0\n",
      "Train loss and acc of batch 61: 47.71349334716797, 1.0\n",
      "Train loss and acc of batch 62: 47.7134895324707, 1.0\n",
      "Train loss and acc of batch 63: 48.904884338378906, 0.96875\n",
      "Train loss and acc of batch 64: 47.93023681640625, 0.984375\n",
      "Train loss and acc of batch 65: 47.71345901489258, 1.0\n",
      "Train loss and acc of batch 66: 47.71345138549805, 1.0\n",
      "Train loss and acc of batch 67: 48.52591323852539, 0.96875\n",
      "Train loss and acc of batch 68: 48.30913543701172, 0.984375\n",
      "Train loss and acc of batch 69: 47.93019104003906, 0.984375\n",
      "Train loss and acc of batch 70: 47.71342086791992, 1.0\n",
      "Training accuracy and loss of epoch #546: 0.9897, 48.0346\n",
      "Saved model by train loss 48.03461150048484\n",
      "Train loss and acc of batch 0: 47.713409423828125, 1.0\n",
      "Train loss and acc of batch 1: 47.713401794433594, 1.0\n",
      "Train loss and acc of batch 2: 47.71339416503906, 1.0\n",
      "Train loss and acc of batch 3: 47.930152893066406, 0.984375\n",
      "Train loss and acc of batch 4: 47.713375091552734, 1.0\n",
      "Train loss and acc of batch 5: 49.062294006347656, 0.96875\n",
      "Train loss and acc of batch 6: 48.21597671508789, 0.96875\n",
      "Train loss and acc of batch 7: 47.71335220336914, 1.0\n",
      "Train loss and acc of batch 8: 48.309043884277344, 0.984375\n",
      "Train loss and acc of batch 9: 47.999183654785156, 0.984375\n",
      "Train loss and acc of batch 10: 47.71332550048828, 1.0\n",
      "Train loss and acc of batch 11: 47.71331024169922, 1.0\n",
      "Train loss and acc of batch 12: 48.466529846191406, 0.984375\n",
      "Train loss and acc of batch 13: 47.9300537109375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 14: 47.93004608154297, 0.984375\n",
      "Train loss and acc of batch 15: 48.30897521972656, 0.984375\n",
      "Train loss and acc of batch 16: 48.30896759033203, 0.984375\n",
      "Train loss and acc of batch 17: 48.46648406982422, 0.984375\n",
      "Train loss and acc of batch 18: 48.59480667114258, 0.96875\n",
      "Train loss and acc of batch 19: 47.71324157714844, 1.0\n",
      "Train loss and acc of batch 20: 47.71323013305664, 1.0\n",
      "Train loss and acc of batch 21: 48.308921813964844, 0.984375\n",
      "Train loss and acc of batch 22: 48.30891418457031, 0.984375\n",
      "Train loss and acc of batch 23: 47.71320343017578, 1.0\n",
      "Train loss and acc of batch 24: 48.30890655517578, 0.984375\n",
      "Train loss and acc of batch 25: 47.71318817138672, 1.0\n",
      "Train loss and acc of batch 26: 47.71318435668945, 1.0\n",
      "Train loss and acc of batch 27: 47.71316909790039, 1.0\n",
      "Train loss and acc of batch 28: 47.713157653808594, 1.0\n",
      "Train loss and acc of batch 29: 48.30885314941406, 0.984375\n",
      "Train loss and acc of batch 30: 47.71314239501953, 1.0\n",
      "Train loss and acc of batch 31: 47.929901123046875, 0.984375\n",
      "Train loss and acc of batch 32: 47.71312713623047, 1.0\n",
      "Train loss and acc of batch 33: 47.71311569213867, 1.0\n",
      "Train loss and acc of batch 34: 48.308815002441406, 0.984375\n",
      "Train loss and acc of batch 35: 48.146629333496094, 0.96875\n",
      "Train loss and acc of batch 36: 47.71308898925781, 1.0\n",
      "Train loss and acc of batch 37: 48.466304779052734, 0.984375\n",
      "Train loss and acc of batch 38: 49.06199645996094, 0.96875\n",
      "Train loss and acc of batch 39: 47.92982482910156, 0.984375\n",
      "Train loss and acc of batch 40: 47.71306228637695, 1.0\n",
      "Train loss and acc of batch 41: 49.06196975708008, 0.96875\n",
      "Train loss and acc of batch 42: 47.71303176879883, 1.0\n",
      "Train loss and acc of batch 43: 48.30873107910156, 0.984375\n",
      "Train loss and acc of batch 44: 47.7130241394043, 1.0\n",
      "Train loss and acc of batch 45: 48.3087158203125, 0.984375\n",
      "Train loss and acc of batch 46: 47.99885559082031, 0.984375\n",
      "Train loss and acc of batch 47: 47.71299362182617, 1.0\n",
      "Train loss and acc of batch 48: 47.71298599243164, 1.0\n",
      "Train loss and acc of batch 49: 47.71297836303711, 1.0\n",
      "Train loss and acc of batch 50: 48.30866241455078, 0.984375\n",
      "Train loss and acc of batch 51: 49.06188201904297, 0.96875\n",
      "Train loss and acc of batch 52: 48.96879196166992, 0.953125\n",
      "Train loss and acc of batch 53: 47.71294403076172, 1.0\n",
      "Train loss and acc of batch 54: 47.92969512939453, 0.984375\n",
      "Train loss and acc of batch 55: 47.71292495727539, 1.0\n",
      "Train loss and acc of batch 56: 47.71290969848633, 1.0\n",
      "Train loss and acc of batch 57: 48.30860900878906, 0.984375\n",
      "Train loss and acc of batch 58: 47.712894439697266, 1.0\n",
      "Train loss and acc of batch 59: 47.712886810302734, 1.0\n",
      "Train loss and acc of batch 60: 47.7128791809082, 1.0\n",
      "Train loss and acc of batch 61: 47.712867736816406, 1.0\n",
      "Train loss and acc of batch 62: 47.712860107421875, 1.0\n",
      "Train loss and acc of batch 63: 48.904258728027344, 0.96875\n",
      "Train loss and acc of batch 64: 47.929603576660156, 0.984375\n",
      "Train loss and acc of batch 65: 47.712833404541016, 1.0\n",
      "Train loss and acc of batch 66: 47.71282196044922, 1.0\n",
      "Train loss and acc of batch 67: 48.52528381347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.308509826660156, 0.984375\n",
      "Train loss and acc of batch 69: 47.9295654296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.71278762817383, 1.0\n",
      "Training accuracy and loss of epoch #547: 0.9897, 48.0340\n",
      "Saved model by train loss 48.033983364911144\n",
      "Train loss and acc of batch 0: 47.7127799987793, 1.0\n",
      "Train loss and acc of batch 1: 47.712772369384766, 1.0\n",
      "Train loss and acc of batch 2: 47.71276092529297, 1.0\n",
      "Train loss and acc of batch 3: 47.92951965332031, 0.984375\n",
      "Train loss and acc of batch 4: 47.712745666503906, 1.0\n",
      "Train loss and acc of batch 5: 49.06166076660156, 0.96875\n",
      "Train loss and acc of batch 6: 48.21534729003906, 0.96875\n",
      "Train loss and acc of batch 7: 47.71271514892578, 1.0\n",
      "Train loss and acc of batch 8: 48.30841064453125, 0.984375\n",
      "Train loss and acc of batch 9: 47.998558044433594, 0.984375\n",
      "Train loss and acc of batch 10: 47.71269226074219, 1.0\n",
      "Train loss and acc of batch 11: 47.712684631347656, 1.0\n",
      "Train loss and acc of batch 12: 48.46589660644531, 0.984375\n",
      "Train loss and acc of batch 13: 47.92942810058594, 0.984375\n",
      "Train loss and acc of batch 14: 47.92942810058594, 0.984375\n",
      "Train loss and acc of batch 15: 48.308349609375, 0.984375\n",
      "Train loss and acc of batch 16: 48.30833435058594, 0.984375\n",
      "Train loss and acc of batch 17: 48.46585464477539, 0.984375\n",
      "Train loss and acc of batch 18: 48.594173431396484, 0.96875\n",
      "Train loss and acc of batch 19: 47.71261215209961, 1.0\n",
      "Train loss and acc of batch 20: 47.71260452270508, 1.0\n",
      "Train loss and acc of batch 21: 48.30829620361328, 0.984375\n",
      "Train loss and acc of batch 22: 48.30828094482422, 0.984375\n",
      "Train loss and acc of batch 23: 47.712581634521484, 1.0\n",
      "Train loss and acc of batch 24: 48.308265686035156, 0.984375\n",
      "Train loss and acc of batch 25: 47.712562561035156, 1.0\n",
      "Train loss and acc of batch 26: 47.71255111694336, 1.0\n",
      "Train loss and acc of batch 27: 47.71254348754883, 1.0\n",
      "Train loss and acc of batch 28: 47.712528228759766, 1.0\n",
      "Train loss and acc of batch 29: 48.3082275390625, 0.984375\n",
      "Train loss and acc of batch 30: 47.71251678466797, 1.0\n",
      "Train loss and acc of batch 31: 47.92927551269531, 0.984375\n",
      "Train loss and acc of batch 32: 47.712493896484375, 1.0\n",
      "Train loss and acc of batch 33: 47.712486267089844, 1.0\n",
      "Train loss and acc of batch 34: 48.30818176269531, 0.984375\n",
      "Train loss and acc of batch 35: 48.14600372314453, 0.96875\n",
      "Train loss and acc of batch 36: 47.712459564208984, 1.0\n",
      "Train loss and acc of batch 37: 48.465675354003906, 0.984375\n",
      "Train loss and acc of batch 38: 49.061370849609375, 0.96875\n",
      "Train loss and acc of batch 39: 47.92919921875, 0.984375\n",
      "Train loss and acc of batch 40: 47.712425231933594, 1.0\n",
      "Train loss and acc of batch 41: 49.061344146728516, 0.96875\n",
      "Train loss and acc of batch 42: 47.71240997314453, 1.0\n",
      "Train loss and acc of batch 43: 48.30810546875, 0.984375\n",
      "Train loss and acc of batch 44: 47.7123908996582, 1.0\n",
      "Train loss and acc of batch 45: 48.308082580566406, 0.984375\n",
      "Train loss and acc of batch 46: 47.99822998046875, 0.984375\n",
      "Train loss and acc of batch 47: 47.712364196777344, 1.0\n",
      "Train loss and acc of batch 48: 47.71236038208008, 1.0\n",
      "Train loss and acc of batch 49: 47.71234893798828, 1.0\n",
      "Train loss and acc of batch 50: 48.30803680419922, 0.984375\n",
      "Train loss and acc of batch 51: 49.061256408691406, 0.96875\n",
      "Train loss and acc of batch 52: 48.968162536621094, 0.953125\n",
      "Train loss and acc of batch 53: 47.712310791015625, 1.0\n",
      "Train loss and acc of batch 54: 47.92906951904297, 0.984375\n",
      "Train loss and acc of batch 55: 47.7122917175293, 1.0\n",
      "Train loss and acc of batch 56: 47.71228790283203, 1.0\n",
      "Train loss and acc of batch 57: 48.30797576904297, 0.984375\n",
      "Train loss and acc of batch 58: 47.7122688293457, 1.0\n",
      "Train loss and acc of batch 59: 47.712257385253906, 1.0\n",
      "Train loss and acc of batch 60: 47.712249755859375, 1.0\n",
      "Train loss and acc of batch 61: 47.712242126464844, 1.0\n",
      "Train loss and acc of batch 62: 47.71223449707031, 1.0\n",
      "Train loss and acc of batch 63: 48.90362548828125, 0.96875\n",
      "Train loss and acc of batch 64: 47.928977966308594, 0.984375\n",
      "Train loss and acc of batch 65: 47.71220397949219, 1.0\n",
      "Train loss and acc of batch 66: 47.71220016479492, 1.0\n",
      "Train loss and acc of batch 67: 48.52465057373047, 0.96875\n",
      "Train loss and acc of batch 68: 48.30787658691406, 0.984375\n",
      "Train loss and acc of batch 69: 47.928932189941406, 0.984375\n",
      "Train loss and acc of batch 70: 47.712162017822266, 1.0\n",
      "Training accuracy and loss of epoch #548: 0.9897, 48.0334\n",
      "Saved model by train loss 48.033354423415496\n",
      "Train loss and acc of batch 0: 47.712154388427734, 1.0\n",
      "Train loss and acc of batch 1: 47.71214294433594, 1.0\n",
      "Train loss and acc of batch 2: 47.71213150024414, 1.0\n",
      "Train loss and acc of batch 3: 47.92888641357422, 0.984375\n",
      "Train loss and acc of batch 4: 47.71211624145508, 1.0\n",
      "Train loss and acc of batch 5: 49.06103515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.21471405029297, 0.96875\n",
      "Train loss and acc of batch 7: 47.71208953857422, 1.0\n",
      "Train loss and acc of batch 8: 48.30778503417969, 0.984375\n",
      "Train loss and acc of batch 9: 47.9979248046875, 0.984375\n",
      "Train loss and acc of batch 10: 47.71206283569336, 1.0\n",
      "Train loss and acc of batch 11: 47.71205139160156, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 12: 48.46527099609375, 0.984375\n",
      "Train loss and acc of batch 13: 47.928802490234375, 0.984375\n",
      "Train loss and acc of batch 14: 47.928794860839844, 0.984375\n",
      "Train loss and acc of batch 15: 48.30772399902344, 0.984375\n",
      "Train loss and acc of batch 16: 48.307708740234375, 0.984375\n",
      "Train loss and acc of batch 17: 48.4652214050293, 0.984375\n",
      "Train loss and acc of batch 18: 48.59354782104492, 0.96875\n",
      "Train loss and acc of batch 19: 47.71198654174805, 1.0\n",
      "Train loss and acc of batch 20: 47.71197509765625, 1.0\n",
      "Train loss and acc of batch 21: 48.30766296386719, 0.984375\n",
      "Train loss and acc of batch 22: 48.30766296386719, 0.984375\n",
      "Train loss and acc of batch 23: 47.71194839477539, 1.0\n",
      "Train loss and acc of batch 24: 48.307640075683594, 0.984375\n",
      "Train loss and acc of batch 25: 47.71192932128906, 1.0\n",
      "Train loss and acc of batch 26: 47.71192169189453, 1.0\n",
      "Train loss and acc of batch 27: 47.711910247802734, 1.0\n",
      "Train loss and acc of batch 28: 47.7119026184082, 1.0\n",
      "Train loss and acc of batch 29: 48.307594299316406, 0.984375\n",
      "Train loss and acc of batch 30: 47.71188735961914, 1.0\n",
      "Train loss and acc of batch 31: 47.92864227294922, 0.984375\n",
      "Train loss and acc of batch 32: 47.71186828613281, 1.0\n",
      "Train loss and acc of batch 33: 47.71186065673828, 1.0\n",
      "Train loss and acc of batch 34: 48.30754852294922, 0.984375\n",
      "Train loss and acc of batch 35: 48.14536666870117, 0.96875\n",
      "Train loss and acc of batch 36: 47.71183776855469, 1.0\n",
      "Train loss and acc of batch 37: 48.46504592895508, 0.984375\n",
      "Train loss and acc of batch 38: 49.06073760986328, 0.96875\n",
      "Train loss and acc of batch 39: 47.92857360839844, 0.984375\n",
      "Train loss and acc of batch 40: 47.711795806884766, 1.0\n",
      "Train loss and acc of batch 41: 49.06071472167969, 0.96875\n",
      "Train loss and acc of batch 42: 47.71178436279297, 1.0\n",
      "Train loss and acc of batch 43: 48.307472229003906, 0.984375\n",
      "Train loss and acc of batch 44: 47.71176528930664, 1.0\n",
      "Train loss and acc of batch 45: 48.30744934082031, 0.984375\n",
      "Train loss and acc of batch 46: 47.997596740722656, 0.984375\n",
      "Train loss and acc of batch 47: 47.711734771728516, 1.0\n",
      "Train loss and acc of batch 48: 47.71173095703125, 1.0\n",
      "Train loss and acc of batch 49: 47.71171569824219, 1.0\n",
      "Train loss and acc of batch 50: 48.307411193847656, 0.984375\n",
      "Train loss and acc of batch 51: 49.06062316894531, 0.96875\n",
      "Train loss and acc of batch 52: 48.967533111572266, 0.953125\n",
      "Train loss and acc of batch 53: 47.7116813659668, 1.0\n",
      "Train loss and acc of batch 54: 47.928436279296875, 0.984375\n",
      "Train loss and acc of batch 55: 47.71166229248047, 1.0\n",
      "Train loss and acc of batch 56: 47.71165466308594, 1.0\n",
      "Train loss and acc of batch 57: 48.307350158691406, 0.984375\n",
      "Train loss and acc of batch 58: 47.71163558959961, 1.0\n",
      "Train loss and acc of batch 59: 47.71162796020508, 1.0\n",
      "Train loss and acc of batch 60: 47.71162414550781, 1.0\n",
      "Train loss and acc of batch 61: 47.711612701416016, 1.0\n",
      "Train loss and acc of batch 62: 47.711605072021484, 1.0\n",
      "Train loss and acc of batch 63: 48.90299606323242, 0.96875\n",
      "Train loss and acc of batch 64: 47.92835235595703, 0.984375\n",
      "Train loss and acc of batch 65: 47.711578369140625, 1.0\n",
      "Train loss and acc of batch 66: 47.711570739746094, 1.0\n",
      "Train loss and acc of batch 67: 48.52402114868164, 0.96875\n",
      "Train loss and acc of batch 68: 48.30725860595703, 0.984375\n",
      "Train loss and acc of batch 69: 47.928306579589844, 0.984375\n",
      "Train loss and acc of batch 70: 47.71153259277344, 1.0\n",
      "Training accuracy and loss of epoch #549: 0.9897, 48.0327\n",
      "Saved model by train loss 48.03272537446358\n",
      "Train loss and acc of batch 0: 47.71152114868164, 1.0\n",
      "Train loss and acc of batch 1: 47.711509704589844, 1.0\n",
      "Train loss and acc of batch 2: 47.71150588989258, 1.0\n",
      "Train loss and acc of batch 3: 47.928260803222656, 0.984375\n",
      "Train loss and acc of batch 4: 47.711490631103516, 1.0\n",
      "Train loss and acc of batch 5: 49.060401916503906, 0.96875\n",
      "Train loss and acc of batch 6: 48.214088439941406, 0.96875\n",
      "Train loss and acc of batch 7: 47.71146011352539, 1.0\n",
      "Train loss and acc of batch 8: 48.307159423828125, 0.984375\n",
      "Train loss and acc of batch 9: 47.99729919433594, 0.984375\n",
      "Train loss and acc of batch 10: 47.71143341064453, 1.0\n",
      "Train loss and acc of batch 11: 47.71142578125, 1.0\n",
      "Train loss and acc of batch 12: 48.46464157104492, 0.984375\n",
      "Train loss and acc of batch 13: 47.92816925048828, 0.984375\n",
      "Train loss and acc of batch 14: 47.92816925048828, 0.984375\n",
      "Train loss and acc of batch 15: 48.307090759277344, 0.984375\n",
      "Train loss and acc of batch 16: 48.30708312988281, 0.984375\n",
      "Train loss and acc of batch 17: 48.464595794677734, 0.984375\n",
      "Train loss and acc of batch 18: 48.592918395996094, 0.96875\n",
      "Train loss and acc of batch 19: 47.71135330200195, 1.0\n",
      "Train loss and acc of batch 20: 47.71134567260742, 1.0\n",
      "Train loss and acc of batch 21: 48.307037353515625, 0.984375\n",
      "Train loss and acc of batch 22: 48.307029724121094, 0.984375\n",
      "Train loss and acc of batch 23: 47.71131896972656, 1.0\n",
      "Train loss and acc of batch 24: 48.30701446533203, 0.984375\n",
      "Train loss and acc of batch 25: 47.7113037109375, 1.0\n",
      "Train loss and acc of batch 26: 47.71129608154297, 1.0\n",
      "Train loss and acc of batch 27: 47.71128463745117, 1.0\n",
      "Train loss and acc of batch 28: 47.71127700805664, 1.0\n",
      "Train loss and acc of batch 29: 48.306968688964844, 0.984375\n",
      "Train loss and acc of batch 30: 47.71126174926758, 1.0\n",
      "Train loss and acc of batch 31: 47.928016662597656, 0.984375\n",
      "Train loss and acc of batch 32: 47.711238861083984, 1.0\n",
      "Train loss and acc of batch 33: 47.71123504638672, 1.0\n",
      "Train loss and acc of batch 34: 48.306915283203125, 0.984375\n",
      "Train loss and acc of batch 35: 48.14474105834961, 0.96875\n",
      "Train loss and acc of batch 36: 47.711204528808594, 1.0\n",
      "Train loss and acc of batch 37: 48.464420318603516, 0.984375\n",
      "Train loss and acc of batch 38: 49.06011199951172, 0.96875\n",
      "Train loss and acc of batch 39: 47.927940368652344, 0.984375\n",
      "Train loss and acc of batch 40: 47.7111701965332, 1.0\n",
      "Train loss and acc of batch 41: 49.060089111328125, 0.96875\n",
      "Train loss and acc of batch 42: 47.711151123046875, 1.0\n",
      "Train loss and acc of batch 43: 48.306846618652344, 0.984375\n",
      "Train loss and acc of batch 44: 47.71113204956055, 1.0\n",
      "Train loss and acc of batch 45: 48.30683135986328, 0.984375\n",
      "Train loss and acc of batch 46: 47.996971130371094, 0.984375\n",
      "Train loss and acc of batch 47: 47.71111297607422, 1.0\n",
      "Train loss and acc of batch 48: 47.711097717285156, 1.0\n",
      "Train loss and acc of batch 49: 47.71108627319336, 1.0\n",
      "Train loss and acc of batch 50: 48.30677795410156, 0.984375\n",
      "Train loss and acc of batch 51: 49.05999755859375, 0.96875\n",
      "Train loss and acc of batch 52: 48.96689987182617, 0.953125\n",
      "Train loss and acc of batch 53: 47.711055755615234, 1.0\n",
      "Train loss and acc of batch 54: 47.92781066894531, 0.984375\n",
      "Train loss and acc of batch 55: 47.71104049682617, 1.0\n",
      "Train loss and acc of batch 56: 47.71102523803711, 1.0\n",
      "Train loss and acc of batch 57: 48.30671691894531, 0.984375\n",
      "Train loss and acc of batch 58: 47.71100997924805, 1.0\n",
      "Train loss and acc of batch 59: 47.711002349853516, 1.0\n",
      "Train loss and acc of batch 60: 47.71099090576172, 1.0\n",
      "Train loss and acc of batch 61: 47.71098709106445, 1.0\n",
      "Train loss and acc of batch 62: 47.710975646972656, 1.0\n",
      "Train loss and acc of batch 63: 48.90237045288086, 0.96875\n",
      "Train loss and acc of batch 64: 47.92771911621094, 0.984375\n",
      "Train loss and acc of batch 65: 47.7109489440918, 1.0\n",
      "Train loss and acc of batch 66: 47.7109375, 1.0\n",
      "Train loss and acc of batch 67: 48.52339553833008, 0.96875\n",
      "Train loss and acc of batch 68: 48.30662536621094, 0.984375\n",
      "Train loss and acc of batch 69: 47.92768096923828, 0.984375\n",
      "Train loss and acc of batch 70: 47.71090316772461, 1.0\n",
      "Training accuracy and loss of epoch #550: 0.9897, 48.0321\n",
      "Saved model by train loss 48.03209718516175\n",
      "Train loss and acc of batch 0: 47.71089172363281, 1.0\n",
      "Train loss and acc of batch 1: 47.71088790893555, 1.0\n",
      "Train loss and acc of batch 2: 47.71087646484375, 1.0\n",
      "Train loss and acc of batch 3: 47.927635192871094, 0.984375\n",
      "Train loss and acc of batch 4: 47.71086502075195, 1.0\n",
      "Train loss and acc of batch 5: 49.059776306152344, 0.96875\n",
      "Train loss and acc of batch 6: 48.213462829589844, 0.96875\n",
      "Train loss and acc of batch 7: 47.71083450317383, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 8: 48.30652618408203, 0.984375\n",
      "Train loss and acc of batch 9: 47.996673583984375, 0.984375\n",
      "Train loss and acc of batch 10: 47.71080017089844, 1.0\n",
      "Train loss and acc of batch 11: 47.71079635620117, 1.0\n",
      "Train loss and acc of batch 12: 48.464012145996094, 0.984375\n",
      "Train loss and acc of batch 13: 47.92755126953125, 0.984375\n",
      "Train loss and acc of batch 14: 47.927528381347656, 0.984375\n",
      "Train loss and acc of batch 15: 48.30646514892578, 0.984375\n",
      "Train loss and acc of batch 16: 48.30644989013672, 0.984375\n",
      "Train loss and acc of batch 17: 48.46397018432617, 0.984375\n",
      "Train loss and acc of batch 18: 48.59228515625, 0.96875\n",
      "Train loss and acc of batch 19: 47.71072769165039, 1.0\n",
      "Train loss and acc of batch 20: 47.71072006225586, 1.0\n",
      "Train loss and acc of batch 21: 48.30641174316406, 0.984375\n",
      "Train loss and acc of batch 22: 48.306396484375, 0.984375\n",
      "Train loss and acc of batch 23: 47.710693359375, 1.0\n",
      "Train loss and acc of batch 24: 48.30638122558594, 0.984375\n",
      "Train loss and acc of batch 25: 47.710670471191406, 1.0\n",
      "Train loss and acc of batch 26: 47.71066665649414, 1.0\n",
      "Train loss and acc of batch 27: 47.710655212402344, 1.0\n",
      "Train loss and acc of batch 28: 47.71064376831055, 1.0\n",
      "Train loss and acc of batch 29: 48.30633544921875, 0.984375\n",
      "Train loss and acc of batch 30: 47.710628509521484, 1.0\n",
      "Train loss and acc of batch 31: 47.92738342285156, 0.984375\n",
      "Train loss and acc of batch 32: 47.71061325073242, 1.0\n",
      "Train loss and acc of batch 33: 47.710601806640625, 1.0\n",
      "Train loss and acc of batch 34: 48.306297302246094, 0.984375\n",
      "Train loss and acc of batch 35: 48.14411544799805, 0.96875\n",
      "Train loss and acc of batch 36: 47.71057891845703, 1.0\n",
      "Train loss and acc of batch 37: 48.46379089355469, 0.984375\n",
      "Train loss and acc of batch 38: 49.059486389160156, 0.96875\n",
      "Train loss and acc of batch 39: 47.92731475830078, 0.984375\n",
      "Train loss and acc of batch 40: 47.710540771484375, 1.0\n",
      "Train loss and acc of batch 41: 49.0594596862793, 0.96875\n",
      "Train loss and acc of batch 42: 47.71052169799805, 1.0\n",
      "Train loss and acc of batch 43: 48.30621337890625, 0.984375\n",
      "Train loss and acc of batch 44: 47.71050262451172, 1.0\n",
      "Train loss and acc of batch 45: 48.30619812011719, 0.984375\n",
      "Train loss and acc of batch 46: 47.99634552001953, 0.984375\n",
      "Train loss and acc of batch 47: 47.710479736328125, 1.0\n",
      "Train loss and acc of batch 48: 47.710472106933594, 1.0\n",
      "Train loss and acc of batch 49: 47.71046447753906, 1.0\n",
      "Train loss and acc of batch 50: 48.30615997314453, 0.984375\n",
      "Train loss and acc of batch 51: 49.059364318847656, 0.96875\n",
      "Train loss and acc of batch 52: 48.96627426147461, 0.953125\n",
      "Train loss and acc of batch 53: 47.710426330566406, 1.0\n",
      "Train loss and acc of batch 54: 47.92718505859375, 0.984375\n",
      "Train loss and acc of batch 55: 47.71040344238281, 1.0\n",
      "Train loss and acc of batch 56: 47.71039581298828, 1.0\n",
      "Train loss and acc of batch 57: 48.30609130859375, 0.984375\n",
      "Train loss and acc of batch 58: 47.71038055419922, 1.0\n",
      "Train loss and acc of batch 59: 47.71036911010742, 1.0\n",
      "Train loss and acc of batch 60: 47.710365295410156, 1.0\n",
      "Train loss and acc of batch 61: 47.710350036621094, 1.0\n",
      "Train loss and acc of batch 62: 47.71034622192383, 1.0\n",
      "Train loss and acc of batch 63: 48.901737213134766, 0.96875\n",
      "Train loss and acc of batch 64: 47.927093505859375, 0.984375\n",
      "Train loss and acc of batch 65: 47.7103157043457, 1.0\n",
      "Train loss and acc of batch 66: 47.71030807495117, 1.0\n",
      "Train loss and acc of batch 67: 48.52276611328125, 0.96875\n",
      "Train loss and acc of batch 68: 48.305992126464844, 0.984375\n",
      "Train loss and acc of batch 69: 47.92704772949219, 0.984375\n",
      "Train loss and acc of batch 70: 47.71027374267578, 1.0\n",
      "Training accuracy and loss of epoch #551: 0.9897, 48.0315\n",
      "Saved model by train loss 48.0314682436661\n",
      "Train loss and acc of batch 0: 47.71026611328125, 1.0\n",
      "Train loss and acc of batch 1: 47.71025466918945, 1.0\n",
      "Train loss and acc of batch 2: 47.71024703979492, 1.0\n",
      "Train loss and acc of batch 3: 47.92699432373047, 0.984375\n",
      "Train loss and acc of batch 4: 47.710227966308594, 1.0\n",
      "Train loss and acc of batch 5: 49.05914306640625, 0.96875\n",
      "Train loss and acc of batch 6: 48.21282958984375, 0.96875\n",
      "Train loss and acc of batch 7: 47.710205078125, 1.0\n",
      "Train loss and acc of batch 8: 48.30589294433594, 0.984375\n",
      "Train loss and acc of batch 9: 47.99603271484375, 0.984375\n",
      "Train loss and acc of batch 10: 47.71017837524414, 1.0\n",
      "Train loss and acc of batch 11: 47.71017074584961, 1.0\n",
      "Train loss and acc of batch 12: 48.46337890625, 0.984375\n",
      "Train loss and acc of batch 13: 47.926918029785156, 0.984375\n",
      "Train loss and acc of batch 14: 47.926910400390625, 0.984375\n",
      "Train loss and acc of batch 15: 48.30583190917969, 0.984375\n",
      "Train loss and acc of batch 16: 48.30583190917969, 0.984375\n",
      "Train loss and acc of batch 17: 48.46333694458008, 0.984375\n",
      "Train loss and acc of batch 18: 48.59165954589844, 0.96875\n",
      "Train loss and acc of batch 19: 47.7100944519043, 1.0\n",
      "Train loss and acc of batch 20: 47.71009063720703, 1.0\n",
      "Train loss and acc of batch 21: 48.30577850341797, 0.984375\n",
      "Train loss and acc of batch 22: 48.30577087402344, 0.984375\n",
      "Train loss and acc of batch 23: 47.710060119628906, 1.0\n",
      "Train loss and acc of batch 24: 48.305755615234375, 0.984375\n",
      "Train loss and acc of batch 25: 47.710044860839844, 1.0\n",
      "Train loss and acc of batch 26: 47.71003723144531, 1.0\n",
      "Train loss and acc of batch 27: 47.710025787353516, 1.0\n",
      "Train loss and acc of batch 28: 47.710018157958984, 1.0\n",
      "Train loss and acc of batch 29: 48.30570983886719, 0.984375\n",
      "Train loss and acc of batch 30: 47.709999084472656, 1.0\n",
      "Train loss and acc of batch 31: 47.92675018310547, 0.984375\n",
      "Train loss and acc of batch 32: 47.70998001098633, 1.0\n",
      "Train loss and acc of batch 33: 47.7099723815918, 1.0\n",
      "Train loss and acc of batch 34: 48.3056640625, 0.984375\n",
      "Train loss and acc of batch 35: 48.14348220825195, 0.96875\n",
      "Train loss and acc of batch 36: 47.70994567871094, 1.0\n",
      "Train loss and acc of batch 37: 48.46316146850586, 0.984375\n",
      "Train loss and acc of batch 38: 49.05885314941406, 0.96875\n",
      "Train loss and acc of batch 39: 47.92668151855469, 0.984375\n",
      "Train loss and acc of batch 40: 47.70991134643555, 1.0\n",
      "Train loss and acc of batch 41: 49.05883026123047, 0.96875\n",
      "Train loss and acc of batch 42: 47.709896087646484, 1.0\n",
      "Train loss and acc of batch 43: 48.30558776855469, 0.984375\n",
      "Train loss and acc of batch 44: 47.70988082885742, 1.0\n",
      "Train loss and acc of batch 45: 48.305572509765625, 0.984375\n",
      "Train loss and acc of batch 46: 47.995704650878906, 0.984375\n",
      "Train loss and acc of batch 47: 47.70984649658203, 1.0\n",
      "Train loss and acc of batch 48: 47.709842681884766, 1.0\n",
      "Train loss and acc of batch 49: 47.709835052490234, 1.0\n",
      "Train loss and acc of batch 50: 48.305519104003906, 0.984375\n",
      "Train loss and acc of batch 51: 49.058738708496094, 0.96875\n",
      "Train loss and acc of batch 52: 48.96564483642578, 0.953125\n",
      "Train loss and acc of batch 53: 47.70979690551758, 1.0\n",
      "Train loss and acc of batch 54: 47.926551818847656, 0.984375\n",
      "Train loss and acc of batch 55: 47.70977783203125, 1.0\n",
      "Train loss and acc of batch 56: 47.70977020263672, 1.0\n",
      "Train loss and acc of batch 57: 48.30546569824219, 0.984375\n",
      "Train loss and acc of batch 58: 47.709754943847656, 1.0\n",
      "Train loss and acc of batch 59: 47.70974349975586, 1.0\n",
      "Train loss and acc of batch 60: 47.7097282409668, 1.0\n",
      "Train loss and acc of batch 61: 47.70972442626953, 1.0\n",
      "Train loss and acc of batch 62: 47.709712982177734, 1.0\n",
      "Train loss and acc of batch 63: 48.9011116027832, 0.96875\n",
      "Train loss and acc of batch 64: 47.92646789550781, 0.984375\n",
      "Train loss and acc of batch 65: 47.70969009399414, 1.0\n",
      "Train loss and acc of batch 66: 47.70968246459961, 1.0\n",
      "Train loss and acc of batch 67: 48.52213668823242, 0.96875\n",
      "Train loss and acc of batch 68: 48.30536651611328, 0.984375\n",
      "Train loss and acc of batch 69: 47.926414489746094, 0.984375\n",
      "Train loss and acc of batch 70: 47.70964431762695, 1.0\n",
      "Training accuracy and loss of epoch #552: 0.9897, 48.0308\n",
      "Saved model by train loss 48.030838549976615\n",
      "Train loss and acc of batch 0: 47.70963668823242, 1.0\n",
      "Train loss and acc of batch 1: 47.70962905883789, 1.0\n",
      "Train loss and acc of batch 2: 47.709617614746094, 1.0\n",
      "Train loss and acc of batch 3: 47.92637634277344, 0.984375\n",
      "Train loss and acc of batch 4: 47.70960235595703, 1.0\n",
      "Train loss and acc of batch 5: 49.05851745605469, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 6: 48.21220397949219, 0.96875\n",
      "Train loss and acc of batch 7: 47.70957565307617, 1.0\n",
      "Train loss and acc of batch 8: 48.305267333984375, 0.984375\n",
      "Train loss and acc of batch 9: 47.99540710449219, 0.984375\n",
      "Train loss and acc of batch 10: 47.70954895019531, 1.0\n",
      "Train loss and acc of batch 11: 47.70954132080078, 1.0\n",
      "Train loss and acc of batch 12: 48.46275329589844, 0.984375\n",
      "Train loss and acc of batch 13: 47.92628479003906, 0.984375\n",
      "Train loss and acc of batch 14: 47.92627716064453, 0.984375\n",
      "Train loss and acc of batch 15: 48.305206298828125, 0.984375\n",
      "Train loss and acc of batch 16: 48.30519104003906, 0.984375\n",
      "Train loss and acc of batch 17: 48.462711334228516, 0.984375\n",
      "Train loss and acc of batch 18: 48.59103012084961, 0.96875\n",
      "Train loss and acc of batch 19: 47.709468841552734, 1.0\n",
      "Train loss and acc of batch 20: 47.7094612121582, 1.0\n",
      "Train loss and acc of batch 21: 48.305152893066406, 0.984375\n",
      "Train loss and acc of batch 22: 48.305145263671875, 0.984375\n",
      "Train loss and acc of batch 23: 47.709434509277344, 1.0\n",
      "Train loss and acc of batch 24: 48.30513000488281, 0.984375\n",
      "Train loss and acc of batch 25: 47.70941925048828, 1.0\n",
      "Train loss and acc of batch 26: 47.70940399169922, 1.0\n",
      "Train loss and acc of batch 27: 47.70939636230469, 1.0\n",
      "Train loss and acc of batch 28: 47.70938491821289, 1.0\n",
      "Train loss and acc of batch 29: 48.305084228515625, 0.984375\n",
      "Train loss and acc of batch 30: 47.709373474121094, 1.0\n",
      "Train loss and acc of batch 31: 47.92613220214844, 0.984375\n",
      "Train loss and acc of batch 32: 47.709354400634766, 1.0\n",
      "Train loss and acc of batch 33: 47.70934295654297, 1.0\n",
      "Train loss and acc of batch 34: 48.30503845214844, 0.984375\n",
      "Train loss and acc of batch 35: 48.14285659790039, 0.96875\n",
      "Train loss and acc of batch 36: 47.70931625366211, 1.0\n",
      "Train loss and acc of batch 37: 48.4625358581543, 0.984375\n",
      "Train loss and acc of batch 38: 49.0582275390625, 0.96875\n",
      "Train loss and acc of batch 39: 47.926055908203125, 0.984375\n",
      "Train loss and acc of batch 40: 47.70927810668945, 1.0\n",
      "Train loss and acc of batch 41: 49.05819320678711, 0.96875\n",
      "Train loss and acc of batch 42: 47.70926284790039, 1.0\n",
      "Train loss and acc of batch 43: 48.304954528808594, 0.984375\n",
      "Train loss and acc of batch 44: 47.70924377441406, 1.0\n",
      "Train loss and acc of batch 45: 48.304931640625, 0.984375\n",
      "Train loss and acc of batch 46: 47.995079040527344, 0.984375\n",
      "Train loss and acc of batch 47: 47.70921325683594, 1.0\n",
      "Train loss and acc of batch 48: 47.70920944213867, 1.0\n",
      "Train loss and acc of batch 49: 47.709197998046875, 1.0\n",
      "Train loss and acc of batch 50: 48.304893493652344, 0.984375\n",
      "Train loss and acc of batch 51: 49.05810546875, 0.96875\n",
      "Train loss and acc of batch 52: 48.96501541137695, 0.953125\n",
      "Train loss and acc of batch 53: 47.709163665771484, 1.0\n",
      "Train loss and acc of batch 54: 47.92591857910156, 0.984375\n",
      "Train loss and acc of batch 55: 47.70914077758789, 1.0\n",
      "Train loss and acc of batch 56: 47.70914077758789, 1.0\n",
      "Train loss and acc of batch 57: 48.304832458496094, 0.984375\n",
      "Train loss and acc of batch 58: 47.70912170410156, 1.0\n",
      "Train loss and acc of batch 59: 47.709110260009766, 1.0\n",
      "Train loss and acc of batch 60: 47.709102630615234, 1.0\n",
      "Train loss and acc of batch 61: 47.7090950012207, 1.0\n",
      "Train loss and acc of batch 62: 47.709083557128906, 1.0\n",
      "Train loss and acc of batch 63: 48.900482177734375, 0.96875\n",
      "Train loss and acc of batch 64: 47.92583465576172, 0.984375\n",
      "Train loss and acc of batch 65: 47.70905685424805, 1.0\n",
      "Train loss and acc of batch 66: 47.70905303955078, 1.0\n",
      "Train loss and acc of batch 67: 48.521507263183594, 0.96875\n",
      "Train loss and acc of batch 68: 48.30473327636719, 0.984375\n",
      "Train loss and acc of batch 69: 47.92578125, 0.984375\n",
      "Train loss and acc of batch 70: 47.70901107788086, 1.0\n",
      "Training accuracy and loss of epoch #553: 0.9897, 48.0302\n",
      "Saved model by train loss 48.03020901747153\n",
      "Train loss and acc of batch 0: 47.70900344848633, 1.0\n",
      "Train loss and acc of batch 1: 47.7089958190918, 1.0\n",
      "Train loss and acc of batch 2: 47.708988189697266, 1.0\n",
      "Train loss and acc of batch 3: 47.925743103027344, 0.984375\n",
      "Train loss and acc of batch 4: 47.70896911621094, 1.0\n",
      "Train loss and acc of batch 5: 49.057891845703125, 0.96875\n",
      "Train loss and acc of batch 6: 48.21156692504883, 0.96875\n",
      "Train loss and acc of batch 7: 47.70894241333008, 1.0\n",
      "Train loss and acc of batch 8: 48.30463409423828, 0.984375\n",
      "Train loss and acc of batch 9: 47.994781494140625, 0.984375\n",
      "Train loss and acc of batch 10: 47.70891571044922, 1.0\n",
      "Train loss and acc of batch 11: 47.70891189575195, 1.0\n",
      "Train loss and acc of batch 12: 48.46212387084961, 0.984375\n",
      "Train loss and acc of batch 13: 47.92565155029297, 0.984375\n",
      "Train loss and acc of batch 14: 47.92564392089844, 0.984375\n",
      "Train loss and acc of batch 15: 48.30457305908203, 0.984375\n",
      "Train loss and acc of batch 16: 48.3045654296875, 0.984375\n",
      "Train loss and acc of batch 17: 48.46207809448242, 0.984375\n",
      "Train loss and acc of batch 18: 48.59040069580078, 0.96875\n",
      "Train loss and acc of batch 19: 47.70883560180664, 1.0\n",
      "Train loss and acc of batch 20: 47.70882797241211, 1.0\n",
      "Train loss and acc of batch 21: 48.30451965332031, 0.984375\n",
      "Train loss and acc of batch 22: 48.30451202392578, 0.984375\n",
      "Train loss and acc of batch 23: 47.70880126953125, 1.0\n",
      "Train loss and acc of batch 24: 48.30449676513672, 0.984375\n",
      "Train loss and acc of batch 25: 47.70878601074219, 1.0\n",
      "Train loss and acc of batch 26: 47.708778381347656, 1.0\n",
      "Train loss and acc of batch 27: 47.708763122558594, 1.0\n",
      "Train loss and acc of batch 28: 47.70875930786133, 1.0\n",
      "Train loss and acc of batch 29: 48.30445098876953, 0.984375\n",
      "Train loss and acc of batch 30: 47.708740234375, 1.0\n",
      "Train loss and acc of batch 31: 47.92549133300781, 0.984375\n",
      "Train loss and acc of batch 32: 47.70872116088867, 1.0\n",
      "Train loss and acc of batch 33: 47.70871353149414, 1.0\n",
      "Train loss and acc of batch 34: 48.304405212402344, 0.984375\n",
      "Train loss and acc of batch 35: 48.14221954345703, 0.96875\n",
      "Train loss and acc of batch 36: 47.708683013916016, 1.0\n",
      "Train loss and acc of batch 37: 48.46189880371094, 0.984375\n",
      "Train loss and acc of batch 38: 49.057594299316406, 0.96875\n",
      "Train loss and acc of batch 39: 47.92542266845703, 0.984375\n",
      "Train loss and acc of batch 40: 47.70865249633789, 1.0\n",
      "Train loss and acc of batch 41: 49.05756759643555, 0.96875\n",
      "Train loss and acc of batch 42: 47.70863342285156, 1.0\n",
      "Train loss and acc of batch 43: 48.3043212890625, 0.984375\n",
      "Train loss and acc of batch 44: 47.708614349365234, 1.0\n",
      "Train loss and acc of batch 45: 48.30430603027344, 0.984375\n",
      "Train loss and acc of batch 46: 47.99444580078125, 0.984375\n",
      "Train loss and acc of batch 47: 47.70859146118164, 1.0\n",
      "Train loss and acc of batch 48: 47.70858383178711, 1.0\n",
      "Train loss and acc of batch 49: 47.70857238769531, 1.0\n",
      "Train loss and acc of batch 50: 48.30426025390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.05747985839844, 0.96875\n",
      "Train loss and acc of batch 52: 48.964385986328125, 0.953125\n",
      "Train loss and acc of batch 53: 47.70853805541992, 1.0\n",
      "Train loss and acc of batch 54: 47.92529296875, 0.984375\n",
      "Train loss and acc of batch 55: 47.708518981933594, 1.0\n",
      "Train loss and acc of batch 56: 47.7085075378418, 1.0\n",
      "Train loss and acc of batch 57: 48.30419921875, 0.984375\n",
      "Train loss and acc of batch 58: 47.70848846435547, 1.0\n",
      "Train loss and acc of batch 59: 47.7084846496582, 1.0\n",
      "Train loss and acc of batch 60: 47.708473205566406, 1.0\n",
      "Train loss and acc of batch 61: 47.708465576171875, 1.0\n",
      "Train loss and acc of batch 62: 47.708457946777344, 1.0\n",
      "Train loss and acc of batch 63: 48.89984893798828, 0.96875\n",
      "Train loss and acc of batch 64: 47.925201416015625, 0.984375\n",
      "Train loss and acc of batch 65: 47.70842742919922, 1.0\n",
      "Train loss and acc of batch 66: 47.70841979980469, 1.0\n",
      "Train loss and acc of batch 67: 48.520877838134766, 0.96875\n",
      "Train loss and acc of batch 68: 48.304100036621094, 0.984375\n",
      "Train loss and acc of batch 69: 47.92516326904297, 0.984375\n",
      "Train loss and acc of batch 70: 47.7083854675293, 1.0\n",
      "Training accuracy and loss of epoch #554: 0.9897, 48.0296\n",
      "Saved model by train loss 48.02957841040383\n",
      "Train loss and acc of batch 0: 47.708377838134766, 1.0\n",
      "Train loss and acc of batch 1: 47.7083625793457, 1.0\n",
      "Train loss and acc of batch 2: 47.70835876464844, 1.0\n",
      "Train loss and acc of batch 3: 47.92510986328125, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 4: 47.708343505859375, 1.0\n",
      "Train loss and acc of batch 5: 49.05725860595703, 0.96875\n",
      "Train loss and acc of batch 6: 48.2109375, 0.96875\n",
      "Train loss and acc of batch 7: 47.70831298828125, 1.0\n",
      "Train loss and acc of batch 8: 48.30400085449219, 0.984375\n",
      "Train loss and acc of batch 9: 47.99414825439453, 0.984375\n",
      "Train loss and acc of batch 10: 47.70828628540039, 1.0\n",
      "Train loss and acc of batch 11: 47.70827865600586, 1.0\n",
      "Train loss and acc of batch 12: 48.46149444580078, 0.984375\n",
      "Train loss and acc of batch 13: 47.925025939941406, 0.984375\n",
      "Train loss and acc of batch 14: 47.925018310546875, 0.984375\n",
      "Train loss and acc of batch 15: 48.30394744873047, 0.984375\n",
      "Train loss and acc of batch 16: 48.303932189941406, 0.984375\n",
      "Train loss and acc of batch 17: 48.461448669433594, 0.984375\n",
      "Train loss and acc of batch 18: 48.58977508544922, 0.96875\n",
      "Train loss and acc of batch 19: 47.70820999145508, 1.0\n",
      "Train loss and acc of batch 20: 47.70819854736328, 1.0\n",
      "Train loss and acc of batch 21: 48.30389404296875, 0.984375\n",
      "Train loss and acc of batch 22: 48.30387878417969, 0.984375\n",
      "Train loss and acc of batch 23: 47.70817184448242, 1.0\n",
      "Train loss and acc of batch 24: 48.303863525390625, 0.984375\n",
      "Train loss and acc of batch 25: 47.708152770996094, 1.0\n",
      "Train loss and acc of batch 26: 47.70814514160156, 1.0\n",
      "Train loss and acc of batch 27: 47.70813751220703, 1.0\n",
      "Train loss and acc of batch 28: 47.7081298828125, 1.0\n",
      "Train loss and acc of batch 29: 48.30382537841797, 0.984375\n",
      "Train loss and acc of batch 30: 47.708106994628906, 1.0\n",
      "Train loss and acc of batch 31: 47.92486572265625, 0.984375\n",
      "Train loss and acc of batch 32: 47.70809555053711, 1.0\n",
      "Train loss and acc of batch 33: 47.70808792114258, 1.0\n",
      "Train loss and acc of batch 34: 48.30377197265625, 0.984375\n",
      "Train loss and acc of batch 35: 48.14159393310547, 0.96875\n",
      "Train loss and acc of batch 36: 47.70805740356445, 1.0\n",
      "Train loss and acc of batch 37: 48.461273193359375, 0.984375\n",
      "Train loss and acc of batch 38: 49.056968688964844, 0.96875\n",
      "Train loss and acc of batch 39: 47.92478942871094, 0.984375\n",
      "Train loss and acc of batch 40: 47.7080192565918, 1.0\n",
      "Train loss and acc of batch 41: 49.05693817138672, 0.96875\n",
      "Train loss and acc of batch 42: 47.708003997802734, 1.0\n",
      "Train loss and acc of batch 43: 48.30370330810547, 0.984375\n",
      "Train loss and acc of batch 44: 47.707984924316406, 1.0\n",
      "Train loss and acc of batch 45: 48.303680419921875, 0.984375\n",
      "Train loss and acc of batch 46: 47.99382019042969, 0.984375\n",
      "Train loss and acc of batch 47: 47.70795822143555, 1.0\n",
      "Train loss and acc of batch 48: 47.707950592041016, 1.0\n",
      "Train loss and acc of batch 49: 47.707942962646484, 1.0\n",
      "Train loss and acc of batch 50: 48.30363464355469, 0.984375\n",
      "Train loss and acc of batch 51: 49.056846618652344, 0.96875\n",
      "Train loss and acc of batch 52: 48.96375274658203, 0.953125\n",
      "Train loss and acc of batch 53: 47.707908630371094, 1.0\n",
      "Train loss and acc of batch 54: 47.924659729003906, 0.984375\n",
      "Train loss and acc of batch 55: 47.707889556884766, 1.0\n",
      "Train loss and acc of batch 56: 47.707881927490234, 1.0\n",
      "Train loss and acc of batch 57: 48.30357360839844, 0.984375\n",
      "Train loss and acc of batch 58: 47.70785903930664, 1.0\n",
      "Train loss and acc of batch 59: 47.707847595214844, 1.0\n",
      "Train loss and acc of batch 60: 47.70784378051758, 1.0\n",
      "Train loss and acc of batch 61: 47.70783615112305, 1.0\n",
      "Train loss and acc of batch 62: 47.707828521728516, 1.0\n",
      "Train loss and acc of batch 63: 48.89922332763672, 0.96875\n",
      "Train loss and acc of batch 64: 47.92457580566406, 0.984375\n",
      "Train loss and acc of batch 65: 47.707801818847656, 1.0\n",
      "Train loss and acc of batch 66: 47.707794189453125, 1.0\n",
      "Train loss and acc of batch 67: 48.52024841308594, 0.96875\n",
      "Train loss and acc of batch 68: 48.30347442626953, 0.984375\n",
      "Train loss and acc of batch 69: 47.924530029296875, 0.984375\n",
      "Train loss and acc of batch 70: 47.707759857177734, 1.0\n",
      "Training accuracy and loss of epoch #555: 0.9897, 48.0289\n",
      "Saved model by train loss 48.028949415180044\n",
      "Train loss and acc of batch 0: 47.70774841308594, 1.0\n",
      "Train loss and acc of batch 1: 47.707740783691406, 1.0\n",
      "Train loss and acc of batch 2: 47.707725524902344, 1.0\n",
      "Train loss and acc of batch 3: 47.92448425292969, 0.984375\n",
      "Train loss and acc of batch 4: 47.70771026611328, 1.0\n",
      "Train loss and acc of batch 5: 49.05662536621094, 0.96875\n",
      "Train loss and acc of batch 6: 48.21030807495117, 0.96875\n",
      "Train loss and acc of batch 7: 47.70768737792969, 1.0\n",
      "Train loss and acc of batch 8: 48.303382873535156, 0.984375\n",
      "Train loss and acc of batch 9: 47.99352264404297, 0.984375\n",
      "Train loss and acc of batch 10: 47.70765686035156, 1.0\n",
      "Train loss and acc of batch 11: 47.70764923095703, 1.0\n",
      "Train loss and acc of batch 12: 48.46086120605469, 0.984375\n",
      "Train loss and acc of batch 13: 47.924400329589844, 0.984375\n",
      "Train loss and acc of batch 14: 47.92438507080078, 0.984375\n",
      "Train loss and acc of batch 15: 48.303314208984375, 0.984375\n",
      "Train loss and acc of batch 16: 48.303306579589844, 0.984375\n",
      "Train loss and acc of batch 17: 48.460819244384766, 0.984375\n",
      "Train loss and acc of batch 18: 48.589141845703125, 0.96875\n",
      "Train loss and acc of batch 19: 47.707576751708984, 1.0\n",
      "Train loss and acc of batch 20: 47.70756912231445, 1.0\n",
      "Train loss and acc of batch 21: 48.303260803222656, 0.984375\n",
      "Train loss and acc of batch 22: 48.303253173828125, 0.984375\n",
      "Train loss and acc of batch 23: 47.70754623413086, 1.0\n",
      "Train loss and acc of batch 24: 48.30323791503906, 0.984375\n",
      "Train loss and acc of batch 25: 47.707523345947266, 1.0\n",
      "Train loss and acc of batch 26: 47.707515716552734, 1.0\n",
      "Train loss and acc of batch 27: 47.70751190185547, 1.0\n",
      "Train loss and acc of batch 28: 47.70750045776367, 1.0\n",
      "Train loss and acc of batch 29: 48.303192138671875, 0.984375\n",
      "Train loss and acc of batch 30: 47.707481384277344, 1.0\n",
      "Train loss and acc of batch 31: 47.92424011230469, 0.984375\n",
      "Train loss and acc of batch 32: 47.70746612548828, 1.0\n",
      "Train loss and acc of batch 33: 47.70745086669922, 1.0\n",
      "Train loss and acc of batch 34: 48.30314636230469, 0.984375\n",
      "Train loss and acc of batch 35: 48.14096450805664, 0.96875\n",
      "Train loss and acc of batch 36: 47.70743179321289, 1.0\n",
      "Train loss and acc of batch 37: 48.46064376831055, 0.984375\n",
      "Train loss and acc of batch 38: 49.05633544921875, 0.96875\n",
      "Train loss and acc of batch 39: 47.924163818359375, 0.984375\n",
      "Train loss and acc of batch 40: 47.707393646240234, 1.0\n",
      "Train loss and acc of batch 41: 49.056312561035156, 0.96875\n",
      "Train loss and acc of batch 42: 47.707374572753906, 1.0\n",
      "Train loss and acc of batch 43: 48.303070068359375, 0.984375\n",
      "Train loss and acc of batch 44: 47.70736312866211, 1.0\n",
      "Train loss and acc of batch 45: 48.30305480957031, 0.984375\n",
      "Train loss and acc of batch 46: 47.993194580078125, 0.984375\n",
      "Train loss and acc of batch 47: 47.70732879638672, 1.0\n",
      "Train loss and acc of batch 48: 47.70732116699219, 1.0\n",
      "Train loss and acc of batch 49: 47.70730972290039, 1.0\n",
      "Train loss and acc of batch 50: 48.303009033203125, 0.984375\n",
      "Train loss and acc of batch 51: 49.05622100830078, 0.96875\n",
      "Train loss and acc of batch 52: 48.96312713623047, 0.953125\n",
      "Train loss and acc of batch 53: 47.707275390625, 1.0\n",
      "Train loss and acc of batch 54: 47.924034118652344, 0.984375\n",
      "Train loss and acc of batch 55: 47.70726013183594, 1.0\n",
      "Train loss and acc of batch 56: 47.70724868774414, 1.0\n",
      "Train loss and acc of batch 57: 48.302940368652344, 0.984375\n",
      "Train loss and acc of batch 58: 47.707237243652344, 1.0\n",
      "Train loss and acc of batch 59: 47.70722579956055, 1.0\n",
      "Train loss and acc of batch 60: 47.707218170166016, 1.0\n",
      "Train loss and acc of batch 61: 47.70720672607422, 1.0\n",
      "Train loss and acc of batch 62: 47.70719909667969, 1.0\n",
      "Train loss and acc of batch 63: 48.898590087890625, 0.96875\n",
      "Train loss and acc of batch 64: 47.92394256591797, 0.984375\n",
      "Train loss and acc of batch 65: 47.70717239379883, 1.0\n",
      "Train loss and acc of batch 66: 47.70716094970703, 1.0\n",
      "Train loss and acc of batch 67: 48.51961898803711, 0.96875\n",
      "Train loss and acc of batch 68: 48.30284881591797, 0.984375\n",
      "Train loss and acc of batch 69: 47.92390441894531, 0.984375\n",
      "Train loss and acc of batch 70: 47.707122802734375, 1.0\n",
      "Training accuracy and loss of epoch #556: 0.9897, 48.0283\n",
      "Saved model by train loss 48.028320688596914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 0: 47.70711898803711, 1.0\n",
      "Train loss and acc of batch 1: 47.70711135864258, 1.0\n",
      "Train loss and acc of batch 2: 47.70710372924805, 1.0\n",
      "Train loss and acc of batch 3: 47.923858642578125, 0.984375\n",
      "Train loss and acc of batch 4: 47.70708465576172, 1.0\n",
      "Train loss and acc of batch 5: 49.055992126464844, 0.96875\n",
      "Train loss and acc of batch 6: 48.209678649902344, 0.96875\n",
      "Train loss and acc of batch 7: 47.707054138183594, 1.0\n",
      "Train loss and acc of batch 8: 48.30274963378906, 0.984375\n",
      "Train loss and acc of batch 9: 47.992889404296875, 0.984375\n",
      "Train loss and acc of batch 10: 47.70703125, 1.0\n",
      "Train loss and acc of batch 11: 47.70702362060547, 1.0\n",
      "Train loss and acc of batch 12: 48.46023941040039, 0.984375\n",
      "Train loss and acc of batch 13: 47.92375946044922, 0.984375\n",
      "Train loss and acc of batch 14: 47.92375946044922, 0.984375\n",
      "Train loss and acc of batch 15: 48.30268859863281, 0.984375\n",
      "Train loss and acc of batch 16: 48.30268096923828, 0.984375\n",
      "Train loss and acc of batch 17: 48.46018981933594, 0.984375\n",
      "Train loss and acc of batch 18: 48.58851623535156, 0.96875\n",
      "Train loss and acc of batch 19: 47.706947326660156, 1.0\n",
      "Train loss and acc of batch 20: 47.706939697265625, 1.0\n",
      "Train loss and acc of batch 21: 48.30262756347656, 0.984375\n",
      "Train loss and acc of batch 22: 48.30261993408203, 0.984375\n",
      "Train loss and acc of batch 23: 47.706912994384766, 1.0\n",
      "Train loss and acc of batch 24: 48.30260467529297, 0.984375\n",
      "Train loss and acc of batch 25: 47.70689392089844, 1.0\n",
      "Train loss and acc of batch 26: 47.70689392089844, 1.0\n",
      "Train loss and acc of batch 27: 47.706878662109375, 1.0\n",
      "Train loss and acc of batch 28: 47.706871032714844, 1.0\n",
      "Train loss and acc of batch 29: 48.30255889892578, 0.984375\n",
      "Train loss and acc of batch 30: 47.706851959228516, 1.0\n",
      "Train loss and acc of batch 31: 47.923606872558594, 0.984375\n",
      "Train loss and acc of batch 32: 47.70683670043945, 1.0\n",
      "Train loss and acc of batch 33: 47.706825256347656, 1.0\n",
      "Train loss and acc of batch 34: 48.302520751953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.14033889770508, 0.96875\n",
      "Train loss and acc of batch 36: 47.70680236816406, 1.0\n",
      "Train loss and acc of batch 37: 48.46001434326172, 0.984375\n",
      "Train loss and acc of batch 38: 49.055702209472656, 0.96875\n",
      "Train loss and acc of batch 39: 47.92353820800781, 0.984375\n",
      "Train loss and acc of batch 40: 47.706764221191406, 1.0\n",
      "Train loss and acc of batch 41: 49.05568313598633, 0.96875\n",
      "Train loss and acc of batch 42: 47.70674133300781, 1.0\n",
      "Train loss and acc of batch 43: 48.30243682861328, 0.984375\n",
      "Train loss and acc of batch 44: 47.706729888916016, 1.0\n",
      "Train loss and acc of batch 45: 48.30242156982422, 0.984375\n",
      "Train loss and acc of batch 46: 47.99256134033203, 0.984375\n",
      "Train loss and acc of batch 47: 47.706703186035156, 1.0\n",
      "Train loss and acc of batch 48: 47.706695556640625, 1.0\n",
      "Train loss and acc of batch 49: 47.706687927246094, 1.0\n",
      "Train loss and acc of batch 50: 48.30237579345703, 0.984375\n",
      "Train loss and acc of batch 51: 49.05559539794922, 0.96875\n",
      "Train loss and acc of batch 52: 48.962493896484375, 0.953125\n",
      "Train loss and acc of batch 53: 47.7066535949707, 1.0\n",
      "Train loss and acc of batch 54: 47.92340850830078, 0.984375\n",
      "Train loss and acc of batch 55: 47.70663070678711, 1.0\n",
      "Train loss and acc of batch 56: 47.70661926269531, 1.0\n",
      "Train loss and acc of batch 57: 48.30231475830078, 0.984375\n",
      "Train loss and acc of batch 58: 47.70660400390625, 1.0\n",
      "Train loss and acc of batch 59: 47.70659255981445, 1.0\n",
      "Train loss and acc of batch 60: 47.70658493041992, 1.0\n",
      "Train loss and acc of batch 61: 47.70657730102539, 1.0\n",
      "Train loss and acc of batch 62: 47.70656967163086, 1.0\n",
      "Train loss and acc of batch 63: 48.89796829223633, 0.96875\n",
      "Train loss and acc of batch 64: 47.923316955566406, 0.984375\n",
      "Train loss and acc of batch 65: 47.70654296875, 1.0\n",
      "Train loss and acc of batch 66: 47.70653533935547, 1.0\n",
      "Train loss and acc of batch 67: 48.51898956298828, 0.96875\n",
      "Train loss and acc of batch 68: 48.302215576171875, 0.984375\n",
      "Train loss and acc of batch 69: 47.92327880859375, 0.984375\n",
      "Train loss and acc of batch 70: 47.70649719238281, 1.0\n",
      "Training accuracy and loss of epoch #557: 0.9897, 48.0277\n",
      "Saved model by train loss 48.027691639645\n",
      "Train loss and acc of batch 0: 47.70648956298828, 1.0\n",
      "Train loss and acc of batch 1: 47.70648193359375, 1.0\n",
      "Train loss and acc of batch 2: 47.70647430419922, 1.0\n",
      "Train loss and acc of batch 3: 47.92322540283203, 0.984375\n",
      "Train loss and acc of batch 4: 47.706451416015625, 1.0\n",
      "Train loss and acc of batch 5: 49.05536651611328, 0.96875\n",
      "Train loss and acc of batch 6: 48.20905685424805, 0.96875\n",
      "Train loss and acc of batch 7: 47.70642852783203, 1.0\n",
      "Train loss and acc of batch 8: 48.30211639404297, 0.984375\n",
      "Train loss and acc of batch 9: 47.99226379394531, 0.984375\n",
      "Train loss and acc of batch 10: 47.70640182495117, 1.0\n",
      "Train loss and acc of batch 11: 47.70639419555664, 1.0\n",
      "Train loss and acc of batch 12: 48.45960998535156, 0.984375\n",
      "Train loss and acc of batch 13: 47.92314147949219, 0.984375\n",
      "Train loss and acc of batch 14: 47.923126220703125, 0.984375\n",
      "Train loss and acc of batch 15: 48.30205535888672, 0.984375\n",
      "Train loss and acc of batch 16: 48.302040100097656, 0.984375\n",
      "Train loss and acc of batch 17: 48.459564208984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.5878791809082, 0.96875\n",
      "Train loss and acc of batch 19: 47.706321716308594, 1.0\n",
      "Train loss and acc of batch 20: 47.70631408691406, 1.0\n",
      "Train loss and acc of batch 21: 48.302001953125, 0.984375\n",
      "Train loss and acc of batch 22: 48.30199432373047, 0.984375\n",
      "Train loss and acc of batch 23: 47.7062873840332, 1.0\n",
      "Train loss and acc of batch 24: 48.301979064941406, 0.984375\n",
      "Train loss and acc of batch 25: 47.70627212524414, 1.0\n",
      "Train loss and acc of batch 26: 47.706260681152344, 1.0\n",
      "Train loss and acc of batch 27: 47.70625305175781, 1.0\n",
      "Train loss and acc of batch 28: 47.70624542236328, 1.0\n",
      "Train loss and acc of batch 29: 48.30193328857422, 0.984375\n",
      "Train loss and acc of batch 30: 47.70622253417969, 1.0\n",
      "Train loss and acc of batch 31: 47.9229736328125, 0.984375\n",
      "Train loss and acc of batch 32: 47.70620346069336, 1.0\n",
      "Train loss and acc of batch 33: 47.70619583129883, 1.0\n",
      "Train loss and acc of batch 34: 48.30189514160156, 0.984375\n",
      "Train loss and acc of batch 35: 48.13970947265625, 0.96875\n",
      "Train loss and acc of batch 36: 47.70616912841797, 1.0\n",
      "Train loss and acc of batch 37: 48.45938491821289, 0.984375\n",
      "Train loss and acc of batch 38: 49.055076599121094, 0.96875\n",
      "Train loss and acc of batch 39: 47.92291259765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.706138610839844, 1.0\n",
      "Train loss and acc of batch 41: 49.055049896240234, 0.96875\n",
      "Train loss and acc of batch 42: 47.706119537353516, 1.0\n",
      "Train loss and acc of batch 43: 48.30181884765625, 0.984375\n",
      "Train loss and acc of batch 44: 47.70610046386719, 1.0\n",
      "Train loss and acc of batch 45: 48.301788330078125, 0.984375\n",
      "Train loss and acc of batch 46: 47.99193572998047, 0.984375\n",
      "Train loss and acc of batch 47: 47.70607376098633, 1.0\n",
      "Train loss and acc of batch 48: 47.7060661315918, 1.0\n",
      "Train loss and acc of batch 49: 47.7060546875, 1.0\n",
      "Train loss and acc of batch 50: 48.30175018310547, 0.984375\n",
      "Train loss and acc of batch 51: 49.054962158203125, 0.96875\n",
      "Train loss and acc of batch 52: 48.96186447143555, 0.953125\n",
      "Train loss and acc of batch 53: 47.70602035522461, 1.0\n",
      "Train loss and acc of batch 54: 47.92277526855469, 0.984375\n",
      "Train loss and acc of batch 55: 47.70600128173828, 1.0\n",
      "Train loss and acc of batch 56: 47.705997467041016, 1.0\n",
      "Train loss and acc of batch 57: 48.30168914794922, 0.984375\n",
      "Train loss and acc of batch 58: 47.70597839355469, 1.0\n",
      "Train loss and acc of batch 59: 47.705970764160156, 1.0\n",
      "Train loss and acc of batch 60: 47.705955505371094, 1.0\n",
      "Train loss and acc of batch 61: 47.70594787597656, 1.0\n",
      "Train loss and acc of batch 62: 47.7059440612793, 1.0\n",
      "Train loss and acc of batch 63: 48.89733123779297, 0.96875\n",
      "Train loss and acc of batch 64: 47.92268371582031, 0.984375\n",
      "Train loss and acc of batch 65: 47.70591354370117, 1.0\n",
      "Train loss and acc of batch 66: 47.705909729003906, 1.0\n",
      "Train loss and acc of batch 67: 48.51836013793945, 0.96875\n",
      "Train loss and acc of batch 68: 48.30158996582031, 0.984375\n",
      "Train loss and acc of batch 69: 47.922637939453125, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 70: 47.70587158203125, 1.0\n",
      "Training accuracy and loss of epoch #558: 0.9897, 48.0271\n",
      "Saved model by train loss 48.02706302051813\n",
      "Train loss and acc of batch 0: 47.70586395263672, 1.0\n",
      "Train loss and acc of batch 1: 47.70585250854492, 1.0\n",
      "Train loss and acc of batch 2: 47.70584487915039, 1.0\n",
      "Train loss and acc of batch 3: 47.922607421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.7058219909668, 1.0\n",
      "Train loss and acc of batch 5: 49.05474853515625, 0.96875\n",
      "Train loss and acc of batch 6: 48.20842742919922, 0.96875\n",
      "Train loss and acc of batch 7: 47.7057991027832, 1.0\n",
      "Train loss and acc of batch 8: 48.301490783691406, 0.984375\n",
      "Train loss and acc of batch 9: 47.99163818359375, 0.984375\n",
      "Train loss and acc of batch 10: 47.705772399902344, 1.0\n",
      "Train loss and acc of batch 11: 47.70576095581055, 1.0\n",
      "Train loss and acc of batch 12: 48.45897674560547, 0.984375\n",
      "Train loss and acc of batch 13: 47.922508239746094, 0.984375\n",
      "Train loss and acc of batch 14: 47.92250061035156, 0.984375\n",
      "Train loss and acc of batch 15: 48.301429748535156, 0.984375\n",
      "Train loss and acc of batch 16: 48.301422119140625, 0.984375\n",
      "Train loss and acc of batch 17: 48.45893859863281, 0.984375\n",
      "Train loss and acc of batch 18: 48.58725357055664, 0.96875\n",
      "Train loss and acc of batch 19: 47.70569610595703, 1.0\n",
      "Train loss and acc of batch 20: 47.705684661865234, 1.0\n",
      "Train loss and acc of batch 21: 48.30137634277344, 0.984375\n",
      "Train loss and acc of batch 22: 48.301368713378906, 0.984375\n",
      "Train loss and acc of batch 23: 47.705657958984375, 1.0\n",
      "Train loss and acc of batch 24: 48.30134582519531, 0.984375\n",
      "Train loss and acc of batch 25: 47.70563888549805, 1.0\n",
      "Train loss and acc of batch 26: 47.705631256103516, 1.0\n",
      "Train loss and acc of batch 27: 47.70561981201172, 1.0\n",
      "Train loss and acc of batch 28: 47.70561599731445, 1.0\n",
      "Train loss and acc of batch 29: 48.301300048828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.705596923828125, 1.0\n",
      "Train loss and acc of batch 31: 47.92235565185547, 0.984375\n",
      "Train loss and acc of batch 32: 47.70557403564453, 1.0\n",
      "Train loss and acc of batch 33: 47.705570220947266, 1.0\n",
      "Train loss and acc of batch 34: 48.30126190185547, 0.984375\n",
      "Train loss and acc of batch 35: 48.139076232910156, 0.96875\n",
      "Train loss and acc of batch 36: 47.70554733276367, 1.0\n",
      "Train loss and acc of batch 37: 48.45875930786133, 0.984375\n",
      "Train loss and acc of batch 38: 49.05445098876953, 0.96875\n",
      "Train loss and acc of batch 39: 47.922279357910156, 0.984375\n",
      "Train loss and acc of batch 40: 47.705501556396484, 1.0\n",
      "Train loss and acc of batch 41: 49.05442428588867, 0.96875\n",
      "Train loss and acc of batch 42: 47.70549392700195, 1.0\n",
      "Train loss and acc of batch 43: 48.301185607910156, 0.984375\n",
      "Train loss and acc of batch 44: 47.70547103881836, 1.0\n",
      "Train loss and acc of batch 45: 48.30116271972656, 0.984375\n",
      "Train loss and acc of batch 46: 47.991302490234375, 0.984375\n",
      "Train loss and acc of batch 47: 47.7054443359375, 1.0\n",
      "Train loss and acc of batch 48: 47.70543670654297, 1.0\n",
      "Train loss and acc of batch 49: 47.70542526245117, 1.0\n",
      "Train loss and acc of batch 50: 48.301124572753906, 0.984375\n",
      "Train loss and acc of batch 51: 49.05433654785156, 0.96875\n",
      "Train loss and acc of batch 52: 48.96124267578125, 0.953125\n",
      "Train loss and acc of batch 53: 47.70539474487305, 1.0\n",
      "Train loss and acc of batch 54: 47.922142028808594, 0.984375\n",
      "Train loss and acc of batch 55: 47.70537567138672, 1.0\n",
      "Train loss and acc of batch 56: 47.70536422729492, 1.0\n",
      "Train loss and acc of batch 57: 48.301055908203125, 0.984375\n",
      "Train loss and acc of batch 58: 47.705345153808594, 1.0\n",
      "Train loss and acc of batch 59: 47.70533752441406, 1.0\n",
      "Train loss and acc of batch 60: 47.70532989501953, 1.0\n",
      "Train loss and acc of batch 61: 47.705322265625, 1.0\n",
      "Train loss and acc of batch 62: 47.7053108215332, 1.0\n",
      "Train loss and acc of batch 63: 48.89670181274414, 0.96875\n",
      "Train loss and acc of batch 64: 47.92205810546875, 0.984375\n",
      "Train loss and acc of batch 65: 47.70528793334961, 1.0\n",
      "Train loss and acc of batch 66: 47.70527648925781, 1.0\n",
      "Train loss and acc of batch 67: 48.51773452758789, 0.96875\n",
      "Train loss and acc of batch 68: 48.30095672607422, 0.984375\n",
      "Train loss and acc of batch 69: 47.92201232910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.70524597167969, 1.0\n",
      "Training accuracy and loss of epoch #559: 0.9897, 48.0264\n",
      "Saved model by train loss 48.02643477748817\n",
      "Train loss and acc of batch 0: 47.70523452758789, 1.0\n",
      "Train loss and acc of batch 1: 47.705223083496094, 1.0\n",
      "Train loss and acc of batch 2: 47.70521545410156, 1.0\n",
      "Train loss and acc of batch 3: 47.921966552734375, 0.984375\n",
      "Train loss and acc of batch 4: 47.705196380615234, 1.0\n",
      "Train loss and acc of batch 5: 49.054115295410156, 0.96875\n",
      "Train loss and acc of batch 6: 48.20779037475586, 0.96875\n",
      "Train loss and acc of batch 7: 47.705169677734375, 1.0\n",
      "Train loss and acc of batch 8: 48.300865173339844, 0.984375\n",
      "Train loss and acc of batch 9: 47.991004943847656, 0.984375\n",
      "Train loss and acc of batch 10: 47.70515060424805, 1.0\n",
      "Train loss and acc of batch 11: 47.70513916015625, 1.0\n",
      "Train loss and acc of batch 12: 48.45834732055664, 0.984375\n",
      "Train loss and acc of batch 13: 47.92188262939453, 0.984375\n",
      "Train loss and acc of batch 14: 47.921875, 0.984375\n",
      "Train loss and acc of batch 15: 48.30079650878906, 0.984375\n",
      "Train loss and acc of batch 16: 48.30079650878906, 0.984375\n",
      "Train loss and acc of batch 17: 48.45830535888672, 0.984375\n",
      "Train loss and acc of batch 18: 48.58662796020508, 0.96875\n",
      "Train loss and acc of batch 19: 47.70506286621094, 1.0\n",
      "Train loss and acc of batch 20: 47.705047607421875, 1.0\n",
      "Train loss and acc of batch 21: 48.300743103027344, 0.984375\n",
      "Train loss and acc of batch 22: 48.300743103027344, 0.984375\n",
      "Train loss and acc of batch 23: 47.70502853393555, 1.0\n",
      "Train loss and acc of batch 24: 48.30072784423828, 0.984375\n",
      "Train loss and acc of batch 25: 47.705013275146484, 1.0\n",
      "Train loss and acc of batch 26: 47.70500183105469, 1.0\n",
      "Train loss and acc of batch 27: 47.704994201660156, 1.0\n",
      "Train loss and acc of batch 28: 47.70498275756836, 1.0\n",
      "Train loss and acc of batch 29: 48.30067443847656, 0.984375\n",
      "Train loss and acc of batch 30: 47.70497131347656, 1.0\n",
      "Train loss and acc of batch 31: 47.921722412109375, 0.984375\n",
      "Train loss and acc of batch 32: 47.70494842529297, 1.0\n",
      "Train loss and acc of batch 33: 47.7049446105957, 1.0\n",
      "Train loss and acc of batch 34: 48.300628662109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.138450622558594, 0.96875\n",
      "Train loss and acc of batch 36: 47.70491409301758, 1.0\n",
      "Train loss and acc of batch 37: 48.458126068115234, 0.984375\n",
      "Train loss and acc of batch 38: 49.05382537841797, 0.96875\n",
      "Train loss and acc of batch 39: 47.921653747558594, 0.984375\n",
      "Train loss and acc of batch 40: 47.70487594604492, 1.0\n",
      "Train loss and acc of batch 41: 49.05379867553711, 0.96875\n",
      "Train loss and acc of batch 42: 47.70486068725586, 1.0\n",
      "Train loss and acc of batch 43: 48.30055236816406, 0.984375\n",
      "Train loss and acc of batch 44: 47.7048454284668, 1.0\n",
      "Train loss and acc of batch 45: 48.300537109375, 0.984375\n",
      "Train loss and acc of batch 46: 47.99067687988281, 0.984375\n",
      "Train loss and acc of batch 47: 47.7048225402832, 1.0\n",
      "Train loss and acc of batch 48: 47.704803466796875, 1.0\n",
      "Train loss and acc of batch 49: 47.704795837402344, 1.0\n",
      "Train loss and acc of batch 50: 48.30049133300781, 0.984375\n",
      "Train loss and acc of batch 51: 49.05370330810547, 0.96875\n",
      "Train loss and acc of batch 52: 48.96061325073242, 0.953125\n",
      "Train loss and acc of batch 53: 47.70476531982422, 1.0\n",
      "Train loss and acc of batch 54: 47.92151641845703, 0.984375\n",
      "Train loss and acc of batch 55: 47.704750061035156, 1.0\n",
      "Train loss and acc of batch 56: 47.70473861694336, 1.0\n",
      "Train loss and acc of batch 57: 48.30043029785156, 0.984375\n",
      "Train loss and acc of batch 58: 47.70471954345703, 1.0\n",
      "Train loss and acc of batch 59: 47.7047119140625, 1.0\n",
      "Train loss and acc of batch 60: 47.7047004699707, 1.0\n",
      "Train loss and acc of batch 61: 47.70469665527344, 1.0\n",
      "Train loss and acc of batch 62: 47.704681396484375, 1.0\n",
      "Train loss and acc of batch 63: 48.89607238769531, 0.96875\n",
      "Train loss and acc of batch 64: 47.92143249511719, 0.984375\n",
      "Train loss and acc of batch 65: 47.704654693603516, 1.0\n",
      "Train loss and acc of batch 66: 47.704647064208984, 1.0\n",
      "Train loss and acc of batch 67: 48.51710510253906, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 68: 48.300331115722656, 0.984375\n",
      "Train loss and acc of batch 69: 47.92138671875, 0.984375\n",
      "Train loss and acc of batch 70: 47.704612731933594, 1.0\n",
      "Training accuracy and loss of epoch #560: 0.9897, 48.0258\n",
      "Saved model by train loss 48.0258061583613\n",
      "Train loss and acc of batch 0: 47.70459747314453, 1.0\n",
      "Train loss and acc of batch 1: 47.70459747314453, 1.0\n",
      "Train loss and acc of batch 2: 47.70458984375, 1.0\n",
      "Train loss and acc of batch 3: 47.92134094238281, 0.984375\n",
      "Train loss and acc of batch 4: 47.70457077026367, 1.0\n",
      "Train loss and acc of batch 5: 49.053489685058594, 0.96875\n",
      "Train loss and acc of batch 6: 48.20716857910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.70454406738281, 1.0\n",
      "Train loss and acc of batch 8: 48.30023193359375, 0.984375\n",
      "Train loss and acc of batch 9: 47.990379333496094, 0.984375\n",
      "Train loss and acc of batch 10: 47.70451354980469, 1.0\n",
      "Train loss and acc of batch 11: 47.704505920410156, 1.0\n",
      "Train loss and acc of batch 12: 48.45772171020508, 0.984375\n",
      "Train loss and acc of batch 13: 47.92125701904297, 0.984375\n",
      "Train loss and acc of batch 14: 47.921241760253906, 0.984375\n",
      "Train loss and acc of batch 15: 48.3001708984375, 0.984375\n",
      "Train loss and acc of batch 16: 48.30016326904297, 0.984375\n",
      "Train loss and acc of batch 17: 48.45767593383789, 0.984375\n",
      "Train loss and acc of batch 18: 48.58599853515625, 0.96875\n",
      "Train loss and acc of batch 19: 47.70443344116211, 1.0\n",
      "Train loss and acc of batch 20: 47.70442581176758, 1.0\n",
      "Train loss and acc of batch 21: 48.30012512207031, 0.984375\n",
      "Train loss and acc of batch 22: 48.30010986328125, 0.984375\n",
      "Train loss and acc of batch 23: 47.70439910888672, 1.0\n",
      "Train loss and acc of batch 24: 48.30009460449219, 0.984375\n",
      "Train loss and acc of batch 25: 47.70438003540039, 1.0\n",
      "Train loss and acc of batch 26: 47.70437240600586, 1.0\n",
      "Train loss and acc of batch 27: 47.704368591308594, 1.0\n",
      "Train loss and acc of batch 28: 47.70435333251953, 1.0\n",
      "Train loss and acc of batch 29: 48.300048828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.70433807373047, 1.0\n",
      "Train loss and acc of batch 31: 47.92108917236328, 0.984375\n",
      "Train loss and acc of batch 32: 47.70431900024414, 1.0\n",
      "Train loss and acc of batch 33: 47.70431137084961, 1.0\n",
      "Train loss and acc of batch 34: 48.30000305175781, 0.984375\n",
      "Train loss and acc of batch 35: 48.13782501220703, 0.96875\n",
      "Train loss and acc of batch 36: 47.70428466796875, 1.0\n",
      "Train loss and acc of batch 37: 48.457496643066406, 0.984375\n",
      "Train loss and acc of batch 38: 49.053192138671875, 0.96875\n",
      "Train loss and acc of batch 39: 47.9210205078125, 0.984375\n",
      "Train loss and acc of batch 40: 47.70425033569336, 1.0\n",
      "Train loss and acc of batch 41: 49.05316925048828, 0.96875\n",
      "Train loss and acc of batch 42: 47.70423126220703, 1.0\n",
      "Train loss and acc of batch 43: 48.29991912841797, 0.984375\n",
      "Train loss and acc of batch 44: 47.7042121887207, 1.0\n",
      "Train loss and acc of batch 45: 48.299903869628906, 0.984375\n",
      "Train loss and acc of batch 46: 47.99005126953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.70418930053711, 1.0\n",
      "Train loss and acc of batch 48: 47.70417785644531, 1.0\n",
      "Train loss and acc of batch 49: 47.70417404174805, 1.0\n",
      "Train loss and acc of batch 50: 48.29986572265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.053070068359375, 0.96875\n",
      "Train loss and acc of batch 52: 48.95998764038086, 0.953125\n",
      "Train loss and acc of batch 53: 47.704132080078125, 1.0\n",
      "Train loss and acc of batch 54: 47.92089080810547, 0.984375\n",
      "Train loss and acc of batch 55: 47.704124450683594, 1.0\n",
      "Train loss and acc of batch 56: 47.70410919189453, 1.0\n",
      "Train loss and acc of batch 57: 48.29979705810547, 0.984375\n",
      "Train loss and acc of batch 58: 47.7040901184082, 1.0\n",
      "Train loss and acc of batch 59: 47.704078674316406, 1.0\n",
      "Train loss and acc of batch 60: 47.704071044921875, 1.0\n",
      "Train loss and acc of batch 61: 47.70405960083008, 1.0\n",
      "Train loss and acc of batch 62: 47.70405197143555, 1.0\n",
      "Train loss and acc of batch 63: 48.895450592041016, 0.96875\n",
      "Train loss and acc of batch 64: 47.920799255371094, 0.984375\n",
      "Train loss and acc of batch 65: 47.70402526855469, 1.0\n",
      "Train loss and acc of batch 66: 47.70402145385742, 1.0\n",
      "Train loss and acc of batch 67: 48.516475677490234, 0.96875\n",
      "Train loss and acc of batch 68: 48.299705505371094, 0.984375\n",
      "Train loss and acc of batch 69: 47.92076110839844, 0.984375\n",
      "Train loss and acc of batch 70: 47.703983306884766, 1.0\n",
      "Training accuracy and loss of epoch #561: 0.9897, 48.0252\n",
      "Saved model by train loss 48.02517716313751\n",
      "Train loss and acc of batch 0: 47.703975677490234, 1.0\n",
      "Train loss and acc of batch 1: 47.70396423339844, 1.0\n",
      "Train loss and acc of batch 2: 47.703956604003906, 1.0\n",
      "Train loss and acc of batch 3: 47.92071533203125, 0.984375\n",
      "Train loss and acc of batch 4: 47.70393753051758, 1.0\n",
      "Train loss and acc of batch 5: 49.05284881591797, 0.96875\n",
      "Train loss and acc of batch 6: 48.206539154052734, 0.96875\n",
      "Train loss and acc of batch 7: 47.703914642333984, 1.0\n",
      "Train loss and acc of batch 8: 48.29960632324219, 0.984375\n",
      "Train loss and acc of batch 9: 47.98974609375, 0.984375\n",
      "Train loss and acc of batch 10: 47.70388412475586, 1.0\n",
      "Train loss and acc of batch 11: 47.70387649536133, 1.0\n",
      "Train loss and acc of batch 12: 48.457096099853516, 0.984375\n",
      "Train loss and acc of batch 13: 47.920623779296875, 0.984375\n",
      "Train loss and acc of batch 14: 47.920616149902344, 0.984375\n",
      "Train loss and acc of batch 15: 48.29954528808594, 0.984375\n",
      "Train loss and acc of batch 16: 48.299537658691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.45704650878906, 0.984375\n",
      "Train loss and acc of batch 18: 48.58536911010742, 0.96875\n",
      "Train loss and acc of batch 19: 47.70380401611328, 1.0\n",
      "Train loss and acc of batch 20: 47.703800201416016, 1.0\n",
      "Train loss and acc of batch 21: 48.29949188232422, 0.984375\n",
      "Train loss and acc of batch 22: 48.29948425292969, 0.984375\n",
      "Train loss and acc of batch 23: 47.70376968383789, 1.0\n",
      "Train loss and acc of batch 24: 48.299461364746094, 0.984375\n",
      "Train loss and acc of batch 25: 47.70375061035156, 1.0\n",
      "Train loss and acc of batch 26: 47.70375061035156, 1.0\n",
      "Train loss and acc of batch 27: 47.7037353515625, 1.0\n",
      "Train loss and acc of batch 28: 47.70372772216797, 1.0\n",
      "Train loss and acc of batch 29: 48.29942321777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.70370864868164, 1.0\n",
      "Train loss and acc of batch 31: 47.92046356201172, 0.984375\n",
      "Train loss and acc of batch 32: 47.70368957519531, 1.0\n",
      "Train loss and acc of batch 33: 47.70368194580078, 1.0\n",
      "Train loss and acc of batch 34: 48.29937744140625, 0.984375\n",
      "Train loss and acc of batch 35: 48.13719177246094, 0.96875\n",
      "Train loss and acc of batch 36: 47.70365905761719, 1.0\n",
      "Train loss and acc of batch 37: 48.45686721801758, 0.984375\n",
      "Train loss and acc of batch 38: 49.05256652832031, 0.96875\n",
      "Train loss and acc of batch 39: 47.92039489746094, 0.984375\n",
      "Train loss and acc of batch 40: 47.7036247253418, 1.0\n",
      "Train loss and acc of batch 41: 49.05253601074219, 0.96875\n",
      "Train loss and acc of batch 42: 47.7036018371582, 1.0\n",
      "Train loss and acc of batch 43: 48.29930114746094, 0.984375\n",
      "Train loss and acc of batch 44: 47.70358657836914, 1.0\n",
      "Train loss and acc of batch 45: 48.299278259277344, 0.984375\n",
      "Train loss and acc of batch 46: 47.98942565917969, 0.984375\n",
      "Train loss and acc of batch 47: 47.70355987548828, 1.0\n",
      "Train loss and acc of batch 48: 47.70355224609375, 1.0\n",
      "Train loss and acc of batch 49: 47.70354080200195, 1.0\n",
      "Train loss and acc of batch 50: 48.299232482910156, 0.984375\n",
      "Train loss and acc of batch 51: 49.052452087402344, 0.96875\n",
      "Train loss and acc of batch 52: 48.959354400634766, 0.953125\n",
      "Train loss and acc of batch 53: 47.70350646972656, 1.0\n",
      "Train loss and acc of batch 54: 47.920265197753906, 0.984375\n",
      "Train loss and acc of batch 55: 47.703487396240234, 1.0\n",
      "Train loss and acc of batch 56: 47.70347595214844, 1.0\n",
      "Train loss and acc of batch 57: 48.299171447753906, 0.984375\n",
      "Train loss and acc of batch 58: 47.703460693359375, 1.0\n",
      "Train loss and acc of batch 59: 47.703453063964844, 1.0\n",
      "Train loss and acc of batch 60: 47.70344543457031, 1.0\n",
      "Train loss and acc of batch 61: 47.703433990478516, 1.0\n",
      "Train loss and acc of batch 62: 47.703426361083984, 1.0\n",
      "Train loss and acc of batch 63: 48.89482498168945, 0.96875\n",
      "Train loss and acc of batch 64: 47.92017364501953, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 65: 47.70340347290039, 1.0\n",
      "Train loss and acc of batch 66: 47.703392028808594, 1.0\n",
      "Train loss and acc of batch 67: 48.515846252441406, 0.96875\n",
      "Train loss and acc of batch 68: 48.299072265625, 0.984375\n",
      "Train loss and acc of batch 69: 47.920127868652344, 0.984375\n",
      "Train loss and acc of batch 70: 47.70335006713867, 1.0\n",
      "Training accuracy and loss of epoch #562: 0.9897, 48.0245\n",
      "Saved model by train loss 48.02454875892317\n",
      "Train loss and acc of batch 0: 47.70335006713867, 1.0\n",
      "Train loss and acc of batch 1: 47.70333480834961, 1.0\n",
      "Train loss and acc of batch 2: 47.703330993652344, 1.0\n",
      "Train loss and acc of batch 3: 47.920082092285156, 0.984375\n",
      "Train loss and acc of batch 4: 47.70330810546875, 1.0\n",
      "Train loss and acc of batch 5: 49.052223205566406, 0.96875\n",
      "Train loss and acc of batch 6: 48.20591735839844, 0.96875\n",
      "Train loss and acc of batch 7: 47.70328140258789, 1.0\n",
      "Train loss and acc of batch 8: 48.298980712890625, 0.984375\n",
      "Train loss and acc of batch 9: 47.98912048339844, 0.984375\n",
      "Train loss and acc of batch 10: 47.7032585144043, 1.0\n",
      "Train loss and acc of batch 11: 47.7032470703125, 1.0\n",
      "Train loss and acc of batch 12: 48.45646667480469, 0.984375\n",
      "Train loss and acc of batch 13: 47.91999816894531, 0.984375\n",
      "Train loss and acc of batch 14: 47.91999053955078, 0.984375\n",
      "Train loss and acc of batch 15: 48.298912048339844, 0.984375\n",
      "Train loss and acc of batch 16: 48.29890441894531, 0.984375\n",
      "Train loss and acc of batch 17: 48.4564208984375, 0.984375\n",
      "Train loss and acc of batch 18: 48.58473587036133, 0.96875\n",
      "Train loss and acc of batch 19: 47.70317840576172, 1.0\n",
      "Train loss and acc of batch 20: 47.70317077636719, 1.0\n",
      "Train loss and acc of batch 21: 48.298858642578125, 0.984375\n",
      "Train loss and acc of batch 22: 48.298851013183594, 0.984375\n",
      "Train loss and acc of batch 23: 47.70314407348633, 1.0\n",
      "Train loss and acc of batch 24: 48.29883575439453, 0.984375\n",
      "Train loss and acc of batch 25: 47.703128814697266, 1.0\n",
      "Train loss and acc of batch 26: 47.70310974121094, 1.0\n",
      "Train loss and acc of batch 27: 47.70310592651367, 1.0\n",
      "Train loss and acc of batch 28: 47.703102111816406, 1.0\n",
      "Train loss and acc of batch 29: 48.298789978027344, 0.984375\n",
      "Train loss and acc of batch 30: 47.70308303833008, 1.0\n",
      "Train loss and acc of batch 31: 47.919837951660156, 0.984375\n",
      "Train loss and acc of batch 32: 47.70305633544922, 1.0\n",
      "Train loss and acc of batch 33: 47.70305633544922, 1.0\n",
      "Train loss and acc of batch 34: 48.29875183105469, 0.984375\n",
      "Train loss and acc of batch 35: 48.13656234741211, 0.96875\n",
      "Train loss and acc of batch 36: 47.703025817871094, 1.0\n",
      "Train loss and acc of batch 37: 48.45624542236328, 0.984375\n",
      "Train loss and acc of batch 38: 49.05193328857422, 0.96875\n",
      "Train loss and acc of batch 39: 47.919769287109375, 0.984375\n",
      "Train loss and acc of batch 40: 47.702999114990234, 1.0\n",
      "Train loss and acc of batch 41: 49.05190658569336, 0.96875\n",
      "Train loss and acc of batch 42: 47.70297622680664, 1.0\n",
      "Train loss and acc of batch 43: 48.298667907714844, 0.984375\n",
      "Train loss and acc of batch 44: 47.70295715332031, 1.0\n",
      "Train loss and acc of batch 45: 48.29865264892578, 0.984375\n",
      "Train loss and acc of batch 46: 47.988792419433594, 0.984375\n",
      "Train loss and acc of batch 47: 47.70293045043945, 1.0\n",
      "Train loss and acc of batch 48: 47.70292282104492, 1.0\n",
      "Train loss and acc of batch 49: 47.702911376953125, 1.0\n",
      "Train loss and acc of batch 50: 48.298606872558594, 0.984375\n",
      "Train loss and acc of batch 51: 49.05182647705078, 0.96875\n",
      "Train loss and acc of batch 52: 48.95872497558594, 0.953125\n",
      "Train loss and acc of batch 53: 47.702880859375, 1.0\n",
      "Train loss and acc of batch 54: 47.91963195800781, 0.984375\n",
      "Train loss and acc of batch 55: 47.70285415649414, 1.0\n",
      "Train loss and acc of batch 56: 47.702850341796875, 1.0\n",
      "Train loss and acc of batch 57: 48.298545837402344, 0.984375\n",
      "Train loss and acc of batch 58: 47.70283126831055, 1.0\n",
      "Train loss and acc of batch 59: 47.702823638916016, 1.0\n",
      "Train loss and acc of batch 60: 47.702816009521484, 1.0\n",
      "Train loss and acc of batch 61: 47.70280838012695, 1.0\n",
      "Train loss and acc of batch 62: 47.702796936035156, 1.0\n",
      "Train loss and acc of batch 63: 48.89418411254883, 0.96875\n",
      "Train loss and acc of batch 64: 47.91954803466797, 0.984375\n",
      "Train loss and acc of batch 65: 47.70277404785156, 1.0\n",
      "Train loss and acc of batch 66: 47.702762603759766, 1.0\n",
      "Train loss and acc of batch 67: 48.515220642089844, 0.96875\n",
      "Train loss and acc of batch 68: 48.29845428466797, 0.984375\n",
      "Train loss and acc of batch 69: 47.91949462890625, 0.984375\n",
      "Train loss and acc of batch 70: 47.702728271484375, 1.0\n",
      "Training accuracy and loss of epoch #563: 0.9897, 48.0239\n",
      "Saved model by train loss 48.02392030098069\n",
      "Train loss and acc of batch 0: 47.702720642089844, 1.0\n",
      "Train loss and acc of batch 1: 47.70270919799805, 1.0\n",
      "Train loss and acc of batch 2: 47.70270538330078, 1.0\n",
      "Train loss and acc of batch 3: 47.919456481933594, 0.984375\n",
      "Train loss and acc of batch 4: 47.70268249511719, 1.0\n",
      "Train loss and acc of batch 5: 49.051597595214844, 0.96875\n",
      "Train loss and acc of batch 6: 48.20527648925781, 0.96875\n",
      "Train loss and acc of batch 7: 47.70265579223633, 1.0\n",
      "Train loss and acc of batch 8: 48.29834747314453, 0.984375\n",
      "Train loss and acc of batch 9: 47.988487243652344, 0.984375\n",
      "Train loss and acc of batch 10: 47.70262908935547, 1.0\n",
      "Train loss and acc of batch 11: 47.70262145996094, 1.0\n",
      "Train loss and acc of batch 12: 48.455833435058594, 0.984375\n",
      "Train loss and acc of batch 13: 47.91936492919922, 0.984375\n",
      "Train loss and acc of batch 14: 47.91936492919922, 0.984375\n",
      "Train loss and acc of batch 15: 48.29828643798828, 0.984375\n",
      "Train loss and acc of batch 16: 48.29827880859375, 0.984375\n",
      "Train loss and acc of batch 17: 48.455787658691406, 0.984375\n",
      "Train loss and acc of batch 18: 48.584110260009766, 0.96875\n",
      "Train loss and acc of batch 19: 47.702552795410156, 1.0\n",
      "Train loss and acc of batch 20: 47.702537536621094, 1.0\n",
      "Train loss and acc of batch 21: 48.29823303222656, 0.984375\n",
      "Train loss and acc of batch 22: 48.29822540283203, 0.984375\n",
      "Train loss and acc of batch 23: 47.702510833740234, 1.0\n",
      "Train loss and acc of batch 24: 48.29820251464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.70249557495117, 1.0\n",
      "Train loss and acc of batch 26: 47.70248794555664, 1.0\n",
      "Train loss and acc of batch 27: 47.702476501464844, 1.0\n",
      "Train loss and acc of batch 28: 47.70246505737305, 1.0\n",
      "Train loss and acc of batch 29: 48.29815673828125, 0.984375\n",
      "Train loss and acc of batch 30: 47.70245361328125, 1.0\n",
      "Train loss and acc of batch 31: 47.91920471191406, 0.984375\n",
      "Train loss and acc of batch 32: 47.70243453979492, 1.0\n",
      "Train loss and acc of batch 33: 47.702430725097656, 1.0\n",
      "Train loss and acc of batch 34: 48.298118591308594, 0.984375\n",
      "Train loss and acc of batch 35: 48.13593292236328, 0.96875\n",
      "Train loss and acc of batch 36: 47.70240020751953, 1.0\n",
      "Train loss and acc of batch 37: 48.45560836791992, 0.984375\n",
      "Train loss and acc of batch 38: 49.051307678222656, 0.96875\n",
      "Train loss and acc of batch 39: 47.91914367675781, 0.984375\n",
      "Train loss and acc of batch 40: 47.702362060546875, 1.0\n",
      "Train loss and acc of batch 41: 49.05127716064453, 0.96875\n",
      "Train loss and acc of batch 42: 47.70234298706055, 1.0\n",
      "Train loss and acc of batch 43: 48.29803466796875, 0.984375\n",
      "Train loss and acc of batch 44: 47.70233154296875, 1.0\n",
      "Train loss and acc of batch 45: 48.29801940917969, 0.984375\n",
      "Train loss and acc of batch 46: 47.9881591796875, 0.984375\n",
      "Train loss and acc of batch 47: 47.70230484008789, 1.0\n",
      "Train loss and acc of batch 48: 47.702293395996094, 1.0\n",
      "Train loss and acc of batch 49: 47.7022819519043, 1.0\n",
      "Train loss and acc of batch 50: 48.2979736328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.051185607910156, 0.96875\n",
      "Train loss and acc of batch 52: 48.958099365234375, 0.953125\n",
      "Train loss and acc of batch 53: 47.70225143432617, 1.0\n",
      "Train loss and acc of batch 54: 47.91899871826172, 0.984375\n",
      "Train loss and acc of batch 55: 47.70222854614258, 1.0\n",
      "Train loss and acc of batch 56: 47.70222091674805, 1.0\n",
      "Train loss and acc of batch 57: 48.29791259765625, 0.984375\n",
      "Train loss and acc of batch 58: 47.702205657958984, 1.0\n",
      "Train loss and acc of batch 59: 47.70219421386719, 1.0\n",
      "Train loss and acc of batch 60: 47.70218276977539, 1.0\n",
      "Train loss and acc of batch 61: 47.702178955078125, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 62: 47.70216751098633, 1.0\n",
      "Train loss and acc of batch 63: 48.89356231689453, 0.96875\n",
      "Train loss and acc of batch 64: 47.918914794921875, 0.984375\n",
      "Train loss and acc of batch 65: 47.70214080810547, 1.0\n",
      "Train loss and acc of batch 66: 47.70213317871094, 1.0\n",
      "Train loss and acc of batch 67: 48.514591217041016, 0.96875\n",
      "Train loss and acc of batch 68: 48.297813415527344, 0.984375\n",
      "Train loss and acc of batch 69: 47.91886901855469, 0.984375\n",
      "Train loss and acc of batch 70: 47.70210266113281, 1.0\n",
      "Training accuracy and loss of epoch #564: 0.9897, 48.0233\n",
      "Saved model by train loss 48.02329055356308\n",
      "Train loss and acc of batch 0: 47.702091217041016, 1.0\n",
      "Train loss and acc of batch 1: 47.70207977294922, 1.0\n",
      "Train loss and acc of batch 2: 47.702064514160156, 1.0\n",
      "Train loss and acc of batch 3: 47.9188232421875, 0.984375\n",
      "Train loss and acc of batch 4: 47.702056884765625, 1.0\n",
      "Train loss and acc of batch 5: 49.05097198486328, 0.96875\n",
      "Train loss and acc of batch 6: 48.20465087890625, 0.96875\n",
      "Train loss and acc of batch 7: 47.7020263671875, 1.0\n",
      "Train loss and acc of batch 8: 48.29771423339844, 0.984375\n",
      "Train loss and acc of batch 9: 47.98786163330078, 0.984375\n",
      "Train loss and acc of batch 10: 47.702003479003906, 1.0\n",
      "Train loss and acc of batch 11: 47.701988220214844, 1.0\n",
      "Train loss and acc of batch 12: 48.45520782470703, 0.984375\n",
      "Train loss and acc of batch 13: 47.918739318847656, 0.984375\n",
      "Train loss and acc of batch 14: 47.918731689453125, 0.984375\n",
      "Train loss and acc of batch 15: 48.29765319824219, 0.984375\n",
      "Train loss and acc of batch 16: 48.29765319824219, 0.984375\n",
      "Train loss and acc of batch 17: 48.45515823364258, 0.984375\n",
      "Train loss and acc of batch 18: 48.5834846496582, 0.96875\n",
      "Train loss and acc of batch 19: 47.7019157409668, 1.0\n",
      "Train loss and acc of batch 20: 47.70191192626953, 1.0\n",
      "Train loss and acc of batch 21: 48.29759979248047, 0.984375\n",
      "Train loss and acc of batch 22: 48.29759216308594, 0.984375\n",
      "Train loss and acc of batch 23: 47.701881408691406, 1.0\n",
      "Train loss and acc of batch 24: 48.297576904296875, 0.984375\n",
      "Train loss and acc of batch 25: 47.701866149902344, 1.0\n",
      "Train loss and acc of batch 26: 47.70185852050781, 1.0\n",
      "Train loss and acc of batch 27: 47.70185470581055, 1.0\n",
      "Train loss and acc of batch 28: 47.70184326171875, 1.0\n",
      "Train loss and acc of batch 29: 48.29753112792969, 0.984375\n",
      "Train loss and acc of batch 30: 47.701820373535156, 1.0\n",
      "Train loss and acc of batch 31: 47.9185791015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.70180892944336, 1.0\n",
      "Train loss and acc of batch 33: 47.70180130004883, 1.0\n",
      "Train loss and acc of batch 34: 48.2974853515625, 0.984375\n",
      "Train loss and acc of batch 35: 48.13530731201172, 0.96875\n",
      "Train loss and acc of batch 36: 47.70176315307617, 1.0\n",
      "Train loss and acc of batch 37: 48.45498275756836, 0.984375\n",
      "Train loss and acc of batch 38: 49.05067443847656, 0.96875\n",
      "Train loss and acc of batch 39: 47.91850280761719, 0.984375\n",
      "Train loss and acc of batch 40: 47.70173263549805, 1.0\n",
      "Train loss and acc of batch 41: 49.050655364990234, 0.96875\n",
      "Train loss and acc of batch 42: 47.701717376708984, 1.0\n",
      "Train loss and acc of batch 43: 48.29740905761719, 0.984375\n",
      "Train loss and acc of batch 44: 47.70170211791992, 1.0\n",
      "Train loss and acc of batch 45: 48.297393798828125, 0.984375\n",
      "Train loss and acc of batch 46: 47.98753356933594, 0.984375\n",
      "Train loss and acc of batch 47: 47.70167541503906, 1.0\n",
      "Train loss and acc of batch 48: 47.70166015625, 1.0\n",
      "Train loss and acc of batch 49: 47.701656341552734, 1.0\n",
      "Train loss and acc of batch 50: 48.29734802246094, 0.984375\n",
      "Train loss and acc of batch 51: 49.05055236816406, 0.96875\n",
      "Train loss and acc of batch 52: 48.95746612548828, 0.953125\n",
      "Train loss and acc of batch 53: 47.70161056518555, 1.0\n",
      "Train loss and acc of batch 54: 47.918373107910156, 0.984375\n",
      "Train loss and acc of batch 55: 47.701602935791016, 1.0\n",
      "Train loss and acc of batch 56: 47.70158767700195, 1.0\n",
      "Train loss and acc of batch 57: 48.297279357910156, 0.984375\n",
      "Train loss and acc of batch 58: 47.70157241821289, 1.0\n",
      "Train loss and acc of batch 59: 47.701560974121094, 1.0\n",
      "Train loss and acc of batch 60: 47.70155334472656, 1.0\n",
      "Train loss and acc of batch 61: 47.7015495300293, 1.0\n",
      "Train loss and acc of batch 62: 47.701534271240234, 1.0\n",
      "Train loss and acc of batch 63: 48.8929328918457, 0.96875\n",
      "Train loss and acc of batch 64: 47.91828155517578, 0.984375\n",
      "Train loss and acc of batch 65: 47.701507568359375, 1.0\n",
      "Train loss and acc of batch 66: 47.70150375366211, 1.0\n",
      "Train loss and acc of batch 67: 48.51395034790039, 0.96875\n",
      "Train loss and acc of batch 68: 48.29718017578125, 0.984375\n",
      "Train loss and acc of batch 69: 47.918243408203125, 0.984375\n",
      "Train loss and acc of batch 70: 47.70146560668945, 1.0\n",
      "Training accuracy and loss of epoch #565: 0.9897, 48.0227\n",
      "Saved model by train loss 48.02266069868921\n",
      "Train loss and acc of batch 0: 47.701454162597656, 1.0\n",
      "Train loss and acc of batch 1: 47.70145034790039, 1.0\n",
      "Train loss and acc of batch 2: 47.70143508911133, 1.0\n",
      "Train loss and acc of batch 3: 47.91819763183594, 0.984375\n",
      "Train loss and acc of batch 4: 47.701419830322266, 1.0\n",
      "Train loss and acc of batch 5: 49.05033874511719, 0.96875\n",
      "Train loss and acc of batch 6: 48.20402145385742, 0.96875\n",
      "Train loss and acc of batch 7: 47.70139694213867, 1.0\n",
      "Train loss and acc of batch 8: 48.297080993652344, 0.984375\n",
      "Train loss and acc of batch 9: 47.98722839355469, 0.984375\n",
      "Train loss and acc of batch 10: 47.70136260986328, 1.0\n",
      "Train loss and acc of batch 11: 47.701358795166016, 1.0\n",
      "Train loss and acc of batch 12: 48.45457458496094, 0.984375\n",
      "Train loss and acc of batch 13: 47.91810607910156, 0.984375\n",
      "Train loss and acc of batch 14: 47.9180908203125, 0.984375\n",
      "Train loss and acc of batch 15: 48.297027587890625, 0.984375\n",
      "Train loss and acc of batch 16: 48.29701232910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.45452880859375, 0.984375\n",
      "Train loss and acc of batch 18: 48.58285140991211, 0.96875\n",
      "Train loss and acc of batch 19: 47.70128631591797, 1.0\n",
      "Train loss and acc of batch 20: 47.70127868652344, 1.0\n",
      "Train loss and acc of batch 21: 48.296974182128906, 0.984375\n",
      "Train loss and acc of batch 22: 48.296966552734375, 0.984375\n",
      "Train loss and acc of batch 23: 47.701255798339844, 1.0\n",
      "Train loss and acc of batch 24: 48.29694366455078, 0.984375\n",
      "Train loss and acc of batch 25: 47.70123291015625, 1.0\n",
      "Train loss and acc of batch 26: 47.70122528076172, 1.0\n",
      "Train loss and acc of batch 27: 47.70121383666992, 1.0\n",
      "Train loss and acc of batch 28: 47.701210021972656, 1.0\n",
      "Train loss and acc of batch 29: 48.296905517578125, 0.984375\n",
      "Train loss and acc of batch 30: 47.70118713378906, 1.0\n",
      "Train loss and acc of batch 31: 47.917945861816406, 0.984375\n",
      "Train loss and acc of batch 32: 47.701175689697266, 1.0\n",
      "Train loss and acc of batch 33: 47.70116424560547, 1.0\n",
      "Train loss and acc of batch 34: 48.29685974121094, 0.984375\n",
      "Train loss and acc of batch 35: 48.13467788696289, 0.96875\n",
      "Train loss and acc of batch 36: 47.70113754272461, 1.0\n",
      "Train loss and acc of batch 37: 48.4543571472168, 0.984375\n",
      "Train loss and acc of batch 38: 49.05004119873047, 0.96875\n",
      "Train loss and acc of batch 39: 47.917877197265625, 0.984375\n",
      "Train loss and acc of batch 40: 47.70110321044922, 1.0\n",
      "Train loss and acc of batch 41: 49.050018310546875, 0.96875\n",
      "Train loss and acc of batch 42: 47.701080322265625, 1.0\n",
      "Train loss and acc of batch 43: 48.296775817871094, 0.984375\n",
      "Train loss and acc of batch 44: 47.70106506347656, 1.0\n",
      "Train loss and acc of batch 45: 48.2967529296875, 0.984375\n",
      "Train loss and acc of batch 46: 47.986900329589844, 0.984375\n",
      "Train loss and acc of batch 47: 47.7010383605957, 1.0\n",
      "Train loss and acc of batch 48: 47.70103073120117, 1.0\n",
      "Train loss and acc of batch 49: 47.701019287109375, 1.0\n",
      "Train loss and acc of batch 50: 48.296714782714844, 0.984375\n",
      "Train loss and acc of batch 51: 49.04993438720703, 0.96875\n",
      "Train loss and acc of batch 52: 48.95684051513672, 0.953125\n",
      "Train loss and acc of batch 53: 47.700984954833984, 1.0\n",
      "Train loss and acc of batch 54: 47.917747497558594, 0.984375\n",
      "Train loss and acc of batch 55: 47.70096969604492, 1.0\n",
      "Train loss and acc of batch 56: 47.70096206665039, 1.0\n",
      "Train loss and acc of batch 57: 48.296653747558594, 0.984375\n",
      "Train loss and acc of batch 58: 47.7009391784668, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 59: 47.700931549072266, 1.0\n",
      "Train loss and acc of batch 60: 47.700927734375, 1.0\n",
      "Train loss and acc of batch 61: 47.7009162902832, 1.0\n",
      "Train loss and acc of batch 62: 47.700904846191406, 1.0\n",
      "Train loss and acc of batch 63: 48.89229965209961, 0.96875\n",
      "Train loss and acc of batch 64: 47.91765594482422, 0.984375\n",
      "Train loss and acc of batch 65: 47.70088195800781, 1.0\n",
      "Train loss and acc of batch 66: 47.700870513916016, 1.0\n",
      "Train loss and acc of batch 67: 48.513328552246094, 0.96875\n",
      "Train loss and acc of batch 68: 48.29655456542969, 0.984375\n",
      "Train loss and acc of batch 69: 47.91761016845703, 0.984375\n",
      "Train loss and acc of batch 70: 47.700836181640625, 1.0\n",
      "Training accuracy and loss of epoch #566: 0.9897, 48.0220\n",
      "Saved model by train loss 48.02202960806833\n",
      "Train loss and acc of batch 0: 47.700828552246094, 1.0\n",
      "Train loss and acc of batch 1: 47.7008171081543, 1.0\n",
      "Train loss and acc of batch 2: 47.700809478759766, 1.0\n",
      "Train loss and acc of batch 3: 47.917572021484375, 0.984375\n",
      "Train loss and acc of batch 4: 47.70079040527344, 1.0\n",
      "Train loss and acc of batch 5: 49.049705505371094, 0.96875\n",
      "Train loss and acc of batch 6: 48.203392028808594, 0.96875\n",
      "Train loss and acc of batch 7: 47.70076370239258, 1.0\n",
      "Train loss and acc of batch 8: 48.29646301269531, 0.984375\n",
      "Train loss and acc of batch 9: 47.986602783203125, 0.984375\n",
      "Train loss and acc of batch 10: 47.700740814208984, 1.0\n",
      "Train loss and acc of batch 11: 47.70072937011719, 1.0\n",
      "Train loss and acc of batch 12: 48.45394515991211, 0.984375\n",
      "Train loss and acc of batch 13: 47.91747283935547, 0.984375\n",
      "Train loss and acc of batch 14: 47.91747283935547, 0.984375\n",
      "Train loss and acc of batch 15: 48.29639434814453, 0.984375\n",
      "Train loss and acc of batch 16: 48.29638671875, 0.984375\n",
      "Train loss and acc of batch 17: 48.45390701293945, 0.984375\n",
      "Train loss and acc of batch 18: 48.58222198486328, 0.96875\n",
      "Train loss and acc of batch 19: 47.70065689086914, 1.0\n",
      "Train loss and acc of batch 20: 47.70065689086914, 1.0\n",
      "Train loss and acc of batch 21: 48.29634094238281, 0.984375\n",
      "Train loss and acc of batch 22: 48.29633331298828, 0.984375\n",
      "Train loss and acc of batch 23: 47.700626373291016, 1.0\n",
      "Train loss and acc of batch 24: 48.29631805419922, 0.984375\n",
      "Train loss and acc of batch 25: 47.70060348510742, 1.0\n",
      "Train loss and acc of batch 26: 47.700599670410156, 1.0\n",
      "Train loss and acc of batch 27: 47.700584411621094, 1.0\n",
      "Train loss and acc of batch 28: 47.70058059692383, 1.0\n",
      "Train loss and acc of batch 29: 48.29627227783203, 0.984375\n",
      "Train loss and acc of batch 30: 47.700565338134766, 1.0\n",
      "Train loss and acc of batch 31: 47.917320251464844, 0.984375\n",
      "Train loss and acc of batch 32: 47.70054244995117, 1.0\n",
      "Train loss and acc of batch 33: 47.70053482055664, 1.0\n",
      "Train loss and acc of batch 34: 48.296234130859375, 0.984375\n",
      "Train loss and acc of batch 35: 48.1340446472168, 0.96875\n",
      "Train loss and acc of batch 36: 47.70051193237305, 1.0\n",
      "Train loss and acc of batch 37: 48.4537239074707, 0.984375\n",
      "Train loss and acc of batch 38: 49.049415588378906, 0.96875\n",
      "Train loss and acc of batch 39: 47.91724395751953, 0.984375\n",
      "Train loss and acc of batch 40: 47.700469970703125, 1.0\n",
      "Train loss and acc of batch 41: 49.04938888549805, 0.96875\n",
      "Train loss and acc of batch 42: 47.70045471191406, 1.0\n",
      "Train loss and acc of batch 43: 48.29615020751953, 0.984375\n",
      "Train loss and acc of batch 44: 47.700439453125, 1.0\n",
      "Train loss and acc of batch 45: 48.29613494873047, 0.984375\n",
      "Train loss and acc of batch 46: 47.98627471923828, 0.984375\n",
      "Train loss and acc of batch 47: 47.70041275024414, 1.0\n",
      "Train loss and acc of batch 48: 47.70040512084961, 1.0\n",
      "Train loss and acc of batch 49: 47.70039367675781, 1.0\n",
      "Train loss and acc of batch 50: 48.29608154296875, 0.984375\n",
      "Train loss and acc of batch 51: 49.04930114746094, 0.96875\n",
      "Train loss and acc of batch 52: 48.95620346069336, 0.953125\n",
      "Train loss and acc of batch 53: 47.70036315917969, 1.0\n",
      "Train loss and acc of batch 54: 47.9171142578125, 0.984375\n",
      "Train loss and acc of batch 55: 47.70033645629883, 1.0\n",
      "Train loss and acc of batch 56: 47.7003288269043, 1.0\n",
      "Train loss and acc of batch 57: 48.2960205078125, 0.984375\n",
      "Train loss and acc of batch 58: 47.700313568115234, 1.0\n",
      "Train loss and acc of batch 59: 47.70030975341797, 1.0\n",
      "Train loss and acc of batch 60: 47.70029830932617, 1.0\n",
      "Train loss and acc of batch 61: 47.700286865234375, 1.0\n",
      "Train loss and acc of batch 62: 47.700279235839844, 1.0\n",
      "Train loss and acc of batch 63: 48.89167022705078, 0.96875\n",
      "Train loss and acc of batch 64: 47.917022705078125, 0.984375\n",
      "Train loss and acc of batch 65: 47.70025634765625, 1.0\n",
      "Train loss and acc of batch 66: 47.70024108886719, 1.0\n",
      "Train loss and acc of batch 67: 48.512699127197266, 0.96875\n",
      "Train loss and acc of batch 68: 48.295928955078125, 0.984375\n",
      "Train loss and acc of batch 69: 47.91698455810547, 0.984375\n",
      "Train loss and acc of batch 70: 47.7002067565918, 1.0\n",
      "Training accuracy and loss of epoch #567: 0.9897, 48.0214\n",
      "Saved model by train loss 48.02140136503837\n",
      "Train loss and acc of batch 0: 47.700199127197266, 1.0\n",
      "Train loss and acc of batch 1: 47.70018768310547, 1.0\n",
      "Train loss and acc of batch 2: 47.7001838684082, 1.0\n",
      "Train loss and acc of batch 3: 47.91693878173828, 0.984375\n",
      "Train loss and acc of batch 4: 47.700164794921875, 1.0\n",
      "Train loss and acc of batch 5: 49.04907989501953, 0.96875\n",
      "Train loss and acc of batch 6: 48.202762603759766, 0.96875\n",
      "Train loss and acc of batch 7: 47.700138092041016, 1.0\n",
      "Train loss and acc of batch 8: 48.29582977294922, 0.984375\n",
      "Train loss and acc of batch 9: 47.98596954345703, 0.984375\n",
      "Train loss and acc of batch 10: 47.700111389160156, 1.0\n",
      "Train loss and acc of batch 11: 47.700103759765625, 1.0\n",
      "Train loss and acc of batch 12: 48.45331573486328, 0.984375\n",
      "Train loss and acc of batch 13: 47.916847229003906, 0.984375\n",
      "Train loss and acc of batch 14: 47.916831970214844, 0.984375\n",
      "Train loss and acc of batch 15: 48.29576873779297, 0.984375\n",
      "Train loss and acc of batch 16: 48.29576110839844, 0.984375\n",
      "Train loss and acc of batch 17: 48.45327377319336, 0.984375\n",
      "Train loss and acc of batch 18: 48.58159255981445, 0.96875\n",
      "Train loss and acc of batch 19: 47.70003128051758, 1.0\n",
      "Train loss and acc of batch 20: 47.70001983642578, 1.0\n",
      "Train loss and acc of batch 21: 48.29571533203125, 0.984375\n",
      "Train loss and acc of batch 22: 48.29570770263672, 0.984375\n",
      "Train loss and acc of batch 23: 47.69999313354492, 1.0\n",
      "Train loss and acc of batch 24: 48.295692443847656, 0.984375\n",
      "Train loss and acc of batch 25: 47.699981689453125, 1.0\n",
      "Train loss and acc of batch 26: 47.69997024536133, 1.0\n",
      "Train loss and acc of batch 27: 47.6999626159668, 1.0\n",
      "Train loss and acc of batch 28: 47.699947357177734, 1.0\n",
      "Train loss and acc of batch 29: 48.29564666748047, 0.984375\n",
      "Train loss and acc of batch 30: 47.6999397277832, 1.0\n",
      "Train loss and acc of batch 31: 47.91668701171875, 0.984375\n",
      "Train loss and acc of batch 32: 47.699913024902344, 1.0\n",
      "Train loss and acc of batch 33: 47.69990921020508, 1.0\n",
      "Train loss and acc of batch 34: 48.29560089111328, 0.984375\n",
      "Train loss and acc of batch 35: 48.133419036865234, 0.96875\n",
      "Train loss and acc of batch 36: 47.69988250732422, 1.0\n",
      "Train loss and acc of batch 37: 48.453094482421875, 0.984375\n",
      "Train loss and acc of batch 38: 49.048789978027344, 0.96875\n",
      "Train loss and acc of batch 39: 47.9166259765625, 0.984375\n",
      "Train loss and acc of batch 40: 47.69984436035156, 1.0\n",
      "Train loss and acc of batch 41: 49.048763275146484, 0.96875\n",
      "Train loss and acc of batch 42: 47.699825286865234, 1.0\n",
      "Train loss and acc of batch 43: 48.29551696777344, 0.984375\n",
      "Train loss and acc of batch 44: 47.69981002807617, 1.0\n",
      "Train loss and acc of batch 45: 48.295501708984375, 0.984375\n",
      "Train loss and acc of batch 46: 47.98564147949219, 0.984375\n",
      "Train loss and acc of batch 47: 47.69978332519531, 1.0\n",
      "Train loss and acc of batch 48: 47.69977569580078, 1.0\n",
      "Train loss and acc of batch 49: 47.69976806640625, 1.0\n",
      "Train loss and acc of batch 50: 48.29545593261719, 0.984375\n",
      "Train loss and acc of batch 51: 49.048667907714844, 0.96875\n",
      "Train loss and acc of batch 52: 48.9555778503418, 0.953125\n",
      "Train loss and acc of batch 53: 47.699729919433594, 1.0\n",
      "Train loss and acc of batch 54: 47.91648864746094, 0.984375\n",
      "Train loss and acc of batch 55: 47.69971466064453, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 56: 47.699703216552734, 1.0\n",
      "Train loss and acc of batch 57: 48.29539489746094, 0.984375\n",
      "Train loss and acc of batch 58: 47.69968795776367, 1.0\n",
      "Train loss and acc of batch 59: 47.69968032836914, 1.0\n",
      "Train loss and acc of batch 60: 47.69966506958008, 1.0\n",
      "Train loss and acc of batch 61: 47.69966125488281, 1.0\n",
      "Train loss and acc of batch 62: 47.69965362548828, 1.0\n",
      "Train loss and acc of batch 63: 48.89104461669922, 0.96875\n",
      "Train loss and acc of batch 64: 47.91639709472656, 0.984375\n",
      "Train loss and acc of batch 65: 47.69961929321289, 1.0\n",
      "Train loss and acc of batch 66: 47.699615478515625, 1.0\n",
      "Train loss and acc of batch 67: 48.51207733154297, 0.96875\n",
      "Train loss and acc of batch 68: 48.29530334472656, 0.984375\n",
      "Train loss and acc of batch 69: 47.916351318359375, 0.984375\n",
      "Train loss and acc of batch 70: 47.699581146240234, 1.0\n",
      "Training accuracy and loss of epoch #568: 0.9897, 48.0208\n",
      "Saved model by train loss 48.020773122008414\n",
      "Train loss and acc of batch 0: 47.69956588745117, 1.0\n",
      "Train loss and acc of batch 1: 47.69956588745117, 1.0\n",
      "Train loss and acc of batch 2: 47.699554443359375, 1.0\n",
      "Train loss and acc of batch 3: 47.91630554199219, 0.984375\n",
      "Train loss and acc of batch 4: 47.69953918457031, 1.0\n",
      "Train loss and acc of batch 5: 49.04844665527344, 0.96875\n",
      "Train loss and acc of batch 6: 48.20213317871094, 0.96875\n",
      "Train loss and acc of batch 7: 47.69951248168945, 1.0\n",
      "Train loss and acc of batch 8: 48.295196533203125, 0.984375\n",
      "Train loss and acc of batch 9: 47.98534393310547, 0.984375\n",
      "Train loss and acc of batch 10: 47.69947814941406, 1.0\n",
      "Train loss and acc of batch 11: 47.6994743347168, 1.0\n",
      "Train loss and acc of batch 12: 48.45268630981445, 0.984375\n",
      "Train loss and acc of batch 13: 47.916221618652344, 0.984375\n",
      "Train loss and acc of batch 14: 47.91621398925781, 0.984375\n",
      "Train loss and acc of batch 15: 48.295143127441406, 0.984375\n",
      "Train loss and acc of batch 16: 48.295127868652344, 0.984375\n",
      "Train loss and acc of batch 17: 48.452640533447266, 0.984375\n",
      "Train loss and acc of batch 18: 48.58096694946289, 0.96875\n",
      "Train loss and acc of batch 19: 47.69940948486328, 1.0\n",
      "Train loss and acc of batch 20: 47.69939422607422, 1.0\n",
      "Train loss and acc of batch 21: 48.29508972167969, 0.984375\n",
      "Train loss and acc of batch 22: 48.295074462890625, 0.984375\n",
      "Train loss and acc of batch 23: 47.699363708496094, 1.0\n",
      "Train loss and acc of batch 24: 48.29505920410156, 0.984375\n",
      "Train loss and acc of batch 25: 47.69934844970703, 1.0\n",
      "Train loss and acc of batch 26: 47.6993408203125, 1.0\n",
      "Train loss and acc of batch 27: 47.6993293762207, 1.0\n",
      "Train loss and acc of batch 28: 47.69932556152344, 1.0\n",
      "Train loss and acc of batch 29: 48.295021057128906, 0.984375\n",
      "Train loss and acc of batch 30: 47.69930648803711, 1.0\n",
      "Train loss and acc of batch 31: 47.91606140136719, 0.984375\n",
      "Train loss and acc of batch 32: 47.69929122924805, 1.0\n",
      "Train loss and acc of batch 33: 47.69927978515625, 1.0\n",
      "Train loss and acc of batch 34: 48.29497528076172, 0.984375\n",
      "Train loss and acc of batch 35: 48.132789611816406, 0.96875\n",
      "Train loss and acc of batch 36: 47.699249267578125, 1.0\n",
      "Train loss and acc of batch 37: 48.45246505737305, 0.984375\n",
      "Train loss and acc of batch 38: 49.04815673828125, 0.96875\n",
      "Train loss and acc of batch 39: 47.915985107421875, 0.984375\n",
      "Train loss and acc of batch 40: 47.699214935302734, 1.0\n",
      "Train loss and acc of batch 41: 49.048133850097656, 0.96875\n",
      "Train loss and acc of batch 42: 47.69919967651367, 1.0\n",
      "Train loss and acc of batch 43: 48.294891357421875, 0.984375\n",
      "Train loss and acc of batch 44: 47.699180603027344, 1.0\n",
      "Train loss and acc of batch 45: 48.29486846923828, 0.984375\n",
      "Train loss and acc of batch 46: 47.985015869140625, 0.984375\n",
      "Train loss and acc of batch 47: 47.69915771484375, 1.0\n",
      "Train loss and acc of batch 48: 47.69914627075195, 1.0\n",
      "Train loss and acc of batch 49: 47.69914245605469, 1.0\n",
      "Train loss and acc of batch 50: 48.294830322265625, 0.984375\n",
      "Train loss and acc of batch 51: 49.04804229736328, 0.96875\n",
      "Train loss and acc of batch 52: 48.954952239990234, 0.953125\n",
      "Train loss and acc of batch 53: 47.699100494384766, 1.0\n",
      "Train loss and acc of batch 54: 47.915863037109375, 0.984375\n",
      "Train loss and acc of batch 55: 47.69908142089844, 1.0\n",
      "Train loss and acc of batch 56: 47.699073791503906, 1.0\n",
      "Train loss and acc of batch 57: 48.294769287109375, 0.984375\n",
      "Train loss and acc of batch 58: 47.69906234741211, 1.0\n",
      "Train loss and acc of batch 59: 47.69904708862305, 1.0\n",
      "Train loss and acc of batch 60: 47.699039459228516, 1.0\n",
      "Train loss and acc of batch 61: 47.699031829833984, 1.0\n",
      "Train loss and acc of batch 62: 47.69902038574219, 1.0\n",
      "Train loss and acc of batch 63: 48.890419006347656, 0.96875\n",
      "Train loss and acc of batch 64: 47.915771484375, 0.984375\n",
      "Train loss and acc of batch 65: 47.69899368286133, 1.0\n",
      "Train loss and acc of batch 66: 47.69898986816406, 1.0\n",
      "Train loss and acc of batch 67: 48.511444091796875, 0.96875\n",
      "Train loss and acc of batch 68: 48.29467010498047, 0.984375\n",
      "Train loss and acc of batch 69: 47.91572570800781, 0.984375\n",
      "Train loss and acc of batch 70: 47.69894790649414, 1.0\n",
      "Training accuracy and loss of epoch #569: 0.9897, 48.0201\n",
      "Saved model by train loss 48.02014450288155\n",
      "Train loss and acc of batch 0: 47.698944091796875, 1.0\n",
      "Train loss and acc of batch 1: 47.69893264770508, 1.0\n",
      "Train loss and acc of batch 2: 47.69892501831055, 1.0\n",
      "Train loss and acc of batch 3: 47.915679931640625, 0.984375\n",
      "Train loss and acc of batch 4: 47.698909759521484, 1.0\n",
      "Train loss and acc of batch 5: 49.047821044921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.201507568359375, 0.96875\n",
      "Train loss and acc of batch 7: 47.69887924194336, 1.0\n",
      "Train loss and acc of batch 8: 48.29457092285156, 0.984375\n",
      "Train loss and acc of batch 9: 47.984718322753906, 0.984375\n",
      "Train loss and acc of batch 10: 47.698856353759766, 1.0\n",
      "Train loss and acc of batch 11: 47.69884490966797, 1.0\n",
      "Train loss and acc of batch 12: 48.452064514160156, 0.984375\n",
      "Train loss and acc of batch 13: 47.91558837890625, 0.984375\n",
      "Train loss and acc of batch 14: 47.91558837890625, 0.984375\n",
      "Train loss and acc of batch 15: 48.294517517089844, 0.984375\n",
      "Train loss and acc of batch 16: 48.29450225830078, 0.984375\n",
      "Train loss and acc of batch 17: 48.45201110839844, 0.984375\n",
      "Train loss and acc of batch 18: 48.5803337097168, 0.96875\n",
      "Train loss and acc of batch 19: 47.69877243041992, 1.0\n",
      "Train loss and acc of batch 20: 47.698768615722656, 1.0\n",
      "Train loss and acc of batch 21: 48.294456481933594, 0.984375\n",
      "Train loss and acc of batch 22: 48.29444885253906, 0.984375\n",
      "Train loss and acc of batch 23: 47.6987419128418, 1.0\n",
      "Train loss and acc of batch 24: 48.29443359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.6987190246582, 1.0\n",
      "Train loss and acc of batch 26: 47.69871520996094, 1.0\n",
      "Train loss and acc of batch 27: 47.69870376586914, 1.0\n",
      "Train loss and acc of batch 28: 47.698692321777344, 1.0\n",
      "Train loss and acc of batch 29: 48.294395446777344, 0.984375\n",
      "Train loss and acc of batch 30: 47.69867706298828, 1.0\n",
      "Train loss and acc of batch 31: 47.915435791015625, 0.984375\n",
      "Train loss and acc of batch 32: 47.69865798950195, 1.0\n",
      "Train loss and acc of batch 33: 47.69865036010742, 1.0\n",
      "Train loss and acc of batch 34: 48.294342041015625, 0.984375\n",
      "Train loss and acc of batch 35: 48.13216018676758, 0.96875\n",
      "Train loss and acc of batch 36: 47.69862365722656, 1.0\n",
      "Train loss and acc of batch 37: 48.451839447021484, 0.984375\n",
      "Train loss and acc of batch 38: 49.04753112792969, 0.96875\n",
      "Train loss and acc of batch 39: 47.91535949707031, 0.984375\n",
      "Train loss and acc of batch 40: 47.69858932495117, 1.0\n",
      "Train loss and acc of batch 41: 49.047508239746094, 0.96875\n",
      "Train loss and acc of batch 42: 47.698570251464844, 1.0\n",
      "Train loss and acc of batch 43: 48.29426574707031, 0.984375\n",
      "Train loss and acc of batch 44: 47.698551177978516, 1.0\n",
      "Train loss and acc of batch 45: 48.29424285888672, 0.984375\n",
      "Train loss and acc of batch 46: 47.98439025878906, 0.984375\n",
      "Train loss and acc of batch 47: 47.698524475097656, 1.0\n",
      "Train loss and acc of batch 48: 47.698516845703125, 1.0\n",
      "Train loss and acc of batch 49: 47.698509216308594, 1.0\n",
      "Train loss and acc of batch 50: 48.29419708251953, 0.984375\n",
      "Train loss and acc of batch 51: 49.04741668701172, 0.96875\n",
      "Train loss and acc of batch 52: 48.954322814941406, 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 53: 47.69847106933594, 1.0\n",
      "Train loss and acc of batch 54: 47.91522979736328, 0.984375\n",
      "Train loss and acc of batch 55: 47.69845199584961, 1.0\n",
      "Train loss and acc of batch 56: 47.698448181152344, 1.0\n",
      "Train loss and acc of batch 57: 48.29414367675781, 0.984375\n",
      "Train loss and acc of batch 58: 47.69842529296875, 1.0\n",
      "Train loss and acc of batch 59: 47.698421478271484, 1.0\n",
      "Train loss and acc of batch 60: 47.69841003417969, 1.0\n",
      "Train loss and acc of batch 61: 47.698402404785156, 1.0\n",
      "Train loss and acc of batch 62: 47.69839096069336, 1.0\n",
      "Train loss and acc of batch 63: 48.88978958129883, 0.96875\n",
      "Train loss and acc of batch 64: 47.915138244628906, 0.984375\n",
      "Train loss and acc of batch 65: 47.698368072509766, 1.0\n",
      "Train loss and acc of batch 66: 47.69835662841797, 1.0\n",
      "Train loss and acc of batch 67: 48.51081466674805, 0.96875\n",
      "Train loss and acc of batch 68: 48.294036865234375, 0.984375\n",
      "Train loss and acc of batch 69: 47.91509246826172, 0.984375\n",
      "Train loss and acc of batch 70: 47.69832229614258, 1.0\n",
      "Training accuracy and loss of epoch #570: 0.9897, 48.0195\n",
      "Saved model by train loss 48.01951604493907\n",
      "Train loss and acc of batch 0: 47.69831848144531, 1.0\n",
      "Train loss and acc of batch 1: 47.69830322265625, 1.0\n",
      "Train loss and acc of batch 2: 47.698299407958984, 1.0\n",
      "Train loss and acc of batch 3: 47.91505432128906, 0.984375\n",
      "Train loss and acc of batch 4: 47.698280334472656, 1.0\n",
      "Train loss and acc of batch 5: 49.04719543457031, 0.96875\n",
      "Train loss and acc of batch 6: 48.20087432861328, 0.96875\n",
      "Train loss and acc of batch 7: 47.69824981689453, 1.0\n",
      "Train loss and acc of batch 8: 48.2939453125, 0.984375\n",
      "Train loss and acc of batch 9: 47.98408508300781, 0.984375\n",
      "Train loss and acc of batch 10: 47.69822311401367, 1.0\n",
      "Train loss and acc of batch 11: 47.698219299316406, 1.0\n",
      "Train loss and acc of batch 12: 48.45143127441406, 0.984375\n",
      "Train loss and acc of batch 13: 47.91496276855469, 0.984375\n",
      "Train loss and acc of batch 14: 47.914955139160156, 0.984375\n",
      "Train loss and acc of batch 15: 48.29387664794922, 0.984375\n",
      "Train loss and acc of batch 16: 48.29386901855469, 0.984375\n",
      "Train loss and acc of batch 17: 48.45138931274414, 0.984375\n",
      "Train loss and acc of batch 18: 48.579708099365234, 0.96875\n",
      "Train loss and acc of batch 19: 47.698143005371094, 1.0\n",
      "Train loss and acc of batch 20: 47.69813537597656, 1.0\n",
      "Train loss and acc of batch 21: 48.29383087158203, 0.984375\n",
      "Train loss and acc of batch 22: 48.2938232421875, 0.984375\n",
      "Train loss and acc of batch 23: 47.69811248779297, 1.0\n",
      "Train loss and acc of batch 24: 48.29380798339844, 0.984375\n",
      "Train loss and acc of batch 25: 47.69809341430664, 1.0\n",
      "Train loss and acc of batch 26: 47.69807815551758, 1.0\n",
      "Train loss and acc of batch 27: 47.69807434082031, 1.0\n",
      "Train loss and acc of batch 28: 47.69806671142578, 1.0\n",
      "Train loss and acc of batch 29: 48.29376220703125, 0.984375\n",
      "Train loss and acc of batch 30: 47.69804763793945, 1.0\n",
      "Train loss and acc of batch 31: 47.91481018066406, 0.984375\n",
      "Train loss and acc of batch 32: 47.698028564453125, 1.0\n",
      "Train loss and acc of batch 33: 47.69802474975586, 1.0\n",
      "Train loss and acc of batch 34: 48.29371643066406, 0.984375\n",
      "Train loss and acc of batch 35: 48.131534576416016, 0.96875\n",
      "Train loss and acc of batch 36: 47.697994232177734, 1.0\n",
      "Train loss and acc of batch 37: 48.45120620727539, 0.984375\n",
      "Train loss and acc of batch 38: 49.046905517578125, 0.96875\n",
      "Train loss and acc of batch 39: 47.91473388671875, 0.984375\n",
      "Train loss and acc of batch 40: 47.697959899902344, 1.0\n",
      "Train loss and acc of batch 41: 49.046878814697266, 0.96875\n",
      "Train loss and acc of batch 42: 47.69794464111328, 1.0\n",
      "Train loss and acc of batch 43: 48.29364013671875, 0.984375\n",
      "Train loss and acc of batch 44: 47.69792556762695, 1.0\n",
      "Train loss and acc of batch 45: 48.293617248535156, 0.984375\n",
      "Train loss and acc of batch 46: 47.98375701904297, 0.984375\n",
      "Train loss and acc of batch 47: 47.69790267944336, 1.0\n",
      "Train loss and acc of batch 48: 47.69789123535156, 1.0\n",
      "Train loss and acc of batch 49: 47.697879791259766, 1.0\n",
      "Train loss and acc of batch 50: 48.29357147216797, 0.984375\n",
      "Train loss and acc of batch 51: 49.046783447265625, 0.96875\n",
      "Train loss and acc of batch 52: 48.953697204589844, 0.953125\n",
      "Train loss and acc of batch 53: 47.697845458984375, 1.0\n",
      "Train loss and acc of batch 54: 47.91459655761719, 0.984375\n",
      "Train loss and acc of batch 55: 47.69783020019531, 1.0\n",
      "Train loss and acc of batch 56: 47.69782257080078, 1.0\n",
      "Train loss and acc of batch 57: 48.29351043701172, 0.984375\n",
      "Train loss and acc of batch 58: 47.69780349731445, 1.0\n",
      "Train loss and acc of batch 59: 47.697792053222656, 1.0\n",
      "Train loss and acc of batch 60: 47.697784423828125, 1.0\n",
      "Train loss and acc of batch 61: 47.697776794433594, 1.0\n",
      "Train loss and acc of batch 62: 47.6977653503418, 1.0\n",
      "Train loss and acc of batch 63: 48.88916015625, 0.96875\n",
      "Train loss and acc of batch 64: 47.914512634277344, 0.984375\n",
      "Train loss and acc of batch 65: 47.69773864746094, 1.0\n",
      "Train loss and acc of batch 66: 47.697731018066406, 1.0\n",
      "Train loss and acc of batch 67: 48.51018524169922, 0.96875\n",
      "Train loss and acc of batch 68: 48.29341125488281, 0.984375\n",
      "Train loss and acc of batch 69: 47.914466857910156, 0.984375\n",
      "Train loss and acc of batch 70: 47.69770050048828, 1.0\n",
      "Training accuracy and loss of epoch #571: 0.9897, 48.0189\n",
      "Saved model by train loss 48.018888070549764\n",
      "Train loss and acc of batch 0: 47.69768524169922, 1.0\n",
      "Train loss and acc of batch 1: 47.69767761230469, 1.0\n",
      "Train loss and acc of batch 2: 47.69766616821289, 1.0\n",
      "Train loss and acc of batch 3: 47.9144287109375, 0.984375\n",
      "Train loss and acc of batch 4: 47.697654724121094, 1.0\n",
      "Train loss and acc of batch 5: 49.04656219482422, 0.96875\n",
      "Train loss and acc of batch 6: 48.20024871826172, 0.96875\n",
      "Train loss and acc of batch 7: 47.697628021240234, 1.0\n",
      "Train loss and acc of batch 8: 48.29331970214844, 0.984375\n",
      "Train loss and acc of batch 9: 47.98345947265625, 0.984375\n",
      "Train loss and acc of batch 10: 47.69759750366211, 1.0\n",
      "Train loss and acc of batch 11: 47.69758224487305, 1.0\n",
      "Train loss and acc of batch 12: 48.450801849365234, 0.984375\n",
      "Train loss and acc of batch 13: 47.914337158203125, 0.984375\n",
      "Train loss and acc of batch 14: 47.914329528808594, 0.984375\n",
      "Train loss and acc of batch 15: 48.29325866699219, 0.984375\n",
      "Train loss and acc of batch 16: 48.293243408203125, 0.984375\n",
      "Train loss and acc of batch 17: 48.45075607299805, 0.984375\n",
      "Train loss and acc of batch 18: 48.57908248901367, 0.96875\n",
      "Train loss and acc of batch 19: 47.6975212097168, 1.0\n",
      "Train loss and acc of batch 20: 47.697509765625, 1.0\n",
      "Train loss and acc of batch 21: 48.29320526123047, 0.984375\n",
      "Train loss and acc of batch 22: 48.293190002441406, 0.984375\n",
      "Train loss and acc of batch 23: 47.697479248046875, 1.0\n",
      "Train loss and acc of batch 24: 48.293174743652344, 0.984375\n",
      "Train loss and acc of batch 25: 47.69746017456055, 1.0\n",
      "Train loss and acc of batch 26: 47.69745635986328, 1.0\n",
      "Train loss and acc of batch 27: 47.697452545166016, 1.0\n",
      "Train loss and acc of batch 28: 47.69743728637695, 1.0\n",
      "Train loss and acc of batch 29: 48.293128967285156, 0.984375\n",
      "Train loss and acc of batch 30: 47.697418212890625, 1.0\n",
      "Train loss and acc of batch 31: 47.91417694091797, 0.984375\n",
      "Train loss and acc of batch 32: 47.69740676879883, 1.0\n",
      "Train loss and acc of batch 33: 47.69739532470703, 1.0\n",
      "Train loss and acc of batch 34: 48.29308319091797, 0.984375\n",
      "Train loss and acc of batch 35: 48.13090896606445, 0.96875\n",
      "Train loss and acc of batch 36: 47.69736862182617, 1.0\n",
      "Train loss and acc of batch 37: 48.450584411621094, 0.984375\n",
      "Train loss and acc of batch 38: 49.04627227783203, 0.96875\n",
      "Train loss and acc of batch 39: 47.914100646972656, 0.984375\n",
      "Train loss and acc of batch 40: 47.697330474853516, 1.0\n",
      "Train loss and acc of batch 41: 49.04624938964844, 0.96875\n",
      "Train loss and acc of batch 42: 47.69731140136719, 1.0\n",
      "Train loss and acc of batch 43: 48.293006896972656, 0.984375\n",
      "Train loss and acc of batch 44: 47.697296142578125, 1.0\n",
      "Train loss and acc of batch 45: 48.29298400878906, 0.984375\n",
      "Train loss and acc of batch 46: 47.983131408691406, 0.984375\n",
      "Train loss and acc of batch 47: 47.697269439697266, 1.0\n",
      "Train loss and acc of batch 48: 47.697261810302734, 1.0\n",
      "Train loss and acc of batch 49: 47.69725036621094, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 50: 48.292945861816406, 0.984375\n",
      "Train loss and acc of batch 51: 49.04615783691406, 0.96875\n",
      "Train loss and acc of batch 52: 48.95306396484375, 0.953125\n",
      "Train loss and acc of batch 53: 47.69721603393555, 1.0\n",
      "Train loss and acc of batch 54: 47.913970947265625, 0.984375\n",
      "Train loss and acc of batch 55: 47.697200775146484, 1.0\n",
      "Train loss and acc of batch 56: 47.69718551635742, 1.0\n",
      "Train loss and acc of batch 57: 48.292884826660156, 0.984375\n",
      "Train loss and acc of batch 58: 47.697174072265625, 1.0\n",
      "Train loss and acc of batch 59: 47.69716262817383, 1.0\n",
      "Train loss and acc of batch 60: 47.6971549987793, 1.0\n",
      "Train loss and acc of batch 61: 47.697147369384766, 1.0\n",
      "Train loss and acc of batch 62: 47.6971321105957, 1.0\n",
      "Train loss and acc of batch 63: 48.88853073120117, 0.96875\n",
      "Train loss and acc of batch 64: 47.91388702392578, 0.984375\n",
      "Train loss and acc of batch 65: 47.697113037109375, 1.0\n",
      "Train loss and acc of batch 66: 47.69710922241211, 1.0\n",
      "Train loss and acc of batch 67: 48.509559631347656, 0.96875\n",
      "Train loss and acc of batch 68: 48.29278564453125, 0.984375\n",
      "Train loss and acc of batch 69: 47.913841247558594, 0.984375\n",
      "Train loss and acc of batch 70: 47.69706726074219, 1.0\n",
      "Training accuracy and loss of epoch #572: 0.9897, 48.0183\n",
      "Saved model by train loss 48.01825961260728\n",
      "Train loss and acc of batch 0: 47.69705581665039, 1.0\n",
      "Train loss and acc of batch 1: 47.697052001953125, 1.0\n",
      "Train loss and acc of batch 2: 47.697044372558594, 1.0\n",
      "Train loss and acc of batch 3: 47.913795471191406, 0.984375\n",
      "Train loss and acc of batch 4: 47.697021484375, 1.0\n",
      "Train loss and acc of batch 5: 49.045936584472656, 0.96875\n",
      "Train loss and acc of batch 6: 48.199623107910156, 0.96875\n",
      "Train loss and acc of batch 7: 47.69699478149414, 1.0\n",
      "Train loss and acc of batch 8: 48.292686462402344, 0.984375\n",
      "Train loss and acc of batch 9: 47.98283386230469, 0.984375\n",
      "Train loss and acc of batch 10: 47.69696807861328, 1.0\n",
      "Train loss and acc of batch 11: 47.696956634521484, 1.0\n",
      "Train loss and acc of batch 12: 48.45017623901367, 0.984375\n",
      "Train loss and acc of batch 13: 47.91370391845703, 0.984375\n",
      "Train loss and acc of batch 14: 47.9136962890625, 0.984375\n",
      "Train loss and acc of batch 15: 48.292625427246094, 0.984375\n",
      "Train loss and acc of batch 16: 48.29261779785156, 0.984375\n",
      "Train loss and acc of batch 17: 48.45012664794922, 0.984375\n",
      "Train loss and acc of batch 18: 48.57844924926758, 0.96875\n",
      "Train loss and acc of batch 19: 47.69688415527344, 1.0\n",
      "Train loss and acc of batch 20: 47.69688034057617, 1.0\n",
      "Train loss and acc of batch 21: 48.292572021484375, 0.984375\n",
      "Train loss and acc of batch 22: 48.292564392089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.69685745239258, 1.0\n",
      "Train loss and acc of batch 24: 48.29254913330078, 0.984375\n",
      "Train loss and acc of batch 25: 47.696834564208984, 1.0\n",
      "Train loss and acc of batch 26: 47.69682693481445, 1.0\n",
      "Train loss and acc of batch 27: 47.69681930541992, 1.0\n",
      "Train loss and acc of batch 28: 47.696807861328125, 1.0\n",
      "Train loss and acc of batch 29: 48.292503356933594, 0.984375\n",
      "Train loss and acc of batch 30: 47.69679260253906, 1.0\n",
      "Train loss and acc of batch 31: 47.913551330566406, 0.984375\n",
      "Train loss and acc of batch 32: 47.696781158447266, 1.0\n",
      "Train loss and acc of batch 33: 47.69676208496094, 1.0\n",
      "Train loss and acc of batch 34: 48.292457580566406, 0.984375\n",
      "Train loss and acc of batch 35: 48.130279541015625, 0.96875\n",
      "Train loss and acc of batch 36: 47.69673538208008, 1.0\n",
      "Train loss and acc of batch 37: 48.449954986572266, 0.984375\n",
      "Train loss and acc of batch 38: 49.04564666748047, 0.96875\n",
      "Train loss and acc of batch 39: 47.913475036621094, 0.984375\n",
      "Train loss and acc of batch 40: 47.69670486450195, 1.0\n",
      "Train loss and acc of batch 41: 49.04561996459961, 0.96875\n",
      "Train loss and acc of batch 42: 47.69668197631836, 1.0\n",
      "Train loss and acc of batch 43: 48.292381286621094, 0.984375\n",
      "Train loss and acc of batch 44: 47.69667053222656, 1.0\n",
      "Train loss and acc of batch 45: 48.29236602783203, 0.984375\n",
      "Train loss and acc of batch 46: 47.982505798339844, 0.984375\n",
      "Train loss and acc of batch 47: 47.69664001464844, 1.0\n",
      "Train loss and acc of batch 48: 47.69662857055664, 1.0\n",
      "Train loss and acc of batch 49: 47.69662857055664, 1.0\n",
      "Train loss and acc of batch 50: 48.29231262207031, 0.984375\n",
      "Train loss and acc of batch 51: 49.0455322265625, 0.96875\n",
      "Train loss and acc of batch 52: 48.95243453979492, 0.953125\n",
      "Train loss and acc of batch 53: 47.69658660888672, 1.0\n",
      "Train loss and acc of batch 54: 47.91334533691406, 0.984375\n",
      "Train loss and acc of batch 55: 47.69656753540039, 1.0\n",
      "Train loss and acc of batch 56: 47.69655990600586, 1.0\n",
      "Train loss and acc of batch 57: 48.292259216308594, 0.984375\n",
      "Train loss and acc of batch 58: 47.69654083251953, 1.0\n",
      "Train loss and acc of batch 59: 47.696533203125, 1.0\n",
      "Train loss and acc of batch 60: 47.696529388427734, 1.0\n",
      "Train loss and acc of batch 61: 47.69651794433594, 1.0\n",
      "Train loss and acc of batch 62: 47.69650650024414, 1.0\n",
      "Train loss and acc of batch 63: 48.88790512084961, 0.96875\n",
      "Train loss and acc of batch 64: 47.91325378417969, 0.984375\n",
      "Train loss and acc of batch 65: 47.69648361206055, 1.0\n",
      "Train loss and acc of batch 66: 47.69647216796875, 1.0\n",
      "Train loss and acc of batch 67: 48.50893020629883, 0.96875\n",
      "Train loss and acc of batch 68: 48.29216003417969, 0.984375\n",
      "Train loss and acc of batch 69: 47.9132080078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.696434020996094, 1.0\n",
      "Training accuracy and loss of epoch #573: 0.9897, 48.0176\n",
      "Saved model by train loss 48.01763099348042\n",
      "Train loss and acc of batch 0: 47.69643020629883, 1.0\n",
      "Train loss and acc of batch 1: 47.6964225769043, 1.0\n",
      "Train loss and acc of batch 2: 47.6964111328125, 1.0\n",
      "Train loss and acc of batch 3: 47.913169860839844, 0.984375\n",
      "Train loss and acc of batch 4: 47.69639205932617, 1.0\n",
      "Train loss and acc of batch 5: 49.045310974121094, 0.96875\n",
      "Train loss and acc of batch 6: 48.19899368286133, 0.96875\n",
      "Train loss and acc of batch 7: 47.69636535644531, 1.0\n",
      "Train loss and acc of batch 8: 48.29206085205078, 0.984375\n",
      "Train loss and acc of batch 9: 47.982200622558594, 0.984375\n",
      "Train loss and acc of batch 10: 47.69633483886719, 1.0\n",
      "Train loss and acc of batch 11: 47.69633483886719, 1.0\n",
      "Train loss and acc of batch 12: 48.449546813964844, 0.984375\n",
      "Train loss and acc of batch 13: 47.91307067871094, 0.984375\n",
      "Train loss and acc of batch 14: 47.91307067871094, 0.984375\n",
      "Train loss and acc of batch 15: 48.29199981689453, 0.984375\n",
      "Train loss and acc of batch 16: 48.29198455810547, 0.984375\n",
      "Train loss and acc of batch 17: 48.44950485229492, 0.984375\n",
      "Train loss and acc of batch 18: 48.577823638916016, 0.96875\n",
      "Train loss and acc of batch 19: 47.69626235961914, 1.0\n",
      "Train loss and acc of batch 20: 47.696250915527344, 1.0\n",
      "Train loss and acc of batch 21: 48.29194641113281, 0.984375\n",
      "Train loss and acc of batch 22: 48.29193115234375, 0.984375\n",
      "Train loss and acc of batch 23: 47.69622802734375, 1.0\n",
      "Train loss and acc of batch 24: 48.29191589355469, 0.984375\n",
      "Train loss and acc of batch 25: 47.69621276855469, 1.0\n",
      "Train loss and acc of batch 26: 47.696197509765625, 1.0\n",
      "Train loss and acc of batch 27: 47.69618606567383, 1.0\n",
      "Train loss and acc of batch 28: 47.6961784362793, 1.0\n",
      "Train loss and acc of batch 29: 48.2918701171875, 0.984375\n",
      "Train loss and acc of batch 30: 47.696163177490234, 1.0\n",
      "Train loss and acc of batch 31: 47.91291809082031, 0.984375\n",
      "Train loss and acc of batch 32: 47.696144104003906, 1.0\n",
      "Train loss and acc of batch 33: 47.696136474609375, 1.0\n",
      "Train loss and acc of batch 34: 48.291831970214844, 0.984375\n",
      "Train loss and acc of batch 35: 48.1296501159668, 0.96875\n",
      "Train loss and acc of batch 36: 47.696109771728516, 1.0\n",
      "Train loss and acc of batch 37: 48.44932556152344, 0.984375\n",
      "Train loss and acc of batch 38: 49.045013427734375, 0.96875\n",
      "Train loss and acc of batch 39: 47.91284942626953, 0.984375\n",
      "Train loss and acc of batch 40: 47.69607925415039, 1.0\n",
      "Train loss and acc of batch 41: 49.044986724853516, 0.96875\n",
      "Train loss and acc of batch 42: 47.6960563659668, 1.0\n",
      "Train loss and acc of batch 43: 48.291748046875, 0.984375\n",
      "Train loss and acc of batch 44: 47.69603729248047, 1.0\n",
      "Train loss and acc of batch 45: 48.29173278808594, 0.984375\n",
      "Train loss and acc of batch 46: 47.98187255859375, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 47: 47.69601058959961, 1.0\n",
      "Train loss and acc of batch 48: 47.696006774902344, 1.0\n",
      "Train loss and acc of batch 49: 47.69599151611328, 1.0\n",
      "Train loss and acc of batch 50: 48.29168701171875, 0.984375\n",
      "Train loss and acc of batch 51: 49.04490661621094, 0.96875\n",
      "Train loss and acc of batch 52: 48.951812744140625, 0.953125\n",
      "Train loss and acc of batch 53: 47.695960998535156, 1.0\n",
      "Train loss and acc of batch 54: 47.9127197265625, 0.984375\n",
      "Train loss and acc of batch 55: 47.695945739746094, 1.0\n",
      "Train loss and acc of batch 56: 47.69593048095703, 1.0\n",
      "Train loss and acc of batch 57: 48.29161834716797, 0.984375\n",
      "Train loss and acc of batch 58: 47.69591522216797, 1.0\n",
      "Train loss and acc of batch 59: 47.6959114074707, 1.0\n",
      "Train loss and acc of batch 60: 47.69589614868164, 1.0\n",
      "Train loss and acc of batch 61: 47.69588851928711, 1.0\n",
      "Train loss and acc of batch 62: 47.695884704589844, 1.0\n",
      "Train loss and acc of batch 63: 48.88727569580078, 0.96875\n",
      "Train loss and acc of batch 64: 47.912620544433594, 0.984375\n",
      "Train loss and acc of batch 65: 47.69585418701172, 1.0\n",
      "Train loss and acc of batch 66: 47.69584274291992, 1.0\n",
      "Train loss and acc of batch 67: 48.50830078125, 0.96875\n",
      "Train loss and acc of batch 68: 48.291534423828125, 0.984375\n",
      "Train loss and acc of batch 69: 47.91258239746094, 0.984375\n",
      "Train loss and acc of batch 70: 47.6958122253418, 1.0\n",
      "Training accuracy and loss of epoch #574: 0.9897, 48.0170\n",
      "Saved model by train loss 48.017002428081675\n",
      "Train loss and acc of batch 0: 47.695796966552734, 1.0\n",
      "Train loss and acc of batch 1: 47.6957893371582, 1.0\n",
      "Train loss and acc of batch 2: 47.69578170776367, 1.0\n",
      "Train loss and acc of batch 3: 47.91253662109375, 0.984375\n",
      "Train loss and acc of batch 4: 47.695762634277344, 1.0\n",
      "Train loss and acc of batch 5: 49.04468536376953, 0.96875\n",
      "Train loss and acc of batch 6: 48.1983642578125, 0.96875\n",
      "Train loss and acc of batch 7: 47.69573211669922, 1.0\n",
      "Train loss and acc of batch 8: 48.29142761230469, 0.984375\n",
      "Train loss and acc of batch 9: 47.98157501220703, 0.984375\n",
      "Train loss and acc of batch 10: 47.69571304321289, 1.0\n",
      "Train loss and acc of batch 11: 47.695709228515625, 1.0\n",
      "Train loss and acc of batch 12: 48.448917388916016, 0.984375\n",
      "Train loss and acc of batch 13: 47.912445068359375, 0.984375\n",
      "Train loss and acc of batch 14: 47.912445068359375, 0.984375\n",
      "Train loss and acc of batch 15: 48.29136657714844, 0.984375\n",
      "Train loss and acc of batch 16: 48.291358947753906, 0.984375\n",
      "Train loss and acc of batch 17: 48.44886779785156, 0.984375\n",
      "Train loss and acc of batch 18: 48.57719421386719, 0.96875\n",
      "Train loss and acc of batch 19: 47.69563293457031, 1.0\n",
      "Train loss and acc of batch 20: 47.69562530517578, 1.0\n",
      "Train loss and acc of batch 21: 48.29131317138672, 0.984375\n",
      "Train loss and acc of batch 22: 48.29130554199219, 0.984375\n",
      "Train loss and acc of batch 23: 47.695594787597656, 1.0\n",
      "Train loss and acc of batch 24: 48.291290283203125, 0.984375\n",
      "Train loss and acc of batch 25: 47.69558334350586, 1.0\n",
      "Train loss and acc of batch 26: 47.69557189941406, 1.0\n",
      "Train loss and acc of batch 27: 47.695560455322266, 1.0\n",
      "Train loss and acc of batch 28: 47.695556640625, 1.0\n",
      "Train loss and acc of batch 29: 48.291236877441406, 0.984375\n",
      "Train loss and acc of batch 30: 47.69553756713867, 1.0\n",
      "Train loss and acc of batch 31: 47.91229248046875, 0.984375\n",
      "Train loss and acc of batch 32: 47.69551467895508, 1.0\n",
      "Train loss and acc of batch 33: 47.69550704956055, 1.0\n",
      "Train loss and acc of batch 34: 48.29119873046875, 0.984375\n",
      "Train loss and acc of batch 35: 48.1290168762207, 0.96875\n",
      "Train loss and acc of batch 36: 47.69548034667969, 1.0\n",
      "Train loss and acc of batch 37: 48.448692321777344, 0.984375\n",
      "Train loss and acc of batch 38: 49.04438781738281, 0.96875\n",
      "Train loss and acc of batch 39: 47.91222381591797, 0.984375\n",
      "Train loss and acc of batch 40: 47.6954460144043, 1.0\n",
      "Train loss and acc of batch 41: 49.04436111450195, 0.96875\n",
      "Train loss and acc of batch 42: 47.6954345703125, 1.0\n",
      "Train loss and acc of batch 43: 48.29112243652344, 0.984375\n",
      "Train loss and acc of batch 44: 47.695411682128906, 1.0\n",
      "Train loss and acc of batch 45: 48.291107177734375, 0.984375\n",
      "Train loss and acc of batch 46: 47.98124694824219, 0.984375\n",
      "Train loss and acc of batch 47: 47.69538497924805, 1.0\n",
      "Train loss and acc of batch 48: 47.69538116455078, 1.0\n",
      "Train loss and acc of batch 49: 47.69536590576172, 1.0\n",
      "Train loss and acc of batch 50: 48.29106140136719, 0.984375\n",
      "Train loss and acc of batch 51: 49.044273376464844, 0.96875\n",
      "Train loss and acc of batch 52: 48.951175689697266, 0.953125\n",
      "Train loss and acc of batch 53: 47.69533157348633, 1.0\n",
      "Train loss and acc of batch 54: 47.912086486816406, 0.984375\n",
      "Train loss and acc of batch 55: 47.6953125, 1.0\n",
      "Train loss and acc of batch 56: 47.695308685302734, 1.0\n",
      "Train loss and acc of batch 57: 48.290992736816406, 0.984375\n",
      "Train loss and acc of batch 58: 47.69528579711914, 1.0\n",
      "Train loss and acc of batch 59: 47.69527816772461, 1.0\n",
      "Train loss and acc of batch 60: 47.69527053833008, 1.0\n",
      "Train loss and acc of batch 61: 47.69526290893555, 1.0\n",
      "Train loss and acc of batch 62: 47.695255279541016, 1.0\n",
      "Train loss and acc of batch 63: 48.88664245605469, 0.96875\n",
      "Train loss and acc of batch 64: 47.91199493408203, 0.984375\n",
      "Train loss and acc of batch 65: 47.695228576660156, 1.0\n",
      "Train loss and acc of batch 66: 47.695213317871094, 1.0\n",
      "Train loss and acc of batch 67: 48.50767517089844, 0.96875\n",
      "Train loss and acc of batch 68: 48.2908935546875, 0.984375\n",
      "Train loss and acc of batch 69: 47.911949157714844, 0.984375\n",
      "Train loss and acc of batch 70: 47.69518280029297, 1.0\n",
      "Training accuracy and loss of epoch #575: 0.9897, 48.0164\n",
      "Saved model by train loss 48.016373647770415\n",
      "Train loss and acc of batch 0: 47.69517517089844, 1.0\n",
      "Train loss and acc of batch 1: 47.695159912109375, 1.0\n",
      "Train loss and acc of batch 2: 47.695152282714844, 1.0\n",
      "Train loss and acc of batch 3: 47.911903381347656, 0.984375\n",
      "Train loss and acc of batch 4: 47.69513702392578, 1.0\n",
      "Train loss and acc of batch 5: 49.04405212402344, 0.96875\n",
      "Train loss and acc of batch 6: 48.1977424621582, 0.96875\n",
      "Train loss and acc of batch 7: 47.69511032104492, 1.0\n",
      "Train loss and acc of batch 8: 48.290802001953125, 0.984375\n",
      "Train loss and acc of batch 9: 47.98094177246094, 0.984375\n",
      "Train loss and acc of batch 10: 47.69508361816406, 1.0\n",
      "Train loss and acc of batch 11: 47.695072174072266, 1.0\n",
      "Train loss and acc of batch 12: 48.44828414916992, 0.984375\n",
      "Train loss and acc of batch 13: 47.91181945800781, 0.984375\n",
      "Train loss and acc of batch 14: 47.91181182861328, 0.984375\n",
      "Train loss and acc of batch 15: 48.290740966796875, 0.984375\n",
      "Train loss and acc of batch 16: 48.290733337402344, 0.984375\n",
      "Train loss and acc of batch 17: 48.4482421875, 0.984375\n",
      "Train loss and acc of batch 18: 48.57656478881836, 0.96875\n",
      "Train loss and acc of batch 19: 47.695003509521484, 1.0\n",
      "Train loss and acc of batch 20: 47.69499206542969, 1.0\n",
      "Train loss and acc of batch 21: 48.290687561035156, 0.984375\n",
      "Train loss and acc of batch 22: 48.290679931640625, 0.984375\n",
      "Train loss and acc of batch 23: 47.69497299194336, 1.0\n",
      "Train loss and acc of batch 24: 48.29066467285156, 0.984375\n",
      "Train loss and acc of batch 25: 47.6949462890625, 1.0\n",
      "Train loss and acc of batch 26: 47.6949348449707, 1.0\n",
      "Train loss and acc of batch 27: 47.6949348449707, 1.0\n",
      "Train loss and acc of batch 28: 47.694923400878906, 1.0\n",
      "Train loss and acc of batch 29: 48.290618896484375, 0.984375\n",
      "Train loss and acc of batch 30: 47.69490432739258, 1.0\n",
      "Train loss and acc of batch 31: 47.911659240722656, 0.984375\n",
      "Train loss and acc of batch 32: 47.69488525390625, 1.0\n",
      "Train loss and acc of batch 33: 47.694881439208984, 1.0\n",
      "Train loss and acc of batch 34: 48.29057312011719, 0.984375\n",
      "Train loss and acc of batch 35: 48.12839126586914, 0.96875\n",
      "Train loss and acc of batch 36: 47.694854736328125, 1.0\n",
      "Train loss and acc of batch 37: 48.44806671142578, 0.984375\n",
      "Train loss and acc of batch 38: 49.04376220703125, 0.96875\n",
      "Train loss and acc of batch 39: 47.911590576171875, 0.984375\n",
      "Train loss and acc of batch 40: 47.6948127746582, 1.0\n",
      "Train loss and acc of batch 41: 49.043739318847656, 0.96875\n",
      "Train loss and acc of batch 42: 47.69480514526367, 1.0\n",
      "Train loss and acc of batch 43: 48.290489196777344, 0.984375\n",
      "Train loss and acc of batch 44: 47.69478225708008, 1.0\n",
      "Train loss and acc of batch 45: 48.29047393798828, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 46: 47.980613708496094, 0.984375\n",
      "Train loss and acc of batch 47: 47.694759368896484, 1.0\n",
      "Train loss and acc of batch 48: 47.69474411010742, 1.0\n",
      "Train loss and acc of batch 49: 47.69473648071289, 1.0\n",
      "Train loss and acc of batch 50: 48.290428161621094, 0.984375\n",
      "Train loss and acc of batch 51: 49.04364776611328, 0.96875\n",
      "Train loss and acc of batch 52: 48.9505500793457, 0.953125\n",
      "Train loss and acc of batch 53: 47.6947021484375, 1.0\n",
      "Train loss and acc of batch 54: 47.91145324707031, 0.984375\n",
      "Train loss and acc of batch 55: 47.69468688964844, 1.0\n",
      "Train loss and acc of batch 56: 47.694679260253906, 1.0\n",
      "Train loss and acc of batch 57: 48.290367126464844, 0.984375\n",
      "Train loss and acc of batch 58: 47.69466018676758, 1.0\n",
      "Train loss and acc of batch 59: 47.694644927978516, 1.0\n",
      "Train loss and acc of batch 60: 47.694637298583984, 1.0\n",
      "Train loss and acc of batch 61: 47.69463348388672, 1.0\n",
      "Train loss and acc of batch 62: 47.69462203979492, 1.0\n",
      "Train loss and acc of batch 63: 48.88601303100586, 0.96875\n",
      "Train loss and acc of batch 64: 47.91136932373047, 0.984375\n",
      "Train loss and acc of batch 65: 47.69459533691406, 1.0\n",
      "Train loss and acc of batch 66: 47.69458770751953, 1.0\n",
      "Train loss and acc of batch 67: 48.507041931152344, 0.96875\n",
      "Train loss and acc of batch 68: 48.29026794433594, 0.984375\n",
      "Train loss and acc of batch 69: 47.91132354736328, 0.984375\n",
      "Train loss and acc of batch 70: 47.69455337524414, 1.0\n",
      "Training accuracy and loss of epoch #576: 0.9897, 48.0157\n",
      "Saved model by train loss 48.01574476000289\n",
      "Train loss and acc of batch 0: 47.69453811645508, 1.0\n",
      "Train loss and acc of batch 1: 47.69453811645508, 1.0\n",
      "Train loss and acc of batch 2: 47.69453048706055, 1.0\n",
      "Train loss and acc of batch 3: 47.911277770996094, 0.984375\n",
      "Train loss and acc of batch 4: 47.69451141357422, 1.0\n",
      "Train loss and acc of batch 5: 49.043418884277344, 0.96875\n",
      "Train loss and acc of batch 6: 48.19710159301758, 0.96875\n",
      "Train loss and acc of batch 7: 47.69448471069336, 1.0\n",
      "Train loss and acc of batch 8: 48.29017639160156, 0.984375\n",
      "Train loss and acc of batch 9: 47.980316162109375, 0.984375\n",
      "Train loss and acc of batch 10: 47.694454193115234, 1.0\n",
      "Train loss and acc of batch 11: 47.69444274902344, 1.0\n",
      "Train loss and acc of batch 12: 48.44765853881836, 0.984375\n",
      "Train loss and acc of batch 13: 47.91119384765625, 0.984375\n",
      "Train loss and acc of batch 14: 47.91118621826172, 0.984375\n",
      "Train loss and acc of batch 15: 48.29011535644531, 0.984375\n",
      "Train loss and acc of batch 16: 48.29010772705078, 0.984375\n",
      "Train loss and acc of batch 17: 48.44761657714844, 0.984375\n",
      "Train loss and acc of batch 18: 48.57593536376953, 0.96875\n",
      "Train loss and acc of batch 19: 47.694374084472656, 1.0\n",
      "Train loss and acc of batch 20: 47.69436264038086, 1.0\n",
      "Train loss and acc of batch 21: 48.290061950683594, 0.984375\n",
      "Train loss and acc of batch 22: 48.29004669189453, 0.984375\n",
      "Train loss and acc of batch 23: 47.69434356689453, 1.0\n",
      "Train loss and acc of batch 24: 48.2900390625, 0.984375\n",
      "Train loss and acc of batch 25: 47.69432067871094, 1.0\n",
      "Train loss and acc of batch 26: 47.694313049316406, 1.0\n",
      "Train loss and acc of batch 27: 47.69430923461914, 1.0\n",
      "Train loss and acc of batch 28: 47.69429397583008, 1.0\n",
      "Train loss and acc of batch 29: 48.28998565673828, 0.984375\n",
      "Train loss and acc of batch 30: 47.694278717041016, 1.0\n",
      "Train loss and acc of batch 31: 47.911033630371094, 0.984375\n",
      "Train loss and acc of batch 32: 47.69425964355469, 1.0\n",
      "Train loss and acc of batch 33: 47.69424819946289, 1.0\n",
      "Train loss and acc of batch 34: 48.289939880371094, 0.984375\n",
      "Train loss and acc of batch 35: 48.12776184082031, 0.96875\n",
      "Train loss and acc of batch 36: 47.69422912597656, 1.0\n",
      "Train loss and acc of batch 37: 48.44743728637695, 0.984375\n",
      "Train loss and acc of batch 38: 49.04313659667969, 0.96875\n",
      "Train loss and acc of batch 39: 47.91095733642578, 0.984375\n",
      "Train loss and acc of batch 40: 47.694190979003906, 1.0\n",
      "Train loss and acc of batch 41: 49.04310989379883, 0.96875\n",
      "Train loss and acc of batch 42: 47.69417190551758, 1.0\n",
      "Train loss and acc of batch 43: 48.28986358642578, 0.984375\n",
      "Train loss and acc of batch 44: 47.69415283203125, 1.0\n",
      "Train loss and acc of batch 45: 48.28984832763672, 0.984375\n",
      "Train loss and acc of batch 46: 47.97998809814453, 0.984375\n",
      "Train loss and acc of batch 47: 47.694129943847656, 1.0\n",
      "Train loss and acc of batch 48: 47.69411849975586, 1.0\n",
      "Train loss and acc of batch 49: 47.69410705566406, 1.0\n",
      "Train loss and acc of batch 50: 48.28980255126953, 0.984375\n",
      "Train loss and acc of batch 51: 49.04301452636719, 0.96875\n",
      "Train loss and acc of batch 52: 48.949928283691406, 0.953125\n",
      "Train loss and acc of batch 53: 47.69407272338867, 1.0\n",
      "Train loss and acc of batch 54: 47.91082763671875, 0.984375\n",
      "Train loss and acc of batch 55: 47.694053649902344, 1.0\n",
      "Train loss and acc of batch 56: 47.69404602050781, 1.0\n",
      "Train loss and acc of batch 57: 48.28973388671875, 0.984375\n",
      "Train loss and acc of batch 58: 47.69403076171875, 1.0\n",
      "Train loss and acc of batch 59: 47.69401931762695, 1.0\n",
      "Train loss and acc of batch 60: 47.69401550292969, 1.0\n",
      "Train loss and acc of batch 61: 47.694000244140625, 1.0\n",
      "Train loss and acc of batch 62: 47.693992614746094, 1.0\n",
      "Train loss and acc of batch 63: 48.8853874206543, 0.96875\n",
      "Train loss and acc of batch 64: 47.910743713378906, 0.984375\n",
      "Train loss and acc of batch 65: 47.693965911865234, 1.0\n",
      "Train loss and acc of batch 66: 47.69396209716797, 1.0\n",
      "Train loss and acc of batch 67: 48.506412506103516, 0.96875\n",
      "Train loss and acc of batch 68: 48.289642333984375, 0.984375\n",
      "Train loss and acc of batch 69: 47.91069793701172, 0.984375\n",
      "Train loss and acc of batch 70: 47.69392013549805, 1.0\n",
      "Training accuracy and loss of epoch #577: 0.9897, 48.0151\n",
      "Saved model by train loss 48.015116731885456\n",
      "Train loss and acc of batch 0: 47.693912506103516, 1.0\n",
      "Train loss and acc of batch 1: 47.69390869140625, 1.0\n",
      "Train loss and acc of batch 2: 47.69389343261719, 1.0\n",
      "Train loss and acc of batch 3: 47.91065216064453, 0.984375\n",
      "Train loss and acc of batch 4: 47.693878173828125, 1.0\n",
      "Train loss and acc of batch 5: 49.04278564453125, 0.96875\n",
      "Train loss and acc of batch 6: 48.196475982666016, 0.96875\n",
      "Train loss and acc of batch 7: 47.69384765625, 1.0\n",
      "Train loss and acc of batch 8: 48.28954315185547, 0.984375\n",
      "Train loss and acc of batch 9: 47.97968292236328, 0.984375\n",
      "Train loss and acc of batch 10: 47.69382095336914, 1.0\n",
      "Train loss and acc of batch 11: 47.69381332397461, 1.0\n",
      "Train loss and acc of batch 12: 48.4470329284668, 0.984375\n",
      "Train loss and acc of batch 13: 47.910560607910156, 0.984375\n",
      "Train loss and acc of batch 14: 47.910552978515625, 0.984375\n",
      "Train loss and acc of batch 15: 48.28947448730469, 0.984375\n",
      "Train loss and acc of batch 16: 48.289466857910156, 0.984375\n",
      "Train loss and acc of batch 17: 48.446983337402344, 0.984375\n",
      "Train loss and acc of batch 18: 48.57530212402344, 0.96875\n",
      "Train loss and acc of batch 19: 47.69374084472656, 1.0\n",
      "Train loss and acc of batch 20: 47.69373321533203, 1.0\n",
      "Train loss and acc of batch 21: 48.2894287109375, 0.984375\n",
      "Train loss and acc of batch 22: 48.28942108154297, 0.984375\n",
      "Train loss and acc of batch 23: 47.69370651245117, 1.0\n",
      "Train loss and acc of batch 24: 48.289398193359375, 0.984375\n",
      "Train loss and acc of batch 25: 47.69369125366211, 1.0\n",
      "Train loss and acc of batch 26: 47.69368362426758, 1.0\n",
      "Train loss and acc of batch 27: 47.69367218017578, 1.0\n",
      "Train loss and acc of batch 28: 47.693660736083984, 1.0\n",
      "Train loss and acc of batch 29: 48.28936004638672, 0.984375\n",
      "Train loss and acc of batch 30: 47.693641662597656, 1.0\n",
      "Train loss and acc of batch 31: 47.910400390625, 0.984375\n",
      "Train loss and acc of batch 32: 47.69363021850586, 1.0\n",
      "Train loss and acc of batch 33: 47.69361877441406, 1.0\n",
      "Train loss and acc of batch 34: 48.28931427001953, 0.984375\n",
      "Train loss and acc of batch 35: 48.12712860107422, 0.96875\n",
      "Train loss and acc of batch 36: 47.6935920715332, 1.0\n",
      "Train loss and acc of batch 37: 48.446807861328125, 0.984375\n",
      "Train loss and acc of batch 38: 49.042503356933594, 0.96875\n",
      "Train loss and acc of batch 39: 47.91033172607422, 0.984375\n",
      "Train loss and acc of batch 40: 47.69355773925781, 1.0\n",
      "Train loss and acc of batch 41: 49.04247283935547, 0.96875\n",
      "Train loss and acc of batch 42: 47.69353485107422, 1.0\n",
      "Train loss and acc of batch 43: 48.28923034667969, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 44: 47.69351577758789, 1.0\n",
      "Train loss and acc of batch 45: 48.289215087890625, 0.984375\n",
      "Train loss and acc of batch 46: 47.97935485839844, 0.984375\n",
      "Train loss and acc of batch 47: 47.6934928894043, 1.0\n",
      "Train loss and acc of batch 48: 47.69348907470703, 1.0\n",
      "Train loss and acc of batch 49: 47.693477630615234, 1.0\n",
      "Train loss and acc of batch 50: 48.28916931152344, 0.984375\n",
      "Train loss and acc of batch 51: 49.042381286621094, 0.96875\n",
      "Train loss and acc of batch 52: 48.94928741455078, 0.953125\n",
      "Train loss and acc of batch 53: 47.693443298339844, 1.0\n",
      "Train loss and acc of batch 54: 47.91020202636719, 0.984375\n",
      "Train loss and acc of batch 55: 47.69342803955078, 1.0\n",
      "Train loss and acc of batch 56: 47.693416595458984, 1.0\n",
      "Train loss and acc of batch 57: 48.28910827636719, 0.984375\n",
      "Train loss and acc of batch 58: 47.693397521972656, 1.0\n",
      "Train loss and acc of batch 59: 47.693389892578125, 1.0\n",
      "Train loss and acc of batch 60: 47.69337844848633, 1.0\n",
      "Train loss and acc of batch 61: 47.69336700439453, 1.0\n",
      "Train loss and acc of batch 62: 47.693363189697266, 1.0\n",
      "Train loss and acc of batch 63: 48.8847541809082, 0.96875\n",
      "Train loss and acc of batch 64: 47.91011047363281, 0.984375\n",
      "Train loss and acc of batch 65: 47.69333267211914, 1.0\n",
      "Train loss and acc of batch 66: 47.69332504272461, 1.0\n",
      "Train loss and acc of batch 67: 48.50578308105469, 0.96875\n",
      "Train loss and acc of batch 68: 48.28900909423828, 0.984375\n",
      "Train loss and acc of batch 69: 47.910064697265625, 0.984375\n",
      "Train loss and acc of batch 70: 47.693294525146484, 1.0\n",
      "Training accuracy and loss of epoch #578: 0.9897, 48.0145\n",
      "Saved model by train loss 48.01448451297384\n",
      "Train loss and acc of batch 0: 47.69328308105469, 1.0\n",
      "Train loss and acc of batch 1: 47.69327163696289, 1.0\n",
      "Train loss and acc of batch 2: 47.69326400756836, 1.0\n",
      "Train loss and acc of batch 3: 47.91001892089844, 0.984375\n",
      "Train loss and acc of batch 4: 47.69324493408203, 1.0\n",
      "Train loss and acc of batch 5: 49.04216766357422, 0.96875\n",
      "Train loss and acc of batch 6: 48.19584655761719, 0.96875\n",
      "Train loss and acc of batch 7: 47.69322204589844, 1.0\n",
      "Train loss and acc of batch 8: 48.288917541503906, 0.984375\n",
      "Train loss and acc of batch 9: 47.97904968261719, 0.984375\n",
      "Train loss and acc of batch 10: 47.69319152832031, 1.0\n",
      "Train loss and acc of batch 11: 47.69318771362305, 1.0\n",
      "Train loss and acc of batch 12: 48.4463996887207, 0.984375\n",
      "Train loss and acc of batch 13: 47.909934997558594, 0.984375\n",
      "Train loss and acc of batch 14: 47.90992736816406, 0.984375\n",
      "Train loss and acc of batch 15: 48.288848876953125, 0.984375\n",
      "Train loss and acc of batch 16: 48.288841247558594, 0.984375\n",
      "Train loss and acc of batch 17: 48.44636154174805, 0.984375\n",
      "Train loss and acc of batch 18: 48.57467269897461, 0.96875\n",
      "Train loss and acc of batch 19: 47.693115234375, 1.0\n",
      "Train loss and acc of batch 20: 47.69310760498047, 1.0\n",
      "Train loss and acc of batch 21: 48.28880310058594, 0.984375\n",
      "Train loss and acc of batch 22: 48.288787841796875, 0.984375\n",
      "Train loss and acc of batch 23: 47.693077087402344, 1.0\n",
      "Train loss and acc of batch 24: 48.28876495361328, 0.984375\n",
      "Train loss and acc of batch 25: 47.69306182861328, 1.0\n",
      "Train loss and acc of batch 26: 47.693050384521484, 1.0\n",
      "Train loss and acc of batch 27: 47.69304275512695, 1.0\n",
      "Train loss and acc of batch 28: 47.69303512573242, 1.0\n",
      "Train loss and acc of batch 29: 48.288726806640625, 0.984375\n",
      "Train loss and acc of batch 30: 47.693016052246094, 1.0\n",
      "Train loss and acc of batch 31: 47.909767150878906, 0.984375\n",
      "Train loss and acc of batch 32: 47.692996978759766, 1.0\n",
      "Train loss and acc of batch 33: 47.692989349365234, 1.0\n",
      "Train loss and acc of batch 34: 48.28868865966797, 0.984375\n",
      "Train loss and acc of batch 35: 48.126502990722656, 0.96875\n",
      "Train loss and acc of batch 36: 47.69296646118164, 1.0\n",
      "Train loss and acc of batch 37: 48.4461784362793, 0.984375\n",
      "Train loss and acc of batch 38: 49.0418701171875, 0.96875\n",
      "Train loss and acc of batch 39: 47.909706115722656, 0.984375\n",
      "Train loss and acc of batch 40: 47.692928314208984, 1.0\n",
      "Train loss and acc of batch 41: 49.041847229003906, 0.96875\n",
      "Train loss and acc of batch 42: 47.69291305541992, 1.0\n",
      "Train loss and acc of batch 43: 48.288604736328125, 0.984375\n",
      "Train loss and acc of batch 44: 47.692893981933594, 1.0\n",
      "Train loss and acc of batch 45: 48.28858947753906, 0.984375\n",
      "Train loss and acc of batch 46: 47.978729248046875, 0.984375\n",
      "Train loss and acc of batch 47: 47.692867279052734, 1.0\n",
      "Train loss and acc of batch 48: 47.6928596496582, 1.0\n",
      "Train loss and acc of batch 49: 47.692848205566406, 1.0\n",
      "Train loss and acc of batch 50: 48.288543701171875, 0.984375\n",
      "Train loss and acc of batch 51: 49.041748046875, 0.96875\n",
      "Train loss and acc of batch 52: 48.94866180419922, 0.953125\n",
      "Train loss and acc of batch 53: 47.692813873291016, 1.0\n",
      "Train loss and acc of batch 54: 47.909568786621094, 0.984375\n",
      "Train loss and acc of batch 55: 47.69279479980469, 1.0\n",
      "Train loss and acc of batch 56: 47.69279098510742, 1.0\n",
      "Train loss and acc of batch 57: 48.288475036621094, 0.984375\n",
      "Train loss and acc of batch 58: 47.692771911621094, 1.0\n",
      "Train loss and acc of batch 59: 47.6927604675293, 1.0\n",
      "Train loss and acc of batch 60: 47.6927490234375, 1.0\n",
      "Train loss and acc of batch 61: 47.69274139404297, 1.0\n",
      "Train loss and acc of batch 62: 47.6927375793457, 1.0\n",
      "Train loss and acc of batch 63: 48.884124755859375, 0.96875\n",
      "Train loss and acc of batch 64: 47.90948486328125, 0.984375\n",
      "Train loss and acc of batch 65: 47.69270706176758, 1.0\n",
      "Train loss and acc of batch 66: 47.69269561767578, 1.0\n",
      "Train loss and acc of batch 67: 48.50515365600586, 0.96875\n",
      "Train loss and acc of batch 68: 48.28838348388672, 0.984375\n",
      "Train loss and acc of batch 69: 47.90943145751953, 0.984375\n",
      "Train loss and acc of batch 70: 47.692665100097656, 1.0\n",
      "Training accuracy and loss of epoch #579: 0.9897, 48.0139\n",
      "Saved model by train loss 48.01385621621575\n",
      "Train loss and acc of batch 0: 47.69265365600586, 1.0\n",
      "Train loss and acc of batch 1: 47.692649841308594, 1.0\n",
      "Train loss and acc of batch 2: 47.6926383972168, 1.0\n",
      "Train loss and acc of batch 3: 47.909385681152344, 0.984375\n",
      "Train loss and acc of batch 4: 47.69261932373047, 1.0\n",
      "Train loss and acc of batch 5: 49.041534423828125, 0.96875\n",
      "Train loss and acc of batch 6: 48.19521713256836, 0.96875\n",
      "Train loss and acc of batch 7: 47.69259262084961, 1.0\n",
      "Train loss and acc of batch 8: 48.28828430175781, 0.984375\n",
      "Train loss and acc of batch 9: 47.978424072265625, 0.984375\n",
      "Train loss and acc of batch 10: 47.69256591796875, 1.0\n",
      "Train loss and acc of batch 11: 47.69255828857422, 1.0\n",
      "Train loss and acc of batch 12: 48.445770263671875, 0.984375\n",
      "Train loss and acc of batch 13: 47.9093017578125, 0.984375\n",
      "Train loss and acc of batch 14: 47.90929412841797, 0.984375\n",
      "Train loss and acc of batch 15: 48.28822326660156, 0.984375\n",
      "Train loss and acc of batch 16: 48.28821563720703, 0.984375\n",
      "Train loss and acc of batch 17: 48.44572067260742, 0.984375\n",
      "Train loss and acc of batch 18: 48.57405090332031, 0.96875\n",
      "Train loss and acc of batch 19: 47.69248962402344, 1.0\n",
      "Train loss and acc of batch 20: 47.69247817993164, 1.0\n",
      "Train loss and acc of batch 21: 48.288169860839844, 0.984375\n",
      "Train loss and acc of batch 22: 48.28816223144531, 0.984375\n",
      "Train loss and acc of batch 23: 47.692447662353516, 1.0\n",
      "Train loss and acc of batch 24: 48.28814697265625, 0.984375\n",
      "Train loss and acc of batch 25: 47.69242858886719, 1.0\n",
      "Train loss and acc of batch 26: 47.692420959472656, 1.0\n",
      "Train loss and acc of batch 27: 47.69241714477539, 1.0\n",
      "Train loss and acc of batch 28: 47.69240951538086, 1.0\n",
      "Train loss and acc of batch 29: 48.28810119628906, 0.984375\n",
      "Train loss and acc of batch 30: 47.6923942565918, 1.0\n",
      "Train loss and acc of batch 31: 47.909141540527344, 0.984375\n",
      "Train loss and acc of batch 32: 47.69236755371094, 1.0\n",
      "Train loss and acc of batch 33: 47.69236373901367, 1.0\n",
      "Train loss and acc of batch 34: 48.288055419921875, 0.984375\n",
      "Train loss and acc of batch 35: 48.12586975097656, 0.96875\n",
      "Train loss and acc of batch 36: 47.69233703613281, 1.0\n",
      "Train loss and acc of batch 37: 48.44554901123047, 0.984375\n",
      "Train loss and acc of batch 38: 49.04124450683594, 0.96875\n",
      "Train loss and acc of batch 39: 47.90907287597656, 0.984375\n",
      "Train loss and acc of batch 40: 47.69229507446289, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 41: 49.04121780395508, 0.96875\n",
      "Train loss and acc of batch 42: 47.69227600097656, 1.0\n",
      "Train loss and acc of batch 43: 48.28797149658203, 0.984375\n",
      "Train loss and acc of batch 44: 47.69226837158203, 1.0\n",
      "Train loss and acc of batch 45: 48.28795623779297, 0.984375\n",
      "Train loss and acc of batch 46: 47.97809600830078, 0.984375\n",
      "Train loss and acc of batch 47: 47.692237854003906, 1.0\n",
      "Train loss and acc of batch 48: 47.69222640991211, 1.0\n",
      "Train loss and acc of batch 49: 47.69221878051758, 1.0\n",
      "Train loss and acc of batch 50: 48.28791809082031, 0.984375\n",
      "Train loss and acc of batch 51: 49.04113006591797, 0.96875\n",
      "Train loss and acc of batch 52: 48.948036193847656, 0.953125\n",
      "Train loss and acc of batch 53: 47.69218826293945, 1.0\n",
      "Train loss and acc of batch 54: 47.908935546875, 0.984375\n",
      "Train loss and acc of batch 55: 47.692169189453125, 1.0\n",
      "Train loss and acc of batch 56: 47.69215774536133, 1.0\n",
      "Train loss and acc of batch 57: 48.28784942626953, 0.984375\n",
      "Train loss and acc of batch 58: 47.69214630126953, 1.0\n",
      "Train loss and acc of batch 59: 47.6921272277832, 1.0\n",
      "Train loss and acc of batch 60: 47.69211959838867, 1.0\n",
      "Train loss and acc of batch 61: 47.692115783691406, 1.0\n",
      "Train loss and acc of batch 62: 47.69210433959961, 1.0\n",
      "Train loss and acc of batch 63: 48.88350296020508, 0.96875\n",
      "Train loss and acc of batch 64: 47.908851623535156, 0.984375\n",
      "Train loss and acc of batch 65: 47.69207763671875, 1.0\n",
      "Train loss and acc of batch 66: 47.69207000732422, 1.0\n",
      "Train loss and acc of batch 67: 48.50453186035156, 0.96875\n",
      "Train loss and acc of batch 68: 48.287750244140625, 0.984375\n",
      "Train loss and acc of batch 69: 47.90880584716797, 0.984375\n",
      "Train loss and acc of batch 70: 47.69203567504883, 1.0\n",
      "Training accuracy and loss of epoch #580: 0.9897, 48.0132\n",
      "Saved model by train loss 48.01322754336075\n",
      "Train loss and acc of batch 0: 47.69202423095703, 1.0\n",
      "Train loss and acc of batch 1: 47.692020416259766, 1.0\n",
      "Train loss and acc of batch 2: 47.69200897216797, 1.0\n",
      "Train loss and acc of batch 3: 47.90876007080078, 0.984375\n",
      "Train loss and acc of batch 4: 47.69198989868164, 1.0\n",
      "Train loss and acc of batch 5: 49.04090118408203, 0.96875\n",
      "Train loss and acc of batch 6: 48.194583892822266, 0.96875\n",
      "Train loss and acc of batch 7: 47.69196319580078, 1.0\n",
      "Train loss and acc of batch 8: 48.28765106201172, 0.984375\n",
      "Train loss and acc of batch 9: 47.97779846191406, 0.984375\n",
      "Train loss and acc of batch 10: 47.69194030761719, 1.0\n",
      "Train loss and acc of batch 11: 47.691925048828125, 1.0\n",
      "Train loss and acc of batch 12: 48.44514083862305, 0.984375\n",
      "Train loss and acc of batch 13: 47.90867614746094, 0.984375\n",
      "Train loss and acc of batch 14: 47.908668518066406, 0.984375\n",
      "Train loss and acc of batch 15: 48.28759765625, 0.984375\n",
      "Train loss and acc of batch 16: 48.28758239746094, 0.984375\n",
      "Train loss and acc of batch 17: 48.445098876953125, 0.984375\n",
      "Train loss and acc of batch 18: 48.57342529296875, 0.96875\n",
      "Train loss and acc of batch 19: 47.691856384277344, 1.0\n",
      "Train loss and acc of batch 20: 47.69184875488281, 1.0\n",
      "Train loss and acc of batch 21: 48.28754425048828, 0.984375\n",
      "Train loss and acc of batch 22: 48.28752899169922, 0.984375\n",
      "Train loss and acc of batch 23: 47.69182205200195, 1.0\n",
      "Train loss and acc of batch 24: 48.28752136230469, 0.984375\n",
      "Train loss and acc of batch 25: 47.69180679321289, 1.0\n",
      "Train loss and acc of batch 26: 47.691795349121094, 1.0\n",
      "Train loss and acc of batch 27: 47.69178771972656, 1.0\n",
      "Train loss and acc of batch 28: 47.691776275634766, 1.0\n",
      "Train loss and acc of batch 29: 48.2874755859375, 0.984375\n",
      "Train loss and acc of batch 30: 47.69175720214844, 1.0\n",
      "Train loss and acc of batch 31: 47.90851593017578, 0.984375\n",
      "Train loss and acc of batch 32: 47.69174575805664, 1.0\n",
      "Train loss and acc of batch 33: 47.691734313964844, 1.0\n",
      "Train loss and acc of batch 34: 48.28742218017578, 0.984375\n",
      "Train loss and acc of batch 35: 48.125247955322266, 0.96875\n",
      "Train loss and acc of batch 36: 47.691707611083984, 1.0\n",
      "Train loss and acc of batch 37: 48.444923400878906, 0.984375\n",
      "Train loss and acc of batch 38: 49.040611267089844, 0.96875\n",
      "Train loss and acc of batch 39: 47.908447265625, 0.984375\n",
      "Train loss and acc of batch 40: 47.69166946411133, 1.0\n",
      "Train loss and acc of batch 41: 49.040592193603516, 0.96875\n",
      "Train loss and acc of batch 42: 47.691650390625, 1.0\n",
      "Train loss and acc of batch 43: 48.28734588623047, 0.984375\n",
      "Train loss and acc of batch 44: 47.69163131713867, 1.0\n",
      "Train loss and acc of batch 45: 48.287330627441406, 0.984375\n",
      "Train loss and acc of batch 46: 47.97747039794922, 0.984375\n",
      "Train loss and acc of batch 47: 47.691612243652344, 1.0\n",
      "Train loss and acc of batch 48: 47.69159698486328, 1.0\n",
      "Train loss and acc of batch 49: 47.691593170166016, 1.0\n",
      "Train loss and acc of batch 50: 48.28727722167969, 0.984375\n",
      "Train loss and acc of batch 51: 49.040496826171875, 0.96875\n",
      "Train loss and acc of batch 52: 48.94740676879883, 0.953125\n",
      "Train loss and acc of batch 53: 47.69155502319336, 1.0\n",
      "Train loss and acc of batch 54: 47.90830993652344, 0.984375\n",
      "Train loss and acc of batch 55: 47.6915397644043, 1.0\n",
      "Train loss and acc of batch 56: 47.6915283203125, 1.0\n",
      "Train loss and acc of batch 57: 48.28722381591797, 0.984375\n",
      "Train loss and acc of batch 58: 47.69150924682617, 1.0\n",
      "Train loss and acc of batch 59: 47.69150161743164, 1.0\n",
      "Train loss and acc of batch 60: 47.69149398803711, 1.0\n",
      "Train loss and acc of batch 61: 47.69148635864258, 1.0\n",
      "Train loss and acc of batch 62: 47.69147872924805, 1.0\n",
      "Train loss and acc of batch 63: 48.88286590576172, 0.96875\n",
      "Train loss and acc of batch 64: 47.908226013183594, 0.984375\n",
      "Train loss and acc of batch 65: 47.69144821166992, 1.0\n",
      "Train loss and acc of batch 66: 47.691444396972656, 1.0\n",
      "Train loss and acc of batch 67: 48.5038948059082, 0.96875\n",
      "Train loss and acc of batch 68: 48.28712463378906, 0.984375\n",
      "Train loss and acc of batch 69: 47.908180236816406, 0.984375\n",
      "Train loss and acc of batch 70: 47.691402435302734, 1.0\n",
      "Training accuracy and loss of epoch #581: 0.9897, 48.0126\n",
      "Saved model by train loss 48.01259887050575\n",
      "Train loss and acc of batch 0: 47.69139862060547, 1.0\n",
      "Train loss and acc of batch 1: 47.69138717651367, 1.0\n",
      "Train loss and acc of batch 2: 47.691375732421875, 1.0\n",
      "Train loss and acc of batch 3: 47.90813446044922, 0.984375\n",
      "Train loss and acc of batch 4: 47.69136047363281, 1.0\n",
      "Train loss and acc of batch 5: 49.040283203125, 0.96875\n",
      "Train loss and acc of batch 6: 48.1939582824707, 0.96875\n",
      "Train loss and acc of batch 7: 47.69133377075195, 1.0\n",
      "Train loss and acc of batch 8: 48.287025451660156, 0.984375\n",
      "Train loss and acc of batch 9: 47.9771728515625, 0.984375\n",
      "Train loss and acc of batch 10: 47.69131088256836, 1.0\n",
      "Train loss and acc of batch 11: 47.69129943847656, 1.0\n",
      "Train loss and acc of batch 12: 48.44451141357422, 0.984375\n",
      "Train loss and acc of batch 13: 47.908042907714844, 0.984375\n",
      "Train loss and acc of batch 14: 47.90803527832031, 0.984375\n",
      "Train loss and acc of batch 15: 48.286956787109375, 0.984375\n",
      "Train loss and acc of batch 16: 48.286956787109375, 0.984375\n",
      "Train loss and acc of batch 17: 48.44447326660156, 0.984375\n",
      "Train loss and acc of batch 18: 48.57278823852539, 0.96875\n",
      "Train loss and acc of batch 19: 47.69123077392578, 1.0\n",
      "Train loss and acc of batch 20: 47.691219329833984, 1.0\n",
      "Train loss and acc of batch 21: 48.28691101074219, 0.984375\n",
      "Train loss and acc of batch 22: 48.286903381347656, 0.984375\n",
      "Train loss and acc of batch 23: 47.69119644165039, 1.0\n",
      "Train loss and acc of batch 24: 48.286888122558594, 0.984375\n",
      "Train loss and acc of batch 25: 47.69117736816406, 1.0\n",
      "Train loss and acc of batch 26: 47.691165924072266, 1.0\n",
      "Train loss and acc of batch 27: 47.691158294677734, 1.0\n",
      "Train loss and acc of batch 28: 47.6911506652832, 1.0\n",
      "Train loss and acc of batch 29: 48.286842346191406, 0.984375\n",
      "Train loss and acc of batch 30: 47.69112777709961, 1.0\n",
      "Train loss and acc of batch 31: 47.90789031982422, 0.984375\n",
      "Train loss and acc of batch 32: 47.69111251831055, 1.0\n",
      "Train loss and acc of batch 33: 47.691104888916016, 1.0\n",
      "Train loss and acc of batch 34: 48.28679656982422, 0.984375\n",
      "Train loss and acc of batch 35: 48.124610900878906, 0.96875\n",
      "Train loss and acc of batch 36: 47.691078186035156, 1.0\n",
      "Train loss and acc of batch 37: 48.44429397583008, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 38: 49.03998565673828, 0.96875\n",
      "Train loss and acc of batch 39: 47.907814025878906, 0.984375\n",
      "Train loss and acc of batch 40: 47.691043853759766, 1.0\n",
      "Train loss and acc of batch 41: 49.03996276855469, 0.96875\n",
      "Train loss and acc of batch 42: 47.6910285949707, 1.0\n",
      "Train loss and acc of batch 43: 48.286712646484375, 0.984375\n",
      "Train loss and acc of batch 44: 47.691001892089844, 1.0\n",
      "Train loss and acc of batch 45: 48.28669738769531, 0.984375\n",
      "Train loss and acc of batch 46: 47.976844787597656, 0.984375\n",
      "Train loss and acc of batch 47: 47.69097900390625, 1.0\n",
      "Train loss and acc of batch 48: 47.690975189208984, 1.0\n",
      "Train loss and acc of batch 49: 47.69095993041992, 1.0\n",
      "Train loss and acc of batch 50: 48.286651611328125, 0.984375\n",
      "Train loss and acc of batch 51: 49.03987121582031, 0.96875\n",
      "Train loss and acc of batch 52: 48.94677734375, 0.953125\n",
      "Train loss and acc of batch 53: 47.69092559814453, 1.0\n",
      "Train loss and acc of batch 54: 47.907684326171875, 0.984375\n",
      "Train loss and acc of batch 55: 47.69091033935547, 1.0\n",
      "Train loss and acc of batch 56: 47.6909065246582, 1.0\n",
      "Train loss and acc of batch 57: 48.286590576171875, 0.984375\n",
      "Train loss and acc of batch 58: 47.69087600708008, 1.0\n",
      "Train loss and acc of batch 59: 47.69087219238281, 1.0\n",
      "Train loss and acc of batch 60: 47.69086837768555, 1.0\n",
      "Train loss and acc of batch 61: 47.69085693359375, 1.0\n",
      "Train loss and acc of batch 62: 47.69084930419922, 1.0\n",
      "Train loss and acc of batch 63: 48.882240295410156, 0.96875\n",
      "Train loss and acc of batch 64: 47.9075927734375, 0.984375\n",
      "Train loss and acc of batch 65: 47.690818786621094, 1.0\n",
      "Train loss and acc of batch 66: 47.69081115722656, 1.0\n",
      "Train loss and acc of batch 67: 48.50326919555664, 0.96875\n",
      "Train loss and acc of batch 68: 48.2864990234375, 0.984375\n",
      "Train loss and acc of batch 69: 47.90754699707031, 0.984375\n",
      "Train loss and acc of batch 70: 47.69078063964844, 1.0\n",
      "Training accuracy and loss of epoch #582: 0.9897, 48.0120\n",
      "Saved model by train loss 48.01196998273823\n",
      "Train loss and acc of batch 0: 47.690765380859375, 1.0\n",
      "Train loss and acc of batch 1: 47.690757751464844, 1.0\n",
      "Train loss and acc of batch 2: 47.69075012207031, 1.0\n",
      "Train loss and acc of batch 3: 47.907508850097656, 0.984375\n",
      "Train loss and acc of batch 4: 47.690731048583984, 1.0\n",
      "Train loss and acc of batch 5: 49.039649963378906, 0.96875\n",
      "Train loss and acc of batch 6: 48.193328857421875, 0.96875\n",
      "Train loss and acc of batch 7: 47.69070053100586, 1.0\n",
      "Train loss and acc of batch 8: 48.286399841308594, 0.984375\n",
      "Train loss and acc of batch 9: 47.976539611816406, 0.984375\n",
      "Train loss and acc of batch 10: 47.69068145751953, 1.0\n",
      "Train loss and acc of batch 11: 47.690670013427734, 1.0\n",
      "Train loss and acc of batch 12: 48.443885803222656, 0.984375\n",
      "Train loss and acc of batch 13: 47.90741729736328, 0.984375\n",
      "Train loss and acc of batch 14: 47.90740966796875, 0.984375\n",
      "Train loss and acc of batch 15: 48.28633117675781, 0.984375\n",
      "Train loss and acc of batch 16: 48.28633117675781, 0.984375\n",
      "Train loss and acc of batch 17: 48.44384002685547, 0.984375\n",
      "Train loss and acc of batch 18: 48.57216262817383, 0.96875\n",
      "Train loss and acc of batch 19: 47.69060134887695, 1.0\n",
      "Train loss and acc of batch 20: 47.69059753417969, 1.0\n",
      "Train loss and acc of batch 21: 48.286277770996094, 0.984375\n",
      "Train loss and acc of batch 22: 48.286277770996094, 0.984375\n",
      "Train loss and acc of batch 23: 47.6905632019043, 1.0\n",
      "Train loss and acc of batch 24: 48.2862548828125, 0.984375\n",
      "Train loss and acc of batch 25: 47.69054412841797, 1.0\n",
      "Train loss and acc of batch 26: 47.69053649902344, 1.0\n",
      "Train loss and acc of batch 27: 47.690528869628906, 1.0\n",
      "Train loss and acc of batch 28: 47.69051742553711, 1.0\n",
      "Train loss and acc of batch 29: 48.28620910644531, 0.984375\n",
      "Train loss and acc of batch 30: 47.69050216674805, 1.0\n",
      "Train loss and acc of batch 31: 47.907257080078125, 0.984375\n",
      "Train loss and acc of batch 32: 47.690486907958984, 1.0\n",
      "Train loss and acc of batch 33: 47.69047546386719, 1.0\n",
      "Train loss and acc of batch 34: 48.286170959472656, 0.984375\n",
      "Train loss and acc of batch 35: 48.123985290527344, 0.96875\n",
      "Train loss and acc of batch 36: 47.690452575683594, 1.0\n",
      "Train loss and acc of batch 37: 48.44366455078125, 0.984375\n",
      "Train loss and acc of batch 38: 49.03935241699219, 0.96875\n",
      "Train loss and acc of batch 39: 47.907188415527344, 0.984375\n",
      "Train loss and acc of batch 40: 47.69041061401367, 1.0\n",
      "Train loss and acc of batch 41: 49.03933334350586, 0.96875\n",
      "Train loss and acc of batch 42: 47.690399169921875, 1.0\n",
      "Train loss and acc of batch 43: 48.28608703613281, 0.984375\n",
      "Train loss and acc of batch 44: 47.69037628173828, 1.0\n",
      "Train loss and acc of batch 45: 48.28607177734375, 0.984375\n",
      "Train loss and acc of batch 46: 47.97621154785156, 0.984375\n",
      "Train loss and acc of batch 47: 47.69035339355469, 1.0\n",
      "Train loss and acc of batch 48: 47.690345764160156, 1.0\n",
      "Train loss and acc of batch 49: 47.69033432006836, 1.0\n",
      "Train loss and acc of batch 50: 48.286033630371094, 0.984375\n",
      "Train loss and acc of batch 51: 49.03923797607422, 0.96875\n",
      "Train loss and acc of batch 52: 48.946144104003906, 0.953125\n",
      "Train loss and acc of batch 53: 47.69029998779297, 1.0\n",
      "Train loss and acc of batch 54: 47.90705108642578, 0.984375\n",
      "Train loss and acc of batch 55: 47.69028091430664, 1.0\n",
      "Train loss and acc of batch 56: 47.69027328491211, 1.0\n",
      "Train loss and acc of batch 57: 48.28596496582031, 0.984375\n",
      "Train loss and acc of batch 58: 47.69025421142578, 1.0\n",
      "Train loss and acc of batch 59: 47.69024658203125, 1.0\n",
      "Train loss and acc of batch 60: 47.69023513793945, 1.0\n",
      "Train loss and acc of batch 61: 47.69022750854492, 1.0\n",
      "Train loss and acc of batch 62: 47.690216064453125, 1.0\n",
      "Train loss and acc of batch 63: 48.881614685058594, 0.96875\n",
      "Train loss and acc of batch 64: 47.90696716308594, 0.984375\n",
      "Train loss and acc of batch 65: 47.6901969909668, 1.0\n",
      "Train loss and acc of batch 66: 47.690181732177734, 1.0\n",
      "Train loss and acc of batch 67: 48.50263977050781, 0.96875\n",
      "Train loss and acc of batch 68: 48.285865783691406, 0.984375\n",
      "Train loss and acc of batch 69: 47.90692138671875, 0.984375\n",
      "Train loss and acc of batch 70: 47.690147399902344, 1.0\n",
      "Training accuracy and loss of epoch #583: 0.9897, 48.0113\n",
      "Saved model by train loss 48.01134125615509\n",
      "Train loss and acc of batch 0: 47.69013595581055, 1.0\n",
      "Train loss and acc of batch 1: 47.690128326416016, 1.0\n",
      "Train loss and acc of batch 2: 47.690120697021484, 1.0\n",
      "Train loss and acc of batch 3: 47.90687561035156, 0.984375\n",
      "Train loss and acc of batch 4: 47.69010543823242, 1.0\n",
      "Train loss and acc of batch 5: 49.03901672363281, 0.96875\n",
      "Train loss and acc of batch 6: 48.19270324707031, 0.96875\n",
      "Train loss and acc of batch 7: 47.69007873535156, 1.0\n",
      "Train loss and acc of batch 8: 48.28577423095703, 0.984375\n",
      "Train loss and acc of batch 9: 47.975914001464844, 0.984375\n",
      "Train loss and acc of batch 10: 47.69004821777344, 1.0\n",
      "Train loss and acc of batch 11: 47.69004440307617, 1.0\n",
      "Train loss and acc of batch 12: 48.44325256347656, 0.984375\n",
      "Train loss and acc of batch 13: 47.90679168701172, 0.984375\n",
      "Train loss and acc of batch 14: 47.906776428222656, 0.984375\n",
      "Train loss and acc of batch 15: 48.28571319580078, 0.984375\n",
      "Train loss and acc of batch 16: 48.28569793701172, 0.984375\n",
      "Train loss and acc of batch 17: 48.443214416503906, 0.984375\n",
      "Train loss and acc of batch 18: 48.571529388427734, 0.96875\n",
      "Train loss and acc of batch 19: 47.689971923828125, 1.0\n",
      "Train loss and acc of batch 20: 47.68996047973633, 1.0\n",
      "Train loss and acc of batch 21: 48.28565979003906, 0.984375\n",
      "Train loss and acc of batch 22: 48.28565216064453, 0.984375\n",
      "Train loss and acc of batch 23: 47.689937591552734, 1.0\n",
      "Train loss and acc of batch 24: 48.28562927246094, 0.984375\n",
      "Train loss and acc of batch 25: 47.689918518066406, 1.0\n",
      "Train loss and acc of batch 26: 47.689910888671875, 1.0\n",
      "Train loss and acc of batch 27: 47.68989944458008, 1.0\n",
      "Train loss and acc of batch 28: 47.68988800048828, 1.0\n",
      "Train loss and acc of batch 29: 48.28558349609375, 0.984375\n",
      "Train loss and acc of batch 30: 47.689876556396484, 1.0\n",
      "Train loss and acc of batch 31: 47.90663146972656, 0.984375\n",
      "Train loss and acc of batch 32: 47.689857482910156, 1.0\n",
      "Train loss and acc of batch 33: 47.68984603881836, 1.0\n",
      "Train loss and acc of batch 34: 48.28553771972656, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 35: 48.12335968017578, 0.96875\n",
      "Train loss and acc of batch 36: 47.6898193359375, 1.0\n",
      "Train loss and acc of batch 37: 48.44303512573242, 0.984375\n",
      "Train loss and acc of batch 38: 49.038726806640625, 0.96875\n",
      "Train loss and acc of batch 39: 47.90655517578125, 0.984375\n",
      "Train loss and acc of batch 40: 47.68978500366211, 1.0\n",
      "Train loss and acc of batch 41: 49.03870391845703, 0.96875\n",
      "Train loss and acc of batch 42: 47.68976593017578, 1.0\n",
      "Train loss and acc of batch 43: 48.28546142578125, 0.984375\n",
      "Train loss and acc of batch 44: 47.68975067138672, 1.0\n",
      "Train loss and acc of batch 45: 48.285438537597656, 0.984375\n",
      "Train loss and acc of batch 46: 47.9755859375, 0.984375\n",
      "Train loss and acc of batch 47: 47.68972396850586, 1.0\n",
      "Train loss and acc of batch 48: 47.68971252441406, 1.0\n",
      "Train loss and acc of batch 49: 47.68970489501953, 1.0\n",
      "Train loss and acc of batch 50: 48.285400390625, 0.984375\n",
      "Train loss and acc of batch 51: 49.038612365722656, 0.96875\n",
      "Train loss and acc of batch 52: 48.945518493652344, 0.953125\n",
      "Train loss and acc of batch 53: 47.68967819213867, 1.0\n",
      "Train loss and acc of batch 54: 47.90642547607422, 0.984375\n",
      "Train loss and acc of batch 55: 47.68965530395508, 1.0\n",
      "Train loss and acc of batch 56: 47.68964385986328, 1.0\n",
      "Train loss and acc of batch 57: 48.28533935546875, 0.984375\n",
      "Train loss and acc of batch 58: 47.68962860107422, 1.0\n",
      "Train loss and acc of batch 59: 47.68962097167969, 1.0\n",
      "Train loss and acc of batch 60: 47.68960952758789, 1.0\n",
      "Train loss and acc of batch 61: 47.689598083496094, 1.0\n",
      "Train loss and acc of batch 62: 47.6895866394043, 1.0\n",
      "Train loss and acc of batch 63: 48.8809814453125, 0.96875\n",
      "Train loss and acc of batch 64: 47.906341552734375, 0.984375\n",
      "Train loss and acc of batch 65: 47.68955993652344, 1.0\n",
      "Train loss and acc of batch 66: 47.68955612182617, 1.0\n",
      "Train loss and acc of batch 67: 48.50201416015625, 0.96875\n",
      "Train loss and acc of batch 68: 48.285240173339844, 0.984375\n",
      "Train loss and acc of batch 69: 47.90629577636719, 0.984375\n",
      "Train loss and acc of batch 70: 47.68952178955078, 1.0\n",
      "Training accuracy and loss of epoch #584: 0.9897, 48.0107\n",
      "Saved model by train loss 48.01071322803766\n",
      "Train loss and acc of batch 0: 47.689510345458984, 1.0\n",
      "Train loss and acc of batch 1: 47.68950653076172, 1.0\n",
      "Train loss and acc of batch 2: 47.68949508666992, 1.0\n",
      "Train loss and acc of batch 3: 47.90625, 0.984375\n",
      "Train loss and acc of batch 4: 47.689476013183594, 1.0\n",
      "Train loss and acc of batch 5: 49.03839111328125, 0.96875\n",
      "Train loss and acc of batch 6: 48.192073822021484, 0.96875\n",
      "Train loss and acc of batch 7: 47.68944549560547, 1.0\n",
      "Train loss and acc of batch 8: 48.28514099121094, 0.984375\n",
      "Train loss and acc of batch 9: 47.97528076171875, 0.984375\n",
      "Train loss and acc of batch 10: 47.689422607421875, 1.0\n",
      "Train loss and acc of batch 11: 47.689414978027344, 1.0\n",
      "Train loss and acc of batch 12: 48.442630767822266, 0.984375\n",
      "Train loss and acc of batch 13: 47.906158447265625, 0.984375\n",
      "Train loss and acc of batch 14: 47.906150817871094, 0.984375\n",
      "Train loss and acc of batch 15: 48.28507995605469, 0.984375\n",
      "Train loss and acc of batch 16: 48.285072326660156, 0.984375\n",
      "Train loss and acc of batch 17: 48.44258499145508, 0.984375\n",
      "Train loss and acc of batch 18: 48.57090759277344, 0.96875\n",
      "Train loss and acc of batch 19: 47.68934631347656, 1.0\n",
      "Train loss and acc of batch 20: 47.68933868408203, 1.0\n",
      "Train loss and acc of batch 21: 48.28502655029297, 0.984375\n",
      "Train loss and acc of batch 22: 48.28501892089844, 0.984375\n",
      "Train loss and acc of batch 23: 47.68930435180664, 1.0\n",
      "Train loss and acc of batch 24: 48.285003662109375, 0.984375\n",
      "Train loss and acc of batch 25: 47.68928909301758, 1.0\n",
      "Train loss and acc of batch 26: 47.68928146362305, 1.0\n",
      "Train loss and acc of batch 27: 47.68927001953125, 1.0\n",
      "Train loss and acc of batch 28: 47.689266204833984, 1.0\n",
      "Train loss and acc of batch 29: 48.28495788574219, 0.984375\n",
      "Train loss and acc of batch 30: 47.689247131347656, 1.0\n",
      "Train loss and acc of batch 31: 47.90599822998047, 0.984375\n",
      "Train loss and acc of batch 32: 47.68922805786133, 1.0\n",
      "Train loss and acc of batch 33: 47.6892204284668, 1.0\n",
      "Train loss and acc of batch 34: 48.284912109375, 0.984375\n",
      "Train loss and acc of batch 35: 48.12273406982422, 0.96875\n",
      "Train loss and acc of batch 36: 47.68918991088867, 1.0\n",
      "Train loss and acc of batch 37: 48.44240951538086, 0.984375\n",
      "Train loss and acc of batch 38: 49.03810119628906, 0.96875\n",
      "Train loss and acc of batch 39: 47.90592956542969, 0.984375\n",
      "Train loss and acc of batch 40: 47.68915939331055, 1.0\n",
      "Train loss and acc of batch 41: 49.0380744934082, 0.96875\n",
      "Train loss and acc of batch 42: 47.68914031982422, 1.0\n",
      "Train loss and acc of batch 43: 48.284828186035156, 0.984375\n",
      "Train loss and acc of batch 44: 47.68912124633789, 1.0\n",
      "Train loss and acc of batch 45: 48.284812927246094, 0.984375\n",
      "Train loss and acc of batch 46: 47.97496032714844, 0.984375\n",
      "Train loss and acc of batch 47: 47.68909454345703, 1.0\n",
      "Train loss and acc of batch 48: 47.689090728759766, 1.0\n",
      "Train loss and acc of batch 49: 47.68907928466797, 1.0\n",
      "Train loss and acc of batch 50: 48.284767150878906, 0.984375\n",
      "Train loss and acc of batch 51: 49.03797912597656, 0.96875\n",
      "Train loss and acc of batch 52: 48.944889068603516, 0.953125\n",
      "Train loss and acc of batch 53: 47.68904113769531, 1.0\n",
      "Train loss and acc of batch 54: 47.905799865722656, 0.984375\n",
      "Train loss and acc of batch 55: 47.689022064208984, 1.0\n",
      "Train loss and acc of batch 56: 47.68901443481445, 1.0\n",
      "Train loss and acc of batch 57: 48.284706115722656, 0.984375\n",
      "Train loss and acc of batch 58: 47.68899917602539, 1.0\n",
      "Train loss and acc of batch 59: 47.688987731933594, 1.0\n",
      "Train loss and acc of batch 60: 47.68898010253906, 1.0\n",
      "Train loss and acc of batch 61: 47.68897247314453, 1.0\n",
      "Train loss and acc of batch 62: 47.68896484375, 1.0\n",
      "Train loss and acc of batch 63: 48.8803596496582, 0.96875\n",
      "Train loss and acc of batch 64: 47.90570831298828, 0.984375\n",
      "Train loss and acc of batch 65: 47.68893814086914, 1.0\n",
      "Train loss and acc of batch 66: 47.688926696777344, 1.0\n",
      "Train loss and acc of batch 67: 48.50138473510742, 0.96875\n",
      "Train loss and acc of batch 68: 48.28460693359375, 0.984375\n",
      "Train loss and acc of batch 69: 47.905662536621094, 0.984375\n",
      "Train loss and acc of batch 70: 47.68888854980469, 1.0\n",
      "Training accuracy and loss of epoch #585: 0.9897, 48.0101\n",
      "Saved model by train loss 48.01008487755144\n",
      "Train loss and acc of batch 0: 47.68888473510742, 1.0\n",
      "Train loss and acc of batch 1: 47.688873291015625, 1.0\n",
      "Train loss and acc of batch 2: 47.68886184692383, 1.0\n",
      "Train loss and acc of batch 3: 47.905616760253906, 0.984375\n",
      "Train loss and acc of batch 4: 47.688846588134766, 1.0\n",
      "Train loss and acc of batch 5: 49.03776550292969, 0.96875\n",
      "Train loss and acc of batch 6: 48.19144821166992, 0.96875\n",
      "Train loss and acc of batch 7: 47.688819885253906, 1.0\n",
      "Train loss and acc of batch 8: 48.284515380859375, 0.984375\n",
      "Train loss and acc of batch 9: 47.97465515136719, 0.984375\n",
      "Train loss and acc of batch 10: 47.68879699707031, 1.0\n",
      "Train loss and acc of batch 11: 47.68878936767578, 1.0\n",
      "Train loss and acc of batch 12: 48.44200134277344, 0.984375\n",
      "Train loss and acc of batch 13: 47.90553283691406, 0.984375\n",
      "Train loss and acc of batch 14: 47.90552520751953, 0.984375\n",
      "Train loss and acc of batch 15: 48.284454345703125, 0.984375\n",
      "Train loss and acc of batch 16: 48.28443908691406, 0.984375\n",
      "Train loss and acc of batch 17: 48.44195556640625, 0.984375\n",
      "Train loss and acc of batch 18: 48.570274353027344, 0.96875\n",
      "Train loss and acc of batch 19: 47.68871307373047, 1.0\n",
      "Train loss and acc of batch 20: 47.6887092590332, 1.0\n",
      "Train loss and acc of batch 21: 48.284393310546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.284393310546875, 0.984375\n",
      "Train loss and acc of batch 23: 47.68867874145508, 1.0\n",
      "Train loss and acc of batch 24: 48.28437042236328, 0.984375\n",
      "Train loss and acc of batch 25: 47.688663482666016, 1.0\n",
      "Train loss and acc of batch 26: 47.68865203857422, 1.0\n",
      "Train loss and acc of batch 27: 47.68864440917969, 1.0\n",
      "Train loss and acc of batch 28: 47.688636779785156, 1.0\n",
      "Train loss and acc of batch 29: 48.284332275390625, 0.984375\n",
      "Train loss and acc of batch 30: 47.68861770629883, 1.0\n",
      "Train loss and acc of batch 31: 47.905372619628906, 0.984375\n",
      "Train loss and acc of batch 32: 47.688594818115234, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 33: 47.68859100341797, 1.0\n",
      "Train loss and acc of batch 34: 48.28428649902344, 0.984375\n",
      "Train loss and acc of batch 35: 48.122100830078125, 0.96875\n",
      "Train loss and acc of batch 36: 47.68856430053711, 1.0\n",
      "Train loss and acc of batch 37: 48.44178009033203, 0.984375\n",
      "Train loss and acc of batch 38: 49.03746795654297, 0.96875\n",
      "Train loss and acc of batch 39: 47.905303955078125, 0.984375\n",
      "Train loss and acc of batch 40: 47.68852615356445, 1.0\n",
      "Train loss and acc of batch 41: 49.037445068359375, 0.96875\n",
      "Train loss and acc of batch 42: 47.68851089477539, 1.0\n",
      "Train loss and acc of batch 43: 48.284202575683594, 0.984375\n",
      "Train loss and acc of batch 44: 47.68849563598633, 1.0\n",
      "Train loss and acc of batch 45: 48.28418731689453, 0.984375\n",
      "Train loss and acc of batch 46: 47.974327087402344, 0.984375\n",
      "Train loss and acc of batch 47: 47.68846893310547, 1.0\n",
      "Train loss and acc of batch 48: 47.68845748901367, 1.0\n",
      "Train loss and acc of batch 49: 47.68844985961914, 1.0\n",
      "Train loss and acc of batch 50: 48.284141540527344, 0.984375\n",
      "Train loss and acc of batch 51: 49.037353515625, 0.96875\n",
      "Train loss and acc of batch 52: 48.94425964355469, 0.953125\n",
      "Train loss and acc of batch 53: 47.68841552734375, 1.0\n",
      "Train loss and acc of batch 54: 47.90516662597656, 0.984375\n",
      "Train loss and acc of batch 55: 47.68839645385742, 1.0\n",
      "Train loss and acc of batch 56: 47.68838882446289, 1.0\n",
      "Train loss and acc of batch 57: 48.284080505371094, 0.984375\n",
      "Train loss and acc of batch 58: 47.68836975097656, 1.0\n",
      "Train loss and acc of batch 59: 47.688358306884766, 1.0\n",
      "Train loss and acc of batch 60: 47.688350677490234, 1.0\n",
      "Train loss and acc of batch 61: 47.6883430480957, 1.0\n",
      "Train loss and acc of batch 62: 47.688331604003906, 1.0\n",
      "Train loss and acc of batch 63: 48.879730224609375, 0.96875\n",
      "Train loss and acc of batch 64: 47.90507507324219, 0.984375\n",
      "Train loss and acc of batch 65: 47.68830871582031, 1.0\n",
      "Train loss and acc of batch 66: 47.688297271728516, 1.0\n",
      "Train loss and acc of batch 67: 48.500755310058594, 0.96875\n",
      "Train loss and acc of batch 68: 48.28398132324219, 0.984375\n",
      "Train loss and acc of batch 69: 47.90503692626953, 0.984375\n",
      "Train loss and acc of batch 70: 47.688262939453125, 1.0\n",
      "Training accuracy and loss of epoch #586: 0.9897, 48.0095\n",
      "Saved model by train loss 48.0094563121527\n",
      "Train loss and acc of batch 0: 47.688255310058594, 1.0\n",
      "Train loss and acc of batch 1: 47.6882438659668, 1.0\n",
      "Train loss and acc of batch 2: 47.68824005126953, 1.0\n",
      "Train loss and acc of batch 3: 47.904991149902344, 0.984375\n",
      "Train loss and acc of batch 4: 47.68821716308594, 1.0\n",
      "Train loss and acc of batch 5: 49.037132263183594, 0.96875\n",
      "Train loss and acc of batch 6: 48.19081497192383, 0.96875\n",
      "Train loss and acc of batch 7: 47.688194274902344, 1.0\n",
      "Train loss and acc of batch 8: 48.28388214111328, 0.984375\n",
      "Train loss and acc of batch 9: 47.974029541015625, 0.984375\n",
      "Train loss and acc of batch 10: 47.68816375732422, 1.0\n",
      "Train loss and acc of batch 11: 47.68815612792969, 1.0\n",
      "Train loss and acc of batch 12: 48.441368103027344, 0.984375\n",
      "Train loss and acc of batch 13: 47.9049072265625, 0.984375\n",
      "Train loss and acc of batch 14: 47.90489196777344, 0.984375\n",
      "Train loss and acc of batch 15: 48.28382110595703, 0.984375\n",
      "Train loss and acc of batch 16: 48.2838134765625, 0.984375\n",
      "Train loss and acc of batch 17: 48.44132995605469, 0.984375\n",
      "Train loss and acc of batch 18: 48.569644927978516, 0.96875\n",
      "Train loss and acc of batch 19: 47.68809127807617, 1.0\n",
      "Train loss and acc of batch 20: 47.688079833984375, 1.0\n",
      "Train loss and acc of batch 21: 48.28376770019531, 0.984375\n",
      "Train loss and acc of batch 22: 48.28376007080078, 0.984375\n",
      "Train loss and acc of batch 23: 47.68804931640625, 1.0\n",
      "Train loss and acc of batch 24: 48.28374481201172, 0.984375\n",
      "Train loss and acc of batch 25: 47.68803405761719, 1.0\n",
      "Train loss and acc of batch 26: 47.688018798828125, 1.0\n",
      "Train loss and acc of batch 27: 47.688018798828125, 1.0\n",
      "Train loss and acc of batch 28: 47.68800735473633, 1.0\n",
      "Train loss and acc of batch 29: 48.28369903564453, 0.984375\n",
      "Train loss and acc of batch 30: 47.68798828125, 1.0\n",
      "Train loss and acc of batch 31: 47.904747009277344, 0.984375\n",
      "Train loss and acc of batch 32: 47.68796920776367, 1.0\n",
      "Train loss and acc of batch 33: 47.68796157836914, 1.0\n",
      "Train loss and acc of batch 34: 48.283653259277344, 0.984375\n",
      "Train loss and acc of batch 35: 48.1214714050293, 0.96875\n",
      "Train loss and acc of batch 36: 47.68793487548828, 1.0\n",
      "Train loss and acc of batch 37: 48.44115447998047, 0.984375\n",
      "Train loss and acc of batch 38: 49.036842346191406, 0.96875\n",
      "Train loss and acc of batch 39: 47.90467071533203, 0.984375\n",
      "Train loss and acc of batch 40: 47.687896728515625, 1.0\n",
      "Train loss and acc of batch 41: 49.03681945800781, 0.96875\n",
      "Train loss and acc of batch 42: 47.68788528442383, 1.0\n",
      "Train loss and acc of batch 43: 48.2835693359375, 0.984375\n",
      "Train loss and acc of batch 44: 47.6878662109375, 1.0\n",
      "Train loss and acc of batch 45: 48.28356170654297, 0.984375\n",
      "Train loss and acc of batch 46: 47.97370147705078, 0.984375\n",
      "Train loss and acc of batch 47: 47.68783950805664, 1.0\n",
      "Train loss and acc of batch 48: 47.68783187866211, 1.0\n",
      "Train loss and acc of batch 49: 47.68781661987305, 1.0\n",
      "Train loss and acc of batch 50: 48.28351593017578, 0.984375\n",
      "Train loss and acc of batch 51: 49.03672790527344, 0.96875\n",
      "Train loss and acc of batch 52: 48.94363784790039, 0.953125\n",
      "Train loss and acc of batch 53: 47.68778610229492, 1.0\n",
      "Train loss and acc of batch 54: 47.90453338623047, 0.984375\n",
      "Train loss and acc of batch 55: 47.687767028808594, 1.0\n",
      "Train loss and acc of batch 56: 47.68775939941406, 1.0\n",
      "Train loss and acc of batch 57: 48.283447265625, 0.984375\n",
      "Train loss and acc of batch 58: 47.687744140625, 1.0\n",
      "Train loss and acc of batch 59: 47.68772888183594, 1.0\n",
      "Train loss and acc of batch 60: 47.68772506713867, 1.0\n",
      "Train loss and acc of batch 61: 47.68771743774414, 1.0\n",
      "Train loss and acc of batch 62: 47.687705993652344, 1.0\n",
      "Train loss and acc of batch 63: 48.87909698486328, 0.96875\n",
      "Train loss and acc of batch 64: 47.904457092285156, 0.984375\n",
      "Train loss and acc of batch 65: 47.687679290771484, 1.0\n",
      "Train loss and acc of batch 66: 47.68767166137695, 1.0\n",
      "Train loss and acc of batch 67: 48.5001220703125, 0.96875\n",
      "Train loss and acc of batch 68: 48.283355712890625, 0.984375\n",
      "Train loss and acc of batch 69: 47.90440368652344, 0.984375\n",
      "Train loss and acc of batch 70: 47.68763732910156, 1.0\n",
      "Training accuracy and loss of epoch #587: 0.9897, 48.0088\n",
      "Saved model by train loss 48.00882774675396\n",
      "Train loss and acc of batch 0: 47.6876220703125, 1.0\n",
      "Train loss and acc of batch 1: 47.687618255615234, 1.0\n",
      "Train loss and acc of batch 2: 47.68760681152344, 1.0\n",
      "Train loss and acc of batch 3: 47.90436553955078, 0.984375\n",
      "Train loss and acc of batch 4: 47.687591552734375, 1.0\n",
      "Train loss and acc of batch 5: 49.03650665283203, 0.96875\n",
      "Train loss and acc of batch 6: 48.190185546875, 0.96875\n",
      "Train loss and acc of batch 7: 47.687564849853516, 1.0\n",
      "Train loss and acc of batch 8: 48.28325653076172, 0.984375\n",
      "Train loss and acc of batch 9: 47.97340393066406, 0.984375\n",
      "Train loss and acc of batch 10: 47.687538146972656, 1.0\n",
      "Train loss and acc of batch 11: 47.687530517578125, 1.0\n",
      "Train loss and acc of batch 12: 48.44074249267578, 0.984375\n",
      "Train loss and acc of batch 13: 47.904273986816406, 0.984375\n",
      "Train loss and acc of batch 14: 47.904266357421875, 0.984375\n",
      "Train loss and acc of batch 15: 48.28319549560547, 0.984375\n",
      "Train loss and acc of batch 16: 48.28318786621094, 0.984375\n",
      "Train loss and acc of batch 17: 48.440696716308594, 0.984375\n",
      "Train loss and acc of batch 18: 48.56901931762695, 0.96875\n",
      "Train loss and acc of batch 19: 47.68745803833008, 1.0\n",
      "Train loss and acc of batch 20: 47.68744659423828, 1.0\n",
      "Train loss and acc of batch 21: 48.28314208984375, 0.984375\n",
      "Train loss and acc of batch 22: 48.28313446044922, 0.984375\n",
      "Train loss and acc of batch 23: 47.687416076660156, 1.0\n",
      "Train loss and acc of batch 24: 48.283119201660156, 0.984375\n",
      "Train loss and acc of batch 25: 47.68740463256836, 1.0\n",
      "Train loss and acc of batch 26: 47.68739700317383, 1.0\n",
      "Train loss and acc of batch 27: 47.68738555908203, 1.0\n",
      "Train loss and acc of batch 28: 47.687381744384766, 1.0\n",
      "Train loss and acc of batch 29: 48.28306579589844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 30: 47.68735885620117, 1.0\n",
      "Train loss and acc of batch 31: 47.90411376953125, 0.984375\n",
      "Train loss and acc of batch 32: 47.687347412109375, 1.0\n",
      "Train loss and acc of batch 33: 47.68733215332031, 1.0\n",
      "Train loss and acc of batch 34: 48.28302001953125, 0.984375\n",
      "Train loss and acc of batch 35: 48.120845794677734, 0.96875\n",
      "Train loss and acc of batch 36: 47.68730545043945, 1.0\n",
      "Train loss and acc of batch 37: 48.440521240234375, 0.984375\n",
      "Train loss and acc of batch 38: 49.03620910644531, 0.96875\n",
      "Train loss and acc of batch 39: 47.90404510498047, 0.984375\n",
      "Train loss and acc of batch 40: 47.68727111816406, 1.0\n",
      "Train loss and acc of batch 41: 49.03619384765625, 0.96875\n",
      "Train loss and acc of batch 42: 47.687252044677734, 1.0\n",
      "Train loss and acc of batch 43: 48.28294372558594, 0.984375\n",
      "Train loss and acc of batch 44: 47.68723678588867, 1.0\n",
      "Train loss and acc of batch 45: 48.282928466796875, 0.984375\n",
      "Train loss and acc of batch 46: 47.97307586669922, 0.984375\n",
      "Train loss and acc of batch 47: 47.68720626831055, 1.0\n",
      "Train loss and acc of batch 48: 47.687198638916016, 1.0\n",
      "Train loss and acc of batch 49: 47.687191009521484, 1.0\n",
      "Train loss and acc of batch 50: 48.28288269042969, 0.984375\n",
      "Train loss and acc of batch 51: 49.036094665527344, 0.96875\n",
      "Train loss and acc of batch 52: 48.9430046081543, 0.953125\n",
      "Train loss and acc of batch 53: 47.687156677246094, 1.0\n",
      "Train loss and acc of batch 54: 47.90391540527344, 0.984375\n",
      "Train loss and acc of batch 55: 47.68714141845703, 1.0\n",
      "Train loss and acc of batch 56: 47.68712615966797, 1.0\n",
      "Train loss and acc of batch 57: 48.28282165527344, 0.984375\n",
      "Train loss and acc of batch 58: 47.68711471557617, 1.0\n",
      "Train loss and acc of batch 59: 47.687103271484375, 1.0\n",
      "Train loss and acc of batch 60: 47.687095642089844, 1.0\n",
      "Train loss and acc of batch 61: 47.68708801269531, 1.0\n",
      "Train loss and acc of batch 62: 47.68707275390625, 1.0\n",
      "Train loss and acc of batch 63: 48.87847137451172, 0.96875\n",
      "Train loss and acc of batch 64: 47.90382385253906, 0.984375\n",
      "Train loss and acc of batch 65: 47.687049865722656, 1.0\n",
      "Train loss and acc of batch 66: 47.687042236328125, 1.0\n",
      "Train loss and acc of batch 67: 48.49949645996094, 0.96875\n",
      "Train loss and acc of batch 68: 48.28272247314453, 0.984375\n",
      "Train loss and acc of batch 69: 47.903785705566406, 0.984375\n",
      "Train loss and acc of batch 70: 47.687007904052734, 1.0\n",
      "Training accuracy and loss of epoch #588: 0.9897, 48.0082\n",
      "Saved model by train loss 48.008199127627094\n",
      "Train loss and acc of batch 0: 47.68699645996094, 1.0\n",
      "Train loss and acc of batch 1: 47.68698501586914, 1.0\n",
      "Train loss and acc of batch 2: 47.686981201171875, 1.0\n",
      "Train loss and acc of batch 3: 47.90373229980469, 0.984375\n",
      "Train loss and acc of batch 4: 47.68696594238281, 1.0\n",
      "Train loss and acc of batch 5: 49.03587341308594, 0.96875\n",
      "Train loss and acc of batch 6: 48.1895637512207, 0.96875\n",
      "Train loss and acc of batch 7: 47.68693923950195, 1.0\n",
      "Train loss and acc of batch 8: 48.282623291015625, 0.984375\n",
      "Train loss and acc of batch 9: 47.97277069091797, 0.984375\n",
      "Train loss and acc of batch 10: 47.68690872192383, 1.0\n",
      "Train loss and acc of batch 11: 47.68689727783203, 1.0\n",
      "Train loss and acc of batch 12: 48.440120697021484, 0.984375\n",
      "Train loss and acc of batch 13: 47.903648376464844, 0.984375\n",
      "Train loss and acc of batch 14: 47.90363311767578, 0.984375\n",
      "Train loss and acc of batch 15: 48.282562255859375, 0.984375\n",
      "Train loss and acc of batch 16: 48.282554626464844, 0.984375\n",
      "Train loss and acc of batch 17: 48.44007110595703, 0.984375\n",
      "Train loss and acc of batch 18: 48.56839370727539, 0.96875\n",
      "Train loss and acc of batch 19: 47.68682861328125, 1.0\n",
      "Train loss and acc of batch 20: 47.68682098388672, 1.0\n",
      "Train loss and acc of batch 21: 48.282508850097656, 0.984375\n",
      "Train loss and acc of batch 22: 48.282501220703125, 0.984375\n",
      "Train loss and acc of batch 23: 47.68679428100586, 1.0\n",
      "Train loss and acc of batch 24: 48.28248596191406, 0.984375\n",
      "Train loss and acc of batch 25: 47.68677520751953, 1.0\n",
      "Train loss and acc of batch 26: 47.686771392822266, 1.0\n",
      "Train loss and acc of batch 27: 47.6867561340332, 1.0\n",
      "Train loss and acc of batch 28: 47.68674850463867, 1.0\n",
      "Train loss and acc of batch 29: 48.282440185546875, 0.984375\n",
      "Train loss and acc of batch 30: 47.686729431152344, 1.0\n",
      "Train loss and acc of batch 31: 47.90348815917969, 0.984375\n",
      "Train loss and acc of batch 32: 47.68671417236328, 1.0\n",
      "Train loss and acc of batch 33: 47.68670654296875, 1.0\n",
      "Train loss and acc of batch 34: 48.28240203857422, 0.984375\n",
      "Train loss and acc of batch 35: 48.12022018432617, 0.96875\n",
      "Train loss and acc of batch 36: 47.686676025390625, 1.0\n",
      "Train loss and acc of batch 37: 48.43989181518555, 0.984375\n",
      "Train loss and acc of batch 38: 49.03558349609375, 0.96875\n",
      "Train loss and acc of batch 39: 47.903411865234375, 0.984375\n",
      "Train loss and acc of batch 40: 47.6866455078125, 1.0\n",
      "Train loss and acc of batch 41: 49.03556442260742, 0.96875\n",
      "Train loss and acc of batch 42: 47.686622619628906, 1.0\n",
      "Train loss and acc of batch 43: 48.282318115234375, 0.984375\n",
      "Train loss and acc of batch 44: 47.686607360839844, 1.0\n",
      "Train loss and acc of batch 45: 48.28230285644531, 0.984375\n",
      "Train loss and acc of batch 46: 47.972442626953125, 0.984375\n",
      "Train loss and acc of batch 47: 47.686580657958984, 1.0\n",
      "Train loss and acc of batch 48: 47.68656921386719, 1.0\n",
      "Train loss and acc of batch 49: 47.686561584472656, 1.0\n",
      "Train loss and acc of batch 50: 48.282257080078125, 0.984375\n",
      "Train loss and acc of batch 51: 49.03547668457031, 0.96875\n",
      "Train loss and acc of batch 52: 48.94237518310547, 0.953125\n",
      "Train loss and acc of batch 53: 47.686527252197266, 1.0\n",
      "Train loss and acc of batch 54: 47.903282165527344, 0.984375\n",
      "Train loss and acc of batch 55: 47.6865119934082, 1.0\n",
      "Train loss and acc of batch 56: 47.68650436401367, 1.0\n",
      "Train loss and acc of batch 57: 48.282196044921875, 0.984375\n",
      "Train loss and acc of batch 58: 47.68648147583008, 1.0\n",
      "Train loss and acc of batch 59: 47.68647766113281, 1.0\n",
      "Train loss and acc of batch 60: 47.68647003173828, 1.0\n",
      "Train loss and acc of batch 61: 47.686458587646484, 1.0\n",
      "Train loss and acc of batch 62: 47.68644714355469, 1.0\n",
      "Train loss and acc of batch 63: 48.877845764160156, 0.96875\n",
      "Train loss and acc of batch 64: 47.9031982421875, 0.984375\n",
      "Train loss and acc of batch 65: 47.686424255371094, 1.0\n",
      "Train loss and acc of batch 66: 47.6864128112793, 1.0\n",
      "Train loss and acc of batch 67: 48.49886703491211, 0.96875\n",
      "Train loss and acc of batch 68: 48.28209686279297, 0.984375\n",
      "Train loss and acc of batch 69: 47.90314483642578, 0.984375\n",
      "Train loss and acc of batch 70: 47.686378479003906, 1.0\n",
      "Training accuracy and loss of epoch #589: 0.9897, 48.0076\n",
      "Saved model by train loss 48.00757077714087\n",
      "Train loss and acc of batch 0: 47.686370849609375, 1.0\n",
      "Train loss and acc of batch 1: 47.68635940551758, 1.0\n",
      "Train loss and acc of batch 2: 47.68635177612305, 1.0\n",
      "Train loss and acc of batch 3: 47.903114318847656, 0.984375\n",
      "Train loss and acc of batch 4: 47.68633270263672, 1.0\n",
      "Train loss and acc of batch 5: 49.035247802734375, 0.96875\n",
      "Train loss and acc of batch 6: 48.188934326171875, 0.96875\n",
      "Train loss and acc of batch 7: 47.686309814453125, 1.0\n",
      "Train loss and acc of batch 8: 48.282005310058594, 0.984375\n",
      "Train loss and acc of batch 9: 47.972145080566406, 0.984375\n",
      "Train loss and acc of batch 10: 47.686279296875, 1.0\n",
      "Train loss and acc of batch 11: 47.68627166748047, 1.0\n",
      "Train loss and acc of batch 12: 48.439483642578125, 0.984375\n",
      "Train loss and acc of batch 13: 47.90302276611328, 0.984375\n",
      "Train loss and acc of batch 14: 47.90300750732422, 0.984375\n",
      "Train loss and acc of batch 15: 48.28193664550781, 0.984375\n",
      "Train loss and acc of batch 16: 48.28192901611328, 0.984375\n",
      "Train loss and acc of batch 17: 48.43944549560547, 0.984375\n",
      "Train loss and acc of batch 18: 48.5677604675293, 0.96875\n",
      "Train loss and acc of batch 19: 47.68619918823242, 1.0\n",
      "Train loss and acc of batch 20: 47.686195373535156, 1.0\n",
      "Train loss and acc of batch 21: 48.281883239746094, 0.984375\n",
      "Train loss and acc of batch 22: 48.28187561035156, 0.984375\n",
      "Train loss and acc of batch 23: 47.6861686706543, 1.0\n",
      "Train loss and acc of batch 24: 48.28185272216797, 0.984375\n",
      "Train loss and acc of batch 25: 47.686153411865234, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 26: 47.68614196777344, 1.0\n",
      "Train loss and acc of batch 27: 47.68613052368164, 1.0\n",
      "Train loss and acc of batch 28: 47.686119079589844, 1.0\n",
      "Train loss and acc of batch 29: 48.28181457519531, 0.984375\n",
      "Train loss and acc of batch 30: 47.68610382080078, 1.0\n",
      "Train loss and acc of batch 31: 47.902862548828125, 0.984375\n",
      "Train loss and acc of batch 32: 47.68608474731445, 1.0\n",
      "Train loss and acc of batch 33: 47.68607711791992, 1.0\n",
      "Train loss and acc of batch 34: 48.281768798828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.11958694458008, 0.96875\n",
      "Train loss and acc of batch 36: 47.68605041503906, 1.0\n",
      "Train loss and acc of batch 37: 48.439266204833984, 0.984375\n",
      "Train loss and acc of batch 38: 49.03495788574219, 0.96875\n",
      "Train loss and acc of batch 39: 47.90278625488281, 0.984375\n",
      "Train loss and acc of batch 40: 47.68601608276367, 1.0\n",
      "Train loss and acc of batch 41: 49.03492736816406, 0.96875\n",
      "Train loss and acc of batch 42: 47.685997009277344, 1.0\n",
      "Train loss and acc of batch 43: 48.28168487548828, 0.984375\n",
      "Train loss and acc of batch 44: 47.685977935791016, 1.0\n",
      "Train loss and acc of batch 45: 48.28166961669922, 0.984375\n",
      "Train loss and acc of batch 46: 47.97180938720703, 0.984375\n",
      "Train loss and acc of batch 47: 47.68594741821289, 1.0\n",
      "Train loss and acc of batch 48: 47.685943603515625, 1.0\n",
      "Train loss and acc of batch 49: 47.68592834472656, 1.0\n",
      "Train loss and acc of batch 50: 48.28163146972656, 0.984375\n",
      "Train loss and acc of batch 51: 49.03484344482422, 0.96875\n",
      "Train loss and acc of batch 52: 48.94174575805664, 0.953125\n",
      "Train loss and acc of batch 53: 47.68589782714844, 1.0\n",
      "Train loss and acc of batch 54: 47.90264892578125, 0.984375\n",
      "Train loss and acc of batch 55: 47.68587875366211, 1.0\n",
      "Train loss and acc of batch 56: 47.68586730957031, 1.0\n",
      "Train loss and acc of batch 57: 48.28156280517578, 0.984375\n",
      "Train loss and acc of batch 58: 47.68585205078125, 1.0\n",
      "Train loss and acc of batch 59: 47.68584442138672, 1.0\n",
      "Train loss and acc of batch 60: 47.68584060668945, 1.0\n",
      "Train loss and acc of batch 61: 47.68582534790039, 1.0\n",
      "Train loss and acc of batch 62: 47.68581771850586, 1.0\n",
      "Train loss and acc of batch 63: 48.8772087097168, 0.96875\n",
      "Train loss and acc of batch 64: 47.902565002441406, 0.984375\n",
      "Train loss and acc of batch 65: 47.685791015625, 1.0\n",
      "Train loss and acc of batch 66: 47.6857795715332, 1.0\n",
      "Train loss and acc of batch 67: 48.49823760986328, 0.96875\n",
      "Train loss and acc of batch 68: 48.281471252441406, 0.984375\n",
      "Train loss and acc of batch 69: 47.90251922607422, 0.984375\n",
      "Train loss and acc of batch 70: 47.68574523925781, 1.0\n",
      "Training accuracy and loss of epoch #590: 0.9897, 48.0069\n",
      "Saved model by train loss 48.006941728188956\n",
      "Train loss and acc of batch 0: 47.68573760986328, 1.0\n",
      "Train loss and acc of batch 1: 47.685726165771484, 1.0\n",
      "Train loss and acc of batch 2: 47.68572235107422, 1.0\n",
      "Train loss and acc of batch 3: 47.90248107910156, 0.984375\n",
      "Train loss and acc of batch 4: 47.68570327758789, 1.0\n",
      "Train loss and acc of batch 5: 49.03462219238281, 0.96875\n",
      "Train loss and acc of batch 6: 48.188297271728516, 0.96875\n",
      "Train loss and acc of batch 7: 47.68567657470703, 1.0\n",
      "Train loss and acc of batch 8: 48.2813720703125, 0.984375\n",
      "Train loss and acc of batch 9: 47.97150421142578, 0.984375\n",
      "Train loss and acc of batch 10: 47.68565368652344, 1.0\n",
      "Train loss and acc of batch 11: 47.68564224243164, 1.0\n",
      "Train loss and acc of batch 12: 48.43885803222656, 0.984375\n",
      "Train loss and acc of batch 13: 47.90238952636719, 0.984375\n",
      "Train loss and acc of batch 14: 47.902381896972656, 0.984375\n",
      "Train loss and acc of batch 15: 48.28130340576172, 0.984375\n",
      "Train loss and acc of batch 16: 48.28130340576172, 0.984375\n",
      "Train loss and acc of batch 17: 48.438812255859375, 0.984375\n",
      "Train loss and acc of batch 18: 48.56713104248047, 0.96875\n",
      "Train loss and acc of batch 19: 47.685569763183594, 1.0\n",
      "Train loss and acc of batch 20: 47.68556213378906, 1.0\n",
      "Train loss and acc of batch 21: 48.28125, 0.984375\n",
      "Train loss and acc of batch 22: 48.28124237060547, 0.984375\n",
      "Train loss and acc of batch 23: 47.68553161621094, 1.0\n",
      "Train loss and acc of batch 24: 48.281227111816406, 0.984375\n",
      "Train loss and acc of batch 25: 47.68552017211914, 1.0\n",
      "Train loss and acc of batch 26: 47.685508728027344, 1.0\n",
      "Train loss and acc of batch 27: 47.68550491333008, 1.0\n",
      "Train loss and acc of batch 28: 47.68549346923828, 1.0\n",
      "Train loss and acc of batch 29: 48.28118133544922, 0.984375\n",
      "Train loss and acc of batch 30: 47.68547439575195, 1.0\n",
      "Train loss and acc of batch 31: 47.90222930908203, 0.984375\n",
      "Train loss and acc of batch 32: 47.685455322265625, 1.0\n",
      "Train loss and acc of batch 33: 47.685447692871094, 1.0\n",
      "Train loss and acc of batch 34: 48.28113555908203, 0.984375\n",
      "Train loss and acc of batch 35: 48.11895751953125, 0.96875\n",
      "Train loss and acc of batch 36: 47.68541717529297, 1.0\n",
      "Train loss and acc of batch 37: 48.438629150390625, 0.984375\n",
      "Train loss and acc of batch 38: 49.034324645996094, 0.96875\n",
      "Train loss and acc of batch 39: 47.90216064453125, 0.984375\n",
      "Train loss and acc of batch 40: 47.68538284301758, 1.0\n",
      "Train loss and acc of batch 41: 49.034305572509766, 0.96875\n",
      "Train loss and acc of batch 42: 47.685367584228516, 1.0\n",
      "Train loss and acc of batch 43: 48.28105926513672, 0.984375\n",
      "Train loss and acc of batch 44: 47.68535232543945, 1.0\n",
      "Train loss and acc of batch 45: 48.281044006347656, 0.984375\n",
      "Train loss and acc of batch 46: 47.97117614746094, 0.984375\n",
      "Train loss and acc of batch 47: 47.68532180786133, 1.0\n",
      "Train loss and acc of batch 48: 47.68531799316406, 1.0\n",
      "Train loss and acc of batch 49: 47.685306549072266, 1.0\n",
      "Train loss and acc of batch 50: 48.28099822998047, 0.984375\n",
      "Train loss and acc of batch 51: 49.034210205078125, 0.96875\n",
      "Train loss and acc of batch 52: 48.94111633300781, 0.953125\n",
      "Train loss and acc of batch 53: 47.685272216796875, 1.0\n",
      "Train loss and acc of batch 54: 47.90202331542969, 0.984375\n",
      "Train loss and acc of batch 55: 47.68525314331055, 1.0\n",
      "Train loss and acc of batch 56: 47.68524169921875, 1.0\n",
      "Train loss and acc of batch 57: 48.28092956542969, 0.984375\n",
      "Train loss and acc of batch 58: 47.68522644042969, 1.0\n",
      "Train loss and acc of batch 59: 47.68521499633789, 1.0\n",
      "Train loss and acc of batch 60: 47.685203552246094, 1.0\n",
      "Train loss and acc of batch 61: 47.68519973754883, 1.0\n",
      "Train loss and acc of batch 62: 47.68518829345703, 1.0\n",
      "Train loss and acc of batch 63: 48.876583099365234, 0.96875\n",
      "Train loss and acc of batch 64: 47.901939392089844, 0.984375\n",
      "Train loss and acc of batch 65: 47.68516540527344, 1.0\n",
      "Train loss and acc of batch 66: 47.685150146484375, 1.0\n",
      "Train loss and acc of batch 67: 48.497615814208984, 0.96875\n",
      "Train loss and acc of batch 68: 48.28083801269531, 0.984375\n",
      "Train loss and acc of batch 69: 47.901893615722656, 0.984375\n",
      "Train loss and acc of batch 70: 47.68511962890625, 1.0\n",
      "Training accuracy and loss of epoch #591: 0.9897, 48.0063\n",
      "Saved model by train loss 48.00631208822761\n",
      "Train loss and acc of batch 0: 47.68510437011719, 1.0\n",
      "Train loss and acc of batch 1: 47.68510055541992, 1.0\n",
      "Train loss and acc of batch 2: 47.685096740722656, 1.0\n",
      "Train loss and acc of batch 3: 47.90184783935547, 0.984375\n",
      "Train loss and acc of batch 4: 47.68507766723633, 1.0\n",
      "Train loss and acc of batch 5: 49.03398895263672, 0.96875\n",
      "Train loss and acc of batch 6: 48.18767547607422, 0.96875\n",
      "Train loss and acc of batch 7: 47.68505096435547, 1.0\n",
      "Train loss and acc of batch 8: 48.280731201171875, 0.984375\n",
      "Train loss and acc of batch 9: 47.97087860107422, 0.984375\n",
      "Train loss and acc of batch 10: 47.68502426147461, 1.0\n",
      "Train loss and acc of batch 11: 47.68501281738281, 1.0\n",
      "Train loss and acc of batch 12: 48.438228607177734, 0.984375\n",
      "Train loss and acc of batch 13: 47.901763916015625, 0.984375\n",
      "Train loss and acc of batch 14: 47.90174865722656, 0.984375\n",
      "Train loss and acc of batch 15: 48.280677795410156, 0.984375\n",
      "Train loss and acc of batch 16: 48.280670166015625, 0.984375\n",
      "Train loss and acc of batch 17: 48.43817901611328, 0.984375\n",
      "Train loss and acc of batch 18: 48.566505432128906, 0.96875\n",
      "Train loss and acc of batch 19: 47.684940338134766, 1.0\n",
      "Train loss and acc of batch 20: 47.684932708740234, 1.0\n",
      "Train loss and acc of batch 21: 48.28062438964844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 22: 48.280616760253906, 0.984375\n",
      "Train loss and acc of batch 23: 47.684906005859375, 1.0\n",
      "Train loss and acc of batch 24: 48.280601501464844, 0.984375\n",
      "Train loss and acc of batch 25: 47.68489074707031, 1.0\n",
      "Train loss and acc of batch 26: 47.684879302978516, 1.0\n",
      "Train loss and acc of batch 27: 47.68487548828125, 1.0\n",
      "Train loss and acc of batch 28: 47.68485641479492, 1.0\n",
      "Train loss and acc of batch 29: 48.280555725097656, 0.984375\n",
      "Train loss and acc of batch 30: 47.684844970703125, 1.0\n",
      "Train loss and acc of batch 31: 47.90159606933594, 0.984375\n",
      "Train loss and acc of batch 32: 47.6848258972168, 1.0\n",
      "Train loss and acc of batch 33: 47.684818267822266, 1.0\n",
      "Train loss and acc of batch 34: 48.28050994873047, 0.984375\n",
      "Train loss and acc of batch 35: 48.11833190917969, 0.96875\n",
      "Train loss and acc of batch 36: 47.68478775024414, 1.0\n",
      "Train loss and acc of batch 37: 48.43800354003906, 0.984375\n",
      "Train loss and acc of batch 38: 49.03369903564453, 0.96875\n",
      "Train loss and acc of batch 39: 47.90153503417969, 0.984375\n",
      "Train loss and acc of batch 40: 47.68475341796875, 1.0\n",
      "Train loss and acc of batch 41: 49.03367614746094, 0.96875\n",
      "Train loss and acc of batch 42: 47.68473815917969, 1.0\n",
      "Train loss and acc of batch 43: 48.280433654785156, 0.984375\n",
      "Train loss and acc of batch 44: 47.684722900390625, 1.0\n",
      "Train loss and acc of batch 45: 48.28040313720703, 0.984375\n",
      "Train loss and acc of batch 46: 47.970558166503906, 0.984375\n",
      "Train loss and acc of batch 47: 47.684696197509766, 1.0\n",
      "Train loss and acc of batch 48: 47.68468475341797, 1.0\n",
      "Train loss and acc of batch 49: 47.6846809387207, 1.0\n",
      "Train loss and acc of batch 50: 48.280364990234375, 0.984375\n",
      "Train loss and acc of batch 51: 49.03357696533203, 0.96875\n",
      "Train loss and acc of batch 52: 48.94049072265625, 0.953125\n",
      "Train loss and acc of batch 53: 47.68463897705078, 1.0\n",
      "Train loss and acc of batch 54: 47.901397705078125, 0.984375\n",
      "Train loss and acc of batch 55: 47.68462371826172, 1.0\n",
      "Train loss and acc of batch 56: 47.68461608886719, 1.0\n",
      "Train loss and acc of batch 57: 48.280311584472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.68459701538086, 1.0\n",
      "Train loss and acc of batch 59: 47.6845817565918, 1.0\n",
      "Train loss and acc of batch 60: 47.68457794189453, 1.0\n",
      "Train loss and acc of batch 61: 47.684566497802734, 1.0\n",
      "Train loss and acc of batch 62: 47.6845588684082, 1.0\n",
      "Train loss and acc of batch 63: 48.87595748901367, 0.96875\n",
      "Train loss and acc of batch 64: 47.90131378173828, 0.984375\n",
      "Train loss and acc of batch 65: 47.684532165527344, 1.0\n",
      "Train loss and acc of batch 66: 47.68452835083008, 1.0\n",
      "Train loss and acc of batch 67: 48.49698257446289, 0.96875\n",
      "Train loss and acc of batch 68: 48.28020477294922, 0.984375\n",
      "Train loss and acc of batch 69: 47.901268005371094, 0.984375\n",
      "Train loss and acc of batch 70: 47.68449020385742, 1.0\n",
      "Training accuracy and loss of epoch #592: 0.9897, 48.0057\n",
      "Saved model by train loss 48.00568341537261\n",
      "Train loss and acc of batch 0: 47.684478759765625, 1.0\n",
      "Train loss and acc of batch 1: 47.684478759765625, 1.0\n",
      "Train loss and acc of batch 2: 47.68446731567383, 1.0\n",
      "Train loss and acc of batch 3: 47.901214599609375, 0.984375\n",
      "Train loss and acc of batch 4: 47.6844482421875, 1.0\n",
      "Train loss and acc of batch 5: 49.033363342285156, 0.96875\n",
      "Train loss and acc of batch 6: 48.18704605102539, 0.96875\n",
      "Train loss and acc of batch 7: 47.684417724609375, 1.0\n",
      "Train loss and acc of batch 8: 48.28010559082031, 0.984375\n",
      "Train loss and acc of batch 9: 47.97026062011719, 0.984375\n",
      "Train loss and acc of batch 10: 47.684391021728516, 1.0\n",
      "Train loss and acc of batch 11: 47.68437957763672, 1.0\n",
      "Train loss and acc of batch 12: 48.437599182128906, 0.984375\n",
      "Train loss and acc of batch 13: 47.90113067626953, 0.984375\n",
      "Train loss and acc of batch 14: 47.901123046875, 0.984375\n",
      "Train loss and acc of batch 15: 48.280052185058594, 0.984375\n",
      "Train loss and acc of batch 16: 48.28004455566406, 0.984375\n",
      "Train loss and acc of batch 17: 48.43755340576172, 0.984375\n",
      "Train loss and acc of batch 18: 48.56587600708008, 0.96875\n",
      "Train loss and acc of batch 19: 47.68431091308594, 1.0\n",
      "Train loss and acc of batch 20: 47.684303283691406, 1.0\n",
      "Train loss and acc of batch 21: 48.279998779296875, 0.984375\n",
      "Train loss and acc of batch 22: 48.27998352050781, 0.984375\n",
      "Train loss and acc of batch 23: 47.68428039550781, 1.0\n",
      "Train loss and acc of batch 24: 48.27996826171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.68425369262695, 1.0\n",
      "Train loss and acc of batch 26: 47.68425369262695, 1.0\n",
      "Train loss and acc of batch 27: 47.68423843383789, 1.0\n",
      "Train loss and acc of batch 28: 47.684234619140625, 1.0\n",
      "Train loss and acc of batch 29: 48.279930114746094, 0.984375\n",
      "Train loss and acc of batch 30: 47.68421936035156, 1.0\n",
      "Train loss and acc of batch 31: 47.900970458984375, 0.984375\n",
      "Train loss and acc of batch 32: 47.684200286865234, 1.0\n",
      "Train loss and acc of batch 33: 47.68418884277344, 1.0\n",
      "Train loss and acc of batch 34: 48.279884338378906, 0.984375\n",
      "Train loss and acc of batch 35: 48.11770248413086, 0.96875\n",
      "Train loss and acc of batch 36: 47.68416213989258, 1.0\n",
      "Train loss and acc of batch 37: 48.4373779296875, 0.984375\n",
      "Train loss and acc of batch 38: 49.03307342529297, 0.96875\n",
      "Train loss and acc of batch 39: 47.90089416503906, 0.984375\n",
      "Train loss and acc of batch 40: 47.68412780761719, 1.0\n",
      "Train loss and acc of batch 41: 49.033042907714844, 0.96875\n",
      "Train loss and acc of batch 42: 47.68410873413086, 1.0\n",
      "Train loss and acc of batch 43: 48.279808044433594, 0.984375\n",
      "Train loss and acc of batch 44: 47.6840934753418, 1.0\n",
      "Train loss and acc of batch 45: 48.27978515625, 0.984375\n",
      "Train loss and acc of batch 46: 47.96992492675781, 0.984375\n",
      "Train loss and acc of batch 47: 47.68406295776367, 1.0\n",
      "Train loss and acc of batch 48: 47.684059143066406, 1.0\n",
      "Train loss and acc of batch 49: 47.684051513671875, 1.0\n",
      "Train loss and acc of batch 50: 48.27973937988281, 0.984375\n",
      "Train loss and acc of batch 51: 49.03295135498047, 0.96875\n",
      "Train loss and acc of batch 52: 48.93986892700195, 0.953125\n",
      "Train loss and acc of batch 53: 47.68400955200195, 1.0\n",
      "Train loss and acc of batch 54: 47.90076446533203, 0.984375\n",
      "Train loss and acc of batch 55: 47.68399429321289, 1.0\n",
      "Train loss and acc of batch 56: 47.683982849121094, 1.0\n",
      "Train loss and acc of batch 57: 48.27967834472656, 0.984375\n",
      "Train loss and acc of batch 58: 47.68396759033203, 1.0\n",
      "Train loss and acc of batch 59: 47.6839599609375, 1.0\n",
      "Train loss and acc of batch 60: 47.683956146240234, 1.0\n",
      "Train loss and acc of batch 61: 47.68394088745117, 1.0\n",
      "Train loss and acc of batch 62: 47.68393325805664, 1.0\n",
      "Train loss and acc of batch 63: 48.875328063964844, 0.96875\n",
      "Train loss and acc of batch 64: 47.900672912597656, 0.984375\n",
      "Train loss and acc of batch 65: 47.68390655517578, 1.0\n",
      "Train loss and acc of batch 66: 47.683902740478516, 1.0\n",
      "Train loss and acc of batch 67: 48.49635314941406, 0.96875\n",
      "Train loss and acc of batch 68: 48.279579162597656, 0.984375\n",
      "Train loss and acc of batch 69: 47.900634765625, 0.984375\n",
      "Train loss and acc of batch 70: 47.683860778808594, 1.0\n",
      "Training accuracy and loss of epoch #593: 0.9897, 48.0051\n",
      "Saved model by train loss 48.00505506488639\n",
      "Train loss and acc of batch 0: 47.68385314941406, 1.0\n",
      "Train loss and acc of batch 1: 47.683841705322266, 1.0\n",
      "Train loss and acc of batch 2: 47.683834075927734, 1.0\n",
      "Train loss and acc of batch 3: 47.900596618652344, 0.984375\n",
      "Train loss and acc of batch 4: 47.68381881713867, 1.0\n",
      "Train loss and acc of batch 5: 49.03273010253906, 0.96875\n",
      "Train loss and acc of batch 6: 48.18642044067383, 0.96875\n",
      "Train loss and acc of batch 7: 47.68378829956055, 1.0\n",
      "Train loss and acc of batch 8: 48.27948760986328, 0.984375\n",
      "Train loss and acc of batch 9: 47.969635009765625, 0.984375\n",
      "Train loss and acc of batch 10: 47.68376541137695, 1.0\n",
      "Train loss and acc of batch 11: 47.683753967285156, 1.0\n",
      "Train loss and acc of batch 12: 48.43696975708008, 0.984375\n",
      "Train loss and acc of batch 13: 47.90049743652344, 0.984375\n",
      "Train loss and acc of batch 14: 47.90049743652344, 0.984375\n",
      "Train loss and acc of batch 15: 48.2794189453125, 0.984375\n",
      "Train loss and acc of batch 16: 48.27941131591797, 0.984375\n",
      "Train loss and acc of batch 17: 48.436927795410156, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 18: 48.56524658203125, 0.96875\n",
      "Train loss and acc of batch 19: 47.68368148803711, 1.0\n",
      "Train loss and acc of batch 20: 47.683677673339844, 1.0\n",
      "Train loss and acc of batch 21: 48.27936553955078, 0.984375\n",
      "Train loss and acc of batch 22: 48.27935791015625, 0.984375\n",
      "Train loss and acc of batch 23: 47.68365478515625, 1.0\n",
      "Train loss and acc of batch 24: 48.27934265136719, 0.984375\n",
      "Train loss and acc of batch 25: 47.683631896972656, 1.0\n",
      "Train loss and acc of batch 26: 47.683624267578125, 1.0\n",
      "Train loss and acc of batch 27: 47.68361282348633, 1.0\n",
      "Train loss and acc of batch 28: 47.68360900878906, 1.0\n",
      "Train loss and acc of batch 29: 48.279296875, 0.984375\n",
      "Train loss and acc of batch 30: 47.68358612060547, 1.0\n",
      "Train loss and acc of batch 31: 47.90034484863281, 0.984375\n",
      "Train loss and acc of batch 32: 47.68356704711914, 1.0\n",
      "Train loss and acc of batch 33: 47.68355941772461, 1.0\n",
      "Train loss and acc of batch 34: 48.27925109863281, 0.984375\n",
      "Train loss and acc of batch 35: 48.117069244384766, 0.96875\n",
      "Train loss and acc of batch 36: 47.68353271484375, 1.0\n",
      "Train loss and acc of batch 37: 48.43675231933594, 0.984375\n",
      "Train loss and acc of batch 38: 49.032440185546875, 0.96875\n",
      "Train loss and acc of batch 39: 47.90027618408203, 0.984375\n",
      "Train loss and acc of batch 40: 47.68350601196289, 1.0\n",
      "Train loss and acc of batch 41: 49.032413482666016, 0.96875\n",
      "Train loss and acc of batch 42: 47.6834831237793, 1.0\n",
      "Train loss and acc of batch 43: 48.2791748046875, 0.984375\n",
      "Train loss and acc of batch 44: 47.6834602355957, 1.0\n",
      "Train loss and acc of batch 45: 48.27915954589844, 0.984375\n",
      "Train loss and acc of batch 46: 47.96929168701172, 0.984375\n",
      "Train loss and acc of batch 47: 47.68343734741211, 1.0\n",
      "Train loss and acc of batch 48: 47.68342971801758, 1.0\n",
      "Train loss and acc of batch 49: 47.683414459228516, 1.0\n",
      "Train loss and acc of batch 50: 48.27910614013672, 0.984375\n",
      "Train loss and acc of batch 51: 49.03233337402344, 0.96875\n",
      "Train loss and acc of batch 52: 48.939231872558594, 0.953125\n",
      "Train loss and acc of batch 53: 47.68338394165039, 1.0\n",
      "Train loss and acc of batch 54: 47.900146484375, 0.984375\n",
      "Train loss and acc of batch 55: 47.68336486816406, 1.0\n",
      "Train loss and acc of batch 56: 47.68335723876953, 1.0\n",
      "Train loss and acc of batch 57: 48.279052734375, 0.984375\n",
      "Train loss and acc of batch 58: 47.6833381652832, 1.0\n",
      "Train loss and acc of batch 59: 47.68333053588867, 1.0\n",
      "Train loss and acc of batch 60: 47.68332290649414, 1.0\n",
      "Train loss and acc of batch 61: 47.68331527709961, 1.0\n",
      "Train loss and acc of batch 62: 47.683311462402344, 1.0\n",
      "Train loss and acc of batch 63: 48.874691009521484, 0.96875\n",
      "Train loss and acc of batch 64: 47.900047302246094, 0.984375\n",
      "Train loss and acc of batch 65: 47.68328094482422, 1.0\n",
      "Train loss and acc of batch 66: 47.683265686035156, 1.0\n",
      "Train loss and acc of batch 67: 48.495723724365234, 0.96875\n",
      "Train loss and acc of batch 68: 48.278953552246094, 0.984375\n",
      "Train loss and acc of batch 69: 47.90000915527344, 0.984375\n",
      "Train loss and acc of batch 70: 47.683231353759766, 1.0\n",
      "Training accuracy and loss of epoch #594: 0.9897, 48.0044\n",
      "Saved model by train loss 48.00442671440017\n",
      "Train loss and acc of batch 0: 47.683223724365234, 1.0\n",
      "Train loss and acc of batch 1: 47.6832160949707, 1.0\n",
      "Train loss and acc of batch 2: 47.68320846557617, 1.0\n",
      "Train loss and acc of batch 3: 47.89996337890625, 0.984375\n",
      "Train loss and acc of batch 4: 47.683189392089844, 1.0\n",
      "Train loss and acc of batch 5: 49.0321044921875, 0.96875\n",
      "Train loss and acc of batch 6: 48.1857795715332, 0.96875\n",
      "Train loss and acc of batch 7: 47.683162689208984, 1.0\n",
      "Train loss and acc of batch 8: 48.27886199951172, 0.984375\n",
      "Train loss and acc of batch 9: 47.968994140625, 0.984375\n",
      "Train loss and acc of batch 10: 47.68313217163086, 1.0\n",
      "Train loss and acc of batch 11: 47.683128356933594, 1.0\n",
      "Train loss and acc of batch 12: 48.43634033203125, 0.984375\n",
      "Train loss and acc of batch 13: 47.899879455566406, 0.984375\n",
      "Train loss and acc of batch 14: 47.899871826171875, 0.984375\n",
      "Train loss and acc of batch 15: 48.278785705566406, 0.984375\n",
      "Train loss and acc of batch 16: 48.278785705566406, 0.984375\n",
      "Train loss and acc of batch 17: 48.436302185058594, 0.984375\n",
      "Train loss and acc of batch 18: 48.56462097167969, 0.96875\n",
      "Train loss and acc of batch 19: 47.68305969238281, 1.0\n",
      "Train loss and acc of batch 20: 47.683048248291016, 1.0\n",
      "Train loss and acc of batch 21: 48.27873992919922, 0.984375\n",
      "Train loss and acc of batch 22: 48.27873229980469, 0.984375\n",
      "Train loss and acc of batch 23: 47.68301773071289, 1.0\n",
      "Train loss and acc of batch 24: 48.278709411621094, 0.984375\n",
      "Train loss and acc of batch 25: 47.683006286621094, 1.0\n",
      "Train loss and acc of batch 26: 47.68299102783203, 1.0\n",
      "Train loss and acc of batch 27: 47.682987213134766, 1.0\n",
      "Train loss and acc of batch 28: 47.682979583740234, 1.0\n",
      "Train loss and acc of batch 29: 48.278663635253906, 0.984375\n",
      "Train loss and acc of batch 30: 47.68295669555664, 1.0\n",
      "Train loss and acc of batch 31: 47.89971923828125, 0.984375\n",
      "Train loss and acc of batch 32: 47.68294143676758, 1.0\n",
      "Train loss and acc of batch 33: 47.68293762207031, 1.0\n",
      "Train loss and acc of batch 34: 48.27862548828125, 0.984375\n",
      "Train loss and acc of batch 35: 48.11643981933594, 0.96875\n",
      "Train loss and acc of batch 36: 47.68290710449219, 1.0\n",
      "Train loss and acc of batch 37: 48.43612289428711, 0.984375\n",
      "Train loss and acc of batch 38: 49.03181457519531, 0.96875\n",
      "Train loss and acc of batch 39: 47.89964294433594, 0.984375\n",
      "Train loss and acc of batch 40: 47.6828727722168, 1.0\n",
      "Train loss and acc of batch 41: 49.03178787231445, 0.96875\n",
      "Train loss and acc of batch 42: 47.68285369873047, 1.0\n",
      "Train loss and acc of batch 43: 48.278541564941406, 0.984375\n",
      "Train loss and acc of batch 44: 47.68283462524414, 1.0\n",
      "Train loss and acc of batch 45: 48.278526306152344, 0.984375\n",
      "Train loss and acc of batch 46: 47.96867370605469, 0.984375\n",
      "Train loss and acc of batch 47: 47.68281173706055, 1.0\n",
      "Train loss and acc of batch 48: 47.682804107666016, 1.0\n",
      "Train loss and acc of batch 49: 47.68279266357422, 1.0\n",
      "Train loss and acc of batch 50: 48.27848815917969, 0.984375\n",
      "Train loss and acc of batch 51: 49.031700134277344, 0.96875\n",
      "Train loss and acc of batch 52: 48.938602447509766, 0.953125\n",
      "Train loss and acc of batch 53: 47.68275833129883, 1.0\n",
      "Train loss and acc of batch 54: 47.899513244628906, 0.984375\n",
      "Train loss and acc of batch 55: 47.682735443115234, 1.0\n",
      "Train loss and acc of batch 56: 47.68273162841797, 1.0\n",
      "Train loss and acc of batch 57: 48.278419494628906, 0.984375\n",
      "Train loss and acc of batch 58: 47.682708740234375, 1.0\n",
      "Train loss and acc of batch 59: 47.68270492553711, 1.0\n",
      "Train loss and acc of batch 60: 47.68269348144531, 1.0\n",
      "Train loss and acc of batch 61: 47.68268585205078, 1.0\n",
      "Train loss and acc of batch 62: 47.68267822265625, 1.0\n",
      "Train loss and acc of batch 63: 48.87406921386719, 0.96875\n",
      "Train loss and acc of batch 64: 47.89942932128906, 0.984375\n",
      "Train loss and acc of batch 65: 47.682647705078125, 1.0\n",
      "Train loss and acc of batch 66: 47.682640075683594, 1.0\n",
      "Train loss and acc of batch 67: 48.49509811401367, 0.96875\n",
      "Train loss and acc of batch 68: 48.27832794189453, 0.984375\n",
      "Train loss and acc of batch 69: 47.899375915527344, 0.984375\n",
      "Train loss and acc of batch 70: 47.68260955810547, 1.0\n",
      "Training accuracy and loss of epoch #595: 0.9897, 48.0038\n",
      "Saved model by train loss 48.003798740010865\n",
      "Train loss and acc of batch 0: 47.68259811401367, 1.0\n",
      "Train loss and acc of batch 1: 47.68258285522461, 1.0\n",
      "Train loss and acc of batch 2: 47.68257522583008, 1.0\n",
      "Train loss and acc of batch 3: 47.899330139160156, 0.984375\n",
      "Train loss and acc of batch 4: 47.682559967041016, 1.0\n",
      "Train loss and acc of batch 5: 49.03147888183594, 0.96875\n",
      "Train loss and acc of batch 6: 48.185157775878906, 0.96875\n",
      "Train loss and acc of batch 7: 47.68253707885742, 1.0\n",
      "Train loss and acc of batch 8: 48.278228759765625, 0.984375\n",
      "Train loss and acc of batch 9: 47.96836853027344, 0.984375\n",
      "Train loss and acc of batch 10: 47.6825065612793, 1.0\n",
      "Train loss and acc of batch 11: 47.682498931884766, 1.0\n",
      "Train loss and acc of batch 12: 48.43571472167969, 0.984375\n",
      "Train loss and acc of batch 13: 47.899253845214844, 0.984375\n",
      "Train loss and acc of batch 14: 47.89923858642578, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 15: 48.278160095214844, 0.984375\n",
      "Train loss and acc of batch 16: 48.278160095214844, 0.984375\n",
      "Train loss and acc of batch 17: 48.435672760009766, 0.984375\n",
      "Train loss and acc of batch 18: 48.56399154663086, 0.96875\n",
      "Train loss and acc of batch 19: 47.68242645263672, 1.0\n",
      "Train loss and acc of batch 20: 47.68241882324219, 1.0\n",
      "Train loss and acc of batch 21: 48.278114318847656, 0.984375\n",
      "Train loss and acc of batch 22: 48.278099060058594, 0.984375\n",
      "Train loss and acc of batch 23: 47.68238830566406, 1.0\n",
      "Train loss and acc of batch 24: 48.27808380126953, 0.984375\n",
      "Train loss and acc of batch 25: 47.682376861572266, 1.0\n",
      "Train loss and acc of batch 26: 47.682369232177734, 1.0\n",
      "Train loss and acc of batch 27: 47.6823616027832, 1.0\n",
      "Train loss and acc of batch 28: 47.682350158691406, 1.0\n",
      "Train loss and acc of batch 29: 48.278038024902344, 0.984375\n",
      "Train loss and acc of batch 30: 47.682334899902344, 1.0\n",
      "Train loss and acc of batch 31: 47.899085998535156, 0.984375\n",
      "Train loss and acc of batch 32: 47.68231201171875, 1.0\n",
      "Train loss and acc of batch 33: 47.68230438232422, 1.0\n",
      "Train loss and acc of batch 34: 48.27799987792969, 0.984375\n",
      "Train loss and acc of batch 35: 48.115814208984375, 0.96875\n",
      "Train loss and acc of batch 36: 47.682281494140625, 1.0\n",
      "Train loss and acc of batch 37: 48.435489654541016, 0.984375\n",
      "Train loss and acc of batch 38: 49.03118133544922, 0.96875\n",
      "Train loss and acc of batch 39: 47.899017333984375, 0.984375\n",
      "Train loss and acc of batch 40: 47.68224334716797, 1.0\n",
      "Train loss and acc of batch 41: 49.03116226196289, 0.96875\n",
      "Train loss and acc of batch 42: 47.68222427368164, 1.0\n",
      "Train loss and acc of batch 43: 48.277915954589844, 0.984375\n",
      "Train loss and acc of batch 44: 47.682212829589844, 1.0\n",
      "Train loss and acc of batch 45: 48.27790069580078, 0.984375\n",
      "Train loss and acc of batch 46: 47.968040466308594, 0.984375\n",
      "Train loss and acc of batch 47: 47.68217849731445, 1.0\n",
      "Train loss and acc of batch 48: 47.68217086791992, 1.0\n",
      "Train loss and acc of batch 49: 47.68216323852539, 1.0\n",
      "Train loss and acc of batch 50: 48.277862548828125, 0.984375\n",
      "Train loss and acc of batch 51: 49.03107452392578, 0.96875\n",
      "Train loss and acc of batch 52: 48.93797302246094, 0.953125\n",
      "Train loss and acc of batch 53: 47.682125091552734, 1.0\n",
      "Train loss and acc of batch 54: 47.89888000488281, 0.984375\n",
      "Train loss and acc of batch 55: 47.68210983276367, 1.0\n",
      "Train loss and acc of batch 56: 47.68210220336914, 1.0\n",
      "Train loss and acc of batch 57: 48.277793884277344, 0.984375\n",
      "Train loss and acc of batch 58: 47.68208694458008, 1.0\n",
      "Train loss and acc of batch 59: 47.68207550048828, 1.0\n",
      "Train loss and acc of batch 60: 47.68206024169922, 1.0\n",
      "Train loss and acc of batch 61: 47.68205642700195, 1.0\n",
      "Train loss and acc of batch 62: 47.682044982910156, 1.0\n",
      "Train loss and acc of batch 63: 48.873443603515625, 0.96875\n",
      "Train loss and acc of batch 64: 47.89879608154297, 0.984375\n",
      "Train loss and acc of batch 65: 47.68202209472656, 1.0\n",
      "Train loss and acc of batch 66: 47.682010650634766, 1.0\n",
      "Train loss and acc of batch 67: 48.49447250366211, 0.96875\n",
      "Train loss and acc of batch 68: 48.27769470214844, 0.984375\n",
      "Train loss and acc of batch 69: 47.89875030517578, 0.984375\n",
      "Train loss and acc of batch 70: 47.681976318359375, 1.0\n",
      "Training accuracy and loss of epoch #596: 0.9897, 48.0032\n",
      "Saved model by train loss 48.00317022834026\n",
      "Train loss and acc of batch 0: 47.681968688964844, 1.0\n",
      "Train loss and acc of batch 1: 47.68196105957031, 1.0\n",
      "Train loss and acc of batch 2: 47.681949615478516, 1.0\n",
      "Train loss and acc of batch 3: 47.898704528808594, 0.984375\n",
      "Train loss and acc of batch 4: 47.68193435668945, 1.0\n",
      "Train loss and acc of batch 5: 49.030845642089844, 0.96875\n",
      "Train loss and acc of batch 6: 48.18453598022461, 0.96875\n",
      "Train loss and acc of batch 7: 47.681907653808594, 1.0\n",
      "Train loss and acc of batch 8: 48.27760314941406, 0.984375\n",
      "Train loss and acc of batch 9: 47.967742919921875, 0.984375\n",
      "Train loss and acc of batch 10: 47.68187713623047, 1.0\n",
      "Train loss and acc of batch 11: 47.68186950683594, 1.0\n",
      "Train loss and acc of batch 12: 48.43508529663086, 0.984375\n",
      "Train loss and acc of batch 13: 47.89861297607422, 0.984375\n",
      "Train loss and acc of batch 14: 47.89861297607422, 0.984375\n",
      "Train loss and acc of batch 15: 48.27753448486328, 0.984375\n",
      "Train loss and acc of batch 16: 48.27753448486328, 0.984375\n",
      "Train loss and acc of batch 17: 48.43503952026367, 0.984375\n",
      "Train loss and acc of batch 18: 48.56336212158203, 0.96875\n",
      "Train loss and acc of batch 19: 47.68179702758789, 1.0\n",
      "Train loss and acc of batch 20: 47.68178939819336, 1.0\n",
      "Train loss and acc of batch 21: 48.277488708496094, 0.984375\n",
      "Train loss and acc of batch 22: 48.27747344970703, 0.984375\n",
      "Train loss and acc of batch 23: 47.681766510009766, 1.0\n",
      "Train loss and acc of batch 24: 48.27745819091797, 0.984375\n",
      "Train loss and acc of batch 25: 47.68174743652344, 1.0\n",
      "Train loss and acc of batch 26: 47.681739807128906, 1.0\n",
      "Train loss and acc of batch 27: 47.68172836303711, 1.0\n",
      "Train loss and acc of batch 28: 47.68172073364258, 1.0\n",
      "Train loss and acc of batch 29: 48.27741241455078, 0.984375\n",
      "Train loss and acc of batch 30: 47.68170166015625, 1.0\n",
      "Train loss and acc of batch 31: 47.898460388183594, 0.984375\n",
      "Train loss and acc of batch 32: 47.68168258666992, 1.0\n",
      "Train loss and acc of batch 33: 47.68167495727539, 1.0\n",
      "Train loss and acc of batch 34: 48.277366638183594, 0.984375\n",
      "Train loss and acc of batch 35: 48.11518859863281, 0.96875\n",
      "Train loss and acc of batch 36: 47.68164825439453, 1.0\n",
      "Train loss and acc of batch 37: 48.43486404418945, 0.984375\n",
      "Train loss and acc of batch 38: 49.03056335449219, 0.96875\n",
      "Train loss and acc of batch 39: 47.89838409423828, 0.984375\n",
      "Train loss and acc of batch 40: 47.68161392211914, 1.0\n",
      "Train loss and acc of batch 41: 49.03053283691406, 0.96875\n",
      "Train loss and acc of batch 42: 47.68159484863281, 1.0\n",
      "Train loss and acc of batch 43: 48.27729034423828, 0.984375\n",
      "Train loss and acc of batch 44: 47.681575775146484, 1.0\n",
      "Train loss and acc of batch 45: 48.27727508544922, 0.984375\n",
      "Train loss and acc of batch 46: 47.96741485595703, 0.984375\n",
      "Train loss and acc of batch 47: 47.681549072265625, 1.0\n",
      "Train loss and acc of batch 48: 47.68153762817383, 1.0\n",
      "Train loss and acc of batch 49: 47.68153762817383, 1.0\n",
      "Train loss and acc of batch 50: 48.2772216796875, 0.984375\n",
      "Train loss and acc of batch 51: 49.03044128417969, 0.96875\n",
      "Train loss and acc of batch 52: 48.937347412109375, 0.953125\n",
      "Train loss and acc of batch 53: 47.68149948120117, 1.0\n",
      "Train loss and acc of batch 54: 47.89825439453125, 0.984375\n",
      "Train loss and acc of batch 55: 47.68148422241211, 1.0\n",
      "Train loss and acc of batch 56: 47.68146896362305, 1.0\n",
      "Train loss and acc of batch 57: 48.27716827392578, 0.984375\n",
      "Train loss and acc of batch 58: 47.68145751953125, 1.0\n",
      "Train loss and acc of batch 59: 47.68144607543945, 1.0\n",
      "Train loss and acc of batch 60: 47.68143844604492, 1.0\n",
      "Train loss and acc of batch 61: 47.68142318725586, 1.0\n",
      "Train loss and acc of batch 62: 47.681419372558594, 1.0\n",
      "Train loss and acc of batch 63: 48.87281799316406, 0.96875\n",
      "Train loss and acc of batch 64: 47.898162841796875, 0.984375\n",
      "Train loss and acc of batch 65: 47.681392669677734, 1.0\n",
      "Train loss and acc of batch 66: 47.6813850402832, 1.0\n",
      "Train loss and acc of batch 67: 48.49384307861328, 0.96875\n",
      "Train loss and acc of batch 68: 48.277069091796875, 0.984375\n",
      "Train loss and acc of batch 69: 47.89812469482422, 0.984375\n",
      "Train loss and acc of batch 70: 47.68134689331055, 1.0\n",
      "Training accuracy and loss of epoch #597: 0.9897, 48.0025\n",
      "Saved model by train loss 48.002541877854036\n",
      "Train loss and acc of batch 0: 47.681339263916016, 1.0\n",
      "Train loss and acc of batch 1: 47.68133544921875, 1.0\n",
      "Train loss and acc of batch 2: 47.68132400512695, 1.0\n",
      "Train loss and acc of batch 3: 47.89807891845703, 0.984375\n",
      "Train loss and acc of batch 4: 47.681297302246094, 1.0\n",
      "Train loss and acc of batch 5: 49.03022003173828, 0.96875\n",
      "Train loss and acc of batch 6: 48.18390655517578, 0.96875\n",
      "Train loss and acc of batch 7: 47.6812744140625, 1.0\n",
      "Train loss and acc of batch 8: 48.27696990966797, 0.984375\n",
      "Train loss and acc of batch 9: 47.96711730957031, 0.984375\n",
      "Train loss and acc of batch 10: 47.681251525878906, 1.0\n",
      "Train loss and acc of batch 11: 47.681243896484375, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 12: 48.43445587158203, 0.984375\n",
      "Train loss and acc of batch 13: 47.897987365722656, 0.984375\n",
      "Train loss and acc of batch 14: 47.897979736328125, 0.984375\n",
      "Train loss and acc of batch 15: 48.27690887451172, 0.984375\n",
      "Train loss and acc of batch 16: 48.27690124511719, 0.984375\n",
      "Train loss and acc of batch 17: 48.43441390991211, 0.984375\n",
      "Train loss and acc of batch 18: 48.5627326965332, 0.96875\n",
      "Train loss and acc of batch 19: 47.681175231933594, 1.0\n",
      "Train loss and acc of batch 20: 47.6811637878418, 1.0\n",
      "Train loss and acc of batch 21: 48.27685546875, 0.984375\n",
      "Train loss and acc of batch 22: 48.27684020996094, 0.984375\n",
      "Train loss and acc of batch 23: 47.68113708496094, 1.0\n",
      "Train loss and acc of batch 24: 48.276824951171875, 0.984375\n",
      "Train loss and acc of batch 25: 47.681121826171875, 1.0\n",
      "Train loss and acc of batch 26: 47.68111038208008, 1.0\n",
      "Train loss and acc of batch 27: 47.68109893798828, 1.0\n",
      "Train loss and acc of batch 28: 47.68109130859375, 1.0\n",
      "Train loss and acc of batch 29: 48.27678680419922, 0.984375\n",
      "Train loss and acc of batch 30: 47.68107223510742, 1.0\n",
      "Train loss and acc of batch 31: 47.89783477783203, 0.984375\n",
      "Train loss and acc of batch 32: 47.68105697631836, 1.0\n",
      "Train loss and acc of batch 33: 47.68104934692383, 1.0\n",
      "Train loss and acc of batch 34: 48.27674102783203, 0.984375\n",
      "Train loss and acc of batch 35: 48.114559173583984, 0.96875\n",
      "Train loss and acc of batch 36: 47.6810188293457, 1.0\n",
      "Train loss and acc of batch 37: 48.43423843383789, 0.984375\n",
      "Train loss and acc of batch 38: 49.029930114746094, 0.96875\n",
      "Train loss and acc of batch 39: 47.89775848388672, 0.984375\n",
      "Train loss and acc of batch 40: 47.68098449707031, 1.0\n",
      "Train loss and acc of batch 41: 49.02989959716797, 0.96875\n",
      "Train loss and acc of batch 42: 47.68096923828125, 1.0\n",
      "Train loss and acc of batch 43: 48.27665710449219, 0.984375\n",
      "Train loss and acc of batch 44: 47.68095016479492, 1.0\n",
      "Train loss and acc of batch 45: 48.276641845703125, 0.984375\n",
      "Train loss and acc of batch 46: 47.96678924560547, 0.984375\n",
      "Train loss and acc of batch 47: 47.68092346191406, 1.0\n",
      "Train loss and acc of batch 48: 47.68091583251953, 1.0\n",
      "Train loss and acc of batch 49: 47.680908203125, 1.0\n",
      "Train loss and acc of batch 50: 48.27659606933594, 0.984375\n",
      "Train loss and acc of batch 51: 49.029815673828125, 0.96875\n",
      "Train loss and acc of batch 52: 48.93671798706055, 0.953125\n",
      "Train loss and acc of batch 53: 47.680870056152344, 1.0\n",
      "Train loss and acc of batch 54: 47.89762878417969, 0.984375\n",
      "Train loss and acc of batch 55: 47.68084716796875, 1.0\n",
      "Train loss and acc of batch 56: 47.680843353271484, 1.0\n",
      "Train loss and acc of batch 57: 48.27653503417969, 0.984375\n",
      "Train loss and acc of batch 58: 47.68082809448242, 1.0\n",
      "Train loss and acc of batch 59: 47.68082046508789, 1.0\n",
      "Train loss and acc of batch 60: 47.680809020996094, 1.0\n",
      "Train loss and acc of batch 61: 47.68080139160156, 1.0\n",
      "Train loss and acc of batch 62: 47.68079376220703, 1.0\n",
      "Train loss and acc of batch 63: 48.87218475341797, 0.96875\n",
      "Train loss and acc of batch 64: 47.89753723144531, 0.984375\n",
      "Train loss and acc of batch 65: 47.680763244628906, 1.0\n",
      "Train loss and acc of batch 66: 47.68075180053711, 1.0\n",
      "Train loss and acc of batch 67: 48.49321365356445, 0.96875\n",
      "Train loss and acc of batch 68: 48.27644348144531, 0.984375\n",
      "Train loss and acc of batch 69: 47.897491455078125, 0.984375\n",
      "Train loss and acc of batch 70: 47.68071746826172, 1.0\n",
      "Training accuracy and loss of epoch #598: 0.9897, 48.0019\n",
      "Saved model by train loss 48.00191341991156\n",
      "Train loss and acc of batch 0: 47.68071365356445, 1.0\n",
      "Train loss and acc of batch 1: 47.680702209472656, 1.0\n",
      "Train loss and acc of batch 2: 47.680694580078125, 1.0\n",
      "Train loss and acc of batch 3: 47.89745330810547, 0.984375\n",
      "Train loss and acc of batch 4: 47.6806755065918, 1.0\n",
      "Train loss and acc of batch 5: 49.02959442138672, 0.96875\n",
      "Train loss and acc of batch 6: 48.18327713012695, 0.96875\n",
      "Train loss and acc of batch 7: 47.68064880371094, 1.0\n",
      "Train loss and acc of batch 8: 48.276344299316406, 0.984375\n",
      "Train loss and acc of batch 9: 47.96647644042969, 0.984375\n",
      "Train loss and acc of batch 10: 47.68062210083008, 1.0\n",
      "Train loss and acc of batch 11: 47.68061828613281, 1.0\n",
      "Train loss and acc of batch 12: 48.4338264465332, 0.984375\n",
      "Train loss and acc of batch 13: 47.897361755371094, 0.984375\n",
      "Train loss and acc of batch 14: 47.89735412597656, 0.984375\n",
      "Train loss and acc of batch 15: 48.276275634765625, 0.984375\n",
      "Train loss and acc of batch 16: 48.276275634765625, 0.984375\n",
      "Train loss and acc of batch 17: 48.433780670166016, 0.984375\n",
      "Train loss and acc of batch 18: 48.56210708618164, 0.96875\n",
      "Train loss and acc of batch 19: 47.6805419921875, 1.0\n",
      "Train loss and acc of batch 20: 47.680538177490234, 1.0\n",
      "Train loss and acc of batch 21: 48.276222229003906, 0.984375\n",
      "Train loss and acc of batch 22: 48.276222229003906, 0.984375\n",
      "Train loss and acc of batch 23: 47.68050765991211, 1.0\n",
      "Train loss and acc of batch 24: 48.27619934082031, 0.984375\n",
      "Train loss and acc of batch 25: 47.68049240112305, 1.0\n",
      "Train loss and acc of batch 26: 47.680477142333984, 1.0\n",
      "Train loss and acc of batch 27: 47.68047332763672, 1.0\n",
      "Train loss and acc of batch 28: 47.68046569824219, 1.0\n",
      "Train loss and acc of batch 29: 48.276153564453125, 0.984375\n",
      "Train loss and acc of batch 30: 47.68044662475586, 1.0\n",
      "Train loss and acc of batch 31: 47.89720153808594, 0.984375\n",
      "Train loss and acc of batch 32: 47.68042755126953, 1.0\n",
      "Train loss and acc of batch 33: 47.680419921875, 1.0\n",
      "Train loss and acc of batch 34: 48.27611541748047, 0.984375\n",
      "Train loss and acc of batch 35: 48.113929748535156, 0.96875\n",
      "Train loss and acc of batch 36: 47.680389404296875, 1.0\n",
      "Train loss and acc of batch 37: 48.4336051940918, 0.984375\n",
      "Train loss and acc of batch 38: 49.029296875, 0.96875\n",
      "Train loss and acc of batch 39: 47.897132873535156, 0.984375\n",
      "Train loss and acc of batch 40: 47.680355072021484, 1.0\n",
      "Train loss and acc of batch 41: 49.029273986816406, 0.96875\n",
      "Train loss and acc of batch 42: 47.68034362792969, 1.0\n",
      "Train loss and acc of batch 43: 48.276031494140625, 0.984375\n",
      "Train loss and acc of batch 44: 47.68032455444336, 1.0\n",
      "Train loss and acc of batch 45: 48.27601623535156, 0.984375\n",
      "Train loss and acc of batch 46: 47.966156005859375, 0.984375\n",
      "Train loss and acc of batch 47: 47.6802978515625, 1.0\n",
      "Train loss and acc of batch 48: 47.68029022216797, 1.0\n",
      "Train loss and acc of batch 49: 47.68027877807617, 1.0\n",
      "Train loss and acc of batch 50: 48.275970458984375, 0.984375\n",
      "Train loss and acc of batch 51: 49.02918243408203, 0.96875\n",
      "Train loss and acc of batch 52: 48.93608856201172, 0.953125\n",
      "Train loss and acc of batch 53: 47.68024444580078, 1.0\n",
      "Train loss and acc of batch 54: 47.896995544433594, 0.984375\n",
      "Train loss and acc of batch 55: 47.68022537231445, 1.0\n",
      "Train loss and acc of batch 56: 47.68021774291992, 1.0\n",
      "Train loss and acc of batch 57: 48.275909423828125, 0.984375\n",
      "Train loss and acc of batch 58: 47.680198669433594, 1.0\n",
      "Train loss and acc of batch 59: 47.68019104003906, 1.0\n",
      "Train loss and acc of batch 60: 47.680179595947266, 1.0\n",
      "Train loss and acc of batch 61: 47.680171966552734, 1.0\n",
      "Train loss and acc of batch 62: 47.68016815185547, 1.0\n",
      "Train loss and acc of batch 63: 48.87155532836914, 0.96875\n",
      "Train loss and acc of batch 64: 47.89691162109375, 0.984375\n",
      "Train loss and acc of batch 65: 47.680137634277344, 1.0\n",
      "Train loss and acc of batch 66: 47.68012619018555, 1.0\n",
      "Train loss and acc of batch 67: 48.49258804321289, 0.96875\n",
      "Train loss and acc of batch 68: 48.27581024169922, 0.984375\n",
      "Train loss and acc of batch 69: 47.89686584472656, 0.984375\n",
      "Train loss and acc of batch 70: 47.680091857910156, 1.0\n",
      "Training accuracy and loss of epoch #599: 0.9897, 48.0013\n",
      "Saved model by train loss 48.00128533806599\n",
      "Train loss and acc of batch 0: 47.680084228515625, 1.0\n",
      "Train loss and acc of batch 1: 47.68007278442383, 1.0\n",
      "Train loss and acc of batch 2: 47.6800651550293, 1.0\n",
      "Train loss and acc of batch 3: 47.896820068359375, 0.984375\n",
      "Train loss and acc of batch 4: 47.680049896240234, 1.0\n",
      "Train loss and acc of batch 5: 49.028961181640625, 0.96875\n",
      "Train loss and acc of batch 6: 48.18265151977539, 0.96875\n",
      "Train loss and acc of batch 7: 47.680023193359375, 1.0\n",
      "Train loss and acc of batch 8: 48.275718688964844, 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 9: 47.965850830078125, 0.984375\n",
      "Train loss and acc of batch 10: 47.679996490478516, 1.0\n",
      "Train loss and acc of batch 11: 47.67998504638672, 1.0\n",
      "Train loss and acc of batch 12: 48.433197021484375, 0.984375\n",
      "Train loss and acc of batch 13: 47.89673614501953, 0.984375\n",
      "Train loss and acc of batch 14: 47.896728515625, 0.984375\n",
      "Train loss and acc of batch 15: 48.27565002441406, 0.984375\n",
      "Train loss and acc of batch 16: 48.27564239501953, 0.984375\n",
      "Train loss and acc of batch 17: 48.43315505981445, 0.984375\n",
      "Train loss and acc of batch 18: 48.56147766113281, 0.96875\n",
      "Train loss and acc of batch 19: 47.67991638183594, 1.0\n",
      "Train loss and acc of batch 20: 47.679908752441406, 1.0\n",
      "Train loss and acc of batch 21: 48.275596618652344, 0.984375\n",
      "Train loss and acc of batch 22: 48.27558898925781, 0.984375\n",
      "Train loss and acc of batch 23: 47.67987823486328, 1.0\n",
      "Train loss and acc of batch 24: 48.27557373046875, 0.984375\n",
      "Train loss and acc of batch 25: 47.67986297607422, 1.0\n",
      "Train loss and acc of batch 26: 47.67985153198242, 1.0\n",
      "Train loss and acc of batch 27: 47.679847717285156, 1.0\n",
      "Train loss and acc of batch 28: 47.679840087890625, 1.0\n",
      "Train loss and acc of batch 29: 48.27552795410156, 0.984375\n",
      "Train loss and acc of batch 30: 47.67981719970703, 1.0\n",
      "Train loss and acc of batch 31: 47.896575927734375, 0.984375\n",
      "Train loss and acc of batch 32: 47.6797981262207, 1.0\n",
      "Train loss and acc of batch 33: 47.67979049682617, 1.0\n",
      "Train loss and acc of batch 34: 48.275482177734375, 0.984375\n",
      "Train loss and acc of batch 35: 48.113304138183594, 0.96875\n",
      "Train loss and acc of batch 36: 47.67976760864258, 1.0\n",
      "Train loss and acc of batch 37: 48.4329833984375, 0.984375\n",
      "Train loss and acc of batch 38: 49.02867126464844, 0.96875\n",
      "Train loss and acc of batch 39: 47.89649963378906, 0.984375\n",
      "Train loss and acc of batch 40: 47.679725646972656, 1.0\n",
      "Train loss and acc of batch 41: 49.028648376464844, 0.96875\n",
      "Train loss and acc of batch 42: 47.67971420288086, 1.0\n",
      "Train loss and acc of batch 43: 48.27540588378906, 0.984375\n",
      "Train loss and acc of batch 44: 47.679691314697266, 1.0\n",
      "Train loss and acc of batch 45: 48.275390625, 0.984375\n",
      "Train loss and acc of batch 46: 47.96552276611328, 0.984375\n",
      "Train loss and acc of batch 47: 47.67966842651367, 1.0\n",
      "Train loss and acc of batch 48: 47.679656982421875, 1.0\n",
      "Train loss and acc of batch 49: 47.679649353027344, 1.0\n",
      "Train loss and acc of batch 50: 48.27533721923828, 0.984375\n",
      "Train loss and acc of batch 51: 49.02855682373047, 0.96875\n",
      "Train loss and acc of batch 52: 48.935462951660156, 0.953125\n",
      "Train loss and acc of batch 53: 47.67961883544922, 1.0\n",
      "Train loss and acc of batch 54: 47.89636993408203, 0.984375\n",
      "Train loss and acc of batch 55: 47.67959976196289, 1.0\n",
      "Train loss and acc of batch 56: 47.679588317871094, 1.0\n",
      "Train loss and acc of batch 57: 48.27528381347656, 0.984375\n",
      "Train loss and acc of batch 58: 47.679569244384766, 1.0\n",
      "Train loss and acc of batch 59: 47.679561614990234, 1.0\n",
      "Train loss and acc of batch 60: 47.67955017089844, 1.0\n",
      "Train loss and acc of batch 61: 47.679542541503906, 1.0\n",
      "Train loss and acc of batch 62: 47.679534912109375, 1.0\n",
      "Train loss and acc of batch 63: 48.87092590332031, 0.96875\n",
      "Train loss and acc of batch 64: 47.896278381347656, 0.984375\n",
      "Train loss and acc of batch 65: 47.67951202392578, 1.0\n",
      "Train loss and acc of batch 66: 47.679500579833984, 1.0\n",
      "Train loss and acc of batch 67: 48.49195098876953, 0.96875\n",
      "Train loss and acc of batch 68: 48.275184631347656, 0.984375\n",
      "Train loss and acc of batch 69: 47.896240234375, 0.984375\n",
      "Train loss and acc of batch 70: 47.679466247558594, 1.0\n",
      "Training accuracy and loss of epoch #600: 0.9897, 48.0007\n",
      "Saved model by train loss 48.00065714876417\n",
      "Train loss and acc of batch 0: 47.67945861816406, 1.0\n",
      "Train loss and acc of batch 1: 47.679447174072266, 1.0\n",
      "Train loss and acc of batch 2: 47.67943572998047, 1.0\n",
      "Train loss and acc of batch 3: 47.89619445800781, 0.984375\n",
      "Train loss and acc of batch 4: 47.67941665649414, 1.0\n",
      "Train loss and acc of batch 5: 49.02833557128906, 0.96875\n",
      "Train loss and acc of batch 6: 48.18201446533203, 0.96875\n",
      "Train loss and acc of batch 7: 47.67938995361328, 1.0\n",
      "Train loss and acc of batch 8: 48.27508544921875, 0.984375\n",
      "Train loss and acc of batch 9: 47.965232849121094, 0.984375\n",
      "Train loss and acc of batch 10: 47.67936706542969, 1.0\n",
      "Train loss and acc of batch 11: 47.679359436035156, 1.0\n",
      "Train loss and acc of batch 12: 48.43257141113281, 0.984375\n",
      "Train loss and acc of batch 13: 47.89610290527344, 0.984375\n",
      "Train loss and acc of batch 14: 47.896095275878906, 0.984375\n",
      "Train loss and acc of batch 15: 48.2750244140625, 0.984375\n",
      "Train loss and acc of batch 16: 48.27500915527344, 0.984375\n",
      "Train loss and acc of batch 17: 48.432533264160156, 0.984375\n",
      "Train loss and acc of batch 18: 48.56085205078125, 0.96875\n",
      "Train loss and acc of batch 19: 47.67928695678711, 1.0\n",
      "Train loss and acc of batch 20: 47.67927551269531, 1.0\n",
      "Train loss and acc of batch 21: 48.27497100830078, 0.984375\n",
      "Train loss and acc of batch 22: 48.27496337890625, 0.984375\n",
      "Train loss and acc of batch 23: 47.67925262451172, 1.0\n",
      "Train loss and acc of batch 24: 48.274940490722656, 0.984375\n",
      "Train loss and acc of batch 25: 47.679237365722656, 1.0\n",
      "Train loss and acc of batch 26: 47.679222106933594, 1.0\n",
      "Train loss and acc of batch 27: 47.67921829223633, 1.0\n",
      "Train loss and acc of batch 28: 47.67920684814453, 1.0\n",
      "Train loss and acc of batch 29: 48.27490234375, 0.984375\n",
      "Train loss and acc of batch 30: 47.6791877746582, 1.0\n",
      "Train loss and acc of batch 31: 47.89595031738281, 0.984375\n",
      "Train loss and acc of batch 32: 47.67917251586914, 1.0\n",
      "Train loss and acc of batch 33: 47.679161071777344, 1.0\n",
      "Train loss and acc of batch 34: 48.27485656738281, 0.984375\n",
      "Train loss and acc of batch 35: 48.112674713134766, 0.96875\n",
      "Train loss and acc of batch 36: 47.67913818359375, 1.0\n",
      "Train loss and acc of batch 37: 48.432350158691406, 0.984375\n",
      "Train loss and acc of batch 38: 49.028045654296875, 0.96875\n",
      "Train loss and acc of batch 39: 47.8958740234375, 0.984375\n",
      "Train loss and acc of batch 40: 47.679100036621094, 1.0\n",
      "Train loss and acc of batch 41: 49.02801513671875, 0.96875\n",
      "Train loss and acc of batch 42: 47.67908477783203, 1.0\n",
      "Train loss and acc of batch 43: 48.27477264404297, 0.984375\n",
      "Train loss and acc of batch 44: 47.6790657043457, 1.0\n",
      "Train loss and acc of batch 45: 48.274757385253906, 0.984375\n",
      "Train loss and acc of batch 46: 47.96490478515625, 0.984375\n",
      "Train loss and acc of batch 47: 47.67903518676758, 1.0\n",
      "Train loss and acc of batch 48: 47.67903137207031, 1.0\n",
      "Train loss and acc of batch 49: 47.67902374267578, 1.0\n",
      "Train loss and acc of batch 50: 48.27471160888672, 0.984375\n",
      "Train loss and acc of batch 51: 49.027931213378906, 0.96875\n",
      "Train loss and acc of batch 52: 48.93482971191406, 0.953125\n",
      "Train loss and acc of batch 53: 47.678985595703125, 1.0\n",
      "Train loss and acc of batch 54: 47.89573669433594, 0.984375\n",
      "Train loss and acc of batch 55: 47.6789665222168, 1.0\n",
      "Train loss and acc of batch 56: 47.67896270751953, 1.0\n",
      "Train loss and acc of batch 57: 48.27465057373047, 0.984375\n",
      "Train loss and acc of batch 58: 47.67893981933594, 1.0\n",
      "Train loss and acc of batch 59: 47.678932189941406, 1.0\n",
      "Train loss and acc of batch 60: 47.67892837524414, 1.0\n",
      "Train loss and acc of batch 61: 47.678916931152344, 1.0\n",
      "Train loss and acc of batch 62: 47.67890548706055, 1.0\n",
      "Train loss and acc of batch 63: 48.87030029296875, 0.96875\n",
      "Train loss and acc of batch 64: 47.895652770996094, 0.984375\n",
      "Train loss and acc of batch 65: 47.67887878417969, 1.0\n",
      "Train loss and acc of batch 66: 47.678871154785156, 1.0\n",
      "Train loss and acc of batch 67: 48.49132537841797, 0.96875\n",
      "Train loss and acc of batch 68: 48.274559020996094, 0.984375\n",
      "Train loss and acc of batch 69: 47.895606994628906, 0.984375\n",
      "Train loss and acc of batch 70: 47.678836822509766, 1.0\n",
      "Training accuracy and loss of epoch #601: 0.9897, 48.0000\n",
      "Saved model by train loss 48.00002863709356\n",
      "Train loss and acc of batch 0: 47.67882537841797, 1.0\n",
      "Train loss and acc of batch 1: 47.67881774902344, 1.0\n",
      "Train loss and acc of batch 2: 47.67880630493164, 1.0\n",
      "Train loss and acc of batch 3: 47.89556884765625, 0.984375\n",
      "Train loss and acc of batch 4: 47.67879104614258, 1.0\n",
      "Train loss and acc of batch 5: 49.02770233154297, 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 6: 48.18138885498047, 0.96875\n",
      "Train loss and acc of batch 7: 47.67876052856445, 1.0\n",
      "Train loss and acc of batch 8: 48.27445983886719, 0.984375\n",
      "Train loss and acc of batch 9: 47.96460723876953, 0.984375\n",
      "Train loss and acc of batch 10: 47.67873764038086, 1.0\n",
      "Train loss and acc of batch 11: 47.67873001098633, 1.0\n",
      "Train loss and acc of batch 12: 48.431941986083984, 0.984375\n",
      "Train loss and acc of batch 13: 47.895477294921875, 0.984375\n",
      "Train loss and acc of batch 14: 47.895469665527344, 0.984375\n",
      "Train loss and acc of batch 15: 48.274391174316406, 0.984375\n",
      "Train loss and acc of batch 16: 48.274383544921875, 0.984375\n",
      "Train loss and acc of batch 17: 48.43190002441406, 0.984375\n",
      "Train loss and acc of batch 18: 48.56022262573242, 0.96875\n",
      "Train loss and acc of batch 19: 47.67865753173828, 1.0\n",
      "Train loss and acc of batch 20: 47.67864990234375, 1.0\n",
      "Train loss and acc of batch 21: 48.27433776855469, 0.984375\n",
      "Train loss and acc of batch 22: 48.274330139160156, 0.984375\n",
      "Train loss and acc of batch 23: 47.678627014160156, 1.0\n",
      "Train loss and acc of batch 24: 48.274314880371094, 0.984375\n",
      "Train loss and acc of batch 25: 47.67860412597656, 1.0\n",
      "Train loss and acc of batch 26: 47.6786003112793, 1.0\n",
      "Train loss and acc of batch 27: 47.678585052490234, 1.0\n",
      "Train loss and acc of batch 28: 47.67858123779297, 1.0\n",
      "Train loss and acc of batch 29: 48.274269104003906, 0.984375\n",
      "Train loss and acc of batch 30: 47.67856216430664, 1.0\n",
      "Train loss and acc of batch 31: 47.89531707763672, 0.984375\n",
      "Train loss and acc of batch 32: 47.67854309082031, 1.0\n",
      "Train loss and acc of batch 33: 47.678531646728516, 1.0\n",
      "Train loss and acc of batch 34: 48.27422332763672, 0.984375\n",
      "Train loss and acc of batch 35: 48.11204147338867, 0.96875\n",
      "Train loss and acc of batch 36: 47.67850875854492, 1.0\n",
      "Train loss and acc of batch 37: 48.431724548339844, 0.984375\n",
      "Train loss and acc of batch 38: 49.02741241455078, 0.96875\n",
      "Train loss and acc of batch 39: 47.895240783691406, 0.984375\n",
      "Train loss and acc of batch 40: 47.6784782409668, 1.0\n",
      "Train loss and acc of batch 41: 49.02738952636719, 0.96875\n",
      "Train loss and acc of batch 42: 47.6784553527832, 1.0\n",
      "Train loss and acc of batch 43: 48.274147033691406, 0.984375\n",
      "Train loss and acc of batch 44: 47.678436279296875, 1.0\n",
      "Train loss and acc of batch 45: 48.274131774902344, 0.984375\n",
      "Train loss and acc of batch 46: 47.964271545410156, 0.984375\n",
      "Train loss and acc of batch 47: 47.678409576416016, 1.0\n",
      "Train loss and acc of batch 48: 47.678401947021484, 1.0\n",
      "Train loss and acc of batch 49: 47.67839050292969, 1.0\n",
      "Train loss and acc of batch 50: 48.274085998535156, 0.984375\n",
      "Train loss and acc of batch 51: 49.02729797363281, 0.96875\n",
      "Train loss and acc of batch 52: 48.934200286865234, 0.953125\n",
      "Train loss and acc of batch 53: 47.67835998535156, 1.0\n",
      "Train loss and acc of batch 54: 47.895118713378906, 0.984375\n",
      "Train loss and acc of batch 55: 47.678340911865234, 1.0\n",
      "Train loss and acc of batch 56: 47.67832946777344, 1.0\n",
      "Train loss and acc of batch 57: 48.274024963378906, 0.984375\n",
      "Train loss and acc of batch 58: 47.67831039428711, 1.0\n",
      "Train loss and acc of batch 59: 47.678306579589844, 1.0\n",
      "Train loss and acc of batch 60: 47.67829895019531, 1.0\n",
      "Train loss and acc of batch 61: 47.678287506103516, 1.0\n",
      "Train loss and acc of batch 62: 47.67827606201172, 1.0\n",
      "Train loss and acc of batch 63: 48.869667053222656, 0.96875\n",
      "Train loss and acc of batch 64: 47.89501953125, 0.984375\n",
      "Train loss and acc of batch 65: 47.67824935913086, 1.0\n",
      "Train loss and acc of batch 66: 47.67823791503906, 1.0\n",
      "Train loss and acc of batch 67: 48.49069595336914, 0.96875\n",
      "Train loss and acc of batch 68: 48.27392578125, 0.984375\n",
      "Train loss and acc of batch 69: 47.89497375488281, 0.984375\n",
      "Train loss and acc of batch 70: 47.67820358276367, 1.0\n",
      "Training accuracy and loss of epoch #602: 0.9897, 47.9994\n",
      "Saved model by train loss 47.99939953441351\n",
      "Train loss and acc of batch 0: 47.678192138671875, 1.0\n",
      "Train loss and acc of batch 1: 47.678184509277344, 1.0\n",
      "Train loss and acc of batch 2: 47.67818069458008, 1.0\n",
      "Train loss and acc of batch 3: 47.894935607910156, 0.984375\n",
      "Train loss and acc of batch 4: 47.678157806396484, 1.0\n",
      "Train loss and acc of batch 5: 49.027076721191406, 0.96875\n",
      "Train loss and acc of batch 6: 48.180763244628906, 0.96875\n",
      "Train loss and acc of batch 7: 47.67813491821289, 1.0\n",
      "Train loss and acc of batch 8: 48.273826599121094, 0.984375\n",
      "Train loss and acc of batch 9: 47.963966369628906, 0.984375\n",
      "Train loss and acc of batch 10: 47.678104400634766, 1.0\n",
      "Train loss and acc of batch 11: 47.6781005859375, 1.0\n",
      "Train loss and acc of batch 12: 48.43130874633789, 0.984375\n",
      "Train loss and acc of batch 13: 47.89484405517578, 0.984375\n",
      "Train loss and acc of batch 14: 47.89483642578125, 0.984375\n",
      "Train loss and acc of batch 15: 48.27375793457031, 0.984375\n",
      "Train loss and acc of batch 16: 48.27375793457031, 0.984375\n",
      "Train loss and acc of batch 17: 48.431270599365234, 0.984375\n",
      "Train loss and acc of batch 18: 48.55958557128906, 0.96875\n",
      "Train loss and acc of batch 19: 47.67803192138672, 1.0\n",
      "Train loss and acc of batch 20: 47.67802047729492, 1.0\n",
      "Train loss and acc of batch 21: 48.273712158203125, 0.984375\n",
      "Train loss and acc of batch 22: 48.273704528808594, 0.984375\n",
      "Train loss and acc of batch 23: 47.6779899597168, 1.0\n",
      "Train loss and acc of batch 24: 48.273681640625, 0.984375\n",
      "Train loss and acc of batch 25: 47.677974700927734, 1.0\n",
      "Train loss and acc of batch 26: 47.67795944213867, 1.0\n",
      "Train loss and acc of batch 27: 47.67795944213867, 1.0\n",
      "Train loss and acc of batch 28: 47.677947998046875, 1.0\n",
      "Train loss and acc of batch 29: 48.27363586425781, 0.984375\n",
      "Train loss and acc of batch 30: 47.67792892456055, 1.0\n",
      "Train loss and acc of batch 31: 47.894691467285156, 0.984375\n",
      "Train loss and acc of batch 32: 47.67790985107422, 1.0\n",
      "Train loss and acc of batch 33: 47.67790603637695, 1.0\n",
      "Train loss and acc of batch 34: 48.273597717285156, 0.984375\n",
      "Train loss and acc of batch 35: 48.11141586303711, 0.96875\n",
      "Train loss and acc of batch 36: 47.67787551879883, 1.0\n",
      "Train loss and acc of batch 37: 48.431087493896484, 0.984375\n",
      "Train loss and acc of batch 38: 49.02677917480469, 0.96875\n",
      "Train loss and acc of batch 39: 47.894615173339844, 0.984375\n",
      "Train loss and acc of batch 40: 47.67784118652344, 1.0\n",
      "Train loss and acc of batch 41: 49.026756286621094, 0.96875\n",
      "Train loss and acc of batch 42: 47.67782211303711, 1.0\n",
      "Train loss and acc of batch 43: 48.27350616455078, 0.984375\n",
      "Train loss and acc of batch 44: 47.67780685424805, 1.0\n",
      "Train loss and acc of batch 45: 48.27349853515625, 0.984375\n",
      "Train loss and acc of batch 46: 47.96363830566406, 0.984375\n",
      "Train loss and acc of batch 47: 47.67778015136719, 1.0\n",
      "Train loss and acc of batch 48: 47.677772521972656, 1.0\n",
      "Train loss and acc of batch 49: 47.67776107788086, 1.0\n",
      "Train loss and acc of batch 50: 48.27345275878906, 0.984375\n",
      "Train loss and acc of batch 51: 49.02666473388672, 0.96875\n",
      "Train loss and acc of batch 52: 48.93357467651367, 0.953125\n",
      "Train loss and acc of batch 53: 47.67772674560547, 1.0\n",
      "Train loss and acc of batch 54: 47.89448547363281, 0.984375\n",
      "Train loss and acc of batch 55: 47.677711486816406, 1.0\n",
      "Train loss and acc of batch 56: 47.67770004272461, 1.0\n",
      "Train loss and acc of batch 57: 48.27338409423828, 0.984375\n",
      "Train loss and acc of batch 58: 47.67768096923828, 1.0\n",
      "Train loss and acc of batch 59: 47.67767333984375, 1.0\n",
      "Train loss and acc of batch 60: 47.67765808105469, 1.0\n",
      "Train loss and acc of batch 61: 47.67765426635742, 1.0\n",
      "Train loss and acc of batch 62: 47.67764663696289, 1.0\n",
      "Train loss and acc of batch 63: 48.86903762817383, 0.96875\n",
      "Train loss and acc of batch 64: 47.89439392089844, 0.984375\n",
      "Train loss and acc of batch 65: 47.67761993408203, 1.0\n",
      "Train loss and acc of batch 66: 47.677608489990234, 1.0\n",
      "Train loss and acc of batch 67: 48.49007034301758, 0.96875\n",
      "Train loss and acc of batch 68: 48.27330017089844, 0.984375\n",
      "Train loss and acc of batch 69: 47.89434814453125, 0.984375\n",
      "Train loss and acc of batch 70: 47.677574157714844, 1.0\n",
      "Training accuracy and loss of epoch #603: 0.9897, 47.9988\n",
      "Saved model by train loss 47.99876844379264\n",
      "Train loss and acc of batch 0: 47.67756652832031, 1.0\n",
      "Train loss and acc of batch 1: 47.67756271362305, 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and acc of batch 2: 47.677547454833984, 1.0\n",
      "Train loss and acc of batch 3: 47.89429473876953, 0.984375\n",
      "Train loss and acc of batch 4: 47.677528381347656, 1.0\n",
      "Train loss and acc of batch 5: 49.026451110839844, 0.96875\n",
      "Train loss and acc of batch 6: 48.18013381958008, 0.96875\n",
      "Train loss and acc of batch 7: 47.67750930786133, 1.0\n",
      "Train loss and acc of batch 8: 48.273193359375, 0.984375\n",
      "Train loss and acc of batch 9: 47.96333312988281, 0.984375\n",
      "Train loss and acc of batch 10: 47.6774787902832, 1.0\n",
      "Train loss and acc of batch 11: 47.67747497558594, 1.0\n",
      "Train loss and acc of batch 12: 48.43068313598633, 0.984375\n",
      "Train loss and acc of batch 13: 47.89421844482422, 0.984375\n",
      "Train loss and acc of batch 14: 47.89421081542969, 0.984375\n",
      "Train loss and acc of batch 15: 48.27313995361328, 0.984375\n",
      "Train loss and acc of batch 16: 48.27312469482422, 0.984375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f3e28d8712e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./saved_models_overlap_fasterer_loss/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-a11d72862e47>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtrain_loss_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_gen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_trigger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalization_switch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalization_switch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train loss and acc of batch {0}: {1}, {2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BCMarcel\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BCMarcel\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BCMarcel\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BCMarcel\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BCMarcel\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\BCMarcel\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session()\n",
    "\n",
    "    saver.restore(sess, \"./saved_models_overlap_fasterer_loss/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\")\n",
    "    train_network(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models_overlap_fasterer/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "saver.restore(sess, \"./saved_models_overlap_fasterer/best_model_bidirectional_128_l2_accuracy_overlap_faster_learning_5000eps_training_no_validation.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(session, data, labels):\n",
    "    predictions = sess.run(tf.argmax(prediction, 1), feed_dict={X:data, Y:labels, keep_prob:1.0, normalization_switch: False})\n",
    "    true_labels = [onehot.index(1.0) for onehot in labels]\n",
    "    return confusion_matrix(predictions, true_labels)\n",
    "\n",
    "def get_final_results(session, data, labels):\n",
    "    final_dict = {'ang': 0, 'hap': 0, 'neu': 0, 'sad': 0}\n",
    "    overall_dict = {'ang': 0, 'hap': 0, 'neu': 0, 'sad': 0}\n",
    "    predictions = session.run(correct_prediction, feed_dict={X:data, Y:labels, keep_prob:1.0, normalization_switch: False})\n",
    "    coupled = list(zip(predictions, onehot_decode(labels)))\n",
    "    \n",
    "    for couple in coupled:\n",
    "        if (couple[0]):\n",
    "            final_dict[couple[1]] += 1\n",
    "        overall_dict[couple[1]] += 1\n",
    "    \n",
    "    return final_dict, overall_dict\n",
    "\n",
    "def get_final_results_glued(session, labels, correct):\n",
    "    final_dict = {'ang': 0, 'hap': 0, 'neu': 0, 'sad': 0}\n",
    "    overall_dict = {'ang': 0, 'hap': 0, 'neu': 0, 'sad': 0}\n",
    "    coupled = list(zip(correct, onehot_decode(labels)))\n",
    "    \n",
    "    for couple in coupled:\n",
    "        if (couple[0]):\n",
    "            final_dict[couple[1]] += 1\n",
    "        overall_dict[couple[1]] += 1\n",
    "    \n",
    "    return final_dict, overall_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = np.asarray([])\n",
    "final_correct_preds = np.asarray([])\n",
    "final_probs = np.empty((0, 4))\n",
    "final_probs_softmax = np.empty((0, 4))\n",
    "\n",
    "\n",
    "midpoint = math.ceil(len(test_labels)/2)\n",
    "for i in range(0, 2):\n",
    "    predictions_test = sess.run(correct_prediction, feed_dict={X:test_data[i*midpoint:(i+1)*midpoint], Y:test_labels[i*midpoint:(i+1)*midpoint], keep_prob:1.0, normalization_switch: False})\n",
    "    probabilities_test = sess.run(prediction, feed_dict={X:test_data[i*midpoint:(i+1)*midpoint], Y:test_labels[i*midpoint:(i+1)*midpoint], keep_prob:1.0, normalization_switch: False})\n",
    "    predictions_test_confusion = sess.run(tf.argmax(prediction, 1), feed_dict={X:test_data[i*midpoint:(i+1)*midpoint], Y:test_labels[i*midpoint:(i+1)*midpoint], keep_prob:1.0, normalization_switch: False})\n",
    "    predictions_test_softmax = sess.run(prediction, feed_dict={X:test_data[i*midpoint:(i+1)*midpoint], Y:test_labels[i*midpoint:(i+1)*midpoint], keep_prob:1.0, normalization_switch: False})\n",
    "\n",
    "    final_correct_preds = np.concatenate((final_correct_preds, predictions_test))\n",
    "    final_probs = np.concatenate((final_probs, probabilities_test))\n",
    "    final_preds = np.concatenate((final_preds, predictions_test_confusion))\n",
    "    final_probs_softmax = np.concatenate((final_probs_softmax, predictions_test_softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 40,  21,  48,   5],\n",
       "       [  8,  27,  67,   4],\n",
       "       [ 16,  76, 430,  70],\n",
       "       [  7,   1, 125, 238]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(final_preds, [onehot.index(1.0) for onehot in test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict_test, overall_dict_test = get_final_results_glued(sess, test_labels, final_correct_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ang': 40, 'hap': 27, 'neu': 430, 'sad': 238}\n",
      "{'ang': 71, 'hap': 125, 'neu': 670, 'sad': 317}\n"
     ]
    }
   ],
   "source": [
    "print(final_dict_test)\n",
    "print(overall_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5429899924998458\n",
      "0.621301775147929\n"
     ]
    }
   ],
   "source": [
    "print(unweighted_accuracy(final_dict_test, overall_dict_test))\n",
    "print(weighted_accuracy(final_dict_test, overall_dict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5429899924998458, 0.49336373985703674)\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(final_preds, [onehot.index(1.0) for onehot in test_labels], average='macro')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.00000004 1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.99999988 0.00000012]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.99756098 0.00243898]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.00000091 0.99999905]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.99999082 0.00000914]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.3056455  0.69435453 0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.01605902 0.98394102 0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.00000305 0.         0.9999969  0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.00000007 0.99999988]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.00000191 0.         0.99999809 0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.85232192 0.14767805]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.99876738 0.00123269]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.48512897 0.         0.51487106 0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.00001112 0.99998891]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.00006533 0.99993467 0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.00000001 1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.00000291 0.         0.99999714]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.00064853 0.99935144]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "print(final_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.99984753, 0.00015241, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.00000002],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.00108455, 0.        , 0.99891543, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.99999535, 0.00000464, 0.        ],\n",
       "       [0.        , 0.        , 0.87060416, 0.12939586],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9999094 , 0.00009054, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.96100885, 0.03899107],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.00000122, 0.99999881, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.00000311, 0.9999969 , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.99999952, 0.00000046, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.01398093, 0.98601913],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.00037966, 0.99962032, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.99995387, 0.        , 0.00004618, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.99920911, 0.00079098, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.00000285, 0.99999714, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.99999416, 0.00000579, 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.99999857, 0.        , 0.00000137],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.00651271, 0.99348724],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.07755695, 0.92244309, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.00000005],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.98002863, 0.        , 0.01997141],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_probs_softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
